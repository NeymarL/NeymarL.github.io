<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>NIUHE</title>
  
  <subtitle>日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれんな</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.52coding.com.cn/"/>
  <updated>2019-04-12T07:10:35.318Z</updated>
  <id>http://www.52coding.com.cn/</id>
  
  <author>
    <name>NIUHE</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Microeconomics - The Costs of Production</title>
    <link href="http://www.52coding.com.cn/2019/04/10/The%20Costs%20of%20Production/"/>
    <id>http://www.52coding.com.cn/2019/04/10/The Costs of Production/</id>
    <published>2019-04-10T03:23:45.000Z</published>
    <updated>2019-04-12T07:10:35.318Z</updated>
    
    <content type="html"><![CDATA[<p>In this chapter, we examine firm behavior in more detail. This topic will give you a better understanding of the decisions behind the supply curve. In addition, it will introduce you to a part of economics called <em>industrial organization</em> — the study of how firms’ decisions about prices and quantities depend on the market conditions they face.</p><a id="more"></a><h2><span id="what-are-costs">WHAT ARE COSTS?</span></h2><p>We begin our discussion of costs at a Cookie factory. By examining some of the issues that the owner faces in his/her business, we can learn some lessons about costs that apply to all firms in an economy.</p><h3><span id="total-revenue-total-cost-and-profit">Total Revenue, Total Cost, and Profit</span></h3><p>The amount that the firm receives for the sale of its output is called its <strong>total revenue</strong>. The amount that the firm pays to buy inputs is called its <strong>total cost</strong>. <strong>Profit</strong> is a firm’s total revenue minus its total cost:</p><p><span class="math display">\[\text{Profit} = \text{Total revenue} - \text{Total cost}\]</span></p><p>To see how a firm goes about maximizing profit, we must consider fully how to measure its total revenue and its total cost. Total revenue is the easy part: It equals the <em>quantity</em> of output the firm produces <em>times</em> the <em>price</em> at which it sells its output. By contrast, the measurement of a firm’s total cost is more subtle.</p><h3><span id="costs-as-opportunity-costs">Costs As Opportunity Costs</span></h3><p><strong>explicit costs</strong>: input costs that require an outlay of money by the firm <strong>implicit costs</strong>: input costs that do not require an outlay of money by the firm</p><p>Imagine that the owner of the cookie factory is skilled with computers and could earn ¥100 per hour working as a programmer. For every hour that she works at her cookie factory, she gives up ¥100 in income, and this forgone income is also part of her costs. The total cost of her business is the sum of the explicit costs and the implicit costs.</p><h3><span id="the-cost-of-capital-as-an-opportunity-cost">The Cost of Capital as An Opportunity Cost</span></h3><p>An important implicit cost of almost every business is the opportunity cost of the financial capital that has been invested in the business. Suppose, for instance, that the owner of the cookie factory used ¥300,000 of her savings to buy her cookie factory from its previous owner. If she had instead left this money deposited in a savings account that pays an interest rate of 5 percent, she would have earned ¥15,000 per year. To own her cookie factory, therefore, Caroline has given up ¥15,000 a year in interest income. This forgone ¥15,000 is one of the <strong>implicit opportunity costs</strong> of Caroline’s business.</p><h3><span id="economic-profit-versus-accounting-profit">Economic Profit Versus Accounting Profit</span></h3><p>Now let’s return to the firm’s objective: <strong>profit</strong>. An economist measures a firm’s <strong>economic profit</strong> as the firm’s total revenue minus all the opportunity costs (explicit and implicit) of producing the goods and services sold. An accountant measures the firm’s <strong>accounting profit</strong> as the firm’s total revenue minus only the firm’s explicit costs as shown in Figure 1.</p><p><img src="/images/costandprod/DraggedImage.jpg"></p><p>Economic profit is an important concept because it is what motivates the firms that supply goods and services. As we will see, <em>a firm making positive economic profit will stay in business</em>. It is covering all its opportunity costs and has some revenue left to reward the firm owners. When a firm is making economic losses, the business owners are failing to earn enough revenue to cover all the costs of production. Unless conditions change, the firm owners will eventually close down the business and exit the industry. To understand business decisions, we need to keep an eye on economic profit.</p><p><strong>Economic profit equals to zero</strong> means your business is running well and you pay yourself the same amount as you get paid somewhere else.</p><h2><span id="production-and-costs">PRODUCTION AND COSTS</span></h2><p><img src="/images/costandprod/DraggedImage-1.jpg"></p><p>Table 1 shows how the quantity of cookies produced per hour at the cookie factory depends on the number of workers. This relationship between the <em>quantity of inputs</em> (workers) and <em>quantity of output</em> (cookies) is called the <strong>production function</strong>.</p><p><img src="/images/costandprod/DraggedImage-2.jpg"></p><p>To take a step toward understanding these decisions, the third column in the table gives the <strong>marginal product</strong> of a worker. Notice that as the number of workers increases, the marginal product declines. The second worker has a marginal product of 40 cookies, the third worker has a marginal product of 30 cookies, and the fourth worker has a marginal product of 20 cookies. This property is called <strong>diminishing marginal product</strong>.</p><p>Diminishing marginal product is also apparent in Figure 2. The production function’s slope tells us the change in the factory’s output of cookies for each additional input of labor. That is, the <strong>slope of the production function</strong> measures the <em>marginal product</em> of a worker. As the number of workers increases, the marginal product declines, and the production function becomes flatter.</p><h3><span id="from-the-production-function-to-the-total-cost-curve">From The Production Function To The Total-Cost Curve</span></h3><p>Our goal in the next is to study firms’ production and pricing decisions. For this purpose, the most important relationship in Table 1 is between quantity produced and total costs. Panel (b) of Figure 2 graphs these two columns of data with the quantity produced on the horizontal axis and total cost on the vertical axis. This graph is called the <strong>total-cost curve</strong>.</p><p>Now compare the total-cost curve in panel (b) with the production function in panel (a). These two curves are opposite sides of the same coin. The total-cost curve gets <em>steeper</em> as the amount produced rises, whereas the production function gets <em>flatter</em> as production rises. These changes in slope occur for the same reason. High production of cookies means that Caroline’s kitchen is crowded with many workers. Because the kitchen is crowded, each additional worker adds less to production, reflecting diminishing marginal product. Therefore, the production function is relatively flat. But now turn this logic around: When the kitchen is crowded, producing an additional cookie requires a lot of additional labor and is thus very costly. Therefore, when the quantity produced is large, the total-cost curve is relatively steep.</p><h2><span id="the-various-measures-of-cost">THE VARIOUS MEASURES OF COST</span></h2><p><img src="/images/costandprod/DraggedImage-3.jpg"></p><p>To see how related measures of cost are derived, we consider the example in Table 2. This table presents cost data on Conrad’s Coffee Shop. Figure 3 plots Conrad’s total-cost curve. Conrad’s total-cost curve becomes steeper as the quantity produced rises, which (as we have discussed) reflects <em>diminishing marginal product</em>.</p><p><img src="/images/costandprod/DraggedImage-4.jpg"></p><h3><span id="fixed-and-variable-costs">Fixed And Variable Costs</span></h3><p><strong>Fixed costs</strong> are costs that do not vary with the <em>quantity of output produced</em>. They are incurred even if the firm produces nothing at all. Conrad’s fixed costs include any rent he pays because this cost is the same regardless of how much coffee he produces.</p><p><strong>Variable costs</strong> are costs that change as the firm alters the quantity of output produced. Conrad’s variable costs include the cost of coffee beans, milk, sugar, and paper cups: The more cups of coffee Conrad makes, the more of these items he needs to buy.</p><p>A firm’s <strong>total cost</strong> is the sum of fixed and variable costs. In Table 2, total cost in the second column equals fixed cost in the third column plus variable cost in the fourth column.</p><h3><span id="average-and-marginal-cost">Average and Marginal Cost</span></h3><p>Total cost divided by the quantity of output is called <strong>average total cost</strong>. Because total cost is the sum of fixed and variable costs, average total cost can be expressed as the sum of average fixed cost and average variable cost. <strong>Average fixed cost</strong> is the fixed cost divided by the quantity of output, and <strong>average variable cost</strong> is the variable cost divided by the quantity of output.</p><p>Although average total cost tells us the cost of the typical unit, it does not tell us how much total cost will change as the firm alters its level of production. <strong>Marginal cost</strong> is the increase in total cost that arises from an extra unit of production. In the table, the marginal cost appears halfway between two rows because it represents the change in total cost as quantity of output increases from one level to another.</p><p>Mathematically:</p><p><span class="math display">\[ATC = TC/Q \\MC = \triangle TC / \triangle Q\]</span></p><h3><span id="cost-curves-and-their-shapes">Cost Curves And Their Shapes</span></h3><p><img src="/images/costandprod/DraggedImage-5.jpg"></p><p>Figure 4 graphs Conrad’s costs using the data from Table 2. The horizontal axis measures the quantity the firm produces, and the vertical axis measures marginal and average costs. The graph shows four curves: average total cost (ATC), average fixed cost (AFC), average variable cost (AVC), and marginal cost (MC).</p><p><strong>Rising Marginal Cost</strong> Conrad’s marginal cost rises with the quantity of out- put produced. This reflects the property of diminishing marginal product.</p><p><strong>U-Shaped Average Total Cost</strong> Average total cost is the sum of average fixed cost and average variable cost. Average fixed cost always declines as output rises because the fixed cost is spread over a larger number of units. Average variable cost typically rises as output increases because of diminishing marginal product. Average total cost reflects the shapes of both average fixed cost and average variable cost.</p><p>The bottom of the U-shape occurs at the quantity that minimizes average total cost. This <em>quantity</em> is sometimes called the <strong>efficient scale</strong> of the firm. At the efficient scale, these two forces are balanced to yield the lowest average total cost.</p><p><strong>The Relationship Between Marginal Cost and Average Total Cost</strong> * Whenever marginal cost is less than average total cost, average total cost is falling. * Whenever marginal cost is greater than average total cost, average total cost is rising.</p><p>To see why, consider an analogy. Average total cost is like your cumulative grade point average. Marginal cost is like the grade in the next course you will take. If your grade in your next course is less than your grade point average, your grade point average will fall. If your grade in your next course is higher than your grade point average, your grade point average will rise. The mathematics of average and marginal costs is exactly the same as the mathematics of average and marginal grades.</p><p>This relationship between average total cost and marginal cost has an important corollary: <strong>The marginal-cost curve crosses the average-total-cost curve at its minimum</strong>. As you will see in the next chapter, <strong>minimum average total cost</strong> plays a key role in the analysis of competitive firms.</p><h3><span id="typical-cost-curves">Typical Cost Curves</span></h3><p><img src="/images/costandprod/DraggedImage-6.jpg"></p><p>Actual firms are usually more complicated than what we talked about before. In many firms, marginal product does not start to fall immediately after the first worker is hired. Depending on the production process, the second or third worker might have a higher marginal product than the first because a team of workers can divide tasks and work more productively than a single worker. Firms exhibiting this pattern would experience increasing marginal product for a while before diminishing marginal product set in.</p><p>Figure 5 shows the cost curves for such a firm, including average total cost (ATC), average fixed cost (AFC), average variable cost (AVC), and marginal cost (MC). Despite these differences from our previous example, the cost curves shown here share the three properties that are most important to remember:</p><ul><li>Marginal cost eventually rises with the quantity of output.</li><li>The average-total-cost curve is U-shaped.</li><li>The marginal-cost curve crosses the average-total-cost curve at the <strong>minimum of average total cost</strong>.</li></ul><h2><span id="conclusion">CONCLUSION</span></h2><p><img src="/images/costandprod/DraggedImage-7.jpg"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In this chapter, we examine firm behavior in more detail. This topic will give you a better understanding of the decisions behind the supply curve. In addition, it will introduce you to a part of economics called &lt;em&gt;industrial organization&lt;/em&gt; — the study of how firms’ decisions about prices and quantities depend on the market conditions they face.&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="微观经济型原理" scheme="http://www.52coding.com.cn/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%9E%8B%E5%8E%9F%E7%90%86/"/>
    
      <category term="Marginal Cost" scheme="http://www.52coding.com.cn/tags/Marginal-Cost/"/>
    
      <category term="Profit" scheme="http://www.52coding.com.cn/tags/Profit/"/>
    
  </entry>
  
  <entry>
    <title>Microeconomics - Consumers, Producers, and the Efficiency of Markets</title>
    <link href="http://www.52coding.com.cn/2019/03/20/Consumers,%20Producers,%20and%20the%20Efficiency%20of%20Markets/"/>
    <id>http://www.52coding.com.cn/2019/03/20/Consumers, Producers, and the Efficiency of Markets/</id>
    <published>2019-03-20T08:17:37.000Z</published>
    <updated>2019-04-12T07:10:01.054Z</updated>
    
    <content type="html"><![CDATA[<p>In this chapter, we take up the topic of <strong>welfare economics</strong>, the study of how the allocation of resources affects economic well-being. This analysis leads to a profound conclusion: The equilibrium of supply and demand in a market maximizes the total benefits received by buyers and sellers.</p><a id="more"></a><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#consumer-surplus">CONSUMER SURPLUS</a><ul><li><a href="#willingness-to-pay">Willingness To Pay</a></li><li><a href="#using-the-demand-curve-to-measure-consumer-surplus">Using The Demand Curve To Measure Consumer Surplus</a></li><li><a href="#how-a-lower-price-raises-consumer-surplus">How A Lower Price Raises Consumer Surplus</a></li><li><a href="#what-does-consumer-surplus-measure">What Does Consumer Surplus Measure?</a></li></ul></li><li><a href="#producer-surplus">PRODUCER SURPLUS</a><ul><li><a href="#cost-and-the-willingness-to-sell">Cost And The Willingness To Sell</a></li><li><a href="#using-the-supply-curve-to-measure-producer-surplus">Using The Supply Curve To Measure Producer Surplus</a></li><li><a href="#how-a-higher-price-raises-producer-surplus">How A Higher Price Raises Producer Surplus</a></li></ul></li><li><a href="#market-efficiency">MARKET EFFICIENCY</a><ul><li><a href="#the-benevolent-social-planner">The Benevolent Social Planner</a></li><li><a href="#evaluating-the-market-equilibrium">Evaluating The Market Equilibrium</a></li></ul></li><li><a href="#conclusion">CONCLUSION</a></li></ul><!-- tocstop --><h2><span id="consumer-surplus">CONSUMER SURPLUS</span></h2><h3><span id="willingness-to-pay">Willingness To Pay</span></h3><p><strong>Willingness to pay</strong> is the maximum amount that a buyer will pay for a good. <strong>Consumer surplus</strong> is the amount a buyer is willing to pay for a good minus the amount the buyer actually pays for it. For example, John is willing to pay ¥100 for an album but pays only ¥80 for it. So John receives <em>consumer surplus</em> of ¥20.</p><h3><span id="using-the-demand-curve-to-measure-consumer-surplus">Using The Demand Curve To Measure Consumer Surplus</span></h3><p>Say John, Paul, George, and Ringo willing to buy an old album. Table 1 shows the maximum price that each of the four possible buyers would pay. The table in Figure 1 shows the demand schedule that corresponds to Table 1.</p><p><img src="/images/surplus/DraggedImage.jpg"> <img src="/images/surplus/DraggedImage-1.jpg"></p><p>Because the demand curve reflects buyers’ willingness to pay, we can also use it to measure consumer surplus. Figure 2 uses the demand curve to compute consumer surplus in our two examples.</p><p><img src="/images/surplus/DraggedImage-2.jpg"></p><p>We can find out that <strong>the area below the demand curve and above the price measures the consumer surplus in a market</strong>. This is true because the height of the demand curve measures the value buyers place on the good, as measured by their willingness to pay for it. The difference between this willingness to pay and the market price is each buyer’s consumer surplus. Thus, the total area below the demand curve and above the price is the sum of the consumer surplus of all buyers in the market for a good or service.</p><h3><span id="how-a-lower-price-raises-consumer-surplus">How A Lower Price Raises Consumer Surplus</span></h3><p><img src="/images/surplus/DraggedImage-3.jpg"></p><p>Figure 3 shows a typical demand curve. In panel (a), consumer surplus at a price of P1 is the area of triangle ABC. Now suppose that the price falls from P1 to P2, as shown in panel (b). The consumer surplus now equals area ADF.</p><p>This increase in consumer surplus is composed of two parts. First, those buyers who were already buying Q1 of the good at the higher price P1 are better off because they now pay less. It equals the area of the rectangle BCDE. Seconds, some new buyers enter the market. The consumer surplus these newcomers receive is the area of the triangle CEF.</p><h3><span id="what-does-consumer-surplus-measure">What Does Consumer Surplus Measure?</span></h3><p>Consumer surplus, the amount that buyers are willing to pay for a good minus the amount they actually pay for it, measures the benefit that buyers reveille from a good as the buyers themselves perceive it. Thus, consumer surplus is a good measure of economic well-being if policymakers want to respect the <strong>preferences of buyers</strong>.</p><h2><span id="producer-surplus">PRODUCER SURPLUS</span></h2><h3><span id="cost-and-the-willingness-to-sell">Cost And The Willingness To Sell</span></h3><p>A seller’s <strong>cost</strong> of doing a work is the value of everything the seller must give up to produce a good. <strong>Producer surplus</strong> is the amount a seller is paid for a good minus the seller’s cost of providing it.</p><h3><span id="using-the-supply-curve-to-measure-producer-surplus">Using The Supply Curve To Measure Producer Surplus</span></h3><p>Say there are four painters, Mary, Frida, Georgia, Grandma, compete for painting a house. Table 2 shows the costs of them. <img src="/images/surplus/DraggedImage-4.jpg"></p><p>Producer surplus is closely related to the supply curve. The table in Figure 4 shows the supply schedule that corresponds to the costs in Table 2. The graph in Figure 4 shows the supply curve that corresponds to this supply schedule.</p><p><img src="/images/surplus/DraggedImage-5.jpg"></p><p>Because the supply curve reflects sellers’ cost, we can use it to measure producer surplus, as shown in Figure 5. <strong>The area below the price and above the supply curve measures the producer surplus in a market</strong>. The logic is straightforward: The height of the supply curve measures sellers’ costs, and the difference between the price and the cost of production is each seller’s producer surplus. Thus, the total area is the sum of the producer surplus of all sellers. <img src="/images/surplus/DraggedImage-6.jpg"></p><h3><span id="how-a-higher-price-raises-producer-surplus">How A Higher Price Raises Producer Surplus</span></h3><p><img src="/images/surplus/DraggedImage-7.jpg"></p><p>Figure 6 shows a typical upward-sloping supply curve that would arise in a market with many sellers. In panel (a), the price is P1, and producer surplus is the area of triangle ABC. Panel (b) shows what happens when the price rises from P1 to P2. Producer surplus now equals area ADF.</p><h2><span id="market-efficiency">MARKET EFFICIENCY</span></h2><h3><span id="the-benevolent-social-planner">The Benevolent Social Planner</span></h3><p>One possible way to measure the economic well-being of a society is the sum of consumer and producer surplus, which we called <strong>total surplus</strong>. Consumer surplus is the benefit that buyers receive from participating in a market, and producer surplus is the benefit that sellers receive. It is therefore natural to use total surplus as a measure of society’s economic well-being.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Total surplus = Value to buyers - Cost to sellers</span><br></pre></td></tr></table></figure><p>Total surplus in a market is the total value to buyers of the goods, as measured by their willingness to pay, minus the total cost to sellers of providing those goods. If an allocation of resources maximizes total surplus, we say that the allocation exhibits <strong>efficiency</strong>.</p><p>In addition to efficiency, the social planner might also care about <strong>equality</strong>— that is, whether the various buyers and sellers in the market have a similar level of economic well-being.</p><h3><span id="evaluating-the-market-equilibrium">Evaluating The Market Equilibrium</span></h3><p><img src="/images/surplus/DraggedImage-8.jpg"></p><p>Figure 7 shows consumer and producer surplus when a market reaches the equilibrium of supply and demand curve. The total area between the supply and demand curves up to the point of equilibrium represents the total surplus in this market. Those buyers who value the good more than the price choose the buy the good; buyers who value it less than the price do not. Similarly, those sellers whose costs are less than the price choose to produce and sell the good.</p><p>These observations lead to three insights about market outcomes: 1. Free markets allocate the supply of goods to the buyers who value them most highly, as measured by their willingness to pay. 2. Free markets allocate the demand for goods to the sellers who can produce them at the least cost. 3. Free markets produce the quantity of goods that maximizes the sum of consumer and producer surplus.</p><p><img src="/images/surplus/DraggedImage-9.jpg"></p><p>Figure 8 illustrates why this is true. At any quantity below the equilibrium level, such as Q1, the value to the marginal buyer exceeds the cost to the marginal seller. As a result, increasing the quantity produced and consumed raises total surplus. This continues to be true until the quantity reaches the equilibrium level. Similar situations happed when the quantity larger than the equilibrium level.</p><p>Therefore, the equilibrium outcome is an <strong>efficient</strong> allocation of resources.</p><h2><span id="conclusion">CONCLUSION</span></h2><p>This chapter introduced the basic tools of welfare economics — consumer and producer surplus — and used them to evaluate the efficiency of free markets. We showed that the forces of supply and demand allocate resources efficiently.</p><p>A word of warning is in order. To conclude that markets are efficient, we made several assumptions about how markets work. First, our analysis assumed that markets are perfectly competitive. In the world, however, competition is sometimes far from perfect. Second, out analysis assumed that the outcome in a market matters only to the buyers and sellers in that market. Yet, in the world, the decisions of buyers and sellers sometimes affect people who are not participants in the market at all. Pollution is the classic example. Such side effects, called <strong>externalities</strong>, cause welfare in a market to depend on more than just the value to the buyers and the cost to the sellers.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In this chapter, we take up the topic of &lt;strong&gt;welfare economics&lt;/strong&gt;, the study of how the allocation of resources affects economic well-being. This analysis leads to a profound conclusion: The equilibrium of supply and demand in a market maximizes the total benefits received by buyers and sellers.&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="微观经济型原理" scheme="http://www.52coding.com.cn/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%9E%8B%E5%8E%9F%E7%90%86/"/>
    
      <category term="Market Efficiency" scheme="http://www.52coding.com.cn/tags/Market-Efficiency/"/>
    
      <category term="Consumer Surplus" scheme="http://www.52coding.com.cn/tags/Consumer-Surplus/"/>
    
      <category term="Producer Surplus" scheme="http://www.52coding.com.cn/tags/Producer-Surplus/"/>
    
  </entry>
  
  <entry>
    <title>Microeconomics - Elasticity and Its Application</title>
    <link href="http://www.52coding.com.cn/2019/02/22/Elasticity%20and%20Its%20Application/"/>
    <id>http://www.52coding.com.cn/2019/02/22/Elasticity and Its Application/</id>
    <published>2019-02-22T08:02:01.000Z</published>
    <updated>2019-04-12T07:10:06.980Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#the-elasticity-of-demand">The Elasticity of Demand</a><ul><li><a href="#the-price-elasticity-of-demand-and-its-determinants">The Price Elasticity of Demand and Its Determinants</a></li><li><a href="#computing-the-price-elasticity-of-demand">Computing the Price Elasticity of Demand</a></li><li><a href="#the-midpoint-method-a-better-way-to-calculate-percentage-changes-and-elasticities">The Midpoint Method: A Better Way To Calculate Percentage Changes and Elasticities</a></li><li><a href="#the-variety-of-demand-curves">The Variety of Demand Curves</a></li><li><a href="#total-revenue-and-the-price-elasticity-of-demand">Total Revenue and The Price Elasticity of Demand</a></li><li><a href="#elasticity-and-total-revenue-along-a-linear-demand-curve">Elasticity and Total Revenue Along A Linear Demand Curve</a></li><li><a href="#other-demand-elasticities">Other Demand Elasticities</a></li></ul></li><li><a href="#the-elasticity-of-supply">The Elasticity Of Supply</a><ul><li><a href="#the-price-elasticity-of-supply-and-its-determinants">The Price Elasticity of Supply And Its Determinants</a></li><li><a href="#computing-the-price-elasticity-of-supply">Computing The Price Elasticity of Supply</a></li><li><a href="#the-vary-of-supply-curves">The Vary Of Supply Curves</a></li></ul></li><li><a href="#three-applications-of-supply-demand-and-elasticity">Three Applications Of Supply, Demand, And Elasticity</a><ul><li><a href="#can-good-news-for-farming-be-bad-news-for-farmers">Can Good News For Farming Be Bad News For Farmers</a></li><li><a href="#why-did-opec-fail-to-keep-the-price-of-oil-high">Why Did OPEC Fail To Keep The Price Of Oil High?</a></li><li><a href="#does-drug-interdiction-increase-or-decrease-drug-related-crime">Does Drug Interdiction Increase Or Decrease Drug-Related Crime?</a></li></ul></li><li><a href="#the-distributional-effects-of-tax">The Distributional Effects of Tax</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="the-elasticity-of-demand">The Elasticity of Demand</span></h2><p>To measure how much consumers respond to changes in economic variables, economists use the concept of <strong>elasticity</strong>. Elasticity is a measure of the responsiveness of quantity demanded or quantity supplied to one of its determinants.</p><h3><span id="the-price-elasticity-of-demand-and-its-determinants">The Price Elasticity of Demand and Its Determinants</span></h3><p>The <strong>price elasticity of demand</strong> measures how much the quantity demanded responds to a change in price. Demand for a good is said to be <em>elastic</em> if the quantity demanded responds substantially to changes in the price. Demand is said to be <em>inelastic</em> if the quantity demanded responds only slightly to changes in the price.</p><p>Based on experience, however, we can state some general rules about what determines the price elasticity of demand.</p><ul><li>Availablity of Close Substitutes</li><li>Necessities versus Luxuries</li><li>Definition of the Market</li><li>Time Horizon</li></ul><h3><span id="computing-the-price-elasticity-of-demand">Computing the Price Elasticity of Demand</span></h3><p><strong>Price elasticity of demand</strong> = Percentage change in quantity demanded / Percentage change in price</p><p>For example, suppose that a 10 percent increase in the price of an ice-cream cone causes the amount of ie cream you buy to fall by 20 percent. We calculate your elasticity of demand as</p><p>Price elasticity of demand = 20 percent / 10 percent = 2.</p><p>In this example, the elasticity is 2, reflecting that the change in the quantity demanded is proportionately twice as large as the change in the price. <em>A larger price elasticity implies a greater responsiveness of quantity demanded to price.</em></p><h3><span id="the-midpoint-method-a-better-way-to-calculate-percentage-changes-and-elasticities">The Midpoint Method: A Better Way To Calculate Percentage Changes and Elasticities</span></h3><p>The elasticity from point A to point B seems different from the elasticity from point B to point A. This difference arises because the percentage changes are calculated from a different base.</p><p>One way to avoid this problem is to use the <strong>midpoint method</strong> for calculating elasticities. The midpoint method computes a percentage change by dividing the midpoint of the initial and final levels. The following formula expresses the midpoint method for calculating the price elasticity of demand between two points, denoted (Q1, P1) and (Q2, P2):</p><p><img src="/images/elastic/DraggedImage.jpg"></p><h3><span id="the-variety-of-demand-curves">The Variety of Demand Curves</span></h3><p>Demand is considered <strong>elastic</strong> when the elasticity is greater than 1. Demand is considered <strong>inelastic</strong> when the elasticity is less than 1. Because the price elasticity of demand measures how much quantity demanded responds to changes in the price, it is closely related to the slope of the demand curve. The <strong>flatter</strong> the demand curve that passes through a given point, the <strong>greater</strong> the price elasticity of demand. The <strong>steeper</strong> the demand curve that passes through a given point, the <strong>smaller</strong> the price elasticity of demand. Figure 1 shows five cases.</p><p><img src="/images/elastic/DraggedImage-1.jpg"></p><h3><span id="total-revenue-and-the-price-elasticity-of-demand">Total Revenue and The Price Elasticity of Demand</span></h3><p><strong>Toal revenue</strong> is the amount paid by buyers and received by sellers of the good. In any market, total revenue is P * Q, the price of the good times the quantity of the good sold. We can show total revenue graphically, as in Figure 2.</p><p><img src="/images/elastic/DraggedImage-2.jpg"></p><p>How does total revenue change as one moves along the demand curve? There are some examples in Figure 3.</p><p><img src="/images/elastic/DraggedImage-3.jpg"></p><p>Although the examples in this figure are extreme, they illustrate some general rules:</p><ul><li>When demand is <strong>inelastic</strong>, price and total revenue move in the <strong>same direction</strong>.</li><li>When demand is <strong>elastic</strong>, price and total revenue move in <strong>opposite directions</strong>.</li><li>If demand is <strong>unit elastic</strong> (a price elasticity exactly equal to 1), total revenue <strong>remains constant</strong> when the price changes.</li></ul><h3><span id="elasticity-and-total-revenue-along-a-linear-demand-curve">Elasticity and Total Revenue Along A Linear Demand Curve</span></h3><p><img src="/images/elastic/DraggedImage-4.jpg"></p><p>Even though the slope of a linear demand curve is constant, the elasticity is not. This is true because the slope is the ratio of <em>changes</em> in the two variables, whereas the elasticity is the ratio of <em>percentage changes</em> in the two variables. At points with a low price and high quantity, the demand curve is inelastic. At points with a high price and low quantity, the demand curve is elastic.</p><p>The linear demand curve illustrates that the price elasticity of demand need not be the same at all points on a demand curve. A constant elasticity is possible, but it is not always the case.</p><h3><span id="other-demand-elasticities">Other Demand Elasticities</span></h3><p><strong>The Income Elasticity of Demand</strong> measures how the quantity demanded changes as consumer income changes.</p><p><img src="/images/elastic/DraggedImage-5.jpg"></p><p>Most of goods are <em>normal goods</em>: Higher income raises the quantity demanded, which have positive income elasticities. A few goods, such as bus rides, are <em>inferior goods</em>: Higher income lowers the quantity demanded, which have negative income elasticities.</p><p><strong>The Cross-Price Elasticity of Demand</strong> measures how the quantity demanded of one good responds to a change in the price of another good.</p><p><img src="/images/elastic/DraggedImage-6.jpg"></p><p>Substitutes are goods that are typically used in place of one another, whose cross-price elasticity is positive. Conversely, complements are goods that are typically used together, whose cross-price elasticity is negative.</p><h2><span id="the-elasticity-of-supply">The Elasticity Of Supply</span></h2><h3><span id="the-price-elasticity-of-supply-and-its-determinants">The Price Elasticity of Supply And Its Determinants</span></h3><p>The <strong>price elasticity of supply</strong> measures how much the quantity supplied responds to changes in the price. Supply of a good is said to be <em>elastic</em> if the quantity supplied responds substantially to changes in the price.</p><p>In most markets, a key determinant of the price elasticity of supply is the <strong>time period</strong> being considered. Supply is usually <em>more elastic in the long run</em> than in the short run.</p><h3><span id="computing-the-price-elasticity-of-supply">Computing The Price Elasticity of Supply</span></h3><p>Economists compute the price elasticity of supply as the percentage change in the quantity supplied divided by the percentage change in the price. That is, <img src="/images/elastic/DraggedImage-7.jpg"></p><h3><span id="the-vary-of-supply-curves">The Vary Of Supply Curves</span></h3><p><img src="/images/elastic/DraggedImage-8.jpg"></p><p><img src="/images/elastic/DraggedImage-9.jpg"></p><h2><span id="three-applications-of-supply-demand-and-elasticity">Three Applications Of Supply, Demand, And Elasticity</span></h2><h3><span id="can-good-news-for-farming-be-bad-news-for-farmers">Can Good News For Farming Be Bad News For Farmers</span></h3><p>The raise of production provided by new farming technology could make farmers worse off. Because the new technic increase the amount of wheat that can be produced on each acre of land, farmers are willing to supply more wheat at any price. In other words, <strong>the supply curve shift to the right</strong> and the demand curve still remain the same, which cause the price of wheat falls.</p><p><img src="/images/elastic/DraggedImage-10.jpg"></p><p>Wheat being an <strong>inelastic good</strong>, the price of wheat falls doesn’t make people buy a lot more wheat. So a decrease in price causes farmers’ total revenue to fall.</p><p>You may wonder why farmers would adopt the new technology. The answer goes to the heart of <strong>how competitive markets work</strong>. Because each farmer is only a small part of the market for wheat, it’s better to use the new technic to produce and sell more wheat at any given price. Yet when all farmers do this, the supply of wheat increases, the price falls, and farmers are worse off.</p><p>It is important to keep in mind that what is good for farmers is not necessarily good for society as a whole. Improvement in farm technology can be bad for farmers because it makes farmers increasingly unnecessary, but it is surely good for consumers who pay less for food.</p><h3><span id="why-did-opec-fail-to-keep-the-price-of-oil-high">Why Did OPEC Fail To Keep The Price Of Oil High?</span></h3><p>The OPEC episode of 1970s and 1980s shows how supply and demand can behave differently in the short run and in the long run. <strong>In the short run</strong>, both the supply and demand for oil are <strong>inelastic</strong>. Supply is inelastic because the quantity of known oil reserves and the capacity for oil extraction cannot be changed quickly. Demand is inelastic because buying habits do not respond immediately to changes in price. Thus, as panel (a) of Figure 8 shows, <em>the short-run supply and demand curves are steep</em>.</p><p><img src="/images/elastic/DraggedImage-11.jpg"></p><p>The situation is very different in the long run. Over long periods of time, producers of oil outside OPEC respond to high prices by increasing oil exploration. Consumers respond with greater conservation. Thus, as panel (b) of Figure 8 shows, <em>the long-run supply and demand curves are more elastic</em>.</p><h3><span id="does-drug-interdiction-increase-or-decrease-drug-related-crime">Does Drug Interdiction Increase Or Decrease Drug-Related Crime?</span></h3><p><img src="/images/elastic/DraggedImage-12.jpg"></p><p>Suppose the government increase the number of federal agents devoted to the war on drugs. When the government stops some drugs from entering the country and arrests more smugglers, it raises the cost of selling drugs and, therefore, reduces the quantity of drugs supplied at any given price. But the <em>demand for drugs is not changed</em>, as panel (a) of Figure 9 shows.</p><p>But in terms of drug-related crime, since the demand for drugs is inelastic, then an increase in price raises total revenue in the drug market. Addicts who already had to steal to support their habits would have an even greater need for quick cash. Thus, <strong>drug interdiction could increase drug-related crime</strong>.</p><p>Rather than trying to reduce the supply of drugs, policymakers might try to reduce the demand by pursuing a policy of <strong>drug education</strong>. Successful drug education has the effects shown in panel (b) of Figure 9. Thus, in contrast to drug interdiction, <strong>drug education can reduce both drug use and drug-related crime</strong>.</p><p>However, the demand for drugs is probably inelastic over short periods, it may be more elastic elastic over longer periods because higher prices would discourage experimentation with drugs among the young and, over time, lead to fewer drug addicts. In this case, <strong>drug interdiction would increase drug-related crime in the short run while decreasing it in the long run</strong>.</p><h2><span id="the-distributional-effects-of-tax">The Distributional Effects of Tax</span></h2><p>Suppose this is the supply and demand curve of the gasoline market of Chicago without tax. The market price will be ¥3 when there is no tax. So buyers pay ¥3 to buy one gallon of gasoline and sellers receive ¥3 for one gallon of gasoline.</p><p><img src="/images/elastic/DraggedImage-13.jpg"></p><p>Suppose the government imposes a tax of ¥0.5 per gallon of gasoline and suppose the buyer will pay the tax. Then the demand curve will move left because there's a tax more. And that is changing the tax everywhere in the curve. So from any point, vertically in the curve, to the other point, we're going to have a distance of 50 cents. Let’s say the new demand curve generate a new equilibrium at price ¥2.75. So, what the buyers end up paying is at ¥2.75, the buyer that goes to the Sellers, plus the 50 cents that goes to the government. So in the end, they're actually paying ¥3.25 for a gallon of gasoline.</p><p><img src="/images/elastic/DraggedImage.png"></p><p>Now the buyers are paying ¥3.25. So they are worse off because they have a higher price by ¥0.25. And the sellers, while they were receiving ¥3 before, now they're only getting ¥2.75. So they are worse off by 25 cents too. Well, it looks like, in this particular situation, the buyers are sharing 25 cents, they're paying of the tax and sellers are putting up with 25 cents of the tax. So, <strong>this tax is equally distributed among the buyers and the sellers</strong>. And it doesn't matter if the sellers are the ones sending this tax to the government.</p><table><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;">No Tax</th><th style="text-align: center;">Tax ¥0.5</th><th style="text-align: center;">Change</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Market Price</td><td style="text-align: center;">¥3.00</td><td style="text-align: center;">¥2.75</td><td style="text-align: center;">¥0.25</td></tr><tr class="even"><td style="text-align: center;">Buyers Pay</td><td style="text-align: center;">¥3.00</td><td style="text-align: center;">¥3.25</td><td style="text-align: center;">¥0.25</td></tr><tr class="odd"><td style="text-align: center;">Sellers Receive</td><td style="text-align: center;">¥3.00</td><td style="text-align: center;">¥2.75</td><td style="text-align: center;">¥0.25</td></tr></tbody></table><p>So what determined the distribution of the tax is which side of the market <em>has the most trouble adjusting to a tax</em>. And in this particular example, we're assuming that both have the same trouble and that is based on the elasticity. And the more inclined the curve is, the more inelastic that side of the market is.</p><p>Let's say the demand curve is like that below and the supply curve is a lot flatter. So this model here makes the assumption that the demand of gasoline is more inelastic than the supply of gasoline.</p><p><img src="/images/elastic/DraggedImage-14.jpg"></p><p>What happened? The market price went down to ¥2.80. The buyers pays ¥2.80 to the sellers, but then they pay 50 cents to the government. So they're actually paying effectively ¥3.30 with this tax. So they're paying 30 cents more than they were paying before per gallon of gasoline. How about the sellers? The sellers were selling it for ¥3 before. Now, they're getting ¥2.80 from the buyers, so they're worse off 20 cents. And it's a whole different story, because now, of the 50 cents, 30 cents are shared by the buyers and only 20 cents by the sellers. So <em>the sellers are not sharing as much of the burden of this tax as the buyers are</em>.</p><table><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;">No Tax</th><th style="text-align: center;">Tax ¥0.5</th><th style="text-align: center;">Change</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Market Price</td><td style="text-align: center;">¥3.00</td><td style="text-align: center;">¥2.80</td><td style="text-align: center;">¥0.20</td></tr><tr class="even"><td style="text-align: center;">Buyers Pay</td><td style="text-align: center;">¥3.00</td><td style="text-align: center;">¥3.30</td><td style="text-align: center;">¥0.30</td></tr><tr class="odd"><td style="text-align: center;">Sellers Receive</td><td style="text-align: center;">¥3.00</td><td style="text-align: center;">¥2.80</td><td style="text-align: center;">¥0.20</td></tr></tbody></table><p>So the seller has a lot more freedom here to adjust to this tax by perhaps charging a higher price to the buyers. The buyers cannot adjust as easily and they will have to put up with most of the burden. So in the end, <strong>the most inelastic side of the market is the one that actually shares most of the burden of the tax</strong> regardless of who send the tax to the government.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-elasticity-of-demand&quot;&gt;The Elasticity of Demand&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-price-elasticity-of-demand-and-its-determinants&quot;&gt;The Price Elasticity of Demand and Its Determinants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#computing-the-price-elasticity-of-demand&quot;&gt;Computing the Price Elasticity of Demand&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-midpoint-method-a-better-way-to-calculate-percentage-changes-and-elasticities&quot;&gt;The Midpoint Method: A Better Way To Calculate Percentage Changes and Elasticities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-variety-of-demand-curves&quot;&gt;The Variety of Demand Curves&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#total-revenue-and-the-price-elasticity-of-demand&quot;&gt;Total Revenue and The Price Elasticity of Demand&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#elasticity-and-total-revenue-along-a-linear-demand-curve&quot;&gt;Elasticity and Total Revenue Along A Linear Demand Curve&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#other-demand-elasticities&quot;&gt;Other Demand Elasticities&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-elasticity-of-supply&quot;&gt;The Elasticity Of Supply&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-price-elasticity-of-supply-and-its-determinants&quot;&gt;The Price Elasticity of Supply And Its Determinants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#computing-the-price-elasticity-of-supply&quot;&gt;Computing The Price Elasticity of Supply&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-vary-of-supply-curves&quot;&gt;The Vary Of Supply Curves&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#three-applications-of-supply-demand-and-elasticity&quot;&gt;Three Applications Of Supply, Demand, And Elasticity&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#can-good-news-for-farming-be-bad-news-for-farmers&quot;&gt;Can Good News For Farming Be Bad News For Farmers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#why-did-opec-fail-to-keep-the-price-of-oil-high&quot;&gt;Why Did OPEC Fail To Keep The Price Of Oil High?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#does-drug-interdiction-increase-or-decrease-drug-related-crime&quot;&gt;Does Drug Interdiction Increase Or Decrease Drug-Related Crime?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-distributional-effects-of-tax&quot;&gt;The Distributional Effects of Tax&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="微观经济型原理" scheme="http://www.52coding.com.cn/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%9E%8B%E5%8E%9F%E7%90%86/"/>
    
      <category term="elasticity" scheme="http://www.52coding.com.cn/tags/elasticity/"/>
    
      <category term="economic" scheme="http://www.52coding.com.cn/tags/economic/"/>
    
  </entry>
  
  <entry>
    <title>Microeconomics - The Market Forces of Supply and Demand</title>
    <link href="http://www.52coding.com.cn/2019/02/11/The%20Market%20Forces%20of%20Supply%20and%20Demand/"/>
    <id>http://www.52coding.com.cn/2019/02/11/The Market Forces of Supply and Demand/</id>
    <published>2019-02-11T10:28:47.000Z</published>
    <updated>2019-04-12T07:11:40.482Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#markets-and-competition">Markets and Competition</a><ul><li><a href="#what-is-a-market">What Is A Market?</a></li><li><a href="#what-is-competition">What is Competition?</a></li></ul></li><li><a href="#demand">Demand</a><ul><li><a href="#the-demand-curve-the-relationship-between-price-and-quantity-demand">The Demand Curve: The Relationship Between Price and Quantity Demand</a></li><li><a href="#market-demand-vs-individual-demand">Market Demand VS. Individual Demand</a></li><li><a href="#shifts-in-the-demand-curve">Shifts In the Demand Curve</a></li></ul></li><li><a href="#supply">Supply</a><ul><li><a href="#the-supply-curve-the-relationship-between-price-and-quantity-supplied">The Supply Curve: The Relationship Between Price and Quantity Supplied</a></li><li><a href="#market-supply-vs-individual-supply">Market Supply VS. Individual Supply</a></li><li><a href="#shifts-in-the-supply-curve">Shifts In The Supply Curve</a></li></ul></li><li><a href="#supply-and-demand-together">Supply And Demand Together</a><ul><li><a href="#equilibrium">Equilibrium</a></li><li><a href="#three-steps-to-analyzing-changes-in-equilibrium">Three Steps To Analyzing Changes In Equilibrium</a></li></ul></li><li><a href="#conclusion-how-prices-allocate-resources">Conclusion: How prices Allocate Resources</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="markets-and-competition">Markets and Competition</span></h2><h3><span id="what-is-a-market">What Is A Market?</span></h3><p>A <strong>market</strong> is a group of buyers and sellers of a particular good or service. Buyers decide the demand for the product while sellers decide the supply of the product.</p><h3><span id="what-is-competition">What is Competition?</span></h3><p>Economists use the term <strong>competitive market</strong> to describe a market in which there are so many buyers and so many sellers that each has a negligible impact on the market price.</p><p>Competition has various degrees, from <strong>perfectly competitive</strong> to <strong>monopoly</strong>.</p><p><em>Perfectly competitive</em> requires two characteristics: 1. the goods offered for sale are all exactly the same 2. the buyers and sellers are so numerous that no single buyer or seller has any influence over the market price.</p><p>However, some marketplace has only one seller, such a seller is called a <em>monopoly</em>.</p><h2><span id="demand">Demand</span></h2><p>We begin our study of markets by examining the behavior of buyers. To focus our thinking, let’s keep in mind a particular good — ice cream.</p><h3><span id="the-demand-curve-the-relationship-between-price-and-quantity-demand">The Demand Curve: The Relationship Between Price and Quantity Demand</span></h3><p>The <strong>quantity demanded</strong> of any good is the amount of the good that buyers are willing and able to purchase. The relationship of price and quantity demanded follows the <strong>law of demand</strong>: Other things equal, when the price of a good rises, the quantity demanded of the good falls, and when the price falls, the quantity demanded rises. A table that shows the relationship between the price of a good and the quantity demanded is called <strong>demand schedule</strong>.</p><p><img src="/images/IMG_BD7E38AD92C1-1.jpg"></p><p>The graph in Figure 1 uses the numbers from the table to illustrate the law of demand. By convention, the quantity of ice cream demanded is on the horizontal axis. The downward-sloping line relating price and quantity demanded is called the <strong>demand curve</strong>.</p><h3><span id="market-demand-vs-individual-demand">Market Demand VS. Individual Demand</span></h3><p>Figure 1 shows the individual demand of ice-cream. However, most of the time, we want to focus on the <strong>market demand</strong> which is the sum of all individual’s demands.</p><p><img src="/images/market/DraggedImage.jpg"></p><p>Figure 2 shows the Catherine’s demand, Nicholas’s demand as well as the market demand. At each price, the total quantity demand is the sum of Catherine’s quantity demand and Nicholas’s quantity demand. The market demand curve shows how the total quantity demanded of a good varies as the price of the good varies, while all the other factors are held constant.</p><h3><span id="shifts-in-the-demand-curve">Shifts In the Demand Curve</span></h3><p><img src="/images/market/DraggedImage-1.jpg"></p><p>Figure 3 illustrates shifts in the demand. There are many variables that can shift the demand curve. Here are the most important.</p><p><strong>Income</strong> If the demand for a good falls when income falls, the good is called a <strong>normal good</strong>. If the demand for a good rises when income falls, the good is called an <strong>inferior good</strong>, such as bus rides. As your income falls, you are less likely to buy a car or take a cab and more likely to ride a bus.</p><p><strong>Prices of Related Goods</strong> When a fall in the price of one good reduces the demand for another good, the two goods are called <strong>substitutes</strong>, such as ice cream and frozen yogurt, hot dogs and hamburgers. When a fall in the price of one good raises the demand for another good, the two goods are called <strong>complements</strong>, such as gasoline and automobiles, computers and software.</p><p><strong>Tastes</strong> If you like ice cream, you buy more of it. Economists examine what happens when tastes change.</p><p><strong>Expectations</strong> Your expectations about the future may affect your demand for a good or service today.</p><p><strong>Number of Buyers</strong> Market demand depends on the number of buyers.</p><p><strong>Summary</strong> <img src="/images/market/DraggedImage-2.jpg"></p><h2><span id="supply">Supply</span></h2><p>We now turn to the other side of the market and examine the behavior of sellers. Once again, to focus our thinking, let’s consider the market for ice cream.</p><h3><span id="the-supply-curve-the-relationship-between-price-and-quantity-supplied">The Supply Curve: The Relationship Between Price and Quantity Supplied</span></h3><p><strong>Quantity supplied</strong> is the amount of a good that sellers are willing and able to sell. When other things equal, the quantity supplied of a good rises when the price of the good rises, which is called <strong>the law of supply</strong>.</p><p><strong>Supply schedule</strong> is a table that shows the relationship between the price of a good and the quantity supplied. The curve relating price and quantity supplied is called the <strong>supply curve</strong>.</p><p><img src="/images/market/DraggedImage-3.jpg"></p><h3><span id="market-supply-vs-individual-supply">Market Supply VS. Individual Supply</span></h3><p>Just as market demand is the sum of the demands of all buyers, market supply is the sum of the supplies of all sellers. As with demand curves, we sum the individual supply curves <em>horizontally</em> to obtain the market supply curves. <img src="/images/market/DraggedImage-4.jpg"></p><h3><span id="shifts-in-the-supply-curve">Shifts In The Supply Curve</span></h3><p><img src="/images/market/DraggedImage-5.jpg"></p><p>Figure 7 illustrate shifts in the supply curve. There are many variables that can shift the supply curve. Here are some of the most important.</p><p><strong>Input Prices</strong> When the price of one or more inputs rises, producing the good is less profitable, and firms supply less the good.</p><p><strong>Technology</strong> By reducing firms’ costs, the advanced technology raised the supply of goods.</p><p><strong>Expectations</strong> The amount of good a firm supplies today may depend on its expectations about the future.</p><p><strong>Number of Sellers</strong> In addition to the preceding factors, which influence the behavior of individual sellers, market supply depends on the number of these sellers.</p><p><strong>Summary</strong></p><p><img src="/images/market/DraggedImage-6.jpg"></p><h2><span id="supply-and-demand-together">Supply And Demand Together</span></h2><h3><span id="equilibrium">Equilibrium</span></h3><p>Figure 8 shows the market supply curve and market demand together. The intersection point is called <strong>equilibrium</strong>. Equilibrium is a situation in which the market price has reached the level at which quantity supplied equals quantity demanded. The price that balances quantity supplied and quantity demanded is called <strong>equilibrium</strong>.</p><p><img src="/images/market/DraggedImage-7.jpg"></p><p>At the equilibrium price, the quantity of the good that buyers are willing and able to buy exactly balances the quantity that sellers are willing and able to sell. The actions of buyers and sellers <strong>naturally move markets toward the equilibrium</strong> of supply and demand.</p><p><strong>Law of supply and demand</strong>: The price of any good adjusts to bring the quantity supplied and the quantity demanded for that good into balance.</p><p><img src="/images/market/DraggedImage-8.jpg"></p><h3><span id="three-steps-to-analyzing-changes-in-equilibrium">Three Steps To Analyzing Changes In Equilibrium</span></h3><ol type="1"><li>Decide whether the event shifts the supply or demand curve (or perhaps both).</li><li>Decide in which direction the curve shifts.</li><li>Use the supply-and-demand diagram to see how the shift changes the equilibrium price and quantity.</li></ol><p>Example 1:</p><p><img src="IMG_A9BD8FC2E549-1.jpeg"></p><p>In the ice-cream example, <strong>supply</strong> (which <em>refers to the position of the supply curve</em>) does not change because the weather does not alter firms’ desire to sell at any given price. Instead, the hot weather alters consumers’ desire to buy at any given price and thereby shifts the demand curve to the right. The increase in demand causes the equilibrium price to rise. When the price rises, the <strong>quantity supplied</strong> rises. This increase in quantity supplied is represented by the <strong>movement along the supply curve</strong>.</p><p>Example 2: Shifts in Both Supply and Demand</p><p><img src="/images/market/DraggedImage-9.jpg"></p><p><strong>Summary</strong></p><p><img src="/images/market/DraggedImage-10.jpg"></p><h2><span id="conclusion-how-prices-allocate-resources">Conclusion: How prices Allocate Resources</span></h2><p>Consider the allocation of beachfront land. Because the amount of this land is limited, not everyone can enjoy the luxury of living by the beach. Who gets this resource? The answer is whoever is <strong>willing and able to pay the price</strong>. The price of beachfront land adjusts until the quantity of land demanded exactly balances the quantity supplied. Thus, in market economies, <strong>prices are the mechanism for rationing scarce resources</strong>.</p><p>Similarly, prices determine who produces each good and how much is produced. If an invisible hand guides market economies, as Adam Smith famously suggested, then the price system is the baton that the invisible hand uses to conduct the economic orchestra.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#markets-and-competition&quot;&gt;Markets and Competition&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#what-is-a-market&quot;&gt;What Is A Market?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#what-is-competition&quot;&gt;What is Competition?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#demand&quot;&gt;Demand&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-demand-curve-the-relationship-between-price-and-quantity-demand&quot;&gt;The Demand Curve: The Relationship Between Price and Quantity Demand&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#market-demand-vs-individual-demand&quot;&gt;Market Demand VS. Individual Demand&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#shifts-in-the-demand-curve&quot;&gt;Shifts In the Demand Curve&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#supply&quot;&gt;Supply&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-supply-curve-the-relationship-between-price-and-quantity-supplied&quot;&gt;The Supply Curve: The Relationship Between Price and Quantity Supplied&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#market-supply-vs-individual-supply&quot;&gt;Market Supply VS. Individual Supply&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#shifts-in-the-supply-curve&quot;&gt;Shifts In The Supply Curve&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#supply-and-demand-together&quot;&gt;Supply And Demand Together&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#equilibrium&quot;&gt;Equilibrium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#three-steps-to-analyzing-changes-in-equilibrium&quot;&gt;Three Steps To Analyzing Changes In Equilibrium&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#conclusion-how-prices-allocate-resources&quot;&gt;Conclusion: How prices Allocate Resources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="微观经济型原理" scheme="http://www.52coding.com.cn/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%9E%8B%E5%8E%9F%E7%90%86/"/>
    
      <category term="Supply Curve" scheme="http://www.52coding.com.cn/tags/Supply-Curve/"/>
    
      <category term="Demand Curve" scheme="http://www.52coding.com.cn/tags/Demand-Curve/"/>
    
      <category term="Equilibrium" scheme="http://www.52coding.com.cn/tags/Equilibrium/"/>
    
  </entry>
  
  <entry>
    <title>Recognizing Vehicles</title>
    <link href="http://www.52coding.com.cn/2018/12/09/RS%20-%20Recognizing%20Vehicles/"/>
    <id>http://www.52coding.com.cn/2018/12/09/RS - Recognizing Vehicles/</id>
    <published>2018-12-09T11:54:07.000Z</published>
    <updated>2019-04-12T03:28:03.249Z</updated>
    
    <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 6. 识别系统复习笔记。</p><p>Vehicle recognition, including detection, tracking and identification, has been a research topic among automotive manufacturers, suppliers and universities for enhancing road safety.</p><p>For example, the <a href="http://www.argo.ce.unipr.it/ARGO/english/index.html" target="_blank" rel="noopener">ARGO</a> project, started in 1996 at the University of Parma and the University of Pavia, Italy, is aimed at developing a system for improving road safety by controlling and supervising the driver activity.</p><a id="more"></a><!-- toc --><ul><li><a href="#lane-detection">Lane Detection</a><ul><li><a href="#canny-edge-detector">Canny edge detector</a></li></ul></li><li><a href="#vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</a></li><li><a href="#visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</a></li><li><a href="#application-examples">Application Examples</a></li></ul><!-- tocstop --><h2><span id="lane-detection">Lane Detection</span></h2><p>For vehicle detection and tracking and intelligent transportation systems, lane marking detection is one of the key steps. Lane markings can be detected based on the camera inverse perspective mapping (IPM) and the assumption that the lane markings are represented by almost vertical bright lines of constant width, surrounded by a darker background.</p><p>The lanes can then be detected by using the camera <strong>inverse perspective mapping (IPM)</strong> and the <strong>Canny edge detector</strong>.</p><p><strong>Inverse perspective mapping</strong></p><p><img src="/images/impres.png"></p><p><img src="/images/ipmreason.png"></p><h3><span id="canny-edge-detector">Canny edge detector</span></h3><p><a href="http://en.wikipedia.org/wiki/Canny_edge_detector" target="_blank" rel="noopener">Canny edge detector</a> is one of the most popular detectors of edge pixels. The edge detection process serves to simplify the analysis of images by drastically <strong>reducing the amount of data to be processed</strong>, while at the same time <strong>preserving useful structural information</strong> about object boundaries.</p><p>There are three common criteria relevant to edge detector performance.</p><ul><li>It is important that edges that occur in the image should not be missed and that there be <em>no spurious responses</em>.</li><li>The edge points should be well localized. That is, the distance between the points marked by the detector and the true edge center should be minimized.</li><li>The last requirement is to circumvent the possibility of multiple responses to a single edge.</li></ul><p><img src="/images/cedbalala.jpg"></p><p>In the figure above, (a) is a noisy step edge; (b) is a difference of boxes operator; (c) is the output of filtering by box operator; (d) is the first derivative of Gaussian operator; and (e) is the first derivative of Gaussian applied to the edge.</p><p><img src="/images/cannysd.png"></p><p>The <strong>edge center</strong> is marked as <strong>red circle</strong> at a local maximum in the output of the filter responses. Within the region of the edge, the boxes operator exhibits more local maxima than the Gaussian operator. Therefore, <strong>the Gaussian operator is better</strong> than the boxes operator in this example.</p><p><strong>The three performance criteria</strong></p><ol type="1"><li><p>Good detection → Detection Criterion</p><p>There should be a low probability of failing to mark real edge points, and low probability of falsely marking non-edge points. This is controlled by signal-to-noise ratio: <span class="math display">\[\text{SNR}=\frac{|\int_{-w}^{+w}G(-x)f(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f(x)^2dx}}\]</span></p></li><li><p>Good localization → Localization Criterion</p><p>The points marked as edge points by the operator should be as close as possible to the true edge center. The localization is defined as the reciprocal of <span class="math inline">\(\delta x_0\)</span>: <span class="math display">\[\text{Localization}=\frac{|\int_{-w}^{+w}G(-x)f&#39;(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f&#39;(x)^2dx}}\]</span></p></li><li><p>Only one response to a single edge → Multiple Response Constraint <span class="math display">\[x_{zc}(f)=\pi\left(\frac{\int_{-\infty}^{+\infty}f&#39;(x)^2dx}{\int_{-\infty}^{+\infty}f&#39;&#39;(x)^2dx}\right)^{1/2}\]</span></p></li></ol><p>It is very difficult to find the function <span class="math inline">\(f\)</span> (filter) which maximizes the detection and localization criteria subject to the multiple response constraint. Numerical optimization is therefore used.</p><p>The solution is of the form <span class="math display">\[f(x)=a_1e^{\alpha x}\sin\omega x+a_2e^{\alpha x}\cos\omega x+a_3e^{-\alpha x}\sin\omega x\\+a_4e^{-\alpha x}\cos\omega x+c\]</span> The variables are determined by the non-linear optimization with boundary conditions.</p><p>The numerically estimated optimal edge detector can be approximated by the <strong>first derivative of a Gaussian</strong> G, where <span class="math display">\[G(x)=\exp(-\frac{x^2}{2\sigma^2})\\f(x)=G&#39;(x)=-\frac{x}{\sigma^2}\exp(-\frac{x^2}{2\sigma^2})\]</span> For 2D, the solution proposed by Canny amounts to convolving the initial image with a Gaussian function followed by computation of the derivatives in <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> of the result.</p><p><img src="/images/firstderofgaus.png"></p><p>There are three main steps in the Canny edge detection</p><ol type="1"><li><p>Gradient calculation</p><p>compute <span class="math inline">\(M\)</span>: <span class="math display">\[I_x=\frac{\partial}{\partial x}(I\ast G(x,y))\\I_y=\frac{\partial}{\partial y}(I\ast G(x,y))\\M=\sqrt{I_x^2+I_y^2}\approx |I_x|+|I_y|\]</span></p></li><li><p>Non-maximum suppression</p><p>keep local maximum, set others to zero.</p></li><li><p>Hysteresis thresholding</p><p><img src="/images/hyposisthres.png"></p></li></ol><h2><span id="vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</span></h2><p>Vehicle detection is based on the assumption that the rear or frontal views of the vehicles are generally symmetric; can be characterized by a rectangular bounding box which satisfies specific aspect ratio constraints and is placed in a specific region of the image, e.g., within lanes.</p><p>These features are used to identify vehicles in the image.</p><ol type="1"><li>Area of interest is identified on the basis of road position and perspective constraints.</li><li>This area of interest is searched for possible vertical symmetries. Not only are the gray level symmetries considered, but also vertical and horizontal edge symmetries are considered.</li><li>Step 3: Once the symmetry axis has been detected, the lower part (the two bottom corners) of a rectangular bounding box is detected.</li><li>The top horizontal limit of the vehicle is then searched according to the pre-defined aspect ratio.</li></ol><p><img src="/images/vdbasedonsys.png"></p><p>Vertical and horizontal binary edges can help solve the problems of strong reflection areas in the vehicle images. The analysis of symmetry produces symmetry maps for gray-level intensity, edge (total), horizontal edge, vertical edge and total (combined) symmetry. The symmetry axis can be found from the total symmetry map.</p><p><strong>Bounding box detection</strong></p><p>After detecting the symmetry axis, the width of the symmetrical region is checked for the presence of two corners representing the bottom of the bounding box around the vehicle.</p><p>Once the two corners are detected, the top side of the rectangle box can be detected by searching.</p><p><img src="/images/boundingboxde.png"></p><h2><span id="visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</span></h2><p><strong>Visual saliency</strong> refers to the idea that certain parts of a scene are pre-attentively distinctive (pop-out) and create some form of immediate significant visual arousal within the early stages of the <strong>Human Visual System (HVS)</strong>. The figure below is an example.</p><p>In image analysis, an <strong>edge</strong> is a pop-out region (<strong>region of saliency</strong>) since the edge is more visually significant than the other parts of the image.</p><p><img src="/images/vsexamples.png"></p><p>The salient points are literally the points on the object which are almost unique. These points maximize the discrimination between objects. The visual saliency is defined in terms of <strong>local signal complexity</strong>.</p><p><strong>Shannon entropy</strong> of local attributes (called <strong>local entropy</strong>) is <span class="math display">\[H_{D,Rx}(x)=-\sum_{i\in D}P_{D,Rx}(x,d_i)\log_2P_{D,Rx}(x,d_i)\]</span> where <span class="math inline">\(x\)</span> is point location, <span class="math inline">\(Rx\)</span> is local neighborhood at <span class="math inline">\(x\)</span>, <span class="math inline">\(D\)</span> is descriptor (e.g. intensity), and <span class="math inline">\(P_{D,Rx}(x,d_i)\)</span> is histogram value at <span class="math inline">\(x\)</span>.</p><p><img src="/images/entropylsakdjad.jpg"></p><p>Below are sample frames from the processed sequences using a <strong>fixed scale</strong> based on local entropy. Red square boxes represent the most salient icons or parts of the image. The size of the local window or scale and threshold used were selected manually to give the most satisfactory results.</p><p><img src="/images/saliegsdas.png"></p><ul><li>Problem: the scale is fixed and global. For example, the scale is inappropriate for the pedestrians and the road markings in DT sequence.</li><li>Problem: Small salient regions are not picked up. Highly textured regions, e.g., large intensity variation regions, are picked up. For example, trees and bushes in Vicky sequence.</li></ul><p>Therefore, scale is an important and implicit part of the saliency detection problem.</p><p><strong>Scale selection for salient region detection</strong></p><p>Scale is selected based on the scale-space behavior of the saliency of a given feature.</p><p>For each pixel position <span class="math inline">\(x\)</span></p><ul><li><p>For each scale <span class="math inline">\(s\)</span> inside a range between <span class="math inline">\(s_\min\)</span> and <span class="math inline">\(s_\max\)</span> :</p><ul><li><p>Measure the local descriptor values (e.g.,intensity values) within a window of scale <span class="math inline">\(s\)</span>.</p></li><li><p>Estimate the local probability density function (PDF) from this (e.g. using histogram).</p></li><li><p>Calculate the local entropy <span class="math inline">\(H_D\)</span> <span class="math display">\[H_{D}(s,x)=-\sum_{i\in D}P_{D}(s,x,d_i)\log_2P_{D}(s,x,d_i)\]</span></p></li></ul></li><li><p>Select scales for which the entropy is peaked <span class="math display">\[s:\frac{\partial^2H_D(s,x)}{\partial s^2}&lt;0\]</span></p></li><li><p>Detection performance can be further improved if change of histogram is considered.</p></li></ul><p><img src="/images/salenscaleg.png"></p><p><strong>Vehicle Detection by using AdaBoost</strong></p><p>Vehicles can be detected by using <a href="https://www.52coding.com.cn/2018/12/06/RS%20-%20Recognizing%20Faces/#adaboost">AdaBoost</a>.</p><p><img src="/images/vehildabboo.png"></p><p>By using the AdaBoost, vehicles in their lateral view can be detected in real time.</p><p><strong>Vehicle Recognition</strong></p><p>After vehicle detection, the vehicle can be recognition by using PCA and classification methods, e.g., k-NN or Bayesian methods.</p><h2><span id="application-examples">Application Examples</span></h2><p><strong>Vehicle counting in traffic surveillance</strong></p><p><img src="/images/survelleg.png"></p><p><strong>Traffic jam detection and alarming</strong></p><p><img src="/images/trafficjamsdeg.png"></p><p><strong>Abnormal vehicle behavior detection</strong></p><p><img src="/images/abnormaldetec.png"></p><p><strong>Target tracking in night</strong></p><p><img src="/images/targetrackinni.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HKUST CSIT5401 Recognition System lecture notes 6. 识别系统复习笔记。&lt;/p&gt;
&lt;p&gt;Vehicle recognition, including detection, tracking and identification, has been a research topic among automotive manufacturers, suppliers and universities for enhancing road safety.&lt;/p&gt;
&lt;p&gt;For example, the &lt;a href=&quot;http://www.argo.ce.unipr.it/ARGO/english/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ARGO&lt;/a&gt; project, started in 1996 at the University of Parma and the University of Pavia, Italy, is aimed at developing a system for improving road safety by controlling and supervising the driver activity.&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Recognition System" scheme="http://www.52coding.com.cn/tags/Recognition-System/"/>
    
      <category term="Canny" scheme="http://www.52coding.com.cn/tags/Canny/"/>
    
      <category term="visual saliency" scheme="http://www.52coding.com.cn/tags/visual-saliency/"/>
    
      <category term="lane detection" scheme="http://www.52coding.com.cn/tags/lane-detection/"/>
    
      <category term="vehicle detection" scheme="http://www.52coding.com.cn/tags/vehicle-detection/"/>
    
  </entry>
  
  <entry>
    <title>Recognizing License Plates</title>
    <link href="http://www.52coding.com.cn/2018/12/08/RS%20-%20Recognizing%20License%20Plates/"/>
    <id>http://www.52coding.com.cn/2018/12/08/RS - Recognizing License Plates/</id>
    <published>2018-12-08T11:54:07.000Z</published>
    <updated>2019-04-12T03:28:00.362Z</updated>
    
    <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 5. 识别系统复习笔记。</p><p><a href="http://www.licenseplaterecognition.com/" target="_blank" rel="noopener">License Plate Recognition</a> is an image-processing technology which is used to identify vehicles by their license plates. This technology is used in various security and traffic applications, such as the access-control system, toll payment, parking fee payment, etc.</p><a id="more"></a><p>A number of license plate recognition units are installed in different locations and the passing vehicle plate numbers are matched between the points. The average speed and travel time between these points can be calculated and presented in order to monitor traffic loads. Additionally, the average speed may be used to issue a speeding ticket.</p><!-- toc --><ul><li><a href="#automatic-vehicle-identification-system">Automatic Vehicle Identification System</a></li><li><a href="#license-plate-detection">License Plate Detection</a><ul><li><a href="#global-search">Global Search</a></li><li><a href="#partial-image-analysis">Partial Image Analysis</a></li><li><a href="#sliding-concentric-windows">Sliding Concentric Windows</a></li><li><a href="#adaboost">Adaboost</a></li></ul></li><li><a href="#character-segmentation">Character Segmentation</a></li><li><a href="#character-recognition">Character Recognition</a></li></ul><!-- tocstop --><h2><span id="automatic-vehicle-identification-system">Automatic Vehicle Identification System</span></h2><p>The installation and responses of sensors help to frame a front-view/rear-view of a passing vehicle. <strong>Infra-red sensors</strong> are used for vehicle sensing.</p><p><img src="/images/infredsens.png"></p><p><strong>Anisotropic magneto-resistive (AMR) sensors</strong> for automated vehicle sensing.</p><p><img src="/images/amrsense.png"></p><p><strong>License plate recognition</strong> is generally composed of three steps.</p><ol type="1"><li>Location of the license plate region (License Plate Detection)</li><li>Segmentation of the plate characters (Character Segmentation)</li><li>Recognition of the plate characters (Character Recognition)</li></ol><p>The license plate recognition should operate fast enough to make sure that the system does not miss a single object of interest that moves through the scene.</p><p>With the growth of the computer processing power, the latest developments operate within less than 50ms for plate detection and recognition. It enables the processing of more than 20 frames per second for videos.</p><h2><span id="license-plate-detection">License Plate Detection</span></h2><p>There are several methods for detecting license plate in a vehicle image.</p><ul><li>Global search [Comelli-TVT-95$]$</li><li>Partial image analysis (vertical edge density)[Anagnostopoulos-TITS-08$]$</li><li>Sliding concentric windows [Anagnostopoulos-TITS-06$]$</li><li>AdaBoost [Dlagnekov-04$]$</li></ul><h3><span id="global-search">Global Search</span></h3><p>Comelli et al. presented a system called RITA. RITA can recognize automatically the characters written on the license plate placed on the rear-side of motor vehicles. The goal is to read only the Italian license plates and reject all the others. It is assumed that a Italian license plate is rectangular and the plate contains black characters over a white background.</p><p>The license plate detection algorithm is a <strong>global searching</strong> method because the algorithm picks within the vehicle image globally the area presenting the maximum local contrast based on <strong>gradient analysis</strong>. The picked area possibly corresponds to the rectangle that contains the license plate.</p><p>The algorithm selects the area that presents the <strong>maximum local contrast</strong> that (possibly) corresponds to the rectangle that contains the license plate.</p><p><img src="/images/globalsearch.png"></p><h3><span id="partial-image-analysis">Partial Image Analysis</span></h3><p>The vehicle image can be filtered to extract <strong>vertical edges</strong> and scanned with N-row distance. The number of the existing edges along each scan line is recorded.</p><p>If the number of the edges is greater than a threshold value, the presence of a plate can be assumed.</p><p><img src="/images/piasdsa.png"></p><p>Specifically, if the plate is not found in the first scanning processing, then the algorithm is repeated, reducing the threshold for counting edges or adjusting the threshold for finding vertical edges.</p><h3><span id="sliding-concentric-windows">Sliding Concentric Windows</span></h3><p>An adaptive image segmentation technique, called <strong>sliding concentric windows</strong> (SCW), was proposed for license plate detection. The SCW method was developed to describe the local irregularity in the vehicle image.</p><p>The method uses image statistics such as the standard deviation and the mean for finding possible plate locations.</p><p><img src="/images/slidingwc.png"></p><p>In two concentric windows A and B of different sizes (<span class="math inline">\(2X_1\times 2Y_1\)</span> and <span class="math inline">\(2X_2\times2Y_2\)</span> respectively), which scan the vehicle image from left to right and from top to bottom, the mean or the standard deviation is calculated.</p><p>If the ratio of the statistical measurements in the two windows exceeds a threshold set by the user, then the central pixel of the concentric windows is considered to belong to a license plate. <span class="math display">\[I_{output}=\begin{cases}0 &amp; \text{if }\frac{M_B}{M_A}\leq T,\\1 &amp; \text{if }\frac{M_B}{M_A}&gt; T\end{cases}\]</span> where <span class="math inline">\(M\)</span> is the statistical measurement, eigher mean or standard devation.</p><p>The result is a binary image <span class="math inline">\(I_{output}\)</span>, which eliminates all the redundant regions from the original vehicle image.</p><p>The result binary image is used as a <strong>mask for highlighting the license plate</strong> by computing the product between the binary mask and the input vehicle image. The license plate can then be found in the highlighted image based on the binary mask.</p><p><img src="/images/scwimg.png"></p><h3><span id="adaboost">Adaboost</span></h3><p>Adaptive boosting (AdaBoost) was used in conjunction with the rectangle features for training a strong classifier based on weak classifiers.</p><p>For detecting license plates, a total of 100 rectangle features can be applied to sub-regions sized 45(columns) × 15(rows) pixels being scanned as the expected license plate areas in the original vehicle image.</p><p><img src="/images/recpladaboo.png"></p><p>Within the 100 rectangle features for detection, there are 37 variance based features, 40 x-derivative features, 18 y-derivative features, and 5 mean pixel intensity features.</p><p><img src="/images/plrecoadaboo.png"></p><p>When sliding the search window across the vehicle image to be analyzed, several matches can be found. Clustering method can be used to group detected windows that are close to each other and <strong>use the mean window as the detected location</strong>.</p><h2><span id="character-segmentation">Character Segmentation</span></h2><p>In most systems with a subsequent recognition module, the vertical resolution of the plate vary from 20 to 40 pixels. Prior to character recognition, the detected license plates are enhanced for <strong>improving plate image quality</strong>, e.g., image normalization and histogram equalization.</p><p><img src="/images/characseg.png"></p><p>Given the enhanced detected license plate image, the goal is to <strong>segment each character</strong> in the image. A global threshold can be found to segment the detected license plate. <a href="http://en.wikipedia.org/wiki/Otsu&#39;s_method" target="_blank" rel="noopener">Otsu's method</a> is one of widely used methods for image binarization.</p><p><strong>Otsu's method</strong></p><p>The method is designed for finding optimum global threshold for image binarization and is optimum in the sense that it maximizes the between-class variance.</p><p>There are six steps.</p><ol type="1"><li><p>Compute the normalized histogram of the input image. Denote the components of histogram by <span class="math display">\[p_i=\frac{n_i}{MN}, i=0, 1, ..., L-1\]</span> where <span class="math inline">\(L\)</span> is the number of gray levels; <span class="math inline">\(n_i\)</span> is the number of pixels with intensity <span class="math inline">\(i\)</span>; <span class="math inline">\(M\)</span> is the number of rows; and <span class="math inline">\(N\)</span> is the number of columns.</p></li><li><p>Compute the cumulative sums (the probability that a pixel is assigned to class <span class="math inline">\(C_1\)</span>) <span class="math display">\[P_1(k)=\sum_{i=0}^kp_i\]</span> where <span class="math inline">\(k\)</span> is current threshold for thresholding the input image into two classes <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>.</p></li><li><p>Compute the cumulative means <span class="math display">\[m(k)=\sum_{i=0}^kip_i,\ k=0,1,...,L-1\]</span></p></li><li><p>Compute the global intensity mean <span class="math display">\[m_G=\sum_{i=0}^{L-1}ip_i\]</span> where <span class="math inline">\(L\)</span> is the number of gray levels.</p></li><li><p>Compute the between-class variance <span class="math display">\[\sigma^2_B(k)=\frac{[m_GP_1(k)-m(k)]^2}{P_1(k)[1-P_1(k)]},\ k=0, 1, ..., L-1\]</span></p></li><li><p>Obtain the Otsu threshold, <span class="math inline">\(k^\ast\)</span>, as the value for <span class="math inline">\(k\)</span> for which the value of <strong>between-class variance is maximum</strong>. If the maximum is not unique, obtain <span class="math inline">\(k^\ast\)</span> by averaging the values of <span class="math inline">\(k\)</span> corresponding to the various maxima detected. <span class="math display">\[\sigma^2_B(k^\ast)=\max_{0\leq k\leq L-2}\sigma^2_B(k)\]</span></p></li></ol><p><img src="/images/otsuresukt.png"></p><p>Global thresholding on the entire image may not always produce useful results due to uneven lighting environment.</p><p><img src="/images/charseg.png"></p><p>Characters can be extracted from the license plate image. Each character can then be segmented by using the thresholding method. Instead of dividing the image into regular blocks, the shape (size) of each block is defined adaptively for each character.</p><p><img src="/images/characsegggg.png"></p><p>Projections of binary edge images are performed. Rows of strings are separated based on the horizontal pixel accumulation. Same for columns of characters.</p><p>After the blocks for characters are defined adaptively, the Otsu's method is applied for each blocks adaptively.</p><p><strong>Maximally stable extremal regions</strong></p><p>Characters can be extracted and segmented by thresholding the image with a variable brightness threshold, and using the enumeration of extremal regions which are stable for a large range of the threshold <span class="math inline">\(T\)</span>.</p><p>Extremal regions are connected components of an image binarized at certain threshold. When the threshold <span class="math inline">\(T\)</span> is increasing/decreasing, the behavior of the extremal regions is used for character classification and segmentation.</p><p><a href="http://en.wikipedia.org/wiki/Maximally_stable_extremal_regions" target="_blank" rel="noopener">Maximally stable extremal regions (MSERs)</a> are usually of arbitrary shape. The MSER detector is stable and invariant to affine transformations, which is useful for handling viewpoint changes.</p><p><img src="/images/msersss.png"></p><p><img src="/images/mseralgo.png"></p><p><img src="/images/mserrrr.png"></p><p><img src="/images/mserapp.png"></p><h2><span id="character-recognition">Character Recognition</span></h2><p>After the characters are segmented, the segmented characters will be matched against a set of pre-defined characters, e.g. ten numerals (zero to nine), alphabets, etc.</p><p>The pre-defined characters usually have single font, fixed character size, and are not rotated heavily. Therefore, pattern/template matching is a suitable technique for character recognition. Templates can be generated in advance for the matching tasks.</p><p><img src="/images/charrecogpatt.png"></p><p>The matching process can be done by computing the <strong>normalized cross-correlation</strong> values for all the translational shifts of each character template over the character block (sub-image).</p><p>The normalized cross-correlation is defined as <span class="math display">\[C_{fg}=\frac{\sum_{m=1}^M\sum_{n=1}^N(f(i,j)-\bar{f})(g(i,j)-\bar{g})}{\sqrt{\sum_{m=1}^M\sum_{n=1}^N(f(i,j)-\bar{f})^2(g(i,j)-\bar{g})^2}}\]</span> where <span class="math inline">\(g\)</span> is shifted template and <span class="math inline">\(f\)</span> is character block.</p><p>More advanced techniques, e.g. <a href="http://en.wikipedia.org/wiki/Shape_context" target="_blank" rel="noopener">shape context</a>, can be used for character recognition. ([Belongie-02, Treiber-10])</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HKUST CSIT5401 Recognition System lecture notes 5. 识别系统复习笔记。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.licenseplaterecognition.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;License Plate Recognition&lt;/a&gt; is an image-processing technology which is used to identify vehicles by their license plates. This technology is used in various security and traffic applications, such as the access-control system, toll payment, parking fee payment, etc.&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Recognition System" scheme="http://www.52coding.com.cn/tags/Recognition-System/"/>
    
      <category term="Adaboost" scheme="http://www.52coding.com.cn/tags/Adaboost/"/>
    
      <category term="Otsu" scheme="http://www.52coding.com.cn/tags/Otsu/"/>
    
      <category term="MSER" scheme="http://www.52coding.com.cn/tags/MSER/"/>
    
      <category term="sliding concentric windows" scheme="http://www.52coding.com.cn/tags/sliding-concentric-windows/"/>
    
  </entry>
  
  <entry>
    <title>Recognizing Fingerprints</title>
    <link href="http://www.52coding.com.cn/2018/12/07/RS%20-%20Recognizing%20Fingerprints/"/>
    <id>http://www.52coding.com.cn/2018/12/07/RS - Recognizing Fingerprints/</id>
    <published>2018-12-07T13:20:07.000Z</published>
    <updated>2019-04-12T03:27:51.914Z</updated>
    
    <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 4. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#fingerprint-image-acquisition-systems">Fingerprint image acquisition systems</a></li><li><a href="#minutiae">Minutiae</a></li><li><a href="#fingerprint-enhancement">Fingerprint Enhancement</a><ul><li><a href="#normalization">Normalization</a></li><li><a href="#orientation-image-estimation">Orientation Image Estimation</a></li><li><a href="#ridge-frequency-estimation">Ridge Frequency Estimation</a></li><li><a href="#region-mask-estimation">Region mask estimation</a></li><li><a href="#gabor-filter">Gabor Filter*</a></li></ul></li><li><a href="#fingerprint-matching">Fingerprint Matching</a></li><li><a href="#fingercode">FingerCode</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="fingerprint-image-acquisition-systems">Fingerprint image acquisition systems</span></h2><p><a href="http://en.wikipedia.org/wiki/Fingerprint" target="_blank" rel="noopener">Fingerprint</a> matching (recognition) is the most popular biometric technique used in automatic personal identification. The main reason for the popularity of fingerprints as a form of identification is that the fingerprint of a person is unique and remains invariant with his or her age.</p><p>There are three kinds of sensing devices typically: <strong>optical sensors</strong>, <strong>solid-state sensors</strong> and <strong>ultrasound sensors</strong>.</p><p><strong>Optical sensors</strong></p><p>The finger touches the top side of a glass prism. The left side of the prism is illustrated through a diffused light. The light entering the prism is reflected at the valleys, and absorbed at the ridges. The lack of reflection allows the ridges to be discriminated from the valleys. The light rays exit from the right side of the prism and are focused through a lens onto an image sensor.</p><p><img src="/images/ridgeandvall.png"></p><p><strong>Solid-state sensors</strong></p><p>All silicon-based sensors consist of an array of pixels, each pixel being a tiny sensor itself. The user directly touches the surface of the silicon. The physical information is converted into <strong>electrical signals</strong> by using the capacitive sensor (other kinds of sensor can also be used, e.g., thermal, electric field and piezoelectric).</p><p>The capacitive sensor is a 2D array of micro-capacitor plates embedded in a chip. The other plate of each micro-capacitor is the finger skin itself.</p><p><img src="/images/ssdfinger.png"></p><p>Small electrical charges are created between the surface of the finger and each of the silicon plates when a finger is placed on the chip. The magnitude of these electrical charges depends on the distance between the fingerprint surface and the capacitance plates.</p><p><strong>Ultrasound sensors</strong></p><p>An ultrasound sensor is based on sending acoustic signals toward the fingertip and capturing the echo signal. The echo signal is used to compute the range image of the fingerprint and, subsequently, the ridge structure itself.</p><p><img src="/images/ultrasound.png"></p><h2><span id="minutiae">Minutiae</span></h2><p>An <strong>automatic fingerprint identification system</strong> (AFIS) consists of various processing stages.</p><p><img src="/images/afis.png"></p><p>In AFIS, the high-level structural features (<strong>ridges and valleys</strong>) are extracted from the fingerprint image for the purpose of representation and matching. The ridges and valleys in a fingerprint alternate, flowing in a local constant direction.</p><p><img src="/images/ridandval.png"></p><p>The ridges (or the valleys) exhibit anomalies of various kinds, such as ridge bifurcations, ridge endings, short ridges, and ridge crossovers. These features are called <a href="http://en.wikipedia.org/wiki/Minutiae" target="_blank" rel="noopener">minutiae</a>.</p><p>In a good quality rolled fingerprint image, there are about 70 to 80 minutia points and in a latent fingerprint the number of minutiae is much less (approximately 20 to 30 minutia points). Commercially available fingerprint identification systems typically use <strong>ridge bifurcations</strong> and <strong>ridge endings</strong> as features.</p><p><img src="/images/bifandending.png"></p><ul><li>A ridge ending is defined as the point where a ridge ends abruptly.</li><li>A ridge bifurcation is defined as the point where a ridge diverges into branch ridges.</li></ul><p>A critical step in fingerprint matching is to automatically and reliably <strong>extract minutiae</strong> from the input fingerprint images, which is a difficult task.</p><p><img src="/images/bifandend2.png"></p><h2><span id="fingerprint-enhancement">Fingerprint Enhancement</span></h2><p>Fingerprint images can be of very poor quality. An enhancement algorithm which can improve the clarity of the ridge structure is therefore necessary.</p><p>The flowchart of the fingerprint enhancement algorithm is shown below.</p><p><img src="/images/imgnorflow.png"></p><h3><span id="normalization">Normalization</span></h3><p>A gray-level fingerprint image <span class="math inline">\(I\)</span> is defined as an <span class="math inline">\(N \times N\)</span> matrix. At the <span class="math inline">\(i\)</span> th row and <span class="math inline">\(j\)</span> th column, the intensity of the pixel is <span class="math inline">\(I(i, j)\)</span>. It is assumed that the fingerprint images are scanned at a resolution of 500 dots per inch (dpi), which is the resolution recommended by FBI.</p><p>The mean and variance of a gray-level fingerprint image are defined as</p><p><img src="/images/imgnorma.png"></p><p>An input fingerprint image is normalized so that it has a pre-specified mean <span class="math inline">\(M_0\)</span> and variance <span class="math inline">\(\text{VAR}_0\)</span>.</p><p>The normalized image <span class="math inline">\(G(i,j)\)</span> is defined as <span class="math display">\[G(i,j)=\begin{cases}M_0+\sqrt{\frac{VAR_0(I(i,j)-M)^2}{VAR}} &amp;\text{if }I(i,j)&gt;M\\M_0-\sqrt{\frac{VAR_0(I(i,j)-M)^2}{VAR}}&amp;\text{otherwise}\\\end{cases}\]</span> <img src="/images/imgnor2.png"></p><h3><span id="orientation-image-estimation">Orientation Image Estimation</span></h3><p>The orientation image (field) is estimated from the normalized input fingerprint image. By viewing a fingerprint image as an oriented image, a <strong>least-mean-square orientation estimation</strong> algorithm is used to estimate the local orientation.</p><p>The main steps are as follows.</p><p>[1] Divide the normalized image <span class="math inline">\(G\)</span> into blocks of size <span class="math inline">\(w \times w\)</span>.</p><p>[2] For each block, compute the gradients <span class="math inline">\(I_x\)</span> and <span class="math inline">\(I_y\)</span> at each pixel <span class="math inline">\((i , j)\)</span>.</p><p>[3] Estimate the local orientation of each block centered at pixel <span class="math inline">\((i, j)\)</span> using the following equations. <span class="math display">\[\theta(i,j)=90^o+\frac{1}{2}\text{atan2}\left(\frac{V_1(i,j)}{V_2(i,j)}\right)\]</span> where <span class="math display">\[V_1(i,j)=\sum_{u=i-\frac{w}2}^{i+\frac{w}2}\sum_{v=j-\frac{w}2}^{j+\frac{w}2}2I_x(u,v)I_y(i,v)\\V_2(i,j)=\sum_{u=i-\frac{w}2}^{i+\frac{w}2}\sum_{v=j-\frac{w}2}^{j+\frac{w}2}(I_x(u,v)^2-I_y(u,v)^2)\\-180^o≤\text{atan2}(x)≤180^o\]</span> [4] Due to the presence of noise, corrupted ridge and valley structures, minutiae, etc. in the input image, the estimated local ridge orientation may not always be correct. The local orientation image can be smoothed by using the low-pass smoothing filter and the concept of continuous vector field.</p><p><img src="/images/orienesti.png"></p><h3><span id="ridge-frequency-estimation">Ridge Frequency Estimation</span></h3><p>The gray levels along ridges and valleys can be modeled as a sinusoidal-shaped wave along a direction normal to the local ridge orientation.</p><p><img src="/images/ridgefreq.jpg"></p><p>Let <span class="math inline">\(G\)</span> be the normalized image and <span class="math inline">\(O\)</span> be the orientation image (field). For estimating the ridge frequency <span class="math inline">\(Ω\)</span> image,</p><ul><li><p>Step 1: divide <span class="math inline">\(G\)</span> into blocks of size <span class="math inline">\(w \times w\)</span>.</p></li><li><p>Step 2: for each block centered at pixel <span class="math inline">\((i, j)\)</span>, compute an oriented window of size <span class="math inline">\(w \times l\)</span> that is defined in the ridge coordinate system <span class="math inline">\((k, d)\)</span>. <img src="/images/ridgesys.png"></p></li><li><p>Step 3: for each block centered at pixel <span class="math inline">\((i, j)\)</span>, compute the x-signature, <span class="math inline">\(X[0], X[1], ..., X[l-1]\)</span>, of the ridges and valleys within the oriented window, where <span class="math display">\[X[k]=\frac{1}w\sum_{d=0}^{w-1}G(u,v)\\u=i+(d-\frac{w}2)\cos O(i,j)+(k+\frac{l}2)\sin O(i,j)\\v=i+(d-\frac{w}2)\sin O(i,j)+(\frac{l}2-k)\cos O(i,j)\]</span> <img src="/images/w2blabla.png"> <img src="/images/orientationdsa.png"></p></li></ul><p>The x-signature forms a discrete sinusoidal-shape wave, which has the same frequency as that of the ridges and valleys in the oriented window. Therefore, the <strong>frequency of ridges and valleys can be estimated from the x-signature</strong>.</p><p>Let <span class="math inline">\(T(i, j)\)</span> be the average number of pixels between two consecutive peaks in the x-signature, then the ridge frequency <span class="math inline">\(Ω(i, j)\)</span> is computed as <span class="math display">\[\Omega(i,j)=\frac{1}{T(i,j)}\]</span></p><h3><span id="region-mask-estimation">Region mask estimation</span></h3><p>A pixel (or a block) in an input fingerprint image can be either in a recoverable region or an unrecoverable region. Classification of pixels into recoverable and unrecoverable categories can be performed based on the assessment of the shape of the wave formed by the local ridges and valleys.</p><p><img src="/images/imgmaskest.png"></p><p>Three features are used to characterize the sinusoidal-shaped wave: amplitude, frequency, and variance.</p><p><img src="/images/imgmaskest2.png"></p><p>Typical fingerprint images where both recoverable and unrecoverable regions were manually labeled can be selected for region mask estimation. The above three features can be computed for each image.</p><p>Using the k-NN and clustering algorithms, each <span class="math inline">\(w \times w\)</span> block in an input fingerprint image can be classified into a recoverable or an unrecoverable block.</p><h3><span id="gabor-filter">Gabor Filter*</span></h3><p>The configurations of parallel ridges and valleys with well-defined frequency and orientation in a fingerprint image provide useful information which helps in removing undesired noise.</p><p>A special (bandpass) filter, namely <strong>Gabor filter</strong>, that is tuned to the corresponding frequency and orientation can efficiently remove the undesired noise and preserve the true ridge and valley structures.</p><p>Gabor filters have both frequency-selective and orientation-selective properties and are used for removing noise and preserving true ridge or valley structures.</p><p>The even-symmetric Gabor filter has the following general form:</p><p><img src="/images/gaborfilter.png"></p><p>The frequency of the filter <span class="math inline">\(f\)</span> is completely determined by the local ridge frequency and the Gabor filter orientation is determined by the local ridge orientation.</p><p><img src="/images/gabororien.png"></p><p>The ridge pixels are assigned a value '1' (white) and the remaining pixels are assigned a value '0' (black) in the resulting binary ridge image.</p><p><img src="/images/imgseg.png"></p><p>Once the ridges are located, <strong>directional smoothing</strong> is applied to smooth the ridges. A 3×7 mask is placed along the orientation field for each window. The mask containing all '1's enables us to count the number of '1's in the mask area.If the count of '1's is more than 25% of the total number of pixels, the ridge point is retained.</p><p><strong>Extracting minutiae</strong></p><p>Locating minutia points in the thinned image is relatively easy.</p><p>A count of the number of 'on' neighbors at a point of interest in a <span class="math inline">\(3\times 3\)</span> window is sufficient for this purpose.</p><ul><li>A ridge end point has only neighbor in the window.</li><li>A ridge bifurcation has at least three neighbors.</li></ul><p>Some post-processing can be performed to further improve detection quality.</p><p><img src="/images/endandbif3.jpg"></p><p><img src="/images/minuextra.png"></p><h2><span id="fingerprint-matching">Fingerprint Matching</span></h2><p>Matching a query fingerprint and a database fingerprint is equivalent to matching their minutia sets. Each database fingerprint minutia, <span class="math inline">\(p\)</span>, is examined to determine whether there is a corresponding query fingerprint minutia, <span class="math inline">\(q\)</span>.</p><p>There are three steps.</p><ol type="1"><li>Registration</li><li>Minutia paring</li><li>Matching score computation</li></ol><p><strong>Registration via Hough Transform</strong></p><p>The input to the registration algorithm consists of two sets of minutia points <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>. <span class="math inline">\(|P|\)</span> and <span class="math inline">\(|Q|\)</span> represent the sizes of point sets <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> respectively. <span class="math display">\[P=\{(p_x^1,p_y^1,\alpha^1),...,(p_x^{|P|},p_y^{|P|},\alpha^{|P|})\}\\Q=\{(q_x^1,q_y^1,\beta^1),...,(q_x^{|Q|},q_y^{|Q|},\beta^{|Q|})\}\]</span> Each minutia has three components: x-coordinate, y-coordinate and orientation of the minutia. Each minutia in <span class="math inline">\(P\)</span> is <strong>rotated, scaled and translated</strong> for matching against a minutia in <span class="math inline">\(Q\)</span>.</p><p>The usual <strong>Hough transform</strong> for line detection can be generalized for point matching.</p><p><img src="/images/regishoughtra.png"></p><p>The transform has maximum value of <span class="math inline">\(A\)</span> means that it can match as much points as possible.</p><p><img src="/images/imgregriscomp.png"></p><p><strong>Minutia pairing and score computation</strong></p><p>After minutia registration, the minutiae need to be paired. Two minutiae are said to be paired or matched if their components <span class="math inline">\((x, y,θ)\)</span> are equal with some tolerance after registration.</p><p><img src="/images/minutiamatch.png"></p><p>The matching algorithm is based on finding the number of paired minutiae between each database fingerprint and the query fingerprint.</p><p>In order to reduce the amount of computation, the matching algorithm takes into account only those minutiae that fall within a common bounding box. The common bounding box is the intersection of the bounding box for query and reference (database) fingerprints. Once the count of matching minutiae is obtained, a matching score is computed. The matching score is used for deciding the degree of match. Finally, a set of top ten scoring reference fingerprints is obtained as a result of matching.</p><h2><span id="fingercode">FingerCode</span></h2><p><em>FingerCode</em> is a new representation for the fingerprints which yields a <strong>relatively short, fixed length code</strong> suitable for matching as well as storage on a smartcard.</p><p>The matching reduces to finding the <strong>Euclidean distance</strong> between these <em>FingerCodes</em> and hence the matching is very fast and the representation is amenable to indexing.</p><p>The FingerCode partitions the region of interest of the given fingerprint image with respect to a reference point. A feature vector is composed of an ordered enumeration of features extracted from the information contained in each sector specified by the tessellation.</p><p><img src="/images/fingercode1.png"></p><p>The feature elements capture the local information by using the <strong>Gabor filterbank</strong>. The ordered enumeration of the tessellation captures the <strong>invariant global relationships</strong> among the local patterns.</p><p>These features capture both the global pattern of ridges and valleys and the local characteristics. Matching is based on the Euclidean distance between the FingerCodes.</p><p>There are four steps for extracting the FingerCode.</p><ol type="1"><li>Determining the reference point for the fingerprint image.</li><li>Partitioning the region around the reference point.</li><li>Filtering the region of interest in eight different directions using a bank of Gabor filters.</li><li>Computing the <strong>average absolute deviation</strong> (AAD) from the mean of gray values in individual sectors in filtered images to define the <em>FingerCode</em> (the feature vector) for matching.</li></ol><p><strong>Determining the reference point</strong></p><p><img src="/images/fingercode2.png"></p><p>Given an input fingerprint image, there are seven steps for finding the reference point.</p><ol type="1"><li><p>Estimate the orientation field <span class="math inline">\(O\)</span> using a window size of <span class="math inline">\(w\times w\)</span>.</p></li><li><p>Smooth the orientation field.</p></li><li><p>Compute the sine component <span class="math inline">\(E\)</span> of the orientation field <span class="math inline">\(O\)</span>.<br><span class="math display">\[E(i,j)=\sin O(i,j)\]</span></p></li><li><p>Initialize <span class="math inline">\(A\)</span>, a label image used to indicate the reference point.</p></li><li><p>For each pixel <span class="math inline">\(E(i, j)\)</span>, integrate pixel intensities in regions <span class="math inline">\(R_I\)</span> and <span class="math inline">\(R_{II}\)</span>, and assign the corresponding pixels in <span class="math inline">\(A\)</span> according to the value of their difference. <span class="math display">\[A(i,j)=\sum_{R_I}E(i,j)-\sum_{R_{II}}E(i,j)\]</span> <img src="/images/fingercode4.png"></p></li><li><p>Find the maximum value in <span class="math inline">\(A\)</span> and assign its coordinate to the reference point.</p></li><li><p>Repeat steps 1-6 by using a window size <span class="math inline">\(w&#39;\times w&#39;\)</span>, where <span class="math inline">\(w&#39; &lt; w\)</span>, and restrict the search for the reference point in step 6 in a local neighborhood of the detected reference point.</p></li></ol><p>The geometry of regions <span class="math inline">\(R_I\)</span> and <span class="math inline">\(R_{II}\)</span> is designed to capture the maximum curvature in concave ridges.</p><p><img src="/images/fingercode3.png"></p><p><strong>Partitioning the region around the reference point</strong></p><p>Given the detected reference point, the input fingerprint image is partitioned into 80 sectors.</p><p><img src="/images/fingercode5.png"></p><p><strong>Filtering the region of interest</strong></p><p>A minutia point can be viewed as an anomaly in locally parallel ridges and it is the information that is captured by using the Gabor filters.</p><p>Before filtering the fingerprint image, <strong>image normalization</strong> is performed separately for each sector with <span class="math inline">\(M_0\)</span> and <span class="math inline">\(VAR_0\)</span>.</p><p>An even symmetric Gabor filter is given <a href="#gabor-filter*">the Gabor filer setction</a>. The filter frequency <span class="math inline">\(f\)</span> can be set to the average ridge frequency. The average ridge frequency is the reciprocal of the average inter-ridge distance, which is around 10 pixels in a 500 dpi fingerprint image. Eight different values (<span class="math inline">\(0^o\)</span>, <span class="math inline">\(22.5^o\)</span>, <span class="math inline">\(45^o\)</span>, <span class="math inline">\(67.5^o\)</span>, <span class="math inline">\(90^o\)</span>, <span class="math inline">\(112.5^o\)</span>, <span class="math inline">\(135^o\)</span> and <span class="math inline">\(157.5^o\)</span>) are used for the direction θ with respect to the x-axis.</p><p>A fingerprint convolved with a <span class="math inline">\(0^o\)</span>-oriented filter accentuates those ridges which are parallel to the x-axis and smoothes the ridges in the other directions. These eight directional-sensitive filters capture <strong>most of the global ridge directionality information</strong> as well as the <strong>local ridge characteristics</strong> present in a fingerprint.</p><p><img src="/images/fingercode6.png"></p><p><strong>Compute AAD</strong></p><p>Let <span class="math inline">\(F_{iθ}(x, y)\)</span> be the θ-direction filtered image for sector <span class="math inline">\(S_i\)</span>. The feature value <span class="math inline">\(V_{iθ}\)</span> is the average absolute deviation (AAD) from the mean which is defined as <span class="math display">\[V_{i\theta}=\frac{1}{n_i}\sum_{(x,y)\in S_i}|F_{i\theta}(x,y)-P_{i\theta}|\]</span> where <span class="math inline">\(P_{i\theta}=\frac{1}{n_i}\sum_{(x,y)\in S_i}F_{i\theta}(x,y)\)</span>; <span class="math inline">\(n_i\)</span> is the number of pixels in <span class="math inline">\(S_i\)</span>.</p><p><img src="/images/fingercode7.png"></p><p>The average absolute deviation of each sector in each of the eight filtered images defines the components of the feature vector. Fingerprint matching is based on finding the <strong>Euclidean distance</strong> between the corresponding <em>FingerCodes</em>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HKUST CSIT5401 Recognition System lecture notes 4. 识别系统复习笔记。&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#fingerprint-image-acquisition-systems&quot;&gt;Fingerprint image acquisition systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#minutiae&quot;&gt;Minutiae&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#fingerprint-enhancement&quot;&gt;Fingerprint Enhancement&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#normalization&quot;&gt;Normalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#orientation-image-estimation&quot;&gt;Orientation Image Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#ridge-frequency-estimation&quot;&gt;Ridge Frequency Estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#region-mask-estimation&quot;&gt;Region mask estimation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#gabor-filter&quot;&gt;Gabor Filter*&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#fingerprint-matching&quot;&gt;Fingerprint Matching&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#fingercode&quot;&gt;FingerCode&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Recognition System" scheme="http://www.52coding.com.cn/tags/Recognition-System/"/>
    
      <category term="fingerprints" scheme="http://www.52coding.com.cn/tags/fingerprints/"/>
    
      <category term="fingercode" scheme="http://www.52coding.com.cn/tags/fingercode/"/>
    
      <category term="hough transform" scheme="http://www.52coding.com.cn/tags/hough-transform/"/>
    
      <category term="minutiae" scheme="http://www.52coding.com.cn/tags/minutiae/"/>
    
  </entry>
  
  <entry>
    <title>Recognizing Faces</title>
    <link href="http://www.52coding.com.cn/2018/12/06/RS%20-%20Recognizing%20Faces/"/>
    <id>http://www.52coding.com.cn/2018/12/06/RS - Recognizing Faces/</id>
    <published>2018-12-06T14:03:09.000Z</published>
    <updated>2019-04-12T03:27:49.612Z</updated>
    
    <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 3. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#histogram-equalization">Histogram Equalization</a></li><li><a href="#image-pyramid-and-neural-networks">Image Pyramid and Neural Networks</a></li><li><a href="#integral-image">Integral Image</a></li><li><a href="#adaboost">Adaboost</a></li><li><a href="#face-recognition-pca">Face Recognition (PCA)</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="histogram-equalization">Histogram Equalization</span></h2><p><a href="http://en.wikipedia.org/wiki/Face_detection" target="_blank" rel="noopener">Face detection</a> is the first step in automated face recognition. Its reliability has a major influence on the performance and usability of the entire face recognition system.</p><p>Due to lighting or shadow, intensity can vary significantly in an image. Normalization of pixel intensity helps correct variations in imaging parameters in cameras as well as changes in illumination conditions. One widely used technique is <a href="http://en.wikipedia.org/wiki/Histogram_equalization" target="_blank" rel="noopener">histogram equalization</a>, which is based on image histogram. It helps reduce extreme illumination.</p><p><strong>Image histogram</strong></p><p>It is assumed that there is a digital image with <span class="math inline">\(L\)</span> gray levels <span class="math inline">\(r_k\)</span>. The probability of occurrence of gray level <span class="math inline">\(r_k\)</span> is given by <span class="math display">\[p_r(r_k)=\frac{n_k}{N}\]</span> where <span class="math inline">\(n_k\)</span> is number of pixels with gray level <span class="math inline">\(r_k\)</span>; <span class="math inline">\(N\)</span> is total number of pixels in an image; <span class="math inline">\(k = 0,1,2,...,L-1\)</span>.</p><p><img src="/images/imagehis.png"></p><p>We want an image with equally many pixels at every gray level, or the output intensity approx follows <strong>uniform distribution</strong>.</p><p>That is, a flat histogram, where each gray level, <span class="math inline">\(r_k\)</span>, appears equal number of times, i.e., <span class="math inline">\(N/L\)</span> times.</p><p><img src="/images/imgequ.png"></p><p>Assume that variable <span class="math inline">\(r\)</span> has been normalized between <span class="math inline">\([0,1]\)</span>. The intensity transformation is <span class="math inline">\(s = T(r)\)</span>, such that</p><ul><li><span class="math inline">\(T(r)\)</span> is single-valued and non-decreasing in the interval <span class="math inline">\(0≤r≤1\)</span>.</li><li><span class="math inline">\(0≤T(r)≤1\)</span> for <span class="math inline">\(0≤r≤1\)</span>.</li></ul><p><strong>Histogram equalization transform</strong></p><p>The intensity transformation is the cumulative distribution function (CDF) of <span class="math inline">\(r\)</span>, which is represented by <span class="math display">\[s=T(r)=\int_0^rp_r(w)dw\]</span> The discrete implementation is given by <span class="math display">\[s_k=T(r_k)=\sum_{j=0}^k\frac{n_j}{N}=\sum_{j=0}^kp_r(r_j)\]</span> where <span class="math inline">\(s_k\)</span> is the <strong>output intensity</strong>; <span class="math inline">\(r_k\)</span> is the input intensity; <span class="math inline">\(n_j\)</span> is the number of pixels with gray level <span class="math inline">\(r_j\)</span>.</p><p>Below are some examples:</p><p><img src="/images/hisequeg.png"></p><p><img src="/images/hisequeg2.png"></p><p>Histogram equalization can significantly improve image appearance</p><ul><li>Automatic</li><li>User doesn’t have to perform windowing</li></ul><p>Nice pre-processing step before face detection</p><ul><li>Account for different lighting conditions</li><li>Account for different camera/device properties</li></ul><p>There are two methods for <strong>face detection</strong>:</p><ol type="1"><li>Method using image pyramid and neural networks [Rowley-Baluja-Kanade-98]</li><li>Method using integral image and AdaBoost learning [Viola-Jones-04]</li></ol><h2><span id="image-pyramid-and-neural-networks">Image Pyramid and Neural Networks</span></h2><p>With the neural networks, a classifier may be trained directly using preprocessed and normalized face and nonface training subwindows.</p><p><a href="http://www.cs.cmu.edu/~har/" target="_blank" rel="noopener">Rowley et al</a> use the preprocessed 20x20 subwindows as the input to a neural network. The final decision is made to classify the 20x20 subwindow into face and nonface. The architecture is shown below.</p><p><img src="/images/facepy.png"></p><p>Instead of upright, frontal faces, a <strong>router network</strong> can be trained to process each input window so that orientation can be estimated. Once the orientation is estimated, the input window can be prepared for detector neural network.</p><p><img src="/images/router.png"></p><p><strong>Rowley et al.</strong> proposed two neural networks, as presented in the previous slides. The first one is the router network which is trained to estimate the orientation of an assumed face in the 20x20 sub-window. The second one is the normal frontal, upright face detector. However, it only handles <strong>in-plane rotation</strong>.</p><p><strong>Huang et al.</strong> proposed a multi-view face tree structure for handling both in-plane and <strong>out-of-plane rotations</strong>. Every node corresponds to a strong classifier.</p><p><img src="/images/hung.png"></p><h2><span id="integral-image">Integral Image</span></h2><p><strong>Method using integral image and AdaBoost learning</strong></p><p>The <a href="http://en.wikipedia.org/wiki/Summed_area_table" target="_blank" rel="noopener">integral image</a> <span class="math inline">\(ii(x, y)\)</span> at location <span class="math inline">\((x, y)\)</span> contains the <strong>sum of the pixel intensity values above and to the left</strong> of the location <span class="math inline">\((x, y)\)</span>, inclusive.</p><p>The <span class="math inline">\(ii\)</span> is defined as <span class="math display">\[ii(x,y)=\sum_{x&#39;≤x,y&#39;≤y}i(x&#39;,y&#39;)\]</span> where <span class="math inline">\(ii(x,y)\)</span> is the integral image and <span class="math inline">\(i(x,y)\)</span> is the original input image.</p><p><img src="/images/integralimg.png"></p><p>Using the following pair of recurrences: <span class="math display">\[s(x, y)=s(x, y-1)+i(x,y)\\ii(x,y)=ii(x-1, y)+s(x,y)\]</span> where <span class="math inline">\(s(x,y)\)</span> is the cumulative row sum, <span class="math inline">\(s(x, -1) = 0\)</span>, and <span class="math inline">\(ii(-1, y)=0\)</span>, the integral image can be computed in one pass over the original image.</p><p>Using the integral image, any rectangular sum can be computed in four array references.</p><p><img src="/images/inteeg.png"></p><p><strong>Rectangle features</strong></p><p>The features for face detection are Haar-like functions. There are three kinds of features.</p><p>[1] Two-rectangle feature: The difference between the sum of the pixels within two rectangular regions.</p><p><img src="/images/recfea1.png"></p><p>[2] Three-rectangle feature: The feature is the sum within two outside rectangles subtracted from the sum in a center rectangle.</p><p><img src="/images/recfea2.png"></p><p>[3] Four-rectangle feature: The difference between diagonal pairs of rectangles.</p><p><img src="/images/recfea3.png"></p><p>The rectangle features are sensitive to the presence of edges, bars/lines, and other simple image structures in different scales and at different locations.</p><p>Given that the base resolution of the detector is 24 x 24 pixels, the exhaustive set of rectangle features is quite large, 160,000.</p><p>Given a feature set and a training set of positive and negative images, a classification function must be learned to classify a pattern into either face or non-face.</p><h2><span id="adaboost">Adaboost</span></h2><p>In this work, the classifier is designed based on the assumption that a very small number of features can be combined to form an effective classifier.</p><p>The <a href="http://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">AdaBoost</a> learning algorithm is used to boost the classification performance of a simple learning algorithm. The simple learning algorithm is applied to all rectangle features.</p><p>It does this by <strong>combining a collection of weak classification functions</strong> (weak classifiers with relatively high classification error) to form a stronger classifier. The final strong classifier takes the form of <strong>a weighted combination of weak classifiers followed by a threshold</strong>.</p><p>Weak classifier <span class="math inline">\(h_t\)</span> (each classifier compute one rectangle feature): <span class="math display">\[h_t(\vec{x})=\begin{cases}1\ \text{if }\vec{x}\text{ represents a face image }(f_t(\vec{x})&gt;\text{Threshold})\\-1\ \text{otherwise}\end{cases}\\f_t(\vec{x})=\sum_{white} x-\sum_{black} x\]</span> The strong classifier is <span class="math display">\[H(\vec{x})=\text{sgn}\left(\sum_{t=1}^T\alpha_th_t(\vec{x})\right)\]</span> where <span class="math inline">\(\alpha_t\)</span> is weight; and <span class="math inline">\(\text{sgn}(x)\)</span> is sign function: <span class="math display">\[\text{sgn}(x)=\begin{cases} -1,  &amp; \mbox{if }x≤0 \\1, &amp; \mbox{if }x&gt;0\end{cases}\]</span> <strong>Algorithm</strong></p><p>Given example images and classifications <span class="math inline">\((\vec{x}_i, y_i), i = 1, 2,..., N\)</span>, where <span class="math inline">\(N\)</span> is the total number of images.</p><p>Start with equal weights on each image <span class="math inline">\(\vec{x}_i\)</span>.</p><p>For <span class="math inline">\(t=1, ..., T\)</span>:</p><ul><li><p>Normalize all weights <span class="math inline">\(w_i = \frac{w_i}{\sum_{j=1}^Nw_j}\)</span> such that <span class="math inline">\(\sum_{i=1}^Nw_i=1\)</span>.</p></li><li><p>Select the weak classifier <span class="math inline">\(h_k\)</span> with minimum error: <span class="math display">\[e_k=\sum_{i=1}^Nw_i\left(\frac{1-h_k(\vec{x}_i)y_i}{2}\right)\]</span> where <span class="math inline">\(0≤e_k≤1\)</span>.</p></li><li><p>Set weight for selected weak classifier <span class="math display">\[\alpha_t=\frac{1}{2}\ln\left(\frac{1-e_k}{e_k}\right)\]</span></p></li><li><p>Reweight the examples (boosting) <span class="math display">\[w_i=w_i\exp(-\alpha_iy_ih_k(\vec{x}_i))\]</span></p></li></ul><p>For the last step, if the weak classifier classify example <span class="math inline">\(i\)</span> correctly, i.e. <span class="math inline">\(h_k(\vec{x}_i)=y_i\)</span>, then the example weight <span class="math inline">\(w_i=w_ie^{-\alpha_t}\)</span> will decrease; if the weak classifier classify example <span class="math inline">\(i\)</span> wrongly, the weight <span class="math inline">\(w_i=w_i^{\alpha_t}\)</span> will increase.</p><p>Values of <span class="math inline">\(T\)</span> can be 200 for <span class="math inline">\(N=10^8\)</span> images and 180,000 filters. Given the above strong classifier, a new image can classified as either face or non-face.</p><h2><span id="face-recognition-pca">Face Recognition (PCA)</span></h2><p>Images of faces often belong to a manifold of intrinsically low dimension. For example, if there are three 3x1 images (see below), then each image has three intensity values. If each intensity value is viewed as a coordinate in a 3D space, then each image can be viewed as a point in a 3D space.</p><p><img src="/images/imgspace.png"></p><p>To represent these points effectively, the number of dimensions can be reduced from three to one. It is the concept of <a href="http://en.wikipedia.org/wiki/Dimension_reduction" target="_blank" rel="noopener">dimensionality reduction</a>.</p><p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">Principal component analysis</a> (PCA) is a method for performing dimensionality reduction of high dimensional face images.</p><p><strong>Eigenfaces</strong></p><p>Let us consider a set of <span class="math inline">\(N\)</span> sample images (image vectors) with <span class="math inline">\(m\times n\)</span> dimensions:</p><p><img src="/images/eigenface1.png"></p><p>Each image is represented by a 1D vector with dimensions <span class="math inline">\((m\times n) \times 1\)</span>. The <strong>mean image vector</strong> is given by <span class="math display">\[\vec{x}=\frac{1}{N}\sum_{i=1}^N\begin{bmatrix}x_{i,1}      \\\vdots \\x_{i,mn}\end{bmatrix}\]</span> The <strong>scatter matrix</strong> is given by <span class="math display">\[\vec{S}=[\vec{x_1}-\bar{x}\ \ \vec{x_2}-\bar{x}\ \dots\ \vec{x_N}-\bar{x}]\begin{bmatrix}(\vec{x_1}-\bar{x})^T     \\(\vec{x_2}-\bar{x})^T\\\vdots \\(\vec{x_N}-\bar{x})^T\end{bmatrix}\]</span> The corresponding <span class="math inline">\(t\)</span> eigenvectors with non-zero eigenvalues <span class="math inline">\(\lambda_i\)</span> are <span class="math display">\[\vec{e}_1\ \ \vec{e}_2\ \ \dots\ \ \vec{e}_t\]</span> where <span class="math inline">\(\lambda_1≥\lambda_2≥...≥\lambda_t\)</span>.</p><p>Then the origin image vector can be approximated by <span class="math display">\[\vec{x}_j\approx\bar{x}+\sum_{i=1}^tg_{ji}\vec{e}_i\]</span> where <span class="math inline">\(g_{ji}=(\vec{x}_j-\bar{x})\cdot\vec{e}_i\)</span>.</p><p><img src="/images/egface.png"></p><p>Since the eigenvectors <span class="math inline">\(e\)</span> have the same dimension as the image vectors, the eigenvectors are referred as <a href="http://en.wikipedia.org/wiki/Eigenface" target="_blank" rel="noopener">Eigenfaces</a>. The value of <span class="math inline">\(t\)</span> is usually much smaller than the value of <span class="math inline">\(mn\)</span>. Therefore, the number of dimensions can be reduced significantly.</p><p>For each image <span class="math inline">\(\vec{x}_i\)</span>, the dimension reduced representation is <span class="math display">\[(g_{i1}, g_{i2}, ..., g_{it})\]</span> To detect if the new image <span class="math inline">\(\vec{x}\)</span> with <span class="math inline">\(t\)</span> coefficients <span class="math inline">\((g_1, g_2, ..., g_t)\)</span> is a face: <span class="math display">\[||\vec{x}-(\bar{x}+g_1\vec{e}_1+g_2\vec{e}_2+...+g_t\vec{e}_t)||&lt;\text{Threshold}\]</span> If it is a face, find the closest labeled face based on the nearest neighbor in the <span class="math inline">\(t\)</span>-dimensional space.</p><p><strong>Near-infrared images for face recognition</strong></p><p>Most current face recognition systems are based on face images captured in the visible light spectrum. The infrared imaging system is able to produce face images of good condition regardless of visible lights in the environment.</p><p><img src="/images/infared.png"></p><p><img src="/images/infeared2.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HKUST CSIT5401 Recognition System lecture notes 3. 识别系统复习笔记。&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#histogram-equalization&quot;&gt;Histogram Equalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#image-pyramid-and-neural-networks&quot;&gt;Image Pyramid and Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#integral-image&quot;&gt;Integral Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#adaboost&quot;&gt;Adaboost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#face-recognition-pca&quot;&gt;Face Recognition (PCA)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="PCA" scheme="http://www.52coding.com.cn/tags/PCA/"/>
    
      <category term="Recognition System" scheme="http://www.52coding.com.cn/tags/Recognition-System/"/>
    
      <category term="Face Recognition" scheme="http://www.52coding.com.cn/tags/Face-Recognition/"/>
    
      <category term="histogram equalization" scheme="http://www.52coding.com.cn/tags/histogram-equalization/"/>
    
      <category term="Adaboost" scheme="http://www.52coding.com.cn/tags/Adaboost/"/>
    
  </entry>
  
  <entry>
    <title>Recognizing Irises</title>
    <link href="http://www.52coding.com.cn/2018/12/05/RS%20-%20Recognizing%20Irises/"/>
    <id>http://www.52coding.com.cn/2018/12/05/RS - Recognizing Irises/</id>
    <published>2018-12-05T13:56:09.000Z</published>
    <updated>2019-04-12T03:27:57.922Z</updated>
    
    <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 2. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#introduction">Introduction</a></li><li><a href="#image-acquisition-systems">Image Acquisition Systems</a></li><li><a href="#iris-localization">Iris localization</a></li><li><a href="#pattern-matching">Pattern Matching</a><ul><li><a href="#alignment-registration">Alignment (Registration)</a></li><li><a href="#representation">Representation</a></li><li><a href="#goodness-of-match">Goodness of Match</a></li><li><a href="#decision-fld">Decision (FLD)</a></li></ul></li><li><a href="#hough-transform">Hough Transform</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="introduction">Introduction</span></h2><p>Face recognition and iris recognition are non-invasive method for verification and identification of people. In particular, the spatial patterns that are apparent in the human iris are highly distinctive to an individual.</p><p><img src="/images/iries.png"></p><p><strong>Schematic diagram of iris recognition</strong></p><p><img src="/images/iries_recog.png"></p><h2><span id="image-acquisition-systems">Image Acquisition Systems</span></h2><p>One of the major challenges of automated iris recognition is to capture a high-quality image of the iris while remaining non-invasive to the human operator.</p><p>There are three concerns while acquiring iris images:</p><ul><li>To support recognition, it is desirable to acquire images of the iris with sufficient resolution and sharpness.</li><li>It is important to have good contrast in the interior iris pattern without resorting to a level of illumination that annoys the operator, i.e., adequate intensity of source constrained by operator comfort with brightness.</li><li>These images must be well framed (i.e., centered) without unduly constraining the operator.</li></ul><p><strong>The Daugman system</strong></p><p>The Daugman system captures images with the iris diameter typically between 100 and 200 pixels from a distance of 15-46cm.</p><p>The system makes use of an LED-based point light source in conjunction with a standard video. By carefully positioning of the point source below the operator, reflections of the light source off eyeglasses can be avoided in the imaged iris.</p><p><img src="/images/daugman.png"></p><p>The Daugman system provides the operator with live video feedback via a tiny liquidcrystal display placed in line with the camera's optics via a beam splitter. This allows the operator to see what the camera is capturing and to adjust his position accordingly.</p><p><strong>The Wildes system</strong></p><p>The Wildes system images the iris with approximately 256 pixels across the diameter from 20cm. The system makes use of a diffused source and polarization in conjunction with a low-light level camera.</p><p>The use of matched <strong>circular polarizer</strong> at the light source and camera essentially eliminates the specular reflection of the light source.</p><p><img src="/images/wildes.png"></p><p>The coupling of a low light level camera with a diffused illumination allows for a level of illumination that is entirely unobjectionable to human operators.</p><p>The relative sizes and positions of the square contours are chosen so that when the eye is in an appropriate position, the squares overlap and appear as one to the operator.</p><h2><span id="iris-localization">Iris localization</span></h2><p><img src="/images/iries_loc.png"></p><p>Image acquisition will capture the iris as part of a larger image that also contains data derived from the immediately surrounding eye region. For example, eyelashes, upper eyelid, lower eyelid and sclera. Therefore, prior to performing iris pattern matching, it is important to <strong>localize</strong> that portion of the acquired image that corresponds to an iris.</p><p><strong>The Wildes system</strong> makes use of the <strong>first derivatives</strong> of image intensity to signal the location of edges that correspond to the borders of the iris.</p><ul><li>Step 1: The image intensity information is converted into binary edge-map.</li><li>Step 2: The edge points vote to particular contour parameter values.</li></ul><p><strong>Step 1</strong></p><p>The edge map is recovered via <strong>gradient-based edge detection</strong>. This operation consists of thresholding the magnitude of the image intensity gradient magnitude. <span class="math inline">\(I\)</span> is the intensity and (x, y) are the image coordinates. <span class="math display">\[\text{Gradient magnitude }|\triangledown G(x, y)\ast I(x, y)|\\\text{2D Gaussian function } G(x, y)=\frac{1}{2\pi\sigma^2}\exp(\frac{(x-x_0)^2+(y-y_0)^2}{2\sigma^2})\]</span> <img src="/images/iris_edge.png"></p><p><strong>Step 2</strong></p><p>The voting procedure is realized via the <a href="#hough-transform">Hough transform</a>. For circular limbic or pupillary boundaries and a set of recovered edge points, a Hough transform is defined as follows.</p><p>Edge points <span class="math inline">\((x_j, y_j)\)</span> for <span class="math inline">\(j = 1, ..., n\)</span>: <span class="math display">\[H(x_c, y_c, r)=\sum_{j=1}^nh(x_j,y_j,x_c,y_c,r)\]</span> where <span class="math display">\[h(x_j, y_j, x_c, y_c, r)=\begin{cases}1, \text{ if }\ g(x_j, y_j, x_c, y_c, r)=0\\0, \text{ otherwise}\end{cases}\\g(x_j, y_j, x_c, y_c, r)=(x_j-x_c)^2+(y_j-y_c)^2-r^2\]</span> For every parameter triple <span class="math inline">\((x_c, y_c, r)\)</span> that represents a circle through the edge point <span class="math inline">\((x_j, y_j)\)</span>, <span class="math display">\[g(x_j, y_j, x_c, y_c, r)=0\]</span> <img src="/images/wildescir.png"></p><p>The parameter triple that <strong>maximizes</strong> the Hough space <span class="math inline">\(H\)</span> is common to the largest number of edge points and is a reasonable choice to represent the contour of interest.</p><hr><p>The limbus and pupil are modeled with <strong>circular contour models</strong>.</p><p><strong>The Daugman system</strong> fits the <strong>circular contours</strong> via gradient ascent on the parameters so as to maximize <span class="math display">\[\left|\frac{\partial}{\partial r}G(r)\ast\oint_{x_c,y_c,r}\frac{I(x,y)}{2\pi r}ds\right|\]</span> where <span class="math inline">\(G(r)=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(r-r_0)^2}{2\sigma^2})\)</span>; <span class="math inline">\(r_0\)</span> is the center.</p><p>The first part of the equation is to perform Gaussian smoothing; while the second part is computing the average intensity along the circle.</p><p><img src="/images/IMG_66247EE67551-1.jpg"></p><p>In order to incorporate directional tuning of the image derivative, the arc of integration <span class="math inline">\(ds\)</span> is restricted to the left and right quadrants (i.e., near vertical edges) when fitting the <em>limbic boundary</em>.</p><p>This arc is considered over a fuller range when fitting the <em>pupillary boundary</em>.</p><h2><span id="pattern-matching">Pattern Matching</span></h2><p>Having localized the region of an acquired image that corresponds to the iris, the final task is to decide if this pattern matches a previously stored iris pattern.</p><p>There are four steps:</p><ol type="1"><li>Alignment: bringing the newly acquired iris pattern into spatial alignment with a candidate data base entry.</li><li>Representation: choosing a representation of the aligned iris patterns that makes their distinctive patterns apparent.</li><li>Goodness of Match: evaluating the goodness of match between the newly acquired and data base representations.</li><li>Decision: deciding if the newly acquired data and the data base entry were derived from the same iris based on the goodness of match.</li></ol><h3><span id="alignment-registration">Alignment (Registration)</span></h3><p>To make a detailed comparison between two images, it is advantageous to establish a precise correspondence (or matching) between characteristic structures across the pair.</p><p>Both systems (Daugman and Wildes systems) compensate for image shift, scaling and rotation.</p><p><strong>The Daugman system for alignment</strong></p><p>The Daugman system uses <strong>radial scaling</strong> to compensate for overall size as well as a simple model pupil variation based on <strong>linear stretching</strong>.</p><p>The system maps the Cartesian image coordinates <span class="math inline">\((x, y)\)</span> to dimensionless polar image coordinates <span class="math inline">\((r, θ)\)</span> according to <span class="math display">\[x(r,\theta)=(1-r)x_p(0,\theta)+rx_l(1,\theta)\\y(r,\theta)=(1-r)y_p(0,\theta)+ry_l(1,\theta)\]</span> <img src="/images/daugalign.png"></p><p><img src="/images/daugali.png"></p><p><strong>The Wildes system for alignment</strong></p><p>The Wildes system uses an <strong>image-registration</strong> technique to compensate for both scaling and rotation.</p><p>This approach geometrically warps a newly acquired image <span class="math inline">\(I_a (x, y)\)</span> into alignment with a selected data base image <span class="math inline">\(I_d (x, y)\)</span> according to a mapping function <span class="math inline">\((u(x, y), v(x, y))\)</span> such that for all <span class="math inline">\((x, y)\)</span>, the image intensity value at <span class="math inline">\((x, y) – (u(x, y), v(x, y))\)</span> is close to that at <span class="math inline">\((x, y)\)</span> at <span class="math inline">\(I_d\)</span>.</p><p>The mapping function is taken to minimize <span class="math display">\[\int_x\int_y\left(I_d(x,y)-I_a(x-u, y-v)\right)^2dxdy\]</span> under the constrains to capture similarity transformation of image coordinates <span class="math inline">\((x,y)\)</span> to <span class="math inline">\((x&#39;=x-u, y&#39;=y-v)\)</span>.</p><p><img src="/images/imgreg.jpg"></p><p><strong>Translation</strong> <span class="math display">\[\vec{x}&#39;=\vec{x}+\vec{d}\]</span> <img src="/images/imgtrans.png"></p><p><strong>Rotation</strong> <span class="math display">\[\vec{x}&#39;=R_\theta\vec{x}\\R_\theta=\begin{pmatrix}\cos\theta &amp; -\sin\theta \\\sin\theta &amp; \cos\theta\end{pmatrix}\]</span> <img src="/images/imgrot.png"></p><p><strong>Rotation + Translation</strong> <span class="math display">\[\vec{x}&#39;=R\vec{x}+\vec{d}\]</span> <strong>Scaling + Translation</strong> <span class="math display">\[\vec{x}&#39;=S\vec{x}+\vec{d}\]</span> <img src="/images/scatra.png"></p><p><strong>Shearing</strong> <span class="math display">\[\vec{x}&#39;=K\vec{x}\\K=\begin{bmatrix}1      &amp; k_{xy}     \\k_{yx}     &amp; 1\end{bmatrix}\]</span> <img src="/images/shearing.png"></p><p><strong>Affine</strong>: translation + rotation + scaling + shearing <span class="math display">\[\vec{x}&#39;=R_\theta S K\vec{x}+\vec{d}\]</span> Example: <span class="math display">\[\begin{bmatrix}x&#39; \\y&#39;\end{bmatrix}=\begin{bmatrix}\cos\theta &amp; -\sin\theta \\\sin\theta &amp; \cos\theta\end{bmatrix}\begin{bmatrix}s_x &amp; 0 \\0 &amp; s_y\end{bmatrix}\begin{bmatrix}1 &amp; k_{xy} \\k_{yx} &amp; 1\end{bmatrix}\begin{bmatrix}x \\y\end{bmatrix}+\begin{bmatrix}d_x \\d_y\end{bmatrix}\]</span></p><h3><span id="representation">Representation</span></h3><p>To represent the iris image for matching, both the Daugman and Wildes systems capture the multiscale information extracted from the image.</p><p>The Wildes system makes use of the Laplacian of Gaussian filters to construct a <strong>Laplacian pyramid</strong>.</p><p>The Laplacian of Gaussian (LoG) filter is given by <span class="math display">\[-\frac{1}{\pi\sigma^4}\left(1-\frac{\rho^2}{2\sigma^2}\right)\exp(-\frac{\rho^2}{2\sigma^2})\]</span> where <span class="math inline">\(\rho\)</span> is radial distance of a point from the filter's center; <span class="math inline">\(\sigma\)</span> is standard deviation.</p><p>A Laplacian pyramid is formed by collecting the LoG filtered images.</p><p><img src="/images/logpra.png"></p><h3><span id="goodness-of-match">Goodness of Match</span></h3><p>The Wildes system uses the <strong>normalized correlation</strong> between the acquired representation and data base representation. In discrete form, the normalized correlation can be defined as follows.</p><p>Let <span class="math inline">\(p_1[i, j]\)</span> and <span class="math inline">\(p_2[i, j]\)</span> be two image arrays of size <span class="math inline">\(n \times m\)</span>.</p><p><img src="/images/gom.png"></p><p>The normal correlation is <span class="math display">\[NC=\frac{\sum_{i=1}^n\sum_{j=1}^m(p_1[i,j]-\mu_1)(p_2[i,j]-\mu_2)}{nm\sigma_1\sigma_2}\]</span> <img src="/images/gompy.png"></p><h3><span id="decision-fld">Decision (FLD)</span></h3><p>The Wildes system combines four estimated normalized correlation values into a single <strong>accept/reject</strong> judgment.</p><p>In this application, the concept of <a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis" target="_blank" rel="noopener">Fisher's linear discriminant</a> is used for making binary decision. A <strong>weight vector</strong> is found such that <strong>the variance within a class of iris data is minimized</strong> while <strong>the variance between different classes of iris data is maximized</strong> for the transformed samples.</p><p>In iris recognition application, usually there are two classes: <strong>Authentic class (A)</strong> and <strong>Imposter class (I)</strong>.</p><p>To make a binary decision on a line, all points are projected onto the weight vector (or samples are transformed by using the weight vector).</p><p><img src="/images/fld1.png"></p><p>In iris recognition using the Wildes system, all samples are 4-dimensional vectors. Let there be n 4-dimensional samples.</p><p><img src="/images/fld2.png"></p><p>The total within class variance is <span class="math display">\[\vec{S}_w=\vec{S}_i+\vec{S}_a\]</span> Between class variance is <span class="math display">\[\vec{S}_b=(\vec{\mu}_a-\vec{\mu}_i)(\vec{\mu}_a-\vec{\mu}_i)^T\]</span> If all samples are transformed, the ratio of between class variance to total within class variance is <span class="math display">\[\frac{\vec{w}^T\vec{S}_b\vec{w}}{\vec{w}^T\vec{S}_w\vec{w}}\]</span> The ratio is maximized when <span class="math display">\[\vec{w}=\vec{S}_w^{-1}(\vec{\mu}_a-\vec{\mu}_i)\]</span> And the separation point for decision making is <span class="math display">\[\frac{1}{2}\vec{w}^T(\vec{\mu}_a+\vec{\mu}_i)\]</span> Therefore, values above this point will be taken as derived from class <span class="math inline">\(A\)</span>; values below this point will be taken as derived from class <span class="math inline">\(I\)</span>.</p><p><img src="/images/fld3.png"></p><h2><span id="hough-transform">Hough Transform</span></h2><p><strong>Detecting Lines</strong></p><p>Idea: if two edge points <span class="math inline">\((x_i, y_i)\)</span> and <span class="math inline">\((x_j, y_j)\)</span> lie on the same straight line, then they should have the same values of slope and y-intercepts on the xy-plane.</p><p><img src="/images/houghline.png"></p><p><strong>[1]</strong> For a point <span class="math inline">\((x_i,y_i)\)</span>, we set up a straight line equation: <span class="math display">\[y_i=ax_i+b\Leftrightarrow b=(-x_i)a+y_i\]</span> where <span class="math inline">\(a\)</span> = slope, <span class="math inline">\(b\)</span> = y-intercept, <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> are known and fixed.</p><p><strong>[2]</strong> We subdivide the a axis into <span class="math inline">\(K\)</span> increments between <span class="math inline">\([a_\min,a_\max]\)</span>. For each increment of <span class="math inline">\(a\)</span>, we evaluate the value of <span class="math inline">\(b\)</span>.</p><p><strong>[3]</strong> A relationship between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> can be plotted in a parameter space, i.e., ab-plane.</p><p><strong>[4]</strong> We partition the parameter space into a number of bins (accumulator cells), and increment the corresponding bin <span class="math inline">\(A(a,b)\)</span> by 1 (<span class="math inline">\(b\)</span> is rounded into the nearest integer).</p><p><img src="/images/houghbin.png"></p><p><strong>[5]</strong> For another point <span class="math inline">\((x_j,y_j)\)</span>, we set up another straight line equation: <span class="math display">\[y_j=ax_j+b\Leftrightarrow b=(-x_j)a+y_j\]</span> <strong>[6]</strong> Similarly, we subdivide the a axis into K increments between <span class="math inline">\([a_\min,a_\max]\)</span>. For each increment of <span class="math inline">\(a\)</span>, we evaluate the value of <span class="math inline">\(b\)</span>. We plot the relationship between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> in the same parameter space, and update bin values in the discrete parameter space.</p><p><strong>[7]</strong> The bin <span class="math inline">\(A(a,b)\)</span> having the highest count corresponds to the straight line passing through the points <span class="math inline">\((x_i,y_i)\)</span> and <span class="math inline">\((x_j,y_j)\)</span>.</p><p><img src="/images/hough2.png"></p><p><strong>[8]</strong> The same procedure can be applied to all points. The bin <span class="math inline">\(A(a,b)\)</span> having the <strong>highest count</strong> corresponds to the straight line passing through (or passing near) the largest number of points.</p><p>Problem: Values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> run from negative infinity to positive infinity. We need infinite number of bins!</p><p>Solution: use normal representation of a line: <span class="math display">\[x\cos(\theta)+y\sin(\theta)=\rho\]</span> <img src="/images/houghnormal.png"></p><p><span class="math inline">\(\theta\)</span> runs from <span class="math inline">\(–90^o\)</span> to <span class="math inline">\(90^o\)</span>. <span class="math inline">\(\rho\)</span> runs from <span class="math inline">\(-\sqrt{2}D\)</span> to <span class="math inline">\(\sqrt{2}D\)</span>, where <span class="math inline">\(D\)</span> is the distance between corners in the image (length and width).</p><p><strong>Circle Hough Transform (CHT)</strong></p><p>The Hough transform can be used to determine the parameters of a circle when a number of points that fall on the perimeter are known. A circle with radius <span class="math inline">\(R\)</span> and center <span class="math inline">\((a, b)\)</span> can be described with the parametric equations: <span class="math display">\[x=a+R\cos(\theta)\\y=b+R\sin(\theta)\]</span> When the angle <span class="math inline">\(θ\)</span> sweeps through the full 360 degree range the points <span class="math inline">\((x, y)\)</span> trace the perimeter of a circle.</p><p>If the circles in an image are of <strong>known radius</strong> <span class="math inline">\(R\)</span>, then the search can be reduced to 2D. The objective is to find the <span class="math inline">\((a, b)\)</span> coordinates of the centers.</p><p><img src="/images/cht1.png"></p><p>If the <strong>radius is not known</strong>, then the locus of points in parameter space will fall on the surface of a <strong>cone</strong>. Each point <span class="math inline">\((x, y)\)</span> on the perimeter of a circle will produce a cone surface in parameter space. The triplet <span class="math inline">\((a, b, R)\)</span> will correspond to the accumulation cell where the largest number of cone surfaces intersect.</p><p><img src="/images/cone.png">The drawing above illustrates the generation of a conical surface in parameter space for one <span class="math inline">\((x, y)\)</span> point. A circle with a different radius will be constructed at each level, <span class="math inline">\(r\)</span>.</p><p>The search for circles with unknown radius can be conducted by using a three dimensional accumulation matrix.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HKUST CSIT5401 Recognition System lecture notes 2. 识别系统复习笔记。&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#image-acquisition-systems&quot;&gt;Image Acquisition Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#iris-localization&quot;&gt;Iris localization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#pattern-matching&quot;&gt;Pattern Matching&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#alignment-registration&quot;&gt;Alignment (Registration)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#representation&quot;&gt;Representation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#goodness-of-match&quot;&gt;Goodness of Match&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#decision-fld&quot;&gt;Decision (FLD)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#hough-transform&quot;&gt;Hough Transform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Recognition System" scheme="http://www.52coding.com.cn/tags/Recognition-System/"/>
    
      <category term="Iris" scheme="http://www.52coding.com.cn/tags/Iris/"/>
    
      <category term="FLD" scheme="http://www.52coding.com.cn/tags/FLD/"/>
    
      <category term="Daugman" scheme="http://www.52coding.com.cn/tags/Daugman/"/>
    
      <category term="Wildes" scheme="http://www.52coding.com.cn/tags/Wildes/"/>
    
      <category term="Hough Transform" scheme="http://www.52coding.com.cn/tags/Hough-Transform/"/>
    
  </entry>
  
  <entry>
    <title>Recognizing Image Features and Patterns</title>
    <link href="http://www.52coding.com.cn/2018/12/04/RS%20-%20Recognizing%20Image%20Features%20and%20Patterns/"/>
    <id>http://www.52coding.com.cn/2018/12/04/RS - Recognizing Image Features and Patterns/</id>
    <published>2018-12-04T13:56:09.000Z</published>
    <updated>2019-04-12T03:27:54.554Z</updated>
    
    <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 1. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#laplacian-point-detector">Laplacian Point Detector</a></li><li><a href="#line-detector">Line Detector</a></li><li><a href="#edge-detectors">Edge Detectors</a><ul><li><a href="#gradient-operator">Gradient Operator</a></li><li><a href="#marr-hildreth-edge-detector">Marr-Hildreth Edge Detector</a></li></ul></li><li><a href="#scale-invariant-feature-transform-sift">Scale Invariant Feature Transform (SIFT)</a></li><li><a href="#harris-corner-detector">Harris Corner Detector</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="laplacian-point-detector">Laplacian Point Detector</span></h2><p>There are three different types of intensity discontinuities in a digital image:</p><ul><li>Point (Isolated Point)</li><li>Line</li><li>Edge (Ideal, Ramp and Roof)</li></ul><p>Intensity discountinuity is detected based on the mask response <span class="math inline">\(R\)</span> within a pre-defined window, e.g. <span class="math inline">\(3\times3\)</span>: <span class="math display">\[R=\sum_{i=1}^9w_iz_i\]</span> where <span class="math inline">\(w_i\)</span> represent weights within a pre-defined window; <span class="math inline">\(z_i\)</span> represent intensity values.</p><p>If <span class="math inline">\(|R|≥T\)</span> , then a point has been detected. This point is the location on which the mask is <strong>centred</strong>, where <span class="math inline">\(T\)</span> is a non-negative threshold.</p><p>The mask below is the <strong>Laplacian mask</strong> for detecting point. Sum of all weights is zero to make sure that there is no response at a flat region (constant intensity region).</p><table><thead><tr class="header"><th style="text-align: center;">1</th><th style="text-align: center;">1</th><th style="text-align: center;">1</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">-8</td><td style="text-align: center;">1</td></tr><tr class="even"><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;">1</td></tr></tbody></table><p>The Laplacian is given as (<span class="math inline">\(f\)</span> is input image): <span class="math display">\[\triangledown^2f(x,y)=\frac{\partial^2f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}\]</span> where <span class="math display">\[\frac{\partial^2f}{\partial x^2}=f(x+1,y)-2f(x,y)+f(x-1,y)\\\frac{\partial^2 f}{\partial y^2}=f(x,y+1)-2f(x,y)+f(x,y-1)\]</span> The discrete implementation of the Laplacian operator is given as: <span class="math display">\[\triangledown^2f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)\]</span> Below are several Laplacian masks:</p><p><img src="/images/pd.png"></p><h2><span id="line-detector">Line Detector</span></h2><p>A line is detected when more than one aligned, connected points are detected or, the <strong>response</strong> of line mask <strong>is greater than some threshold</strong>. The below are line masks for detecting lines (1 pixel thick) in 4 different specific directions:</p><p><img src="/images/ld.png"></p><p>If we want to detect a line in a specified direction, then we should use the mask associated with that direction and threshold its output responses.</p><p>If 4 line masks are used, then the final response is equal to the <strong>largest</strong> response among the masks: <span class="math display">\[R = \max\left(|R_{horizontal}|, |R_{45}|, |R_{vertical}|, |R_{-45}|\right)\]</span> Example code (Matlab):</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = imread(<span class="string">'xxx.png'</span>); <span class="comment">% read image</span></span><br><span class="line">w = [<span class="number">2</span> <span class="number">-1</span> <span class="number">-1</span>; <span class="number">-1</span> <span class="number">2</span> <span class="number">-1</span>; <span class="number">-1</span> <span class="number">-1</span> <span class="number">2</span>]; <span class="comment">% mask</span></span><br><span class="line">g = <span class="built_in">abs</span>(imfilter(double(f),w)); <span class="comment">% mask responses</span></span><br></pre></td></tr></table></figure><h2><span id="edge-detectors">Edge Detectors</span></h2><p>Edge is the boundary of regions. The boundary has meaningful discontinuities in grey intensity level. There are three types of edges: ideal edge (left), ramp edge (middle) and roof edge (right).</p><p><img src="/images/3t.png"></p><p>For an <strong>ideal edge</strong> (step edge, left), an edge is a collection of connected pixels on the region boundary. Ideal edges can occur over the distance of 1 pixel.</p><p><strong>Roof edges</strong> (right) are models of lines through a region, with the base (width) of a roof edge being determined by the thickness and sharpness of the line. In the limit, when its base is 1 pixel wide, a roof edge becomes a 1 pixel thick line running through a region in an image. Roof edges can represent thin features, e.g., roads, line drawings, etc.</p><p>For a <strong>ramp edge</strong> (middle):</p><ul><li>edge point is any point contained in the ramp</li><li>edge length is determined by the length of the ramp</li><li>the slope of the ramp is inversely proportional to the degree of blurring in the edge</li><li>the <strong>first derivative</strong> of the intensity profile is positive at the points of transition into and out of the ramp (we move from left to right)</li><li>the <strong>second derivative</strong> of the intensity profile is positive at the transition associated with the dark side of the edge, and negative at the transition associated with the light side of the edge</li></ul><p><img src="/images/ramp.png"></p><p>The <strong>magnitude of the first derivative</strong> can be used to detect the presence of an edge. The <strong>sign of the second derivative</strong> can be used to determine whether an edge pixel lies on the dark or light side of an edge. The <strong>zero-crossing property</strong> of the second derivative is very useful for <strong>locating</strong> the centres of thick edge.</p><p>However, fairly little noise can have a significant impact on the first and second derivatives used for edge detection in images. <strong>Image smoothing</strong> is commonly used prior to the edge detection so that the estimations of the two derivatives can be more accurate.</p><h3><span id="gradient-operator">Gradient Operator</span></h3><p>The computation of the gradient of an image is based on obtaining the partial derivatives <span class="math inline">\(G_x = \partial f/\partial x\)</span> and <span class="math inline">\(G_y = \partial f/\partial y\)</span> at every pixel location (x,y). The gradient direction and gradient magnitude are <span class="math display">\[\tan^{-1}\left(\frac{G_y}{G_x}\right)\\|\triangledown f|\approx|G_x|+|G_y|\]</span> <img src="/images/z.png"></p><p>The are several ways to approximate the partial derivatives:</p><ul><li>Roberts cross-gradient operators<ul><li><span class="math inline">\(G_x = (z_9-z_5)\)</span></li><li><span class="math inline">\(G_y=(z_8-z_6)\)</span></li></ul></li><li>Prewitt operators<ul><li><span class="math inline">\(G_x=(z_7+z_8+z_9)-(z_1+z_2+z_3)\)</span></li><li><span class="math inline">\(G_y=(z_3+z_6+z_9)-(z_1+z_4+z_7)\)</span></li></ul></li><li>Sobel operators<ul><li><span class="math inline">\(G_x=(z_7+2z_8+z_9)-(z_1+2z_2+z_3)\)</span></li><li><span class="math inline">\(G_y=(z_3+2z_6+z_9)-(z_1+2z_4+z_7)\)</span></li></ul></li></ul><p><img src="/images/ed.png"></p><p>Below are diagonal edge masks for detecting discontinuities in the <strong>diagonal directions</strong>.</p><p><img src="/images/diag.png"></p><h3><span id="marr-hildreth-edge-detector">Marr-Hildreth Edge Detector</span></h3><p>The Laplacian of an image f(x,y) at location (x,y) is defined as <span class="math display">\[\triangledown^2f(x,y)=\frac{\partial^2f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}\]</span> There are two approximations: <span class="math display">\[\triangledown^2f=4z_5-(z_2+z_4+z_6+z_8)\\\triangledown^2f=8z_5-(z_1+z_2+z_3+z_4+z_6+z_7+z_8+z_9)\]</span> The Laplacian generally is <strong>not</strong> used in its original form for edge detection (based on zero-crossing property) because it is <strong>unacceptably sensitive to noise</strong>. We smooth the image by using a Gaussian blurring function <span class="math inline">\(G(r)\)</span>, where <span class="math inline">\(r\)</span> = radius, before we apply the Laplacian operator: <span class="math display">\[G(r)=\exp(\frac{-r^2}{2\sigma^2})\]</span> The <strong>Laplacian of a Gaussian (LoG)</strong> operator is defined by <span class="math display">\[\text{LoG}(f)=\triangledown^2(f\ast G)=f\ast(\triangledown^2G)\]</span> Using the LoG, the location of edges can be detected reliably based on the zero-crossing values because image noise level is reduced by the Gaussian function.</p><p><strong>Marr-Hildreth algorithm</strong></p><ol type="1"><li><p>Filter the input with an n-by-n Gaussian blurring filter <span class="math inline">\(G(r)\)</span>.</p></li><li><p>Compute the Laplacian of the image resulting from Step 1 using one of the following 3-by-3 masks.</p><p><img src="/images/mha.png"></p></li><li><p>Find the <strong>zero crossings</strong> of the image from Step 2.</p><ol type="1"><li>A zero crossing at a pixel implies that the signs of at least two of its opposing neighboring pixels must be different.</li><li>There are four cases to test: left/right, up/down, and the two diagonals.</li><li>For testing, the signs of the two opposing neighboring pixels must be different and their absolute Laplacian values must be larger than or equal to some threshold.</li><li>If yes, we call the current pixel a zero-crossing pixel.</li></ol></li></ol><p><img src="/images/mhed.png"></p><h2><span id="scale-invariant-feature-transform-sift">Scale Invariant Feature Transform (SIFT)</span></h2><p>SIFT is useful for finding distinctive patches (<strong>keypoints</strong>) in images and transforming keypoints (locations) into <strong>features vectors</strong> for recognition tasks.</p><p>SIFT consists of four steps:</p><ol type="1"><li>Scale-space extrema detection</li><li>Keypoint localization</li><li>Orientation assignment</li><li>Keypoint descriptor</li></ol><p>SIFT feature is</p><ul><li>invariant to image rotation and scale</li><li>partially invariant to change in illumination and 3D camera viewpoint</li></ul><p>The method is a cascade (one step followed by the other step) filtering approach, in which more computationally expensive operations are applied only at locations that pass an initial test.</p><p><strong>[1] Scale-space extrema detection</strong></p><p>Candidate locations are identified by searching for stable features across all scales in the scale space. The <strong>scale space</strong> of an image is defined as <span class="math display">\[L(x,y,\sigma)=G(x,y,\sigma)\ast I(x,y)\\G(x,y,\sigma)=\frac{1}{2\pi\sigma^2}\exp(-\frac{x^2+y^2}{2\sigma^2})\]</span> , where <span class="math inline">\(\ast\)</span> is the convolution operator (filtering operation), the variable-scale Gaussian is <span class="math inline">\(G(x, y, \sigma)\)</span> and the image is <span class="math inline">\(I(s, y)\)</span>.</p><p>The difference between two nearby scales separated by a constant multiplicative factor <span class="math inline">\(k\)</span> is <span class="math display">\[\begin{align}D(x,y,\sigma)&amp;=L(x,y,k\sigma)-L(x,y,\sigma)\\&amp;=\left(G(x,y,k\sigma)-G(x,y,\sigma)\right)\ast I(x,y)\end{align}\]</span> The DoG function provides a close and efficient approximation to the scale-normalized Laplacian of Gaussian (LoG).</p><p><img src="/images/dog.jpg"></p><p>Local <strong>extrema</strong> (maxima and minima) of <span class="math inline">\(D( x, y, σ)\)</span> are detected by comparing the values of its 26 neighbors, including 9 from the above image, 9 from bottom image and 8 from the current image.It is selected only if the center pixel is larger than <strong>all</strong> of these neighbors (26 neighbors) or smaller than all of them.</p><p><img src="/images/extra.png"></p><p><img src="/images/exdet.png"></p><p><strong>[2] Keypoint localization</strong></p><p>Once a keypoint candidate has been found by comparing a pixel to its neighbors, the next step is to determine whether the keypoint is selected based on <strong>local contrast and localization along edge</strong>. Therefore, the keypoints will be rejected if these points have low contrast.</p><p>All extrema are discarded if <span class="math inline">\(|D(x)|&lt;0.03\)</span> (minimum contrast), where <span class="math inline">\(x\)</span> represents a relative image position with maximum value of <span class="math inline">\(D\)</span>. The keypoints will be rejected if these points are poorly localized along an edge (determined based on the <strong>ratio of principle curvatures</strong>).</p><p><img src="/images/kl.png"></p><p><strong>[3] Orientation assignment</strong></p><p>Each corresponding keypoint in <span class="math inline">\(L\)</span> is assigned a dominant orientation. The keypoint descriptor can be represented relative to this orientation and therefore achieve invariance to image rotation.</p><p>The gradient magnitude and orientation are <span class="math display">\[m(x,y)=\sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2}\\\theta(x,y)=\tan^{-1}\left(\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right)\]</span> An <strong>orientation histogram</strong> is formed from the gradient orientations within a region around the keypoint. The orientation histogram has 36 bins covering the 360 degree range of orientations, 10 degrees per bin. Each sample added to the histogram is weighted by its gradient magnitude and by a Gaussian-weighted circular window (with σ that is 1.5 times that of the scale of the keypoint, and it is related to effective window size). Peak in the orientation histogram corresponds to dominant direction of the local gradients.</p><p><img src="/images/IMG_2E4DF1ED416A-1.jpg"></p><p><strong>[4] Descriptor for local image region</strong></p><p><img src="/images/kd.png"></p><p>For each detected keypoint, a local image descriptor is computed. It is partially invariant to change in illumination and 3D viewpoint.</p><p>In order to achieve orientation invariance, the coordinates and the gradient orientations are rotated relative to the keypoint orientation. A Gaussian weighting function with σ equal to one half the width of the descriptor window is used to assign a weight to the magnitude of each sample point.</p><p>Each subregion generates an orientation histogram with 8 orientation bins. Therefore, for each keypoint, if <span class="math inline">\(2\times2\)</span> descriptor is used, a feature vector can be formed with <span class="math inline">\(2\times2\times8 = 32\)</span> elements; if <span class="math inline">\(4\times4\)</span> descriptor is used, there will be <span class="math inline">\(4\times4\times8 = 128\)</span> elements in a feature vector. The <strong>optimal</strong> setting is 4x4 subregions and 8 orientation bins (the above picture).</p><p><strong>Feature matching</strong></p><p><img src="/images/IMG_043BB8EF0160-1.jpg"></p><p>Matlab Implementation</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% num = match(image1, image2)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% This function reads two images, finds their SIFT features, and</span></span><br><span class="line"><span class="comment">%   displays lines connecting the matched keypoints.  A match is accepted</span></span><br><span class="line"><span class="comment">%   only if its distance is less than distRatio times the distance to the</span></span><br><span class="line"><span class="comment">%   second closest match.</span></span><br><span class="line"><span class="comment">% It returns the number of matches displayed.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Example: match('scene.pgm','book.pgm');</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">num</span> = <span class="title">match</span><span class="params">(image1, image2)</span></span></span><br><span class="line"><span class="comment">% Find SIFT keypoints for each image</span></span><br><span class="line">[im1, des1, loc1] = sift(image1);</span><br><span class="line">[im2, des2, loc2] = sift(image2);</span><br><span class="line"><span class="comment">% For efficiency in Matlab, it is cheaper to compute dot products between</span></span><br><span class="line"><span class="comment">%  unit vectors rather than Euclidean distances.  Note that the ratio of</span></span><br><span class="line"><span class="comment">%  angles (acos of dot products of unit vectors) is a close approximation</span></span><br><span class="line"><span class="comment">%  to the ratio of Euclidean distances for small angles.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% distRatio: Only keep matches in which the ratio of vector angles from the</span></span><br><span class="line"><span class="comment">%   nearest to second nearest neighbor is less than distRatio.</span></span><br><span class="line">distRatio = <span class="number">0.6</span>;</span><br><span class="line"><span class="comment">% For each descriptor in the first image, select its match to second image.</span></span><br><span class="line">des2t = des2';</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(des1,<span class="number">1</span>)</span><br><span class="line">    dotprods = des1(<span class="built_in">i</span>,:) * des2t; <span class="comment">% compute orientation of des1[i] and des2[j] for all j</span></span><br><span class="line">    [vals, indx] = <span class="built_in">sort</span>(<span class="built_in">acos</span>(dotprods)); <span class="comment">% Take inverse cosine and sort results</span></span><br><span class="line">    <span class="comment">% Check if nearest neighbor has angle less than distRatio times 2nd.</span></span><br><span class="line">    <span class="keyword">if</span> (vals(<span class="number">1</span>) &lt; distRatio * vals(<span class="number">2</span>))</span><br><span class="line">      match(<span class="built_in">i</span>) = indx(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      match(<span class="built_in">i</span>) = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><img src="/images/IMG_DAD55EC9C383-1.jpg"></p><h2><span id="harris-corner-detector">Harris Corner Detector</span></h2><p><strong>Basic Idea</strong></p><p>We should easily recognize the point by looking at intensity values within a small window. hifting the window in any direction should yield a large change in appearance.</p><p><img src="/images/cornersad1.png"></p><p>Harris corner detector gives a mathematical approach for determining which case holds.</p><p>Change of intensity for the shift <span class="math inline">\([u, v]\)</span>: <span class="math display">\[E(u,v)=\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]\]</span> where <span class="math inline">\(w(x,y)\)</span> is window function.</p><p>For nearly constant patches, this will be near 0. For very distinctive patches, this will be larger. Hence... we want patches where <span class="math inline">\(E(u,v)\)</span> is LARGE.</p><p><img src="/images/harriasequ.png"></p><p>For small shifts <span class="math inline">\([u, v]\)</span>, we have a bilinear approximation: <span class="math display">\[E(u,v)\approx [u,v]M[u,v]^T\]</span> where <span class="math inline">\(M\)</span> is a 2x2 matrix computed from image derivatives: <span class="math display">\[M=\sum_{x,y}w(x,y)\begin{bmatrix}I_x^2      &amp; I_xI_y      \\I_xI_y      &amp; I_y^2\end{bmatrix}\]</span> Treat gradient vectors as a set of <span class="math inline">\((dx,dy)\)</span> points with a center of mass defined as being at <span class="math inline">\((0,0)\)</span>. Fit an ellipse to that set of points via scatter matrix.</p><p><img src="/images/harrianaly.png"></p><p><img src="/images/harrrieclips.png"></p><p>Measure of corner response: <span class="math display">\[R=Det(M)-k(Trace(M))^2\]</span> where <span class="math display">\[Det(M)=\lambda_1\lambda_2\\Trace(M)=\lambda_1+\lambda_2\]</span> According to <span class="math inline">\(R\)</span>, we can detect corner:</p><p><img src="/images/harrieres.png"></p><p><span class="math inline">\(R\)</span> depends only on eigenvalues of <span class="math inline">\(M\)</span>. As we can see from figure above,</p><ul><li><span class="math inline">\(R\)</span> is large for a corner.</li><li><span class="math inline">\(R\)</span> is negative with large magnitude for an edge</li><li><span class="math inline">\(|R|\)</span> is small for a flat region</li></ul><p><strong>Harris Corner Detection Algorithm</strong></p><ol type="1"><li><p>Compute <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> derivatives of image: <span class="math display">\[I_x=G_\sigma^x\ast I\\I_y=G_\sigma^y\ast I\]</span></p></li><li><p>Compute products of derivatives at every pixel: <span class="math display">\[I_x^2=I_x\cdot I_x\\I_y^2=I_y\cdot I_y\\I_{xy}=I_x\cdot I_y\]</span></p></li><li><p>Compute the sums of the products of derrivatives at each pixel: <span class="math display">\[S_x^2=G_\sigma&#39;\ast I_x^2\\S_y^2=G_\sigma&#39;\ast I_y^2\\S_{xy}=G_\sigma&#39;\ast I_{xy}\]</span></p></li><li><p>Define at each pixel <span class="math inline">\((x,y)\)</span> the matrix: <span class="math display">\[M(x,y)=\begin{bmatrix}S_x^2(x,y)      &amp; S_{xy}(x,y)      \\S_{xy}(x,y)     &amp; S_y^2(x,y)\end{bmatrix}\]</span></p></li><li><p>Compute the response of the detector at each pixel: <span class="math display">\[R=Det(M)-k(Trace(M))^2\]</span></p></li><li><p>Threshold of value of <span class="math inline">\(R\)</span>. Compute nonmax suppression.</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HKUST CSIT5401 Recognition System lecture notes 1. 识别系统复习笔记。&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#laplacian-point-detector&quot;&gt;Laplacian Point Detector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#line-detector&quot;&gt;Line Detector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#edge-detectors&quot;&gt;Edge Detectors&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#gradient-operator&quot;&gt;Gradient Operator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#marr-hildreth-edge-detector&quot;&gt;Marr-Hildreth Edge Detector&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#scale-invariant-feature-transform-sift&quot;&gt;Scale Invariant Feature Transform (SIFT)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#harris-corner-detector&quot;&gt;Harris Corner Detector&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Recognition System" scheme="http://www.52coding.com.cn/tags/Recognition-System/"/>
    
      <category term="Prewitt" scheme="http://www.52coding.com.cn/tags/Prewitt/"/>
    
      <category term="Sobel" scheme="http://www.52coding.com.cn/tags/Sobel/"/>
    
      <category term="Marr-Hildreth Edge Detector" scheme="http://www.52coding.com.cn/tags/Marr-Hildreth-Edge-Detector/"/>
    
      <category term="SIFT" scheme="http://www.52coding.com.cn/tags/SIFT/"/>
    
  </entry>
  
  <entry>
    <title>RL - Deep Deterministic Policy Gradient (DDPG)</title>
    <link href="http://www.52coding.com.cn/2018/11/30/RL%20-%20Deep%20Deterministic%20Policy%20Gradient/"/>
    <id>http://www.52coding.com.cn/2018/11/30/RL - Deep Deterministic Policy Gradient/</id>
    <published>2018-11-30T05:53:09.000Z</published>
    <updated>2019-04-12T03:26:48.527Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1509.02971" target="_blank" rel="noopener">Deep Deterministic Policy Gradient (DDPG)</a> 是由 DeepMind 的 Lillicrap 等人于2015年提出的算法，发表在ICLR 2016上。DDPG 是基于 <a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener">DPG</a> 算法的改进，可以看作是 Actor-critic 和 <a href="https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/">DQN</a> 的结合，它同时学习一个 Q-function 和一个策略（policy）：用 Q-learning 的方法学习 Q-function，然后用 Q-function 更新策略。</p><a id="more"></a><h2><span id="dpg">DPG</span></h2><p><a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener">Deterministic Policy Gradient (DPG)</a> 是把策略梯度（policy gradient）算法扩展到确定性策略（deterministic policy）上。事实上，DPG 被证明是随机策略梯度（stochastic policy gradient）的一种特殊情况。</p><blockquote><p>随机策略梯度： <span class="math display">\[\triangledown_\theta J(\pi_\theta)=\mathbb{E}_{s\sim\rho^\pi, a\sim\pi_\theta}[\triangledown_\theta\log\pi_\theta(a|s)Q^\pi(s,a)]\]</span> 其中，<span class="math inline">\(\pi_\theta\)</span> 是由参数为 <span class="math inline">\(\theta\)</span> 的函数近似的策略，<span class="math inline">\(\rho^\pi\)</span> 为策略 <span class="math inline">\(\pi_\theta\)</span> 的状态分布（state distribution）。</p></blockquote><p>大部分 model-free 的增强学习算法属于泛化的<a href="https://www.52coding.com.cn/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/">策略迭代（policy iteration）</a>算法，一般分为两步：策略评估（policy evaluation） 和策略改进（ policy improvement）。策略评估通常使用 <a href="https://www.52coding.com.cn/2017/12/16/RL%20-%20Model-Free%20Prediction/#monte-carlo-learning">Monte-Carlo evaluation</a> 或 <a href="https://www.52coding.com.cn/2017/12/16/RL%20-%20Model-Free%20Prediction/#temporal-difference-learning">temporal difference learning</a> 来近似 <span class="math inline">\(Q^\pi(s, a)\)</span>。策略改进则通常通过最大化评估的 action-value 来得到：<span class="math inline">\(\mu^{k+1}(s) = \arg\max_aQ^{\mu^k}(s, a)\)</span>。</p><p>然而，在连续的动作空间（continuous action spaces）里这种最大化却是不可行的。在离散的动作空间里，我们可以为每个action计算相应 Q-value 然后进行比较；但是在连续的动作空间中，我们不可能把每个action的 Q-value 都计算出来再比较，而通过对 Q-function 求导求的方式计算最大值开销又很大。所以，取而代之的是单独用一个函数近似策略，然后<strong>用 Q-function 的梯度来改进该策略</strong>。具体来说，对于每个访问过的状态 <span class="math inline">\(s\)</span>，策略函数的参数 <span class="math inline">\(\theta^{k+1}\)</span> 根据 <span class="math inline">\(\triangledown_\theta Q^{\mu_k}(s, \mu_\theta(s))\)</span> 来更新： <span class="math display">\[\begin{align}\theta^{k+1}&amp;=\theta^k+\alpha\mathbb{E}_{s\sim\rho^{\mu^k}}[\triangledown_\theta Q^{\mu^k}(s, \mu_\theta(s))]\\&amp;= \theta^k + \alpha\mathbb{E}_{s\sim\rho^{\mu^k}}[\triangledown_\theta \mu_\theta(s)\triangledown_aQ^{\mu^k}(s, a)|_{a=\mu_\theta(s)}]\end{align}\]</span></p><p>可以证明，上述更新也属于策略梯度算法，这就是DPG算法的策略更新公式。</p><h2><span id="ddpg">DDPG</span></h2><p>DDPG改进了 Q-function 的学习方式，而策略端的更新方式和DPG相同，即如式(1)所示。在 DPG 中，Q-function 是通过 Q-learning 的方式来学习的，而当使用神经网络来近似 Q-function 的时候会导致训练不稳定，DDPG 应用了 <a href="https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/#deep-q-network">DQN</a> 中的两个trick来解决不稳定的问题，也就是<strong>经验池（replay buffer）</strong>和<strong>目标网络（target network）</strong>。</p><p>具体来说，经验池 <span class="math inline">\(D\)</span> 每次探索都会存储元组 <span class="math inline">\((s, a, r, s&#39;, d)\)</span>，其中 <span class="math inline">\(d\)</span> 为一个布尔变量，如果 <code>d == True</code>，就表明 <span class="math inline">\(s&#39;\)</span> 是终止状态（terminal state）。 每次更新时都会从经验池随机采样一批数据进行更新。经验池的大小是一个需要微调的超参数：如果经验池过小的话，会导致对池内数据过拟合；如果经验池存储所有数据的话，又会放慢学习的速度。</p><p>目标网络是指用单独的网络参数来生成目标（q-target），设策略函数的参数为 <span class="math inline">\(\theta\)</span>，Q-function 的参数为 <span class="math inline">\(\phi\)</span>，则对应的目标网络参数为 <span class="math inline">\(\theta_{tag}\)</span> 和 <span class="math inline">\(\phi_{tag}\)</span>，生成的目标为： <span class="math display">\[r + \gamma(1-d)Q_{\phi_{tag}}(s&#39;, \mu_{\theta_{tag}}(s&#39;))\]</span> 所以 Q-value 端的更新公式为： <span class="math display">\[\triangledown_\phi \mathbb{E}_{s,a,r,s&#39;,d\sim D}\left[\left(Q(s,a)-(r + \gamma(1-d)Q_{\phi_{tag}}(s&#39;, \mu_{\theta_{tag}}(s&#39;)))\right)^2\right]\]</span> 与DQN不同的是，DDPG中的目标网络使用“软更新”的方式，即目标网络并不是隔一定时间后与主网络同步，而是朝着主网络缓慢移动： <span class="math display">\[\theta_{tag}\leftarrow\tau\theta+(1-\tau)\theta_{tag}\\\phi_{tag}\leftarrow\tau\phi+(1-\tau)\phi_{tag}\]</span> 其中，<span class="math inline">\(\tau \in (0, 1)\)</span> 是一个超参数，通常取值接近 1。</p><p>为了增加探索能力，训练时在选择每个动作的时候都会加上随机噪声 <span class="math inline">\(\mathcal{N}\)</span>，论文作者建议使用时间相关的 <a href="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process" target="_blank" rel="noopener">OU噪声</a>，但是最近的研究结果表明使用不相关的、zero-mean的高斯噪声效果会更好。同时为了取得更高质量的训练数据，噪声可以随着训练过程逐步减小。另外，在评测时应去掉噪声。</p><p><strong>DDPG算法</strong></p><p><img src="/images/ddpg_algo.svg"></p><h2><span id="总结">总结</span></h2><p><strong>特点</strong></p><ul><li>off-policy算法</li><li>只能用于连续的动作空间</li><li>可以看作是把DQN应用到连续动作空间</li></ul><h2><span id="references">References</span></h2><p>[1] http://proceedings.mlr.press/v32/silver14.pdf</p><p>[2] https://arxiv.org/abs/1509.02971</p><p>[3] https://spinningup.openai.com/en/latest/algorithms/ddpg.html</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1509.02971&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Deep Deterministic Policy Gradient (DDPG)&lt;/a&gt; 是由 DeepMind 的 Lillicrap 等人于2015年提出的算法，发表在ICLR 2016上。DDPG 是基于 &lt;a href=&quot;http://proceedings.mlr.press/v32/silver14.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DPG&lt;/a&gt; 算法的改进，可以看作是 Actor-critic 和 &lt;a href=&quot;https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/&quot;&gt;DQN&lt;/a&gt; 的结合，它同时学习一个 Q-function 和一个策略（policy）：用 Q-learning 的方法学习 Q-function，然后用 Q-function 更新策略。&lt;/p&gt;
    
    </summary>
    
      <category term="博客" scheme="http://www.52coding.com.cn/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Reinforcement Learning" scheme="http://www.52coding.com.cn/tags/Reinforcement-Learning/"/>
    
      <category term="增强学习" scheme="http://www.52coding.com.cn/tags/%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Policy Gradient" scheme="http://www.52coding.com.cn/tags/Policy-Gradient/"/>
    
      <category term="DPG" scheme="http://www.52coding.com.cn/tags/DPG/"/>
    
      <category term="DDPG" scheme="http://www.52coding.com.cn/tags/DDPG/"/>
    
      <category term="DQN" scheme="http://www.52coding.com.cn/tags/DQN/"/>
    
  </entry>
  
  <entry>
    <title>RL - Proximal Policy Optimization (PPO)</title>
    <link href="http://www.52coding.com.cn/2018/11/25/RL%20-%20PPO/"/>
    <id>http://www.52coding.com.cn/2018/11/25/RL - PPO/</id>
    <published>2018-11-25T14:00:09.000Z</published>
    <updated>2019-04-12T03:27:35.929Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1707.06347" target="_blank" rel="noopener">Proximal Policy Optimization (PPO, PPO-Clip, PPO-Penalty)</a> 是由<a href="https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/">TRPO</a>的作者Schulman等人于2017年提出的策略梯度类算法。PPO算法的思路和TRPO一致，都是想在优化时采取尽可能大的步幅但又不能太大以至于产生崩坏。相比于比TRPO，PPO实现起来更简单，泛化能力更强，可以使用随机梯度下降（SGD）进行优化。</p><a id="more"></a><h2><span id="背景">背景</span></h2><p>PPO的背景与<a href="https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/#背景">TRPO的背景</a>一致，最终TRPO推导出如下的带约束优化问题： <span class="math display">\[\max_{\theta}\mathbb{E}_t[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t]\\\text{subject to }\mathbb{E}_t[\text{KL}[\pi_{\theta_{old}}(\cdot|s_t), \pi_\theta(\cdot|s_t)]]\]</span> 令 <span class="math inline">\(r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\)</span> 为新旧策略的概率比（易知 <span class="math inline">\(r_t(\theta_{old}) = 1\)</span>）。TRPO最大化的替代目标（surrogate objective）可以写为如下形式： <span class="math display">\[L^{CPI}(\theta)=\mathbb{E}_t[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t]=\mathbb{E}_t[r_t(\theta)A_t]\]</span> 如果不加约束的话，直接优化该目标会产生巨大的更新，导致更新不稳定甚至崩溃。所以需要考虑一种惩罚方法，使 <span class="math inline">\(r_t(\theta)\)</span> 接近 <span class="math inline">\(1\)</span>。</p><h2><span id="ppo-clip">PPO-Clip</span></h2><p>PPO-Clip的目标函数为： <span class="math display">\[L^{CLIP}(\theta)=\mathbb{E}_t[\min(r_t(\theta)A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)A_t)]\]</span> 其中 <span class="math inline">\(\epsilon\)</span> 为超参数控制截断率，取值通常比较小（0.2左右）。</p><p>上述目标函数的第一项与 <span class="math inline">\(L^{CPI}\)</span> 一致，第二项则是为了限制更新幅度（施加惩罚），控制 <span class="math inline">\(r_t(\theta) \in [1-\epsilon, 1+\epsilon]\)</span>。可见 <span class="math inline">\(L^{CLIP}(\theta)\)</span> 是 <span class="math inline">\(L^{CPI}(\theta)\)</span> 的一个下界。</p><p><img src="/images/lclip.png"></p><p>上图显示了 <span class="math inline">\(\text{clip}\)</span> 函数的工作方式：</p><ul><li>当 <span class="math inline">\(A &gt; 0\)</span> 时，如果想使目标函数取得更大的值，就需要增大 <span class="math inline">\(\pi_\theta(a_t|s_t)\)</span> 的值，也就是增大 <span class="math inline">\(r_t(\theta)\)</span> 。但是式中的 <span class="math inline">\(\min\)</span> 函数限制了 <span class="math inline">\(r_t(\theta)\)</span> 最大取到 <span class="math inline">\(1+\epsilon\)</span>，所以新策略再远离旧策略（<span class="math inline">\(r_t(\theta)\)</span> 继续增大）并不会带来更多地好处。</li><li>当 <span class="math inline">\(A &lt; 0\)</span> 时，如果想使目标函数取得更大的值，就需要减小 <span class="math inline">\(\pi_\theta(a_t|s_t)\)</span> 的值，也就是减小 <span class="math inline">\(r_t(\theta)\)</span> 。但是式中的 <span class="math inline">\(\min\)</span> 函数限制了 <span class="math inline">\(r_t(\theta)\)</span> 最小取到 <span class="math inline">\(1-\epsilon\)</span>，所以新策略再远离旧策略（<span class="math inline">\(r_t(\theta)\)</span> 继续减小）并不会带来更多地好处。</li></ul><p>在实现中，目标函数通常使用更简单的形式： <span class="math display">\[L^{CLIP}(s, a, \theta_k, \theta)=\min(\frac{\pi_\theta(a|s)}{\pi_{\theta_{k}}(a|s)}A^{\pi_{\theta_k}}(s, a), g(\epsilon, A^{\pi_{\theta_k}}(s, a)))\]</span> 其中， <span class="math display">\[g(\epsilon, A^{\pi_{\theta_k}}(s, a))=\begin{cases} (1+\epsilon)A,  &amp; \mbox{if }A ≥0 \\(1-\epsilon)A, &amp; \mbox{if }A&lt;0\end{cases}\]</span></p><blockquote><p>注：即便对 <span class="math inline">\(r_t(\theta)\)</span> 加上截断，新策略仍染有可能偏离旧策略很远，不过有很多trick来处理这个问题。其中一个特别简单的处理方式就是：如果新策略和旧策略的平均KL距离大于某个阈值，则停止进行更新（<strong>early stopping</strong>）。</p></blockquote><p>相比于TRPO，由于没有了KL约束，PPO可以用SGD来进行优化，实现简单很多。</p><p><strong>PPO-Clip算法</strong></p><p><img src="/images/ppo_algo.svg"></p><h2><span id="ppo-penalty">PPO-Penalty</span></h2><p>这种方法使用KL距离作为惩罚项，关键在于求出能够自适应多种任务的惩罚因子 <span class="math inline">\(\beta\)</span>。算法的逻辑为，在每次策略进行更新时：</p><ul><li><p>使用SGD优化目标函数： <span class="math display">\[L^{KLPEN}(\theta)=\mathbb{E}_t\left[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t-\beta\cdot\text{KL}[\pi_{old}(a_t|s_t), \pi_\theta(a_t|s_t)]\right]\]</span></p></li><li><p>计算 <span class="math inline">\(d = \mathbb{E}\left[\text{KL}[\pi_{\theta_{old}}(\cdot|s_t), \pi_\theta(\cdot|s_t)]\right]\)</span></p><ul><li>如果 <span class="math inline">\(d &lt; d_{targ}/1.5\)</span>，则 <span class="math inline">\(\beta \leftarrow \beta/2\)</span></li><li>如果 <span class="math inline">\(d &gt; d_{targ} \times 1.5\)</span>，则 <span class="math inline">\(\beta \leftarrow\beta \times 2\)</span></li></ul><p>其中，<span class="math inline">\(d_{targ}\)</span> 为超参数。</p></li></ul><blockquote><p>注：PPO-Penalty 没有 PPO-Clip 效果好。</p></blockquote><h2><span id="实验和总结">实验和总结</span></h2><p><strong>特点</strong></p><ul><li>训练稳定</li><li>通过限制 <span class="math inline">\(r_t(\theta)\)</span> 来找到尽可能大的并且合理的步长</li><li>on-policy 算法</li><li>可用于离散和连续的动作空间</li><li>相比于TRPO，PPO实现简单，效果更好</li></ul><p><strong>实验性能</strong></p><p>在大部分 MuJoCo 环境中强于其他策略梯度类算法，在Atari环境中，表现仅次于ACER，但是学习速度优于ACER。</p><p><img src="/images/ppo_mujoco.png"></p><p><img src="/images/ppo_atari.png"></p><h3><span id="代码">代码</span></h3><p>自己也实现了一下PPO-Clip算法，代码在<a href="https://github.com/NeymarL/Pacman-RL/blob/master/src/ppo.py" target="_blank" rel="noopener">这里</a>。下图显示了在 OpenAI <a href="https://gym.openai.com/" target="_blank" rel="noopener">Gym</a> 上的 <code>MsPacman-ram-v0</code> 环境上的测试结果：</p><p><img src="/images/ppo_pacman.png"></p><p><img src="/images/sample1.gif"></p><p><img src="/images/sample2.gif"></p><h2><span id="references">References</span></h2><p>[1] https://arxiv.org/abs/1707.06347</p><p>[2] https://spinningup.openai.com/en/latest/algorithms/ppo.html</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.06347&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Proximal Policy Optimization (PPO, PPO-Clip, PPO-Penalty)&lt;/a&gt; 是由&lt;a href=&quot;https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/&quot;&gt;TRPO&lt;/a&gt;的作者Schulman等人于2017年提出的策略梯度类算法。PPO算法的思路和TRPO一致，都是想在优化时采取尽可能大的步幅但又不能太大以至于产生崩坏。相比于比TRPO，PPO实现起来更简单，泛化能力更强，可以使用随机梯度下降（SGD）进行优化。&lt;/p&gt;
    
    </summary>
    
      <category term="博客" scheme="http://www.52coding.com.cn/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Reinforcement Learning" scheme="http://www.52coding.com.cn/tags/Reinforcement-Learning/"/>
    
      <category term="增强学习" scheme="http://www.52coding.com.cn/tags/%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Policy Gradient" scheme="http://www.52coding.com.cn/tags/Policy-Gradient/"/>
    
      <category term="PPO" scheme="http://www.52coding.com.cn/tags/PPO/"/>
    
  </entry>
  
  <entry>
    <title>RL - Trust Region Policy Optimization (TRPO)</title>
    <link href="http://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/"/>
    <id>http://www.52coding.com.cn/2018/11/22/RL - TRPO/</id>
    <published>2018-11-22T09:10:09.000Z</published>
    <updated>2019-04-12T03:27:40.560Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1502.05477" target="_blank" rel="noopener">Trust Region Policy Optimization (TRPO)</a>算法是由伯克利大学的Schulman等人于2015年提出的策略梯度（Policy Gradients）算法。TRPO通过最大化新策略相对于当前策略的优势来保证每次更新都是单调递增的（稳定），同时找到尽可能大的更新步幅。算法推导出的最终结果是在KL约束下最大化替代优势函数。</p><a id="more"></a><h2><span id="背景">背景</span></h2><p>考虑经典的 MDP<span class="math inline">\(&lt;S, A, P, r, \rho_0, \gamma&gt;\)</span>，其中 <span class="math inline">\(S\)</span> 是所有状态（state）的集合，<span class="math inline">\(A\)</span> 是所有动作（action）的集合，<span class="math inline">\(P: S\times A\times S \rightarrow \mathbb{R}\)</span> 是转移概率分布，<span class="math inline">\(r\)</span> 是奖励（reward）函数，<span class="math inline">\(\rho_0\)</span> 是初始状态（<span class="math inline">\(s_0\)</span>）分布，<span class="math inline">\(\gamma\)</span> 是折扣因子（ discount factor）。</p><p>定义 <span class="math inline">\(\pi\)</span> 为一个随机策略：<span class="math inline">\(\pi: S\times A\rightarrow [0, 1]\)</span>，定义 <span class="math inline">\(\eta(\pi)\)</span> 来衡量策略 <span class="math inline">\(\pi\)</span> 的好坏： <span class="math display">\[\eta(\pi)=\mathbb{E}_{s_0, a_0, ...\sim\pi}[\sum_{t=0}^\infty\gamma^tr(s_t)]\]</span> 接着定义 state-action value function <span class="math inline">\(Q_\pi\)</span>, value function <span class="math inline">\(V_\pi\)</span>, 优势函数（advantage function）<span class="math inline">\(A_\pi\)</span>: <span class="math display">\[Q_\pi(s_t, a_t) = \mathbb{E}_{s_{t+1}, a_{t+1}, ...\sim\pi}[\sum_{l=0}^\infty\gamma^lr_{s_{t+l}}]\]</span></p><p><span class="math display">\[V_\pi(s_t) =\mathbb{E}_{a_t, s_{t+1}, ...\sim\pi}[\sum_{l=0}^\infty\gamma^lr_{s_{t+l}}]\]</span></p><p><span class="math display">\[A_\pi(s, a) = Q_\pi(s, a) - V_\pi(s)\]</span></p><p>然后可以通过下式来衡量策略 <span class="math inline">\(\tilde{\pi}\)</span> 相对于策略 <span class="math inline">\(\pi\)</span> 的优势（证明详见论文）： <span class="math display">\[\begin{align}\eta(\tilde{\pi})&amp;=\eta(\pi)+\mathbb{E}_{s_0, a_0, ...\sim\color{red}{\tilde{\pi}}}[\sum_{t=0}^\infty\gamma^tA_\pi(s_t,a_t)]\\&amp;= \eta(\pi)+\sum_s\color{red}{\rho_\tilde{\pi}(s)}\sum_a\tilde{\pi}(a|s)A_\pi(s, a)\end{align}\]</span> 其中 <span class="math inline">\(\rho_\pi\)</span> 为策略 <span class="math inline">\(\pi\)</span> 的折扣访问频率（discounted visitation frequency）： <span class="math display">\[\rho_\pi(s) = P(s_0=s)+\gamma P(s_1=s) + \gamma^2 P(s_2=s)+...\]</span> 通过上式可知，只要每个状态 <span class="math inline">\(s\)</span> 的期望优势非负，即 <span class="math inline">\(\sum_a\tilde{\pi}(a|s)A_\pi(s, a)&gt;0\)</span>，就可以保证更新是单调非递减的，这其实就是经典的<a href="https://www.52coding.com.cn/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/">策略迭代（policy iteration）</a>的更新方式。然而，由于 <span class="math inline">\(\rho_\tilde{\pi}(s)\)</span> 的存在，导致直接优化上式很困难，所以引入一个<strong>替代优势</strong>（surrogate advantage）： <span class="math display">\[\begin{align}L_\pi(\tilde{\pi})&amp;=\eta(\pi)+\sum_s\color{red}{\rho_\pi(s)}\sum_a\tilde{\pi}(a|s)A_\pi(s, a)\\\end{align}\]</span> 经过一系列推导，可以得到策略 <span class="math inline">\(\tilde{\pi}\)</span> 的优势下界： <span class="math display">\[\eta(\tilde{\pi})≥L_\pi(\tilde{\pi})-C\cdot D_{KL}^\max(\pi, \tilde{\pi})\]</span> 其中，<span class="math inline">\(C=\frac{4\epsilon\gamma}{(1-\gamma)^2}\)</span>，<span class="math inline">\(D_{KL}^\max\)</span> 是最大的KL散度。</p><p>这里相当于对优化目标 <span class="math inline">\(L_\pi(\tilde{\pi})\)</span> 进行了惩罚，惩罚因子为 <span class="math inline">\(C\)</span>，惩罚项为KL散度，目的是限制新旧策略的差距。通过最大化上述公式，就能最大化新策略 <span class="math inline">\(\tilde{\pi}\)</span> 所得到的奖励，同时又不会离旧策略 <span class="math inline">\(\pi\)</span> 太远（导致对当前数据过拟合），算法如下：</p><p><img src="/images/IMG_1925FD469BD9-1.jpeg"></p><h2><span id="trpo">TRPO</span></h2><p>由于Deep RL都是使用参数为 <span class="math inline">\(\theta\)</span> 的神经网络来拟合策略 <span class="math inline">\(\pi_\theta\)</span>，为了使公式更简洁，把算法1中公式的 <span class="math inline">\(\pi\)</span> 替换成 <span class="math inline">\(\theta\)</span>: <span class="math display">\[\theta = \arg\max_{\theta}[L(\theta_{old}, \theta)-C\cdot D_{KL}^\max(\theta_{old}|| \theta)]\]</span> 其中， <span class="math display">\[\begin{align}L(\theta_{old}, \theta) &amp;= \sum_s\rho_{\theta_{old}}(s)\sum_a\pi_\theta(a|s)A_{\theta_{old}}(s,a) \\&amp;= \mathbb{E}_{s,a\sim\pi_{\theta_{old}}}[\frac{\pi_\theta(a|s)}{\pi_{\theta_{old}}(a|s)}A_{\theta_{old}}(s,a)]\end{align}\]</span> TRPO是算法1的近似，区别在于：TRPO没有使用惩罚项 <span class="math inline">\(C\)</span>，而是使用 KL散度约束（i.e. trust region constraint）： <span class="math display">\[\theta = \arg\max_\theta L(\theta_{old}, \theta)\\\text{ s.t. }\bar{D}_{KL}(\theta||\theta_{old})≤\delta\]</span> 其中，<span class="math inline">\(\bar{D}_{KL}\)</span> 是平均KL散度： <span class="math display">\[\bar{D}_{KL}(\theta||\theta_{old})=\mathbb{E}_{s\sim\pi_{\theta_{old}}}[D_{KL}(\pi_{\theta}(\cdot|s)||\pi_{\theta_{old}}(\cdot|s))]\]</span> 然而上面的带约束优化也并非容易，所以TRPO对上式进行了一些近似，对目标函数和约束进行泰勒展开可以得到： <span class="math display">\[L(\theta_{old}, \theta) \approx g^T(\theta-\theta_{old})\]</span></p><p><span class="math display">\[\bar{D}_{KL}(\theta||\theta_{old})\approx \frac{1}{2}(\theta-\theta_{old})^TH(\theta-\theta_{old})\]</span></p><p>其中，<span class="math inline">\(g\)</span> 是替代函数的梯度在 <span class="math inline">\(\theta=\theta_{old}\)</span> 处的值，凑巧的是，它和策略梯度的值正好相等：<span class="math inline">\(g = \triangledown_\theta J(\pi_\theta)|_{\theta_{old}}\)</span>；<span class="math inline">\(H\)</span> 是对于 <span class="math inline">\(\theta\)</span> 的海森矩阵（Hessian matrix）。</p><p>于是得到如下的近似优化问题： <span class="math display">\[\theta_{k+1}=\arg\max_\theta g^T(\theta-\theta_k)\\\text{s.t. }\frac{1}{2}(\theta-\theta_k)^TH(\theta-\theta_k)≤\delta\]</span> 通过拉格朗日法求解上述约束优化问题得： <span class="math display">\[\theta_{k+1}=\theta_k+\sqrt{\frac{2\delta}{g^TH^{-1}g}}H^{-1}g\]</span> 这个就是 <a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" target="_blank" rel="noopener">Natural Policy Gradient</a> 的更新公式。不过，由于泰勒近似引入了误差，上式的解可能不满足 KL 约束，所以 TRPO 增加了一个线性搜索（backtracking line search）： <span class="math display">\[\theta_{k+1}=\theta_k+\alpha^j\sqrt{\frac{2\delta}{g^TH^{-1}g}}H^{-1}g\]</span> 其中，<span class="math inline">\(\alpha\in(0,1)\)</span> 是回溯系数（backtracking coefficient），<span class="math inline">\(j\)</span> 是最小的非负整数使得 <span class="math inline">\(\pi_{\theta_{k+1}}\)</span> 满足 KL 约束并且产生<strong>正</strong>的替代优势，这样就可以保证训练进步是单调的。</p><p>最后，计算和存储 <span class="math inline">\(H^{-1}\)</span> 的开销是很大的，尤其是神经网络的参数动不动就几M。TRPO 使用<a href="https://www.wikiwand.com/en/Conjugate_gradient_method" target="_blank" rel="noopener">共轭梯度法（conjugate gradient）</a>来解 <span class="math inline">\(Hx = g\)</span>，这样就不用直接计算和存储 <span class="math inline">\(H\)</span>。</p><p>最终的更新公式为： <span class="math display">\[\theta_{k+1}=\theta_k+\alpha^j\sqrt{\frac{2\delta}{\hat{x}^TH\hat{x}}}\hat{x}\]</span> 其中， <span class="math display">\[\begin{align}\hat{x}&amp;\approx H^{-1}g &amp; \text{(using conjugate gradient)}\end{align}\]</span></p><p><span class="math display">\[H\hat{x} = \triangledown_\theta((\triangledown_\theta\bar{D}_{KL}(\theta||\theta_k))^T\hat{x})\]</span></p><p><strong>TRPO算法</strong></p><p><img src="/images/trpo.svg"></p><h2><span id="performance">Performance</span></h2><p><strong>TRPO的一些特点</strong></p><ul><li>保证每次更新在当前训练数据上都是进步的，训练过程更加稳定</li><li>通过满足KL约束来找尽可能大的步长</li><li>on-policy 算法</li><li>可用于离散和连续的动作空间</li><li>算法较为复杂</li></ul><p><strong>实验性能</strong></p><p>在模拟机器人走路、游泳等任务中取得了在当时不错的效果；在通过视频输入玩Atari游戏的任务中表现不如DQN等方法。</p><p><img src="/images/trpo_per.jpg"></p><p>下图是我在 OpenAI <a href="https://gym.openai.com/" target="_blank" rel="noopener">Gym</a> 的 <code>Walker2d-v2</code> 和 <code>MsPacman-ram-v0</code> 中测试的结果。</p><p><img src="/images/walker.png"></p><p><img src="/images/pacman.png"></p><h2><span id="references">References</span></h2><p>[1] https://arxiv.org/abs/1502.05477</p><p>[2] https://spinningup.openai.com/en/latest/algorithms/trpo.html</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1502.05477&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Trust Region Policy Optimization (TRPO)&lt;/a&gt;算法是由伯克利大学的Schulman等人于2015年提出的策略梯度（Policy Gradients）算法。TRPO通过最大化新策略相对于当前策略的优势来保证每次更新都是单调递增的（稳定），同时找到尽可能大的更新步幅。算法推导出的最终结果是在KL约束下最大化替代优势函数。&lt;/p&gt;
    
    </summary>
    
      <category term="博客" scheme="http://www.52coding.com.cn/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Reinforcement Learning" scheme="http://www.52coding.com.cn/tags/Reinforcement-Learning/"/>
    
      <category term="增强学习" scheme="http://www.52coding.com.cn/tags/%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Policy Gradient" scheme="http://www.52coding.com.cn/tags/Policy-Gradient/"/>
    
      <category term="TRPO" scheme="http://www.52coding.com.cn/tags/TRPO/"/>
    
  </entry>
  
  <entry>
    <title>RL - DQN &amp; A3C &amp; GAE</title>
    <link href="http://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/"/>
    <id>http://www.52coding.com.cn/2018/11/16/RL - DQN and A3C/</id>
    <published>2018-11-16T06:24:32.000Z</published>
    <updated>2019-04-12T03:26:58.075Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="deep-q-network">Deep Q-Network</span></h2><p>Deep Q-Network (<a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" target="_blank" rel="noopener">DQN</a>) 是由DeepMind的Mnih等人于2013年提出的算法，该算法成功把深度学习应用到了RL领域，并（一定程度上）解决了训练不稳定的问题，在玩Atari游戏中取得了非常好的结果。</p><p>文章指出使用非线性函数拟合 Q-value 的RL算法不稳定主要因为：</p><ol type="1"><li>同一个观测序列中的数据相关性较大</li><li>当 Q-value 发生了很小的改变，可能导致整个策略（policy）发生较大变化，从而导致 Q-value 和目标 <span class="math inline">\(r + \gamma * \max_{a&#39;}Q(s&#39; ,a&#39;)\)</span> 的差距不稳定</li></ol><a id="more"></a><p>DQN使用了两个trick来解决上述问题：</p><ul><li>Experience replay<ul><li>使用经验池缓存数据，每次训练时从经验池里sample数据，从而降低训练数据之间的相关性</li></ul></li><li>Two Q networks<ul><li>一个网络用来生成 Q-target，另一个网络进行探索；每隔一定时间两个网络进行同步</li><li>这样使得 Q-target 相对稳定</li></ul></li></ul><p><strong>整体算法</strong></p><p><img src="/images/dqn.jpg"></p><hr><h2><span id="asynchronous-actor-critic">Asynchronous Actor Critic</span></h2><p>Asynchronous Actor Critic (<a href="https://arxiv.org/abs/1602.01783" target="_blank" rel="noopener">A3C</a>) 也是由DeepMind的Mnih等人提出的算法，于2016年发表在ICML上。不同于DQN的是，A3C属于策略梯度（Policy Gradient）类算法，而DQN是基于value的；相同的是，A3C也在Atari游戏上取得了非常好的结果（强于DQN）。</p><p>使用上述经验池有以下问题：</p><ol type="1"><li>使用更多的内存和计算资源</li><li>只能使用 <strong>off-policy</strong> 的RL算法（学习 old policy 产生的数据）</li></ol><p>为了使用 on-policy 算法，文章提出了使用异步学习代替经验池的方法，同时也能保持算法的稳定性，其中使用最广泛的是A3C算法，它具有以下特点：</p><ul><li>并行地使用多个 agent 在各自的环境里探索，每个 agent 在同一时刻探索的内容各不相同，从而降低了数据相关性</li><li>在CPU上训练更加高效</li></ul><p><strong>整体算法</strong></p><ol type="1"><li>同步线程专属网络（<span class="math inline">\(\theta&#39;, \theta_v&#39;\)</span>）和全局网络（<span class="math inline">\(\theta, theta_v\)</span>）</li><li>每个 agent 使用线程专属网络各自进行探索</li><li>根据线程专属网络计算梯度：<span class="math inline">\(d\theta, d\theta_v\)</span></li><li>使用 <span class="math inline">\(d\theta, d\theta_v\)</span> 更新全局网络（<span class="math inline">\(\theta, theta_v\)</span>）</li><li>回到第一步</li></ol><p><img src="/images/IMG_25EB14880DD1-1.jpeg"></p><p><strong>其他细节</strong></p><ul><li><strong>主线程向子线程传参数，子线程向主线程传梯度</strong></li><li>agent 和 critic 共用一个网络，输出分为两头</li><li>增加了熵正则化（鼓励探索）<ul><li><span class="math inline">\(\triangledown_{\theta&#39;}\log\pi(a_t|s_t;\theta&#39;)(R_t-V(s_t;\theta_v))+\beta\triangledown_{\theta&#39;}H(\pi(s_t; \theta&#39;))\)</span></li><li><span class="math inline">\(H(X) = E[-\log P(X)]\)</span></li></ul></li><li>代码参考：https://github.com/NeymarL/Pacman-RL/blob/master/src/a3c.py<ul><li><strong>注</strong>：计算 policy loss 中的 advantage 的时候不能保留其梯度，否则 policy 的梯度会流入 value network 中，产生bug</li></ul></li></ul><hr><h2><span id="generalized-advantage-estimator">Generalized Advantage Estimator</span></h2><p>Generalized Advantage Estimator (<a href="https://arxiv.org/abs/1506.02438" target="_blank" rel="noopener">GAE</a>) 是由伯克利大学的Schulman等人于2016年提出的一种新的估计优势函数（Advantage function）的方法。</p><p>我们的目标是定义优势函数 <span class="math inline">\(A^\pi(s_t, a_t)\)</span> 使其用来计算策略梯度： <span class="math display">\[\hat{g}=\mathbb{E}_{s_0, a_0...\sim\pi_\theta}[\sum_{t=0}^\infty A^\pi_t(s_t,a_t)\triangledown_\theta\pi_\theta(a_t|s_t)]\]</span> 优势函数的定义为： <span class="math display">\[A^\pi(s_t, a_t) = Q^\pi(s_t, a_t) - V^\pi(s_t)\]</span> 我们使用 <span class="math inline">\(V\)</span> 来近似价值函数（value function），那么 TD(0) error <span class="math inline">\(\delta_t^V = r_t +\gamma V(s_{t+1}-V(s_t))\)</span> 就是优势函数的一个估计，并且如果 <span class="math inline">\(V = V^\pi\)</span>，则 <span class="math inline">\(\delta_t^V\)</span> 是 <span class="math inline">\(A^\pi\)</span> 的一个无偏估计： <span class="math display">\[\begin{align}\mathbb{E}_{s_{t+1}}[\delta_t^{V^\pi}]&amp;=\mathbb{E}_{s_{t+1}}[r_t+\gamma V^\pi(s_{t+1})-V^\pi(s_t)]\\&amp;= \mathbb{E}_{s_{t+1}}[Q^\pi(s_t,a_t)-V^\pi(s_t)]\\&amp;= A^\pi(s_t,a_t)\end{align}\]</span> 只要 <span class="math inline">\(V\)</span> 是近似的，TD(0) error就是优势函数的一个有偏估计，那么TD(<span class="math inline">\(\lambda\)</span>) error又如何呢？</p><p>顺着这个思路，我们可以多往后看几步： <span class="math display">\[\begin{array}{lcl}\hat{A}_t^{(1)}&amp;:=\delta_t^V&amp;=-V(s_t)+r_t+\gamma V(s_{t+1})\\\hat{A}_t^{(2)}&amp;:=\delta_t^V + \gamma\delta_{t+1}^V&amp;=-V(s_t)+r_t+\gamma r_{t+1}+\gamma^2 V(s_{t+2})\\\hat{A}_t^{(3)}&amp;:=\delta_t^V + \gamma\delta_{t+1}^V+\gamma^2\delta_{t+2}^V &amp;=-V(s_t)+r_t+\gamma r_{t+1}+\gamma^2 r_{t+2} +\gamma^2 V(s_{t+3}) \\\end{array}\]</span></p><p><span class="math display">\[\hat{A}_t^{k}:=\sum_{l=0}^{k-1}\gamma^l\delta_{t+l}^V=-V(s_t)+r_t+\gamma r_{t+1}+...+\gamma^{k-1}r_{t+k-1}+\gamma^kV(s_{t+k})\]</span></p><p>可以看到，虽然 <span class="math inline">\(\hat{A}_t^{(k)}\)</span> 依旧是有偏估计，但是偏差随着 <span class="math inline">\(k\)</span> 的增大在逐渐减小，因为 <span class="math inline">\(\gamma^kV(s_{t+k})\)</span> 这一项衰减的越来越厉害。当 <span class="math inline">\(k\rightarrow\infty\)</span> 时： <span class="math display">\[\hat{A}_t^{(\infty)}=\sum_{l=0}^\infty\gamma^l\delta_{t+l}^V=-V(s_t)+\sum_{l=0}^\infty\gamma^lr_{t+l}\]</span> 可以看到就是 return 减去 baseline。</p><p><span class="math inline">\(\text{GAE}(\lambda)\)</span> 的定义为这些 <span class="math inline">\(k\)</span> 步估计的指数平均，即 TD(<span class="math inline">\(\lambda\)</span>) error： <span class="math display">\[\begin{align}\text{GAE}_t(\lambda)&amp;:=(1-\lambda)(\hat{A}_t^{(1)}+\lambda\hat{A}_t^{(2)}+\lambda^2\hat{A}_t^{(3)}+...)\\&amp;=(1-\lambda)(\delta_t^V+\lambda(\delta_t^V-\gamma\delta_{t+1}^V)+...)\\&amp;=\sum_{l=0}^\infty(\gamma\lambda)^l\delta_{t+l}^V\end{align}\]</span> 代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rews : rewards, vals: values, lam: lambda</span></span><br><span class="line">deltas = rews[:<span class="number">-1</span>] + gamma * vals[<span class="number">1</span>:] - vals[:<span class="number">-1</span>]</span><br><span class="line">adv_buf = discount_cumsum(deltas, gamma * lam)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discount_cumsum</span><span class="params">(x, discount)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    magic from rllab for computing discounted cumulative sums of vectors.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    input: </span></span><br><span class="line"><span class="string">        vector x, </span></span><br><span class="line"><span class="string">        [x0, </span></span><br><span class="line"><span class="string">         x1, </span></span><br><span class="line"><span class="string">         x2]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        [x0 + discount * x1 + discount^2 * x2,  </span></span><br><span class="line"><span class="string">         x1 + discount * x2,</span></span><br><span class="line"><span class="string">         x2]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> scipy.signal.lfilter([<span class="number">1</span>], [<span class="number">1</span>, float(-discount)], x[::<span class="number">-1</span>], axis=<span class="number">0</span>)[::<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><hr><h2><span id="其他">其他</span></h2><h3><span id="batch-normalization">Batch-Normalization</span></h3><p>解决网络层数变多梯度<strong>消失</strong>/爆炸问题</p><ul><li>梯度截断</li><li>初始化</li><li>RELU</li></ul><p>对每层神经元处理结果进行归一化，但又不能破坏上一层提取的特征（变换重构，引入了可学习参数<span class="math inline">\(\gamma, \beta\)</span>）</p><figure><img src="/images/bn.png" alt="bn"><figcaption>bn</figcaption></figure><p>Inference时 <span class="math inline">\(\mu_B\)</span> 和 <span class="math inline">\(\sigma^2_B\)</span> 固定。</p><p>为什么不用白化？</p><ul><li>在模型训练过程中进行白化操作会带来过高的计算代价和运算时间</li></ul><p>在BN中，是通过将activation规范为均值和方差一致的手段使得原本会减小的activation的scale变大。 <span class="math display">\[\frac{\partial h_l}{\partial h_{l-1}} = \frac{\partial BN(w_l h_{l-1})}{\partial h_{l-1}} = \frac{\partial \alpha w_l h_{l-1}}{\partial h_{l-1}}\]</span> 其中 <span class="math inline">\(\alpha\)</span> 指缩放。可以看到此时反向传播乘以的数不再和 <span class="math inline">\(w\)</span> 的尺度相关，也就是说尽管我们在更新过程中改变 <span class="math inline">\(w\)</span> 的值，但是反向传播的梯度却不受影响。</p><h3><span id="activation-layers">Activation Layers</span></h3><h4><span id="relu">ReLU</span></h4><figure><img src="/images/relu.png" alt="relu"><figcaption>relu</figcaption></figure><p>整流线性单元易于优化，因为它们和线性单元非常类似。线性单元和整流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为零。这使得只要整流线性单元处于激活状态，它的导数都能保持较大。它的梯度不仅大而且一致。整流操作的二阶导数几乎处处为 0，并且在整流线性单元处于激活状态时，它的一阶导数处处为 1。这意味着相比于引入二阶效应的激活函数来说，它的梯度方向对于学习来说更加有用。</p><p>ReLU 的过程更接近生物神经元的作用过程</p><p><strong>Leaky ReLU</strong></p><p>ReLU 及其扩展都是基于一个原则，那就是如果它们的行为更接近线性，那么模型更容易优化。 <span class="math display">\[g(z; \alpha) = \max(0, z) + \alpha \min(0, z)\]</span> <span class="math inline">\(\alpha\)</span> 为固定值或可学习参数。</p><h4><span id="sigmoid-amp-tanh">Sigmoid &amp; Tanh</span></h4><p><img src="/images/sigmoid.png" alt="sigmoid"> <span class="math display">\[g(z) = \frac{1}{1 + e^{-z}}\]</span></p><ul><li>sigmoid 常作为输出单元用来预测二值型变量取值为 1 的概率</li><li>sigmoid 函数在输入取绝对值非常大的正值或负值时会出现<strong>饱和</strong>（saturate）现象，在图像上表现为开始变得很平，此时函数会对输入的微小改变会变得不敏感。仅当输入接近 0 时才会变得敏感。从而使得学习变困难。</li><li>如果要使用 sigmoid 作为激活函数时（浅层网络），tanh 通常要比 sigmoid 函数表现更好。</li></ul><h3><span id="bagging">Bagging</span></h3><p>思想：多个模型平均效果好于单个模型</p><p><strong>Bagging（bootstrap aggregating）</strong>是通过结合几个模型降低泛化误差的技术 (Breiman, 1994)。</p><p>具体来说，Bagging 涉及构造 k 个<strong>不同的数据集</strong>。每个数据集从原始数据集中<strong>重复采样</strong>构成，和原始数据集具有<strong>相同数量</strong>的样例。这意味着，每个数据集以高概率缺少一些来自原始数据集的例子，还包含若干重复的例子（更具体的，如果采样所得的训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 <strong>2/3</strong> 的实例）</p><figure><img src="/images/bagging.png" alt="bagging"><figcaption>bagging</figcaption></figure><p>第一个分类器学到上面的圆圈就会认为数字是8，第二个分类器检测到下面的圈就会认为数字是8，把两个结合起来就知道只有当上下都有圈（置信概率最大）的时候数字才是8。</p><h3><span id="dropout">Dropout</span></h3><p>简单来说，Dropout (Srivastava et al., 2014) 通过<strong>参数共享</strong>提供了一种廉价的 <strong>Bagging</strong> 集成近似，能够训练和评估<strong>指数级数量</strong>的神经网络。</p><figure><img src="/images/dropout.png" alt="dropout"><figcaption>dropout</figcaption></figure><p><strong>Dropout与Bagging的不同点</strong>：</p><ul><li>Bagging 为串行策略；Dropout 为并行策略</li><li>在 Bagging 的情况下，所有模型都是独立的；而在 Dropout 的情况下，所有模型<strong>共享参数</strong>，其中每个模型继承父神经网络参数的不同子集。</li><li>在 Bagging 的情况下，每一个模型都会在其相应训练集上训练到收敛。而在 Dropout 的情况下，通常大部分模型都没有显式地被训练；取而代之的是，在单个步骤中我们训练一小部分的子网络，参数共享会使得剩余的子网络也能有好的参数设定。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;deep-q-network&quot;&gt;Deep Q-Network&lt;/h2&gt;
&lt;p&gt;Deep Q-Network (&lt;a href=&quot;https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DQN&lt;/a&gt;) 是由DeepMind的Mnih等人于2013年提出的算法，该算法成功把深度学习应用到了RL领域，并（一定程度上）解决了训练不稳定的问题，在玩Atari游戏中取得了非常好的结果。&lt;/p&gt;
&lt;p&gt;文章指出使用非线性函数拟合 Q-value 的RL算法不稳定主要因为：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;同一个观测序列中的数据相关性较大&lt;/li&gt;
&lt;li&gt;当 Q-value 发生了很小的改变，可能导致整个策略（policy）发生较大变化，从而导致 Q-value 和目标 &lt;span class=&quot;math inline&quot;&gt;\(r + \gamma * \max_{a&amp;#39;}Q(s&amp;#39; ,a&amp;#39;)\)&lt;/span&gt; 的差距不稳定&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="博客" scheme="http://www.52coding.com.cn/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Reinforcement Learning" scheme="http://www.52coding.com.cn/tags/Reinforcement-Learning/"/>
    
      <category term="DQN" scheme="http://www.52coding.com.cn/tags/DQN/"/>
    
      <category term="Q-learning" scheme="http://www.52coding.com.cn/tags/Q-learning/"/>
    
      <category term="A3C" scheme="http://www.52coding.com.cn/tags/A3C/"/>
    
      <category term="GAE" scheme="http://www.52coding.com.cn/tags/GAE/"/>
    
  </entry>
  
  <entry>
    <title>中国象棋Zero技术详解</title>
    <link href="http://www.52coding.com.cn/2018/11/07/CCZero/"/>
    <id>http://www.52coding.com.cn/2018/11/07/CCZero/</id>
    <published>2018-11-07T09:27:47.000Z</published>
    <updated>2019-04-12T03:23:44.922Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://cczero.org/" target="_blank" rel="noopener">中国象棋Zero（CCZero）</a>是一个开源项目，把<a href="https://arxiv.org/abs/1712.01815" target="_blank" rel="noopener">AlphaZero</a>的算法应用到了中国象棋上，旨在借助广大象棋爱好者之力一起训练出一个可以打败旋风名手的“象棋之神”。因为种种原因吧，这个目标到目前（2018/11/07）为止未能实现，或者说还差得远，而跑谱的人也越来越少了，很可能坚持不了多久了。</p><p>虽然未能实现目标，但在技术上还是有一定意义的，<a href="https://github.com/NeymarL/ChineseChess-AlphaZero" target="_blank" rel="noopener">GitHub</a>上也时不时有人询问技术细节，在此总结一下，记录一些坑以后不要再踩。</p><a id="more"></a><h2><span id="模块">模块</span></h2><p>程序主要分为三大模块（每个模块对应一个目录）：</p><ul><li><code>agents</code>：核心模块，决定如何下棋<ul><li><code>model.py</code>：神经网络模型</li><li><code>player.py</code>：MCTS，输出走法</li><li><code>api.py</code>：供外界调用model</li></ul></li><li><code>envrionment</code>：象棋规则<ul><li>训练（跑谱）使用<code>static_env.py</code>，速度快一些</li><li>用自带GUI下棋时使用的是<code>env.py</code>, <code>chessboard.py</code>这些，可以输出PNG格式的棋谱</li></ul></li><li><code>worker</code>：把agent和envrionment串联起来的脚本<ul><li><code>self_play.py</code>：自我博弈</li><li><code>compute_elo.py</code>：评测并上传结果到官网</li><li><code>optimize.py</code>：训练棋谱</li><li><code>_windows</code>后缀表示是在Windows平台上运行的相应功能，之所以分开是因为两个多进程的启动方式不同，导致代码结构也要发生一些变化，详见<a href="#自我博弈">自我博弈</a>。</li></ul></li></ul><h3><span id="神经网络模型">神经网络模型</span></h3><p><strong>网络输入</strong>：<span class="math inline">\(14\times10\times9\)</span></p><ul><li><span class="math inline">\(10 \times 9\)</span> 是中国象棋棋盘的大小</li><li><span class="math inline">\(14\)</span> 是所有棋子种类（红/黑算不同种类）</li><li>整体的输入就是14个棋盘堆叠在一起，每个棋盘表示一种棋子的位置：棋子所在的位置为1，其余位置为0。</li></ul><p><strong>网络输出</strong></p><ul><li>策略头（policy head）输出：<span class="math inline">\(2086\)</span><ul><li><span class="math inline">\(2086\)</span> 是行动空间的大小。行动空间就是说根据中国象棋的规则，任意棋子在任意位置的走法集合。</li></ul></li><li>价值头（value head）输出：<span class="math inline">\(1\)</span><ul><li>价值头输出一个标量衡量当前局势 <span class="math inline">\(v\in[-1, 1]\)</span>：当 <span class="math inline">\(v\)</span> 接近1时，局势大好；接近0为均势；接近-1为败势。</li></ul></li></ul><p>附：棋子编号表</p><table><thead><tr class="header"><th>棋子</th><th>编号</th></tr></thead><tbody><tr class="odd"><td>兵/卒</td><td>0</td></tr><tr class="even"><td>炮</td><td>1</td></tr><tr class="odd"><td>车</td><td>2</td></tr><tr class="even"><td>马</td><td>3</td></tr><tr class="odd"><td>相/象</td><td>4</td></tr><tr class="even"><td>仕/士</td><td>5</td></tr><tr class="odd"><td>帅/将</td><td>6</td></tr></tbody></table><p><strong>网络结构</strong></p><p>网络主体是 ResNet，输出部分分出两个头，分别输出 policy 和 value。现在的架构是中间有10个残叉块（Residual Block），每个块里面有两个CNN：卷积核大小为 <span class="math inline">\(3 \times 3\)</span>，过滤器个数为192。</p><h3><span id="蒙特卡洛树搜索">蒙特卡洛树搜索</span></h3><p><img src="/images/mcts0.png"></p><p>搜索树中的每个节点都包含所有合法移动 a ∈ A(s) 的边(s，a)。 每条边存储一组统计数据， <span class="math display">\[\{N(s,a) ,W(s,a) ,Q(s,a) ,P(s,a)\}\]</span> 其中 <span class="math inline">\(N(s,a)\)</span> 是访问计数，<span class="math inline">\(W(s,a)\)</span> 是总动作价值，<span class="math inline">\(Q(s,a)\)</span> 是平均动作价值，<span class="math inline">\(P(s,a)\)</span> 是选择该边的先验概率。 多个模拟在单独的搜索线程上并行执行。</p><ol type="1"><li><p>选择</p><p>每个模拟的第一个 in-tree 阶段开始于搜索树的根节点 <span class="math inline">\(s_0\)</span>，并且在模拟时刻 L 处到达叶节点 <span class="math inline">\(s_L\)</span> 时结束。在每个这些时刻 <span class="math inline">\(t &lt; L\)</span> 处，根据搜索树中的统计量选择一个移动: <span class="math inline">\(a_t = \arg\max_a(Q(s_t,a) + U(s_t,a))\)</span>，其中 <span class="math inline">\(U(s_t,a)\)</span> 使用PUCT算法的变体得到 <span class="math display">\[U(s,a)=c_{puct}P(s,a)\frac{\sqrt{\sum_bN(s,b)}}{1+N(s,a)}\]</span> 其中 <span class="math inline">\(c_{puct}​\)</span> 是一个决定探索程度的常数; 这种搜索控制策略最初倾向于具有高先验概率和低访问次数的行为，但后期倾向于具有高动作价值的行为。</p></li><li><p>扩展和评估</p><p>叶子结点 <span class="math inline">\(s_L\)</span> 被加入到等待评估队列进行评估: <span class="math inline">\((d_i(p),v)=f_\theta(d_i(s_L))\)</span>，其中 <span class="math inline">\(d_i\)</span>是旋转或反射操作。神经网络一次评估队列里的 8 个结点;搜索进程直到评估完毕才能继续工作。每个叶子结点和每条边 <span class="math inline">\((s_L,a)\)</span> 的统计值被初始化为 <span class="math inline">\(\{N(s_L,a) = 0,W(s_L,a) = 0,Q(s_L,a) =0, P(s_L, a) = p_a\}\)</span>，然后价值 v 开始回溯。</p></li><li><p>回溯</p><p>每条边的统计值延路径反向更新：访问计数递增 <span class="math inline">\(N(s_t,𝑎_t) = N(s_t,𝑎_t) +1\)</span>，移动价值更新为平均值 <span class="math inline">\(W(s_t,a_t)=W(s_t,a_t)+v\)</span>, <span class="math inline">\(Q(s_t,a_t)=\frac{W(s_t,a_t)}{N(s_t,a_t)}\)</span>。</p></li><li><p>下棋</p><p>在搜索结束时，AlphaGo Zero 在根位置 <span class="math inline">\(s_0\)</span> 选择移动 a，与其指数访问计数成比例，<span class="math inline">\(\pi(a|s_0) = \frac{N(s_0,a)^{1/\tau}}{\sum_bN(s,b)^{1/\tau}}\)</span>，其中 <span class="math inline">\(τ\)</span> 是控制探索水平的参数。搜索树可以在后面的时刻重用：与所选择的移动对应的子节点成为新的根节点; 在这个节点下面的子树被保留以及它的所有统计数据，而树的其余部分被丢弃。</p></li></ol><h4><span id="实现细节">实现细节</span></h4><p><strong>在选择的过程中，发现当前state在history中出现过（形成循环）怎么办？</strong></p><ul><li>根据比赛规则：闲着循环3次判和；违规（长捉、长将等）判负；对方违规判胜。</li></ul><p><strong>Virtual Loss</strong></p><ul><li><p>多线程搜索时，当某一线程选择了某个action时，为了鼓励其他线程选择其他action，应该降低该action的价值（施加virtual loss）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">self.tree[state].sum_n += <span class="number">1</span></span><br><span class="line">action_state = self.tree[state].a[sel_action]</span><br><span class="line">action_state.n += virtual_loss</span><br><span class="line">action_state.w -= virtual_loss</span><br><span class="line">action_state.q = action_state.w / action_state.n</span><br></pre></td></tr></table></figure></li><li><p>在回溯时，更新value要考虑到virtual loss的影响</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">node = self.tree[state]</span><br><span class="line">action_state = node.a[action]</span><br><span class="line">action_state.n += <span class="number">1</span> - virtual_loss</span><br><span class="line">action_state.w += v + virtual_loss</span><br><span class="line">action_state.q = action_state.w / action_state.n</span><br></pre></td></tr></table></figure></li></ul><p><strong>state表示</strong></p><p>虽然对于神经网络来说state就是<span class="math inline">\(14\times10\times9\)</span>的tensor，但是对于搜索树来说，显然不能用它来表示每个局面。</p><p>在初始版本中，象棋环境（<code>environment/chessboard.py</code>）里是用数组来表示棋盘的，所以在搜索中也使用相应的数组表示state，这样做虽然没什么问题，但是在搜索的过程中需要大量的深拷贝操作（因为需要回溯），增加了许多开销。</p><p>后来版本进行了改进，使用<a href="https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation" target="_blank" rel="noopener">FEN string</a>作为state的表示，降低了拷贝操作的开销；同时也优化了象棋环境（<code>environment/static_env.py</code>），可以直接对FEN进行操作，无需记录复杂的数组。</p><blockquote><p><strong>Forsyth–Edwards Notation</strong> (<strong>FEN</strong>) is a standard <a href="https://www.wikiwand.com/en/Chess_notation" target="_blank" rel="noopener">notation</a> for describing a particular board position of a <a href="https://www.wikiwand.com/en/Chess" target="_blank" rel="noopener">chess</a> game. The purpose of FEN is to provide all the necessary information to restart a game from a particular position.</p></blockquote><h3><span id="自我博弈">自我博弈</span></h3><p>为了提高CPU/GPU利用率，这里使用了多进程，每个进程各自进行自我博弈。Python的多进程有三个实现方式：<code>fork</code>, <code>spawn</code>, <code>forkserver</code>。</p><blockquote><p>On Windows only <code>'spawn'</code> is available. On Unix <code>'fork'</code> and <code>'spawn'</code> are always supported, with <code>'fork'</code> being the default.</p></blockquote><p>由于我自己在macOS/Linux上开发和测试，所以首先实现的是基于<code>fork</code>的多进程，而当我在程序加了<code>mp.set_start_method('spawn')</code>的时候，程序就跑不了了，会报pickling error（貌似是因为传给子进程的参数里不能出现queue的数据结构），于是只能换种方式实现来绕过这个问题。</p><h2><span id="分布式">分布式</span></h2><p>起初我是没打算做成分布式的，实现完上面说述模块之后我用实验室的K80进行训练，练了几天之后发现进步并不明显，几乎还是随机下，很弱智，这是我才意识到即使把它训练到一个业余玩家的水平也需要巨大的算力。</p><p><img src="/images/issueouashd.png"></p><p>后来有一天有人在GitHub上提了一个issue说你可以把它做成分布式的，像LeelaZero那样，我们可以帮你一起训练。<a href="https://zero.sjeng.org/" target="_blank" rel="noopener">LeelaZero</a>是国外一个开发者复现AlphaGo论文搞的围棋AI，因为DeepMind并没有公开程序或代码，所以他想训练出一个公开的围棋之神，然后就邀请网友帮他一起训练，具体的方法就是：网友们在自己的机器上进行自我博弈，然后把博弈的棋谱上传到他的服务器上，然后他攒够一定棋谱之后进行训练神经网络，训练好之后分发新的权重。</p><p>在国内也有很多人帮他训练（跑谱），给我提issue的那个人也是帮LeelaZero训练中的一员。当时正好程序写完了没什么事做，每天就只能等训练结果，然后就决定尝试一下这个模式。因为之前有过Web开发的经验，所以服务器很快就搭好了，测试基本没问题之后就开始运行。</p><p><strong>架构</strong></p><p><img src="/images/architecture.png"></p><p>在维护这个项目正常运行的过程中遇到很多<strong>坑</strong>，程序也做了很多改进：</p><ol type="1"><li>首先是帮忙跑谱的大多都是象棋爱好者，并非开发者，所以我要把Python代码打包成exe文件分发给他们一键执行，最终使用<a href="https://www.pyinstaller.org/" target="_blank" rel="noopener">PyInstaller</a>打包成功，这其中遇到了很多坑：<ul><li>卸载cytoolz；pandas的版本必须为0.20.3</li><li>代码里加上<code>mp.freeze_support()</code>，否则多进程不会正常工作</li></ul></li><li>服务器带宽有限，客户端下载权重太慢，解决办法：把权重放到云存储服务中，如腾讯云/七牛云的对象存储服务。</li><li>中国象棋棋规的完善。并不是说基础的马走日象走田这种规则，而是像长将、长捉等这种比赛规则，这个算是坑最大的一个，直到现在规则还存在少许问题。</li><li>部分支持了UCI协议。这样就可以使用其他的象棋界面加载这个引擎，并且能和其他引擎对弈。</li><li>因为“同行竞争”，我的服务器在今年暑假期间我的服务器经常遭受DDos攻击，由于买不起腾讯云的高防服务，只能尝试其他办法，包括配置弹性IP、配置防火墙、Cloudfare CDN等，但都不好用。最终把服务转移到<a href="https://www.ovh.com/" target="_blank" rel="noopener">OVH</a>提供的VPS上才解决了问题（OVH提供免费的DDos防护）。</li></ol><hr><h2><span id="alphazero-and-exit">AlphaZero and ExIt</span></h2><p><a href="https://arxiv.org/abs/1705.08439" target="_blank" rel="noopener">Expert Iteration（ExIt）</a>是一种模仿学习（Imitation Learning, IL）算法，普通的 IL 算法中，徒弟模仿专家的策略只能提高自己的策略，专家是不会有任何提高的，而 ExIt 算法就是想让师傅教徒弟的时候自己也有提高。</p><p><strong>ExIt 算法</strong> 师傅根据徒弟的策略进行前向搜索（例如MCTS，alpha-beta，贪心搜索等），得出比徒弟更好的策略，然后徒弟再学习师傅的策略，如此循环，随着徒弟的增强，师傅也会越来越强。</p><p><img src="/images/exit.png"></p><p>可见，AlphaZero也属于 ExIt 算法，师傅为 MCTS，徒弟就是神经网络。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://cczero.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;中国象棋Zero（CCZero）&lt;/a&gt;是一个开源项目，把&lt;a href=&quot;https://arxiv.org/abs/1712.01815&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;AlphaZero&lt;/a&gt;的算法应用到了中国象棋上，旨在借助广大象棋爱好者之力一起训练出一个可以打败旋风名手的“象棋之神”。因为种种原因吧，这个目标到目前（2018/11/07）为止未能实现，或者说还差得远，而跑谱的人也越来越少了，很可能坚持不了多久了。&lt;/p&gt;
&lt;p&gt;虽然未能实现目标，但在技术上还是有一定意义的，&lt;a href=&quot;https://github.com/NeymarL/ChineseChess-AlphaZero&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;上也时不时有人询问技术细节，在此总结一下，记录一些坑以后不要再踩。&lt;/p&gt;
    
    </summary>
    
      <category term="博客" scheme="http://www.52coding.com.cn/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Reinforcement Learning" scheme="http://www.52coding.com.cn/tags/Reinforcement-Learning/"/>
    
      <category term="AlphaZero" scheme="http://www.52coding.com.cn/tags/AlphaZero/"/>
    
      <category term="增强学习" scheme="http://www.52coding.com.cn/tags/%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="CCZero" scheme="http://www.52coding.com.cn/tags/CCZero/"/>
    
      <category term="MCTS" scheme="http://www.52coding.com.cn/tags/MCTS/"/>
    
      <category term="中国象棋" scheme="http://www.52coding.com.cn/tags/%E4%B8%AD%E5%9B%BD%E8%B1%A1%E6%A3%8B/"/>
    
  </entry>
  
  <entry>
    <title>Hexo 搭建博客踩坑记录</title>
    <link href="http://www.52coding.com.cn/2018/11/06/%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E8%AE%B0%E5%BD%95/"/>
    <id>http://www.52coding.com.cn/2018/11/06/博客迁移记录/</id>
    <published>2018-11-06T02:41:47.000Z</published>
    <updated>2019-04-12T03:29:04.580Z</updated>
    
    <content type="html"><![CDATA[<p>博客迁移这个事早就想做了，但到现在才有时间和精力来完成。以前太年轻，写的博客系统并不方便维护，迁移的动力主要有以下几个：</p><ol type="1"><li>原博客更新、维护较麻烦。以前的博客是用<a href="https://www.52coding.com.cn/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/">PHP</a>写的，之前的写作方式是用Markdown写好导出HTML，再修改HTML代码使得静态资源（图片等）加载正确，这就使得修改博客很麻烦；更换主题也很麻烦，博客的主题和Markdown的主题通常会有冲突，所以想换个样式就要改半天CSS。</li><li>觉得UI有些难看，想要简洁一些；</li><li>安全问题。</li></ol><p>现在的解决方案是<a href="https://pages.github.com/" target="_blank" rel="noopener">Github Pages</a> + <a href="https://hexo.io/zh-cn/index.html" target="_blank" rel="noopener">Hexo</a>，主题选的是<a href="https://github.com/CodeDaraW/Hacker" target="_blank" rel="noopener">Hacker</a>，迁移了两天终于搞完了，在此简单记录一下遇到的坑。</p><a id="more"></a><h3><span id="数学公式渲染">数学公式渲染</span></h3><p>由于这款主题并不是原生支持数学公式的，所以要添加些代码来使其支持Mathjax，参考http://searene.me/2016/10/01/Let-hexo-support-mathjax/。</p><p>首先在主题的<code>layout</code>目录下新建<code>mathjax.ejs</code>，文件内容如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">%</span> <span class="attr">if</span> (<span class="attr">theme.mathjax.enable</span>)&#123; %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Config(&#123;</span></span><br><span class="line"><span class="undefined">      tex2jax: &#123;</span></span><br><span class="line"><span class="undefined">        inlineMath: [ ['$','$'], ["\\(","\\)"] ],</span></span><br><span class="line"><span class="undefined">        processEscapes: true</span></span><br><span class="line"><span class="undefined">      &#125;</span></span><br><span class="line"><span class="undefined">    &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Config(&#123;</span></span><br><span class="line"><span class="undefined">        tex2jax: &#123;</span></span><br><span class="line"><span class="undefined">          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined">      &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Queue(function() &#123;</span></span><br><span class="line"><span class="undefined">          var all = MathJax.Hub.getAllJax(), i;</span></span><br><span class="line"><span class="xml">          for(i=0; i <span class="tag">&lt; <span class="attr">all.length</span>; <span class="attr">i</span> += <span class="string">1)</span> &#123;</span></span></span><br><span class="line"><span class="undefined">              all[i].SourceElement().parentNode.className += ' has-jax';</span></span><br><span class="line"><span class="undefined">          &#125;</span></span><br><span class="line"><span class="undefined">      &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%</span> &#125; %&gt;</span></span><br></pre></td></tr></table></figure><p><strong>坑1</strong>：之前在网上查到的代码给的MathJax.js的链接多是过期的，如<code>https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML</code>，然后就被坑了。</p><p>然后在<code>layout.ejs</code>中加上<code>&lt;%- partial('mathjax') %&gt;</code>，文件整体内容为：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE HTML&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">head</span>') %&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"blog"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"content"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">header</span>') %&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">main</span> <span class="attr">class</span>=<span class="string">"site-main posts-loop"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">%-</span> <span class="attr">body</span> %&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">main</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">footer</span>') %&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">googleanalytics</span>') %&gt;</span></span><br><span class="line">      <span class="comment">&lt;!-- 新加的 --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">mathjax</span>') %&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>最后在主题的<code>_config.yml</code>中加上： <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mathjax:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>如果没有安装MathJax插件的话需要安装一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-math --save</span><br></pre></td></tr></table></figure><p>重新生成一下应该就可以渲染数学公式了。</p><p>不过还有些问题，就是你写在数学公式里的下划线(<code>_</code>)、反斜杠(<code>\</code>)、和星号(<code>*</code>)会被当作普通Markdown来处理，比如把下划线(<code>_</code>)和星号(<code>*</code>)替换成<code>&lt;em&gt;</code>标签等导致公式渲染错误。</p><p>解决方案来自https://zhuanlan.zhihu.com/p/33857596，打开<code>nodes_modules/marked/lib/marked.js</code>:</p><ol type="1"><li><p>找到下面的代码:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([\\`*&#123;&#125;\[\]()# +\-.!_&gt;])/</span>,</span><br></pre></td></tr></table></figure><p>改为：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([`*&#123;&#125;\[\]()# +\-.!_&gt;])/</span>,</span><br></pre></td></tr></table></figure></li><li><p>找到em的符号:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">em: <span class="regexp">/^\b((?:[^]|_)+?)\b|^*((?:**|[\s\S])+?)*(?!*)/</span>,</span><br></pre></td></tr></table></figure><p>改为：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">em:<span class="regexp">/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span>,</span><br></pre></td></tr></table></figure></li></ol><p>这样就去掉了<code>_</code>的斜体含义，在公式里使用<code>_</code>就没有问题了，不过要使用<code>*</code>的话要用<code>\ast</code>替代。</p><h3><span id="评论">评论</span></h3><p>Hacker这款主题支持两种评论方式，分别是<a href="https://github.com/imsun/gitment" target="_blank" rel="noopener">Gitment</a>和<a href="https://disqus.com/" target="_blank" rel="noopener">Disqus</a>。一开始试了试Gitment，配置好之后发现不能用，其原因是有一个服务过期了而作者也弃坑了没人管，我也懒得折腾就转向了Disqus，注册了之后就可以直接使用，十分方便，<strong>但是</strong>国内要翻墙才能访问。</p><p>最后换成了<a href="https://www.livere.com/" target="_blank" rel="noopener">来必力</a>评论，国内可以正常访问，虽然主题没有内置支持，但是操作很简单，只需把安装代码放到 <code>layout/components/comment.ejs</code> 里即可。</p><h3><span id="搜索">搜索</span></h3><p>主题内置不支持搜索，需要自己动手，丰衣足食。</p><p>首先安装生成搜索内容的插件： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure></p><p>然后在<code>_config.yml</code>进行如下配置： <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">search:</span></span><br><span class="line"><span class="attr">  path:</span> <span class="string">search.xml</span></span><br><span class="line"><span class="attr">  field:</span> <span class="string">post</span></span><br><span class="line"><span class="attr">  content:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>配置项具体含义参考<a href="https://www.npmjs.com/package/hexo-generator-search" target="_blank" rel="noopener">这里</a>，这个网站还说了应该怎么用这个插件来在博客中支持搜索并且给了demo，分为三步：</p><ol type="1"><li><a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/layout/_widget/search.ejs#L8" target="_blank" rel="noopener">创建搜索框</a></li><li>编写<a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/source/js/search.js" target="_blank" rel="noopener">搜索脚本</a></li><li>在 Hexo 主题中把两部分<a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/layout/_partial/after_footer.ejs#L22" target="_blank" rel="noopener">结合起来</a></li></ol><h4><span id="创建搜索框">创建搜索框</span></h4><p>我的打算是把“搜索”放在顶部，和“主页”、“目录”等一排，是一个单独的页面。所以要先创建新界面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page &quot;search&quot;</span><br></pre></td></tr></table></figure><p>修改 <code>search</code> 目录下的 <code>index.md</code>：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 搜索</span><br><span class="line">date: 2018-11-23 14:42:39</span><br><span class="line">layout: "search"</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>在主题的 <code>_config.yml</code> 中加上：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="string">搜索:</span> <span class="string">/search</span></span><br></pre></td></tr></table></figure><p>在主题的 <code>layout</code> 目录下创建 <code>search.ejs</code>：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">article</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span> <span class="attr">class</span>=<span class="string">"article-title &lt;% if (page.category)&#123; %&gt; category&lt;% &#125; else if (page.category)&#123; %&gt; category&lt;% &#125; %&gt;"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">%=</span> <span class="attr">page.title</span> || <span class="attr">config.title</span> %&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"site_search"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"form-group"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">id</span>=<span class="string">"local-search-input"</span> <span class="attr">name</span>=<span class="string">"q"</span> <span class="attr">results</span>=<span class="string">"0"</span> <span class="attr">placeholder</span>=<span class="string">"输入关键词"</span> <span class="attr">class</span>=<span class="string">"st-search-input st-default-search-input form-control"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"archive"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"local-search-result"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">article</span>&gt;</span></span><br></pre></td></tr></table></figure><p>重新build就应该可以看到“搜索”标签和搜索框了。</p><h4><span id="编写搜索脚本">编写搜索脚本</span></h4><p>在主题目录下创建<code>source/js/search.js</code>，源码照 https://github.com/wzpan/hexo-theme-freemind/blob/master/source/js/search.js 稍作修改。同时也下载jquery到<code>js</code>文件夹。</p><p>然后在 <code>layout/components/head.ejs</code>中添加：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"&lt;%- config.root %&gt;js/search.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"&lt;%- config.root %&gt;js/jquery.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h4><span id="结合">结合</span></h4><p>在 <code>layout/search.ejs</code>里添加</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    <span class="keyword">var</span> search_path = <span class="string">"&lt;%= config.search.path %&gt;"</span>;</span><br><span class="line">    <span class="keyword">if</span> (search_path.length == <span class="number">0</span>) &#123;</span><br><span class="line">        search_path = <span class="string">"search.xml"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> path = <span class="string">"&lt;%= config.root %&gt;"</span> + search_path;</span><br><span class="line">    searchFunc(path, <span class="string">'local-search-input'</span>, <span class="string">'local-search-result'</span>);</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>这样就完全实现了搜索功能！</p><h3><span id="其他">其他</span></h3><p><strong>分割线</strong></p><p>Hexo中写作不能使用<code>___</code>（三个下划线）来实现分割线，用了的话会generate失败，而且提示的错误很迷，曾经困扰了我很久。如果要用分割线的话需要四个下划线。</p><p><strong>修改网站Icon</strong></p><p>在主题中找到<code>head.ejs</code>文件，其中有一行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link href=&quot;&lt;%- config.root %&gt;favicon.ico&quot; rel=&quot;icon&quot;&gt;;</span><br></pre></td></tr></table></figure><p>按理来说只要往根目录（<code>source</code>）下放一个<code>favicon.ico</code>的文件即可。</p><p>可是我的就不行，不知道什么原因，把文件名换了就可以了，所以我改成了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link href=&quot;&lt;%- config.root %&gt;icon.png&quot; type=&quot;image/png&quot; rel=&quot;icon&quot;&gt;</span><br></pre></td></tr></table></figure><p>然后往根目录下放一个<code>icon.png</code>，解决。</p><p><strong>分享</strong></p><p>分享接口使用<a href="https://github.com/overtrue/share.js" target="_blank" rel="noopener">Share.js</a>，只需引入相应的css和js文件，照文档使用即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;博客迁移这个事早就想做了，但到现在才有时间和精力来完成。以前太年轻，写的博客系统并不方便维护，迁移的动力主要有以下几个：&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;原博客更新、维护较麻烦。以前的博客是用&lt;a href=&quot;https://www.52coding.com.cn/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/&quot;&gt;PHP&lt;/a&gt;写的，之前的写作方式是用Markdown写好导出HTML，再修改HTML代码使得静态资源（图片等）加载正确，这就使得修改博客很麻烦；更换主题也很麻烦，博客的主题和Markdown的主题通常会有冲突，所以想换个样式就要改半天CSS。&lt;/li&gt;
&lt;li&gt;觉得UI有些难看，想要简洁一些；&lt;/li&gt;
&lt;li&gt;安全问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;现在的解决方案是&lt;a href=&quot;https://pages.github.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github Pages&lt;/a&gt; + &lt;a href=&quot;https://hexo.io/zh-cn/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;，主题选的是&lt;a href=&quot;https://github.com/CodeDaraW/Hacker&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hacker&lt;/a&gt;，迁移了两天终于搞完了，在此简单记录一下遇到的坑。&lt;/p&gt;
    
    </summary>
    
      <category term="博客" scheme="http://www.52coding.com.cn/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Mathjax" scheme="http://www.52coding.com.cn/tags/Mathjax/"/>
    
      <category term="Hexo" scheme="http://www.52coding.com.cn/tags/Hexo/"/>
    
      <category term="Disqus" scheme="http://www.52coding.com.cn/tags/Disqus/"/>
    
      <category term="Gitment" scheme="http://www.52coding.com.cn/tags/Gitment/"/>
    
      <category term="Github Pages" scheme="http://www.52coding.com.cn/tags/Github-Pages/"/>
    
  </entry>
  
  <entry>
    <title>Microeconomics - Interdependence and the Gains from Trade</title>
    <link href="http://www.52coding.com.cn/2018/11/03/Interdependence%20and%20the%20Gains%20from%20Trade/"/>
    <id>http://www.52coding.com.cn/2018/11/03/Interdependence and the Gains from Trade/</id>
    <published>2018-11-03T12:10:47.000Z</published>
    <updated>2019-04-12T07:10:13.716Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#a-parable-for-the-modern-economy">A Parable for the Modern Economy</a><ul><li><a href="#production-possibilities">Production Possibilities</a></li><li><a href="#specialization-and-trade">Specialization and Trade</a></li></ul></li><li><a href="#comparative-advance-the-driving-force-of-specialization">Comparative Advance: The Driving Force of Specialization</a><ul><li><a href="#absolute-advantage">Absolute Advantage</a></li><li><a href="#opportunity-cost-and-comparative-advantage">Opportunity Cost and Comparative Advantage</a></li><li><a href="#comparative-advantage-and-trade">Comparative Advantage and Trade</a></li><li><a href="#the-price-and-the-trade">The Price and The Trade</a></li></ul></li><li><a href="#applications-of-comparative-advantage">Applications of Comparative Advantage</a><ul><li><a href="#should-tiger-woods-mow-his-own-lawn">Should Tiger Woods Mow His Own Lawn?</a></li><li><a href="#should-the-united-states-trade-with-other-countries">Should the United States Trade With Other Countries?</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="a-parable-for-the-modern-economy">A Parable for the Modern Economy</span></h2><h3><span id="production-possibilities">Production Possibilities</span></h3><p>The graph shows the various mixes of output that an economy can produce and illustrate that people face trade-offs.</p><p><img src="/images/IMG_CBD807794C2B-1.png"> If the farmer and rancher do not trade, the production possibilities frontier is also the consumption possibilities frontier. However, the frontier shows trade-offs but do not show what they will choose to do. So let’s suppose the choose the combinations identified in the graph by points A and B.</p><h3><span id="specialization-and-trade">Specialization and Trade</span></h3><p><img src="/images/IMG_FA9EF67DD902-1.png"> The farmer and rancher can both benefit because trade allows each of them to specialize in doing what they do best. The farmer will spend more time growing potatoes and less time raising cattle. The rancher will spend more time raising cattle and less time growing potatoes. As a result of specialization and trade, each of them can consume more meat and more potatoes without working any more hours.</p><h2><span id="comparative-advance-the-driving-force-of-specialization">Comparative Advance: The Driving Force of Specialization</span></h2><p>The puzzle is why the rancher does better in both fields, he still gain from trade? To solve this puzzle, we should answer first who has a lower cost to produce potatoes?</p><h3><span id="absolute-advantage">Absolute Advantage</span></h3><p>We can measure the cost through <em>absolute advantage</em> which is the ability to produce a good using fewer inputs than another producer. In our example, the only input is time. Because the rancher need fewer time to produce both items, he has the absolute advantage in producing both goods. Base on this the rancher has a lower cost to produce potatoes.</p><h3><span id="opportunity-cost-and-comparative-advantage">Opportunity Cost and Comparative Advantage</span></h3><p>Recall the <em>opportunity cost</em> is whatever must be given up to obtain some item. In our example, the opportunity cost of the rancher to produce 1 ounce potatoes is 1/2 ounce meat and the opportunity cost of him to produce 1 ounce meat is 2 ounce potatoes. Similarly, we can compute the opportunity cost for farmer which summarize in table 1. <img src="/images/IMG_857CB49E31D3-1.png"></p><p>We can also measure the cost through <em>comparative advantage</em>, which is the ability to produce a good at a lower opportunity cost than another producer. Through table 1 we can find out that farmer has comparative advantage in producing potatoes and rancher has comparative advantage in producing meat. That’s why the rancher can gain from trade.</p><p>Although it is possible for one person to have an absolute advantage in both goods, it is impossible for one to have a comparative advantage in both goods. Because the opportunity cost of one good is inverse of the opportunity cost of the other.</p><h3><span id="comparative-advantage-and-trade">Comparative Advantage and Trade</span></h3><p>The gains from specialization and trade based on comparative advantage. By specialization in what he has a comparative advantage, the total production of the society raises which means increase the size of economic pie.</p><p>Also, the price of the goods should lower than their opportunity cost of producing it. For example, the farmer exchange 15 ounce potatoes for 5 ounce meat. The price of meat for the farmer is 3 ounce potatoes which is lower than his opportunity cost of producing meat (4 ounce potatoes). Similarly, for the rancher, the price of 1 ounce potatoes is 1/3 ounce meat which is also lower than his opportunity cost of producing potatoes (1/2 ounce meat).</p><p>Conclude: <strong>Trade can benefit everyone in society because it allows people to specialize in activities in which they have a comparative advantage</strong>.</p><h3><span id="the-price-and-the-trade">The Price and The Trade</span></h3><p><strong>For both parties to gain from trade, the price at which they trade must lie between the two opportunity costs</strong>.</p><h2><span id="applications-of-comparative-advantage">Applications of Comparative Advantage</span></h2><h3><span id="should-tiger-woods-mow-his-own-lawn">Should Tiger Woods Mow His Own Lawn?</span></h3><p>Say Tiger Woods can mow his own lawn in 2 hours while, Forrest, the boy next door, can mow the lawn in 4 hours. Should Tiger Woods mow his own lawn?</p><p>Clearly, Tiger Woods has an absolute advantage in mowing the lawn but he has a higher opportunity cost in doing it because he could spend 2 hours filming a commercial advertisement earning $10000 while Forrest can only earn $20 in 4 hours. So Tiger should hire Forrest to mow the lawn and both of them will better off as long as the payment is between $20 and $10000.</p><h3><span id="should-the-united-states-trade-with-other-countries">Should the United States Trade With Other Countries?</span></h3><p>International trade can make some individuals worse off, even as it makes the country as a whole better off. When the US exports food and imports cars, the impact on an American farmer is not the same as the impact on an American autoworker. Yet, international trade is not like war, in which some countries win and others lose. <em>Trade allows all countries to achieve greater prosperity</em>.</p><h2><span id="summary">Summary</span></h2><ul><li>Each person consumes goods and services produced by many other people both in the United States and around the world. Interdependence and trade are desirable because they allow everyone to enjoy a greater <strong>quantity and variety</strong> of goods and services.</li><li>There are two ways to compare the ability of two people in producing a good. The person who can produce the good with the smaller quantity of inputs is said to have an <em>absolute advantage</em> in producing the good. The person who has the smaller <em>opportunity cost</em> of producing the good is said to have a <em>comparative advantage</em>. The gains from trade are based on comparative advantage, not absolute advantage.</li><li>Trade makes everyone better off because it allows people to specialize in those activities in which they have a comparative advantage.</li><li>The principle of comparative advantage applies to countries as well as to people. Economists use the principle of comparative advantage to advocate free trade among countries.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#a-parable-for-the-modern-economy&quot;&gt;A Parable for the Modern Economy&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#production-possibilities&quot;&gt;Production Possibilities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#specialization-and-trade&quot;&gt;Specialization and Trade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#comparative-advance-the-driving-force-of-specialization&quot;&gt;Comparative Advance: The Driving Force of Specialization&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#absolute-advantage&quot;&gt;Absolute Advantage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#opportunity-cost-and-comparative-advantage&quot;&gt;Opportunity Cost and Comparative Advantage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#comparative-advantage-and-trade&quot;&gt;Comparative Advantage and Trade&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-price-and-the-trade&quot;&gt;The Price and The Trade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#applications-of-comparative-advantage&quot;&gt;Applications of Comparative Advantage&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#should-tiger-woods-mow-his-own-lawn&quot;&gt;Should Tiger Woods Mow His Own Lawn?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#should-the-united-states-trade-with-other-countries&quot;&gt;Should the United States Trade With Other Countries?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#summary&quot;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="微观经济型原理" scheme="http://www.52coding.com.cn/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%9E%8B%E5%8E%9F%E7%90%86/"/>
    
      <category term="trade" scheme="http://www.52coding.com.cn/tags/trade/"/>
    
      <category term="comparative advantage" scheme="http://www.52coding.com.cn/tags/comparative-advantage/"/>
    
  </entry>
  
  <entry>
    <title>Unity学习笔记</title>
    <link href="http://www.52coding.com.cn/2018/11/01/Unity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.52coding.com.cn/2018/11/01/Unity学习笔记/</id>
    <published>2018-11-01T02:41:47.000Z</published>
    <updated>2019-04-12T03:28:34.868Z</updated>
    
    <content type="html"><![CDATA[<p><strong>记录一些小功能的实现</strong></p><!-- toc --><ul><li><a href="#实现相机跟随">实现相机跟随</a></li><li><a href="#拖动图标在场景生成物体">拖动图标在场景生成物体</a></li><li><a href="#技能冷却效果">技能冷却效果</a></li><li><a href="#鼠标点击选中场景中的物体">鼠标点击选中场景中的物体</a></li><li><a href="#2d人物朝左朝右">2D人物朝左朝右</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="实现相机跟随">实现相机跟随</span></h2><ul><li>方法一<ul><li>把相机设置为目标的Child</li></ul></li><li>方法二<ul><li>设置好距目标的距离和角度，根据数学关系计算出相机位置</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">float distance = 15;// 距离</span><br><span class="line">float rot = 0;// 横向角度</span><br><span class="line">GameObject target;// 目标物体</span><br><span class="line">float roll = 30f * Mathf.PI * 2 / 360; // 纵向角度</span><br><span class="line"></span><br><span class="line">void LateUpdate () &#123;</span><br><span class="line">Vector3 targetPos = target.transform.position;</span><br><span class="line">Vector3 cameraPos;</span><br><span class="line">float d = distance * Mathf.Cos (roll);</span><br><span class="line">float height = distance * Mathf.Sin (roll);</span><br><span class="line">cameraPos.x = targetPos.x + d * Mathf.Cos (rot);</span><br><span class="line">cameraPos.z = targetPos.z + d * Mathf.Sin (rot);</span><br><span class="line">cameraPos.y = targetPos.y + height;</span><br><span class="line">Camera.main.transform.position = cameraPos;</span><br><span class="line">Camera.main.transform.LookAt (target.transform);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>相机随鼠标旋转</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">void Rotate()</span><br><span class="line">&#123;</span><br><span class="line"> float w = Input.GetAxis (&quot;Mouse X&quot;) * rotSpeed;</span><br><span class="line">rot -= w;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Roll()</span><br><span class="line">&#123;</span><br><span class="line">float w = Input.GetAxis (&quot;Mouse Y&quot;) * rollSpeed * 0.5f;</span><br><span class="line">roll -= w;</span><br><span class="line">if (roll &gt; maxRoll) &#123;</span><br><span class="line">roll = maxRoll;</span><br><span class="line">&#125;</span><br><span class="line">if (roll &lt; minRoll) &#123;</span><br><span class="line">roll = minRoll;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void LateUpdate () &#123;</span><br><span class="line">Rotate();</span><br><span class="line">  Roll();</span><br><span class="line">....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="拖动图标在场景生成物体">拖动图标在场景生成物体</span></h2><p><strong>拖动UI</strong></p><p>新建<code>Drag</code>类，继承<code>IBeginDragHandler, IDragHandler, IEndDragHandler</code>，实现拖动UI功能有三个接口：</p><ul><li><code>public void OnBeginDrag (PointerEventData eventData)</code></li><li><code>public void OnDrag (PointerEventData eventData)</code></li><li><code>public void OnEndDrag (PointerEventData eventData)</code></li></ul><p>在<code>Drag</code>类里实现这三个接口即可实现想要的拖动效果，最后不用忘了把<code>Drag</code>脚本添加到想要被拖动的UI物体上。</p><p><strong>在场景中生成物体</strong></p><p>要实现这个功能:</p><ul><li>首先在<code>OnBeginDrag</code>中生成新的<code>GameObject</code>；</li><li>然后在<code>OnDrag</code>中，根据鼠标在场景里的位置调整<code>GameObject</code>的位置，再检测<code>GameObject</code>的collider有无和其他物体碰撞；</li><li>最后在<code>OnEndDrag</code>中，如果<code>GameObject</code>的最终位置合法，则不再移动；否则销毁物体，生成失败。</li></ul><h2><span id="技能冷却效果">技能冷却效果</span></h2><p><strong>定时器</strong></p><p>实现冷却效果计时器必不可少，实现方法也很简单，只需两个变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bool timerStarted = false;</span><br><span class="line">float remain = 10f;</span><br></pre></td></tr></table></figure><p>然后在<code>Update</code>中作如下更新：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">void Update ()</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    if (timerStarted) &#123;</span><br><span class="line">remain -= Time.deltaTime;</span><br><span class="line">        if (remain &lt;= 0) &#123;</span><br><span class="line">            CloseTimer();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>UI效果</strong></p><p>Button的层次如下：</p><ul><li><p><code>Button</code></p><ul><li><p><code>Image</code>：按钮显示的图标</p></li><li><p><code>Mask</code>：可以用按钮的默认背景；调整颜色和透明度；ImageType为filled；通过调整Fill Amount来实现转动效果</p><p><img src="/images/Screen%20Shot%202018-10-30%20at%204.09.00%20PM.png"></p></li><li><p><code>CD Text</code>：显示剩余冷却时间</p></li></ul></li></ul><p><strong>Note</strong>：在开始冷却的同时，应把设置<code>btn.interactable = false;</code>，否则按钮可以在冷却过程中再次被点击。</p><p>这里Button的<code>OnClick</code>绑定了两个函数，分别给<code>CharacterController</code>实现技能效果，和给<code>UIManager</code>实现UI动效：</p><p><img src="/images/btnclick.png"></p><h2><span id="鼠标点击选中场景中的物体">鼠标点击选中场景中的物体</span></h2><p>思路：从点击位置向场景发射射线，检测是否击中物体</p><p>实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">void MousePick () &#123;</span><br><span class="line">    if (Input.GetMouseButtonUp (0)) &#123;</span><br><span class="line">        // 发射射线</span><br><span class="line">        Ray myRay = Camera.main.ScreenPointToRay (Input.mousePosition);</span><br><span class="line">        // 选择想被选中的layer</span><br><span class="line">        int layerMask = LayerMask.GetMask (&quot;Building&quot;);</span><br><span class="line">        // 检测碰撞</span><br><span class="line">        RaycastHit2D hit = Physics2D.Raycast (new Vector2 (myRay.origin.x, myRay.origin.y),</span><br><span class="line">            Vector2.down, Mathf.Infinity, layerMask);</span><br><span class="line">        if (hit.collider) &#123;</span><br><span class="line">            // 检测到碰撞，选中该物体</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="2d人物朝左朝右">2D人物朝左朝右</span></h2><p>思路：如果原sprite朝右，那么只要把transform的<code>scale.x</code>变成<code>-1</code>就是朝左了。</p><p><img src="/images/facingside.png"></p><p>实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">void LateUpdate () &#123;</span><br><span class="line">    Vector3 localScale = _transform.localScale;</span><br><span class="line"></span><br><span class="line">    if (_vx &gt; 0) &#123; // moving right so face right</span><br><span class="line">        _facingRight = true;</span><br><span class="line">    &#125; else if (_vx &lt; 0) &#123; // moving left so face left</span><br><span class="line">        _facingRight = false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // check to see if scale x is right for the player</span><br><span class="line">    // if not, multiple by -1 which is an easy way to flip a sprite</span><br><span class="line">    if ((_facingRight) &amp;&amp; (localScale.x &lt; 0) || </span><br><span class="line">        ((localScale.x &gt; 0)) &#123;</span><br><span class="line">        localScale.x *= -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // update the scale</span><br><span class="line">    _transform.localScale = localScale;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>未完待续</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;记录一些小功能的实现&lt;/strong&gt;&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#实现相机跟随&quot;&gt;实现相机跟随&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#拖动图标在场景生成物体&quot;&gt;拖动图标在场景生成物体&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#技能冷却效果&quot;&gt;技能冷却效果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#鼠标点击选中场景中的物体&quot;&gt;鼠标点击选中场景中的物体&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#2d人物朝左朝右&quot;&gt;2D人物朝左朝右&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Unity" scheme="http://www.52coding.com.cn/tags/Unity/"/>
    
      <category term="C#" scheme="http://www.52coding.com.cn/tags/C/"/>
    
      <category term="Game Dev" scheme="http://www.52coding.com.cn/tags/Game-Dev/"/>
    
  </entry>
  
  <entry>
    <title>Microeconomics - Thinking Like an Economist</title>
    <link href="http://www.52coding.com.cn/2018/10/03/Thinking%20Like%20an%20Economist/"/>
    <id>http://www.52coding.com.cn/2018/10/03/Thinking Like an Economist/</id>
    <published>2018-10-03T12:10:47.000Z</published>
    <updated>2019-04-12T07:10:42.172Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#the-economist-as-scientist">The Economist as Scientist</a><ul><li><a href="#the-scientific-method-observation-theory-and-more-observation">The Scientific Method: Observation, Theory, and More Observation</a></li><li><a href="#the-role-of-assumptions">The Role of Assumptions</a></li><li><a href="#economic-models">Economic Models</a></li><li><a href="#our-first-model-the-circular-flow-diagram">Our First Model: The Circular-Flow Diagram</a></li><li><a href="#our-second-model-the-production-possibilities-frontier">Our Second Model: The Production Possibilities Frontier</a></li><li><a href="#microeconomics-and-macroeconomics">Microeconomics and Macroeconomics</a></li></ul></li><li><a href="#the-economist-as-policy-adviser">The Economist as Policy Adviser</a><ul><li><a href="#positive-versus-normative-analysis">Positive versus Normative Analysis</a></li><li><a href="#economists-in-washington">Economists in Washington</a></li><li><a href="#why-economists-advice-is-not-always-followed">Why Economists’ Advice Is Not Always Followed</a></li></ul></li><li><a href="#why-economists-disagree">Why Economists Disagree</a><ul><li><a href="#differences-in-scientific-judgments">Differences in Scientific Judgments</a></li><li><a href="#difference-in-values">Difference in Values</a></li><li><a href="#perception-versus-reality">Perception versus Reality</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="the-economist-as-scientist">The Economist as Scientist</span></h2><h3><span id="the-scientific-method-observation-theory-and-more-observation">The Scientific Method: Observation, Theory, and More Observation</span></h3><p>Invention an economic theory is just like in other scientific fields, which is <em>observation, summary to a theory and then collect data to test it</em>. However, it is often <em>difficult or impossible</em> for economists to <em>collect data</em> because you cannot change policies just for experiments. <strong>Therefore, economists often pay attention to the natural experiments offered by history</strong> which can not only give insight into the economy of the past, but also allow to illustrate and evaluate economic theories of the present.</p><h3><span id="the-role-of-assumptions">The Role of Assumptions</span></h3><p><strong>Make assumptions can simplify the question.</strong> e.g. once we understood the international trade in the simplified imaginary world, we are in a better position to understand international trader in the more complex world.</p><p>Also, the art in scientific thinking is <strong>deciding which assumptions to make</strong>. e.g. study short-run effect or long-run effect make different assumptions.</p><h3><span id="economic-models">Economic Models</span></h3><p>Economic models composed with graphs and equations which omit a lot of details to emphases the essence of economy. Each economic models make assumptions to simplify reality so as to improve our understanding of it.</p><h3><span id="our-first-model-the-circular-flow-diagram">Our First Model: The Circular-Flow Diagram</span></h3><p><img src="/images/IMG_9A38B6F35EC5-1.jpeg.jpg"></p><p>e.g. money in your wallet -&gt; buy coffee in markets for goods and services (local Starbucks) -&gt; revenue of the company -&gt; pay rental or wage -&gt; someone’s wallet</p><p>Because of its simplicity, this circular-flow diagram is useful to keep in mind when thinking about <strong>how the pieces of the economy fit together</strong>.</p><h3><span id="our-second-model-the-production-possibilities-frontier">Our Second Model: The Production Possibilities Frontier</span></h3><p><img src="/images/IMG_2122EF5B828A-1.jpeg.jpg"> The production possibilities frontier shows the <em>efficiency</em> of the society. Because resources are <em>scarce</em>, not every conceivable outcome is feasible. Points <strong>on</strong> the production possibilities frontier represent <em>efficient levels</em> of production.</p><p>It also reveals <em>trade-off</em> and <em>opportunity costs</em>: if produce more computers, means have to produce less cars. The <em>opportunity cost</em> is measured by the <strong>slope</strong> of the production possibilities frontier, which means point F’s opportunity cost of a car is lower and point E’ opportunity cost of producing a car is higher. That’s because when at point E, the society has let all of car engineers to produce cars. Producing one more car means moving some of the best computer technicians out of the computer industry and making them autoworkers.</p><p>The production possibilities frontier also change with time, which shows <em>economic growth</em>. <img src="/images/IMG_0EA219852402-1.jpeg.jpg"></p><h3><span id="microeconomics-and-macroeconomics">Microeconomics and Macroeconomics</span></h3><p>Economics is studied on various levels, which is traditionally divided into two broad subfields:</p><ul><li><strong>Microeconomics</strong> is the study of how households and firms make decisions and how they interact in specific markets.</li><li><strong>Macroeconomics</strong> is the study of economy-wide phenomena, including inflation, unemployment, and economic growth.</li></ul><h2><span id="the-economist-as-policy-adviser">The Economist as Policy Adviser</span></h2><h3><span id="positive-versus-normative-analysis">Positive versus Normative Analysis</span></h3><p><strong>positive statements</strong>: claims that attempt to describe the world as it is <strong>normative statements</strong>: claims that attempt to prescribe how the world should be</p><p>Normative statements comes from positive statements as well as value judgements. Deciding what is good or bad policy is not just a matter of science. It also involves our views on ethics, religion, and political philosophy.</p><h3><span id="economists-in-washington">Economists in Washington</span></h3><p>Economists in Whitehouse also face trade-offs. The influence of economists on policy goes beyond their role as advisers: Their research and writings often affect policy indirectly.</p><h3><span id="why-economists-advice-is-not-always-followed">Why Economists’ Advice Is Not Always Followed</span></h3><p>Economists offer crucial input into the policy process, but their advice is only one ingredient of a complex recipe.</p><h2><span id="why-economists-disagree">Why Economists Disagree</span></h2><h3><span id="differences-in-scientific-judgments">Differences in Scientific Judgments</span></h3><p><strong>Economic is a young science and there is still much to be learned.</strong> They disagree because they have different hunches about the validity of alternative theories or about the size of important parameters that measure how economic variables are related.</p><h3><span id="difference-in-values">Difference in Values</span></h3><p>Economists give conflicting advice sometimes because they have different values.</p><h3><span id="perception-versus-reality">Perception versus Reality</span></h3><p>Why do policies such as rent control persist if the experts are united in their opposition? It may be that the realities of the <strong>political process</strong> stand as immovable obstacles. But it also may be that economists have <strong>not yet convinced</strong> enough of the public that these policies are undesirable.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-economist-as-scientist&quot;&gt;The Economist as Scientist&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#the-scientific-method-observation-theory-and-more-observation&quot;&gt;The Scientific Method: Observation, Theory, and More Observation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-role-of-assumptions&quot;&gt;The Role of Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#economic-models&quot;&gt;Economic Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#our-first-model-the-circular-flow-diagram&quot;&gt;Our First Model: The Circular-Flow Diagram&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#our-second-model-the-production-possibilities-frontier&quot;&gt;Our Second Model: The Production Possibilities Frontier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#microeconomics-and-macroeconomics&quot;&gt;Microeconomics and Macroeconomics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-economist-as-policy-adviser&quot;&gt;The Economist as Policy Adviser&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#positive-versus-normative-analysis&quot;&gt;Positive versus Normative Analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#economists-in-washington&quot;&gt;Economists in Washington&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#why-economists-advice-is-not-always-followed&quot;&gt;Why Economists’ Advice Is Not Always Followed&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#why-economists-disagree&quot;&gt;Why Economists Disagree&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#differences-in-scientific-judgments&quot;&gt;Differences in Scientific Judgments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#difference-in-values&quot;&gt;Difference in Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#perception-versus-reality&quot;&gt;Perception versus Reality&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="微观经济型原理" scheme="http://www.52coding.com.cn/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%9E%8B%E5%8E%9F%E7%90%86/"/>
    
      <category term="Production Possibilities Frontier" scheme="http://www.52coding.com.cn/tags/Production-Possibilities-Frontier/"/>
    
  </entry>
  
  <entry>
    <title>Microeconomics - Ten Principles of Economics</title>
    <link href="http://www.52coding.com.cn/2018/09/16/Chapter%201-%20Ten%20Principles%20of%20Economics/"/>
    <id>http://www.52coding.com.cn/2018/09/16/Chapter 1- Ten Principles of Economics/</id>
    <published>2018-09-16T02:41:47.000Z</published>
    <updated>2019-04-12T07:09:42.722Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#how-people-make-decisions">How People Make Decisions</a><ul><li><a href="#principle-1-people-face-trade-offs">Principle 1: People Face Trade-offs</a></li><li><a href="#principle-2-the-cost-of-something-is-what-you-give-up-to-get-it">Principle 2: The Cost of Something Is What You Give Up to Get It</a></li><li><a href="#principle-3-rational-people-think-at-the-margin">Principle 3: Rational People Think at the Margin</a></li><li><a href="#principle-4-people-respond-to-incentives">Principle 4: People Respond to Incentives</a></li></ul></li><li><a href="#how-people-interact">How People Interact</a><ul><li><a href="#principle-5-trade-can-make-everyone-better-off">Principle 5: Trade Can Make Everyone Better Off</a></li><li><a href="#principle-6-markets-are-usually-a-good-way-to-organize-economic-activity">Principle 6: Markets Are Usually a Good Way to Organize Economic Activity</a></li><li><a href="#principle-7-governments-can-sometimes-improve-market-outcomes">Principle 7: Governments Can Sometimes Improve Market Outcomes</a></li></ul></li><li><a href="#how-the-economy-as-a-whole-works">How the Economy as a Whole Works</a><ul><li><a href="#principle-8-a-countrys-standard-of-living-depends-on-its-ability-to-produce-goods-and-services">Principle 8: A Country’s Standard of Living Depends on Its Ability to Produce Goods and Services</a></li><li><a href="#principle-9-prices-rise-when-the-government-prints-too-much-money">Principle 9: Prices Rise When the Government Prints Too Much Money</a></li><li><a href="#principle-10-society-faces-a-short-run-trade-off-between-inflation-and-unemployment">Principle 10: Society Faces a Short-Run Trade-off between Inflation and Unemployment</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="how-people-make-decisions">How People Make Decisions</span></h2><p><strong>scarcity</strong>: the limited nature of society’s resources <strong>economics</strong>: the study of how society manages its <em>scarce</em> resources</p><h3><span id="principle-1-people-face-trade-offs">Principle 1: People Face Trade-offs</span></h3><p>To get one thing we like, we usually have to give up another thing that we like. <strong>Making decisions</strong> requires trading-off one goal against another.</p><ul><li>student cannot learn two or more things at the same time</li><li>how to spend family income</li><li>guns (defense) and butter (living conditions)</li></ul><p><strong>Efficiency</strong> and <strong> Equality</strong></p><ul><li><em>Efficiency</em> means the property of society getting the most it can from its scarce resources.</li><li><em>Equality</em> means the property of distributing economic prosperity uniformly among the members of society.</li><li>In other words, <em>efficiency</em> refers to the size of the economic pie, and <em>equality</em> refers to how the pie is divided into individual slices.</li><li>When government tries to cut the economic pie into more equal slices, the pie get smaller.</li></ul><p>Nonetheless, people are likely to make good decisions only if they understand the options they have available. Our study of economics, therefore, starts by acknowledging life’s trade-offs.</p><h3><span id="principle-2-the-cost-of-something-is-what-you-give-up-to-get-it">Principle 2: The Cost of Something Is What You Give Up to Get It</span></h3><p><strong>Opportunity cost</strong>: whatever must be given up to obtain some item. When making any decision, decision makers should be aware of the opportunity costs that accompany each possible action.</p><h3><span id="principle-3-rational-people-think-at-the-margin">Principle 3: Rational People Think at the Margin</span></h3><p><strong>Rational people</strong> systematically and purposefully do the best they can to achieve their objectives, given the available opportunities. <strong> Marginal change</strong>: a small incremental adjustment to a plan of action. e.g. when exam around, study one more hour instead of playing games.</p><p>Rational people often make decisions by comparing <em>marginal benefits</em> and <em>marginal costs</em>.</p><ul><li>airline ticket</li><li>why is water so cheap, while diamonds are so expensive?<ul><li>water is plentiful -&gt; margin benefit is small</li><li>diamonds are so rare -&gt; margin benefit is large A rational decision maker takes an action if and only if the <em>marginal benefit</em> of the action <strong>exceeds</strong> the <em>marginal cost</em>.</li></ul></li></ul><h3><span id="principle-4-people-respond-to-incentives">Principle 4: People Respond to Incentives</span></h3><p>An <strong>incentive</strong> is something that induces a person to act, such as the prospect of a punishment or a reward. <em>People respond to incentives, the rest is commentary.</em></p><p>Auto safety</p><ul><li>1950s, no seat belt, accident is costly -&gt; seat belt law -&gt; accident is not that costly -&gt; people drive faster (cost less time) -&gt; few deaths per accident but more accidents -&gt; little change in driver deaths and an increase in the number of pedestrian deaths.</li></ul><p>When analyzing any policy, we must consider not only the direct effects but also the less obvious indirect effects that work through incentives. If the policy changes incentives, it will cause people to alter their behavior.</p><p><em>Incentive Pay</em> Chicago buses do not take the shortcut when around congestion, because they have no incentive to do so. If they are paid by passengers like taxi rather than by bus company, they will choose the shortcuts to get more passengers like other cars do. It will increase the bus driver’s productivity but also increase the risk of having accidents.</p><h2><span id="how-people-interact">How People Interact</span></h2><h3><span id="principle-5-trade-can-make-everyone-better-off">Principle 5: Trade Can Make Everyone Better Off</span></h3><p><strong>Trade</strong> between two countries is not like a sports contest in which one side wins and the other side loses. In fact, the opposite is true: <em>Trade between two countries can make each country better off</em>.</p><p>Trade allows countries to specialize in what they do best and to enjoy a greater variety of goods and services.</p><h3><span id="principle-6-markets-are-usually-a-good-way-to-organize-economic-activity">Principle 6: Markets Are Usually a Good Way to Organize Economic Activity</span></h3><p><em>Communist</em> countries worked on the premise that government officials were in the best position to allocate the economy’s scarce resources. The theory behind <em>central planning</em> was that only the government could organize economic activity in a way that promoted <em>economic well-being for the country as a whole</em>. <em>Central planners</em> failed because they tried to run the economy with one hand tied behind their backs — the invisible hand of the marketplace.</p><p>In a <strong>market economy</strong>, the decisions of a central planner are replaced by the decisions of millions of firms and households.</p><blockquote><p>Households and firms interacting in markets act as if they are guided by an “invisible hand” that leads them to desirable market outcomes. — Adam Smith</p></blockquote><p>In any market, buyers look at the price when determining how much to demand, and sellers look at the price when deciding how much to supply. As a result of the decisions that buyers and sellers make, <em>market prices</em> reflect both <em>the value of a good to society</em> and <em>the cost to society of making the good</em>. Smith’s great insight was that <strong>prices</strong> adjust to <strong>guide</strong> these individual buyers and sellers to reach outcomes that, in many cases, <em>maximize the well-being of society as a whole</em>.</p><h3><span id="principle-7-governments-can-sometimes-improve-market-outcomes">Principle 7: Governments Can Sometimes Improve Market Outcomes</span></h3><p><strong>property right</strong>: the ability of an individual to own and exercise control over scarce resources. <strong>market failure</strong>: a situation in which a market left on its own fails to allocate resources efficiently. <strong>externality</strong>: the impact of one person’s actions on the well-being of a bystander. <strong>market power</strong>: the ability of a single economic actor (or a small group of actors) to have a substantial influence on market prices.</p><p><em>The invisible hand is powerful, but it is not omnipotent.</em> The economy needs the government to</p><ul><li>enforce the rules and maintain the institutions that are key to a market economy</li><li>enforce <strong>property right</strong><ul><li>We all rely on government-provided police and courts to enforce our rights over the things we produce — and the <em>invisible hand</em> counts on our ability to enforce our rights.</li></ul></li><li>promote <strong>efficiency</strong><ul><li><em>market failure</em> because <strong>externality</strong> (e.g. pollution) and <strong>market power</strong> (e.g. monopoly)</li></ul></li><li>promote <strong>equality</strong></li></ul><h2><span id="how-the-economy-as-a-whole-works">How the Economy as a Whole Works</span></h2><h3><span id="principle-8-a-countrys-standard-of-living-depends-on-its-ability-to-produce-goods-and-services">Principle 8: A Country’s Standard of Living Depends on Its Ability to Produce Goods and Services</span></h3><p>Why the differences in living standards among countries and over time are so large? Almost all variation in living standards is attributable to differences in countries’ <strong>productivity</strong> — that is, the amount of goods and services produced from each unit of labor input. When thinking about how any policy will affect our living standards, the key question is <em>how it will affect our ability to produce goods and services</em>.</p><h3><span id="principle-9-prices-rise-when-the-government-prints-too-much-money">Principle 9: Prices Rise When the Government Prints Too Much Money</span></h3><p><strong>inflation</strong>: an increase in the overall level of prices in the economy</p><p>What cause inflation? In almost all cases of large or persistent inflation, the culprit is <em>growth in the quantity of money</em>.</p><blockquote><p>The broken window fallacy Some teenagers, being the little beasts that they are, toss a brick through a bakery window. A crown gathers and laments, “What a shame”. But before you know it, someone suggests a silver lining to the situation: Now the baker will have to spend money to have the window repaired. This will add to the income of the repairman, who will spend his additional income, which will add to another seller’s income, and so on. The chain of spending will multiply and generate higher income and employment. If the broken window is large enough, it might produce an economic boom! But if the baker hadn’t spent his money on window repair, he would have spent it on the new suit he was saving to buy. Then the tailor would have the new income to spend, and so on. <em>The broken window didn’t create new spending; it just diverted spending from somewhere else.</em></p></blockquote><h3><span id="principle-10-society-faces-a-short-run-trade-off-between-inflation-and-unemployment">Principle 10: Society Faces a Short-Run Trade-off between Inflation and Unemployment</span></h3><p>Short-run effects of monetary injections as follows:</p><ul><li>Increasing the amount of money in the economy stimulates the overall level of spending and thus the demand for goods and services</li><li>Higher demand many over time cause firms to raise their prices, but in the meantime, it also encourage them to hire more workers and produce a larger quantity of goods and services.</li><li>More hiring means lower unemployment.</li></ul><p><strong>business cycle</strong>: fluctuations in economic activity, such as employment and production.</p><p>Case: 2008 deep economic downturn -&gt; Barack Obama: <em>stimulus package of reduced taxes and increased government spending</em> -&gt; Federal Reserve: <em>increased the supply of money</em> -&gt; <strong>reduce unemployment</strong> -&gt; might over time lead to an <strong>excessive level of inflation</strong>.</p><h2><span id="summary">Summary</span></h2><ol type="1"><li>The fundamental lessons about individual decision making are that people face trade-offs among alternative goals, that the cost of any action is measured in terms of forgone opportunities, that rational people make decisions by comparing marginal costs and marginal benefits, and that people change their behavior in response to the incentives they face.</li><li>The fundamental lessons about interactions among people are that trade and interdependence can be mutually beneficial, that markets are usually a good way of coordinating economic activity among people, and that the government can potentially improve market outcomes by remedying a market failure or by promoting greater economic equality.</li><li>The fundamental lessons about the economy as a whole are that productivity is the ultimate source of living standards, that growth in the quantity of money is the ultimate source of inflation, and that society faces a short-run trade-off between inflation and unemployment.</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;
&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#how-people-make-decisions&quot;&gt;How People Make Decisions&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#principle-1-people-face-trade-offs&quot;&gt;Principle 1: People Face Trade-offs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#principle-2-the-cost-of-something-is-what-you-give-up-to-get-it&quot;&gt;Principle 2: The Cost of Something Is What You Give Up to Get It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#principle-3-rational-people-think-at-the-margin&quot;&gt;Principle 3: Rational People Think at the Margin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#principle-4-people-respond-to-incentives&quot;&gt;Principle 4: People Respond to Incentives&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#how-people-interact&quot;&gt;How People Interact&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#principle-5-trade-can-make-everyone-better-off&quot;&gt;Principle 5: Trade Can Make Everyone Better Off&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#principle-6-markets-are-usually-a-good-way-to-organize-economic-activity&quot;&gt;Principle 6: Markets Are Usually a Good Way to Organize Economic Activity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#principle-7-governments-can-sometimes-improve-market-outcomes&quot;&gt;Principle 7: Governments Can Sometimes Improve Market Outcomes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#how-the-economy-as-a-whole-works&quot;&gt;How the Economy as a Whole Works&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#principle-8-a-countrys-standard-of-living-depends-on-its-ability-to-produce-goods-and-services&quot;&gt;Principle 8: A Country’s Standard of Living Depends on Its Ability to Produce Goods and Services&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#principle-9-prices-rise-when-the-government-prints-too-much-money&quot;&gt;Principle 9: Prices Rise When the Government Prints Too Much Money&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#principle-10-society-faces-a-short-run-trade-off-between-inflation-and-unemployment&quot;&gt;Principle 10: Society Faces a Short-Run Trade-off between Inflation and Unemployment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#summary&quot;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- tocstop --&gt;
    
    </summary>
    
      <category term="笔记" scheme="http://www.52coding.com.cn/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="微观经济型原理" scheme="http://www.52coding.com.cn/tags/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%9E%8B%E5%8E%9F%E7%90%86/"/>
    
      <category term="inflation" scheme="http://www.52coding.com.cn/tags/inflation/"/>
    
      <category term="marginal benefit" scheme="http://www.52coding.com.cn/tags/marginal-benefit/"/>
    
  </entry>
  
</feed>
