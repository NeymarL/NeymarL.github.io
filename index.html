<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

  <meta charset="utf-8">
  
  <!-- if (config.subtitle) {
    title.push(config.subtitle);
  } -->
  <title>
    NIUHE
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE的博客">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script>
  <script type="text/javascript" src="/js/search.js"></script>
  <script type="text/javascript" src="/js/jquery.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれんな</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">博客</a></li>
      
        <li><a href="/notes">笔记</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/search">搜索</a></li>
      
        <li><a href="/about">关于</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        
<article>

  
  
  <h3 class="article-title"><a href="/2019/06/20/imperfect info game ai/"><span>
        德州扑克AI算法浅析</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/06/20/imperfect info game ai/" rel="bookmark">
        <time class="entry-date published" datetime="2019-06-20T09:55:01.000Z">
          2019-06-20
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>不完全信息的博弈是一种玩家对正在玩的游戏没有共同知识的博弈，也就是说，不能只通过子游戏的信息解决子游戏，这样通常达不到全局最优。在相关研究中，通常的做法是逼近游戏中的纳什均衡策略，也就是每个玩家都无法通过只改变自己的策略来提高自己的收益。在零和游戏中，如果每个玩家都选择对对手的最优策略，那么游戏整体就达到了纳什均衡，每个玩家的策略就是最优策略（纳什均衡策略）。</p>
<p>这几年有明显突破的领域是双人不限注德州扑克，阿尔伯塔大学的DeepStack和CMU的Libratus都取得了明显的突破，尤其是Libratus，已经完胜了顶级人类玩家和其他AI。顺便说一下，限注的德州扑克的决策点的数量是<span class="math inline">\(10^{14}\)</span>，已经可以被完全搜索；不限注的德扑的决策点数量是<span class="math inline">\(10^{161}\)</span>，和围棋的<span class="math inline">\(10^{170}\)</span>很接近。而在其他领域，尤其是多人游戏，如麻将（<span class="math inline">\(10^{150}\)</span>），AI还没有显著成果。这篇文章主要介绍DeepStack和Libratus的算法。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/不完全信息博弈/">不完全信息博弈</a><a href="/tags/DeepStack/">DeepStack</a><a href="/tags/Libratus/">Libratus</a><a href="/tags/CFR/">CFR</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2019/05/05/PyTorch5/"><span>
        PyTorch源码浅析(5)：Python扩展</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch5/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:58:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>这篇是本系列最后一篇博客了，介绍一下前面的C++代码怎么与Python交互，或者说Python里怎么调用C++代码进行高效的计算。首先简单介绍一下预备知识，既Python的C扩展通常怎么写；然后以比较核心的数据结构 Tensor 和 Storage 为例看一下它们怎么转换为Python类型的；最后稍带点儿Python自微分函数的实现。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/C/">C++</a><a href="/tags/PyTorch/">PyTorch</a><a href="/tags/Python扩展/">Python扩展</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2019/05/05/PyTorch4/"><span>
        PyTorch源码浅析(4)：Autograd</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch4/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:57:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>这篇博客介绍 PyTorch 中自动微分引擎的实现，主要分为三部分：首先简要介绍一下计算图的原理；然后介绍 PyTorch 中与 autograd 的相关数据结构和 <code>backward()</code>函数的实现，数据结构包括 <code>torch::autograd::Variable</code>, <code>torch::autograd::Function</code> 等；最后讲一下动态建立计算图的实现，这部分代码涉及到动态派发机制，而且都是用脚本生成的，不太容易理解。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/PyTorch/">PyTorch</a><a href="/tags/Autograd/">Autograd</a><a href="/tags/自动微分引擎/">自动微分引擎</a><a href="/tags/Variable/">Variable</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2019/05/05/PyTorch3/"><span>
        PyTorch源码浅析(3)：NN</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch3/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:55:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>THNN是一个用C语言实现的神经网络模块的库，提供的功能非常底层。它实现了许多基础的神经网络模块，包括线性层，卷积层，Sigmoid等各种激活层，一些基本的loss函数，这些API都声明在<code>THNN/generic/THNN.h</code>中。每个模块都实现了前向传导（forward）和后向传导（backward）的功能。THCUNN则是对应模块的CUDA实现。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/Neural-Network/">Neural Network</a><a href="/tags/PyTorch/">PyTorch</a><a href="/tags/THNN/">THNN</a><a href="/tags/CONV/">CONV</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2019/05/05/PyTorch2/"><span>
        PyTorch源码浅析(2)：THC</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch2/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:53:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>这篇主要看 Torch CUDA 部分，对应源码目录<code>aten/src/THC</code>，里面包含了许多C++和CUDA代码。这部分实现了操作 THCTensor 和 THCStorage 的接口，不过底层用的数据结构还是<code>TensorImpl</code>和<code>StorageImpl</code>。THC里的接口也是通过C语言范式实现的，但是Apply系列操作不再由宏来实现，而是使用了C++模板。其他的区别还有allocator不同，以及多了 THCState 结构。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/PyTorch/">PyTorch</a><a href="/tags/Tensor/">Tensor</a><a href="/tags/CUDA/">CUDA</a><a href="/tags/THC/">THC</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2019/05/05/PyTorch1/"><span>
        PyTorch源码浅析(1)：THTensor</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch1/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:51:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>PyTorch中Tensor的存储和表示分开，多个THTensor可能共享一个THStorage，每个THTensor可能拥有不同的view（e.g. size, stride）。这样设计的好处是，有时看起来不一样的数据底层是共享的，比如矩阵与矩阵的转置、二维矩阵与二维矩阵变成一维时的矩阵。这部分的主要实现在<code>pytorch/aten</code>文件夹中，这里面既实现了底层的Tensor操作库，也封装了名为 <strong>ATen</strong> 的 C++11接口。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/PyTorch/">PyTorch</a><a href="/tags/Tensor/">Tensor</a><a href="/tags/THTensor/">THTensor</a><a href="/tags/THStorage/">THStorage</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2019/05/05/PyTorch0/"><span>
        PyTorch源码浅析：简介</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch0/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:49:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>这个系列文章自底向上针对PyTorch核心源码进行解析，从Tensor库<span class="math inline">\(\rightarrow​\)</span>神经网络算符<span class="math inline">\(\rightarrow​\)</span>自动微分引擎<span class="math inline">\(\rightarrow​\)</span>Python扩展，一共五篇。代码较多，理解有限，如发现理解不当或表达不妥的地方，还请在评论区指出。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/PyTorch/">PyTorch</a><a href="/tags/Tensor/">Tensor</a><a href="/tags/NN/">NN</a><a href="/tags/Autograd/">Autograd</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2018/11/30/RL - Deep Deterministic Policy Gradient/"><span>
        RL - Deep Deterministic Policy Gradient (DDPG)</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/11/30/RL - Deep Deterministic Policy Gradient/" rel="bookmark">
        <time class="entry-date published" datetime="2018-11-30T05:53:09.000Z">
          2018-11-30
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p><a href="https://arxiv.org/abs/1509.02971" target="_blank" rel="noopener">Deep Deterministic Policy Gradient (DDPG)</a> 是由 DeepMind 的 Lillicrap 等人于2015年提出的算法，发表在ICLR 2016上。DDPG 是基于 <a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener">DPG</a> 算法的改进，可以看作是 Actor-critic 和 <a href="https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/">DQN</a> 的结合，它同时学习一个 Q-function 和一个策略（policy）：用 Q-learning 的方法学习 Q-function，然后用 Q-function 更新策略。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/Reinforcement-Learning/">Reinforcement Learning</a><a href="/tags/增强学习/">增强学习</a><a href="/tags/Policy-Gradient/">Policy Gradient</a><a href="/tags/DPG/">DPG</a><a href="/tags/DDPG/">DDPG</a><a href="/tags/DQN/">DQN</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2018/11/25/RL - PPO/"><span>
        RL - Proximal Policy Optimization (PPO)</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/11/25/RL - PPO/" rel="bookmark">
        <time class="entry-date published" datetime="2018-11-25T14:00:09.000Z">
          2018-11-25
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p><a href="https://arxiv.org/abs/1707.06347" target="_blank" rel="noopener">Proximal Policy Optimization (PPO, PPO-Clip, PPO-Penalty)</a> 是由<a href="https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/">TRPO</a>的作者Schulman等人于2017年提出的策略梯度类算法。PPO算法的思路和TRPO一致，都是想在优化时采取尽可能大的步幅但又不能太大以至于产生崩坏。相比于比TRPO，PPO实现起来更简单，泛化能力更强，可以使用随机梯度下降（SGD）进行优化。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/Reinforcement-Learning/">Reinforcement Learning</a><a href="/tags/增强学习/">增强学习</a><a href="/tags/Policy-Gradient/">Policy Gradient</a><a href="/tags/PPO/">PPO</a>
      </span>
      

    </div>

    
  </div>
</article>


<article>

  
  
  <h3 class="article-title"><a href="/2018/11/22/RL - TRPO/"><span>
        RL - Trust Region Policy Optimization (TRPO)</span></a></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/11/22/RL - TRPO/" rel="bookmark">
        <time class="entry-date published" datetime="2018-11-22T09:10:09.000Z">
          2018-11-22
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p><a href="https://arxiv.org/abs/1502.05477" target="_blank" rel="noopener">Trust Region Policy Optimization (TRPO)</a>算法是由伯克利大学的Schulman等人于2015年提出的策略梯度（Policy Gradients）算法。TRPO通过最大化新策略相对于当前策略的优势来保证每次更新都是单调递增的（稳定），同时找到尽可能大的更新步幅。算法推导出的最终结果是在KL约束下最大化替代优势函数。</p>
      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/Reinforcement-Learning/">Reinforcement Learning</a><a href="/tags/增强学习/">增强学习</a><a href="/tags/Policy-Gradient/">Policy Gradient</a><a href="/tags/TRPO/">TRPO</a>
      </span>
      

    </div>

    
  </div>
</article>



<nav class="pagination">
  
  
  <a href="/page/2/" class="pagination-next">Next</a>
  
</nav>
      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2019
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>