<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>PyTorchæºç æµ…æ(5)ï¼šPythonæ‰©å±•</title>
      <link href="/2019/05/05/PyTorch5/"/>
      <url>/2019/05/05/PyTorch5/</url>
      
        <content type="html"><![CDATA[<p>è¿™ç¯‡æ˜¯æœ¬ç³»åˆ—æœ€åä¸€ç¯‡åšå®¢äº†ï¼Œä»‹ç»ä¸€ä¸‹å‰é¢çš„C++ä»£ç æ€ä¹ˆä¸Pythonäº¤äº’ï¼Œæˆ–è€…è¯´Pythoné‡Œæ€ä¹ˆè°ƒç”¨C++ä»£ç è¿›è¡Œé«˜æ•ˆçš„è®¡ç®—ã€‚é¦–å…ˆç®€å•ä»‹ç»ä¸€ä¸‹é¢„å¤‡çŸ¥è¯†ï¼Œæ—¢Pythonçš„Cæ‰©å±•é€šå¸¸æ€ä¹ˆå†™ï¼›ç„¶åä»¥æ¯”è¾ƒæ ¸å¿ƒçš„æ•°æ®ç»“æ„ Tensor å’Œ Storage ä¸ºä¾‹çœ‹ä¸€ä¸‹å®ƒä»¬æ€ä¹ˆè½¬æ¢ä¸ºPythonç±»å‹çš„ï¼›æœ€åç¨å¸¦ç‚¹å„¿Pythonè‡ªå¾®åˆ†å‡½æ•°çš„å®ç°ã€‚</p><a id="more"></a><p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#pythonçš„ccæ‰©å±•">Pythonçš„C/C++æ‰©å±•</a><ul><li><a href="#æ‰©å±•æ¨¡å—">æ‰©å±•æ¨¡å—</a></li><li><a href="#è‡ªå®šä¹‰pythonç±»å‹">è‡ªå®šä¹‰Pythonç±»å‹</a></li></ul></li><li><a href="#torch_c">torch._C</a><ul><li><a href="#storage">Storage</a></li><li><a href="#tensor">Tensor</a></li><li><a href="#nn">NN</a></li></ul></li></ul><!-- tocstop --><h2><span id="pythonçš„ccæ‰©å±•">Pythonçš„C/C++æ‰©å±•</span></h2><h3><span id="æ‰©å±•æ¨¡å—">æ‰©å±•æ¨¡å—</span></h3><p>å¯¹äºç®€å•çš„Cä»£ç ï¼Œæ„å»ºä¸€ä¸ªè‡ªå®šä¹‰æ‰©å±•æ¨¡å—æ˜¯å¾ˆå®¹æ˜“çš„ã€‚<code>C/C++</code>éƒ¨åˆ†åŸºæœ¬ä¸Šåªéœ€è¦åšä»¥ä¸‹å‡ ä»¶äº‹ï¼š</p><ul><li><p>åŒ…å«å¤´æ–‡ä»¶<code>Python.h</code></p></li><li><p>æ­£ç¡®çš„å£°æ˜å‡½æ•°ï¼Œå³</p><ul><li><p>å‡½æ•°å¿…é¡»æ˜¯<code>static</code></p></li><li><p>è¿”å›ç±»å‹å¿…é¡»æ˜¯<code>PyObject *</code></p></li><li><p>å‚æ•°åˆ—è¡¨å¿…é¡»æ˜¯<code>PyObject *self, PyObject *args</code></p></li></ul></li><li><p>å®šä¹‰ä¸€ä¸ªMethod Tableï¼ŒæŠŠæ¨¡å—éœ€è¦åŒ…æ‹¬çš„å‡½æ•°éƒ½æ”¾è¿›å»</p></li><li><p>å®šä¹‰æ¨¡å—å’Œåˆå§‹åŒ–å‡½æ•°</p></li></ul><p>ä¸¾ä¸ªğŸŒ°ï¼Œä¸‹é¢çš„ä»£ç æ„å»ºäº†ä¸€ä¸ªåªæœ‰ä¸€ä¸ªå‡½æ•°çš„Pythonæ¨¡å—ï¼Œè¯¥å‡½æ•°çš„åŠŸèƒ½æ˜¯æ±‚æœ€å¤§å…¬çº¦æ•°ï¼ˆ<code>py_gcd</code>ï¼‰:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"Python.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"sample.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* æŠŠæ™®é€šCè¯­è¨€å®ç°çš„gcd()å°è£…æˆPythonå¯ä»¥è°ƒç”¨çš„å‡½æ•° */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> PyObject *<span class="title">py_gcd</span><span class="params">(PyObject *self, PyObject *args)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> x, y, result;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ä» args é‡Œè§£æå®é™…å‚æ•° */</span></span><br><span class="line">  <span class="keyword">if</span> (!PyArg_ParseTuple(args,<span class="string">"ii"</span>, &amp;x, &amp;y)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/* è°ƒç”¨æ™®é€šCè¯­è¨€å®ç°çš„gcd() */</span></span><br><span class="line">  result = gcd(x,y);</span><br><span class="line">  <span class="comment">/* æŠŠ int è½¬åŒ–ä¸º PyObject* */</span></span><br><span class="line">  <span class="keyword">return</span> Py_BuildValue(<span class="string">"i"</span>, result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* å®šä¹‰æ¨¡å—çš„ method table */</span></span><br><span class="line"><span class="keyword">static</span> PyMethodDef SampleMethods[] = &#123;</span><br><span class="line">  &#123;<span class="string">"gcd"</span>,  py_gcd, METH_VARARGS, <span class="string">"Greatest common divisor"</span>&#125;,</span><br><span class="line">  &#123; <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* å®šä¹‰æ¨¡å—ç»“æ„ */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyModuleDef</span> <span class="title">samplemodule</span> = &#123;</span></span><br><span class="line">  PyModuleDef_HEAD_INIT,</span><br><span class="line">  <span class="string">"sample"</span>,           <span class="comment">/* name of module */</span></span><br><span class="line">  <span class="string">"A sample module"</span>,  <span class="comment">/* Doc string (may be NULL) */</span></span><br><span class="line">  <span class="number">-1</span>,                 <span class="comment">/* Size of per-interpreter state or -1 */</span></span><br><span class="line">  SampleMethods       <span class="comment">/* Method table */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* æ¨¡å—åˆå§‹åŒ–å‡½æ•° */</span></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">PyInit_sample</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> PyModule_Create(&amp;samplemodule);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å…·ä½“ç»†èŠ‚å°±ä¸å±•å¼€äº†ï¼Œæœ‰å…´è¶£çš„ç«¥é‹å¯ä»¥å‚è€ƒä¸‹é¢çš„é“¾æ¥ã€‚</p><p>è¦ç»‘å®šè¿™ä¸ªæ‰©å±•æ¨¡å—ï¼Œåƒä¸‹é¢è¿™æ ·åˆ›å»ºä¸€ä¸ª <code>setup.py</code> æ–‡ä»¶ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># setup.py</span></span><br><span class="line"><span class="keyword">from</span> distutils.core <span class="keyword">import</span> setup, Extension</span><br><span class="line"></span><br><span class="line">setup(name=<span class="string">'sample'</span>,</span><br><span class="line">      ext_modules=[</span><br><span class="line">        Extension(<span class="string">'sample'</span>,</span><br><span class="line">                  [<span class="string">'pysample.c'</span>],</span><br><span class="line">                  include_dirs = [<span class="string">'/some/dir'</span>],</span><br><span class="line">                  define_macros = [(<span class="string">'FOO'</span>,<span class="string">'1'</span>)],</span><br><span class="line">                  undef_macros = [<span class="string">'BAR'</span>],</span><br><span class="line">                  library_dirs = [<span class="string">'/usr/local/lib'</span>],</span><br><span class="line">                  libraries = [<span class="string">'sample'</span>]</span><br><span class="line">                  )</span><br><span class="line">        ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>ä¸ºäº†æ„å»ºæœ€ç»ˆçš„å‡½æ•°åº“ï¼Œåªéœ€ç®€å•çš„ä½¿ç”¨ <code>python3 buildlib.py build_ext --inplace</code> å‘½ä»¤å³å¯ã€‚å®ƒä¼šåˆ›å»ºä¸€ä¸ªåå­—å« <code>sample.so</code> çš„å…±äº«åº“ï¼Œå½“è¢«ç¼–è¯‘åï¼Œä½ å°±èƒ½å°†å®ƒä½œä¸ºä¸€ä¸ªæ¨¡å—å¯¼å…¥è¿›æ¥äº†ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sample</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sample.gcd(<span class="number">35</span>, <span class="number">42</span>)</span><br><span class="line"><span class="number">7</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><blockquote><p>æ³¨ï¼šè¿™éƒ¨åˆ†ä¸»è¦å‚è€ƒ<a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/c15/p02_write_simple_c_extension_module.html" target="_blank" rel="noopener">Python3-Cookbook</a>.</p></blockquote><h3><span id="è‡ªå®šä¹‰pythonç±»å‹">è‡ªå®šä¹‰Pythonç±»å‹</span></h3><p>åœ¨Pythonä»£ç ä¸­å¦‚æœè¦åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰ç±»ä½¿ç”¨<code>class</code>å…³é”®å­—å³å¯ï¼Œä½†æ˜¯åœ¨Cä»£ç ä¸­å°±æ²¡é‚£ä¹ˆæ–¹ä¾¿äº†ã€‚é¦–å…ˆç®€å•ä»‹ç»ä¸‹Pythonä¸­çš„ç±»å‹ã€‚åœ¨Pythonä¸­ä¸€åˆ‡çš†å¯¹è±¡ï¼ŒPythonä¸­æœ‰ä¸¤ç§å¯¹è±¡ï¼š</p><ul><li><p>ä¸€ç§æ˜¯ç±»å‹å¯¹è±¡ï¼ˆclasså¯¹è±¡ï¼‰ï¼šè¡¨ç¤ºPythonå®šä¹‰çš„ç±»å‹ï¼Œä¾‹å¦‚<code>int, str, object</code>ç­‰ï¼›</p></li><li><p>å¦ä¸€ç§æ˜¯å®ä¾‹å¯¹è±¡ï¼ˆinstanceå¯¹è±¡ï¼‰ï¼šè¡¨ç¤ºç”±classå¯¹è±¡åˆ›å»ºçš„å®ä¾‹ã€‚</p></li></ul><p>Pythonä¸­çš„æ‰€æœ‰å¯¹è±¡éƒ½æ˜¯ç›´æ¥æˆ–è€…é—´æ¥ç»§æ‰¿<code>object</code>ï¼Œç„¶å<code>object</code>åˆæ˜¯<code>type</code>ç±»å‹ã€‚Pythonå¯¹è±¡çš„Cè¯­è¨€å®ç°ä¹Ÿæ˜¯åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†è¡¨ç¤ºå®ä¾‹å¯¹è±¡ï¼Œå­˜å‚¨å¯¹è±¡å®é™…çš„æ•°æ®ï¼›å¦ä¸€éƒ¨åˆ†æ˜¯ç±»å‹å¯¹è±¡ï¼Œå­˜å‚¨å¯¹è±¡çš„å…ƒæ•°æ®ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè‡ªå®šä¹‰ç±»å‹ä¹Ÿè¦å®ç°è¿™ä¸¤éƒ¨åˆ†ï¼Œä¸¾ä¸ªä¾‹å­ï¼š</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* å®ä¾‹å¯¹è±¡ */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    PyObject_HEAD</span><br><span class="line">    <span class="comment">/* ç±»å‹å®é™…çš„æ•°æ®åœ¨è¿™é‡Œå®šä¹‰ */</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">&#125; noddy_NoddyObject;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* ç±»å‹å¯¹è±¡ */</span></span><br><span class="line"><span class="keyword">static</span> PyTypeObject noddy_NoddyType = &#123;</span><br><span class="line">    PyVarObject_HEAD_INIT(<span class="literal">NULL</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="string">"noddy.Noddy"</span>,             <span class="comment">/*tp_name*/</span></span><br><span class="line">    <span class="keyword">sizeof</span>(noddy_NoddyObject), <span class="comment">/*tp_basicsize*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_itemsize*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_dealloc*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_print*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_getattr*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_setattr*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_compare*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_repr*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_number*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_sequence*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_mapping*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_hash */</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_call*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_str*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_getattro*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_setattro*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_buffer*/</span></span><br><span class="line">    Py_TPFLAGS_DEFAULT,        <span class="comment">/*tp_flags*/</span></span><br><span class="line">    <span class="string">"Noddy objects"</span>,           <span class="comment">/*tp_doc*/</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>ç„¶ååˆ›å»ºä¸€ä¸ªæ–°æ‰©å±•æ¨¡å—ï¼Œå¹¶å®Œæˆåˆå§‹åŒ–ï¼š</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* å®šä¹‰æ¨¡å—çš„ method table */</span></span><br><span class="line"><span class="keyword">static</span> PyMethodDef noddy_methods[] = &#123;</span><br><span class="line">    &#123;<span class="literal">NULL</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* æ¨¡å—åˆå§‹åŒ–å‡½æ•° */</span></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">initnoddy</span><span class="params">(<span class="keyword">void</span>)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PyObject* m;</span><br><span class="line">    <span class="comment">/* tp_new ç›¸å½“äºPythoné‡Œçš„ __new__ */</span></span><br><span class="line">    noddy_NoddyType.tp_new = PyType_GenericNew;</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (PyType_Ready(&amp;noddy_NoddyType) &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    m = Py_InitModule3(<span class="string">"noddy"</span>, noddy_methods,</span><br><span class="line">                       <span class="string">"Example module"</span>);</span><br><span class="line"></span><br><span class="line">    Py_INCREF(&amp;noddy_NoddyType);</span><br><span class="line">    <span class="comment">/* å‘æ¨¡å—æ·»åŠ ç±»å‹ */</span></span><br><span class="line">    PyModule_AddObject(m, <span class="string">"Noddy"</span>, (PyObject*)&amp;noddy_NoddyType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>æ³¨ï¼šè¿™éƒ¨åˆ†ä»‹ç»çš„æ¯”è¾ƒç®€ç•¥ï¼Œè¯¦ç»†è¯·å‚è€ƒ <a href="http://www.xefan.com/archives/84091.html" class="uri" target="_blank" rel="noopener">http://www.xefan.com/archives/84091.html</a>.</p></blockquote><h2><span id="torch_c">torch._C</span></h2><p>æœ‰äº†ä¸Šé¢çš„é¢„å¤‡çŸ¥è¯†ä¹‹åï¼Œæˆ‘ä»¬å°±èƒ½çœ‹ATenè¿˜æœ‰autogradç­‰æ¨¡å—çš„ä»£ç æ˜¯æ€ä¹ˆå¯¼å…¥Pythonäº†ã€‚æ„å»ºPythonæ‰©å±•æ¨¡å—çš„ä»£ç åœ¨ <code>torch/csrc/Module.cpp</code> é‡Œï¼Œä¸»è¦éƒ¨åˆ†å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">/* method table */</span></span><br><span class="line"><span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;PyMethodDef&gt; methods;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* åˆå§‹åŒ–æ¨¡å— */</span></span><br><span class="line"><span class="function">PyObject* <span class="title">initModule</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  HANDLE_TH_ERRORS</span><br><span class="line">  THInferNumThreads();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* å‘ method table æ·»åŠ å‡½æ•° */</span></span><br><span class="line">  THPUtils_addPyMethodDefs(methods, TorchMethods);</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, </span><br><span class="line">                           torch::autograd::python_functions());</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, </span><br><span class="line">                       torch::multiprocessing::python_functions());</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* æ„å»º torch._C æ¨¡å— */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> PY_MAJOR_VERSION == 2</span></span><br><span class="line">  ASSERT_TRUE(<span class="keyword">module</span> = Py_InitModule(<span class="string">"torch._C"</span>, methods.data()));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  <span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyModuleDef</span> <span class="title">torchmodule</span> = &#123;</span></span><br><span class="line">      PyModuleDef_HEAD_INIT, <span class="string">"torch._C"</span>, <span class="literal">nullptr</span>, <span class="number">-1</span>, </span><br><span class="line">      methods.data()</span><br><span class="line">  &#125;;</span><br><span class="line">  ASSERT_TRUE(<span class="keyword">module</span> = PyModule_Create(&amp;torchmodule));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* å„ç§åˆå§‹åŒ– */</span></span><br><span class="line">  ASSERT_TRUE(THPWrapper_init(<span class="keyword">module</span>));</span><br><span class="line">  ...</span><br><span class="line">  torch::autograd::initNNFunctions(<span class="keyword">module</span>);     <span class="comment">// åˆå§‹åŒ–è‡ªå¾®åˆ†ç›¸å…³API</span></span><br><span class="line">  torch::autograd::init_legacy_variable(<span class="keyword">module</span>);<span class="comment">// åˆå§‹åŒ–Tensorç±»å‹</span></span><br><span class="line">  torch::python::init_bindings(<span class="keyword">module</span>);         <span class="comment">// åˆå§‹åŒ–NNç›¸å…³å‡½æ•°</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> USE_CUDA</span></span><br><span class="line">  torch::cuda::initModule(<span class="keyword">module</span>);              <span class="comment">// åˆå§‹åŒ–CUDAæ¨¡å—</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="comment">/* åˆå§‹åŒ–å„ç§Storageç±»å‹ */</span></span><br><span class="line">  ASSERT_TRUE(THPDoubleStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPFloatStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPHalfStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPLongStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPIntStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPShortStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPCharStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPByteStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPBoolStorage_init(<span class="keyword">module</span>));</span><br><span class="line"> </span><br><span class="line">  ...</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">module</span>;</span><br><span class="line">  END_HANDLE_TH_ERRORS</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åŸºæœ¬ä¸Šæ‰€æœ‰C/C++å®ç°çš„APIéƒ½è¢«ç»‘å®šåœ¨ <code>torch._C</code> æ‰©å±•æ¨¡å—ä¸­ï¼Œä¸‹é¢ä»¥Storageå’ŒTensorä¸ºä¾‹ï¼Œçœ‹ä¸€ä¸‹ <code>torch.Storage</code>å’Œ<code>torch.Tensor</code> ç±»å‹çš„ç»‘å®šæ–¹æ³•ï¼Œæ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯å®ƒä»¬ä¸¤ä¸ªçš„ç»‘å®šæ–¹å¼åŒºåˆ«è¿˜æŒºå¤§çš„ã€‚</p><h3><span id="storage">Storage</span></h3><p>ä»ä¸Šé¢çš„ <code>initModule()</code> å‡½æ•°ä¸­å¯ä»¥çœ‹åˆ°ï¼Œé‡Œé¢æœ‰è®¸å¤šåˆå§‹åŒ–å„ç§Storageç±»å‹çš„ä»£ç ï¼Œå®ƒä»¬çš„ç›®çš„å°±æ˜¯åˆ›å»ºå„ç§Storageç±»å‹ï¼Œå¦‚ <code>torch._C._FloatStorageBase</code>, <code>torch._C._LongStorageBase</code>ç­‰ï¼Œè€Œ <code>torch.FloatStorage</code> ç­‰ç±»å‹æ˜¯ä»Pythonç«¯åˆ›å»ºçš„ï¼Œç»§æ‰¿è‡ª <code>torch._C._FloatStorageBase</code> ç­‰ç±»å‹ï¼Œè¿™éƒ¨åˆ†ä»£ç å¯ä»¥åœ¨<code>torch/__init__.py</code>ä¸­æ‰¾åˆ°ã€‚</p><p>å›åˆ°ç»‘å®šè¿‡ç¨‹ï¼Œ<code>THPDoubleStorage_init()</code> ç­‰å‡½æ•°å…¶å®æ˜¯ç”¨CèŒƒå¼ç”Ÿæˆçš„ï¼Œå’Œ<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/">ç¬¬ä¸€ç¯‡</a>é‡Œçš„THåº“ä¸­ç”¨çš„æ–¹æ³•ä¸€æ ·ã€‚å®ƒå®é™…è°ƒç”¨çš„å‡½æ•°æ˜¯ <code>bool THPStorage_(init)(PyObject *module)</code>ï¼Œå®ç° <code>torch/csrc/generic/Storage.cpp</code>é‡Œï¼Œè¿™ä¸ªå‡½æ•°ä¼šæ ¹æ®ä¸åŒç±»å‹å±•å¼€ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">THPStorage_</span><span class="params">(init)</span><span class="params">(PyObject *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;PyMethodDef&gt; methods;</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> THD_GENERIC_FILE</span></span><br><span class="line">  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ç»‘å®šç±»æ–¹æ³• */</span></span><br><span class="line">  THPStorageType.tp_methods = methods.data();</span><br><span class="line">  <span class="comment">/* ç»‘å®šç±»æˆå‘˜ */</span></span><br><span class="line">  THPStorageType.tp_members = THPStorage_(members);</span><br><span class="line">  <span class="keyword">if</span> (PyType_Ready(&amp;THPStorageType) &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  Py_INCREF(&amp;THPStorageType);</span><br><span class="line">  <span class="comment">/* å‘æ¨¡å—æ·»åŠ  THPStorage ç±»å‹ */</span></span><br><span class="line">  PyModule_AddObject(<span class="keyword">module</span>, THPStorageBaseStr, </span><br><span class="line">                     (PyObject*)&amp;THPStorageType);</span><br><span class="line">  THPStorage_(initCopyMethods)();</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™ä¸ªå‡½æ•°åˆå§‹åŒ–äº† <code>THPStorageType</code> ç±»å‹å¹¶æ·»åŠ åˆ°<code>torch._C</code>æ¨¡å—ä¸­ï¼Œè¯¥ç±»å‹çš„å®šä¹‰å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* å®ä¾‹å¯¹è±¡ */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THPStorage</span> &#123;</span></span><br><span class="line">  PyObject_HEAD</span><br><span class="line">  <span class="comment">/* THWStorage ä¸ºå®å®šä¹‰ï¼Œä¼šè½¬æ¢ä¸º THxxxStorage */</span></span><br><span class="line">  THWStorage *cdata;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* ç±»å‹å¯¹è±¡ */</span></span><br><span class="line">PyTypeObject THPStorageType = &#123;</span><br><span class="line">  PyVarObject_HEAD_INIT(<span class="literal">nullptr</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="string">"torch._C."</span> THPStorageBaseStr,         <span class="comment">/* tp_name */</span></span><br><span class="line">  <span class="keyword">sizeof</span>(THPStorage),                    <span class="comment">/* tp_basicsize */</span></span><br><span class="line">  <span class="number">0</span>,                                     <span class="comment">/* tp_itemsize */</span></span><br><span class="line">  (destructor)THPStorage_(dealloc),      <span class="comment">/* tp_dealloc */</span></span><br><span class="line">  ...</span><br><span class="line">  THPStorage_(pynew),                    <span class="comment">/* tp_new */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Pythoné‡Œç±»å‹çš„åå­—ç”± <code>tp_name</code> åŸŸç¡®å®šï¼Œä¹Ÿå°±æ˜¯ <code>&quot;torch._C.&quot; THPStorageBaseStr</code>ï¼Œåè€…ä¸€çœ‹å°±æ˜¯å®å®šä¹‰ï¼Œå®ƒå±•å¼€åä¼šå˜æˆ <code>_xxxStorageBase</code>ï¼Œå…¶ä¸­<code>xxx</code>ä¸ºå„ç§ç±»å‹ï¼Œæ‰€ä»¥æœ€åå°±å˜æˆäº† <code>torch._C._FloatStorageBase</code> ç­‰ç±»å‹ã€‚</p><h3><span id="tensor">Tensor</span></h3><p><code>torch.Tensor</code>çš„å®ç°å°±ä¸<code>torch.Storage</code> ä¸ä¸€æ ·äº†ï¼Œå› ä¸ºATençš„å­˜åœ¨ï¼Œç»‘å®šçš„è¯ä¹Ÿæ˜¯ç»‘å®šATené‡Œçš„Tensorï¼Œä¸ä¼šç»‘å®šTHTensorã€‚è¿˜æœ‰ä¸€ç‚¹ï¼Œå°±æ˜¯Pythoné‡Œçš„Tensorå’ŒVariableåˆå¹¶äº†ï¼Œæ‰€ä»¥<code>torch.Tensor</code>ç›´æ¥å’Œ <code>autograd::Variable</code> ç»‘å®šåœ¨ä¸€èµ·äº†ã€‚ä¸è¿‡å‡†ç¡®æ¥è¯´æ˜¯ <code>torch._C._TensorBase</code> å’Œ <code>autograd::Variable</code> ç»‘å®šåœ¨ä¸€èµ·äº†ï¼Œè€Œ <code>torch.Tensor</code> ç»§æ‰¿è‡ª <code>torch._C._TensorBase</code>ã€‚</p><p>ç»‘å®šçš„ä»£ç åœ¨ <code>torch/csrc/autograd/python_variable.cpp</code>ä¸­ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// python_variable.h</span></span><br><span class="line"><span class="comment">/* å®ä¾‹å¯¹è±¡ */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THPVariable</span> &#123;</span></span><br><span class="line">    PyObject_HEAD</span><br><span class="line">    <span class="comment">// Payload</span></span><br><span class="line">    torch::autograd::Variable cdata;</span><br><span class="line">    PyObject* backward_hooks = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// python_variable.cpp</span></span><br><span class="line">...</span><br><span class="line"><span class="comment">/* ç±»å‹å¯¹è±¡ */</span></span><br><span class="line">PyTypeObject THPVariableType = &#123;</span><br><span class="line">  PyVarObject_HEAD_INIT(<span class="literal">nullptr</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="string">"torch._C._TensorBase"</span>,                <span class="comment">/* tp_name */</span></span><br><span class="line">  <span class="keyword">sizeof</span>(THPVariable),                   <span class="comment">/* tp_basicsize */</span></span><br><span class="line">  <span class="number">0</span>,                                     <span class="comment">/* tp_itemsize */</span></span><br><span class="line">  (destructor)THPVariable_dealloc,       <span class="comment">/* tp_dealloc */</span></span><br><span class="line">  ...</span><br><span class="line">  THPVariable_pynew                      <span class="comment">/* tp_new */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* åˆå§‹åŒ–ç±»å‹ */</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">THPVariable_initModule</span><span class="params">(PyObject *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">/* è·å– method table */</span></span><br><span class="line">  <span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;PyMethodDef&gt; methods;</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, </span><br><span class="line">                           torch::autograd::variable_methods);</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, extra_methods);</span><br><span class="line">  <span class="comment">/* ç»‘å®šç±»æ–¹æ³• */</span></span><br><span class="line">  THPVariableType.tp_methods = methods.data();</span><br><span class="line">  <span class="keyword">if</span> (PyType_Ready(&amp;THPVariableType) &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  Py_INCREF(&amp;THPVariableType);</span><br><span class="line">  <span class="comment">/* å‘æ¨¡å—ä¸­æ·»åŠ ç±»å‹ */</span></span><br><span class="line">  PyModule_AddObject(<span class="keyword">module</span>, <span class="string">"_TensorBase"</span>, </span><br><span class="line">                     (PyObject *)&amp;THPVariableType);</span><br><span class="line">  torch::autograd::initTorchFunctions(<span class="keyword">module</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ³¨æ„åˆ°ï¼Œè¿™é‡Œåªç»‘å®šäº† <code>_TensorBase</code> ä¸€ç§ç±»å‹ï¼Œè€Œä¸åƒStorageé‚£æ ·åˆ©ç”¨å®æŠŠå„ç§ç±»å‹çš„StorageBaseéƒ½å®šä¹‰äº†ã€‚</p><p>å…¶ä»–ç±»å‹çš„Tensorï¼Œå¦‚ <code>torch.FloatTensor</code> ç­‰åœ¨ <code>torch/tensor/python_tensor.cpp</code> ä¸­çš„ <code>initialize_python_bindings()</code> å‡½æ•°é‡ŒåŠ¨æ€ç»‘å®šï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initialize_python_bindings</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* æŠŠATené‡Œçš„Tensorç±»å‹è½¬åŒ–ä¸ºPythoné‡Œçš„PyTypeObject */</span></span><br><span class="line">  initialize_aten_types(tensor_types);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* åˆå§‹åŒ–ä¸Šé¢è½¬åŒ–æ¥çš„PyTypeObject */</span></span><br><span class="line">  py_initialize_metaclass(metaclass);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* è·å– torch.Tensor çš„æ‰€æœ‰æ–¹æ³• */</span></span><br><span class="line">  <span class="keyword">auto</span> tensor_dict = get_tensor_dict();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* æŠŠtorch.Tensorçš„æ–¹æ³•å¤åˆ¶ç»™æ¯ä¸ªç±»å‹ï¼Œå¦‚torch.FloatTensorç­‰ */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; tensor_type : tensor_types) &#123;</span><br><span class="line">    py_initialize_tensor_type(tensor_type.py_type, </span><br><span class="line">                              tensor_type.name, tensor_dict.get());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* å‘torchæ¨¡å—ç»‘å®šè¿™äº›å„ç§ç±»å‹çš„Tensor */</span></span><br><span class="line">  py_bind_tensor_types(tensor_types);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* è®¾ç½® torch.Tensor çš„é»˜è®¤ç±»å‹ä¸º torch.FloatTensor */</span></span><br><span class="line">  set_default_tensor_type(at::globalContext().getVariableType(</span><br><span class="line">    at::Backend::CPU, at::kFloat));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™ä¸ªå‡½æ•°ç”±Pythonè°ƒç”¨ï¼Œè°ƒç”¨çš„ä»£ç åœ¨ <code>torch/__init__.py</code> ä¸­ï¼ˆ<code>_C._initExtension()</code>ï¼‰ã€‚è°ƒç”¨æ—¶ <code>torch.Tensor</code> å·²ç»å®šä¹‰ï¼Œè¿™ä¸ªå‡½æ•°è¦åšçš„å°±æ˜¯å®šä¹‰å…¶ä»–Tensorç±»å‹ï¼Œç„¶åæŠŠTensorç±»å‹çš„æ–¹æ³•ç›´æ¥æ‹·è´ç»™å®ƒä»¬ï¼Œæœ€ååœ¨è®¾ç½®ä¸€ä¸‹é»˜è®¤ç±»å‹çš„Tensorã€‚ä¸ºä»€ä¹ˆæ•°æ®ç±»å‹ä¸åŒå´å¯ä»¥ç›´æ¥æ‹·è´ï¼Ÿå› ä¸º <code>at::Tensor</code> å¯ä»¥é’ˆå¯¹ä¸åŒæ•°æ®ç±»å‹è°ƒç”¨ä¸åŒçš„æ–¹æ³•ï¼Œç±»å‹å¤šæ€å·²ç»åœ¨ATenå†…éƒ¨å®ç°äº†ã€‚</p><p>åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼ŒTensor ç»‘å®šçš„æ–¹æ³•æ¥è‡ª <code>torch::autograd::variable_methods</code>ï¼Œè¿™ä¸ªåˆ—è¡¨åœ¨ <code>csrc/autograd/generated/python_variable_methods.cpp</code> ä¸­ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PyMethodDef variable_methods[] = &#123;</span><br><span class="line">  &#123;<span class="string">"__add__"</span>, (PyCFunction)THPVariable_add, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__radd__"</span>, (PyCFunction)THPVariable_add, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__iadd__"</span>, (PyCFunction)THPVariable_add_, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__rmul__"</span>, (PyCFunction)THPVariable_mul, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__mul__"</span>, (PyCFunction)THPVariable_mul, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__imul__"</span>, (PyCFunction)THPVariable_mul_, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__sub__"</span>, (PyCFunction)THPVariable_sub, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"addcmul"</span>, (PyCFunction)THPVariable_addcmul, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä»æ–‡ä»¶è·¯å¾„å¯ä»¥çœ‹å‡ºè¿™ä¹Ÿæ˜¯æ ¹æ® <code>derivatives.yaml</code> è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç ï¼Œæ‹¿ <code>addcmul</code> ä¸¾ä¸ªä¾‹å­çœ‹çœ‹è¿™äº›å‡½æ•°çš„å®ç°æ–¹æ³•ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> PyObject * <span class="title">THPVariable_addcmul</span><span class="params">(PyObject* self_, PyObject* args, PyObject* kwargs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  HANDLE_TH_ERRORS</span><br><span class="line">  <span class="function"><span class="keyword">static</span> PythonArgParser <span class="title">parser</span><span class="params">(&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="string">"addcmul(Scalar value, Tensor tensor1, Tensor tensor2)|deprecated"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="string">"addcmul(Tensor tensor1, Tensor tensor2, *, Scalar value=1)"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  &#125;, <span class="comment">/*traceable=*/</span><span class="literal">true</span>)</span></span>;</span><br><span class="line">  <span class="comment">/* è·å–autograd::Variableå®ä¾‹ */</span></span><br><span class="line">  <span class="keyword">auto</span>&amp; self = <span class="keyword">reinterpret_cast</span>&lt;THPVariable*&gt;(self_)-&gt;cdata;</span><br><span class="line">  <span class="comment">/* è§£æå‡½æ•°å‚æ•° */</span></span><br><span class="line">  ParsedArgs&lt;<span class="number">4</span>&gt; parsed_args;</span><br><span class="line">  <span class="keyword">auto</span> r = parser.parse(args, kwargs, parsed_args);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* è°ƒç”¨ dispatch */</span></span><br><span class="line">  <span class="keyword">if</span> (r.idx == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> wrap(dispatch_addcmul(self, r.scalar(<span class="number">0</span>), r.tensor(<span class="number">1</span>), r.tensor(<span class="number">2</span>)));</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (r.idx == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> wrap(dispatch_addcmul(self, r.tensor(<span class="number">0</span>), r.tensor(<span class="number">1</span>), r.scalar(<span class="number">2</span>)));</span><br><span class="line">  &#125;</span><br><span class="line">  Py_RETURN_NONE;</span><br><span class="line">  END_HANDLE_TH_ERRORS</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æœ€ç»ˆå‡½æ•°è°ƒç”¨äº† <code>dispatch_addcmul()</code> è¿›è¡Œä¸‹ä¸€æ­¥è®¡ç®—ï¼Œè¯¥å‡½æ•°åœ¨åŒæ–‡ä»¶å¤¹çš„ <code>python_variable_methods_dispatch.h</code> ï¼Œå¯è§è¿™ä¸ªæ–‡ä»¶ä¹Ÿæ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå‡½æ•°å£°æ˜å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> Tensor <span class="title">dispatch_addcmul</span><span class="params">(Tensor &amp; self, Scalar value, <span class="keyword">const</span> Tensor &amp; tensor1, <span class="keyword">const</span> Tensor &amp; tensor2)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* é‡Šæ”¾GILé” */</span></span><br><span class="line">  AutoNoGIL no_gil;</span><br><span class="line">  <span class="comment">/* è°ƒç”¨ autograd::Variable.addcmul */</span></span><br><span class="line">  <span class="keyword">return</span> self.addcmul(tensor1, tensor2, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™ä¸ªå‡½æ•°é¦–å…ˆè·å–äº†GILé”ï¼Œç„¶åè°ƒç”¨C++å‰ç«¯ <code>Variable.addcmul()</code> è¿›è¡Œè®¡ç®—ï¼Œç”±äºåè€…å®ç°äº†è‡ªåŠ¨å¾®åˆ†ï¼Œæ‰€ä»¥Pythonè°ƒç”¨ä¹Ÿå…·æœ‰è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½ã€‚ä¸ºä»€ä¹ˆè¦é‡Šæ”¾GILé”ï¼Ÿå› ä¸ºè¿™æ ·æ‰èƒ½ä½¿å…¶ä¸Pythonè§£é‡Šå™¨ä¸­çš„å…¶ä»–è¿›ç¨‹ä¸€èµ·æ­£ç¡®çš„æ‰§è¡Œã€‚</p><p>ä¹Ÿå°±æ˜¯è¯´ï¼ŒPython Tensorçš„æ–¹æ³•çš„å°è£…æ€è·¯æ˜¯ï¼š</p><ul><li>ç”Ÿæˆdispatchç³»åˆ—å‡½æ•°ï¼Œè¯¥å‡½æ•°ç”¨äºé‡Šæ”¾GILé”ï¼Œç„¶åè°ƒç”¨Variableçš„å¯¹åº”å®ç°</li><li>ç”Ÿæˆå¯è¢«Pythonè°ƒç”¨çš„APIï¼Œè¯¥å‡½æ•°è§£æPythonå‚æ•°ï¼Œå¹¶è°ƒç”¨dispatchç³»åˆ—å‡½æ•°è¿›è¡Œå®é™…è®¡ç®—</li></ul><h3><span id="nn">NN</span></h3><p>ç¥ç»ç½‘ç»œçš„éƒ¨åˆ†å‡½æ•°ä¹Ÿæœ‰éƒ¨åˆ†å‡½æ•°æ˜¯ç›´æ¥ä» ATen ç»‘å®šè€Œæ¥ï¼Œç»‘å®šåˆ° <code>torch._C._nn</code> æ¨¡å—ä¸­ï¼Œä»£ç åœ¨ <code>csrc/autograd/generate/python_nn_functions.cpp</code> ä¸­ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> PyMethodDef nn_functions[] = &#123;</span><br><span class="line">  &#123;<span class="string">"_parse_to"</span>, (PyCFunction)THPVariable__parse_to, METH_VARARGS | METH_KEYWORDS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_avg_pool2d"</span>, (PyCFunction)THPVariable_adaptive_avg_pool2d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_avg_pool3d"</span>, (PyCFunction)THPVariable_adaptive_avg_pool3d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_max_pool2d"</span>, (PyCFunction)THPVariable_adaptive_max_pool2d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_max_pool3d"</span>, (PyCFunction)THPVariable_adaptive_max_pool3d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"avg_pool2d"</span>, (PyCFunction)THPVariable_avg_pool2d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"avg_pool3d"</span>, (PyCFunction)THPVariable_avg_pool3d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"binary_cross_entropy"</span>, (PyCFunction)THPVariable_binary_cross_entropy, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"elu"</span>, (PyCFunction)THPVariable_elu, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"elu_"</span>, (PyCFunction)THPVariable_elu_, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> initNNFunctions(PyObject* <span class="keyword">module</span>) &#123;</span><br><span class="line">#<span class="keyword">if</span> PY_MAJOR_VERSION == <span class="number">2</span></span><br><span class="line">  PyObject* nn = Py_InitModule(<span class="string">"torch._C._nn"</span>, nn_functions);</span><br><span class="line">  Py_XINCREF(nn);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  <span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyModuleDef</span> <span class="title">def</span> = &#123;</span></span><br><span class="line">     PyModuleDef_HEAD_INIT,</span><br><span class="line">     <span class="string">"torch._C._nn"</span>,</span><br><span class="line">     <span class="literal">NULL</span>,</span><br><span class="line">     <span class="number">-1</span>,</span><br><span class="line">     nn_functions</span><br><span class="line">  &#125;;</span><br><span class="line">  PyObject* nn = PyModule_Create(&amp;def);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="keyword">if</span> (!nn) &#123;</span><br><span class="line">    <span class="keyword">throw</span> python_error();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (PyModule_AddObject(<span class="keyword">module</span>, <span class="string">"_nn"</span>, nn) != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> python_error();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™é‡Œé¢æœ‰pooling, loss, convç­‰ç›¸å…³å‡½æ•°ï¼Œä¾›Pythoné‡Œçš„<code>nn.functional</code>è°ƒç”¨ã€‚</p><p>æ­¤å¤–ï¼Œä¸ºäº†æ–¹ä¾¿åœ¨Pythonä¸­è‡ªå®šä¹‰çš„è‡ªå¾®åˆ†çš„å‡½æ•°ï¼ŒPythoné‡Œä¹Ÿå®ç°äº†ä¸Šä¸€ç¯‡å¯¹åº”çš„Functionï¼š<code>torch.autograd.Function</code>ã€‚ç»§æ‰¿å®ƒï¼Œé‡è½½ <code>forward()</code> å’Œ <code>backward()</code> æ–¹æ³•å°±å¯ä»¥ç”¨Pythonå®ç°è‡ªå®šä¹‰çš„è‡ªå¾®åˆ†å‡½æ•°ï¼Œè¯¦è§<a href="https://pytorch.org/docs/stable/notes/extending.html" target="_blank" rel="noopener">æ–‡æ¡£</a>ã€‚</p><p><code>torch.autograd.Function</code> çš„å®šä¹‰åœ¨ <code>torch/autograd/function.py</code> ä¸­ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Function</span><span class="params">(with_metaclass<span class="params">(FunctionMeta, _C._FunctionBase, _ContextMethodMixin, _HookMixin)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># only for backward compatibility</span></span><br><span class="line">    __call__ = _C._FunctionBase._do_forward</span><br><span class="line"></span><br><span class="line">    <span class="comment"># for the tracer</span></span><br><span class="line">    is_traceable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, *args, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, *grad_outputs)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure><p>å®ƒç»§æ‰¿è‡ª <code>torch._C.FunctionBase</code>ï¼Œè¯¥ç±»å‹åœ¨ <code>csrc/autograd/python_function.cpp</code>ä¸­ç»‘å®šï¼Œå®ç°çš„é€»è¾‘å’Œ <code>autograd::Function</code> ä¸€æ ·ï¼Œä¹Ÿæ˜¯åœ¨å‰å‘è®¡ç®—æ—¶å»ºç«‹åå‘è®¡ç®—å›¾ï¼Œè¿™é‡Œå°±ä¸è¯»èµ˜è¿°äº†ã€‚ç»‘å®šéƒ¨åˆ†çš„ä»£ç å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THPFunction</span> &#123;</span></span><br><span class="line">    PyObject_HEAD</span><br><span class="line"></span><br><span class="line">    PyObject *needs_input_grad;</span><br><span class="line">    PyObject *to_save;</span><br><span class="line">    PyObject *non_differentiable;</span><br><span class="line">    PyObject *dirty_tensors;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;torch::autograd::VariableInfo&gt; output_info;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;torch::autograd::VariableInfo&gt; input_info;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;torch::autograd::SavedVariable&gt; saved_variables;</span><br><span class="line">    <span class="comment">// For each input, true if the input is a THPVariable</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; is_variable_input;</span><br><span class="line">    <span class="keyword">char</span> has_freed_buffers;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* PyFunctionç»§æ‰¿è‡ªFunctionï¼Œå®é™…è°ƒç”¨æœ€ç»ˆè½¬å‘åˆ°Functionä¸­ */</span></span><br><span class="line">    torch::autograd::PyFunction cdata;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyGetSetDef</span> <span class="title">THPFunction_properties</span>[] = &#123;</span></span><br><span class="line">  &#123;<span class="string">"saved_tensors"</span>, (getter)THPFunction_saved_tensors, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"saved_variables"</span>, (getter)THPFunction_saved_variables, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"next_functions"</span>, (getter)THPFunction_next_functions, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  ...</span><br><span class="line">  &#123;<span class="literal">nullptr</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyMethodDef</span> <span class="title">THPFunction_methods</span>[] = &#123;</span></span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"apply"</span>, (PyCFunction)THPFunction_apply, METH_CLASS | METH_VARARGS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"_do_forward"</span>, (PyCFunction)THPFunction_do_forward, METH_VARARGS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"_do_backward"</span>, (PyCFunction)THPFunction_do_backward, METH_VARARGS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"_register_hook_dict"</span>, (PyCFunction)THPFunction__register_hook_dict, METH_O, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"register_hook"</span>, (PyCFunction)THPFunction_register_hook, METH_O, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="literal">nullptr</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">PyTypeObject THPFunctionType = &#123;</span><br><span class="line">  PyVarObject_HEAD_INIT(<span class="literal">nullptr</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="string">"torch._C._FunctionBase"</span>,              <span class="comment">/* tp_name */</span></span><br><span class="line">  <span class="keyword">sizeof</span>(THPFunction),                   <span class="comment">/* tp_basicsize */</span></span><br><span class="line">  <span class="number">0</span>,                                     <span class="comment">/* tp_itemsize */</span></span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">THPFunction_initModule</span><span class="params">(PyObject *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (PyType_Ready(&amp;THPFunctionType) &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  Py_INCREF(&amp;THPFunctionType);</span><br><span class="line">  PyModule_AddObject(<span class="keyword">module</span>, <span class="string">"_FunctionBase"</span>, </span><br><span class="line">                     (PyObject *)&amp;THPFunctionType);</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ€»ç»“ä¸€ä¸‹ï¼š</p><ul><li><p><code>THPFunction</code> = <code>_C._FunctionBase</code></p></li><li><p>Pythonçš„<code>autograd.Function</code>ç»§æ‰¿è‡ªä¸Šé¢å®ç°è‡ªåŠ¨å¾®åˆ†</p></li></ul><p>å®Œ</p><table><thead><tr class="header"><th style="text-align: left;">ä¸Šä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch4/">Autograd</a></th><th style="text-align: right;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"></td><td style="text-align: right;"></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> PyTorch </tag>
            
            <tag> Pythonæ‰©å±• </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PyTorchæºç æµ…æ(4)ï¼šAutograd</title>
      <link href="/2019/05/05/PyTorch4/"/>
      <url>/2019/05/05/PyTorch4/</url>
      
        <content type="html"><![CDATA[<p>è¿™ç¯‡åšå®¢ä»‹ç» PyTorch ä¸­è‡ªåŠ¨å¾®åˆ†å¼•æ“çš„å®ç°ï¼Œä¸»è¦åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šé¦–å…ˆç®€è¦ä»‹ç»ä¸€ä¸‹è®¡ç®—å›¾çš„åŸç†ï¼›ç„¶åä»‹ç» PyTorch ä¸­ä¸ autograd çš„ç›¸å…³æ•°æ®ç»“æ„å’Œ <code>backward()</code>å‡½æ•°çš„å®ç°ï¼Œæ•°æ®ç»“æ„åŒ…æ‹¬ <code>torch::autograd::Variable</code>, <code>torch::autograd::Function</code> ç­‰ï¼›æœ€åè®²ä¸€ä¸‹åŠ¨æ€å»ºç«‹è®¡ç®—å›¾çš„å®ç°ï¼Œè¿™éƒ¨åˆ†ä»£ç æ¶‰åŠåˆ°åŠ¨æ€æ´¾å‘æœºåˆ¶ï¼Œè€Œä¸”éƒ½æ˜¯ç”¨è„šæœ¬ç”Ÿæˆçš„ï¼Œä¸å¤ªå®¹æ˜“ç†è§£ã€‚</p><a id="more"></a><p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#è®¡ç®—å›¾ç®€ä»‹">è®¡ç®—å›¾ç®€ä»‹</a></li><li><a href="#autograd-engine">Autograd Engine</a><ul><li><a href="#variable">Variable</a></li><li><a href="#autogradmeta">AutogradMeta</a></li><li><a href="#function-edge">Function &amp; Edge</a></li><li><a href="#engine">Engine</a></li></ul></li><li><a href="#åŠ¨æ€å»ºç«‹è®¡ç®—å›¾">åŠ¨æ€å»ºç«‹è®¡ç®—å›¾</a></li></ul><!-- tocstop --><h2><span id="è®¡ç®—å›¾ç®€ä»‹">è®¡ç®—å›¾ç®€ä»‹</span></h2><p>è®¡ç®—å›¾æ˜¯ä¸€ä¸ªæœ‰å‘å›¾ï¼Œå®ƒçš„æ¯ä¸ªèŠ‚ç‚¹éƒ½è¡¨ç¤ºä¸€ä¸ªå‡½æ•°ï¼ˆå¦‚åŠ å‡ä¹˜é™¤ç­‰ï¼‰æˆ–è€…è¾“å…¥æ•°æ®ï¼ˆå¶å­èŠ‚ç‚¹ï¼‰ã€‚è®¡ç®—å›¾çš„è¾¹ä»£è¡¨æ•°æ®æµå‘ï¼šæŒ‡å‘æŸä¸ªèŠ‚ç‚¹çš„è¾¹ä¸ºè¯¥èŠ‚ç‚¹çš„è¾“å…¥ï¼Œç”±è¯¥èŠ‚ç‚¹æµå‡ºçš„è¾¹è¡¨ç¤ºå®ƒçš„è¾“å‡ºã€‚è®¡ç®—å›¾å¯ä»¥ç”¨æ¥æè¿°ç¥ç»ç½‘ç»œçš„è®¡ç®—ï¼Œå¦‚ä¸‹å›¾æè¿°äº† <span class="math inline">\(y = \sin(xa+b)â€‹\)</span> çš„è®¡ç®—è¿‡ç¨‹ï¼š</p><p><img src="/images/pytorch/comp_graph.png"></p><p>è®¡ç®—å›¾çš„æ±‚å€¼åˆ†ä¸ºå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼Œåˆ†åˆ«ç”¨äºè®¡ç®—è¾“å‡ºå’Œæ¢¯åº¦ã€‚å‰å‘ä¼ æ’­çš„è¿‡ç¨‹å°±æ˜¯ä»å¶å­èŠ‚ç‚¹å¼€å§‹éå†è®¡ç®—å›¾ï¼Œç›´åˆ°æ•´ä¸ªå›¾éƒ½è¢«éå†è¿‡ï¼›è€Œåå‘ä¼ æ’­å°±æ˜¯ä»è¾“å‡ºèŠ‚ç‚¹å¼€å§‹éå†ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºçš„å‡½æ•°ä¹Ÿå˜ä¸ºåŸå‡½æ•°å¯¹è¾“å…¥çš„å¯¼æ•°ã€‚ä¸¾ä¸ªæ —å­ï¼Œä¸‹é¢æ˜¯<code>addcmul()</code>å‡½æ•°çš„è®¡ç®—å›¾çš„å‰å‘å’Œåå‘è®¡ç®—è¿‡ç¨‹ï¼š</p><p><img src="/images/pytorch/forward.gif"></p><h2><span id="autograd-engine">Autograd Engine</span></h2><p>ä»‹ç»å®Œäº†æ ‡å‡†çš„è®¡ç®—å›¾ç»“æ„ï¼Œé‚£ä¹ˆPyTorché‡Œé¢æ˜¯æ€ä¹ˆå®ç°çš„å‘¢ï¼Ÿåœ¨å›ç­”è¿™ä¸ªé—®é¢˜ä¹‹å‰é¦–å…ˆè¦çœ‹å‡ ä¸ªç›¸å…³çš„æ•°æ®ç»“æ„ï¼Œåˆ†åˆ«æ˜¯<code>Variable</code>, <code>AutogradMeta</code>, <code>Function</code>å’Œ<code>Edge</code>ã€‚</p><h3><span id="variable">Variable</span></h3><p>ç›¸ä¿¡ç”¨è¿‡è€ç‰ˆæœ¬çš„PyTorchçš„å°ä¼™ä¼´å¯¹<code>Variable</code>ä¸€å®šä¸ä¼šé™Œç”Ÿï¼Œå®ƒæ˜¯ç”¨æ¥å®ç°è‡ªåŠ¨å¾®åˆ†çš„æ ¸å¿ƒæ•°æ®ç»“æ„ï¼Œä»£ç åœ¨<code>torch/csrc/autograd/variable.h</code>ã€‚<code>Variable</code>å¯ä»¥è¡¨ç¤ºè®¡ç®—å›¾ä¸­çš„å¶å­èŠ‚ç‚¹ï¼Œå¦‚æƒé‡ï¼Œä¹Ÿå¯ä»¥è¡¨ç¤ºå›¾ä¸­çš„ä¸­é—´å˜é‡ï¼Œè™½ç„¶åœ¨æ–°ç‰ˆæœ¬ä¸­<code>Tensor</code>ä¸<code>Variable</code>åˆå¹¶äº†ï¼Œåœ¨å‰ç«¯ä¸­å¯ä»¥ç›´æ¥ç”¨<code>Tensor</code>ä»£æ›¿<code>Variable</code>ï¼Œä½†æ˜¯<code>Variable</code>å¹¶æ²¡æœ‰æ¶ˆå¤±ã€‚</p><p>å®ƒçš„å®ç°ç¡®å®æ”¹å˜äº†ï¼Œä½†åŠŸèƒ½ä¾æ—§ã€‚<code>Variable</code>ç»§æ‰¿è‡ª<code>at::Tensor</code>ï¼Œé‡è½½äº†<code>Tensor</code>é‡Œä¸æ¢¯åº¦è®¡ç®—ç›¸å…³çš„æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿæä¾›äº†å’Œ<code>Tensor</code>éšå¼è½¬æ¢çš„æ„é€ å‡½æ•°ã€‚</p><p><code>Variable</code>çš„åº•å±‚å®ç°<code>Variable::Impl</code>ä¹Ÿç»§æ‰¿<code>at::TensorImpl</code>ï¼Œè¿™ä¸ªç±»åœ¨<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/">æ­¤ç³»åˆ—çš„ç¬¬ä¸€ç¯‡</a>ä¸­ä»‹ç»è¿‡ï¼Œå®ƒé‡Œé¢æœ‰ä¸€ä¸ªæˆå‘˜<code>bool is_variable</code>ï¼Œç”¨äºè¯†åˆ«è¿™ä¸ª Tensor åˆ°åº•æ˜¯<code>at::Tensor</code>è¿˜æ˜¯<code>Variable</code>ã€‚<code>TensorImpl</code>é‡Œè¿˜æœ‰ä¸€ä¸ªé‡è¦çš„æˆå‘˜ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;c10::AutogradMetaInterface&gt; autograd_meta_=<span class="literal">nullptr</span>;</span><br></pre></td></tr></table></figure><p><code>autograd_meta_</code>è®°å½•äº†å½“å‰ä¸<code>Variable</code>ç›¸å…³çš„è®¡ç®—å›¾ä¿¡æ¯ï¼Œåœ¨<code>Variable::Impl</code>é‡Œå®ƒè¢«å¼ºåˆ¶è½¬æ¢æˆ<code>AutogradMeta*</code>ç±»å‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Variable::<span class="function">AutogradMeta* <span class="title">get_autograd_meta</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;Variable::AutogradMeta*&gt;(autograd_meta());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­<code>AutogradMeta</code>ç±»å‹å®ç°äº†<code>c10::AutogradMetaInterface</code>æ¥å£ã€‚</p><h3><span id="autogradmeta">AutogradMeta</span></h3><p><code>AutogradMeta</code>çš„å£°æ˜ä¹Ÿåœ¨<code>variable.h</code>ä¸­ï¼Œå®ƒçš„å£°æ˜å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TORCH_API</span> <span class="title">Variable</span>:</span>:AutogradMeta : <span class="keyword">public</span> c10::AutogradMetaInterface &#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> name;</span><br><span class="line"></span><br><span class="line">  Variable grad_;<span class="comment">// å­˜å‚¨æ¢¯åº¦</span></span><br><span class="line">  <span class="comment">// åå‘ä¼ æ’­å‡½æ•° for ä¸­é—´èŠ‚ç‚¹</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Function&gt; grad_fn_;</span><br><span class="line">  <span class="comment">// åå‘ä¼ æ’­å‡½æ•° for å¶èŠ‚ç‚¹ï¼ˆæƒé‡ï¼‰ï¼Œåªæ˜¯æŠŠæ¢¯åº¦ç´¯åŠ èµ·æ¥ç”¨æ¥æ›´æ–°</span></span><br><span class="line">  <span class="built_in">std</span>::weak_ptr&lt;Function&gt; grad_accumulator_;</span><br><span class="line"></span><br><span class="line">  VariableVersion version_counter_;</span><br><span class="line">  <span class="comment">// é¢„å¤„ç†</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;FunctionPreHook&gt;&gt; hooks_;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">bool</span> requires_grad_;</span><br><span class="line">  <span class="keyword">bool</span> is_view_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// è‹¥è¯¥Variableæ˜¯æŸä¸ªå‡½æ•°çš„è¾“å‡ºï¼Œé‚£ä¹ˆoutput_nr_è®°å½•å®ƒæ˜¯ç¬¬å‡ ä¸ªè¾“å‡º</span></span><br><span class="line">  <span class="keyword">uint32_t</span> output_nr_;</span><br><span class="line">  PyObject* pyobj_ = <span class="literal">nullptr</span>; <span class="comment">// weak reference</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::mutex mutex_;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_requires_grad</span><span class="params">(<span class="keyword">bool</span> requires_grad, at::TensorImpl* self_impl)</span> override </span>&#123;</span><br><span class="line">    <span class="comment">/* check */</span></span><br><span class="line">    requires_grad_ = requires_grad;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">requires_grad</span><span class="params">()</span> <span class="keyword">const</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requires_grad_ || grad_fn_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">Variable&amp; <span class="title">grad</span><span class="params">()</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> grad_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">const</span> Variable&amp; <span class="title">grad</span><span class="params">()</span> <span class="keyword">const</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> grad_;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>ä»å£°æ˜ä¸­å¯ä»¥çœ‹å‡º<code>AutogradMeta</code>ä¸ä½†å­˜å‚¨äº†æ¢¯åº¦ï¼Œè¿˜å­˜å‚¨äº†è¯¥<code>Variable</code>å¯¹åº”çš„åå‘ä¼ æ’­å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯è®¡ç®—å›¾çš„èŠ‚ç‚¹ã€‚</p><p>PyTorchåªå»ºç«‹åå‘ä¼ æ’­çš„è®¡ç®—å›¾ï¼Œå› ä¸ºå…¶å®å‰å‘ä¼ æ’­æ˜¯ç”¨æˆ·è‡ªå·±å®šä¹‰çš„ï¼Œä¸ç”¨PyTorchå¹²ä»€ä¹ˆã€‚ä½†æ˜¯åœ¨ç”¨æˆ·åœ¨å®šä¹‰å‰å‘è¿æ¥çš„æ—¶å€™ï¼ŒPyTorchéœ€è¦å·å·å»ºç«‹åå‘è¿æ¥ï¼Œå…·ä½“æ€ä¹ˆæ“ä½œè§ä¸‹ä¸€èŠ‚ã€‚PyTorché‡Œè®¡ç®—å›¾çš„èŠ‚ç‚¹å…¨éƒ¨éƒ½æ˜¯<code>Function</code>ï¼Œç”±äºåªè®¡ç®—å›¾åªç”¨äºåå‘ä¼ æ’­ï¼Œæ‰€ä»¥ <code>Function</code> å®ç°éƒ½æ˜¯åå‘ä¼ æ’­å‡½æ•°ã€‚å¯¹äºè®¡ç®—å›¾ä¸­çš„ä¸­é—´ç»“æœï¼Œå¯¹åº”çš„<code>grad_fn_</code>æ˜¯ç›¸åº”çš„åå‘ä¼ æ’­å‡½æ•°ï¼›è€Œå¯¹äºå¶èŠ‚ç‚¹ï¼ˆæƒé‡ï¼‰ï¼Œå¯¹åº”çš„<code>grad_fn_</code>ä¸º<code>nullptr</code>ï¼Œè€Œ<code>grad_accumulator_</code>ä¸ºå…¶ç›¸åº”çš„å¤„ç†å‡½æ•°ï¼Œå°±æ˜¯æŠŠæ¢¯åº¦ç´¯åŠ å­˜å‚¨åˆ°<code>grad_</code>é‡Œã€‚é™¤æ­¤ä¹‹å¤–ï¼Œä¸éœ€è¦æ¢¯åº¦çš„è¾“å…¥æ˜¯ä¸ä¼šè¿›å…¥è®¡ç®—å›¾ä¸­çš„ã€‚</p><p>ä»”ç»†è§‚å¯Ÿæˆ‘ä»¬ä¼šå‘ç°ï¼Œ<code>Variable</code>é‡Œæ‹¥æœ‰<code>AutogradMeta</code>ï¼Œè€Œåè€…é‡Œç”¨æœ‰<code>Function</code>ï¼Œæ‰€ä»¥å®é™…ä¸Š<code>Variable</code>å’Œå®ƒçš„<code>grad_fn_</code>æ˜¯ç»‘å®šçš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œä¸€ä¸ª<code>Variable</code>åªèƒ½æœ‰ä¸€ä¸ª<code>grad_fn_</code>ï¼Œä½†åè¿‡æ¥åˆ™ä¸ä¸€å®šï¼Œä¸€ä¸ª<code>grad_fn_</code>ä¹Ÿå¯èƒ½å±äºå¤šä¸ª<code>Variable</code>ï¼ˆå¦‚æœæ­£å‘ä¼ æ’­å‡½æ•°è¾“å‡ºå¾ˆå¤šçš„è¯ï¼Œé‚£ä¹ˆè¿™äº›è¾“å‡ºå…±äº«ä¸€ä¸ªåå‘ä¼ æ’­å‡½æ•°ï¼‰ã€‚</p><h3><span id="function-amp-edge">Function &amp; Edge</span></h3><p><code>Function</code>å’Œ<code>Edge</code>å®ç°æ˜¯ç´§å¯†ç›¸è¿çš„ï¼Œ<code>Function</code>æœ¬è´¨æ˜¯ä¸€ä¸ªå‡½æ•°å¯¹è±¡ï¼Œå¯ä»¥å½“ä½œåå‘ä¼ æ’­çš„å‡½æ•°æ¥ç”¨ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œ<code>Function</code>é‡Œè¿˜æœ‰ä¸€ä¸ªæˆ <code>edge_list next_edges_;</code>ï¼Œæ˜¯ä¸è¯¥èŠ‚ç‚¹ç›¸è¿çš„è¾¹ã€‚PyTorchçš„è®¡ç®—å›¾ä¸­çš„è¾¹å…¶å®å°±æ˜¯<code>{function, input_nr}</code>pairï¼šå‰è€…è¡¨ç¤ºè¿™æ¡è¾¹æŒ‡å‘å“ªä¸ªèŠ‚ç‚¹ï¼Œåè€…è¡¨ç¤ºæœ¬èŠ‚ç‚¹æ˜¯ç›®æ ‡èŠ‚ç‚¹çš„ç¬¬å‡ ä¸ªè¾“å…¥ï¼ˆä»0å¼€å§‹ï¼‰ã€‚</p><p><code>Function</code>çš„å®ç°åœ¨<code>csrc/autograd/function.h</code>ï¼Œå¤§è‡´å£°æ˜å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TORCH_API</span> <span class="title">Function</span> :</span> <span class="built_in">std</span>::enable_shared_from_this&lt;Function&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">/* æ„é€ å‡½æ•°ç•¥ */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// ä¸å¯æ‹·è´æˆ–ç§»åŠ¨</span></span><br><span class="line">  Function(<span class="keyword">const</span> Function&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  Function(Function&amp;&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  Function&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Function&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  Function&amp; <span class="keyword">operator</span>=(Function&amp;&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  <span class="keyword">virtual</span> ~Function() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// é‡è½½()è¿ç®—ç¬¦å®ç°å‡½æ•°å¯¹è±¡åŠŸèƒ½ï¼Œéœ€é‡è½½applyå‡½æ•°</span></span><br><span class="line">  <span class="comment">// è¯¥å‡½æ•°æ¥æ”¶ä¸€ç³»åˆ—variableï¼Œè¿”å›ä¸€ç³»åˆ—variable</span></span><br><span class="line">  <span class="function">variable_list <span class="title">operator</span><span class="params">()</span><span class="params">(variable_list&amp;&amp; inputs)</span> </span>&#123;</span><br><span class="line">    profiler::<span class="function">RecordFunction <span class="title">rec</span><span class="params">(<span class="keyword">this</span>)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> apply(<span class="built_in">std</span>::move(inputs));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// æœ‰å…³è®¡ç®—å›¾çš„ API</span></span><br><span class="line">  <span class="comment">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">const</span> Edge&amp; <span class="title">next_edge</span><span class="params">(<span class="keyword">size_t</span> index)</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_[index];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_next_edge</span><span class="params">(<span class="keyword">size_t</span> index, Edge edge)</span> </span>&#123;</span><br><span class="line">    next_edges_[index] = <span class="built_in">std</span>::move(edge);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">add_next_edge</span><span class="params">(Edge edge)</span> </span>&#123;</span><br><span class="line">    next_edges_.push_back(<span class="built_in">std</span>::move(edge));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_next_edges</span><span class="params">(edge_list&amp;&amp; next_edges)</span> </span>&#123;</span><br><span class="line">    next_edges_ = <span class="built_in">std</span>::move(next_edges);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">const</span> edge_list&amp; <span class="title">next_edges</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">edge_list&amp; <span class="title">next_edges</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">uint32_t</span> num_outputs() <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_.size();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="function"><span class="keyword">static</span> uint64_t&amp; <span class="title">get_next_sequence_nr</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// éœ€è¦é‡è½½çš„applyå‡½æ•°ï¼Œå®ç°å®é™…åŠŸèƒ½</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> variable_list <span class="title">apply</span><span class="params">(variable_list&amp;&amp; inputs)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">variable_list <span class="title">traced_apply</span><span class="params">(variable_list inputs)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// å‡½æ•°åºåˆ—å·</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">uint64_t</span> sequence_nr_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ä¿å­˜é‚»è¾¹</span></span><br><span class="line">  edge_list next_edges_;</span><br><span class="line">  PyObject* pyobj_ = <span class="literal">nullptr</span>; <span class="comment">// weak reference</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;AnomalyMetadata&gt; anomaly_metadata_ = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;FunctionPreHook&gt;&gt; pre_hooks_;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;FunctionPostHook&gt;&gt; post_hooks_;</span><br><span class="line">  at::SmallVector&lt;InputMetadata, <span class="number">2</span>&gt; input_metadata_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>Edge</code>çš„å£°æ˜åœ¨<code>csrc/autograd/edge.h</code>ï¼Œå®ƒçš„å£°æ˜å°±å¾ˆç®€å•äº†ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Edge</span> &#123;</span></span><br><span class="line">  Edge() <span class="keyword">noexcept</span> : function(<span class="literal">nullptr</span>), input_nr(<span class="number">0</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  Edge(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Function&gt; function_, <span class="keyword">uint32_t</span> input_nr_) <span class="keyword">noexcept</span></span><br><span class="line">      : function(<span class="built_in">std</span>::move(function_)), input_nr(input_nr_) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Convenience method to test if an edge is valid.</span></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">is_valid</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> function != <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Required for use in associative containers.</span></span><br><span class="line">  <span class="keyword">bool</span> <span class="keyword">operator</span>==(<span class="keyword">const</span> Edge&amp; other) <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>-&gt;function == other.function &amp;&amp; <span class="keyword">this</span>-&gt;input_nr == other.input_nr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">bool</span> <span class="keyword">operator</span>!=(<span class="keyword">const</span> Edge&amp; other) <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> !(*<span class="keyword">this</span> == other);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ç›®æ ‡å‡½æ•°</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Function&gt; function;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// ç¬¬å‡ ä¸ªè¾“å…¥</span></span><br><span class="line">  <span class="keyword">uint32_t</span> input_nr;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>æ€»ç»“ä¸€ä¸‹ï¼Œ<code>Variable</code>ï¼Œ<code>AutogradMeta</code>ï¼Œ<code>Function</code>å’Œ<code>Edge</code>çš„å¤§è‡´å…³ç³»å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/pytorch/Variable.svg"></p><h3><span id="engine">Engine</span></h3><p>æˆ‘ä»¬å…ˆä¸çœ‹æ€ä¹ˆå»ºç«‹è®¡ç®—å›¾ï¼Œè€Œæ˜¯å…ˆå‡è®¾å›¾å·²ç»å»ºç«‹å¥½ï¼Œè€ƒè™‘å…·ä½“æ€ä¹ˆæ‰§è¡Œåå‘ä¼ æ’­ã€‚ä½ å¯èƒ½è§‰å¾—ç­”æ¡ˆå·²ç»å¾ˆæ˜æ˜¾äº†ï¼Œä¸å°±æ˜¯å¯¹å›¾è¿›è¡Œéå†ä¹ˆï¼Œæ²¡é”™ï¼Œæ˜¯å¯¹å›¾è¿›è¡Œéå†ï¼Œä½†è€ƒè™‘åˆ°æ•ˆç‡ä»¥åŠè¦åœ¨ä¸åŒè®¾å¤‡ä¸Šè®¡ç®—ï¼Œå®é™…æ“ä½œèµ·æ¥è¿˜æ˜¯æœ‰ç‚¹éº»çƒ¦çš„ï¼Œè¿™éƒ¨åˆ†ä»£ç ä¸»è¦ç”±<code>autograd::Engine</code>å®ç°ï¼Œå£°æ˜å’Œå®ç°åˆ†åˆ«åœ¨<code>csrc/autograd/engine.h</code>å’Œ<code>csrc/autograd/engine.cpp</code>ä¸­ã€‚</p><p>ç”¨ PyTorch å»ºç«‹ç¥ç»ç½‘ç»œçš„æ—¶å€™ï¼Œç›¸ä¿¡ä½ ä¸€å®šç”¨è¿‡<code>loss.backward()</code>æ¥è¿›è¡Œåå‘ä¼ æ’­ï¼Œé‚£å°±ä»<code>Variable::backward()</code>å‡½æ•°å¼€å§‹ä¸€æ­¥ä¸€æ­¥çœ‹åå‘ä¼ æ’­æ˜¯æ€ä¹ˆæ‰§è¡Œçš„ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Variable::backward(</span><br><span class="line">    c10::optional&lt;Tensor&gt; gradient,</span><br><span class="line">    <span class="keyword">bool</span> keep_graph,</span><br><span class="line">    <span class="keyword">bool</span> create_graph) <span class="keyword">const</span> &#123;</span><br><span class="line">  <span class="comment">// è·å– AutogradMeta</span></span><br><span class="line">  <span class="keyword">auto</span> autograd_meta = get_autograd_meta();</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// æ„é€ èµ·å§‹è¾¹ï¼Œåšä¸ºéå†çš„èµ·ç‚¹ï¼ˆå›¾çš„rootï¼‰</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Edge&gt; edges;</span><br><span class="line">  edges.emplace_back(autograd_meta-&gt;grad_fn_, autograd_meta-&gt;output_nr_);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// æ„é€ è¾“å…¥ï¼švariable list</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Variable&gt; inputs;</span><br><span class="line">  inputs.push_back(<span class="built_in">std</span>::move(as_variable_ref(*gradient)));</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// è°ƒç”¨ execute è¿›è¡Œåå‘ä¼ æ’­</span></span><br><span class="line">  Engine::get_default_engine().execute(edges, inputs, keep_graph, create_graph);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å‡½æ•°é¦–å…ˆæ„é€ éå†çš„èµ·ç‚¹å’Œè¾“å…¥ï¼Œç„¶åè°ƒç”¨<code>Engine::execute()</code>è¿›è¡Œè®¡ç®—ï¼Œå…¶ä¸­<code>Engine::get_default_engine()</code>è¿”å›çš„æ˜¯<code>Engine</code>çš„å®ä¾‹ã€‚</p><p>æ¥ç€ç ”ç©¶<code>Engine::execute()</code>ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::execute(<span class="keyword">const</span> edge_list&amp; roots,</span><br><span class="line">                     <span class="keyword">const</span> variable_list&amp; inputs,</span><br><span class="line">                     <span class="keyword">bool</span> keep_graph,</span><br><span class="line">                     <span class="keyword">bool</span> create_graph,</span><br><span class="line">                     <span class="keyword">const</span> edge_list&amp; outputs) -&gt; variable_list &#123;</span><br><span class="line">  <span class="comment">// å¯åŠ¨å¤šçº¿ç¨‹ï¼ˆæ¯ä¸ªè®¾å¤‡ä¸€ä¸ªçº¿ç¨‹ï¼‰</span></span><br><span class="line">  <span class="built_in">std</span>::call_once(start_threads_flag, &amp;Engine::start_threads, <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* éªŒè¯outputs */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// è®°å½•è®¡ç®—å›¾çš„ä»»åŠ¡</span></span><br><span class="line">  <span class="function">GraphTask <span class="title">graph_task</span><span class="params">(keep_graph, create_graph)</span></span>;</span><br><span class="line">  <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lock(graph_task.mutex);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// éå†ä¸€éè®¡ç®—å›¾ï¼Œè®¡ç®—æ¯ä¸ªå‡½æ•°çš„ä¾èµ–</span></span><br><span class="line">  <span class="comment">// æ‰€è°“æŸå‡½æ•°çš„ä¾èµ–å°±æ˜¯æœ‰å‡ æ¡è¾¹æŒ‡å‘è¯¥å‡½æ•°ï¼Œç”¨å›¾çš„æœ¯è¯­è¯´å°±æ˜¯èŠ‚ç‚¹çš„å…¥åº¦</span></span><br><span class="line">  <span class="comment">// ä¾èµ–å¤§äºé›¶ï¼ˆå…¥åº¦&gt;0ï¼‰çš„èŠ‚ç‚¹ä¸èƒ½å¤Ÿæ‰§è¡Œ</span></span><br><span class="line">  <span class="keyword">auto</span> graph_root = <span class="built_in">std</span>::make_shared&lt;GraphRoot&gt;(roots, inputs);</span><br><span class="line">  compute_dependencies(graph_root.get(), graph_task);</span><br><span class="line">  <span class="keyword">if</span> (!outputs.empty()) &#123;</span><br><span class="line">    graph_task.init_to_execute(*graph_root, outputs);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// æŠŠrootåŠ å…¥å‡†å¤‡é˜Ÿåˆ—ï¼Œæ¯ä¸ªè®¾å¤‡æœ‰ä¸€ä¸ªå‡†å¤‡é˜Ÿåˆ—ï¼Œ-1ä»£è¡¨CPU</span></span><br><span class="line">  ready_queue(<span class="number">-1</span>).push(FunctionTask(&amp;graph_task, <span class="built_in">std</span>::move(graph_root), InputBuffer(<span class="number">0</span>)));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (worker_device == NO_DEVICE) &#123;</span><br><span class="line">    <span class="comment">// éå·¥ä½œçº¿ç¨‹ï¼šè€è€å®å®ç­‰å¾…å›¾è®¡ç®—å®Œæ¯•</span></span><br><span class="line">    graph_task.not_done.wait(lock, [&amp;graph_task]&#123;</span><br><span class="line">      <span class="keyword">return</span> graph_task.outstanding_tasks.load() == <span class="number">0</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// å·¥ä½œçº¿ç¨‹ï¼š996!</span></span><br><span class="line">    graph_task.owner = worker_device;</span><br><span class="line">    lock.unlock();</span><br><span class="line">    <span class="comment">// çº¿ç¨‹ä¸»å¾ªç¯</span></span><br><span class="line">    thread_main(&amp;graph_task);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* check exceptions */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> graph_task.captured_vars;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Engine::execute()</code>é‡Œåšäº†è¿™å‡ ä»¶äº‹ï¼ˆå¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªå…¬å¸ï¼‰ï¼š</p><ul><li>æ‹›è˜å‘˜å·¥ï¼ˆå¯åŠ¨å¤šçº¿ç¨‹ï¼‰</li><li>æ˜ç¡®æ•´ä½“ä»»åŠ¡ï¼ˆè®¡ç®—ä¾èµ–ï¼‰</li><li>å‡†å¤‡ç¬¬ä¸€ä»½å·¥ä½œï¼ˆæŠŠ<code>root</code>åŠ å…¥å‡†å¤‡é˜Ÿåˆ—ï¼‰</li><li>å¼€å§‹å·¥ä½œï¼</li></ul><p>é¦–å…ˆçœ‹å¯åŠ¨å¤šçº¿ç¨‹çš„ä»£ç ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::start_threads() -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">// è·å–GPUæ•°ç›®</span></span><br><span class="line">  <span class="keyword">int</span> num_devices = at::getNumGPUs();</span><br><span class="line">  <span class="comment">// çº¿ç¨‹æ•° = GPUæ•° + 1 (for CPU)</span></span><br><span class="line">  <span class="keyword">int</span> num_threads = num_devices + <span class="number">1</span>;</span><br><span class="line">  ready_queues = <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;ReadyQueue&gt;&gt;(num_threads);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; <span class="built_in">queue</span> : ready_queues)</span><br><span class="line">    <span class="comment">// åˆå§‹åŒ–æ¯ä¸ªè®¾å¤‡çš„å‡†å¤‡é˜Ÿåˆ—</span></span><br><span class="line">    <span class="built_in">queue</span>.reset(<span class="keyword">new</span> ReadyQueue());</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_threads; ++i) &#123;</span><br><span class="line">    <span class="comment">// èµ‹äºˆæ¯ä¸ªçº¿ç¨‹å¯¹åº”çš„ deviceï¼Œç„¶åè¿›å…¥ thread_main()</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="function">thread <span class="title">t</span><span class="params">(&amp;Engine::thread_init, <span class="keyword">this</span>, i - <span class="number">1</span>)</span></span>;</span><br><span class="line">    t.detach();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ¥ä¸‹æ¥çœ‹å¦‚ä½•è®¡ç®—ä¾èµ–ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::compute_dependencies(Function* root, GraphTask&amp; task) -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">// è®°å½•å·²è®¿é—®è¿‡èŠ‚ç‚¹</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_set</span>&lt;Function*&gt; seen;</span><br><span class="line">  <span class="comment">// èŠ‚ç‚¹é˜Ÿåˆ—ï¼Œç”¨äºBFS</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Function*&gt; <span class="built_in">queue</span> &#123; root &#125;;</span><br><span class="line"><span class="comment">// è®°å½•ä¾èµ–çš„æ•°æ®ç»“æ„ï¼Œç±»å‹ä¸º unordered_map&lt;Function*, int&gt;</span></span><br><span class="line">  <span class="keyword">auto</span>&amp; dependencies = task.dependencies;</span><br><span class="line">  <span class="comment">// BFS</span></span><br><span class="line">  <span class="keyword">while</span> (!<span class="built_in">queue</span>.empty()) &#123;</span><br><span class="line">    <span class="keyword">auto</span> fn = <span class="built_in">queue</span>.back(); <span class="built_in">queue</span>.pop_back();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; edge : fn-&gt;next_edges()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">auto</span> next_ptr = edge.function.get()) &#123;</span><br><span class="line">        <span class="comment">// ç›®æ ‡èŠ‚ç‚¹çš„ä¾èµ–+1</span></span><br><span class="line">        dependencies[next_ptr] += <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">bool</span> was_inserted = seen.insert(next_ptr).second;</span><br><span class="line">        <span class="keyword">if</span> (was_inserted) <span class="built_in">queue</span>.push_back(next_ptr);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æœ€åæ¥çœ‹æœ€ä¸»è¦çš„<code>thread_main()</code>ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::thread_main(GraphTask *graph_task) -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">// è·å–å½“å‰è¿›ç¨‹çš„å‡†å¤‡é˜Ÿåˆ—</span></span><br><span class="line">  <span class="keyword">auto</span> <span class="built_in">queue</span> = ready_queues[worker_device + <span class="number">1</span>];</span><br><span class="line">  <span class="comment">// å·¥ä½œæ²¡å®Œæˆä¹‹å‰ä¸èƒ½ä¸‹ç­ï¼š</span></span><br><span class="line">  <span class="keyword">while</span> (!graph_task || graph_task-&gt;outstanding_tasks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// è·å–æœ€æ–°å·¥ä½œï¼Œpop()æ˜¯é˜»å¡çš„ï¼Œåªæœ‰æ¥å·¥ä½œäº†æ‰ä¼šç»§ç»­æ‰§è¡Œ</span></span><br><span class="line">    <span class="comment">// ç”Ÿäº§è€…æ¶ˆè´¹è€…æ¨¡å‹</span></span><br><span class="line">    FunctionTask task = <span class="built_in">queue</span>-&gt;pop();</span><br><span class="line">    <span class="keyword">if</span> (task.fn &amp;&amp; !task.base-&gt;has_error.load()) &#123;</span><br><span class="line">      GradMode::set_enabled(task.base-&gt;grad_mode);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// æ‰§è¡Œè¯¥ä»»åŠ¡</span></span><br><span class="line">        evaluate_function(task);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (<span class="built_in">std</span>::exception&amp; e) &#123;</span><br><span class="line">        thread_on_exception(task, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// æ‰¾åˆ°å‘å¸ƒä»»åŠ¡çš„äºº</span></span><br><span class="line">    <span class="keyword">auto</span> base_owner = task.base-&gt;owner;</span><br><span class="line">    <span class="comment">// è‹¥è¯¥ä»»åŠ¡æ¥è‡ªéå·¥ä½œçº¿ç¨‹ï¼ˆi.e.s é¢†å¯¼çº¿ç¨‹ï¼Œå‘å·æ–½ä»¤ï¼‰ï¼š</span></span><br><span class="line">    <span class="keyword">if</span> (base_owner == NO_DEVICE) &#123;</span><br><span class="line">      <span class="comment">// è‡ªå‡å‰©ä½™ä»»åŠ¡æ•°</span></span><br><span class="line">      <span class="keyword">if</span> (--task.base-&gt;outstanding_tasks == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// æ‰€æœ‰ä»»åŠ¡å®Œæ¯•ï¼Œé€šçŸ¥å¤§ä¼™ä¸‹ç­</span></span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(task.base-&gt;mutex);</span><br><span class="line">        task.base-&gt;not_done.notify_all();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// å¦‚æœä»»åŠ¡å‘å¸ƒè€…æ˜¯è‡ªå·±ï¼š</span></span><br><span class="line">      <span class="keyword">if</span> (base_owner == worker_device) &#123;</span><br><span class="line">        <span class="comment">// è‡ªå‡å‰©ä½™ä»»åŠ¡æ•°</span></span><br><span class="line">        --task.base-&gt;outstanding_tasks;</span><br><span class="line">      <span class="comment">// å¦‚æœä»»åŠ¡å‘å¸ƒè‡ªå…¶ä»–å·¥äººï¼š</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (base_owner != worker_device) &#123;</span><br><span class="line">        <span class="comment">// è‡ªå‡å‰©ä½™ä»»åŠ¡æ•°</span></span><br><span class="line">        <span class="keyword">if</span> (--task.base-&gt;outstanding_tasks == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="comment">// æé†’ä»–ä»¬é‚£ä¸ªä»»åŠ¡åšå®Œäº†</span></span><br><span class="line">          <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_release);</span><br><span class="line">          ready_queue(base_owner).push(FunctionTask(task.base, <span class="literal">nullptr</span>, InputBuffer(<span class="number">0</span>)));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>thread_main()</code>é‡Œæ²¡æœ‰å…·ä½“æ‰§è¡Œä»»åŠ¡çš„ä»£ç ï¼Œè€Œæ˜¯æŠŠå®ƒå•ç‹¬æŠ½å‡ºå˜æˆä¸€ä¸ªæ–¹æ³•ï¼Œä¸‹é¢çœ‹è¯¥æ–¹æ³•éƒ½å¹²äº†ä»€ä¹ˆï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::evaluate_function(FunctionTask&amp; task) -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">/* exec info blabla... */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// è°ƒç”¨ task é‡Œçš„å‡½æ•°è·å–è¾“å‡ºï¼ŒåŸºæœ¬ç›¸å½“äº (*task.fn)()</span></span><br><span class="line">  <span class="keyword">auto</span> outputs = call_function(task);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span>&amp; fn = *task.fn;</span><br><span class="line">  <span class="comment">// å¦‚æœä¸ä¿ç•™å›¾çš„è¯å°±æŠŠå½“å‰èŠ‚ç‚¹é‡Šæ”¾äº†</span></span><br><span class="line">  <span class="keyword">if</span> (!task.base-&gt;keep_graph) &#123;</span><br><span class="line">    fn.release_variables();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// è·å–è¾“å‡ºä¸ªæ•°</span></span><br><span class="line">  <span class="keyword">int</span> num_outputs = outputs.size();</span><br><span class="line">  <span class="comment">// å¦‚æœæ²¡æœ‰è¾“å‡ºè¿™ä¸ªä»»åŠ¡å°±å®Œæˆäº†ï¼Œç›´æ¥è¿”å›</span></span><br><span class="line">  <span class="keyword">if</span> (num_outputs == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(task.base-&gt;mutex);</span><br><span class="line">  <span class="comment">// éå†æ¯ä¸ªè¾“å‡ºï¼ˆéå†ä¸ä¹‹ç›¸é‚»çš„èŠ‚ç‚¹ï¼‰ï¼š</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_outputs; ++i) &#123;</span><br><span class="line">    <span class="keyword">auto</span>&amp; output = outputs[i];</span><br><span class="line">    <span class="comment">// è·å–ç¬¬iæ¡è¾¹ï¼ˆæŒ‡å‘ç¬¬iä¸ªè¾“å‡ºæ‰€å¯¹åº”çš„å‡½æ•°ï¼‰</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span>&amp; next = fn.next_edge(i);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!next.is_valid()) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// æ£€æŸ¥è¿™æ¡è¾¹æ˜¯å¦å‡†å¤‡å¥½ï¼ˆä¾èµ–æ˜¯å¦ä¸º0ï¼‰</span></span><br><span class="line">    <span class="keyword">bool</span> is_ready = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">auto</span>&amp; dependencies = task.base-&gt;dependencies;</span><br><span class="line">    <span class="comment">// è·å–è¿™æ¡è¾¹çš„ä¾èµ–æ•°</span></span><br><span class="line">    <span class="keyword">auto</span> it = dependencies.find(next.function.get());</span><br><span class="line">    <span class="keyword">if</span> (it == dependencies.end()) &#123;</span><br><span class="line">      <span class="comment">/* æ²¡æ‰¾åˆ°ï¼ŒæŠ›å‡ºå¼‚å¸¸ */</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (--it-&gt;second == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// ä¾èµ–è‡ªå‡åç­‰äºé›¶ï¼Œè¯´æ˜è¯¥ä»»åŠ¡å·²å‡†å¤‡å¥½</span></span><br><span class="line">      dependencies.erase(it);</span><br><span class="line">      is_ready = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// è·å–/åˆ›å»ºè¯¥èŠ‚ç‚¹çš„ input_buffer</span></span><br><span class="line">    <span class="keyword">auto</span>&amp; not_ready = task.base-&gt;not_ready;</span><br><span class="line">    <span class="keyword">auto</span> not_ready_it = not_ready.find(next.function.get());</span><br><span class="line">    <span class="comment">// è¿˜æ²¡æœ‰ä¸ºè¯¥èŠ‚ç‚¹åˆ†é… input_buffer:</span></span><br><span class="line">    <span class="keyword">if</span> (not_ready_it == not_ready.end()) &#123;</span><br><span class="line">      <span class="comment">/* è·³è¿‡é‚£äº›ä¸è¯¥è¢«æ‰§è¡Œçš„å‡½æ•° */</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment">// ç”¨ output æ„é€ è¯¥èŠ‚ç‚¹çš„ input_buffer</span></span><br><span class="line">      <span class="function">InputBuffer <span class="title">input_buffer</span><span class="params">(next.function-&gt;num_inputs())</span></span>;</span><br><span class="line">      input_buffer.add(next.input_nr, <span class="built_in">std</span>::move(output));</span><br><span class="line">      <span class="keyword">if</span> (is_ready) &#123;</span><br><span class="line">        <span class="comment">// å‡†å¤‡å¥½å°±åŠ å…¥å‡†å¤‡é˜Ÿåˆ—</span></span><br><span class="line">        <span class="keyword">auto</span>&amp; <span class="built_in">queue</span> = ready_queue(input_buffer.device());</span><br><span class="line">        <span class="built_in">queue</span>.push(FunctionTask(task.base, next.function, <span class="built_in">std</span>::move(input_buffer)));</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// æ²¡å‡†å¤‡å¥½å°±ç¼“å­˜ input_buffer</span></span><br><span class="line">        not_ready.emplace(next.function.get(), <span class="built_in">std</span>::move(input_buffer));</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">// è¯¥èŠ‚ç‚¹å·²æœ‰ input_buffer:</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// å‘å·²æœ‰ input_buffer é‡Œæ·»åŠ æ–°çš„è¾“å…¥</span></span><br><span class="line">      <span class="keyword">auto</span> &amp;input_buffer = not_ready_it-&gt;second;</span><br><span class="line">      input_buffer.add(next.input_nr, <span class="built_in">std</span>::move(output));</span><br><span class="line">      <span class="keyword">if</span> (is_ready) &#123;</span><br><span class="line">        <span class="comment">// å‡†å¤‡å¥½å°±åŠ å…¥å‡†å¤‡é˜Ÿåˆ—</span></span><br><span class="line">        <span class="keyword">auto</span>&amp; <span class="built_in">queue</span> = ready_queue(input_buffer.device());</span><br><span class="line">        <span class="built_in">queue</span>.push(FunctionTask(task.base, next.function, <span class="built_in">std</span>::move(input_buffer)));</span><br><span class="line">        <span class="comment">// ä»è¾“å…¥ç¼“å­˜é‡Œåˆ é™¤è¯¥èŠ‚ç‚¹</span></span><br><span class="line">        not_ready.erase(not_ready_it);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å¥½ï¼Œè‡³æ­¤æ‰§è¡Œè®¡ç®—å›¾çš„ä»£ç å°±æ¢³ç†å®Œäº†ï¼Œç®€å•æ€»ç»“ä¸€ä¸‹ï¼š</p><ul><li>æŠŠè°ƒç”¨<code>backward()</code>çš„èŠ‚ç‚¹è®¾ä¸ºæ ¹èŠ‚ç‚¹ï¼Œä»è¯¥èŠ‚ç‚¹å¼€å§‹éå†</li><li>é¦–å…ˆBFSä¸€éè®¡ç®—å›¾ï¼Œè®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„ä¾èµ–</li><li>ä¸ºæ¯ä¸ªè®¾å¤‡å»ºç«‹ä¸€ä¸ªå·¥ä½œçº¿ç¨‹ï¼Œæ¯ä¸ªçº¿ç¨‹é‡Œæœ‰ä¸€ä¸ªå‡†å¤‡é˜Ÿåˆ—<ul><li>æ¯ä¸ªçº¿ç¨‹ç­‰å¾…ä»»åŠ¡åˆ°æ¥ç›´åˆ°ä»»åŠ¡å…¨éƒ¨å®Œæˆ</li><li>å®Œæˆä¸€ä¸ªä»»åŠ¡åéå†ä¸ä¹‹ç›¸é‚»çš„èŠ‚ç‚¹ï¼Œæ›´æ–°ä»–ä»¬çš„ä¾èµ–(-1)ï¼Œè‹¥ä¾èµ–ä¸º0åˆ™åŠ å…¥å‡†å¤‡é˜Ÿåˆ—</li></ul></li></ul><h2><span id="åŠ¨æ€å»ºç«‹è®¡ç®—å›¾">åŠ¨æ€å»ºç«‹è®¡ç®—å›¾</span></h2><p>è¿™ä¸€å°èŠ‚ä»‹ç» PyTorch æ˜¯æ€ä¹ˆå»ºç«‹ç”¨äºåå‘ä¼ æ’­çš„è®¡ç®—å›¾çš„ã€‚æ ¹æ®å‰é¢çš„åˆ†æï¼Œè®¡ç®—å›¾ä¸€å®šæ˜¯åœ¨å®šä¹‰å‰å‘ä¼ æ’­æ˜¯å»ºç«‹çš„ï¼Œé‚£ä¹ˆæœºå¯†ä¸€å®šæ˜¯è—åœ¨å‰å‘ä¼ æ’­APIé‡Œäº†ï¼Œè¿™ä¸ªçŒœæƒ³æ˜¯æ²¡é”™ï¼Œä½†æ˜¯ç”±äº ATen å¤æ‚çš„åŠ¨æ€æ´¾å‘æœºåˆ¶ä»¥åŠä½¿ç”¨è„šæœ¬ç”Ÿæˆä»£ç ï¼Œæˆ‘ä¹Ÿæ˜¯è´¹äº†ä¹ç‰›äºŒè™ä¹‹åŠ›æ‰æ‰¾åˆ°å…·ä½“å®ç°ä»¥åŠç†è§£å…¶ä¸­çš„é€»è¾‘ã€‚</p><p>ç¥ç»ç½‘ç»œçš„å…·ä½“è®¡ç®—ï¼šæ¯ä¸€å±‚çš„å‰å‘å’Œåå‘ä¼ æ’­ï¼Œå…¶å®éƒ½æ˜¯åœ¨ ATen é‡Œå®ç°çš„ï¼Œä½†å›å»çœ‹ ATen çš„APIå®ç°ï¼Œå¹¶æ²¡æœ‰å‘ç°å…¶ä¸­æœ‰ä»»ä½•å»ºç«‹è®¡ç®—å›¾çš„ä»£ç ã€‚è¿™å…¶ä¸­çš„æœºå¯†å®é™…åœ¨<code>tools/autograd</code>ç›®å½•é‡Œã€‚è¿™ä¸ªç›®å½•é‡Œæœ‰<code>derivatives.yaml</code>å’Œç”¨äºç”Ÿæˆä»£ç çš„è„šæœ¬ï¼Œå‰è€…è®°å½•äº†æ‰€æœ‰éœ€è¦è‡ªåŠ¨å¾®åˆ†çš„ATen APIï¼Œåè€…ä¸ºå®ƒä»¬ç”Ÿæˆä¸€å±‚wrapperä»£ç ï¼Œè¿™äº›ä»£ç ä¸»è¦å¹²ä¸¤ä»¶äº‹ï¼š</p><ul><li>æŠŠATençš„åå‘ä¼ æ’­APIè½¬æ¢æˆ<code>Function</code></li><li>åœ¨ATençš„æ­£å‘ä¼ æ’­APIä¸­åŠ å…¥å»ºå›¾è¿‡ç¨‹</li></ul><p>ä¸¾ä¸ªä¾‹å­ï¼Œ<code>derivatives.yaml</code>ç¬¬119è¡Œçš„<code>addcmul()</code>APIï¼š</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">addcmul(Tensor</span> <span class="string">self,</span> <span class="string">Tensor</span> <span class="string">tensor1,</span> <span class="string">Tensor</span> <span class="string">tensor2,</span> <span class="string">*,</span> <span class="string">Scalar</span> <span class="string">value)</span></span><br><span class="line"><span class="attr">  self:</span> <span class="string">grad</span></span><br><span class="line"><span class="attr">  tensor1:</span> <span class="string">grad</span> <span class="string">*</span> <span class="string">tensor2</span> <span class="string">*</span> <span class="string">value</span></span><br><span class="line"><span class="attr">  tensor2:</span> <span class="string">grad</span> <span class="string">*</span> <span class="string">tensor1</span> <span class="string">*</span> <span class="string">value</span></span><br></pre></td></tr></table></figure><p>è¿™é‡ŒæŒ‡æ˜äº†å‡½æ•°åã€å‚æ•°ã€åå‘è®¡ç®—æ–¹æ³•ã€‚æ‰§è¡Œ<code>gen_autograd.py</code>å¯ä»¥è‡ªåŠ¨ä¸ºå…¶ç”Ÿæˆä»£ç ï¼Œç”Ÿæˆçš„ä»£ç åœ¨<code>torch/csrc/autograd/generated</code>ä¸­ï¼Œæœ‰ <code>addcmul()</code>çš„å‰å‘ä¼ æ’­çš„ä»£ç åœ¨<code>VariableType0.cpp</code>ä¸­ï¼Œ åå‘ä¼ æ’­çš„ä»£ç åœ¨<code>Functions.h</code>å’Œ<code>Functionss.cpp</code>ä¸­ã€‚</p><p><strong>å‰å‘ä¼ æ’­</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Tensor VariableType::addcmul(<span class="keyword">const</span> Tensor &amp; self, <span class="keyword">const</span> Tensor &amp; tensor1, <span class="keyword">const</span> Tensor &amp; tensor2, Scalar value) <span class="keyword">const</span> </span><br><span class="line">&#123;</span><br><span class="line">  profiler::<span class="function">RecordFunction <span class="title">profiler</span><span class="params">(<span class="string">"addcmul"</span>, Function::peek_at_next_sequence_nr())</span></span>;</span><br><span class="line">  <span class="comment">// è·å–è¾“å…¥</span></span><br><span class="line">  <span class="keyword">auto</span>&amp; self_ = unpack(self, <span class="string">"self"</span>, <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">auto</span>&amp; tensor1_ = unpack(tensor1, <span class="string">"tensor1"</span>, <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span>&amp; tensor2_ = unpack(tensor2, <span class="string">"tensor2"</span>, <span class="number">2</span>);</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;AddcmulBackward&gt; grad_fn;</span><br><span class="line">  <span class="keyword">if</span> (compute_requires_grad( self, tensor1, tensor2 )) &#123;</span><br><span class="line">    <span class="comment">// å»ºç«‹åå‘ä¼ æ’­èŠ‚ç‚¹ AddcmulBackward</span></span><br><span class="line">    grad_fn = <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;AddcmulBackward&gt;(<span class="keyword">new</span> AddcmulBackward(), deleteFunction);</span><br><span class="line">    <span class="comment">// æ–°å»ºè¾¹æŒ‡å‘ä¸ self, tensor1, tensor2 ç»‘å®šçš„èŠ‚ç‚¹</span></span><br><span class="line">    grad_fn-&gt;set_next_edges(collect_next_edges(self, tensor1, </span><br><span class="line">                                               tensor2));</span><br><span class="line">    <span class="keyword">if</span> (grad_fn-&gt;should_compute_output(<span class="number">1</span>)) &#123;</span><br><span class="line">      grad_fn-&gt;tensor2_ = SavedVariable(tensor2, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    grad_fn-&gt;value = value;</span><br><span class="line">    <span class="keyword">if</span> (grad_fn-&gt;should_compute_output(<span class="number">2</span>)) &#123;</span><br><span class="line">      grad_fn-&gt;tensor1_ = SavedVariable(tensor1, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// è°ƒç”¨ ATen API è¿›è¡Œå®é™…è®¡ç®—</span></span><br><span class="line">  <span class="keyword">auto</span> tmp = ([&amp;]() &#123;</span><br><span class="line">    at::AutoNonVariableTypeMode non_var_type_mode(<span class="literal">true</span>);</span><br><span class="line">    <span class="keyword">return</span> baseType-&gt;addcmul(self_, tensor1_, tensor2_, value);</span><br><span class="line">  &#125;)();</span><br><span class="line">  <span class="keyword">auto</span> result = as_variable(tmp);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// æŠŠ grad_fn ä¸è¾“å‡ºç»‘å®š</span></span><br><span class="line">  set_history(flatten_tensor_args(result), grad_fn);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™ä¸ªå‡½æ•°æ˜¯å‰å‘è®¡ç®—çš„APIï¼Œåœ¨å…·ä½“è®¡ç®—ä¹‹å‰å…ˆå»ºç«‹åå‘ä¼ æ’­å‡½æ•°ï¼ˆèŠ‚ç‚¹ï¼‰ï¼Œå¹¶ä¸”æŠŠè¯¥èŠ‚ç‚¹ä¸<strong>è¾“å…¥</strong>çš„èŠ‚ç‚¹ç›¸è¿ï¼›ç„¶åè°ƒç”¨ä¸‹å±‚APIè®¡ç®—ç»“æœï¼›æœ€åæŠŠç»“æœå’Œæ–°å»ºç«‹çš„èŠ‚ç‚¹ç»‘å®šï¼Œè¿™æ ·ç”¨äºåå‘ä¼ æ’­çš„è®¡ç®—å›¾å°±å»ºç«‹å®Œæˆäº†ã€‚ç”±äºè¿™æ˜¯åå‘ä¼ æ’­è®¡ç®—å›¾ï¼Œæ‰€ä»¥å‰å‘ä¼ æ’­ä¸­çš„è¾“å…¥èŠ‚ç‚¹å˜æˆåå‘çš„è¾“å‡ºï¼Œå‰å‘çš„è¾“å‡ºèŠ‚ç‚¹å˜æˆåå‘çš„è¾“å…¥ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><p><img src="/images/pytorch/addcmul.png"></p><p><strong>åå‘ä¼ æ’­</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// å£°æ˜åœ¨ Functions.h</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">AddcmulBackward</span> :</span> <span class="keyword">public</span> TraceableFunction &#123;</span><br><span class="line">  <span class="keyword">using</span> TraceableFunction::TraceableFunction;</span><br><span class="line">  <span class="function">variable_list <span class="title">apply</span><span class="params">(variable_list&amp;&amp; grads)</span> override</span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> <span class="keyword">const</span> override </span>&#123; <span class="keyword">return</span> <span class="string">"AddcmulBackward"</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">release_variables</span><span class="params">()</span> override </span>&#123;</span><br><span class="line">    tensor2_.reset_data();</span><br><span class="line">    tensor2_.reset_grad_function();</span><br><span class="line">    tensor1_.reset_data();</span><br><span class="line">    tensor1_.reset_grad_function();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  SavedVariable tensor2_;</span><br><span class="line">  Scalar value;</span><br><span class="line">  SavedVariable tensor1_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// å®ç°åœ¨ Functions.cpp</span></span><br><span class="line"><span class="comment">// é‡è½½ Function::apply å®ç°æ¢¯åº¦è®¡ç®—</span></span><br><span class="line">variable_list AddcmulBackward::apply(variable_list&amp;&amp; grads) &#123;</span><br><span class="line">  IndexRangeGenerator gen;</span><br><span class="line">  <span class="keyword">auto</span> self_ix = gen.range(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span> tensor1_ix = gen.range(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span> tensor2_ix = gen.range(<span class="number">1</span>);</span><br><span class="line">  <span class="function">variable_list <span class="title">grad_inputs</span><span class="params">(gen.size())</span></span>;</span><br><span class="line">  <span class="keyword">auto</span>&amp; grad = grads[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">auto</span> tensor2 = tensor2_.unpack();</span><br><span class="line">  <span class="keyword">auto</span> tensor1 = tensor1_.unpack();</span><br><span class="line">  <span class="comment">// è®¡ç®—æ¢¯åº¦ï¼Œä¸ derivatives.yaml ä¸­çš„å®šä¹‰ç›¸åŒ</span></span><br><span class="line">  <span class="keyword">if</span> (should_compute_output(&#123; self_ix &#125;)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> grad_result = grad;</span><br><span class="line">    copy_range(grad_inputs, self_ix, grad_result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (should_compute_output(&#123; tensor1_ix &#125;)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> grad_result = grad * tensor2 * value;</span><br><span class="line">    copy_range(grad_inputs, tensor1_ix, grad_result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (should_compute_output(&#123; tensor2_ix &#125;)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> grad_result = grad * tensor1 * value;</span><br><span class="line">    copy_range(grad_inputs, tensor2_ix, grad_result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> grad_inputs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å¯ä»¥çœ‹åˆ°è¿™äº›ä»£ç ç¡®ç¡®å®å®æŠŠ ATen API è½¬æ¢æˆäº†è®¡ç®—å›¾èŠ‚ç‚¹<code>Function</code>ã€‚</p><p><strong>åŠ¨æ€æ´¾å‘</strong></p><p>æœ€åè¿˜æœ‰ä¸€ä¸ªé—®é¢˜å°±æ˜¯ä»£ç ä¸­è°ƒç”¨çš„APIæ˜¯<code>torch.addcmul()</code>æˆ–<code>variable.addcmul()</code>æ€ä¹ˆå°±ä¼šæ‰§è¡Œåˆ°ä¸Šé¢çš„<code>VariableType::addcmul()</code>å‘¢ï¼Ÿè¿™å°±è¦å½’åŠŸäº ATen çš„åŠ¨æ€æ´¾å‘äº†ï¼Œä»¥ç¬¬äºŒç§è°ƒç”¨ä¸¾ä¾‹åˆ†æä¸€ä¸‹ï¼Œä¹Ÿå°±æ˜¯é€šè¿‡ä¸€ä¸ª<code>Variable</code>ç±»å‹å˜é‡è°ƒç”¨<code>addcmul()</code>ã€‚</p><p>é¦–å…ˆï¼Œä¸Šä¸€ç¯‡è¯´è¿‡ï¼ŒATen çš„APIéƒ½è®°å½•åœ¨<code>ATen/native/native_functions.yaml</code>é‡Œï¼Œè¿™äº›APIå¦‚æœæœ‰ç”Ÿæˆ method çš„éœ€æ±‚çš„è¯ï¼Œä¼šæŠŠå£°æ˜é€šè¿‡è„šæœ¬è‡ªåŠ¨æ·»åŠ  <code>at::Tensor</code>ç±»é‡Œï¼Œè¿™æ ·å°±å¯ä»¥é€šè¿‡<code>tensor.addcmul()</code>è°ƒç”¨è¯¥APIï¼Œè€Œ<code>Variable</code>ç»§æ‰¿è‡ª<code>at::Tensor</code>ï¼Œè‡ªç„¶ä¹Ÿå°±æ‹¥æœ‰äº†è¯¥æ–¹æ³•ã€‚</p><p>ä½†è¿™è¿˜æ²¡å®Œï¼Œå¦‚æœæŸ¥çœ‹è¿™ä¸ªæ–¹æ³•çš„å®ç°ä¼šå‘ç°ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> Tensor Tensor::addcmul(<span class="keyword">const</span> Tensor &amp; tensor1, <span class="keyword">const</span> Tensor &amp; tensor2, Scalar value) <span class="keyword">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> type().addcmul(*<span class="keyword">this</span>, tensor1, tensor2, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å®ƒè°ƒç”¨äº†<code>type()</code>çš„ç›¸åº”æ–¹æ³•ï¼Œè¿™ä¸ª<code>type()</code>è¿”å›çš„æ˜¯<code>Type</code>ç±»å‹çš„å®ä¾‹ã€‚<code>Type</code>ç±»å‹åŒæ ·å£°æ˜äº†æ‰€æœ‰ ATen APIï¼Œå¹¶ä¸”æœ‰<code>TensorType</code> <code>VariableType</code>ç»§æ‰¿è‡ªå®ƒã€‚æ ¹æ®ATençš„åŠ¨æ€æ´¾å‘æœºåˆ¶ï¼Œå¦‚æœè°ƒç”¨è€…æ˜¯<code>Tensor</code>çš„è¯ï¼Œå¹¶ä¸”<code>is_variable == False</code>ï¼Œå°±ä¼šè¿”å›<code>TensorType</code>å®ä¾‹ï¼›å¦‚æœè°ƒç”¨è€…æ˜¯<code>Variable</code>çš„è¯ï¼Œæˆ–è€…<code>is_variable == True</code>ï¼Œå°±ä¼šè¿”å›ä¸Šè¿°çš„<code>VariableType</code>å®ä¾‹ã€‚æ‰€ä»¥ä¸€ä¸ª<code>Variable</code>ç±»å‹çš„å˜é‡è°ƒç”¨<code>addcmul()</code>çš„è¯å®é™…ä¼šæ‰§è¡Œ<code>VariableType::addcmul()</code>ã€‚</p><p>ã¤ã¥ã</p><table><thead><tr class="header"><th style="text-align: left;">ä¸Šä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch3/">NN</a></th><th style="text-align: right;">ä¸‹ä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch5/">Pythonæ‰©å±•</a></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"></td><td style="text-align: right;"></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> Autograd </tag>
            
            <tag> è‡ªåŠ¨å¾®åˆ†å¼•æ“ </tag>
            
            <tag> Variable </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PyTorchæºç æµ…æ(3)ï¼šNN</title>
      <link href="/2019/05/05/PyTorch3/"/>
      <url>/2019/05/05/PyTorch3/</url>
      
        <content type="html"><![CDATA[<p>THNNæ˜¯ä¸€ä¸ªç”¨Cè¯­è¨€å®ç°çš„ç¥ç»ç½‘ç»œæ¨¡å—çš„åº“ï¼Œæä¾›çš„åŠŸèƒ½éå¸¸åº•å±‚ã€‚å®ƒå®ç°äº†è®¸å¤šåŸºç¡€çš„ç¥ç»ç½‘ç»œæ¨¡å—ï¼ŒåŒ…æ‹¬çº¿æ€§å±‚ï¼Œå·ç§¯å±‚ï¼ŒSigmoidç­‰å„ç§æ¿€æ´»å±‚ï¼Œä¸€äº›åŸºæœ¬çš„losså‡½æ•°ï¼Œè¿™äº›APIéƒ½å£°æ˜åœ¨<code>THNN/generic/THNN.h</code>ä¸­ã€‚æ¯ä¸ªæ¨¡å—éƒ½å®ç°äº†å‰å‘ä¼ å¯¼ï¼ˆforwardï¼‰å’Œåå‘ä¼ å¯¼ï¼ˆbackwardï¼‰çš„åŠŸèƒ½ã€‚THCUNNåˆ™æ˜¯å¯¹åº”æ¨¡å—çš„CUDAå®ç°ã€‚</p><a id="more"></a><p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#thnn-thcunn">THNN &amp; THCUNN</a><ul><li><a href="#tanh">Tanh</a></li><li><a href="#2d-convolution">2D Convolution</a><ul><li><a href="#å‰å‘ä¼ æ’­">å‰å‘ä¼ æ’­</a></li><li><a href="#åå‘ä¼ æ’­">åå‘ä¼ æ’­</a></li></ul></li></ul></li><li><a href="#aten">ATen</a></li></ul><!-- tocstop --><h2><span id="thnn-amp-thcunn">THNN &amp; THCUNN</span></h2><p>æˆ‘ä»¬é€šè¿‡å‡ ä¸ªä¾‹å­å…·ä½“çœ‹ä¸€ä¸‹å‡ ç§æ¨¡å—æ˜¯æ€ä¹ˆå®ç°çš„ã€‚</p><h3><span id="tanh">Tanh</span></h3><p>é¦–å…ˆä»æœ€ç®€å•çš„æ¿€æ´»å±‚å¼€å§‹çœ‹ï¼Œä»¥ <span class="math inline">\(\tanhâ€‹\)</span> ä¸ºä»£è¡¨ï¼Œä»£ç åœ¨<code>THNN/generic/Tanh.c</code>ã€‚è¿™ä¸ªæ¨¡å—åªæœ‰ä¸¤ä¸ªå‡½æ•°ï¼Œåˆ†åˆ«æ˜¯<code>THNN_(Tanh_updateOutput)()</code>å’Œ<code>THNN_(Tanh_updateGradInput)()</code>ï¼Œå…¶ä¸­å‰è€…å®ç°äº†å‰å‘ä¼ æ’­ï¼Œåè€…å®ç°äº†åå‘ä¼ æ’­ã€‚æ³¨æ„åˆ°å‡½æ•°çš„å‘½åæ–¹å¼ï¼Œä¾æ—§æ˜¯ä½¿ç”¨å®å®ç°èŒƒå¼ï¼Œ<code>THNN_</code>æ˜¯å®å®šä¹‰ï¼Œ<code>Tanh_</code>æ˜¯å…·ä½“æ¨¡å—åï¼Œ<code>updateOutput</code>è¡¨ç¤ºå‰å‘ä¼ æ’­ï¼Œ<code>updateGradInput</code>è¡¨ç¤ºåå‘ä¼ æ’­ï¼Œä¸ä¹‹å‰ä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œåªéœ€ç”Ÿæˆæµ®ç‚¹ç±»å‹ï¼ˆ<code>float</code>å’Œ<code>double</code>ï¼‰çš„å®ç°å³å¯ã€‚</p><p>å‰å‘ä¼ æ’­çš„å®ç°å¾ˆç®€å•ï¼Œç›´æ¥è°ƒç”¨ä¹‹å‰å®ç°çš„tanhå‡½æ•°å°±è¡Œäº†ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(Tanh_updateOutput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">          THNNState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *output)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THTensor_(<span class="built_in">tanh</span>)(output, input);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å®ƒæœ‰ä¸‰ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯THNNçŠ¶æ€ï¼ˆæš‚ä¸çŸ¥æœ‰ä½•ç”¨ï¼‰ï¼Œæœ¬å±‚çš„è¾“å…¥ï¼ˆ<code>input</code>ï¼‰å’Œæœ¬å±‚çš„è¾“å‡ºï¼ˆ<code>output</code>ï¼‰ï¼Œè¾“å‡ºå­˜å‚¨åœ¨<code>output</code>å‚æ•°ä¸­ã€‚</p><p>åå‘ä¼ æ’­çš„å®ç°ä¸ºï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(Tanh_updateGradInput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">          THNNState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *gradOutput,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *gradInput,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *output)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THNN_CHECK_SHAPE(output, gradOutput);</span><br><span class="line">  THTensor_(resizeAs)(gradInput, output);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="comment">/* output, gradInput, å’Œ gradOutput çš„å†…å­˜æ˜¯è¿ç»­çš„ */</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    TH_TENSOR_APPLY3(<span class="keyword">scalar_t</span>, gradInput, <span class="keyword">scalar_t</span>, gradOutput,</span><br><span class="line">                     <span class="keyword">scalar_t</span>, output,</span><br><span class="line">      <span class="keyword">scalar_t</span> z = *output_data;            \</span><br><span class="line">      *gradInput_data = *gradOutput_data * (<span class="number">1.</span> - z*z);</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">scalar_t</span>* ptr_gradOutput = gradOutput-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;();</span><br><span class="line">    <span class="keyword">scalar_t</span>* ptr_gradInput  = gradInput-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;();</span><br><span class="line">    <span class="keyword">scalar_t</span>* ptr_output     = output-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;();</span><br><span class="line">    <span class="keyword">int64_t</span> i;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for private(i)</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; THTensor_(nElement)(gradInput); i++)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">scalar_t</span> z = ptr_output[i];</span><br><span class="line">      ptr_gradInput[i] = ptr_gradOutput[i] * (<span class="number">1.</span> - z*z);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åå‘ä¼ æ’­æ¥æ”¶5ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯THNNçŠ¶æ€ï¼Œä»åé¢ä¼ å›æ¥çš„æ¢¯åº¦ï¼ˆ<code>gradOutput</code>ï¼‰ï¼Œæœ¬å±‚å¾€å›ä¼ çš„æ¢¯åº¦ï¼ˆ<code>gradInput</code>ï¼‰ï¼Œæœ¬å±‚å‰å‘ä¼ æ’­çš„è¾“å‡ºï¼ˆ<code>output</code>ï¼‰ï¼Œè¿™ä¸ªå‡½æ•°è®¡ç®—çš„æ˜¯æœ¬å±‚çš„æ¢¯åº¦ï¼Œç„¶åå­˜å‚¨åœ¨<code>gradInput</code>ä¸­ã€‚</p><p><span class="math inline">\(\tanh\)</span> çš„å¯¼æ•°ä¸ºï¼š <span class="math display">\[f(z) = \tanh(z)\\f&#39;(z) = 1 - (f(z))^2\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(f(z)â€‹\)</span> å°±æ˜¯å‰å‘ä¼ æ’­æ—¶æœ¬å±‚çš„è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯<code>output</code>å‚æ•°ï¼ˆå¾ªç¯é‡Œçš„<code>z</code>ï¼‰ï¼Œæ ¹æ®é“¾å¼æ³•åˆ™ï¼Œå†ä¹˜ä»¥åé¢å±‚ä¼ å›æ¥çš„æ¢¯åº¦ï¼ˆ<code>gradOutput</code>ï¼‰å°±æ˜¯æœ¬å±‚åº”è¯¥å¾€å›ä¼ çš„æ¢¯åº¦äº†ï¼ˆç›¸å¯¹äºæœ¬å±‚è¾“å…¥çš„æ¢¯åº¦ï¼‰ï¼Œæ‰€ä»¥å¾ªç¯é‡Œçš„ä»£ç ä¸ºï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*gradInput_data = *gradOutput_data * (<span class="number">1.</span> - z*z);</span><br></pre></td></tr></table></figure><p>æ³¨ï¼š<code>_data</code>åç¼€è¡¨ç¤ºæ•°æ®æŒ‡é’ˆï¼Œå…·ä½“å¯ä»¥çœ‹<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/#tensor-apply-dynamic-dispatch">Applyå®</a>çš„å®ç°ã€‚</p><h3><span id="2d-convolution">2D Convolution</span></h3><p>æœ€æ™®é€šçš„2Då·ç§¯ï¼ŒCPUå®ç°åœ¨<code>THNN/generic/SpatialConvolutionMM.c</code>ï¼ŒCUDAå®ç°åœ¨<code>THCUNN/generic/SpatialConvolutionMM.cu</code>ï¼Œå¤§ä½“çš„ç®—æ³•æ˜¯æŠŠè¾“å…¥å±•å¼€æˆä¸€ä¸ªç‰¹æ®Šçš„çŸ©é˜µï¼Œç„¶åæŠŠå·ç§¯è½¬åŒ–ä¸ºçŸ©é˜µç›¸ä¹˜ï¼ˆMM = Matrix Multiplicationï¼‰ã€‚æ¨¡å—é‡Œä¸»è¦åŒ…å«ä¸‰ä¸ªå‡½æ•°ï¼Œå‰å‘ä¼ æ’­ï¼ˆ<code>THNN_(SpatialConvolutionMM_updateOutput)()</code>ï¼‰ï¼Œåå‘ä¼ æ’­ï¼ˆ<code>THNN_(SpatialConvolutionMM_updateGradInput)()</code>ï¼‰ï¼Œå’Œæ›´æ–°å±‚å†…å‚æ•°ï¼ˆ<code>THNN_(SpatialConvolutionMM_accGradParameters)()</code>ï¼‰ã€‚</p><h4><span id="å‰å‘ä¼ æ’­">å‰å‘ä¼ æ’­</span></h4><p>PyTorchå®ç°å·ç§¯çš„åšæ³•æ˜¯ç”¨im2colç®—æ³•æŠŠè¾“å…¥å±•å¼€æˆä¸€ä¸ªå¤§çŸ©é˜µï¼Œç„¶åç”¨kernelä¹˜ä»¥è¿™ä¸ªå¤§çŸ©é˜µï¼Œå°±å¾—äº†å·ç§¯çš„ç»“æœã€‚è¿™é‡Œä¸å…·ä½“ä»‹ç»im2colç®—æ³•æ˜¯æ€ä¹ˆåšçš„ï¼Œä½†ä¼šè§£é‡Šä¸ºä»€ä¹ˆå¯ä»¥è¿™ä¹ˆåšã€‚</p><p>é¦–å…ˆå®šä¹‰ç¬¦å·ï¼Œä¸ºäº†å’Œä»£ç ä¸­çš„ç¬¦å·ä¸€è‡´ï¼Œé¦–å…ˆæ¥çœ‹ä¸€ä¸‹updateOutputçš„å£°æ˜ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_updateOutput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">           THCState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *output,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *weight,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *bias,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *columns,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *ones,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> kW, <span class="keyword">int</span> kH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dW, <span class="keyword">int</span> dH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> padW, <span class="keyword">int</span> padH)</span></span>;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼Œ</p><ul><li><code>input</code>æ˜¯è¾“å…¥çš„4D Tensorï¼Œå¤§å°ä¸º <span class="math inline">\(\text{batch}\times\text{nInputPlane}\times\text{inputHeight}\times\text{inputWidth}\)</span>ï¼Œbatchç»´ä¹Ÿå¯ä»¥æ²¡æœ‰ï¼Œå°±å˜ä¸º3D Tensorï¼›</li><li><code>output</code>æ˜¯è¾“å‡ºçš„4Dæˆ–3D Tensorï¼Œå¤§å°ä¸º <span class="math inline">\(\text{batch}\times\text{nOutputPlane}\times\text{outputHeight}\times\text{outputWidth}\)</span>ï¼Œå…¶ä¸­ï¼Œ</li></ul><p><span class="math display">\[\text{outputHeight}=\frac{\text{inputHeight}+2\ast\text{padH}-\text{kH}}{\text{dH}}+1\\\text{outputWidth}=\frac{\text{inputWidth}+2\ast\text{padW}-\text{kW}}{\text{dW}}+1\]</span></p><ul><li><code>weight</code>æ˜¯æƒé‡ï¼Œä¹Ÿå°±æ˜¯å·ç§¯æ ¸ï¼Œå¤§å°ä¸º <span class="math inline">\(\text{nOutputPlane}\times\text{nInputPlane}\times\text{kH}\times\text{kW}\)</span>ï¼›</li><li><code>bias</code>æ˜¯åç½®ï¼Œå¤§å°ä¸º <span class="math inline">\(\text{nOutputPlane}\times1\times1\times1\)</span>ï¼›</li><li><code>columns</code>ç”¨äºå­˜å‚¨im2colçš„ç»“æœï¼›</li><li><code>ones</code>æ˜¯ä¸€ä¸ªå€¼å…¨ä¸º1çš„çŸ©é˜µï¼Œå¤§å°ä¸º <span class="math inline">\(\text{outputHeight}\times\text{outputWidth}\)</span>ï¼Œç”¨äºè®¡ç®—åç½®ï¼›</li><li><code>kW</code>å’Œ<code>kH</code>æ˜¯å·ç§¯æ ¸ï¼ˆkernelï¼‰çš„å®½å’Œé«˜ï¼›</li><li><code>dW</code>å’Œ<code>dH</code>æ˜¯æ­¥é•¿ï¼ˆstrideï¼‰ï¼›</li><li><code>padW</code>å’Œ<code>padH</code>æ˜¯è¡¥é›¶çš„å®½å’Œé«˜ã€‚</li></ul><p>å®šä¹‰å¥½äº†ç¬¦å·ä¹‹åæ¥çœ‹ä¸€ä¸‹å·ç§¯æ˜¯æ€ä¹ˆè½¬åŒ–ä¸ºä¸€ä¸ªçŸ©é˜µä¹˜æ³•çš„ã€‚é¦–å…ˆæ¥çœ‹å·ç§¯æ˜¯æ€ä¹ˆåšçš„ï¼Œä¸‹å›¾æ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œå…¶ä¸­è¾“å…¥å’Œè¾“å‡ºæ·±åº¦ <span class="math inline">\(\text{nInputPlane}=\text{nOutputPlane}=1â€‹\)</span>ï¼Œå·ç§¯æ ¸å¤§å° <span class="math inline">\(\text{kH}=\text{kW}=3â€‹\)</span>ï¼Œè¾“å…¥å¤§å° <span class="math inline">\(\text{inputHeight}=\text{inputWidth}=7â€‹\)</span>ï¼Œæ­¥é•¿ <span class="math inline">\(\text{dW}=\text{dH}=2â€‹\)</span>ï¼Œè¡¥é›¶ <span class="math inline">\(\text{padW}=\text{padH}=1â€‹\)</span>ï¼Œå¯ä»¥ç®—å‡º <span class="math inline">\(\text{outputHeight}=\text{outputWidth}=3â€‹\)</span>ã€‚</p><p><img src="/images/pytorch/conv.png"></p><p>è¦æƒ³æŠŠå·ç§¯å˜æˆä¸€æ¬¡çŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œå°±éœ€è¦<strong>æŠŠè¾“å…¥ä¸­æ¯ä¸ªå·ç§¯çª—å£å˜ä¸ºå•ç‹¬ä¸€åˆ—</strong>ï¼Œè¿™ä¹Ÿå°±æ˜¯im2colåšçš„äº‹æƒ…ï¼Œè§ä¸‹å›¾ï¼š</p><p><img src="/images/pytorch/im2col.png"></p><p>ä¸Šå›¾ä¸­å³è¾¹çŸ©é˜µçš„æ¯ä¸€åˆ—éƒ½æ˜¯åŸè¾“å…¥çŸ©é˜µçš„ä¸€ä¸ªå·ç§¯çª—å£ï¼Œè½¬æ¢åçš„çŸ©é˜µå¤§å°ä¸º <span class="math display">\[(\text{nInputPlane}\times\text{kH}\times\text{kW})\times(\text{outputHeight}\times\text{outputWidth})\]</span> å¾—åˆ°ä¸Šè¿°çŸ©é˜µä¹‹åï¼Œåªéœ€æŠŠkernelçš„å¤§å°ä¹Ÿresizeæˆ <span class="math display">\[(\text{nOutputPlane})\times(\text{nInputPlane}\times\text{kH}\times\text{kW})\]</span> å°±å¯ä»¥ç›´æ¥ç”¨kernelä¹˜ä»¥è¯¥çŸ©é˜µå¾—åˆ°å·ç§¯ç»“æœäº†ï¼Œè§ä¸‹å›¾ã€‚</p><p><img src="/images/pytorch/convmm.png"></p><p><strong>ä»£ç </strong>ï¼ˆCUDAç‰ˆï¼‰</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_updateOutput)</span><span class="params">(<span class="comment">/* å‚æ•°åˆ—è¡¨å‰é¢æœ‰ */</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* çœç•¥äº†ä¸€äº›å¸¸è§„check */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* resize å·ç§¯æ ¸ */</span></span><br><span class="line">  weight = THNN_(newViewWeightMM2d)(state, weight);</span><br><span class="line">  <span class="comment">/* å¯¹è¾“å…¥çš„ç»´åº¦è¿›è¡Œcheck */</span></span><br><span class="line">  THNN_(SpatialConvolutionMM_shapeCheck)</span><br><span class="line">       (state, input, <span class="literal">NULL</span>, weight, bias, kH, kW, dH, dW, padH, </span><br><span class="line">        padW, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> ndim = input-&gt;dim();</span><br><span class="line">  <span class="keyword">int</span> dimf = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> dimh = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">int</span> dimw = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (ndim == <span class="number">4</span>) &#123;<span class="comment">/* å¦‚æœè¾“å…¥æ˜¯4Dçš„è¯ï¼Œç¬¬0ç»´æ˜¯batch size */</span></span><br><span class="line">    dimf++;</span><br><span class="line">    dimh++;</span><br><span class="line">    dimw++;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* è®¡ç®—è¾“å…¥è¾“å‡ºå¤§å° */</span></span><br><span class="line">  <span class="keyword">int64_t</span> nInputPlane = input-&gt;size(dimf);</span><br><span class="line">  <span class="keyword">int64_t</span> inputHeight  = input-&gt;size(dimh);</span><br><span class="line">  <span class="keyword">int64_t</span> inputWidth   = input-&gt;size(dimw);</span><br><span class="line">  <span class="keyword">int64_t</span> nOutputPlane = weight-&gt;size(<span class="number">0</span>);</span><br><span class="line">  <span class="keyword">int64_t</span> outputHeight = (inputHeight + <span class="number">2</span>*padH - kH) / dH + <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">int64_t</span> outputWidth  = (inputWidth + <span class="number">2</span>*padW - kW) / dW + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  input = THCTensor_(newContiguous)(state, input);</span><br><span class="line">  <span class="keyword">int</span> is_batch = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> (input-&gt;dim() == <span class="number">3</span>) &#123;</span><br><span class="line">    <span class="comment">/* å¼ºè¡ŒåŠ å…¥ batch ç»´åº¦ï¼ŒæŠŠè¾“å…¥å˜ä¸º4D Tensorï¼ˆbatch size = 1ï¼‰*/</span></span><br><span class="line">    is_batch = <span class="number">0</span>;</span><br><span class="line">    THCTensor_(resize4d)(state, input, <span class="number">1</span>, input-&gt;size(<span class="number">0</span>), </span><br><span class="line">                         input-&gt;size(<span class="number">1</span>), input-&gt;size(<span class="number">2</span>));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* è·å– batch size */</span></span><br><span class="line">  <span class="keyword">int64_t</span> batchSize = input-&gt;size(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Resize output</span></span><br><span class="line">  THCTensor_(resize4d)(state, output, batchSize, nOutputPlane,</span><br><span class="line">                       outputHeight, outputWidth);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Resize columns çŸ©é˜µ */</span></span><br><span class="line">  THCTensor_(resize2d)(state, columns, nInputPlane*kW*kH,</span><br><span class="line">                       outputHeight*outputWidth);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* å®šä¹‰ buffer `ones`ï¼Œä»£ç ç•¥ */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Helpers</span></span><br><span class="line">  THCTensor *input_n = THCTensor_(<span class="keyword">new</span>)(state);</span><br><span class="line">  THCTensor *output_n = THCTensor_(<span class="keyword">new</span>)(state);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* å¯¹æ¯ä¸ªbatchå•ç‹¬è®¡ç®—ï¼š */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> elt = <span class="number">0</span>; elt &lt; batchSize; elt ++) &#123;</span><br><span class="line">    <span class="comment">/* å–å‡ºå¯¹åº”batchçš„è¾“å…¥å’Œè¾“å‡ºbuffer */</span></span><br><span class="line">    <span class="comment">/* input_n = input[elt] */</span></span><br><span class="line">    THCTensor_(select)(state, input_n, input, <span class="number">0</span>, elt);</span><br><span class="line">    THCTensor_(select)(state, output_n, output, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* é¦–å…ˆè®¡ç®—åç½® biasï¼Œå³æŠŠ bias å­˜åˆ° output_n ä¸­ */</span></span><br><span class="line">    <span class="comment">// M,N,K are dims of matrix A and B</span></span><br><span class="line">    <span class="keyword">int64_t</span> m_ = nOutputPlane;</span><br><span class="line">    <span class="keyword">int64_t</span> n_ = outputHeight * outputWidth;</span><br><span class="line">    <span class="keyword">int64_t</span> k_ = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* è°ƒç”¨ GEMM è®¡ç®— output_n = 1 * ones * bias + 0 * output_n */</span></span><br><span class="line">    <span class="keyword">if</span> (bias) &#123;</span><br><span class="line">      <span class="meta">#<span class="meta-keyword">ifdef</span> THC_REAL_IS_FLOAT</span></span><br><span class="line">      THCudaBlas_Sgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">      THCudaBlas_Hgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      THCudaBlas_Dgemm(</span><br><span class="line">      #endif</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>, <span class="string">'n'</span>,</span><br><span class="line">          n_, m_, k_,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, ones), k_,</span><br><span class="line">          THCTensor_(data)(state, bias), k_,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">0</span>),</span><br><span class="line">          THCTensor_(data)(state, output_n), n_</span><br><span class="line">      );</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">/* å¦‚æœæ²¡æœ‰ bias å°±æŠŠ output_n å¡«é›¶ */</span></span><br><span class="line">      THCTensor_(zero)(state, output_n);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* ç”¨ im2col æŠŠè¾“å…¥ input_n è½¬åŒ–ä¸ºåˆ—çŸ©é˜µå­˜å‚¨åœ¨ columns */</span></span><br><span class="line">    im2col(</span><br><span class="line">      THCState_getCurrentStream(state),</span><br><span class="line">      THCTensor_(data)(state, input_n),</span><br><span class="line">      nInputPlane, inputHeight, inputWidth,</span><br><span class="line">      outputHeight, outputWidth,</span><br><span class="line">      kH, kW, padH, padW, dH, dW,</span><br><span class="line">      <span class="number">1</span>, <span class="number">1</span>, THCTensor_(data)(state, columns)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* æ¥ä¸‹æ¥è®¡ç®— kernel * columns: */</span></span><br><span class="line">    <span class="keyword">int64_t</span> m = nOutputPlane;</span><br><span class="line">    <span class="keyword">int64_t</span> n = columns-&gt;size(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int64_t</span> k = nInputPlane*kH*kW;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* è®¡ç®— output_n = 1 * weight * columns + 1 * bias */</span></span><br><span class="line">    <span class="comment">/* ä»£ç ä¸­ columns åœ¨ weight å‰é¢æ˜¯å› ä¸º GEMM å‡è®¾çŸ©é˜µæ˜¯åˆ—ä¸»åº */</span></span><br><span class="line">    #ifdef THC_REAL_IS_FLOAT</span><br><span class="line">    THCudaBlas_Sgemm(</span><br><span class="line">    #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">    THCudaBlas_Hgemm(</span><br><span class="line">    #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">    THCudaBlas_Dgemm(</span><br><span class="line">    #endif</span><br><span class="line">        state,</span><br><span class="line">        <span class="string">'n'</span>, <span class="string">'n'</span>,</span><br><span class="line">        n, m, k,</span><br><span class="line">        ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">        THCTensor_(data)(state, columns), n,</span><br><span class="line">        THCTensor_(data)(state, weight), k,</span><br><span class="line">        ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">        THCTensor_(data)(state, output_n), n</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* free ä¸´æ—¶å˜é‡ input_n, output_n ç­‰ */</span></span><br><span class="line">  <span class="comment">/* resize è¾“å‡ºçŸ©é˜µï¼Œä»£ç ç•¥ */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="åå‘ä¼ æ’­">åå‘ä¼ æ’­</span></h4><p>é¦–å…ˆæ¥çœ‹ä¸€ä¸‹å·ç§¯å±‚åå‘ä¼ æ’­çš„å…¬å¼ï¼Œè®¾ç¬¬ <span class="math inline">\(l\)</span> å±‚çš„è¾“å…¥ä¸º <span class="math inline">\(a^{l-1}\)</span>ï¼Œå·ç§¯æ ¸ä¸º <span class="math inline">\(W\)</span>ï¼Œåç½®ä¸º <span class="math inline">\(b\)</span>ï¼Œè¾“å‡ºä¸º <span class="math inline">\(z^l = a^{l-1}*W+b\)</span>ï¼Œç›¸å¯¹äºè¾“å‡ºçš„è¯¯å·®æ¢¯åº¦ä¸º <span class="math inline">\(\delta^l = \frac{\partial \text{Loss}}{\partial z^l}\)</span>ï¼Œåˆ™ç›¸å¯¹äºè¾“å…¥çš„æ¢¯åº¦ä¸ºï¼š <span class="math display">\[\delta^{l-1}=\delta^l*\text{rot180}(W^l)\]</span> ç›¸å¯¹äºæƒé‡å’Œåç½®çš„æ¢¯åº¦ä¸ºï¼š <span class="math display">\[\frac{\partial\text{Loss}}{\partial W^l}=\frac{\partial\text{Loss}}{\partial z^l}\frac{\partial z^l}{\partial W^l}=a^{l-1}*\delta^l\\\frac{\partial\text{Loss}}{\partial b^l}=\sum_{u,v}(\delta^l)_{u,v}\]</span> <strong>æ³¨</strong>ï¼š<span class="math inline">\(*\)</span> ä¸ºå·ç§¯çš„æ„æ€ï¼Œ<span class="math inline">\(\text{rot180}(x)\)</span> ä¸ºæŠŠçŸ©é˜µ <span class="math inline">\(x\)</span> æ—‹è½¬180åº¦çš„æ„æ€ã€‚å…¬å¼æ¨å¯¼å¯ä»¥çœ‹<a href="https://www.cnblogs.com/pinard/p/6494810.html" target="_blank" rel="noopener">è¿™ç¯‡åšå®¢</a>ã€‚</p><p>ä»å…¬å¼å¯ä»¥çœ‹å‡ºåå‘ä¼ æ’­åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šè®¡ç®—å¯¹è¾“å…¥çš„æ¢¯åº¦å’Œè®¡ç®—å¯¹å‚æ•°çš„æ¢¯åº¦ï¼Œè¿™ä¸¤éƒ¨åˆ†ä¹Ÿåˆ†åˆ«å¯¹åº”äº†æ¨¡å—é‡Œçš„ä¸¤ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªåˆ†æã€‚</p><p><strong>THNN_(SpatialConvolutionMM_updateGradInput)</strong></p><p>è¿™éƒ¨åˆ†æ˜¯è®¡ç®—å¯¹è¾“å…¥çš„æ¢¯åº¦ï¼Œè™½ç„¶å…¬å¼æ‘†åœ¨äº†é‚£é‡Œï¼Œä½†Torchçš„ä»£ç å®ç°å¹¶ä¸æ˜¯ç›´æ¥ç¿»è¯‘å…¬å¼ï¼Œæˆ‘ä¹Ÿä¸€ç›´æ²¡èƒ½æŠŠè¿™éƒ¨åˆ†çš„å®ç°å’Œå…¬å¼å¯¹ä¸Šï¼Œä¸è¿‡å€’æ˜¯å¯ä»¥é€šè¿‡å›¾ç¤ºçš„æ–¹å¼æ¥ç†è§£ï¼Œæœ‰ç‚¹åƒå‰å‘ä¼ æ’­çš„é€†è¿‡ç¨‹ï¼ŒæŠŠå·ç§¯åçš„æ¢¯åº¦åˆ†é…å›å·ç§¯å‰ã€‚</p><p>åœ¨ç”»å›¾ä¹‹å‰è¿˜æ˜¯å…ˆå®šä¹‰ä¸€äº›ç¬¦å·ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_updateGradInput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">           THCState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradOutput,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradInput,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *weight,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradColumns,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *ones,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> kW, <span class="keyword">int</span> kH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dW, <span class="keyword">int</span> dH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> padW, <span class="keyword">int</span> padH)</span></span>;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼ˆä¸å‰å‘ä¼ æ’­ç›¸åŒçš„å‚æ•°å°±ä¸é‡å¤ä»‹ç»äº†ï¼‰ï¼Œ</p><ul><li><code>gradOutput</code> æ˜¯ç›¸å¯¹äºè¾“å‡ºçš„æ¢¯åº¦ï¼Œå³ <span class="math inline">\(\delta^l\)</span>ï¼Œå¤§å°ä¸å‰å‘ä¼ æ’­çš„è¾“å‡º <code>output</code> ç›¸åŒï¼›</li><li><code>gradInput</code> æ˜¯ç›¸å¯¹äºè¾“å…¥çš„æ¢¯åº¦ï¼Œå³ <span class="math inline">\(\delta^{l-1}\)</span>ï¼Œæ˜¯è¿™ä¸ªå‡½æ•°éœ€è¦è®¡ç®—çš„å¯¹è±¡ï¼Œå¤§å°ä¸è¾“å…¥ <code>input</code> ç›¸åŒï¼›</li><li><code>gradColumns</code> æ˜¯ä¸ªåˆ—çŸ©é˜µï¼Œç”¨äºå­˜å‚¨ä¸´æ—¶çš„æ¢¯åº¦ï¼Œå¤§å°ä¸º <span class="math inline">\((\text{nInputPlane}\times\text{kH}\times\text{kW})\times(\text{outputHeight}\times\text{outputWidth})\)</span>ï¼›</li></ul><p>ä»£ç çš„å®ç°é€»è¾‘æ˜¯ç”¨æƒé‡çš„è½¬ç½®ä¹˜ä»¥è¾“å‡ºæ¢¯åº¦ï¼Œå¾—åˆ°<code>gradColumns</code>ï¼Œç„¶åé€šè¿‡col2imè¿˜åŸåˆ°è¾“å…¥çš„å¤§å°ï¼Œå³å¾—åˆ°äº†ç›¸å¯¹è¾“å…¥çš„æ¢¯åº¦ <code>gradInput</code>ã€‚è¿™ä¸ªæ“ä½œçœ‹èµ·æ¥å°±æ˜¯å‰å‘ä¼ æ’­çš„é€†æ“ä½œï¼Œä½†æ˜¯æä¸æ‡‚ä¸ºä»€ä¹ˆè¿™æ ·å°±å®ç°äº† <span class="math inline">\(\delta^l*\text{rot180}(W^l)\)</span>ï¼Œ<strong>å¦‚æœæœ‰å¤§ä½¬çŸ¥é“å¸Œæœ›è¯„è®ºåŒºæŒ‡ç‚¹ä¸€ä¸‹</strong>ã€‚ä½¿ç”¨å‰é¢ä¾‹å­çš„è®¾å®šï¼Œè¿™æ³¢æ“ä½œçš„ç¤ºæ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="/images/pytorch/convmm2.png"></p><p><img src="/images/pytorch/col2im.png"></p><p><strong>æ ¸å¿ƒéƒ¨åˆ†ä»£ç </strong>ï¼ˆå…¶ä½™éƒ¨åˆ†ä¸å‰å‘ä¼ æ’­ç±»ä¼¼ï¼‰</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* å¾ªç¯å–æ¯ä¸ªæ‰¹æ¬¡ï¼š */</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> elt = <span class="number">0</span>; elt &lt; batchSize; elt ++) &#123;</span><br><span class="line">  <span class="comment">/* gradInput_n = gradInput[elt]; gradInput_n åŒç† */</span></span><br><span class="line">  THCTensor_(select)(state, gradInput_n, gradInput, <span class="number">0</span>, elt);</span><br><span class="line">  THCTensor_(select)(state, gradOutput_n, gradOutput, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// M,N,K are dims of matrix A and B</span></span><br><span class="line">  <span class="keyword">int64_t</span> m = nInputPlane*kW*kH;</span><br><span class="line">  <span class="keyword">int64_t</span> n = gradColumns-&gt;size(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">int64_t</span> k = nOutputPlane;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* è°ƒç”¨GEMMè®¡ç®— gradColumns = weight' * gradOutput_n */</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">ifdef</span> THC_REAL_IS_FLOAT</span></span><br><span class="line">  THCudaBlas_Sgemm(</span><br><span class="line">  #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">  THCudaBlas_Hgemm(</span><br><span class="line">  #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">  THCudaBlas_Dgemm(</span><br><span class="line">  #endif</span><br><span class="line">      state,</span><br><span class="line">      <span class="string">'n'</span>, <span class="string">'t'</span>,</span><br><span class="line">      n, m, k,</span><br><span class="line">      ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">      THCTensor_(data)(state, gradOutput_n), n,</span><br><span class="line">      THCTensor_(data)(state, weight), m,</span><br><span class="line">      ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">0</span>),</span><br><span class="line">      THCTensor_(data)(state, gradColumns), n</span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* è°ƒç”¨ col2im æŠŠ gradColumns è¿˜åŸä¸º gradInput_n */</span></span><br><span class="line">  col2im&lt;<span class="keyword">scalar_t</span>, accreal&gt;(</span><br><span class="line">    THCState_getCurrentStream(state),</span><br><span class="line">    THCTensor_(data)(state, gradColumns),</span><br><span class="line">    nInputPlane, inputHeight, inputWidth, outputHeight,</span><br><span class="line">    outputWidth, kH, kW, padH, padW, dH, dW,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, THCTensor_(data)(state, gradInput_n)</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>THNN_(SpatialConvolutionMM_accGradParameters)</strong></p><p>æ¥ä¸‹æ¥çœ‹è®¡ç®—å‚æ•°æ¢¯åº¦çš„éƒ¨åˆ†ï¼Œè¿™éƒ¨åˆ†ç›¸å¯¹å¥½ç†è§£ï¼Œå› ä¸ºä»£ç å’Œå…¬å¼ä¸€æ ·ï¼Œè¿˜æ˜¯å…ˆçœ‹å‡½æ•°å£°æ˜ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_accGradParameters)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">           THCState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradOutput,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradWeight,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradBias,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *columns,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *ones,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> kW, <span class="keyword">int</span> kH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dW, <span class="keyword">int</span> dH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> padW, <span class="keyword">int</span> padH,</span></span></span><br><span class="line"><span class="function"><span class="params">           accreal scale_)</span></span>;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼Œ</p><ul><li><code>gradWeight</code> æ˜¯æƒé‡çš„æ¢¯åº¦ï¼Œæ˜¯è¿™ä¸ªå‡½æ•°éœ€è¦è®¡ç®—çš„å¯¹è±¡ï¼Œå¤§å°å’Œæƒé‡ç›¸åŒï¼›</li><li><code>gradBias</code> æ˜¯åç½®çš„æ¢¯åº¦ï¼Œä¹Ÿæ˜¯å‡½æ•°éœ€è¦è®¡ç®—çš„å¯¹è±¡ï¼Œå¤§å°ä¸åç½®ç›¸åŒï¼ˆå°±æ˜¯ä¸€ä¸ªVectorï¼‰</li><li><code>columns</code> æ˜¯ç”¨æ¥å­˜å‚¨ im2col çš„ç»“æœï¼Œå› ä¸ºè¦è®¡ç®—å·ç§¯ï¼Œæ‰€ä»¥è¦æŠŠè¾“å…¥å±•å¼€</li><li><code>scale_</code> æ˜¯å­¦ä¹ é€Ÿç‡ï¼ˆlearning rateï¼‰</li></ul><p>å·²çŸ¥<strong>æƒé‡æ¢¯åº¦</strong>çš„è®¡ç®—å…¬å¼ä¸º <span class="math inline">\(\frac{\partial\text{Loss}}{\partial W^l}=a^{l-1}*\delta^l\)</span>ï¼Œè¿™ä¸ªå·ç§¯çš„è®¡ç®—æ–¹å¼å’Œå‰å‘ä¼ æ’­ç›¸åŒï¼šé¦–å…ˆæŠŠè¾“å…¥ï¼ˆ<span class="math inline">\(a^{l-1}\)</span>ï¼‰é€šè¿‡im2colå±•å¼€ä¸ºåˆ—çŸ©é˜µï¼Œå­˜å‚¨åˆ°<code>columns</code>é‡Œï¼Œç„¶åç”¨ <code>gradOutput</code> ä¹˜ä»¥ <code>columns</code> è®¡ç®—å·ç§¯ã€‚è€Œ<strong>åç½®æ¢¯åº¦</strong>çš„è®¡ç®—å°±æ˜¯æŠŠ <code>gradOutput</code> ç´¯åŠ æˆä¸€ä¸ªé•¿åº¦ä¸º <span class="math inline">\(\text{nOutputPlane}â€‹\)</span> çš„ Tensor å³å¯ã€‚</p><p><strong>æ ¸å¿ƒä»£ç </strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_accGradParameters)</span><span class="params">(<span class="comment">/* ç•¥ */</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* å¾ªç¯å–æ¯ä¸ªbatchï¼š */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> elt = <span class="number">0</span>; elt &lt; batchSize; elt ++) &#123;</span><br><span class="line">    <span class="comment">/* gradOutput_n = gradOutput[elt] */</span></span><br><span class="line">    THCTensor_(select)(state, gradOutput_n, gradOutput, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* è®¡ç®—æƒé‡æ¢¯åº¦ */</span></span><br><span class="line">    <span class="keyword">if</span> (gradWeight) &#123;</span><br><span class="line">      <span class="comment">/* input_n = input[elt] */</span></span><br><span class="line">      THCTensor_(select)(state, input_n, input, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* æŠŠ input_n å±•å¼€ä¸º columns */</span></span><br><span class="line">      im2col(</span><br><span class="line">        THCState_getCurrentStream(state),</span><br><span class="line">        THCTensor_(data)(state, input_n),</span><br><span class="line">        nInputPlane, inputHeight, inputWidth,</span><br><span class="line">        outputHeight, outputWidth,</span><br><span class="line">        kH, kW, padH, padW, dH, dW,</span><br><span class="line">        <span class="number">1</span>, <span class="number">1</span>, THCTensor_(data)(state, columns)</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">      <span class="keyword">int64_t</span> m = nOutputPlane;</span><br><span class="line">      <span class="keyword">int64_t</span> n = nInputPlane*kW*kH;</span><br><span class="line">      <span class="keyword">int64_t</span> k = columns-&gt;size(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* è°ƒç”¨GEMMè®¡ç®—gradWeight += scale * gradOutput_n * columns'*/</span></span><br><span class="line">      <span class="meta">#<span class="meta-keyword">ifdef</span> THC_REAL_IS_FLOAT</span></span><br><span class="line">      THCudaBlas_Sgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">      THCudaBlas_Hgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      THCudaBlas_Dgemm(</span><br><span class="line">      #endif</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>, <span class="string">'n'</span>,</span><br><span class="line">          n, m, k,</span><br><span class="line">          scale,</span><br><span class="line">          THCTensor_(data)(state, columns), k,</span><br><span class="line">          THCTensor_(data)(state, gradOutput_n), k,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, gradWeight), n</span><br><span class="line">      );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* è®¡ç®—åç½®æ¢¯åº¦ */</span></span><br><span class="line">    <span class="keyword">if</span> (gradBias) &#123;</span><br><span class="line">     </span><br><span class="line">      <span class="keyword">int64_t</span> m_ = nOutputPlane;</span><br><span class="line">      <span class="keyword">int64_t</span> k_ = outputHeight * outputWidth;</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* è°ƒç”¨GEMVè®¡ç®— gradBias += scale * gradOutput_n * ones */</span></span><br><span class="line">      #<span class="keyword">if</span> defined(THC_REAL_IS_FLOAT) || defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      #ifdef THC_REAL_IS_FLOAT</span><br><span class="line">      THCudaBlas_Sgemv(</span><br><span class="line">      #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      THCudaBlas_Dgemv(</span><br><span class="line">      #endif</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>,</span><br><span class="line">          k_, m_,</span><br><span class="line">          scale,</span><br><span class="line">          THCTensor_(data)(state, gradOutput_n), k_,</span><br><span class="line">          THCTensor_(data)(state, ones), <span class="number">1</span>,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, gradBias), <span class="number">1</span></span><br><span class="line">      );</span><br><span class="line">      #endif</span><br><span class="line">      #ifdef THC_REAL_IS_HALF</span><br><span class="line">      THCudaBlas_Hgemm(</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>, <span class="string">'n'</span>,</span><br><span class="line">          m_, <span class="number">1</span>, k_,</span><br><span class="line">          scale,</span><br><span class="line">          THCTensor_(data)(state, gradOutput_n), k_,</span><br><span class="line">          THCTensor_(data)(state, ones), k_,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, gradBias), m_</span><br><span class="line">      );</span><br><span class="line">      #endif</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="aten">ATen</span></h2><p>çœ‹äº†<code>THNN.h</code>çš„è¯»è€…å¯èƒ½ä¼šå‘ç°ï¼ŒTHNNå’ŒTHCUNNåªå®šä¹‰äº†å°‘é‡çš„ç¥ç»ç½‘ç»œç›¸å…³çš„å‡½æ•°ï¼Œå…¶å®å¤§éƒ¨åˆ†éƒ½å®šä¹‰åœ¨ATenä¸­ï¼Œè¿™ä¸ªATenæ˜¯æŒ‡<code>pytorch/aten/src/ATen</code>æ–‡ä»¶å¤¹ï¼ˆä¸‹åŒï¼‰ã€‚è¯´åˆ°åº•ï¼ŒTHç³»åˆ—åº“éƒ½æ˜¯torch luaæ—¶ä»£ç•™ä¸‹çš„äº§ç‰©ï¼Œæ˜¯ç”¨Cè¯­è¨€å®ç°çš„ï¼Œåæ¥PyTorchå¼€å‘è€…è§‰å¾—cppå¤§æ³•å¥½ï¼Œå°±ç”¨C++å†™äº†ATenï¼ŒæŠŠTHé‡Œçš„æ¥å£éƒ½å°è£…äº†ï¼ŒåŒæ—¶æ–°çš„APIç›´æ¥åœ¨ATené‡Œå®ç°ã€‚</p><p>è¿™ä¸ªATenæœ‰ç‚¹æ„æ€ï¼Œå®ƒå¤§æ¦‚å¹²äº†è¿™ä¹ˆå‡ ä»¶äº‹æƒ…ï¼š</p><ul><li>åœ¨<code>ATen/core/Tensor.h</code>å®šä¹‰äº†<code>at::Tensor</code>ç±»å‹ï¼Œè¿™ä¸ªæ˜¯C++å‰ç«¯ä»¥åŠæ›´ä¸Šå±‚çš„APIéƒ½åœ¨ç”¨çš„Tensorç±»å‹ï¼Œå®ƒçš„æˆå‘˜å†…æœ‰ä¸€ä¸ª<code>TensorImpl impl_</code>ï¼Œæä¾›åº•å±‚å®ç°ï¼›</li><li>å®ç°å’Œå°è£…äº†æœ‰å…³Tensorçš„æ‰€æœ‰æ“ä½œï¼Œå¹¶æ ¹æ®æ•°æ®ç±»å‹å’Œè®¾å¤‡è¿›è¡Œè‡ªåŠ¨æ´¾å‘ï¼›</li><li>ä½¿ç”¨Pythonè„šæœ¬ç”ŸæˆATen APIã€‚</li></ul><p>å…¶ä¸­ä»THï¼ˆåŒ…æ‹¬THCã€THNNç­‰ï¼‰é‡Œå°è£…çš„å‡½æ•°å«åš legacyå‡½æ•°ï¼Œè€Œåœ¨ATenç›´æ¥å®ç°çš„å‡½æ•°å« nativeå‡½æ•°ã€‚nativeå‡½æ•°çš„å®ç°å…¨åœ¨<code>ATen/native</code>æ–‡ä»¶å¤¹ä¸­ï¼Œå®ç°äº†THNNé‡Œæ²¡æœ‰çš„ç¥ç»ç½‘ç»œå’ŒTensoræ“ä½œï¼Œæ¯”å¦‚RNNä»€ä¹ˆçš„ï¼ŒAPIåˆ—è¡¨åœ¨<code>ATen/native/native_functions.yaml</code>é‡Œï¼Œæ„Ÿå…´è¶£çš„ç«¥é‹å¯ä»¥è‡ªå·±é˜…è¯»ã€‚</p><p>äº†è§£äº†ç¥ç»ç½‘ç»œæ¯ä¸€å±‚çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„å®ç°ä¹‹åï¼Œä¸‹ä¸€æ­¥å°±æ˜¯æ§åˆ¶æ‰§è¡Œé¡ºåºäº†ï¼Œä¹Ÿå°±æ˜¯è‡ªåŠ¨å¾®åˆ†ï¼ˆAutogradï¼‰ï¼Œä¸‹ä¸€ç« å°†ä»‹ç»PyTorchè‡ªåŠ¨å¾®åˆ†çš„å®ç°ã€‚</p><p>ã¤ã¥ã</p><table><thead><tr class="header"><th style="text-align: left;">ä¸Šä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch2/">THC</a></th><th style="text-align: right;">ä¸‹ä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch4/">Autograd</a></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"></td><td style="text-align: right;"></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Neural Network </tag>
            
            <tag> PyTorch </tag>
            
            <tag> THNN </tag>
            
            <tag> CONV </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PyTorchæºç æµ…æ(2)ï¼šTHC</title>
      <link href="/2019/05/05/PyTorch2/"/>
      <url>/2019/05/05/PyTorch2/</url>
      
        <content type="html"><![CDATA[<p>è¿™ç¯‡ä¸»è¦çœ‹ Torch CUDA éƒ¨åˆ†ï¼Œå¯¹åº”æºç ç›®å½•<code>aten/src/THC</code>ï¼Œé‡Œé¢åŒ…å«äº†è®¸å¤šC++å’ŒCUDAä»£ç ã€‚è¿™éƒ¨åˆ†å®ç°äº†æ“ä½œ THCTensor å’Œ THCStorage çš„æ¥å£ï¼Œä¸è¿‡åº•å±‚ç”¨çš„æ•°æ®ç»“æ„è¿˜æ˜¯<code>TensorImpl</code>å’Œ<code>StorageImpl</code>ã€‚THCé‡Œçš„æ¥å£ä¹Ÿæ˜¯é€šè¿‡Cè¯­è¨€èŒƒå¼å®ç°çš„ï¼Œä½†æ˜¯Applyç³»åˆ—æ“ä½œä¸å†ç”±å®æ¥å®ç°ï¼Œè€Œæ˜¯ä½¿ç”¨äº†C++æ¨¡æ¿ã€‚å…¶ä»–çš„åŒºåˆ«è¿˜æœ‰allocatorä¸åŒï¼Œä»¥åŠå¤šäº† THCState ç»“æ„ã€‚</p><a id="more"></a><p>è®°å·ï¼š</p><ul><li>TH = TorcH</li><li>THC = TorcH Cuda</li></ul><p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#thcstate">THCState</a></li><li><a href="#thcallocator">THCAllocator</a><ul><li><a href="#thccachingallocator">THCCachingAllocator</a></li><li><a href="#thccachinghostallocator">THCCachingHostAllocator</a></li></ul></li><li><a href="#thcapply">THCApply</a></li><li><a href="#æ€»ç»“">æ€»ç»“</a></li></ul><!-- tocstop --><h2><span id="thcstate">THCState</span></h2><p>é€šè¿‡è§‚å¯ŸTHCé‡Œé¢å®ç°çš„æ¥å£ä¸éš¾å‘ç°ï¼Œå‡ ä¹æ¯ä¸ªæ¥å£éƒ½éœ€è¦ä¼ å…¥ä¸€ä¸ª<code>THCState*</code>å‚æ•°ï¼Œè€Œè¿™æ˜¯åœ¨THä¸­æ²¡æœ‰çš„ï¼Œè¿™ä¸ªTHCStateçš„å£°æ˜åœ¨<code>THCGeneral.hpp</code>ä¸­ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THCState</span> &#123;</span></span><br><span class="line">  <span class="comment">// è²Œä¼¼æ˜¯ç”¨æ¥ç”Ÿæˆéšæœºæ•°çš„</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">THCRNGState</span>* <span class="title">rngState</span>;</span></span><br><span class="line">  <span class="comment">// è®°å½•æ¯ä¸ªCUDAè®¾å¤‡çš„cuBLASå¥æŸ„å’ŒcuSparseå¥æŸ„</span></span><br><span class="line">  THCCudaResourcesPerDevice* resourcesPerDevice;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// cudaè®¾å¤‡ä¸ªæ•°</span></span><br><span class="line">  <span class="keyword">int</span> numDevices; </span><br><span class="line"></span><br><span class="line">  at::Allocator* cudaHostAllocator;     <span class="comment">// å†…å­˜åˆ†é…å™¨</span></span><br><span class="line">  at::Allocator* cudaDeviceAllocator;   <span class="comment">// æ˜¾å­˜åˆ†é…å™¨</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// äºŒç»´æ•°ç»„ï¼Œå¤§å°ä¸º numDevices * numDevices</span></span><br><span class="line">  <span class="comment">// æ•°ç»„ä¸­çš„æ¯ä¸€é¡¹ i, j è®°å½•äº† CUDA_i èƒ½å¦ç›´æ¥ä» CUDA_j å¤åˆ¶æ•°æ®</span></span><br><span class="line">  <span class="comment">// å¦‚æœå€¼ä¸º 1 ä»£è¡¨å…è®¸æ‹·è´ï¼Œ0 ä»£è¡¨ä¸å…è®¸ï¼Œ-1 ä»£è¡¨ä¸çŸ¥é“ï¼ˆé»˜è®¤å€¼ï¼‰</span></span><br><span class="line">  <span class="keyword">int</span>** p2pAccessEnabled;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>THCStateæ˜¯ä¸€ä¸ªå…¨å±€CUDAçŠ¶æ€ï¼Œè®°å½•äº†CUDAè®¾å¤‡çš„æ‰€æœ‰æœ‰ç”¨çš„ä¿¡æ¯ï¼Œå®ƒçš„åˆå§‹åŒ–åœ¨<code>THCGeneral.cpp</code>ä¸­ï¼Œä»£ç å¹¶ä¸éš¾ç†è§£ã€‚</p><blockquote><p>æ³¨ <strong>hostå’Œdevice</strong>ï¼šåœ¨CUDAç¼–ç¨‹ä¸­ï¼Œ<em>host</em> æŒ‡çš„æ˜¯CPUå’Œå®ƒçš„å†…å­˜ï¼Œè€Œ <em>device</em> æŒ‡GPUåŠå…¶æ˜¾å­˜ã€‚åœ¨ <em>host</em> ä¸Šè¿è¡Œçš„ä»£ç å¯ä»¥æ“æ§å†…å­˜å’Œæ˜¾å­˜ï¼Œè¿˜å¯ä»¥å¯åŠ¨ <em>kernels</em> åœ¨GPUä¸Šè®¡ç®—ã€‚å› ä¸ºCUDAç¼–ç¨‹çš„è¿™äº›ç‰¹æ€§ï¼Œä¸€ä¸ªå…¸å‹CUDAç¨‹åºçš„æ‰§è¡Œè¿‡ç¨‹ä¸ºï¼š</p><ol type="1"><li><p>åˆ†é…å†…å­˜å’Œæ˜¾å­˜ç©ºé—´</p></li><li><p>åˆå§‹åŒ–å†…å­˜æ•°æ®ï¼ˆhostï¼‰</p></li><li><p>æŠŠæ•°æ®ä»å†…å­˜ (host) ä¼ é€åˆ°æ˜¾å­˜ (device)</p></li><li><p>æ‰§è¡Œ kernels</p></li><li><p>æŠŠç»“æœä»æ˜¾å­˜ (device) ä¼ å›å†…å­˜ (host)</p></li></ol></blockquote><h2><span id="thcallocator">THCAllocator</span></h2><p><br></p><h3><span id="thccachingallocator">THCCachingAllocator</span></h3><p>æŸ¥çœ‹THCStateåˆå§‹åŒ–çš„ä»£ç ä¸éš¾å‘ç°ï¼Œæ˜¾å­˜åˆ†é…å™¨<code>cudaDeviceAllocator</code>çš„ç±»å‹ä¸º<code>CudaCachingAllocator</code>ï¼Œå®ƒçš„å®ç°åœ¨<code>c10/cuda/CUDACachingAllocator.cpp</code>ä¸­ã€‚è¿›ä¸€æ­¥è§‚å¯Ÿåå‘ç°ï¼Œ<code>CudaCachingAllocator</code>è°ƒç”¨çš„åˆ†é…å†…å­˜å‡½æ•°å®é™…ä¸Šæ˜¯<code>THCCachingAllocator</code>å®ç°çš„ï¼Œ<code>THCCachingAllocator</code>ä¸å…‰å‘ç³»ç»Ÿè¯·æ±‚åˆ†é…æ˜¾å­˜ï¼Œè¿˜å®ç°äº†ç¼“å­˜ç®¡ç†ç³»ç»Ÿï¼Œæˆ‘ä»¬ä¸»è¦æ¥çœ‹ä¸€ä¸‹<code>THCCachingAllocator</code>çš„å®ç°ã€‚</p><p>é¦–å…ˆå£°æ˜ä¸€ä¸ªå†…å­˜åŒºå—çš„ç»“æ„ä½“ï¼Œé‡Œé¢å­˜å‚¨è®¾å¤‡ã€streamã€åŒºå—å¤§å°ç­‰ä¿¡æ¯ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Block</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span>           device;      <span class="comment">// gpu</span></span><br><span class="line">  cudaStream_t  stream;      <span class="comment">// allocation stream</span></span><br><span class="line">  stream_set    stream_uses; <span class="comment">// streams on which the block was used</span></span><br><span class="line">  <span class="keyword">size_t</span>        size;        <span class="comment">// block size in bytes</span></span><br><span class="line">  <span class="keyword">char</span>*         ptr;         <span class="comment">// memory address</span></span><br><span class="line">  <span class="keyword">bool</span>          allocated;   <span class="comment">// in-use flag      </span></span><br><span class="line">  <span class="keyword">int</span>           event_count; <span class="comment">// number of outstanding CUDA events</span></span><br><span class="line">  <span class="comment">// prev block if split from a larger allocation</span></span><br><span class="line">  Block*        prev;</span><br><span class="line">  <span class="comment">// next block if split from a larger allocation</span></span><br><span class="line">  Block*        next;</span><br><span class="line">  </span><br><span class="line">  Block(<span class="keyword">int</span> device, cudaStream_t stream, <span class="keyword">size_t</span> size) :</span><br><span class="line">      device(device), stream(stream), stream_uses(), size(size),</span><br><span class="line">      ptr(ptr), allocated(<span class="number">0</span>), prev(<span class="literal">NULL</span>), next(<span class="literal">NULL</span>),</span><br><span class="line">      event_count(<span class="number">0</span>) &#123; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>ä¸ºäº†æ–¹ä¾¿æ¯”è¾ƒæŸ¥æ‰¾ï¼Œä¸º<code>Block</code>å®šä¹‰æ¯”è¾ƒå¤§å°çš„æ–¹æ³•ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">bool</span> <span class="title">BlockComparator</span><span class="params">(<span class="keyword">const</span> Block* a, <span class="keyword">const</span> Block* b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">// é¦–å…ˆæ¯”è¾ƒè®¾å¤‡ID</span></span><br><span class="line">  <span class="keyword">if</span> (a-&gt;device != b-&gt;device) &#123;</span><br><span class="line">    <span class="keyword">return</span> a-&gt;device &lt; b-&gt;device;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// å†æ¯”è¾ƒstream id</span></span><br><span class="line">  <span class="keyword">if</span> (a-&gt;stream != b-&gt;stream) &#123;</span><br><span class="line">    <span class="keyword">return</span> (<span class="keyword">uintptr_t</span>)a-&gt;stream &lt; (<span class="keyword">uintptr_t</span>)b-&gt;stream;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// å†æ¯”è¾ƒåŒºå—å¤§å°</span></span><br><span class="line">  <span class="keyword">if</span> (a-&gt;size != b-&gt;size) &#123;</span><br><span class="line">    <span class="keyword">return</span> a-&gt;size &lt; b-&gt;size;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// æœ€åæ¯”è¾ƒå†…å­˜åœ°å€å¤§å°</span></span><br><span class="line">  <span class="keyword">return</span> (<span class="keyword">uintptr_t</span>)a-&gt;ptr &lt; (<span class="keyword">uintptr_t</span>)b-&gt;ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä½¿ç”¨æ­¤æ¯”è¾ƒå‡½æ•°çš„è¯<code>Block(device, NULL, 0)</code>å°±æ˜¯è®¾å¤‡deviceä¸ŠåŒºå—å¤§å°çš„ä¸‹é™ï¼Œè€Œ<code>Block(device + 1, NULL, 0)</code>åˆ™æ˜¯è®¾å¤‡deviceä¸Šçš„åŒºå—å¤§å°ä¸Šé™ã€‚</p><p>æ¥ä¸‹æ¥çœ‹<code>THCCachingAllocator</code>å®šä¹‰çš„å±æ€§ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THCCachingAllocator</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">typedef</span> <span class="title">bool</span> <span class="params">(*Comparison)</span><span class="params">(<span class="keyword">const</span> Block*, <span class="keyword">const</span> Block*)</span></span>;</span><br><span class="line">  <span class="keyword">typedef</span> <span class="built_in">std</span>::<span class="built_in">set</span>&lt;Block*, Comparison&gt; FreeBlocks;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// device statistics</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;DeviceStats&gt; device_stats;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// lock around all operations</span></span><br><span class="line">  <span class="built_in">std</span>::mutex mutex;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// lock around calls to cudaFree (to prevent deadlocks with NCCL)</span></span><br><span class="line">  <span class="built_in">std</span>::mutex cuda_free_mutex;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// cached blocks larger than 1 MB</span></span><br><span class="line">  FreeBlocks large_blocks;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// cached blocks 1 MB or smaller</span></span><br><span class="line">  FreeBlocks small_blocks;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// allocated blocks by device pointer</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="keyword">void</span>*, Block*&gt; allocated_blocks;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// outstanding cuda events</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">deque</span>&lt;<span class="built_in">std</span>::pair&lt;cudaEvent_t, Block*&gt;&gt; cuda_events;</span><br><span class="line"></span><br><span class="line">  THCCachingAllocator() :</span><br><span class="line">      large_blocks(BlockComparator),</span><br><span class="line">      small_blocks(BlockComparator) &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ¯ä¸ªå±æ€§æ˜¯å¹²ä»€ä¹ˆçš„æ³¨é‡Šå·²ç»å†™çš„å¾ˆæ¸…æ¥šäº†ï¼Œæ³¨æ„åˆ°<code>FreeBlocks</code>ç±»å‹æ˜¯Blockçš„æœ‰åºé›†åˆï¼Œæ›¾ç»åˆ†é…è¿‡ä½†æ˜¯ç”¨å®Œäº†çš„å†…å­˜ä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œå¤§äº1Mçš„åˆ†å—ä¼šè¿›å…¥<code>large_blocks</code>ï¼Œå°äºç­‰äº1Mçš„åˆ†å—è¿›å…¥<code>small_blocks</code>ã€‚ä¹‹åå†å‘åˆ†é…å™¨ç”³è¯·å†…å­˜æ—¶ä¼šå…ˆä»ç¼“å­˜é‡Œé¢åˆ†é…ï¼Œåˆ†é…ç­–ç•¥ä¸ºBest-fitï¼Œå³è¿”å›å¤§äºç­‰äºæ‰€éœ€å¤§å°çš„æœ€å°åˆ†å—ï¼ˆä½¿ç”¨<code>set::lower_bound</code>å®ç°ï¼‰ã€‚å¦‚æœç¼“å­˜ä¸­çš„æ‰€æœ‰åˆ†å—éƒ½å°äºç›®æ ‡å¤§å°ï¼Œé‚£ä¹ˆä¼šå°è¯•<code>cudaMalloc</code>åˆ†é…ç›®æ ‡å¤§å°çš„å†…å­˜ï¼Œå¦‚æœè¿˜æ˜¯å¤±è´¥çš„è¯å°±æŠŠç¼“å­˜releaseäº†å†è¯•<code>cudaMalloc</code>ï¼Œå¦‚æœè¿˜æ˜¯åˆ†é…å¤±è´¥å°±ä¼šæŠ¥å†…ï¼ˆæ˜¾ï¼‰å­˜ä¸è¶³çš„é”™è¯¯ã€‚</p><p>å¦‚æœä¸Šé¢æŸä¸€æ­¥åˆ†é…å†…å­˜æˆåŠŸäº†ï¼Œç”±äºåˆ†é…çš„å—å¾ˆæœ‰å¯èƒ½æ¯”å®é™…éœ€è¦çš„sizeå¤§ï¼Œæ‰€ä»¥è¿˜è¦è¿›è¡Œåˆ‡å‰²æ“ä½œã€‚åˆ‡å‰²æ“ä½œå°±æ˜¯åˆ¤æ–­å¤šä½™çš„å¤§å°æ˜¯å¦å¤§äº1Mï¼Œå¦‚æœå¤§äº1Må°±æ’å…¥åˆ°<code>large_blocks</code>ï¼Œå¦åˆ™æ’å…¥åˆ°<code>small_blocks</code>ä¸­ï¼Œç„¶åå†è®¾ç½®ä¸€ä¸‹<code>prev</code>å’Œ<code>next</code>æŒ‡é’ˆå³å¯ã€‚</p><p>åˆ†é…å†…å­˜çš„ï¼ˆç®€ç•¥ï¼‰å®ç°å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * allocates a block which is safe to use from the provided stream </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">void</span> THCCachingAllocator::<span class="built_in">malloc</span>(<span class="keyword">void</span>** devPtr, <span class="keyword">size_t</span> size, cudaStream_t stream)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// åŠ é”ï¼Œå‡½æ•°è¿”å›æ—¶è‡ªåŠ¨é‡Šæ”¾</span></span><br><span class="line">  <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(mutex);</span><br><span class="line">  <span class="comment">// è·å–è®¾å¤‡ID</span></span><br><span class="line">  <span class="keyword">int</span> device;</span><br><span class="line">  C10_CUDA_CHECK(cudaGetDevice(&amp;device));</span><br><span class="line">  <span class="comment">// ç±»ä¼¼å››èˆäº”å…¥</span></span><br><span class="line">  size = round_size(size);</span><br><span class="line">  <span class="keyword">bool</span> small = size &lt;= kSmallAlloc;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// æœç´¢ç›®æ ‡</span></span><br><span class="line">  <span class="function">Block <span class="title">search_key</span><span class="params">(device, stream, size)</span></span>;</span><br><span class="line">  <span class="comment">// åˆ¤æ–­åº”è¯¥ä»å“ªä¸ªé›†åˆåˆ†é…</span></span><br><span class="line">  <span class="keyword">auto</span>&amp; free_blocks = small ? small_blocks : large_blocks;</span><br><span class="line"></span><br><span class="line">  Block* block = <span class="literal">NULL</span>;</span><br><span class="line">  Block* remaining = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// æœç´¢å¤§äºç­‰äºç›®æ ‡çš„ç¬¬ä¸€ä¸ªå—</span></span><br><span class="line">  <span class="keyword">auto</span> it = free_blocks.lower_bound(&amp;search_key);</span><br><span class="line">  <span class="keyword">if</span> (it != free_blocks.end() &amp;&amp; (*it)-&gt;device == device &amp;&amp; (*it)-&gt;stream == stream) &#123;</span><br><span class="line">    <span class="comment">// å¦‚æœdeviceå’Œstreamå’Œç›®æ ‡ç›¸åŒçš„è¯å°±åˆ†é…è¯¥å—å†…å­˜</span></span><br><span class="line">    block = *it;</span><br><span class="line">    free_blocks.erase(it);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">void</span>* ptr;</span><br><span class="line">    <span class="keyword">size_t</span> alloc_size = small ? kSmallAlloc : size;</span><br><span class="line">    <span class="comment">// å°è¯•å‘ç³»ç»Ÿç”³è¯·å†…å­˜</span></span><br><span class="line">    cudaError_t err = cuda_malloc_retry(device, &amp;ptr, alloc_size);</span><br><span class="line">    <span class="keyword">if</span> (err != cudaSuccess) &#123;</span><br><span class="line">      <span class="keyword">if</span> (err == cudaErrorMemoryAllocation) &#123;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">auto</span>&amp; stats = get_stats_for_device(device);</span><br><span class="line">        <span class="comment">// æŠ¥é”™ï¼šåˆ†é…å†…å­˜å¤±è´¥ï¼</span></span><br><span class="line">        AT_ERROR(<span class="string">"CUDA out of memory. Tried to allocate"</span>);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        C10_CUDA_CHECK(err);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    block = <span class="keyword">new</span> Block(device, stream, alloc_size, (<span class="keyword">char</span>*)ptr);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (block-&gt;size - size &gt;= (small? kRoundSmall : kSmallAlloc+<span class="number">1</span>)) &#123;</span><br><span class="line">    remaining = block;</span><br><span class="line">    <span class="comment">// åˆ‡å‰²å¤šä½™å†…å­˜å—</span></span><br><span class="line">    block = <span class="keyword">new</span> Block(device, stream, size, block-&gt;ptr);</span><br><span class="line">    block-&gt;prev = remaining-&gt;prev;</span><br><span class="line">    <span class="keyword">if</span> (block-&gt;prev) &#123;</span><br><span class="line">      block-&gt;prev-&gt;next = block;</span><br><span class="line">    &#125;</span><br><span class="line">    block-&gt;next = remaining;</span><br><span class="line"></span><br><span class="line">    remaining-&gt;prev = block;</span><br><span class="line">    remaining-&gt;ptr += size;</span><br><span class="line">    remaining-&gt;size -= size;</span><br><span class="line">    <span class="comment">// æŠŠå‰©ä½™å—æ’å…¥ç¼“å­˜</span></span><br><span class="line">    free_blocks.insert(remaining);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  block-&gt;allocated = <span class="literal">true</span>;</span><br><span class="line">  allocated_blocks[block-&gt;ptr] = block;</span><br><span class="line"></span><br><span class="line">  *devPtr = (<span class="keyword">void</span>*)block-&gt;ptr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>é‡Šæ”¾å†…å­˜çš„æ—¶å€™ä¸ä¼šæŠŠå†…å­˜ç›´æ¥è¿˜ç»™ç³»ç»Ÿï¼Œè€Œæ˜¯ç¼“å­˜èµ·æ¥æ ¹æ®å—å¤§å°æ’å…¥<code>large_blocks</code>æˆ–<code>small_blocks</code>ï¼Œåœ¨æ’å…¥ä¹‹å‰è¿˜ä¼šæ£€æŸ¥èƒ½å¦å’Œä¹‹å‰è¢«åˆ‡å‰²çš„éƒ¨åˆ†åˆå¹¶ã€‚</p><blockquote><p>æ³¨ <strong>CUDAæ¶æ„</strong>ï¼šä»ç¡¬ä»¶ä¸Šçœ‹ï¼ŒCUDAè®¾å¤‡å«æœ‰ SP (Streaming Processor) å’Œ SM (Streaming Multiprocessor)ï¼›ä»è½¯ä»¶ä¸Šçœ‹ï¼Œæœ‰ thread, block, grid, å’Œ warp ç­‰æ¦‚å¿µã€‚</p><ul><li><p>SPï¼šæœ€åŸºæœ¬çš„å¤„ç†å•å…ƒï¼Œæœ€åå…·ä½“çš„æŒ‡ä»¤éƒ½æ˜¯åœ¨SPä¸Šå¤„ç†çš„ã€‚</p></li><li><p>SMï¼šå¤šä¸ªSPåŠ ä¸Šå…¶ä»–èµ„æºï¼Œå¦‚ï¼šwarp scheduler, register, shared memoryç­‰ç»„æˆçš„å¤§æ ¸ï¼Œç›¸å½“äºCPUçš„æ ¸å¿ƒã€‚</p></li><li><p>threadï¼šæ™®é€šçš„çº¿ç¨‹ï¼Œè¿è¡Œåœ¨SPä¸Šã€‚</p></li><li><p>blockï¼šå¤šä¸ªçº¿ç¨‹ä¼šç»„æˆä¸€ä¸ªblockï¼ŒåŒä¸€ä¸ªblockä¸­çš„çº¿ç¨‹å¯ä»¥é€šè¿‡shared memoryé€šä¿¡ã€‚åŒä¸€ä¸ªblockä¸­çš„çº¿ç¨‹åœ¨åŒä¸€ä¸ªSMä¸­æ‰§è¡Œã€‚</p></li><li><p>gridï¼šå¤šä¸ªblockæ„æˆä¸€ä¸ªgridã€‚</p></li><li><p>warpï¼šè°ƒåº¦å’Œè¿è¡Œçš„åŸºæœ¬å•å…ƒï¼ŒåŒ…å«å¤šä¸ªçº¿ç¨‹ã€‚æ¯ä¸ªçº¿ç¨‹æ‰§è¡Œç›¸åŒæŒ‡ä»¤ï¼Œä½†æ˜¯æ•°æ®ä¸åŒï¼ˆSIMTï¼‰ã€‚ä¸€ä¸ªwarpéœ€è¦å ç”¨ä¸€ä¸ªSMè¿è¡Œï¼Œå¤šä¸ªwarpséœ€è¦è½®æµè¿›å…¥SMã€‚</p></li><li><p>streamï¼šä¸€ä¸ªGPUæ“ä½œé˜Ÿåˆ—ï¼Œè¯¥é˜Ÿåˆ—ä¸­çš„æ“ä½œå°†ä»¥æ·»åŠ åˆ°æµä¸­çš„å…ˆåé¡ºåºè€Œä¾æ¬¡æ‰§è¡Œã€‚</p></li></ul><p><img src="/images/pytorch/cuda.png"></p></blockquote><h3><span id="thccachinghostallocator">THCCachingHostAllocator</span></h3><p><code>THCState</code>ä¸­è¿˜æœ‰ä¸€ä¸ªå†…å­˜åˆ†é…å™¨<code>cudaHostAllocator</code>ç”¨æ¥åˆ†é…main memoryï¼Œè¿™ä¸ªåˆ†é…å™¨æŒ‡é’ˆæŒ‡å‘<code>HostAllocator</code>ï¼Œå®ç°åœ¨<code>aten/src/THC/THCCachingHostAllocator.cpp</code>ä¸­ã€‚è¿™ä¸ªåˆ†é…å™¨çš„å®ç°å’Œä¸Šé¢çš„ç±»ä¼¼ï¼Œä¹Ÿæä¾›äº†ç¼“å­˜åŠŸèƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå®ƒå‘ç³»ç»Ÿåˆ†é…å†…å­˜æ˜¯ç”¨çš„<code>cudaHostAlloc()</code>å‡½æ•°ï¼Œè¿™æ˜¯cudaåº“å‡½æ•°ï¼Œå®ƒä¸<code>malloc()</code>ä¸åŒã€‚<code>malloc()</code>åˆ†é…çš„æ ‡å‡†çš„ã€å¯åˆ†é¡µçš„ä¸»æœºå†…å­˜ï¼Œè€Œ<code>cudaHostAlloc()</code>åˆ†é…çš„æ˜¯é¡µé”å®šçš„ä¸»æœºå†…å­˜ï¼Œä¹Ÿç§°ä½œå›ºå®šå†…å­˜ (pinned memory)ã€‚å®ƒçš„ä¸€ä¸ªé‡è¦ç‰¹ç‚¹æ˜¯æ“ä½œç³»ç»Ÿå°†ä¸ä¼šå¯¹è¿™å—å†…å­˜åˆ†é¡µå¹¶äº¤æ¢åˆ°ç£ç›˜ä¸Šï¼Œä»è€Œä¿è¯äº†å†…å­˜å§‹ç»ˆé©»ç•™åœ¨ç‰©ç†å†…å­˜ä¸­ã€‚ç”±äºGPUçŸ¥é“å†…å­˜çš„ç‰©ç†åœ°å€ï¼Œå› æ­¤å°±å¯ä»¥ä½¿ç”¨DMAæŠ€æœ¯æ¥åœ¨GPUå’ŒCPUä¹‹é—´å¤åˆ¶æ•°æ®ï¼ŒåŠ å¿«å¤åˆ¶é€Ÿåº¦ã€‚</p><p><img src="/images/pytorch/cpugpu.png"></p><h2><span id="thcapply">THCApply</span></h2><p>å’ŒTHä¸­ä¸€æ ·ï¼ŒTHCä¹Ÿæœ‰Applyç³»åˆ—å‡½æ•°ï¼Œä¸åŒçš„æ˜¯THCä¸­çš„Applyä¸å†ç”¨å®å®ç°ï¼Œè€Œæ˜¯ç”¨C++æ¨¡æ¿å‡½æ•°å®ç°ï¼Œä»£ç åœ¨<code>src/THC/THCApply.cuh</code>ã€‚</p><p>é¦–å…ˆæ¥çœ‹ç›´æ¥è¿è¡Œåœ¨GPUä¸Šçš„kernelçš„å®ç°ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Op,</span><br><span class="line">          <span class="keyword">typename</span> Ta,</span><br><span class="line">          <span class="keyword">typename</span> IndexType,</span><br><span class="line">          <span class="keyword">int</span> ADims&gt;</span><br><span class="line">__global__ <span class="keyword">void</span></span><br><span class="line">kernelPointwiseApply1(<span class="keyword">const</span> OffsetInfo&lt;Ta, IndexType, ADims&gt; a,</span><br><span class="line">                      IndexType totalElements,</span><br><span class="line">                      Op op) &#123;</span><br><span class="line">  <span class="keyword">for</span> (IndexType linearIndex = (IndexType) blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">       linearIndex &lt; totalElements;</span><br><span class="line">       linearIndex += (IndexType) gridDim.x * blockDim.x) &#123;</span><br><span class="line">    op(a.get(linearIndex));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„kernelå®ç°äº†å¯¹Tensorçš„ä¸€å…ƒæ“ä½œï¼Œä¹Ÿå°±æ˜¯å¯¹Tensorä¸­çš„æ¯ä¸€ä¸ªéƒ½æ•°æ®éƒ½æ‰§è¡Œ<code>op</code>æ“ä½œï¼ŒäºŒå…ƒå’Œä¸‰å…ƒæ“ä½œä¸ä¸€å…ƒæ“ä½œä»£ç ç±»ä¼¼ï¼Œå°±ä¸åˆ—å‡ºäº†ã€‚è¿™æ®µç†è§£èµ·æ¥ä¸éš¾ï¼Œåªæœ‰ä¸‰ç‚¹éœ€è¦ç‰¹æ®Šè¯´æ˜ä¸€ä¸‹ï¼š</p><p><strong>å‡½æ•°å¯¹è±¡</strong></p><p>æ¨¡æ¿å‚æ•°ä¸­çš„<code>Op</code>æ˜¯<a href="https://www.wikiwand.com/zh-hans/%E5%87%BD%E6%95%B0%E5%AF%B9%E8%B1%A1" target="_blank" rel="noopener">å‡½æ•°å¯¹è±¡</a>ç±»å‹ï¼Œå®ƒå®ç°äº†<code>operator()</code>æ–¹æ³•ï¼Œè¿™æ ·çš„è¯å®ƒçš„å®ä¾‹å¯¹è±¡å°±å¯ä»¥ç›´æ¥å½“å‡½æ•°æ¥ç”¨ï¼Œå¦‚ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">IntComparator</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> &amp;a, <span class="keyword">const</span> <span class="keyword">int</span> &amp;b)</span> <span class="keyword">const</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a &lt; b;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>è¿™å°±æ˜¯ä¸€ä¸ªå¾ˆå¸¸ç”¨çš„ç”¨æ¥æ¯”è¾ƒæ•´æ•°å¤§å°çš„å‡½æ•°å¯¹è±¡ç±»å‹ï¼Œå®ƒå¯ä»¥è¿™æ ·ç”¨ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">IntComparator op;</span><br><span class="line">op(<span class="number">1</span>, <span class="number">2</span>);<span class="comment">// true</span></span><br></pre></td></tr></table></figure><p>å‡½æ•°å¯¹è±¡ç±»ä¼¼äºå‡½æ•°æŒ‡é’ˆï¼Œä½†æœ‰ä¸¤ä¸ªä¼˜ç‚¹ï¼šç¬¬ä¸€æ˜¯ç¼–è¯‘å™¨å¯ä»¥å†…è”æ‰§è¡Œå‡½æ•°å¯¹è±¡çš„è°ƒç”¨ï¼›ç¬¬äºŒæ˜¯å‡½æ•°å¯¹è±¡å†…éƒ¨å¯ä»¥ä¿æŒçŠ¶æ€ã€‚</p><p><strong>å¾ªç¯ä¸‹æ ‡</strong></p><p>å¾ªç¯çš„ä¸‹æ ‡æ¯æ¬¡å¢åŠ <code>gridDim.x * blockDim.x</code>ï¼Œè€Œä¸æ˜¯é€šå¸¸çš„<code>1</code>ï¼Œè¿™å°±æ¶‰åŠåˆ°kernelæ˜¯å¦‚ä½•æ‰§è¡Œçš„äº†ã€‚é¦–å…ˆkernelè¢«åˆ†é…åˆ°å¤šä¸ªGridä¸Šæ‰§è¡Œï¼Œæ¯ä¸ªGridé‡Œæœ‰å¤šä¸ªBlockï¼Œæ¯ä¸ªBlocké‡Œæœ‰å¤šä¸ªThreadï¼Œè¿™äº›çº¿ç¨‹(Thread)éƒ½æ‰§è¡Œç›¸åŒçš„ä»£ç ï¼Œä¹Ÿå°±æ˜¯kernelã€‚ä¸ºäº†è®©è¿™äº›çº¿ç¨‹åˆ†å·¥åˆä½œï¼Œæ¯ä¸ªçº¿ç¨‹éƒ½è®°å½•äº†<code>gridDim</code> <code>blockDim</code>,<code>blockIdx</code>, å’Œ<code>threadIdx</code>ï¼Œåˆ†åˆ«ä»£è¡¨Gridç»´åº¦ï¼ŒBlockç»´åº¦ï¼ŒBlock IDï¼Œå’ŒThread IDã€‚åœ¨è¿™é‡Œï¼ŒGridå’ŒBlockéƒ½æ˜¯ä¸€ç»´çš„ï¼Œæ‰€ä»¥å½“å‰çº¿ç¨‹çš„å…¨å±€IDå¯ä»¥é€šè¿‡</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x * blockDim.x + threadIdx.x</span><br></pre></td></tr></table></figure><p>å¾—åˆ°ï¼Œå…¶ä¸­<code>blockIdx.x</code>è¡¨ç¤ºç¬¬å‡ ä¸ªBlockï¼Œ<code>blockDim.x</code>æ˜¯ä¸€ä¸ªBlockå†…æœ‰å¤šå°‘çº¿ç¨‹ï¼Œ<code>threadIdx.x</code>æ˜¯è¯¥çº¿ç¨‹åœ¨Blockå†…çš„IDã€‚</p><p>å†çœ‹ä¸‹æ ‡é€’å¢çš„é—´éš”<code>gridDim.x * blockDim.x</code>å®é™…ä¸Šæ˜¯æ‰§è¡Œè¿™ä¸ªkernelçš„çº¿ç¨‹ä¸ªæ•°ï¼Œå³ä¸€ä¸ªGridå†…çš„Blockæ•° <span class="math inline">\(\times\)</span> ä¸€ä¸ªBlockå†…çº¿ç¨‹æ•°ã€‚è¿™æ ·çš„å¥½å¤„æ˜¯ï¼Œå¦‚æœä¸åŒçº¿ç¨‹è¦è¯»å–çš„å†…å­˜æ˜¯è¿ç»­çš„ï¼Œåˆ™è¿™äº›å†…å­˜è¯»å–å¯ä»¥æ†ç»‘åˆ°ä¸€èµ·è¿›è¡Œï¼ŒåŠ å¿«äº†å†…å­˜è¯»å–é€Ÿåº¦ï¼Œå¦‚ä¸‹å›¾ã€‚</p><p><img src="/images/pytorch/coalesced.png"></p><p><strong>OffsetInfo</strong></p><p>æ³¨æ„åˆ°å¾ªç¯ä½“é‡Œåªæœ‰ä¸€å¥ä»£ç ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">op(a.get(linearIndex));</span><br></pre></td></tr></table></figure><p>æ„æ€å¯¹ç¬¬<code>linearIndex</code>ä¸ªæ•°æ®è¿›è¡Œ<code>op</code>æ“ä½œã€‚ç”±äº<code>linearIndex</code>æ˜¯çº¿æ€§åœ°å€ï¼Œå¹¶ä¸æ˜¯æ•°æ®çœŸæ­£çš„å†…å­˜åç§»ï¼Œæ‰€ä»¥ <code>a.get()</code>çš„ä½œç”¨æ˜¯æŠŠçº¿æ€§åœ°å€è½¬æ¢ä¸ºå®é™…æ•°æ®çš„å­˜å‚¨åœ°å€ï¼Œè€Œ<code>a</code>çš„ç±»å‹æ˜¯<code>OffsetInfo&lt;Ta, IndexType, Dims&gt;</code>ã€‚</p><p>è½¬æ¢çš„ç®—æ³•å…¶å®å¾ˆç®€å•ï¼Œçº¿æ€§åœ°å€å°±æ˜¯ç¬¬å‡ ä¸ªæ•°æ®ï¼Œæ¯”å¦‚<code>x[0][0]</code>æ˜¯ç¬¬0ä¸ªæ•°æ®ï¼Œçº¿æ€§åœ°å€å°±æ˜¯0ï¼Œ<code>x[0][1]</code>çš„çº¿æ€§åœ°å€å°±æ˜¯1ï¼Œ<code>x[i][j]</code>çš„çº¿æ€§åœ°å€å°±æ˜¯<code>i * size[0] + j</code>ã€‚è€Œä¸”æˆ‘ä»¬çŸ¥é“<code>x[i][j]</code>çš„å†…å­˜åç§»ä¸º<code>i * strides[0] + j * strides[1]</code>ï¼Œé‚£ä¹ˆè½¬æ¢ç®—æ³•è¦åšçš„å°±æ˜¯æŠŠçº¿æ€§åœ°å€è½¬æ¢ä¸º<code>ijk</code>ä¸‹æ ‡ï¼Œç„¶åå†æŠŠä¸‹æ ‡è½¬åŒ–ä¸ºå†…å­˜åœ°å€ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> IndexType&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">IndexToOffset</span>&lt;T, IndexType, -1&gt; &#123;</span></span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">inline</span> __host__ __<span class="function">device__ IndexType <span class="title">get</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    IndexType linearId,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> TensorInfo&lt;T, IndexType&gt;&amp; info)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    IndexType offset = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ä»æœ€å¤–å›´ä¸‹æ ‡å¼€å§‹è®¡ç®—</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = info.dims - <span class="number">1</span>; i &gt; <span class="number">0</span>; --i) &#123;</span><br><span class="line">    <span class="comment">// æ±‚å‡ºç¬¬iç»´ä¸‹æ ‡</span></span><br><span class="line">      IndexType curDimIndex = linearId % info.sizes[i];</span><br><span class="line">      <span class="comment">// è½¬æ¢ä¸ºå†…å­˜åç§»</span></span><br><span class="line">      IndexType curDimOffset = curDimIndex * info.strides[i];</span><br><span class="line">      <span class="comment">// å’Œæ€»åç§»ç›¸åŠ </span></span><br><span class="line">      offset += curDimOffset;</span><br><span class="line">      <span class="comment">// è®¡ç®—ç¬¬i-1ç»´çš„çº¿æ€§åœ°å€</span></span><br><span class="line">      linearId /= info.sizes[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> offset + linearId * info.strides[<span class="number">0</span>];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>ç»†å¿ƒçš„è¯»è€…å¯èƒ½æ³¨æ„åˆ°äº†ï¼Œä¸Šé¢çš„å‡½æ•°æ˜¯<code>IndexToOffset</code>çš„æ–¹æ³•ï¼Œå¹¶ä¸æ˜¯<code>OffsetInfo</code>çš„ï¼Œå®é™…ä¸Šåè€…å¯¹éè´Ÿæ•´æ•°é™¤æ³•å’Œå–ä½™è¿›è¡Œäº†ä¼˜åŒ–ï¼ŒæŠŠé™¤æ³•è½¬æ¢ä¸ºä¸€ç³»åˆ—ä¹˜æ³•ï¼Œä»è€ŒåŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚</p><p>å¤§è‡´æ€æƒ³æ˜¯è¿™æ ·çš„ï¼Œå‡è®¾æˆ‘ä»¬è¦è®¡ç®— <span class="math inline">\(\lfloor\frac{n}{d}\rfloor\)</span>ï¼Œå¯¹ä»»æ„Nä½éè´Ÿæ•´æ•°<span class="math inline">\(d\)</span>ï¼Œæ€»å¯ä»¥æ‰¾åˆ°ä¸€ä¸ª magic number <span class="math inline">\(m\)</span> å’Œ <span class="math inline">\(s\)</span>ï¼Œä½¿å¾—ï¼š <span class="math display">\[\lfloor\frac{n}{d}\rfloor=\lfloor\frac{m\times n}{2^{N+s}}\rfloor\]</span> è¿™æ ·å°±æŠŠé™¤æ³•æ“ä½œè½¬åŒ–ä¸ºä¹˜æ³•å’Œå³ç§»äº†ã€‚</p><p>é‚£ä¹ˆæ€ä¹ˆæ‰¾ <span class="math inline">\(m\)</span> å’Œ <span class="math inline">\(s\)</span> å‘¢ï¼Œéå¸¸ç®€å•ï¼š <span class="math display">\[s=\lceil\log_2 d\rceil \\m = \lfloor 2^N\times\frac{(2^s-d)}{d}\rfloor+2^N+1\]</span> å¯¹äºå›ºå®šçš„é™¤æ•° <span class="math inline">\(d\)</span>ï¼Œè¿™ä¸¤ä¸ªå‚æ•°æ˜¯ä¸ä¼šå˜çš„ï¼Œå¦‚æœéœ€è¦å¤šæ¬¡é™¤ä»¥ <span class="math inline">\(d\)</span>ï¼Œåˆ™å¯ä»¥æå‰è®¡ç®—å¥½ <span class="math inline">\(m\)</span> å’Œ <span class="math inline">\(s\)</span>ï¼Œåœ¨è®¡ç®—æ—¶åŠ å¿«é€Ÿåº¦ã€‚æ³¨æ„åˆ°è®¡ç®— <span class="math inline">\(m\)</span> æ—¶ä¹Ÿæ˜¯éœ€è¦é™¤æ³•è¿ç®—çš„ï¼Œæ‰€ä»¥å¦‚æœè¿™ä¸ªé™¤æ•°åªç”¨ä¸€æ¬¡çš„è¯ï¼Œé‚£ä¹ˆç”¨å¿«é€Ÿé™¤æ³•æ˜¯æ²¡æ„ä¹‰çš„ï¼ˆé™¤é<span class="math inline">\(m\)</span>æ˜¯åœ¨ç¼–è¯‘æœŸè®¡ç®—çš„ï¼‰ã€‚å…³äºè¿™ä¸ªå¼å­çš„è¯æ˜å’Œæ¨å¯¼çœ‹<a href="http://ridiculousfish.com/blog/posts/labor-of-division-episode-i.html" target="_blank" rel="noopener">è¿™é‡Œ</a>ã€‚</p><p>ä»£ç ä¸­ï¼Œ<code>OffsetInfo</code>çš„å®ç°å®é™…ä¸Šæ˜¯è·Ÿæ¨¡æ¿å‚æ•°<code>Dims</code>ç›¸å…³çš„ï¼Œå¦‚æœç»´åº¦èƒ½åœ¨ç¼–è¯‘æœŸç»™å‡ºçš„è¯ï¼ˆå€¼é-1ï¼‰ï¼Œåˆ™åœ¨ç”Ÿæˆ<code>OffsetInfo</code>å¯¹è±¡æ—¶è®¡ç®— <span class="math inline">\(m\)</span> å’Œ <span class="math inline">\(s\)</span>ï¼Œä»¥å¤‡ä¹‹åä½¿ç”¨ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> IndexType, <span class="keyword">int</span> Dims&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OffsetInfo</span> &#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OffsetInfo</span><span class="params">(<span class="keyword">const</span> TensorInfo&lt;T, IndexType&gt;&amp; tinfo)</span> </span>&#123;</span><br><span class="line">    assert(tinfo.dims == Dims);</span><br><span class="line">    data = tinfo.data;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; Dims; ++i) &#123;</span><br><span class="line">      <span class="comment">// æå‰è®¡ç®— m, s (å®ç°åœ¨ IntDivider ç±»ä¸­)</span></span><br><span class="line">      sizes[i] = IntDivider&lt;IndexType&gt;(tinfo.sizes[i]);</span><br><span class="line">      strides[i] = tinfo.strides[i];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  __host__ __<span class="function">device__ T* <span class="title">get</span><span class="params">(IndexType linearIndex)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    IndexType offset = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = Dims - <span class="number">1</span>; i &gt; <span class="number">0</span>; --i) &#123;</span><br><span class="line">      <span class="comment">// ä½¿ç”¨å¿«é€Ÿé™¤æ³•</span></span><br><span class="line">      DivMod&lt;IndexType&gt; divmod = sizes[i].divmod(linearIndex);</span><br><span class="line">      linearIndex = divmod.div;</span><br><span class="line">      offset += divmod.mod * strides[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &amp;data[offset + linearIndex * strides[<span class="number">0</span>]];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  T* data;</span><br><span class="line">  <span class="comment">// Dims æ˜¯ç¼–è¯‘æœŸå¸¸é‡ï¼Œæ‰€ä»¥ sizes å’Œ strides æ˜¯é™æ€åˆ†é…çš„</span></span><br><span class="line">  IntDivider&lt;IndexType&gt; sizes[Dims];</span><br><span class="line">  IndexType strides[Dims];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>å¦‚æœåˆ›å»º<code>OffsetInfo</code>æ—¶ï¼Œ<code>Dims</code>çš„å€¼ä¸º-1çš„è¯ï¼Œä»£è¡¨Tensorçš„å¤§å°ä¸æ˜¯å›ºå®šçš„ï¼Œè¿™æ ·çš„è¯<code>OffsetInfo::sizes</code>å’Œ<code>OffsetInfo::strides</code>æ˜¯åŠ¨æ€åˆ†é…çš„ï¼Œå°±ä¼šè§¦å‘NVCCçš„ä¸€ä¸ªbugï¼š<em>if a kernel argument contains an array that is dynamically accessed, the whole array is first copied into the local memory. Pre-computation makes it worse because now we have more data to copy.</em></p><p>æ‰€ä»¥å¯¹äºå¤§å°ä¸å›ºå®šï¼ˆç¼–è¯‘æœŸä¸èƒ½ç»™å‡ºå…·ä½“ç»´åº¦ï¼‰çš„Tensoré‡‡ç”¨ä¹‹å‰çš„åŠæ³•è®¡ç®—ï¼Œè¿™é‡Œä½¿ç”¨äº†ç‰¹åŒ–æ¨¡æ¿åŒ¹é…<code>Dims</code>ä¸º-1çš„æƒ…å†µï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> IndexType&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OffsetInfo</span>&lt;T, IndexType, -1&gt; &#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">OffsetInfo</span><span class="params">(<span class="keyword">const</span> TensorInfo&lt;T, IndexType&gt;&amp; tinfo)</span></span></span><br><span class="line">    : tinfo(tinfo) &#123; &#125;</span><br><span class="line"></span><br><span class="line">  __host__ __<span class="function">device__ T* <span class="title">get</span><span class="params">(IndexType linearIndex)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="comment">// ç›´æ¥è°ƒç”¨ä¹‹å‰åˆ—å‡ºçš„ IndexToOffset::get æ–¹æ³•</span></span><br><span class="line">    IndexType offset = IndexToOffset&lt;T, IndexType, <span class="number">-1</span>&gt;::get(linearIndex, tinfo);</span><br><span class="line">    <span class="keyword">return</span> &amp;tinfo.data[offset];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  TensorInfo&lt;T, IndexType&gt; tinfo;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2><span id="æ€»ç»“">æ€»ç»“</span></h2><p>æ€»ç»“ä¸€ä¸‹ï¼ŒTHCä¸­çš„APIçš„å£°æ˜å’Œå®ç°éƒ½åœ¨<code>generic</code>ç›®å½•ä¸‹ï¼ŒAPIçš„å½¢å¼æ˜¯Cé£æ ¼èŒƒå¼ï¼š<code>THCTensor_(xxx)(...)</code>ã€‚è¿™äº›å‡½æ•°å‡ ä¹éƒ½ä¼šè°ƒç”¨ apply ç³»åˆ—å‡½æ•°æ¥åœ¨GPUä¸­å®ç°å…·ä½“åŠŸèƒ½ï¼Œè€Œ apply å‡½æ•°çš„æ ¸å¿ƒåœ¨äºä¼ å…¥çš„OPï¼Œè¿™äº›OPéƒ½å®šä¹‰åœ¨<code>THC/</code>æ ¹ç›®å½•ä¸‹ã€‚</p><p>ä¸¾ä¸ªä¾‹å­ï¼Œæ¥çœ‹ä¸€ä¸‹<code>THCTensor_fill(state, self, value)</code>æ˜¯æ€ä¹ˆæ‰§è¡Œçš„ï¼Œå®ƒçš„åŠŸèƒ½æ˜¯æŠŠ<code>self</code>æŒ‡å‘çš„Tensorçš„æ¯ä¸ªå…ƒç´ èµ‹å€¼ä¸º<code>value</code>ã€‚è¿™ä¸ªAPIçš„å®šä¹‰åœ¨<code>THC/generic/THCTensorMath.cu</code>ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THCTensor_</span><span class="params">(fill)</span><span class="params">(THCState* state, THCTensor *self_, <span class="keyword">scalar_t</span> value)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THCAssertSameGPU(THCTensor_(checkGPU)(state, <span class="number">1</span>, self_));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!THC_pointwiseApply1&lt;<span class="keyword">scalar_t</span>&gt;(</span><br><span class="line">        state, self_, TensorFillOp&lt;<span class="keyword">scalar_t</span>&gt;(value))) &#123;</span><br><span class="line">    THArgCheck(<span class="literal">false</span>, <span class="number">1</span>, CUTORCH_DIM_WARNING);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  THCudaCheck(cudaGetLastError());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>æ ¸å¿ƒä»£ç ä¸ºï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">THC_pointwiseApply1&lt;<span class="keyword">scalar_t</span>&gt;(state, self_, TensorFillOp&lt;<span class="keyword">scalar_t</span>&gt;(value))</span><br></pre></td></tr></table></figure><p>è¿™å¥è¯è°ƒç”¨ä¸€å…ƒ apply å‡½æ•°ï¼Œä¼ å…¥çš„å‚æ•°ä¸º THCState, è¦æ“ä½œçš„Tensorå’Œç›¸åº”OPã€‚<code>THC_pointwiseApply1()</code>ä¼šè¿›è¡Œä¸€äº›ç‰¹æ®Šæƒ…å†µçš„å¤„ç†å’Œä¼˜åŒ–ï¼Œæœ€åè°ƒç”¨ä¹‹å‰åˆ—å‡ºçš„apply kernelæ‰§è¡Œç›¸åº”OPã€‚</p><p><code>TensorFillOp</code>å®šä¹‰åœ¨<code>THC/THCTensorMath.cu</code>ä¸­ï¼Œ</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TensorFillOp</span> &#123;</span></span><br><span class="line">  TensorFillOp(T v) : val(v) &#123;&#125;</span><br><span class="line">  __device__ __<span class="function">forceinline__ <span class="keyword">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(T* v)</span> </span>&#123; *v = val; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> T val;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>æ³¨æ„åˆ°å¡«å…¥Tensorçš„å€¼è¢«ä¿å­˜ä¸ºç±»çš„å¸¸é‡ï¼Œè€Œä¸æ˜¯ä½œä¸º<code>operator()</code>çš„å‚æ•°ï¼Œè¿™æ ·æ‰èƒ½ç»Ÿä¸€æ¥å£ï¼Œæ‰èƒ½è¢«<code>kernelPointwiseApply1()</code>ç›´æ¥è°ƒç”¨ã€‚</p><p>è°ƒç”¨è¿‡ç¨‹çš„ç¤ºæ„å›¾å¦‚ä¸‹ï¼š</p><p><img src="/images/pytorch/THCTensor_fill.png"></p><p>ã¤ã¥ã</p><table><thead><tr class="header"><th style="text-align: left;">ä¸Šä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/">THTensor</a></th><th style="text-align: right;">ä¸‹ä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch3/">NN</a></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"></td><td style="text-align: right;"></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> Tensor </tag>
            
            <tag> CUDA </tag>
            
            <tag> THC </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PyTorchæºç æµ…æ(1)ï¼šTHTensor</title>
      <link href="/2019/05/05/PyTorch1/"/>
      <url>/2019/05/05/PyTorch1/</url>
      
        <content type="html"><![CDATA[<p>PyTorchä¸­Tensorçš„å­˜å‚¨å’Œè¡¨ç¤ºåˆ†å¼€ï¼Œå¤šä¸ªTHTensorå¯èƒ½å…±äº«ä¸€ä¸ªTHStorageï¼Œæ¯ä¸ªTHTensorå¯èƒ½æ‹¥æœ‰ä¸åŒçš„viewï¼ˆe.g. size, strideï¼‰ã€‚è¿™æ ·è®¾è®¡çš„å¥½å¤„æ˜¯ï¼Œæœ‰æ—¶çœ‹èµ·æ¥ä¸ä¸€æ ·çš„æ•°æ®åº•å±‚æ˜¯å…±äº«çš„ï¼Œæ¯”å¦‚çŸ©é˜µä¸çŸ©é˜µçš„è½¬ç½®ã€äºŒç»´çŸ©é˜µä¸äºŒç»´çŸ©é˜µå˜æˆä¸€ç»´æ—¶çš„çŸ©é˜µã€‚è¿™éƒ¨åˆ†çš„ä¸»åŠ›å®ç°åœ¨<code>pytorch/aten</code>æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™é‡Œé¢æ—¢å®ç°äº†åº•å±‚çš„Tensoræ“ä½œåº“ï¼Œä¹Ÿå°è£…äº†åä¸º <strong>ATen</strong> çš„ C++11æ¥å£ã€‚</p><a id="more"></a><p><code>aten/src</code>é‡Œæœ‰å‡ ä¸ªé‡è¦çš„æ–‡ä»¶å¤¹ï¼Œå®ƒä»¬å®ç°çš„å†…å®¹å¦‚ä¸‹ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">src</span><br><span class="line">â”œâ”€â”€ ATen        # Tensoræ“ä½œçš„C++11æ¥å£</span><br><span class="line">â”œâ”€â”€ TH          # CPU Tensor çš„åº•å±‚å®ç°ï¼ˆæœ¬ç¯‡å†…å®¹ï¼‰</span><br><span class="line">â”œâ”€â”€ THC         # GPU Tensor (CUDA) çš„åº•å±‚å®ç°ï¼ˆåœ¨ä¸‹ä¸€ç¯‡è®²ï¼‰</span><br><span class="line">â”œâ”€â”€ THCUNN      # CUDAç‰ˆåº•å±‚ç¥ç»ç½‘ç»œå®ç°(ä¸‹ä¸‹ç¯‡è®²)</span><br><span class="line">â””â”€â”€ THNN        # CPUç‰ˆåº•å±‚ç¥ç»ç½‘ç»œå®ç°(ä¸‹ä¸‹ç¯‡è®²)</span><br></pre></td></tr></table></figure><p>è¿™ç¯‡è®²çš„ä¸»è¦ä»£ç ä¹Ÿéƒ½åœ¨THæ–‡ä»¶å¤¹å†…ã€‚</p><p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#thtensor-thstorage">THTensor &amp; THStorage</a><ul><li><a href="#tensorimpl">TensorImpl</a></li><li><a href="#storageimpl">StorageImpl</a></li></ul></li><li><a href="#æ™ºèƒ½æŒ‡é’ˆ-intrusive_ptr">æ™ºèƒ½æŒ‡é’ˆ Intrusive_ptr</a></li><li><a href="#tensor-apply-dynamic-dispatch">Tensor Apply &amp; Dynamic Dispatch</a></li></ul><!-- tocstop --><h2><span id="thtensor-amp-thstorage">THTensor &amp; THStorage</span></h2><p>THé‡Œé¢çš„æ ¸å¿ƒç±»å‹å°±æ˜¯<code>THTensor</code>å’Œ<code>THStorage</code>äº†ï¼Œå‰è€…æ˜¯Tensorçš„viewï¼Œåè€…æ˜¯Tensoræ•°æ®çš„å­˜å‚¨åœ°å€ã€‚ç”±äºTensorçš„æ•°æ®ç±»å‹å¯ä»¥æ˜¯å¤šç§å¤šæ ·çš„ï¼Œè€Œæ¯ç§ç±»å‹çš„APIéƒ½ä¸€è‡´ï¼Œæ‰€ä»¥éœ€è¦ç”¨åˆ°èŒƒå‹æ¥å‡å°‘é‡å¤ä»£ç ï¼ŒTHä¸­æ˜¯ä½¿ç”¨å®å®ç°èŒƒå‹åŠŸèƒ½ï¼ˆå› ä¸ºTorchä¸€å¼€å§‹æ˜¯ç”¨Cå®ç°çš„ï¼‰ï¼Œä¸äº†è§£çš„è¯»è€…å¯ä»¥å…ˆå‚è€ƒä¸€ä¸‹<a href="https://zhuanlan.zhihu.com/p/34496542" target="_blank" rel="noopener">è¿™ç¯‡çŸ¥ä¹ä¸“æ </a>ã€‚</p><p><code>THTensor</code>çš„å®šä¹‰åœ¨<code>aten/src/TH/generic/THTensor.h</code>ä¸­ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THTensor at::TensorImpl</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THFloatTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THDoubleTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THHalfTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THByteTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THCharTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THShortTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THIntTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THLongTensor THTensor</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THBoolTensor THTensor</span></span><br></pre></td></tr></table></figure><p>åŒæ ·çš„ï¼Œ<code>THStorage</code>çš„å®šä¹‰åœ¨<code>Aten/src/TH/generic/THStorage.h</code>ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THStorage at::StorageImpl</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THFloatStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THDoubleStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THHalfStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THByteStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THCharStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THShortStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THIntStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THLongStorage THStorage</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THBoolStorage THStorage</span></span><br></pre></td></tr></table></figure><p>åœ¨<code>THTensor.h</code>ä¸­æœ‰å¾ˆå¤šç±»ä¼¼è¿™æ ·çš„APIå£°æ˜ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">TH_API THStorage* <span class="title">THTensor_</span><span class="params">(storage)</span><span class="params">(<span class="keyword">const</span> THTensor *self)</span></span>;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼Œ<code>THTensor_</code>çš„å®å®šä¹‰ä¸º</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THTensor_(NAME)   TH_CONCAT_4(TH,Real,Tensor_,NAME)</span></span><br></pre></td></tr></table></figure><p>ä¸Šé¢çš„<code>TH_CONCAT_4</code>å®å°±æ˜¯æŠŠå®ƒçš„å››ä¸ªå‚æ•°è¿æ¥èµ·æ¥ï¼Œå…¶ä¸­<code>Real</code>ä¼šè¢«å®šä¹‰ä¸ºå®é™…ç±»å‹ï¼ˆFloat, Boolç­‰ï¼‰ï¼Œæ‰€ä»¥ä¸Šé¢çš„APIä¼šè¢«å±•å¼€æˆï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">at::<span class="function">StorageImpl <span class="title">THFloatTensor_storage</span><span class="params">(<span class="keyword">const</span> at::TensorImpl *self)</span></span>;</span><br><span class="line">at::<span class="function">StorageImpl <span class="title">THBoolTensor_storage</span><span class="params">(<span class="keyword">const</span> at::TensorImpl *self)</span></span>;</span><br><span class="line">at::<span class="function">StorageImpl <span class="title">THLongTensor_storage</span><span class="params">(<span class="keyword">const</span> at::TensorImpl *self)</span></span>;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>åœ¨è¿™äº›APIä¸­è¿˜ä¼šç”¨åˆ°<code>scalar_t</code>ç±»å‹ï¼Œè¿™ä¸ªä¹Ÿæ˜¯ä¸€ä¸ªå®ï¼Œç‰¹åŒ–çš„æ—¶å€™ä¼šä¼ å…¥å…·ä½“çš„ç±»å‹ï¼ˆå¦‚ç”¨æ¥ç¡®ä¿<code>THFloatTensor</code>é‡Œçš„<code>StorageImpl</code>å­˜å‚¨çš„floatç±»å‹ï¼‰ã€‚</p><p>ä¸éš¾å‘ç°ï¼Œæ‰€æœ‰çš„THTensorç±»å‹æœ€ç»ˆéƒ½ä¼šæ›¿æ¢æˆ<code>at::TensorImpl</code>ï¼Œæ‰€æœ‰çš„THStorageç±»å‹ä¹Ÿéƒ½ä¼šæ›¿æ¢æˆ<code>at::StorageImpl</code>ï¼Œå‰è€…çš„å®ç°åœ¨<code>c10/core/TensorImpl.h</code>ä¸­ï¼Œåè€…çš„å®ç°åœ¨<code>c10/core/StorageImpl.h</code>ä¸­ã€‚è¿™ä¸¤ä¸ªç±»å‹çš„å®ç°åœ¨c10ä¸­ï¼Œä¹Ÿå°±æ˜¯è¯´Tensorç±»å‹çš„å®ç°è½¬ç§»åˆ°äº†c10ä¸­ï¼Œä½†APIçš„å®ç°ä¾ç„¶åœ¨THä¸­ã€‚</p><h3><span id="tensorimpl">TensorImpl</span></h3><p>æ¥ç€å…·ä½“æ¥çœ‹ä¸€ä¸‹<code>TensorImpl</code>çš„å®ç°ï¼Œé¦–å…ˆæ¥çœ‹ä¸€ä¸‹å®ƒçš„å£°æ˜å’Œå±æ€§ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">C10_API</span> <span class="title">TensorImpl</span> :</span> <span class="keyword">public</span> c10::intrusive_ptr_target &#123;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">  <span class="comment">// æŒ‡å‘å®é™…æ•°æ®å­˜å‚¨ä½ç½®ï¼Œä¹Ÿå°±æ˜¯æŒ‡å‘StorageImpl</span></span><br><span class="line">  Storage storage_;</span><br><span class="line">    </span><br><span class="line">  <span class="comment">// ç”¨äºè‡ªåŠ¨å¾®åˆ†ï¼Œåªå¯¹Variableé€‚ç”¨</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;c10::AutogradMetaInterface&gt; autograd_meta_ = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  SmallVector&lt;<span class="keyword">int64_t</span>,<span class="number">5</span>&gt; sizes_;      <span class="comment">// Tensorçš„å®é™…å¤§å°</span></span><br><span class="line">  SmallVector&lt;<span class="keyword">int64_t</span>,<span class="number">5</span>&gt; strides_;    <span class="comment">// å„ä¸ªç»´åº¦ç›´æ¥çš„é—´éš”</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">int64_t</span> storage_offset_ = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int64_t</span> numel_ = <span class="number">1</span>; <span class="comment">// Tensorä¸­å…ƒç´ ä¸ªæ•°ï¼Œä¹Ÿå°±æ˜¯sizes_æ•°ç»„ä¸­å…ƒç´ çš„ä¹˜ç§¯</span></span><br><span class="line"></span><br><span class="line">  caffe2::TypeMeta data_type_;        <span class="comment">// æ•°æ®ç±»å‹</span></span><br><span class="line"></span><br><span class="line">  TensorTypeId type_id_;</span><br><span class="line">  <span class="keyword">bool</span> is_contiguous_ = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">bool</span> is_variable_ = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">bool</span> is_wrapped_number_ = <span class="literal">false</span>;</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">bool</span> allow_tensor_metadata_change_ = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">bool</span> reserved_ = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>TensorImpl</code>ç»§æ‰¿è‡ª<code>intrusive_ptr_target</code>ï¼Œåè€…æ˜¯ä¸ºäº†é€šè¿‡ä½¿ç”¨<code>intrusive_ptr&lt;T&gt;</code>å®ç°å¼•ç”¨è®¡æ•°è€Œè®¾è®¡çš„åŸºç±»ï¼Œéœ€è¦å®ç°å¼•ç”¨è®¡æ•°çš„ç±»åªéœ€ç»§æ‰¿å®ƒå³å¯ã€‚<code>TensorImpl</code>ä¸­çš„æ¯ä¸ªæˆå‘˜æ˜¯å¹²ä»€ä¹ˆçš„åŸºæœ¬éƒ½æœ‰æ³¨é‡Šï¼Œå…¶ä¸­<code>strides_</code>æ˜¯ç”¨æ¥å®ç°å†…å­˜å¯»å€çš„ï¼Œå³æŸä¸ªijkè„šæ ‡å¯¹åº”çš„å†…å­˜åœ°å€ä¸ºï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storage_offset_ + i * strides_[<span class="number">0</span>] + j * strides_[<span class="number">1</span>] + k * strides_[<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>æ­£å¸¸æƒ…å†µä¸‹ç”¨<code>sizes_</code>ä»£æ›¿<code>strides_</code>å¯ä»¥å®ç°åŒæ ·çš„åŠŸèƒ½ï¼Œä½†æ˜¯æœ‰çš„Tensoræ˜¯ç”±è¾ƒå¤§çš„Tensoråˆ†å‰²è€Œæ¥ï¼Œç»´åº¦ä¹‹é—´çš„é—´éš”ä¸æ˜¯<code>sizes_</code>ï¼Œæ‰€ä»¥éœ€è¦ç”¨å¦ä¸€ä¸ªæ•°ç»„<code>strides_</code>å­˜å‚¨ç»´åº¦é—´éš”ã€‚</p><p><code>TensorImpl</code>ä¸­çš„æ–¹æ³•è¾ƒå¤šï¼Œå°±ä¸ä¸€ä¸€åˆ—å‡ºäº†ï¼Œå®ç°äº†å¯¹Tensorï¼ˆå’ŒVariableï¼‰çš„åŸºæœ¬æ“ä½œï¼ŒAtenä¸­çš„APIä¹Ÿæ˜¯åŸºäºè¿™äº›åŸºæœ¬æ“ä½œå®ç°çš„ã€‚</p><p><strong><code>Variable</code>ä¸<code>Tensor</code>çš„åˆå¹¶</strong></p><p>åœ¨æ—©æœŸçš„PyTorchç‰ˆæœ¬ä¸­ï¼ŒVariableä¸Tensoræ˜¯ä¸åŒçš„ç±»ï¼ŒVariableç”¨æ¥ä¿å­˜éœ€è¦è®¡ç®—æ¢¯åº¦çš„Tensorï¼Œä½†Variableçš„å®ç°å¹¶ä¸ç¾å¥½ï¼šä¸€æ–¹é¢<code>Variable::Impl</code>æ˜¯Tensorçš„å­ç±»ï¼Œè€Œå®ƒçš„æˆå‘˜é‡Œåˆæ‹¥æœ‰ä¸€ä¸ªTensorï¼ˆå­˜å‚¨æ•°æ®ï¼‰ï¼Œè¿™è¿åäº†<a href="https://www.wikiwand.com/zh-hans/%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%88%99" target="_blank" rel="noopener">é‡Œæ°æ›¿æ¢åŸåˆ™</a>ï¼Œè€Œä¸”è®©Tensorçš„å®ç°å˜å¾—å¾ˆå¤æ‚ã€‚è€Œåœ¨ç°ç‰ˆæœ¬ä¸­ï¼Œå·²ç»æŠŠVariableå˜æˆTensoräº†ï¼ŒæŠŠä¸€äº›<code>Variable</code>ç‰¹æœ‰çš„æ–¹æ³•ï¼ˆe.g.<code>requires_grad</code>ï¼‰ç§»åˆ°äº†<code>TensorImpl</code>é‡Œã€‚</p><h3><span id="storageimpl">StorageImpl</span></h3><p><code>StorageImpl</code>çš„å£°æ˜å’Œå±æ€§å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">C10_API</span> <span class="title">StorageImpl</span> <span class="title">final</span> :</span> <span class="keyword">public</span> c10::intrusive_ptr_target &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  caffe2::TypeMeta data_type_;  <span class="comment">// æ•°æ®ç±»å‹</span></span><br><span class="line">  DataPtr data_ptr_;            <span class="comment">// æŒ‡å‘å­˜å‚¨æ•°æ®çš„å†…å­˜å—</span></span><br><span class="line">  <span class="keyword">int64_t</span> numel_;               <span class="comment">// æ•°æ®æ€»æ•°</span></span><br><span class="line">  <span class="keyword">bool</span> resizable_;</span><br><span class="line">  Allocator* allocator_;        <span class="comment">// å†…å­˜åˆ†é…å™¨</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>å…¶ä¸­ï¼Œ<code>caffe2::TypeMeta data_type_</code>å­˜å‚¨äº†æ•°æ®ç±»å‹ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼šç±»å‹idã€å¤§å°ã€ç±»å‹åå­—ç­‰ï¼›<code>DataPtr</code>å…¶å®å°±æ˜¯ <em>unique_ptr</em>ï¼Œä½†æŒ‡é’ˆç±»å‹å›ºå®š <code>void*</code>ã€‚</p><p><strong>åˆ†é…å†…å­˜</strong></p><p>åœ¨<code>Allocator.cpp</code>ä¸­å®šä¹‰äº†å…¨å±€å˜é‡<code>allocator_array</code>æ¥å­˜å‚¨æ‰€æœ‰çš„ allocatorï¼Œæ¯ä¸ªè®¾å¤‡ç±»å‹å¯¹åº”ä¸€ä¸ªï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">C10_API at::Allocator* allocator_array[at::COMPILE_TIME_MAX_DEVICE_TYPES];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">SetAllocator</span><span class="params">(at::DeviceType t, at::Allocator* alloc)</span> </span>&#123;</span><br><span class="line">  allocator_array[<span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(t)] = alloc;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">at::<span class="function">Allocator* <span class="title">GetAllocator</span><span class="params">(<span class="keyword">const</span> at::DeviceType&amp; t)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span>* alloc = allocator_array[<span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(t)];</span><br><span class="line">  AT_ASSERTM(alloc, <span class="string">"Allocator for "</span>, t, <span class="string">" is not set."</span>);</span><br><span class="line">  <span class="keyword">return</span> alloc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åŒæ—¶é…å¤‡äº†<code>SetAllocator</code>å’Œ<code>GetAllocator</code>æ¥è®¾ç½®å’Œè·å–ç›¸åº”çš„åˆ†é…å™¨ã€‚</p><p><code>Allocator</code>æ˜¯ä¸€ä¸ªè™šåŸºç±»ï¼Œå®ƒçš„å£°æ˜å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">C10_API</span> <span class="title">Allocator</span> &#123;</span></span><br><span class="line">  <span class="keyword">virtual</span> ~Allocator() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> DataPtr <span class="title">allocate</span><span class="params">(<span class="keyword">size_t</span> n)</span> <span class="keyword">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// é‡è½½è¿™ä¸ªå‡½æ•°å¾ˆå…³é”®ï¼Œç”¨æ¥é‡Šæ”¾ç”³è¯·åˆ°çš„å†…å­˜</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> DeleterFnPtr <span class="title">raw_deleter</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span>* <span class="title">raw_allocate</span><span class="params">(<span class="keyword">size_t</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> dptr = allocate(n);</span><br><span class="line">    AT_ASSERT(dptr.get() == dptr.get_context());</span><br><span class="line">    <span class="keyword">return</span> dptr.release_context();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">raw_deallocate</span><span class="params">(<span class="keyword">void</span>* ptr)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> d = raw_deleter();</span><br><span class="line">    AT_ASSERT(d);</span><br><span class="line">    d(ptr);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>è¿™ä¸ªåˆ†é…å™¨æœ‰ä¸¤ç§ä½¿ç”¨æ–¹æ³•ï¼Œç¬¬ä¸€ç§å°±æ˜¯ç›´æ¥è°ƒç”¨<code>raw_allocate</code>å’Œ<code>raw_deallocate</code>åˆ†é…å’Œé‡Šæ”¾å†…å­˜ã€‚ç¬¬äºŒç§æ–¹æ³•æ˜¯è°ƒç”¨<code>Allocator::allocate</code>ï¼Œè¿™ä¸ªæ–¹æ³•å°†è¿”å›ä¸€ä¸ª<code>DataPtr</code>ç±»å‹çš„æŒ‡é’ˆï¼Œä¹Ÿå°±æ˜¯ <em>unique_ptr</em>ï¼Œç”±äºdeleterå­˜å‚¨åœ¨æŒ‡é’ˆä¸­ï¼Œåœ¨é‡Šæ”¾æŒ‡é’ˆçš„æ—¶å€™ä¼šé‡Šæ”¾ç›¸åº”çš„å†…å­˜ã€‚ä¸è¿‡ä¸¤ç§æ–¹æ³•çš„æ­£ç¡®æ€§éƒ½ä¾èµ–äº<code>Allocator::raw_deleter</code>èƒ½æ­£ç¡®è¿”å›ç›¸åº”çš„é‡Šæ”¾å™¨ï¼ˆdeleterï¼‰ï¼Œå¦åˆ™ä¸¤ç§æ–¹æ³•éƒ½ä¸èƒ½æ­£ç¡®é‡Šæ”¾å†…å­˜ã€‚è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé‡Šæ”¾å™¨ï¼ˆdeleterï¼‰æœªå¿…å°±æ˜¯Cåº“å‡½æ•°<code>free</code>ï¼šæ ¹æ®æ“ä½œç³»ç»Ÿçš„ä¸åŒï¼Œä¹Ÿå¯èƒ½æ˜¯<code>_aligned_free</code>ï¼›æ ¹æ®è®¾å¤‡çš„ä¸åŒä¹Ÿå¯èƒ½æ˜¯å…¶ä»–å‡½æ•°ã€‚</p><p>ä¸‹é¢æ˜¯åœ¨CPUä¸Šå†…å­˜åˆ†é…çš„å…·ä½“å®ç°ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">C10_API</span> <span class="title">DefaultCPUAllocator</span> <span class="title">final</span> :</span> at::Allocator &#123;</span><br><span class="line">  ...</span><br><span class="line">      </span><br><span class="line">  at::<span class="function">DataPtr <span class="title">allocate</span><span class="params">(<span class="keyword">size_t</span> nbytes)</span> <span class="keyword">const</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">void</span>* data = alloc_cpu(nbytes);</span><br><span class="line">    <span class="keyword">if</span> (FLAGS_caffe2_report_cpu_memory_usage &amp;&amp; nbytes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      getMemoryAllocationReporter().New(data, nbytes);</span><br><span class="line">      <span class="keyword">return</span> &#123;data, data, &amp;ReportAndDelete, </span><br><span class="line">              at::Device(at::DeviceType::CPU)&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// è¿™å››ä¸ªå‚æ•°ç”¨æ¥æ„é€ ä¸€ä¸ªDataPtr</span></span><br><span class="line">    <span class="keyword">return</span> &#123;data, data, &amp;free_cpu, </span><br><span class="line">            at::Device(at::DeviceType::CPU)&#125;;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  at::<span class="function">DeleterFnPtr <span class="title">raw_deleter</span><span class="params">()</span> <span class="keyword">const</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (FLAGS_caffe2_report_cpu_memory_usage) &#123;</span><br><span class="line">      <span class="keyword">return</span> &amp;ReportAndDelete;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> &amp;free_cpu;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">alloc_cpu</span><span class="params">(<span class="keyword">size_t</span> nbytes)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (nbytes == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">void</span>* data;</span><br><span class="line">  <span class="comment">// åˆ†é…64å­—èŠ‚å¯¹é½çš„è¿ç»­å†…å­˜å—</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __ANDROID__</span></span><br><span class="line">  data = memalign(gAlignment, nbytes);<span class="comment">// gAlignment = 64</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(_MSC_VER)</span></span><br><span class="line">  data = _aligned_malloc(nbytes, gAlignment);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  CAFFE_ENFORCE_EQ(posix_memalign(&amp;data, gAlignment, nbytes), <span class="number">0</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// ç§»åŠ¨æ•°æ®åˆ°çº¿ç¨‹çš„NUMAèŠ‚ç‚¹ä¸­</span></span><br><span class="line">  NUMAMove(data, nbytes, GetCurrentNUMANode());</span><br><span class="line"><span class="comment">// å¡«å……å†…å­˜</span></span><br><span class="line">  <span class="keyword">if</span> (FLAGS_caffe2_cpu_allocator_do_zero_fill) &#123;</span><br><span class="line">    <span class="built_in">memset</span>(data, <span class="number">0</span>, nbytes);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (FLAGS_caffe2_cpu_allocator_do_junk_fill) &#123;</span><br><span class="line">    memset_junk(data, nbytes);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> data;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">free_cpu</span><span class="params">(<span class="keyword">void</span>* data)</span> </span>&#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> _MSC_VER</span></span><br><span class="line">  _aligned_free(data);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  <span class="built_in">free</span>(data);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>åˆ†é…æ—¶ä½¿ç”¨<code>memalign/_aligned_malloc/posix_memalign</code>å‡½æ•°ç¡®ä¿å†…å­˜æ˜¯64å­—èŠ‚å¯¹é½çš„ã€‚</p><h2><span id="æ™ºèƒ½æŒ‡é’ˆ-intrusive_ptr">æ™ºèƒ½æŒ‡é’ˆ Intrusive_ptr</span></h2><p>PyTorchä¸­ä½¿ç”¨intrusive_ptræ¥ç®¡ç†THTensorå’ŒTHStorageçš„å¼•ç”¨è®¡æ•°ï¼Œå…¶ä¸­å¼•ç”¨åˆ†ä¸ºå¼ºå¼•ç”¨å’Œå¼±å¼•ç”¨ï¼ˆå¼±å¼•ç”¨ä¸ºäº†è§£å†³å¾ªç¯å¼•ç”¨é—®é¢˜ï¼‰ï¼Œå¯¹åº”çš„ç±»å <code>intrusive_ptr</code>å’Œ<code>weak_intrusive_ptr</code>ã€‚ç”±äºå¼±å¼•ç”¨å’Œå¼ºå¼•ç”¨çš„å®ç°ç±»ä¼¼ï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘æŠŠå¼±å¼•ç”¨çš„ä»£ç éƒ½å»æ‰äº†ï¼Œç®€åŒ–intrusive_ptrçš„å®ç°å¦‚ä¸‹ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">intrusive_ptr_target</span> &#123;</span></span><br><span class="line">  <span class="keyword">mutable</span> <span class="built_in">std</span>::atomic&lt;<span class="keyword">size_t</span>&gt; refcount_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// å£°æ˜å‹å…ƒç±»ä½¿å¾—åªèƒ½æŒ‡é’ˆå¯ä»¥è®¿é—® refcount_</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">intrusive_ptr</span>;</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="comment">// éšè—ææ„å‡½æ•°ï¼Œé˜²æ­¢ç›´æ¥ææ„å¯¹è±¡</span></span><br><span class="line">  <span class="keyword">virtual</span> ~intrusive_ptr_target() &#123;&#125;</span><br><span class="line"></span><br><span class="line">  constexpr intrusive_ptr_target() noexcept : refcount_(0) &#123;&#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// åœ¨æ‘§æ¯å¯¹è±¡æ—¶ä¼šè°ƒç”¨æ¬¡å‡½æ•°é‡Šæ”¾èµ„æº</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">release_resources</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">TTarget</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">intrusive_ptr</span> <span class="title">final</span> &#123;</span></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  TTarget* target_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// å¢åŠ å¼•ç”¨è®¡æ•°</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">retain_</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (target_ != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      <span class="keyword">size_t</span> new_refcount = ++target_-&gt;refcount_;</span><br><span class="line">      AT_ASSERTM(new_refcount != <span class="number">1</span>,</span><br><span class="line">                 <span class="string">"intrusive_ptr:Cannot increase refcount after it"</span></span><br><span class="line">                 <span class="string">"reached zero."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// é”€æ¯æ™ºèƒ½æŒ‡é’ˆï¼Œå‡å°‘å¼•ç”¨è®¡æ•°ï¼Œå½“å¼•ç”¨è®¡æ•°ä¸º0æ—¶æ‘§æ¯å¯¹è±¡</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">reset_</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (target_ != <span class="literal">nullptr</span> &amp;&amp; --target_-&gt;refcount_ == <span class="number">0</span>) &#123;</span><br><span class="line">      target_-&gt;release_resources();</span><br><span class="line">      <span class="keyword">delete</span> target_;</span><br><span class="line">    &#125;</span><br><span class="line">    target_ = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// éšè—é€šè¿‡æ™®é€šæŒ‡é’ˆåˆå§‹åŒ–çš„æ„é€ å‡½æ•°ï¼ˆåªèƒ½é€šè¿‡make_intrusiveè°ƒç”¨ï¼‰</span></span><br><span class="line">  explicit intrusive_ptr(TTarget* target) noexcept : target_(target) &#123;&#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  intrusive_ptr() <span class="keyword">noexcept</span> : intrusive_ptr(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// é€šè¿‡å…¶ä»–æ™ºèƒ½æŒ‡é’ˆåˆå§‹åŒ–ï¼Œéœ€å¢åŠ å¼•ç”¨è®¡æ•°</span></span><br><span class="line">  intrusive_ptr(<span class="keyword">const</span> intrusive_ptr&amp; rhs) : target_(rhs.target_) &#123;</span><br><span class="line">  retain_(); </span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ~intrusive_ptr() <span class="keyword">noexcept</span> &#123; reset_(); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">TTarget* <span class="title">get</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> target_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// é‡è½½è¿ç®—ç¬¦ä½¿å…¶èƒ½å½“ä½œæ­£å¸¸æŒ‡é’ˆä½¿ç”¨</span></span><br><span class="line">  <span class="keyword">const</span> TTarget&amp; <span class="keyword">operator</span>*() <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123; <span class="keyword">return</span> *target_; &#125;</span><br><span class="line">  TTarget&amp; <span class="keyword">operator</span>*() <span class="keyword">noexcept</span> &#123; <span class="keyword">return</span> *target_; &#125;</span><br><span class="line">  <span class="keyword">const</span> TTarget* <span class="keyword">operator</span>-&gt;() <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123; <span class="keyword">return</span> target_; &#125;</span><br><span class="line">  TTarget* <span class="keyword">operator</span>-&gt;() <span class="keyword">noexcept</span> &#123; <span class="keyword">return</span> target_; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">operator</span> <span class="title">bool</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123; <span class="keyword">return</span> target_ != <span class="literal">nullptr</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// è·å–å½“å‰çš„å¼•ç”¨è®¡æ•°</span></span><br><span class="line">  <span class="keyword">size_t</span> use_count() <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (target_ == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> target_-&gt;refcount_.load();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// æŠŠæ™®é€šæŒ‡é’ˆè½¬æ¢ä¸ºæ™ºèƒ½æŒ‡é’ˆï¼ˆå¢åŠ å¼•ç”¨è®¡æ•°ï¼‰</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span>... <span class="title">Args</span>&gt;</span></span><br><span class="line"><span class="class">  <span class="title">static</span> <span class="title">intrusive_ptr</span> <span class="title">make</span>(<span class="title">Args</span>&amp;&amp;... <span class="title">args</span>) &#123;</span></span><br><span class="line">    <span class="keyword">auto</span> result = intrusive_ptr(<span class="keyword">new</span> TTarget(<span class="built_in">std</span>::forward&lt;Args&gt;(args)...));</span><br><span class="line">    ++result.target_-&gt;refcount_;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// æŠŠæ™ºèƒ½æŒ‡é’ˆè½¬æ¢ä¸ºæ™®é€šæŒ‡é’ˆ</span></span><br><span class="line">  <span class="function">TTarget* <span class="title">release</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    TTarget* result = target_;</span><br><span class="line">    target_ = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// æŠŠæ™®é€šæŒ‡é’ˆè½¬æ¢ä¸ºæ™ºèƒ½æŒ‡é’ˆï¼ˆä¸å¢åŠ å¼•ç”¨è®¡æ•°ï¼‰</span></span><br><span class="line">  <span class="function"><span class="keyword">static</span> intrusive_ptr <span class="title">reclaim</span><span class="params">(TTarget* owning_ptr)</span> </span>&#123;</span><br><span class="line">    AT_ASSERTM(</span><br><span class="line">        owning_ptr == <span class="literal">nullptr</span> || owning_ptr-&gt;refcount_.load() &gt; <span class="number">0</span>,</span><br><span class="line">        <span class="string">"intrusive_ptr: Can only intrusive_ptr::reclaim() owning pointers that were created using intrusive_ptr::release()."</span>);</span><br><span class="line">    <span class="keyword">return</span> intrusive_ptr(owning_ptr);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ç”¨äºæ„é€ æ™ºèƒ½æŒ‡é’ˆ</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">TTarget</span>, <span class="title">class</span>... <span class="title">Args</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">inline</span> <span class="title">intrusive_ptr</span>&lt;TTarget&gt; <span class="title">make_intrusive</span>(<span class="title">Args</span>&amp;&amp;... <span class="title">args</span>) &#123;</span></span><br><span class="line">  <span class="keyword">return</span> intrusive_ptr&lt;TTarget&gt;::make(<span class="built_in">std</span>::forward&lt;Args&gt;(args)...);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>intrusive_ptr_target</code>æ˜¯è¢«å¼•ç”¨å¯¹è±¡çš„çˆ¶ç±»ï¼Œ<code>TensorImpl</code>å’Œ<code>StorageImpl</code>éƒ½ç»§æ‰¿è‡ªå®ƒï¼Œä¸»è¦å·¥ä½œæ˜¯å£°æ˜äº†ä¸€ä¸ªå¼•ç”¨è®¡æ•°<code>refcount_</code>ï¼Œå¹¶ä¸”æŠŠæ™ºèƒ½æŒ‡é’ˆç±»å£°æ˜ä¸ºå‹å…ƒç±»ï¼Œè¿™æ ·åœ¨<code>intrusive_ptr</code>é‡Œé¢å°±å¯ä»¥ç›´æ¥æ“ä½œ<code>refcount_</code>äº†ã€‚</p><p>å†æ¥çœ‹<code>intrusive_ptr</code>çš„å®ç°ï¼Œå®ƒæœ‰ä¸€ä¸ªç§æœ‰æˆå‘˜<code>TTarget* target_</code>ï¼Œæ˜¯è¢«å¼•ç”¨å¯¹è±¡çš„æ™®é€šæŒ‡é’ˆï¼›è¿˜æœ‰ä¸¤ä¸ªç§æœ‰æ–¹æ³•<code>retain_</code>å’Œ<code>reset_</code>ï¼Œåˆ†åˆ«ç”¨æ¥å¢åŠ å’Œå‡å°‘å¼•ç”¨è®¡æ•°ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼šé€šè¿‡æ™®é€šæŒ‡é’ˆåˆå§‹åŒ–<code>intrusive_ptr</code>çš„æ„é€ å‡½æ•°ä¹Ÿæ˜¯ç§æœ‰çš„ï¼Œä¸èƒ½è¢«å¤–éƒ¨è°ƒç”¨ï¼Œåªèƒ½é€šè¿‡é™æ€å‡½æ•°<code>make</code>æ¥è°ƒç”¨ï¼ˆè¯¦è§ä¸‹æ–‡ï¼‰ï¼›åœ¨é€šè¿‡å…¶ä»–æ™ºèƒ½æŒ‡é’ˆåˆå§‹åŒ–çš„æ—¶å€™éœ€è¦å¢åŠ å¼•ç”¨è®¡æ•°ã€‚</p><p>æœ€åè¿˜æœ‰ä¸¤ä¸ªæ–¹æ³•<code>release</code>å’Œ<code>reclaim</code>ï¼Œå®ƒä»¬å®ç°äº†æ™®é€šæŒ‡é’ˆå’Œæ™ºèƒ½æŒ‡é’ˆé—´çš„ç›¸äº’è½¬æ¢ï¼Œç”¨äºCé£æ ¼çš„APIä¸­ï¼ˆåœ¨Atenä¸­ç»å¸¸ç”¨åˆ°ï¼‰ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œ<code>intrusive_ptr</code>é‡Œè¿˜é‡è½½äº†è®¸å¤šè¿ç®—ç¬¦ï¼Œè®©å®ƒå¯ä»¥åƒæ™®é€šæŒ‡é’ˆä¸€æ ·ä½¿ç”¨ï¼Œè¿˜æœ‰è®¸å¤šå…¶ä»–æ–¹æ³•å°±ä¸ä¸€ä¸€ä»‹ç»äº†ã€‚</p><p><strong>åˆ›å»ºTensor</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">THTensor *<span class="title">THTensor_</span><span class="params">(<span class="keyword">new</span>)</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> c10::make_intrusive&lt;at::TensorImpl&gt;(</span><br><span class="line">    <span class="comment">// ä¸‹é¢ä¸‰ä¸ªå‚æ•°å°†é€šè¿‡intrusive_ptr::makeä¼ ç»™TensorImplçš„æ„é€ å‡½æ•°ï¼Œç„¶å</span></span><br><span class="line">    <span class="comment">// é€šè¿‡TensorImplçš„æŒ‡é’ˆæ„é€ intrusive_ptr</span></span><br><span class="line">    c10::intrusive_ptr&lt;at::StorageImpl&gt;::reclaim(THStorage_(<span class="keyword">new</span>)()),<span class="comment">// Storage&amp;&amp; storage</span></span><br><span class="line">    at::CPUTensorId(),<span class="comment">// TensorTypeId type_id</span></span><br><span class="line">    <span class="literal">false</span><span class="comment">// bool is_variable</span></span><br><span class="line">  ).release();<span class="comment">// releaseè¿”å›æ™®é€šæŒ‡é’ˆï¼ŒTensorImpl*</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">THStorage* <span class="title">THStorage_</span><span class="params">(<span class="keyword">new</span>)</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> THStorage_new(caffe2::TypeMeta::Make&lt;<span class="keyword">scalar_t</span>&gt;());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">THStorage* <span class="title">THStorage_new</span><span class="params">(caffe2::TypeMeta data_type)</span> </span>&#123;</span><br><span class="line">  THStorage* storage = c10::make_intrusive&lt;at::StorageImpl&gt;(</span><br><span class="line">      <span class="comment">// åŒç†ä¸‹é¢å››ä¸ªå‚æ•°å°†é€šè¿‡intrusive_ptr::makeä¼ ç»™StorageImplçš„æ„é€ å‡½</span></span><br><span class="line">      <span class="comment">// æ•°ï¼Œç„¶åé€šè¿‡StorageImplçš„æŒ‡é’ˆæ„é€ intrusive_ptr</span></span><br><span class="line">      data_type,</span><br><span class="line">      <span class="number">0</span>,</span><br><span class="line">      getTHDefaultAllocator(),</span><br><span class="line">      <span class="literal">true</span></span><br><span class="line">  ).release();</span><br><span class="line">  <span class="keyword">return</span> storage;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ä¸Šé¢æ˜¯æ–°å»ºä¸€ä¸ªtensorçš„è¿‡ç¨‹ï¼Œé€šè¿‡<code>c10::make_instrusive</code>æ„é€ æ™ºèƒ½æŒ‡é’ˆï¼Œç„¶åè°ƒç”¨<code>release</code>è¿”å›æ™®é€šæŒ‡é’ˆã€‚ä¼ å…¥çš„ä¸‰ä¸ªå‚æ•°ï¼šstorageæ™ºèƒ½æŒ‡é’ˆï¼Œtensortypeï¼Œis_variableä¼šè¢«è½¬å‘åˆ°<code>intrusive_ptr::make</code>å‡½æ•°ä¸­ï¼Œç„¶åç”¨è¿™ä¸‰ä¸ªå‚æ•°æ„é€ ä¸€ä¸ª<code>TensorImpl</code>å¯¹è±¡ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TensorImpl(Storage&amp;&amp; storage, TensorTypeId type_id, <span class="keyword">bool</span> is_variable);</span><br></pre></td></tr></table></figure><p>å†ç”¨è¯¥å¯¹è±¡çš„æŒ‡é’ˆåˆå§‹åŒ–æ™ºèƒ½æŒ‡é’ˆï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">intrusive_ptr(TTarget* target);</span><br></pre></td></tr></table></figure><p>åŒæ—¶å¢åŠ å¼•ç”¨è®¡æ•°ï¼Œæœ€å<code>make_intrusive</code>è¿”å›æ™ºèƒ½æŒ‡é’ˆã€‚THStorageçš„æ„é€ è¿‡ç¨‹åŒç†ã€‚</p><h2><span id="tensor-apply-amp-dynamic-dispatch">Tensor Apply &amp; Dynamic Dispatch</span></h2><p>THä¸­çš„Tensor Applyå°±ç›¸å½“äºmapå‡½æ•°ï¼ŒæŠŠä¸€ä¸ªå‡½æ•°åº”ç”¨åˆ°tensorçš„æ¯ä¸ªæ•°æ®ä¸­ã€‚ä¸¾ä¸ªä¾‹å­æ¥çœ‹ä¸€ä¸‹<code>THTensor_(cadd)</code>çš„å…·ä½“å®ç°ï¼ˆç®€åŒ–è¿‡çš„ï¼‰ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THTensor_</span><span class="params">(cadd)</span><span class="params">(THTensor *r_, THTensor *t, <span class="keyword">scalar_t</span> value, THTensor *src)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THTensor_(resizeAs)(r_, t);</span><br><span class="line">  <span class="keyword">int64_t</span> r_Size = THTensor_(nElement)(r_);</span><br><span class="line">  <span class="keyword">int64_t</span> srcSize = THTensor_(nElement)(src);</span><br><span class="line">  <span class="keyword">int</span> r_Contig = THTensor_(isContiguous)(r_);</span><br><span class="line">  <span class="keyword">int</span> tContig = THTensor_(isContiguous)(t);</span><br><span class="line">  <span class="keyword">int</span> srcContig = THTensor_(isContiguous)(src);</span><br><span class="line">  <span class="keyword">int</span> serial_path = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (srcSize == r_Size)&#123;</span><br><span class="line">    <span class="keyword">if</span> (r_Contig &amp;&amp; tContig &amp;&amp; srcContig) &#123;</span><br><span class="line">      TH_TENSOR_APPLY3_CONTIG(<span class="keyword">scalar_t</span>, r_, <span class="keyword">scalar_t</span>, t, <span class="keyword">scalar_t</span>, src, THVector_(cadd)(r__data, t_data, src_data, value, r__len););</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      serial_path = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    serial_path = <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (serial_path) &#123;</span><br><span class="line">    TH_TENSOR_APPLY3(</span><br><span class="line">      <span class="keyword">scalar_t</span>, r_, <span class="keyword">scalar_t</span>, t, <span class="keyword">scalar_t</span>, src, </span><br><span class="line">      *r__data = *t_data + value * *src_data;</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™ä¸ªå‡½æ•°å®ç°çš„åŠŸèƒ½å¾ˆç®€å•ï¼Œå°±æ˜¯<code>*r_ = *t + value * *src</code>ï¼ŒæŠŠ<code>src</code>çš„å€¼ä¹˜ä»¥<code>value</code>ç„¶åå’Œ<code>t</code>ç›¸åŠ ï¼Œæœ€åèµ‹å€¼ç»™<code>r_</code>ï¼Œå…¶ä¸­<code>r_, t, src</code>éƒ½æ˜¯THTensorã€‚å‡½æ•°é¦–å…ˆè·å–å…ƒç´ ä¸ªæ•°å’Œæ˜¯å¦è¿ç»­ç­‰ä¿¡æ¯ï¼Œå¦‚æœè¿ç»­çš„è¯è°ƒç”¨<code>TH_TENSOR_APPLY3_CONTIG</code>æ¥å¤„ç†ï¼Œå¦åˆ™è°ƒç”¨<code>TH_TENSOR_APPLY3</code>å¤„ç†ã€‚åè€…å¤ªå¤æ‚äº†ï¼Œæˆ‘ä»¬ä¸»è¦çœ‹å‰è€…çš„å®ç°ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> _OPENMP</span></span><br><span class="line"><span class="comment">// å¤šçº¿ç¨‹åŠ é€Ÿ</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TH_TENSOR_APPLY3_CONTIG(TYPE1, TENSOR1, TYPE2, TENSOR2, TYPE3, TENSOR3, CODE) \ </span></span><br><span class="line">&#123; \ </span><br><span class="line">  <span class="keyword">int</span> inOmp = omp_in_parallel(); \</span><br><span class="line">  <span class="keyword">ptrdiff_t</span> TH_TENSOR_size = THTensor_(nElement)(TENSOR1); \ </span><br><span class="line">  # å¯åŠ¨ OpenMP å¤šçº¿ç¨‹</span><br><span class="line">  PRAGMA(omp parallel <span class="keyword">if</span> ((TH_TENSOR_size &gt; TH_OMP_OVERHEAD_THRESHOLD) &amp;&amp; (!inOmp))) \</span><br><span class="line">  &#123; \</span><br><span class="line">    <span class="keyword">size_t</span> num_threads = omp_get_num_threads(); \</span><br><span class="line">    <span class="comment">// è·å–çº¿ç¨‹æ•°</span></span><br><span class="line">    <span class="keyword">size_t</span> tid = omp_get_thread_num(); \</span><br><span class="line">    <span class="comment">// è®¡ç®—å¼€å§‹å’Œç»“å°¾</span></span><br><span class="line">    <span class="keyword">ptrdiff_t</span> TH_TENSOR_offset = tid*(TH_TENSOR_size/num_threads);\</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> TH_TENSOR_end =(tid==num_threads<span class="number">-1</span>)?TH_TENSOR_size: \</span><br><span class="line">      TH_TENSOR_offset + TH_TENSOR_size / num_threads; \</span><br><span class="line">    <span class="comment">// æ¯ä¸ªçº¿ç¨‹è´Ÿè´£ TH_TENSOR_offset åˆ° TH_TENSOR_end ä¹‹é—´çš„æ•°æ®</span></span><br><span class="line">    <span class="keyword">ptrdiff_t</span> TENSOR1##_len = TH_TENSOR_end - TH_TENSOR_offset; \</span><br><span class="line">    <span class="comment">// è·å–Tensorçš„æ•°æ®</span></span><br><span class="line">    TYPE1 *TENSOR1##_data = TENSOR1-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;() + TH_TENSOR_offset; \</span><br><span class="line">    TYPE2 *TENSOR2##_data = TENSOR2-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;() + TH_TENSOR_offset; \</span><br><span class="line">    TYPE3 *TENSOR3##_data = TENSOR3-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;() + TH_TENSOR_offset; \</span><br><span class="line">    CODE \</span><br><span class="line">  &#125; \</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="comment">// æ™®é€šå®ç°</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TH_TENSOR_APPLY3_CONTIG(TYPE1, TENSOR1, TYPE2, TENSOR2, TYPE3, TENSOR3, CODE) \ </span></span><br><span class="line">&#123; \</span><br><span class="line">  <span class="comment">// è·å–Tensorçš„æ•°æ®</span></span><br><span class="line">  TYPE1 *TENSOR1##_data = TENSOR1-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;(); \</span><br><span class="line">  TYPE2 *TENSOR2##_data = TENSOR2-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;(); \</span><br><span class="line">  TYPE3 *TENSOR3##_data = TENSOR3-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;(); \</span><br><span class="line">  <span class="keyword">ptrdiff_t</span> TENSOR1##_len = THTensor_(nElement)(TENSOR1); \</span><br><span class="line">  <span class="comment">// æ‰§è¡Œä¼ å…¥çš„ä»£ç </span></span><br><span class="line">  CODE \</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>ä¸ŠåŠéƒ¨åˆ†çš„å®ç°ä¸ºOPENMPçš„å¤šçº¿ç¨‹åŠ é€Ÿç‰ˆï¼Œä¸‹é¢æ˜¯æ™®é€šç‰ˆã€‚è¿™ä¸ªå®æ¥æ”¶7ä¸ªå‚æ•°ï¼šä¸‰ä¸ªTensorå’Œå¯¹åº”ç±»å‹ï¼Œè¿˜æœ‰è¦æ‰§è¡Œçš„æ“ä½œã€‚<code>THTensor_(cadd)</code>ä¸­ä¼ å…¥çš„æ“ä½œæ˜¯<code>THVector_(cadd)(r__data, t_data, src_data, value, r__len);</code>ï¼Œå®ƒçš„å®šä¹‰ä¸ºï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// THVectorDispatch.cpp</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THVector_</span><span class="params">(cadd)</span><span class="params">(<span class="keyword">scalar_t</span> *z, <span class="keyword">const</span> <span class="keyword">scalar_t</span> *x, <span class="keyword">const</span> <span class="keyword">scalar_t</span> *y, <span class="keyword">const</span> <span class="keyword">scalar_t</span> c, <span class="keyword">const</span> <span class="keyword">ptrdiff_t</span> n)</span> </span>&#123;</span><br><span class="line">  THVector_(cadd_DISPATCHPTR)(z, x, y, c, n);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// åŠ¨æ€æ´¾å‘å‡½æ•°æŒ‡é’ˆ</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="title">void</span> <span class="params">(*THVector_(cadd_DISPATCHPTR))</span><span class="params">(<span class="keyword">scalar_t</span> *, <span class="keyword">const</span> <span class="keyword">scalar_t</span> *, <span class="keyword">const</span> <span class="keyword">scalar_t</span> *, <span class="keyword">const</span> <span class="keyword">scalar_t</span>, <span class="keyword">const</span> <span class="keyword">ptrdiff_t</span>)</span> </span>= &amp;THVector_(cadd_DEFAULT);</span><br><span class="line"><span class="comment">// å¯¹å„ç§å‘é‡åŒ–æŒ‡ä»¤çš„æ”¯æŒ</span></span><br><span class="line">static FunctionDescription THVector_(cadd_DISPATCHTABLE)[] = &#123;</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> defined(__NEON__)</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">if</span> defined(TH_REAL_IS_FLOAT)</span></span><br><span class="line">      FUNCTION_IMPL(THVector_(cadd_NEON), SIMDExtension_NEON),</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> defined(USE_AVX2)</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">if</span> defined(TH_REAL_IS_DOUBLE) || defined(TH_REAL_IS_FLOAT)</span></span><br><span class="line">      FUNCTION_IMPL(THVector_(cadd_AVX2), SIMDExtension_AVX2),</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">if</span> defined(USE_AVX)</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">if</span> defined(TH_REAL_IS_DOUBLE) || defined(TH_REAL_IS_FLOAT)</span></span><br><span class="line">      FUNCTION_IMPL(THVector_(cadd_AVX), SIMDExtension_AVX),</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  FUNCTION_IMPL(THVector_(cadd_DEFAULT), SIMDExtension_DEFAULT)</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// THVectorDefault.cpp</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THVector_</span><span class="params">(cadd_DEFAULT)</span><span class="params">(<span class="keyword">scalar_t</span> *z, <span class="keyword">const</span> <span class="keyword">scalar_t</span> *x, <span class="keyword">const</span> <span class="keyword">scalar_t</span> *y, <span class="keyword">const</span> <span class="keyword">scalar_t</span> c, <span class="keyword">const</span> <span class="keyword">ptrdiff_t</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">ptrdiff_t</span> i = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(; i&lt;n<span class="number">-4</span>; i+=<span class="number">4</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    z[i] = x[i] + c * y[i];</span><br><span class="line">    z[i+<span class="number">1</span>] = x[i+<span class="number">1</span>] + c * y[i+<span class="number">1</span>];</span><br><span class="line">    z[i+<span class="number">2</span>] = x[i+<span class="number">2</span>] + c * y[i+<span class="number">2</span>];</span><br><span class="line">    z[i+<span class="number">3</span>] = x[i+<span class="number">3</span>] + c * y[i+<span class="number">3</span>];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(; i&lt;n; i++)</span><br><span class="line">    z[i] = x[i] + c * y[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è¿™é‡Œæ¶‰åŠåˆ°å¯¹SIMDå‘é‡åŒ–æŒ‡ä»¤çš„æ”¯æŒå’ŒåŠ¨æ€æ´¾å‘ï¼Œå¯ä»¥çœ‹åˆ°<code>THVector_(cadd)</code>å‡½æ•°é‡Œè°ƒç”¨çš„æ˜¯<code>THVector_(cadd_DISPATCHPTR)</code>ï¼Œè€Œå®ƒæ˜¯ä¸€ä¸ªå‡½æ•°æŒ‡é’ˆï¼Œé»˜è®¤æŒ‡å‘<code>THVector_(cadd_DEFAULT)</code>ï¼Œè¿™ä¸ªæ˜¯ä¸æ”¯æŒå‘é‡åŒ–æŒ‡ä»¤çš„å®ç°ã€‚ä»£ç ä¸­é—´éƒ¨åˆ†çš„æ•°ç»„<code>FunctionDescription THVector_(cadd_DISPATCHTABLE)[]</code>è®°å½•å„ç§å‘é‡åŒ–æŒ‡ä»¤çš„å®ç°ï¼Œæœ€åæ˜¯é»˜è®¤çš„å®ç°ã€‚</p><p>åŠ¨æ€æ´¾å‘çš„å®ç°åœ¨<code>TH/vector/simd.h</code>ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INIT_DISPATCH_PTR(OP)                                     \ </span></span><br><span class="line">  <span class="keyword">do</span> &#123;                                                            \ </span><br><span class="line">    <span class="keyword">size_t</span> i;                                                     \ </span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="keyword">sizeof</span>(THVector_(OP ## _DISPATCHTABLE)) /     \ </span><br><span class="line">                         <span class="keyword">sizeof</span>(FunctionDescription); ++i) &#123;      \</span><br><span class="line">      THVector_(OP ## _DISPATCHPTR) =                             \</span><br><span class="line">        <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">decltype</span>(THVector_(OP ## _DISPATCHPTR))&gt; \</span><br><span class="line">        (THVector_(OP ## _DISPATCHTABLE)[i].function);            \</span><br><span class="line">      <span class="keyword">if</span> (THVector_(OP ## _DISPATCHTABLE)[i].supportedSimdExt     \</span><br><span class="line">          &amp; hostSimdExts) &#123;                                       \</span><br><span class="line">        <span class="keyword">break</span>;                                                    \</span><br><span class="line">      &#125;                                                           \</span><br><span class="line">    &#125;                                                             \</span><br><span class="line">  &#125; <span class="keyword">while</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">FunctionDescription</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="keyword">void</span> *function;</span><br><span class="line">  <span class="keyword">uint32_t</span> supportedSimdExt;</span><br><span class="line">&#125; FunctionDescription;</span><br></pre></td></tr></table></figure><p><code>INIT_DISPATCH_PTR</code>è¿™ä¸ªå®åšçš„äº‹å°±æ˜¯éå†<code>THVector_(cadd_DISPATCHTABLE)</code>æ•°ç»„ï¼Œå¾ªç¯å†…æŠŠåŠ¨æ€æ´¾å‘æŒ‡é’ˆï¼ˆ<code>THVector_(cadd_DISPATCHPTR)</code>ï¼‰èµ‹ç»™å½“å‰æ•°ç»„å…ƒç´ æ‰€å¯¹åº”çš„å‡½æ•°æŒ‡é’ˆï¼Œæœ€ååˆ¤æ–­ä¸€ä¸‹å½“å‰æ¶æ„æ˜¯å¦æ”¯æŒè¯¥æŒ‡ä»¤é›†ï¼Œå¦‚æœæ”¯æŒå°±é€€å‡ºå¾ªç¯ï¼›å¦‚æœå‘é‡åŒ–æŒ‡ä»¤é›†éƒ½ä¸æ”¯æŒçš„è¯ï¼Œæœ€åè¿˜ä¼šæŒ‡å‘é»˜è®¤å®ç°çš„å‡½æ•°æŒ‡é’ˆã€‚</p><p>ã¤ã¥ã</p><table><thead><tr class="header"><th style="text-align: left;">ä¸Šä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch0/">ç®€ä»‹</a></th><th style="text-align: right;">ä¸‹ä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch2/">THC</a></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"></td><td style="text-align: right;"></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> Tensor </tag>
            
            <tag> THTensor </tag>
            
            <tag> THStorage </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>PyTorchæºç æµ…æï¼šç®€ä»‹</title>
      <link href="/2019/05/05/PyTorch0/"/>
      <url>/2019/05/05/PyTorch0/</url>
      
        <content type="html"><![CDATA[<p>è¿™ä¸ªç³»åˆ—æ–‡ç« è‡ªåº•å‘ä¸Šé’ˆå¯¹PyTorchæ ¸å¿ƒæºç è¿›è¡Œæµ…æï¼Œä»Tensoråº“$\rightarrowâ€‹$ç¥ç»ç½‘ç»œ$\rightarrowâ€‹$è‡ªåŠ¨å¾®åˆ†$\rightarrowâ€‹$Pythonæ‰©å±•ï¼Œä¸€å…±äº”ç¯‡ã€‚</p><a id="more"></a><h2><span id="ç›®å½•">ç›®å½•</span></h2><blockquote><h3><span id="1-thtensor"></span></h3><p>PyTorchä¸­Tensorçš„å­˜å‚¨å’Œè¡¨ç¤ºåˆ†å¼€ï¼Œå¤šä¸ªTHTensorå¯èƒ½å…±äº«ä¸€ä¸ªTHStorageï¼Œæ¯ä¸ªTHTensorå¯èƒ½æ‹¥æœ‰ä¸åŒçš„viewï¼ˆe.g. size, strideï¼‰ã€‚è¿™æ ·è®¾è®¡çš„å¥½å¤„æ˜¯ï¼Œæœ‰æ—¶çœ‹èµ·æ¥ä¸ä¸€æ ·çš„æ•°æ®åº•å±‚æ˜¯å…±äº«çš„ï¼Œæ¯”å¦‚çŸ©é˜µä¸çŸ©é˜µçš„è½¬ç½®ã€äºŒç»´çŸ©é˜µä¸äºŒç»´çŸ©é˜µå˜æˆä¸€ç»´æ—¶çš„çŸ©é˜µã€‚è¿™éƒ¨åˆ†çš„ä¸»åŠ›å®ç°åœ¨<code>pytorch/aten</code>æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™é‡Œé¢æ—¢å®ç°äº†åº•å±‚çš„Tensoræ“ä½œåº“ï¼Œä¹Ÿå°è£…äº†åä¸º <strong>ATen</strong> çš„ C++11æ¥å£ã€‚</p></blockquote><blockquote><h3><span id="2-thc"></span></h3><p>è¿™ç¯‡ä¸»è¦çœ‹ Torch CUDA éƒ¨åˆ†ï¼Œå¯¹åº”æºç ç›®å½•<code>aten/src/THC</code>ï¼Œé‡Œé¢åŒ…å«äº†è®¸å¤šC++å’ŒCUDAä»£ç ã€‚è¿™éƒ¨åˆ†å®ç°äº†æ“ä½œ THCTensor å’Œ THCStorage çš„æ¥å£ï¼Œä¸è¿‡åº•å±‚ç”¨çš„æ•°æ®ç»“æ„è¿˜æ˜¯<code>TensorImpl</code>å’Œ<code>StorageImpl</code>ã€‚THCé‡Œçš„æ¥å£ä¹Ÿæ˜¯é€šè¿‡Cè¯­è¨€èŒƒå¼å®ç°çš„ï¼Œä½†æ˜¯Applyç³»åˆ—æ“ä½œä¸å†ç”±å®æ¥å®ç°ï¼Œè€Œæ˜¯ä½¿ç”¨äº†C++æ¨¡æ¿ã€‚å…¶ä»–çš„åŒºåˆ«è¿˜æœ‰allocatorä¸åŒï¼Œä»¥åŠå¤šäº† THCState ç»“æ„ã€‚</p></blockquote><blockquote><h3><span id="3-nn"></span></h3><p>THNNæ˜¯ä¸€ä¸ªç”¨Cè¯­è¨€å®ç°çš„ç¥ç»ç½‘ç»œæ¨¡å—çš„åº“ï¼Œæä¾›çš„åŠŸèƒ½éå¸¸åº•å±‚ã€‚å®ƒå®ç°äº†è®¸å¤šåŸºç¡€çš„ç¥ç»ç½‘ç»œæ¨¡å—ï¼ŒåŒ…æ‹¬çº¿æ€§å±‚ï¼Œå·ç§¯å±‚ï¼ŒSigmoidç­‰å„ç§æ¿€æ´»å±‚ï¼Œä¸€äº›åŸºæœ¬çš„losså‡½æ•°ï¼Œè¿™äº›APIéƒ½å£°æ˜åœ¨<code>THNN/generic/THNN.h</code>ä¸­ã€‚æ¯ä¸ªæ¨¡å—éƒ½å®ç°äº†å‰å‘ä¼ å¯¼ï¼ˆforwardï¼‰å’Œåå‘ä¼ å¯¼ï¼ˆbackwardï¼‰çš„åŠŸèƒ½ã€‚THCUNNåˆ™æ˜¯å¯¹åº”æ¨¡å—çš„CUDAå®ç°ã€‚</p></blockquote><blockquote><h3><span id="4-autograd"></span></h3><p>è¿™ç¯‡åšå®¢ä»‹ç» PyTorch ä¸­è‡ªåŠ¨å¾®åˆ†å¼•æ“çš„å®ç°ï¼Œä¸»è¦åˆ†ä¸ºä¸‰éƒ¨åˆ†ï¼šé¦–å…ˆç®€è¦ä»‹ç»ä¸€ä¸‹è®¡ç®—å›¾çš„åŸç†ï¼›ç„¶åä»‹ç» PyTorch ä¸­ä¸ autograd çš„ç›¸å…³æ•°æ®ç»“æ„å’Œ<code>backward()</code>å‡½æ•°çš„å®ç°ï¼Œæ•°æ®ç»“æ„åŒ…æ‹¬<code>torch::autograd::Variable</code>,<code>torch::autograd::Function</code>ç­‰ï¼›æœ€åè®²ä¸€ä¸‹åŠ¨æ€å»ºç«‹è®¡ç®—å›¾çš„å®ç°ï¼Œè¿™éƒ¨åˆ†ä»£ç æ¶‰åŠåˆ°åŠ¨æ€æ´¾å‘æœºåˆ¶ï¼Œè€Œä¸”éƒ½æ˜¯ç”¨è„šæœ¬ç”Ÿæˆçš„ï¼Œä¸å¤ªå®¹æ˜“ç†è§£ã€‚</p></blockquote><blockquote><h3><span id="5-pythonæ‰©å±•"></span></h3><p>è¿™ç¯‡æ˜¯æœ¬ç³»åˆ—æœ€åä¸€ç¯‡åšå®¢äº†ï¼Œä»‹ç»ä¸€ä¸‹å‰é¢çš„C++ä»£ç æ€ä¹ˆä¸Pythonäº¤äº’ï¼Œæˆ–è€…è¯´Pythoné‡Œæ€ä¹ˆè°ƒç”¨C++ä»£ç è¿›è¡Œé«˜æ•ˆçš„è®¡ç®—ã€‚é¦–å…ˆç®€å•ä»‹ç»ä¸€ä¸‹é¢„å¤‡çŸ¥è¯†ï¼Œæ—¢Pythonçš„Cæ‰©å±•é€šå¸¸æ€ä¹ˆå†™ï¼›ç„¶åä»¥æ¯”è¾ƒæ ¸å¿ƒçš„æ•°æ®ç»“æ„ Tensor å’Œ Storage ä¸ºä¾‹çœ‹ä¸€ä¸‹å®ƒä»¬æ€ä¹ˆè½¬æ¢ä¸ºPythonç±»å‹çš„ï¼›æœ€åç¨å¸¦ç‚¹å„¿Pythonè‡ªå¾®åˆ†å‡½æ•°çš„å®ç°ã€‚</p></blockquote><h2><span id="æºç ç›®å½•ç»“æ„">æºç ç›®å½•ç»“æ„</span></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">pytorch</span><br><span class="line">â”œâ”€â”€ aten                    <span class="comment"># ATen: C++ Tensoråº“</span></span><br><span class="line">â”‚Â Â  â”œâ”€â”€ CMakeLists.txt</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ conda</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ src</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ATen            <span class="comment"># C++ bindings</span></span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ README.md</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ TH              <span class="comment"># torch tensor</span></span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ THC             <span class="comment"># torch cuda</span></span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ THCUNN          <span class="comment"># torch cuda nn</span></span><br><span class="line">â”‚Â Â  â”‚Â Â  â””â”€â”€ THNN            <span class="comment"># torch nn</span></span><br><span class="line">â”‚Â Â  â””â”€â”€ tools</span><br><span class="line">â”œâ”€â”€ c10                     <span class="comment"># è¿™é‡Œé¢ä¹ŸåŒ…å«ä¸€äº›Tensorå®ç°</span></span><br><span class="line">â”‚Â Â  â”œâ”€â”€ CMakeLists.txt</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ core</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ cuda</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ hip</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ macros</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ <span class="built_in">test</span></span><br><span class="line">â”‚Â Â  â””â”€â”€ util</span><br><span class="line">â”œâ”€â”€ caffe2                  <span class="comment"># caffe2</span></span><br><span class="line">â”œâ”€â”€ tools</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ autograd            <span class="comment"># ç”Ÿæˆè‡ªå¾®åˆ†ç›¸å…³å‡½æ•°çš„å·¥å…·</span></span><br><span class="line">â”‚Â Â  â”œâ”€â”€ ...</span><br><span class="line">â”‚Â Â  â””â”€â”€ shared</span><br><span class="line">â”œâ”€â”€ torch                   <span class="comment"># Pythonæ¨¡å—</span></span><br><span class="line">â”‚Â Â  â”œâ”€â”€ autograd</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ csrc                <span class="comment"># C++ç›¸å…³æºç </span></span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ autograd        <span class="comment"># è‡ªåŠ¨å¾®åˆ†å¼•æ“å®ç°</span></span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cuda</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ distributed</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ generic</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ jit</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ multiprocessing</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ nn</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ tensor</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ utils</span><br><span class="line">â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ...</span><br><span class="line">â”‚Â Â  â”‚Â Â  â””â”€â”€ utils.h</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ cuda</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ nn</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ ...</span><br><span class="line">â”‚Â Â  â”œâ”€â”€ storage.py</span><br><span class="line">â”‚Â Â  â””â”€â”€ tensor.py</span><br><span class="line">â”œâ”€â”€ ...</span><br><span class="line">â””â”€â”€ ubsan.supp</span><br></pre></td></tr></table></figure><h2><span id="ä»£ç ç»Ÿè®¡">ä»£ç ç»Ÿè®¡</span></h2><table><thead><tr><th style="text-align:center">è¯­è¨€</th><th style="text-align:center">æ–‡ä»¶æ•°</th><th style="text-align:center">ç©ºè¡Œ</th><th style="text-align:center">æ³¨é‡Š</th><th style="text-align:center">ä»£ç </th></tr></thead><tbody><tr><td style="text-align:center">C++</td><td style="text-align:center">464</td><td style="text-align:center">25230</td><td style="text-align:center">9855</td><td style="text-align:center"><strong>330222</strong></td></tr><tr><td style="text-align:center">C/C++ Header</td><td style="text-align:center">1692</td><td style="text-align:center">40380</td><td style="text-align:center">51884</td><td style="text-align:center"><strong>251915</strong></td></tr><tr><td style="text-align:center">Python</td><td style="text-align:center">776</td><td style="text-align:center">27277</td><td style="text-align:center">31616</td><td style="text-align:center"><strong>117105</strong></td></tr><tr><td style="text-align:center">CUDA</td><td style="text-align:center">307</td><td style="text-align:center">7126</td><td style="text-align:center">4140</td><td style="text-align:center">40207</td></tr><tr><td style="text-align:center">â€¦</td><td style="text-align:center">â€¦</td><td style="text-align:center">â€¦</td><td style="text-align:center">â€¦</td><td style="text-align:center">â€¦</td></tr><tr><td style="text-align:center">æ€»è®¡</td><td style="text-align:center">3382</td><td style="text-align:center">104221</td><td style="text-align:center">101689</td><td style="text-align:center"><strong>825756</strong></td></tr></tbody></table><p><strong>æ³¨</strong>ï¼šä»…ç»Ÿè®¡äº†<code>torch</code>å’Œ<code>aten</code>ä¸¤ä¸ªæ ¸å¿ƒæ–‡ä»¶å¤¹ã€‚</p><h2><span id="æ„Ÿå—">æ„Ÿå—</span></h2><p>ä¸€å¼€å§‹åªæ˜¯å¿ƒè¡€æ¥æ½®è§‰å¾—è¿™å­¦æœŸåæ­£ä¸æ˜¯å¾ˆå¿™å°±ç«‹äº†ä¸ªflagå†³å®šå­¦æœŸå†…æŠŠPyTorchæºç çœ‹ä¸€éï¼Œçœ‹çš„è¿‡ç¨‹å¾ˆå—è‹¦ï¼Œåº†å¹¸æœ€ç»ˆè¿˜æ˜¯åšæŒä¸‹æ¥äº†ï¼Œæ”¶è·ä¹Ÿå¾ˆå¤§ã€‚é™¤äº†ç†è§£äº†PyTorchæ˜¯å¦‚ä½•è¿è¡Œçš„ã€è¾“å‡ºè¿™äº”ç¯‡åšå®¢ä¹‹å¤–ï¼Œæˆ‘å¯¹C++çš„ç†è§£ä¹Ÿæœ‰æ˜¾è‘—æå‡ï¼Œå› ä¸ºPyTorchå¤§éƒ¨åˆ†ä»£ç æ˜¯ç”¨C++å†™çš„ï¼Œå„ç§æ–°ç‰¹æ€§ç®€ç›´åˆ·æ–°äº†æˆ‘å¯¹è¿™é—¨è¯­è¨€çš„è®¤è¯†ï¼Œç”±æ­¤ä¹Ÿä¸“é—¨è®°äº†ä¸€ç¯‡<a href="https://www.52coding.com.cn/2019/05/05/C++/">å…³äºC++çš„ç¬”è®°</a>ã€‚</p><p>ç®€å•è¯´ä¸€ä¸‹æˆ‘çš„é˜…è¯»æ–¹æ³•ã€‚é¢å¯¹è¿™ä¹ˆå¤šçš„ä»£ç å’Œæ–‡ä»¶ï¼Œä¸€ä¸‹å­è‚¯å®šä¸çŸ¥æ‰€æªï¼Œå°¤å…¶æ˜¯é˜…è¯»æ–°æ¨¡å—çš„æ—¶å€™ï¼Œæˆ‘é¦–å…ˆä¼šå°è¯•æ‰¾åˆ°è¯¥æ¨¡å—çš„è¯´æ˜ï¼Œé€šè¿‡<code>README.md</code>æˆ–å‰äººçš„åšå®¢æˆ–APIæ–‡æ¡£äº†è§£ä¸‹è¯¥æ¨¡å—å¤§æ¦‚åŠŸèƒ½å’Œç»“æ„ï¼Œç„¶åæ•´ä½“ï¼ˆç²—ç•¥ï¼‰æµè§ˆä¸€éè¯¥æ¨¡å—çš„ä»£ç ï¼Œå¯¹æ¯ä¸ªæ–‡ä»¶é‡Œçš„ä»£ç æ˜¯åšä»€ä¹ˆçš„æœ‰ä¸ªå¤§è‡´æ¦‚å¿µï¼Œæœ€åå†æ ¹æ®è‡ªå·±çš„ç†è§£é€‰æ‹©æ€§åœ°è¿›è¡Œç²¾è¯»ã€‚</p><p>ã¤ã¥ã</p><table><thead><tr><th style="text-align:left"></th><th style="text-align:right">ä¸‹ä¸€ç¯‡ï¼š<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/">THTensor</a></th></tr></thead><tbody><tr><td style="text-align:left"></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyTorch </tag>
            
            <tag> Tensor </tag>
            
            <tag> NN </tag>
            
            <tag> Autograd </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>C++ç¬”è®°</title>
      <link href="/2019/05/05/C++/"/>
      <url>/2019/05/05/C++/</url>
      
        <content type="html"><![CDATA[<p>C++è¿™é—¨è¯­è¨€çœŸçš„æ˜¯åšå¤§ç²¾æ·±ï¼Œåœ¨é˜…è¯»PyTorchæºç çš„æ—¶å€™æ„Ÿè§¦å°¤ä¸ºæ·±åˆ»ï¼Œåœ¨æ­¤è®°å½•ä¸€äº›æˆ‘è®¤ä¸ºå¾ˆå¥½çš„ç¼–ç¨‹å®è·µä»¥åŠä¸€äº›C++çš„â€œæ–°â€ç‰¹æ€§ã€‚</p><a id="more"></a><h3><span id="æ¡ä»¶æ£€æŸ¥">æ¡ä»¶æ£€æŸ¥</span></h3><p>åœ¨ç¨‹åºéœ€è¦åˆ¤æ–­ä¸€äº›æ¡ä»¶æ‰èƒ½æ‰§è¡ŒæŸäº›æ“ä½œçš„æ—¶å€™ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå†™å¦‚ä¸‹ä»£ç ï¼š</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (cond == <span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// error, or throw exception</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">do</span> something ...</span><br></pre></td></tr></table></figure><p>è¿™äº›<code>if</code>è¯­å¥å¯ä»¥ç®€æ´ä¸ºä¸€è¡Œä»£ç ï¼Œå¦‚ä½¿ç”¨<code>assert</code>è¯­å¥ï¼Œä½†å¦‚æœä½ ä¸å¸Œæœ›ç¨‹åºå°±æ­¤ç»ˆæ­¢çš„è¯ï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰ç›¸åº”çš„å¤„ç†å‡½æ•°æˆ–å®ï¼Œå¦‚æœéœ€è¦æ£€æŸ¥çš„æ¡ä»¶å¾ˆå¤šçš„è¯ï¼Œè¿™æ ·è¿›è¡Œæ›¿æ¢å°±ä¼šä½¿ä»£ç æ•´æ´è®¸å¤šã€‚ä¸‹é¢æ˜¯åœ¨<code>pytorch/c10</code>ä¸­çš„æ¡ä»¶åˆ¤æ–­å¤„ç†å®ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> AT_ERROR(...) \</span></span><br><span class="line">  <span class="keyword">throw</span> ::c10::Error(&#123;__func__, __FILE__, <span class="keyword">static_cast</span>&lt;<span class="keyword">uint32_t</span>&gt;(__LINE__)&#125;, ::c10::str(__VA_ARGS__))</span><br><span class="line"></span><br><span class="line">#define AT_CHECK(cond, ...)            \</span><br><span class="line">  <span class="keyword">if</span> (!(cond)) &#123;                       \</span><br><span class="line">    AT_ERROR(::c10::str(__VA_ARGS__)); \</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3><span id="ç‰¹æ€§æµ‹è¯•">ç‰¹æ€§æµ‹è¯•</span></h3><p>å®å®šä¹‰çš„è¿ç”¨åœ¨C/C++ä¸­è‡³å…³é‡è¦ï¼Œå®å¯ä»¥ç”¨æ¥è§£å†³ä¸€äº›å…¼å®¹æ€§çš„é—®é¢˜ï¼Œå¹¶ä¸”ä½¿ä»£ç ä¿æŒç»Ÿä¸€ã€‚å¦‚<code>constexpr</code>å…³é”®å­—åœ¨ä¸åŒç‰ˆæœ¬çš„C++ä¸­èŒƒå›´ä¸åŒï¼Œé‚£ä¹ˆå·²çŸ¥ä¸€ä¸ªå‡½æ•°å¯ä»¥åœ¨C++14åŠä»¥ä¸Šçš„ç‰ˆæœ¬ä¸­å£°æ˜<code>constexpr</code>ä½†åœ¨ä¹‹å‰çš„ç‰ˆæœ¬ä¸­ä¸è¡Œï¼Œè¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿä¸€ä¸ªæ—¢èƒ½å…¼å®¹ä¸åŒç¼–è¯‘å™¨åˆèƒ½ä¿æŒä»£ç æ•´æ´ç»Ÿä¸€çš„æ–¹æ³•å°±æ˜¯ä½¿ç”¨å®å®šä¹‰ï¼Œå¦‚ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">AT_CPP14_CONSTEXPR <span class="keyword">const</span> T&amp; <span class="title">front</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    AT_CHECK(!empty(), <span class="string">"ArrayRef: attempted to access front() of empty list"</span>);</span><br><span class="line">    <span class="keyword">return</span> Data[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>AT_CPP14_CONSTEXPR</code>çš„å®šä¹‰ä¸ºï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__cpp_constexpr) &amp;&amp; __cpp_constexpr &gt;= 201304</span></span><br><span class="line"><span class="meta">#  <span class="meta-keyword">define</span> AT_CPP14_CONSTEXPR constexpr</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#  <span class="meta-keyword">define</span> AT_CPP14_CONSTEXPR</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>é€šè¿‡<a href="https://zh.cppreference.com/w/cpp/feature_test" target="_blank" rel="noopener">ç‰¹æ€§æµ‹è¯•</a>æ£€æŸ¥ç‰¹æ€§çš„æŒ‡å®šç‰ˆæœ¬æ¥åˆ¤æ–­èƒ½å¦ä½¿ç”¨è¯¥å…³é”®å­—ï¼Œå¦‚æœç‰ˆæœ¬å¤§äºæˆ‘ä»¬çš„è¦æ±‚ï¼Œåˆ™æŠŠå®å®šä¹‰ä¸ºè¯¥å…³é”®å­—ï¼Œå¦åˆ™å®šä¹‰ä¸ºç©ºã€‚</p><h3><span id="ä½¿ç”¨-nullptr-è€Œä¸æ˜¯-null">ä½¿ç”¨ nullptr è€Œä¸æ˜¯ NULL</span></h3><p>åœ¨C++ä¸­ï¼Œå®<code>NULL</code>åªæ˜¯å­—é¢é‡0ï¼Œè€Œ<code>nullptr</code>æ‰æ˜¯å­—é¢é‡ç©ºæŒ‡é’ˆã€‚</p><h3><span id="å‡½æ•°ä¸è¦å¤ªé•¿">å‡½æ•°ä¸è¦å¤ªé•¿</span></h3><p>åœ¨PyTorchä¸­ï¼Œå‡½æ•°éƒ½å¾ˆçŸ­ï¼Œä¸€èˆ¬ä¸è¶…è¿‡30è¡Œï¼Œå°½é‡æŠŠå‡½æ•°å˜å¾—ç²¾ç®€ã€‚</p><h3><span id="ampamp">&amp;&amp;</span></h3><p>å½“ <code>&amp;&amp;</code> å‡ºç°åœ¨å‚æ•°åˆ—è¡¨ä¸­æˆ–å‡½æ•°è¿”å›å€¼å¤„æ—¶è¡¨ç¤º<strong>å³å€¼å¼•ç”¨</strong>(RValue-Reference)ã€‚æ‰€è°“å³å€¼å¼•ç”¨å°±æ˜¯å¯¹å³å€¼çš„å¼•ç”¨ï¼Œè€Œå³å€¼å°±æ˜¯åªèƒ½å‡ºç°åœ¨ç­‰å·å³è¾¹çš„å€¼ï¼Œä¹Ÿå¯ä»¥ç†è§£ä¸ºæ²¡æœ‰å†…å­˜åœ°å€çš„å€¼ã€‚å¦‚æ•°å­—å­—é¢é‡ï¼Œ<code>a+1</code>(<code>int a;</code>) ç­‰éƒ½æ˜¯å³å€¼ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ª<code>&amp;&amp;</code>ç”¨æ³•çš„ä¾‹å­ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span>&amp;&amp; a)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//Some magical code...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> b;</span><br><span class="line">    foo(b); <span class="comment">//Error. An rValue reference cannot be pointed to a lValue.</span></span><br><span class="line">    foo(<span class="number">5</span>); <span class="comment">//Compiles with no error.</span></span><br><span class="line">    foo(b+<span class="number">3</span>); <span class="comment">//Compiles with no error.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span>&amp;&amp; c = b; <span class="comment">//Error. An rValue reference cannot be pointed to a lValue.</span></span><br><span class="line">    <span class="keyword">int</span>&amp;&amp; d = <span class="number">5</span>; <span class="comment">//Compiles with no error.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="default-å’Œ-delete">=default å’Œ = delete</span></h3><p>è¯¦è§ï¼šhttps://www.ibm.com/developerworks/cn/aix/library/1212_lufang_c11new/index.html</p><p>ç®€å•æ¥è¯´ï¼Œæ„é€ å‡½æ•°ã€ææ„å‡½æ•°ç­‰ç‰¹æ®Šå‡½æ•°å¯ä»¥ç”¨ <code>=default</code> æ¥è®©ç¼–è¯‘å™¨ä¸ºå…¶æä¾›é»˜è®¤æ„é€ å‡½æ•°æˆ–é»˜è®¤ææ„å‡½æ•°ã€‚è€Œ <code>=delete</code> å¯ä»¥ç¦ç”¨æŸä¸ªå‡½æ•°ï¼Œå¦‚ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">X</span>&#123;</span>            </span><br><span class="line">  <span class="keyword">public</span>: </span><br><span class="line">X(); </span><br><span class="line">X(<span class="keyword">const</span> X&amp;) = <span class="keyword">delete</span>;  <span class="comment">// å£°æ˜æ‹·è´æ„é€ å‡½æ•°ä¸º deleted å‡½æ•°</span></span><br><span class="line">  <span class="comment">// å£°æ˜æ‹·è´èµ‹å€¼æ“ä½œç¬¦ä¸º deleted å‡½æ•°</span></span><br><span class="line">X&amp; <span class="keyword">operator</span> = (<span class="keyword">const</span> X &amp;) = <span class="keyword">delete</span>; </span><br><span class="line">&#125;; </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123; </span><br><span class="line">X x1; </span><br><span class="line">  X x2=x1;   <span class="comment">// é”™è¯¯ï¼Œæ‹·è´æ„é€ å‡½æ•°è¢«ç¦ç”¨</span></span><br><span class="line">X x3; </span><br><span class="line">x3=x1;     <span class="comment">// é”™è¯¯ï¼Œæ‹·è´èµ‹å€¼æ“ä½œç¬¦è¢«ç¦ç”¨</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="æ™ºèƒ½æŒ‡é’ˆ">æ™ºèƒ½æŒ‡é’ˆ</span></h3><h4><span id="unique_ptr">Unique_Ptr</span></h4><p>åŒæ—¶åªèƒ½æœ‰ä¸€ä¸ªæ™ºèƒ½æŒ‡é’ˆå¯¹è±¡æŒ‡å‘æŸå—å†…å­˜ã€‚</p><p>ç‰¹æ€§ï¼š</p><ol type="1"><li><p>æ— æ³•è¿›è¡Œå¤åˆ¶æ„é€ ä¸èµ‹å€¼æ“ä½œ</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; ap(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">88</span> );</span><br><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; one (ap) ; <span class="comment">// error</span></span><br><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; two = one; <span class="comment">// error</span></span><br></pre></td></tr></table></figure></li><li><p>å¯ä»¥è¿›è¡Œç§»åŠ¨æ„é€ å’Œç§»åŠ¨èµ‹å€¼</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; GetVal() &#123;</span><br><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">88</span>));</span><br><span class="line"><span class="keyword">return</span> up;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; uPtr = GetVal();   <span class="comment">//ok</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; up(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">88</span>));</span><br><span class="line"><span class="built_in">unique_ptr</span>&lt;<span class="keyword">int</span>&gt; uPtr2 = <span class="built_in">std</span>:move(up); <span class="comment">// ok</span></span><br></pre></td></tr></table></figure></li></ol><h4><span id="shared_ptr">Shared_Ptr</span></h4><p><code>shared_ptr</code>æ˜¯è‡ªå¸¦å¼•ç”¨è®¡æ•°çš„æ™ºèƒ½æŒ‡é’ˆï¼Œæ¯ä¸€ä¸ª`<code>shared_ptr</code>çš„æ‹·è´éƒ½æŒ‡å‘ç›¸åŒçš„å†…å­˜ã€‚æ¯ä½¿ç”¨ä»–ä¸€æ¬¡ï¼Œå†…éƒ¨çš„å¼•ç”¨è®¡æ•°åŠ 1ï¼Œæ¯ææ„ä¸€æ¬¡ï¼Œå†…éƒ¨çš„å¼•ç”¨è®¡æ•°å‡1ï¼Œå‡ä¸º0æ—¶ï¼Œåˆ é™¤æ‰€æŒ‡å‘çš„å †å†…å­˜ã€‚<code>shared_ptr</code>å†…éƒ¨çš„å¼•ç”¨è®¡æ•°æ˜¯å®‰å…¨çš„ï¼Œä½†æ˜¯å¯¹è±¡çš„è¯»å–éœ€è¦åŠ é”ï¼Œ<a href="https://www.cnblogs.com/jiayayao/p/6128877.html" target="_blank" rel="noopener">é˜…è¯»æ›´å¤š</a>ã€‚</p><h4><span id="weak_ptr">Weak_Ptr</span></h4><p><code>weak_ptr</code> ç”¨æ¥è¡¨è¾¾ä¸´æ—¶æ‰€æœ‰æƒçš„æ¦‚å¿µï¼šå½“æŸä¸ªå¯¹è±¡åªæœ‰å­˜åœ¨æ—¶æ‰éœ€è¦è¢«è®¿é—®ï¼Œè€Œä¸”éšæ—¶å¯èƒ½è¢«ä»–äººåˆ é™¤æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ <code>weak_ptr</code> æ¥è·Ÿè¸ªè¯¥å¯¹è±¡ã€‚éœ€è¦è·å¾—ä¸´æ—¶æ‰€æœ‰æƒæ—¶ï¼Œåˆ™å°†å…¶è½¬æ¢ä¸º <code>shared_ptr</code>ï¼Œæ­¤æ—¶å¦‚æœåŸæ¥çš„ <code>shared_ptr</code> è¢«é”€æ¯ï¼Œåˆ™è¯¥å¯¹è±¡çš„ç”Ÿå‘½æœŸå°†è¢«å»¶é•¿è‡³è¿™ä¸ªä¸´æ—¶çš„ <code>shared_ptr</code> åŒæ ·è¢«é”€æ¯ä¸ºæ­¢ã€‚</p><p><code>weak_ptr</code>æ˜¯ä¸ºäº†é…åˆ<code>shared_ptr</code>è€Œå¼•å…¥çš„ä¸€ç§æ™ºèƒ½æŒ‡é’ˆï¼Œå®ƒæŒ‡å‘ä¸€ä¸ªç”±<code>shared_ptr</code>ç®¡ç†çš„å¯¹è±¡è€Œä¸å½±å“æ‰€æŒ‡å¯¹è±¡çš„ç”Ÿå‘½å‘¨æœŸï¼Œä¹Ÿå°±æ˜¯å°†ä¸€ä¸ª<code>weak_ptr</code>ç»‘å®šåˆ°ä¸€ä¸ª<code>shared_ptr</code>ä¸ä¼šæ”¹å˜<code>shared_ptr</code>çš„å¼•ç”¨è®¡æ•°ã€‚ä¸è®ºæ˜¯å¦æœ‰<code>weak_ptr</code>æŒ‡å‘ï¼Œä¸€æ—¦æœ€åä¸€ä¸ªæŒ‡å‘å¯¹è±¡çš„<code>shared_ptr</code>è¢«é”€æ¯ï¼Œå¯¹è±¡å°±ä¼šè¢«é‡Šæ”¾ã€‚ä»è¿™ä¸ªè§’åº¦çœ‹ï¼Œ<code>weak_ptr</code>æ›´åƒæ˜¯<code>shared_ptr</code>çš„ä¸€ä¸ªåŠ©æ‰‹è€Œä¸æ˜¯æ™ºèƒ½æŒ‡é’ˆã€‚C++ä¸­æä¾›äº†<code>lock</code>å‡½æ•°æ¥å®ç°è®¿é—®åŠŸèƒ½ã€‚å¦‚æœå¯¹è±¡å­˜åœ¨ï¼Œ<code>lock()</code>å‡½æ•°è¿”å›ä¸€ä¸ªæŒ‡å‘å…±äº«å¯¹è±¡çš„<code>shared_ptr</code>ï¼Œå¦åˆ™è¿”å›ä¸€ä¸ªç©º<code>shared_ptr</code>ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    A() : a(<span class="number">3</span>) &#123; <span class="built_in">cout</span> &lt;&lt; <span class="string">"A Constructor..."</span> &lt;&lt; <span class="built_in">endl</span>; &#125;</span><br><span class="line">    ~A() &#123; <span class="built_in">cout</span> &lt;&lt; <span class="string">"A Destructor..."</span> &lt;&lt; <span class="built_in">endl</span>; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> a;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">shared_ptr</span>&lt;A&gt; sp(<span class="keyword">new</span> A());</span><br><span class="line">    weak_ptr&lt;A&gt; wp(sp);</span><br><span class="line">    <span class="comment">//sp.reset();</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">shared_ptr</span>&lt;A&gt; pa = wp.lock())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; pa-&gt;a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"wpæŒ‡å‘å¯¹è±¡ä¸ºç©º"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/Xiejingfa/article/details/50772571" target="_blank" rel="noopener">é˜…è¯»æ›´å¤š</a>ã€‚</p><h3><span id="å˜å‚æ¨¡æ¿">å˜å‚æ¨¡æ¿</span></h3><p>å˜å‚æ¨¡æ¿å£°æ˜ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span>... <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">f</span>(<span class="title">T</span>... <span class="title">args</span>);</span></span><br></pre></td></tr></table></figure><p>çœç•¥å·çš„ä½œç”¨æœ‰ä¸¤ä¸ªï¼š</p><ol type="1"><li>å£°æ˜ä¸€ä¸ªå‚æ•°åŒ… <code>Tâ€¦ args</code>ï¼Œè¿™ä¸ªå‚æ•°åŒ…ä¸­å¯ä»¥åŒ…å«0åˆ°ä»»æ„ä¸ªæ¨¡æ¿å‚æ•°ï¼›</li><li>åœ¨æ¨¡æ¿å®šä¹‰çš„å³è¾¹ï¼Œå¯ä»¥å°†å‚æ•°åŒ…å±•å¼€æˆä¸€ä¸ªä¸€ä¸ªç‹¬ç«‹çš„å‚æ•°ã€‚</li></ol><p><strong>åŸºæœ¬ç”¨æ³•</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span>... <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">f</span>(<span class="title">T</span>... <span class="title">args</span>)</span></span><br><span class="line"><span class="class">&#123;</span>    </span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="keyword">sizeof</span>...(args) &lt;&lt; <span class="built_in">endl</span>; <span class="comment">//æ‰“å°å˜å‚çš„ä¸ªæ•°</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">f();        <span class="comment">//0</span></span><br><span class="line">f(<span class="number">1</span>, <span class="number">2</span>);    <span class="comment">//2</span></span><br><span class="line">f(<span class="number">1</span>, <span class="number">2.5</span>, <span class="string">""</span>);    <span class="comment">//3</span></span><br></pre></td></tr></table></figure><p><strong>é€’å½’å±•å¼€</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function">T <span class="title">sum</span><span class="params">(T t)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> ... Types&gt;</span><br><span class="line"><span class="function">T <span class="title">sum</span> <span class="params">(T first, Types ... rest)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> first + sum&lt;T&gt;(rest...);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sum(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>); <span class="comment">//10</span></span><br></pre></td></tr></table></figure><p><strong>åˆå§‹åŒ–åˆ—è¡¨+é€—å·è¡¨è¾¾å¼å±•å¼€</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">printarg</span>(<span class="title">T</span> <span class="title">t</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">   <span class="built_in">cout</span> &lt;&lt; t &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> ...<span class="title">Args</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">expand</span>(<span class="title">Args</span>... <span class="title">args</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">   <span class="keyword">int</span> arr[] = &#123;(printarg(args), <span class="number">0</span>)...&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">expand(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>);</span><br></pre></td></tr></table></figure><p>è¿™ä¸ªä¾‹å­å°†åˆ†åˆ«æ‰“å°å‡º1,2,3,4å››ä¸ªæ•°å­—ã€‚è¿™ç§å±•å¼€å‚æ•°åŒ…çš„æ–¹å¼ï¼Œä¸éœ€è¦é€šè¿‡é€’å½’ç»ˆæ­¢å‡½æ•°ï¼Œæ˜¯ç›´æ¥åœ¨<code>expand</code>å‡½æ•°ä½“ä¸­å±•å¼€çš„, <code>printarg</code>ä¸æ˜¯ä¸€ä¸ªé€’å½’ç»ˆæ­¢å‡½æ•°ï¼Œåªæ˜¯ä¸€ä¸ªå¤„ç†å‚æ•°åŒ…ä¸­æ¯ä¸€ä¸ªå‚æ•°çš„å‡½æ•°ã€‚</p><p><code>expand</code>å‡½æ•°ä¸­çš„é€—å·è¡¨è¾¾å¼ï¼š<code>(printarg(args), 0)</code>ï¼Œå…ˆæ‰§è¡Œ<code>printarg(args)</code>ï¼Œå†å¾—åˆ°é€—å·è¡¨è¾¾å¼çš„ç»“æœ<code>0</code>ã€‚åŒæ—¶è¿˜ç”¨åˆ°äº†C++11çš„å¦å¤–ä¸€ä¸ªç‰¹æ€§â€”â€”åˆå§‹åŒ–åˆ—è¡¨ï¼Œé€šè¿‡åˆå§‹åŒ–åˆ—è¡¨æ¥åˆå§‹åŒ–ä¸€ä¸ªå˜é•¿æ•°ç»„, <code>{(printarg(args), 0)â€¦}</code>å°†ä¼šå±•å¼€æˆ<code>((printarg(arg1),0), (printarg(arg2),0), (printarg(arg3),0), ...)</code>ï¼Œæœ€ç»ˆä¼šåˆ›å»ºä¸€ä¸ªå…ƒç´ å€¼éƒ½ä¸º<code>0</code>çš„æ•°ç»„<code>int arr[sizeof...(Args)]</code>ã€‚ç”±äºæ˜¯é€—å·è¡¨è¾¾å¼ï¼Œåœ¨åˆ›å»ºæ•°ç»„çš„è¿‡ç¨‹ä¸­ä¼šå…ˆæ‰§è¡Œé€—å·è¡¨è¾¾å¼å‰é¢çš„éƒ¨åˆ†<code>printarg(args)</code>æ‰“å°å‡ºå‚æ•°ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨æ„é€ intæ•°ç»„çš„è¿‡ç¨‹ä¸­å°±å°†å‚æ•°åŒ…å±•å¼€äº†ï¼Œè¿™ä¸ªæ•°ç»„çš„ç›®çš„çº¯ç²¹æ˜¯ä¸ºäº†åœ¨æ•°ç»„æ„é€ çš„è¿‡ç¨‹å±•å¼€å‚æ•°åŒ…ã€‚</p><p><strong>å®Œç¾è½¬å‘</strong></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="class"><span class="keyword">class</span> <span class="title">F</span>, <span class="title">class</span>... <span class="title">Args</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">void</span> <span class="title">expand</span>(<span class="title">const</span> <span class="title">F</span>&amp; <span class="title">f</span>, <span class="title">Args</span>&amp;&amp;...<span class="title">args</span>) </span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="built_in">initializer_list</span>&lt;<span class="keyword">int</span>&gt;&#123;(f(<span class="built_in">std</span>::forward&lt;Args&gt;(args)), <span class="number">0</span>)...&#125;;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// èŒƒå‹Lambdaè¡¨è¾¾å¼</span></span><br><span class="line">expand([](<span class="keyword">auto</span> i)&#123;<span class="built_in">cout</span> &lt;&lt; i &lt;&lt; <span class="built_in">endl</span>;&#125;, <span class="number">1</span>, <span class="number">2.0</span>, â€testâ€);</span><br></pre></td></tr></table></figure><p><code>std::forward</code>å¯ä»¥ä¿æŒå‚æ•°çš„å·¦å€¼æˆ–å³å€¼æ€§è´¨ï¼Œæ‰€ä»¥å«å®Œç¾è½¬å‘ã€‚</p><h3><span id="å‡½æ•°è¿”å›å€¼ç±»å‹åç½®">å‡½æ•°è¿”å›å€¼ç±»å‹åç½®</span></h3><p>ä¾‹å­ï¼š</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> ReadyQueue::push(FunctionTask item) -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(mutex);</span><br><span class="line">    ++item.base-&gt;outstanding_tasks;</span><br><span class="line">    heap.push(<span class="built_in">std</span>::move(item));</span><br><span class="line">  &#125;</span><br><span class="line">  not_empty.notify_one();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>è§£æï¼šhttps://blog.csdn.net/fjb2080/article/details/7527349</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> template </tag>
            
            <tag> æ™ºèƒ½æŒ‡é’ˆ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Microeconomics - The Costs of Production</title>
      <link href="/2019/04/10/The%20Costs%20of%20Production/"/>
      <url>/2019/04/10/The%20Costs%20of%20Production/</url>
      
        <content type="html"><![CDATA[<p>In this chapter, we examine firm behavior in more detail. This topic will give you a better understanding of the decisions behind the supply curve. In addition, it will introduce you to a part of economics called <em>industrial organization</em> â€” the study of how firmsâ€™ decisions about prices and quantities depend on the market conditions they face.</p><a id="more"></a><h2><span id="what-are-costs">WHAT ARE COSTS?</span></h2><p>We begin our discussion of costs at a Cookie factory. By examining some of the issues that the owner faces in his/her business, we can learn some lessons about costs that apply to all firms in an economy.</p><h3><span id="total-revenue-total-cost-and-profit">Total Revenue, Total Cost, and Profit</span></h3><p>The amount that the firm receives for the sale of its output is called its <strong>total revenue</strong>. The amount that the firm pays to buy inputs is called its <strong>total cost</strong>. <strong>Profit</strong> is a firmâ€™s total revenue minus its total cost:</p><p><span class="math display">\[\text{Profit} = \text{Total revenue} - \text{Total cost}\]</span></p><p>To see how a firm goes about maximizing profit, we must consider fully how to measure its total revenue and its total cost. Total revenue is the easy part: It equals the <em>quantity</em> of output the firm produces <em>times</em> the <em>price</em> at which it sells its output. By contrast, the measurement of a firmâ€™s total cost is more subtle.</p><h3><span id="costs-as-opportunity-costs">Costs As Opportunity Costs</span></h3><p><strong>explicit costs</strong>: input costs that require an outlay of money by the firm <strong>implicit costs</strong>: input costs that do not require an outlay of money by the firm</p><p>Imagine that the owner of the cookie factory is skilled with computers and could earn Â¥100 per hour working as a programmer. For every hour that she works at her cookie factory, she gives up Â¥100 in income, and this forgone income is also part of her costs. The total cost of her business is the sum of the explicit costs and the implicit costs.</p><h3><span id="the-cost-of-capital-as-an-opportunity-cost">The Cost of Capital as An Opportunity Cost</span></h3><p>An important implicit cost of almost every business is the opportunity cost of the financial capital that has been invested in the business. Suppose, for instance, that the owner of the cookie factory used Â¥300,000 of her savings to buy her cookie factory from its previous owner. If she had instead left this money deposited in a savings account that pays an interest rate of 5 percent, she would have earned Â¥15,000 per year. To own her cookie factory, therefore, Caroline has given up Â¥15,000 a year in interest income. This forgone Â¥15,000 is one of the <strong>implicit opportunity costs</strong> of Carolineâ€™s business.</p><h3><span id="economic-profit-versus-accounting-profit">Economic Profit Versus Accounting Profit</span></h3><p>Now letâ€™s return to the firmâ€™s objective: <strong>profit</strong>. An economist measures a firmâ€™s <strong>economic profit</strong> as the firmâ€™s total revenue minus all the opportunity costs (explicit and implicit) of producing the goods and services sold. An accountant measures the firmâ€™s <strong>accounting profit</strong> as the firmâ€™s total revenue minus only the firmâ€™s explicit costs as shown in Figure 1.</p><p><img src="/images/costandprod/DraggedImage.jpg"></p><p>Economic profit is an important concept because it is what motivates the firms that supply goods and services. As we will see, <em>a firm making positive economic profit will stay in business</em>. It is covering all its opportunity costs and has some revenue left to reward the firm owners. When a firm is making economic losses, the business owners are failing to earn enough revenue to cover all the costs of production. Unless conditions change, the firm owners will eventually close down the business and exit the industry. To understand business decisions, we need to keep an eye on economic profit.</p><p><strong>Economic profit equals to zero</strong> means your business is running well and you pay yourself the same amount as you get paid somewhere else.</p><h2><span id="production-and-costs">PRODUCTION AND COSTS</span></h2><p><img src="/images/costandprod/DraggedImage-1.jpg"></p><p>Table 1 shows how the quantity of cookies produced per hour at the cookie factory depends on the number of workers. This relationship between the <em>quantity of inputs</em> (workers) and <em>quantity of output</em> (cookies) is called the <strong>production function</strong>.</p><p><img src="/images/costandprod/DraggedImage-2.jpg"></p><p>To take a step toward understanding these decisions, the third column in the table gives the <strong>marginal product</strong> of a worker. Notice that as the number of workers increases, the marginal product declines. The second worker has a marginal product of 40 cookies, the third worker has a marginal product of 30 cookies, and the fourth worker has a marginal product of 20 cookies. This property is called <strong>diminishing marginal product</strong>.</p><p>Diminishing marginal product is also apparent in Figure 2. The production functionâ€™s slope tells us the change in the factoryâ€™s output of cookies for each additional input of labor. That is, the <strong>slope of the production function</strong> measures the <em>marginal product</em> of a worker. As the number of workers increases, the marginal product declines, and the production function becomes flatter.</p><h3><span id="from-the-production-function-to-the-total-cost-curve">From The Production Function To The Total-Cost Curve</span></h3><p>Our goal in the next is to study firmsâ€™ production and pricing decisions. For this purpose, the most important relationship in Table 1 is between quantity produced and total costs. Panel (b) of Figure 2 graphs these two columns of data with the quantity produced on the horizontal axis and total cost on the vertical axis. This graph is called the <strong>total-cost curve</strong>.</p><p>Now compare the total-cost curve in panel (b) with the production function in panel (a). These two curves are opposite sides of the same coin. The total-cost curve gets <em>steeper</em> as the amount produced rises, whereas the production function gets <em>flatter</em> as production rises. These changes in slope occur for the same reason. High production of cookies means that Carolineâ€™s kitchen is crowded with many workers. Because the kitchen is crowded, each additional worker adds less to production, reflecting diminishing marginal product. Therefore, the production function is relatively flat. But now turn this logic around: When the kitchen is crowded, producing an additional cookie requires a lot of additional labor and is thus very costly. Therefore, when the quantity produced is large, the total-cost curve is relatively steep.</p><h2><span id="the-various-measures-of-cost">THE VARIOUS MEASURES OF COST</span></h2><p><img src="/images/costandprod/DraggedImage-3.jpg"></p><p>To see how related measures of cost are derived, we consider the example in Table 2. This table presents cost data on Conradâ€™s Coffee Shop. Figure 3 plots Conradâ€™s total-cost curve. Conradâ€™s total-cost curve becomes steeper as the quantity produced rises, which (as we have discussed) reflects <em>diminishing marginal product</em>.</p><p><img src="/images/costandprod/DraggedImage-4.jpg"></p><h3><span id="fixed-and-variable-costs">Fixed And Variable Costs</span></h3><p><strong>Fixed costs</strong> are costs that do not vary with the <em>quantity of output produced</em>. They are incurred even if the firm produces nothing at all. Conradâ€™s fixed costs include any rent he pays because this cost is the same regardless of how much coffee he produces.</p><p><strong>Variable costs</strong> are costs that change as the firm alters the quantity of output produced. Conradâ€™s variable costs include the cost of coffee beans, milk, sugar, and paper cups: The more cups of coffee Conrad makes, the more of these items he needs to buy.</p><p>A firmâ€™s <strong>total cost</strong> is the sum of fixed and variable costs. In Table 2, total cost in the second column equals fixed cost in the third column plus variable cost in the fourth column.</p><h3><span id="average-and-marginal-cost">Average and Marginal Cost</span></h3><p>Total cost divided by the quantity of output is called <strong>average total cost</strong>. Because total cost is the sum of fixed and variable costs, average total cost can be expressed as the sum of average fixed cost and average variable cost. <strong>Average fixed cost</strong> is the fixed cost divided by the quantity of output, and <strong>average variable cost</strong> is the variable cost divided by the quantity of output.</p><p>Although average total cost tells us the cost of the typical unit, it does not tell us how much total cost will change as the firm alters its level of production. <strong>Marginal cost</strong> is the increase in total cost that arises from an extra unit of production. In the table, the marginal cost appears halfway between two rows because it represents the change in total cost as quantity of output increases from one level to another.</p><p>Mathematically:</p><p><span class="math display">\[ATC = TC/Q \\MC = \triangle TC / \triangle Q\]</span></p><h3><span id="cost-curves-and-their-shapes">Cost Curves And Their Shapes</span></h3><p><img src="/images/costandprod/DraggedImage-5.jpg"></p><p>Figure 4 graphs Conradâ€™s costs using the data from Table 2. The horizontal axis measures the quantity the firm produces, and the vertical axis measures marginal and average costs. The graph shows four curves: average total cost (ATC), average fixed cost (AFC), average variable cost (AVC), and marginal cost (MC).</p><p><strong>Rising Marginal Cost</strong> Conradâ€™s marginal cost rises with the quantity of out- put produced. This reflects the property of diminishing marginal product.</p><p><strong>U-Shaped Average Total Cost</strong> Average total cost is the sum of average fixed cost and average variable cost. Average fixed cost always declines as output rises because the fixed cost is spread over a larger number of units. Average variable cost typically rises as output increases because of diminishing marginal product. Average total cost reflects the shapes of both average fixed cost and average variable cost.</p><p>The bottom of the U-shape occurs at the quantity that minimizes average total cost. This <em>quantity</em> is sometimes called the <strong>efficient scale</strong> of the firm. At the efficient scale, these two forces are balanced to yield the lowest average total cost.</p><p><strong>The Relationship Between Marginal Cost and Average Total Cost</strong> * Whenever marginal cost is less than average total cost, average total cost is falling. * Whenever marginal cost is greater than average total cost, average total cost is rising.</p><p>To see why, consider an analogy. Average total cost is like your cumulative grade point average. Marginal cost is like the grade in the next course you will take. If your grade in your next course is less than your grade point average, your grade point average will fall. If your grade in your next course is higher than your grade point average, your grade point average will rise. The mathematics of average and marginal costs is exactly the same as the mathematics of average and marginal grades.</p><p>This relationship between average total cost and marginal cost has an important corollary: <strong>The marginal-cost curve crosses the average-total-cost curve at its minimum</strong>. As you will see in the next chapter, <strong>minimum average total cost</strong> plays a key role in the analysis of competitive firms.</p><h3><span id="typical-cost-curves">Typical Cost Curves</span></h3><p><img src="/images/costandprod/DraggedImage-6.jpg"></p><p>Actual firms are usually more complicated than what we talked about before. In many firms, marginal product does not start to fall immediately after the first worker is hired. Depending on the production process, the second or third worker might have a higher marginal product than the first because a team of workers can divide tasks and work more productively than a single worker. Firms exhibiting this pattern would experience increasing marginal product for a while before diminishing marginal product set in.</p><p>Figure 5 shows the cost curves for such a firm, including average total cost (ATC), average fixed cost (AFC), average variable cost (AVC), and marginal cost (MC). Despite these differences from our previous example, the cost curves shown here share the three properties that are most important to remember:</p><ul><li>Marginal cost eventually rises with the quantity of output.</li><li>The average-total-cost curve is U-shaped.</li><li>The marginal-cost curve crosses the average-total-cost curve at the <strong>minimum of average total cost</strong>.</li></ul><h2><span id="conclusion">CONCLUSION</span></h2><p><img src="/images/costandprod/DraggedImage-7.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¾®è§‚ç»æµå‹åŸç† </tag>
            
            <tag> Marginal Cost </tag>
            
            <tag> Profit </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Microeconomics - Consumers, Producers, and the Efficiency of Markets</title>
      <link href="/2019/03/20/Consumers,%20Producers,%20and%20the%20Efficiency%20of%20Markets/"/>
      <url>/2019/03/20/Consumers,%20Producers,%20and%20the%20Efficiency%20of%20Markets/</url>
      
        <content type="html"><![CDATA[<p>In this chapter, we take up the topic of <strong>welfare economics</strong>, the study of how the allocation of resources affects economic well-being. This analysis leads to a profound conclusion: The equilibrium of supply and demand in a market maximizes the total benefits received by buyers and sellers.</p><a id="more"></a><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#consumer-surplus">CONSUMER SURPLUS</a><ul><li><a href="#willingness-to-pay">Willingness To Pay</a></li><li><a href="#using-the-demand-curve-to-measure-consumer-surplus">Using The Demand Curve To Measure Consumer Surplus</a></li><li><a href="#how-a-lower-price-raises-consumer-surplus">How A Lower Price Raises Consumer Surplus</a></li><li><a href="#what-does-consumer-surplus-measure">What Does Consumer Surplus Measure?</a></li></ul></li><li><a href="#producer-surplus">PRODUCER SURPLUS</a><ul><li><a href="#cost-and-the-willingness-to-sell">Cost And The Willingness To Sell</a></li><li><a href="#using-the-supply-curve-to-measure-producer-surplus">Using The Supply Curve To Measure Producer Surplus</a></li><li><a href="#how-a-higher-price-raises-producer-surplus">How A Higher Price Raises Producer Surplus</a></li></ul></li><li><a href="#market-efficiency">MARKET EFFICIENCY</a><ul><li><a href="#the-benevolent-social-planner">The Benevolent Social Planner</a></li><li><a href="#evaluating-the-market-equilibrium">Evaluating The Market Equilibrium</a></li></ul></li><li><a href="#conclusion">CONCLUSION</a></li></ul><!-- tocstop --><h2><span id="consumer-surplus">CONSUMER SURPLUS</span></h2><h3><span id="willingness-to-pay">Willingness To Pay</span></h3><p><strong>Willingness to pay</strong> is the maximum amount that a buyer will pay for a good. <strong>Consumer surplus</strong> is the amount a buyer is willing to pay for a good minus the amount the buyer actually pays for it. For example, John is willing to pay Â¥100 for an album but pays only Â¥80 for it. So John receives <em>consumer surplus</em> of Â¥20.</p><h3><span id="using-the-demand-curve-to-measure-consumer-surplus">Using The Demand Curve To Measure Consumer Surplus</span></h3><p>Say John, Paul, George, and Ringo willing to buy an old album. Table 1 shows the maximum price that each of the four possible buyers would pay. The table in Figure 1 shows the demand schedule that corresponds to Table 1.</p><p><img src="/images/surplus/DraggedImage.jpg"> <img src="/images/surplus/DraggedImage-1.jpg"></p><p>Because the demand curve reflects buyersâ€™ willingness to pay, we can also use it to measure consumer surplus. Figure 2 uses the demand curve to compute consumer surplus in our two examples.</p><p><img src="/images/surplus/DraggedImage-2.jpg"></p><p>We can find out that <strong>the area below the demand curve and above the price measures the consumer surplus in a market</strong>. This is true because the height of the demand curve measures the value buyers place on the good, as measured by their willingness to pay for it. The difference between this willingness to pay and the market price is each buyerâ€™s consumer surplus. Thus, the total area below the demand curve and above the price is the sum of the consumer surplus of all buyers in the market for a good or service.</p><h3><span id="how-a-lower-price-raises-consumer-surplus">How A Lower Price Raises Consumer Surplus</span></h3><p><img src="/images/surplus/DraggedImage-3.jpg"></p><p>Figure 3 shows a typical demand curve. In panel (a), consumer surplus at a price of P1 is the area of triangle ABC. Now suppose that the price falls from P1 to P2, as shown in panel (b). The consumer surplus now equals area ADF.</p><p>This increase in consumer surplus is composed of two parts. First, those buyers who were already buying Q1 of the good at the higher price P1 are better off because they now pay less. It equals the area of the rectangle BCDE. Seconds, some new buyers enter the market. The consumer surplus these newcomers receive is the area of the triangle CEF.</p><h3><span id="what-does-consumer-surplus-measure">What Does Consumer Surplus Measure?</span></h3><p>Consumer surplus, the amount that buyers are willing to pay for a good minus the amount they actually pay for it, measures the benefit that buyers reveille from a good as the buyers themselves perceive it. Thus, consumer surplus is a good measure of economic well-being if policymakers want to respect the <strong>preferences of buyers</strong>.</p><h2><span id="producer-surplus">PRODUCER SURPLUS</span></h2><h3><span id="cost-and-the-willingness-to-sell">Cost And The Willingness To Sell</span></h3><p>A sellerâ€™s <strong>cost</strong> of doing a work is the value of everything the seller must give up to produce a good. <strong>Producer surplus</strong> is the amount a seller is paid for a good minus the sellerâ€™s cost of providing it.</p><h3><span id="using-the-supply-curve-to-measure-producer-surplus">Using The Supply Curve To Measure Producer Surplus</span></h3><p>Say there are four painters, Mary, Frida, Georgia, Grandma, compete for painting a house. Table 2 shows the costs of them. <img src="/images/surplus/DraggedImage-4.jpg"></p><p>Producer surplus is closely related to the supply curve. The table in Figure 4 shows the supply schedule that corresponds to the costs in Table 2. The graph in Figure 4 shows the supply curve that corresponds to this supply schedule.</p><p><img src="/images/surplus/DraggedImage-5.jpg"></p><p>Because the supply curve reflects sellersâ€™ cost, we can use it to measure producer surplus, as shown in Figure 5. <strong>The area below the price and above the supply curve measures the producer surplus in a market</strong>. The logic is straightforward: The height of the supply curve measures sellersâ€™ costs, and the difference between the price and the cost of production is each sellerâ€™s producer surplus. Thus, the total area is the sum of the producer surplus of all sellers. <img src="/images/surplus/DraggedImage-6.jpg"></p><h3><span id="how-a-higher-price-raises-producer-surplus">How A Higher Price Raises Producer Surplus</span></h3><p><img src="/images/surplus/DraggedImage-7.jpg"></p><p>Figure 6 shows a typical upward-sloping supply curve that would arise in a market with many sellers. In panel (a), the price is P1, and producer surplus is the area of triangle ABC. Panel (b) shows what happens when the price rises from P1 to P2. Producer surplus now equals area ADF.</p><h2><span id="market-efficiency">MARKET EFFICIENCY</span></h2><h3><span id="the-benevolent-social-planner">The Benevolent Social Planner</span></h3><p>One possible way to measure the economic well-being of a society is the sum of consumer and producer surplus, which we called <strong>total surplus</strong>. Consumer surplus is the benefit that buyers receive from participating in a market, and producer surplus is the benefit that sellers receive. It is therefore natural to use total surplus as a measure of societyâ€™s economic well-being.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Total surplus = Value to buyers - Cost to sellers</span><br></pre></td></tr></table></figure><p>Total surplus in a market is the total value to buyers of the goods, as measured by their willingness to pay, minus the total cost to sellers of providing those goods. If an allocation of resources maximizes total surplus, we say that the allocation exhibits <strong>efficiency</strong>.</p><p>In addition to efficiency, the social planner might also care about <strong>equality</strong>â€” that is, whether the various buyers and sellers in the market have a similar level of economic well-being.</p><h3><span id="evaluating-the-market-equilibrium">Evaluating The Market Equilibrium</span></h3><p><img src="/images/surplus/DraggedImage-8.jpg"></p><p>Figure 7 shows consumer and producer surplus when a market reaches the equilibrium of supply and demand curve. The total area between the supply and demand curves up to the point of equilibrium represents the total surplus in this market. Those buyers who value the good more than the price choose the buy the good; buyers who value it less than the price do not. Similarly, those sellers whose costs are less than the price choose to produce and sell the good.</p><p>These observations lead to three insights about market outcomes: 1. Free markets allocate the supply of goods to the buyers who value them most highly, as measured by their willingness to pay. 2. Free markets allocate the demand for goods to the sellers who can produce them at the least cost. 3. Free markets produce the quantity of goods that maximizes the sum of consumer and producer surplus.</p><p><img src="/images/surplus/DraggedImage-9.jpg"></p><p>Figure 8 illustrates why this is true. At any quantity below the equilibrium level, such as Q1, the value to the marginal buyer exceeds the cost to the marginal seller. As a result, increasing the quantity produced and consumed raises total surplus. This continues to be true until the quantity reaches the equilibrium level. Similar situations happed when the quantity larger than the equilibrium level.</p><p>Therefore, the equilibrium outcome is an <strong>efficient</strong> allocation of resources.</p><h2><span id="conclusion">CONCLUSION</span></h2><p>This chapter introduced the basic tools of welfare economics â€” consumer and producer surplus â€” and used them to evaluate the efficiency of free markets. We showed that the forces of supply and demand allocate resources efficiently.</p><p>A word of warning is in order. To conclude that markets are efficient, we made several assumptions about how markets work. First, our analysis assumed that markets are perfectly competitive. In the world, however, competition is sometimes far from perfect. Second, out analysis assumed that the outcome in a market matters only to the buyers and sellers in that market. Yet, in the world, the decisions of buyers and sellers sometimes affect people who are not participants in the market at all. Pollution is the classic example. Such side effects, called <strong>externalities</strong>, cause welfare in a market to depend on more than just the value to the buyers and the cost to the sellers.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¾®è§‚ç»æµå‹åŸç† </tag>
            
            <tag> Market Efficiency </tag>
            
            <tag> Consumer Surplus </tag>
            
            <tag> Producer Surplus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Microeconomics - Elasticity and Its Application</title>
      <link href="/2019/02/22/Elasticity%20and%20Its%20Application/"/>
      <url>/2019/02/22/Elasticity%20and%20Its%20Application/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#the-elasticity-of-demand">The Elasticity of Demand</a><ul><li><a href="#the-price-elasticity-of-demand-and-its-determinants">The Price Elasticity of Demand and Its Determinants</a></li><li><a href="#computing-the-price-elasticity-of-demand">Computing the Price Elasticity of Demand</a></li><li><a href="#the-midpoint-method-a-better-way-to-calculate-percentage-changes-and-elasticities">The Midpoint Method: A Better Way To Calculate Percentage Changes and Elasticities</a></li><li><a href="#the-variety-of-demand-curves">The Variety of Demand Curves</a></li><li><a href="#total-revenue-and-the-price-elasticity-of-demand">Total Revenue and The Price Elasticity of Demand</a></li><li><a href="#elasticity-and-total-revenue-along-a-linear-demand-curve">Elasticity and Total Revenue Along A Linear Demand Curve</a></li><li><a href="#other-demand-elasticities">Other Demand Elasticities</a></li></ul></li><li><a href="#the-elasticity-of-supply">The Elasticity Of Supply</a><ul><li><a href="#the-price-elasticity-of-supply-and-its-determinants">The Price Elasticity of Supply And Its Determinants</a></li><li><a href="#computing-the-price-elasticity-of-supply">Computing The Price Elasticity of Supply</a></li><li><a href="#the-vary-of-supply-curves">The Vary Of Supply Curves</a></li></ul></li><li><a href="#three-applications-of-supply-demand-and-elasticity">Three Applications Of Supply, Demand, And Elasticity</a><ul><li><a href="#can-good-news-for-farming-be-bad-news-for-farmers">Can Good News For Farming Be Bad News For Farmers</a></li><li><a href="#why-did-opec-fail-to-keep-the-price-of-oil-high">Why Did OPEC Fail To Keep The Price Of Oil High?</a></li><li><a href="#does-drug-interdiction-increase-or-decrease-drug-related-crime">Does Drug Interdiction Increase Or Decrease Drug-Related Crime?</a></li></ul></li><li><a href="#the-distributional-effects-of-tax">The Distributional Effects of Tax</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="the-elasticity-of-demand">The Elasticity of Demand</span></h2><p>To measure how much consumers respond to changes in economic variables, economists use the concept of <strong>elasticity</strong>. Elasticity is a measure of the responsiveness of quantity demanded or quantity supplied to one of its determinants.</p><h3><span id="the-price-elasticity-of-demand-and-its-determinants">The Price Elasticity of Demand and Its Determinants</span></h3><p>The <strong>price elasticity of demand</strong> measures how much the quantity demanded responds to a change in price. Demand for a good is said to be <em>elastic</em> if the quantity demanded responds substantially to changes in the price. Demand is said to be <em>inelastic</em> if the quantity demanded responds only slightly to changes in the price.</p><p>Based on experience, however, we can state some general rules about what determines the price elasticity of demand.</p><ul><li>Availablity of Close Substitutes</li><li>Necessities versus Luxuries</li><li>Definition of the Market</li><li>Time Horizon</li></ul><h3><span id="computing-the-price-elasticity-of-demand">Computing the Price Elasticity of Demand</span></h3><p><strong>Price elasticity of demand</strong> = Percentage change in quantity demanded / Percentage change in price</p><p>For example, suppose that a 10 percent increase in the price of an ice-cream cone causes the amount of ie cream you buy to fall by 20 percent. We calculate your elasticity of demand as</p><p>Price elasticity of demand = 20 percent / 10 percent = 2.</p><p>In this example, the elasticity is 2, reflecting that the change in the quantity demanded is proportionately twice as large as the change in the price. <em>A larger price elasticity implies a greater responsiveness of quantity demanded to price.</em></p><h3><span id="the-midpoint-method-a-better-way-to-calculate-percentage-changes-and-elasticities">The Midpoint Method: A Better Way To Calculate Percentage Changes and Elasticities</span></h3><p>The elasticity from point A to point B seems different from the elasticity from point B to point A. This difference arises because the percentage changes are calculated from a different base.</p><p>One way to avoid this problem is to use the <strong>midpoint method</strong> for calculating elasticities. The midpoint method computes a percentage change by dividing the midpoint of the initial and final levels. The following formula expresses the midpoint method for calculating the price elasticity of demand between two points, denoted (Q1, P1) and (Q2, P2):</p><p><img src="/images/elastic/DraggedImage.jpg"></p><h3><span id="the-variety-of-demand-curves">The Variety of Demand Curves</span></h3><p>Demand is considered <strong>elastic</strong> when the elasticity is greater than 1. Demand is considered <strong>inelastic</strong> when the elasticity is less than 1. Because the price elasticity of demand measures how much quantity demanded responds to changes in the price, it is closely related to the slope of the demand curve. The <strong>flatter</strong> the demand curve that passes through a given point, the <strong>greater</strong> the price elasticity of demand. The <strong>steeper</strong> the demand curve that passes through a given point, the <strong>smaller</strong> the price elasticity of demand. Figure 1 shows five cases.</p><p><img src="/images/elastic/DraggedImage-1.jpg"></p><h3><span id="total-revenue-and-the-price-elasticity-of-demand">Total Revenue and The Price Elasticity of Demand</span></h3><p><strong>Toal revenue</strong> is the amount paid by buyers and received by sellers of the good. In any market, total revenue is P * Q, the price of the good times the quantity of the good sold. We can show total revenue graphically, as in Figure 2.</p><p><img src="/images/elastic/DraggedImage-2.jpg"></p><p>How does total revenue change as one moves along the demand curve? There are some examples in Figure 3.</p><p><img src="/images/elastic/DraggedImage-3.jpg"></p><p>Although the examples in this figure are extreme, they illustrate some general rules:</p><ul><li>When demand is <strong>inelastic</strong>, price and total revenue move in the <strong>same direction</strong>.</li><li>When demand is <strong>elastic</strong>, price and total revenue move in <strong>opposite directions</strong>.</li><li>If demand is <strong>unit elastic</strong> (a price elasticity exactly equal to 1), total revenue <strong>remains constant</strong> when the price changes.</li></ul><h3><span id="elasticity-and-total-revenue-along-a-linear-demand-curve">Elasticity and Total Revenue Along A Linear Demand Curve</span></h3><p><img src="/images/elastic/DraggedImage-4.jpg"></p><p>Even though the slope of a linear demand curve is constant, the elasticity is not. This is true because the slope is the ratio of <em>changes</em> in the two variables, whereas the elasticity is the ratio of <em>percentage changes</em> in the two variables. At points with a low price and high quantity, the demand curve is inelastic. At points with a high price and low quantity, the demand curve is elastic.</p><p>The linear demand curve illustrates that the price elasticity of demand need not be the same at all points on a demand curve. A constant elasticity is possible, but it is not always the case.</p><h3><span id="other-demand-elasticities">Other Demand Elasticities</span></h3><p><strong>The Income Elasticity of Demand</strong> measures how the quantity demanded changes as consumer income changes.</p><p><img src="/images/elastic/DraggedImage-5.jpg"></p><p>Most of goods are <em>normal goods</em>: Higher income raises the quantity demanded, which have positive income elasticities. A few goods, such as bus rides, are <em>inferior goods</em>: Higher income lowers the quantity demanded, which have negative income elasticities.</p><p><strong>The Cross-Price Elasticity of Demand</strong> measures how the quantity demanded of one good responds to a change in the price of another good.</p><p><img src="/images/elastic/DraggedImage-6.jpg"></p><p>Substitutes are goods that are typically used in place of one another, whose cross-price elasticity is positive. Conversely, complements are goods that are typically used together, whose cross-price elasticity is negative.</p><h2><span id="the-elasticity-of-supply">The Elasticity Of Supply</span></h2><h3><span id="the-price-elasticity-of-supply-and-its-determinants">The Price Elasticity of Supply And Its Determinants</span></h3><p>The <strong>price elasticity of supply</strong> measures how much the quantity supplied responds to changes in the price. Supply of a good is said to be <em>elastic</em> if the quantity supplied responds substantially to changes in the price.</p><p>In most markets, a key determinant of the price elasticity of supply is the <strong>time period</strong> being considered. Supply is usually <em>more elastic in the long run</em> than in the short run.</p><h3><span id="computing-the-price-elasticity-of-supply">Computing The Price Elasticity of Supply</span></h3><p>Economists compute the price elasticity of supply as the percentage change in the quantity supplied divided by the percentage change in the price. That is, <img src="/images/elastic/DraggedImage-7.jpg"></p><h3><span id="the-vary-of-supply-curves">The Vary Of Supply Curves</span></h3><p><img src="/images/elastic/DraggedImage-8.jpg"></p><p><img src="/images/elastic/DraggedImage-9.jpg"></p><h2><span id="three-applications-of-supply-demand-and-elasticity">Three Applications Of Supply, Demand, And Elasticity</span></h2><h3><span id="can-good-news-for-farming-be-bad-news-for-farmers">Can Good News For Farming Be Bad News For Farmers</span></h3><p>The raise of production provided by new farming technology could make farmers worse off. Because the new technic increase the amount of wheat that can be produced on each acre of land, farmers are willing to supply more wheat at any price. In other words, <strong>the supply curve shift to the right</strong> and the demand curve still remain the same, which cause the price of wheat falls.</p><p><img src="/images/elastic/DraggedImage-10.jpg"></p><p>Wheat being an <strong>inelastic good</strong>, the price of wheat falls doesnâ€™t make people buy a lot more wheat. So a decrease in price causes farmersâ€™ total revenue to fall.</p><p>You may wonder why farmers would adopt the new technology. The answer goes to the heart of <strong>how competitive markets work</strong>. Because each farmer is only a small part of the market for wheat, itâ€™s better to use the new technic to produce and sell more wheat at any given price. Yet when all farmers do this, the supply of wheat increases, the price falls, and farmers are worse off.</p><p>It is important to keep in mind that what is good for farmers is not necessarily good for society as a whole. Improvement in farm technology can be bad for farmers because it makes farmers increasingly unnecessary, but it is surely good for consumers who pay less for food.</p><h3><span id="why-did-opec-fail-to-keep-the-price-of-oil-high">Why Did OPEC Fail To Keep The Price Of Oil High?</span></h3><p>The OPEC episode of 1970s and 1980s shows how supply and demand can behave differently in the short run and in the long run. <strong>In the short run</strong>, both the supply and demand for oil are <strong>inelastic</strong>. Supply is inelastic because the quantity of known oil reserves and the capacity for oil extraction cannot be changed quickly. Demand is inelastic because buying habits do not respond immediately to changes in price. Thus, as panel (a) of Figure 8 shows, <em>the short-run supply and demand curves are steep</em>.</p><p><img src="/images/elastic/DraggedImage-11.jpg"></p><p>The situation is very different in the long run. Over long periods of time, producers of oil outside OPEC respond to high prices by increasing oil exploration. Consumers respond with greater conservation. Thus, as panel (b) of Figure 8 shows, <em>the long-run supply and demand curves are more elastic</em>.</p><h3><span id="does-drug-interdiction-increase-or-decrease-drug-related-crime">Does Drug Interdiction Increase Or Decrease Drug-Related Crime?</span></h3><p><img src="/images/elastic/DraggedImage-12.jpg"></p><p>Suppose the government increase the number of federal agents devoted to the war on drugs. When the government stops some drugs from entering the country and arrests more smugglers, it raises the cost of selling drugs and, therefore, reduces the quantity of drugs supplied at any given price. But the <em>demand for drugs is not changed</em>, as panel (a) of Figure 9 shows.</p><p>But in terms of drug-related crime, since the demand for drugs is inelastic, then an increase in price raises total revenue in the drug market. Addicts who already had to steal to support their habits would have an even greater need for quick cash. Thus, <strong>drug interdiction could increase drug-related crime</strong>.</p><p>Rather than trying to reduce the supply of drugs, policymakers might try to reduce the demand by pursuing a policy of <strong>drug education</strong>. Successful drug education has the effects shown in panel (b) of Figure 9. Thus, in contrast to drug interdiction, <strong>drug education can reduce both drug use and drug-related crime</strong>.</p><p>However, the demand for drugs is probably inelastic over short periods, it may be more elastic elastic over longer periods because higher prices would discourage experimentation with drugs among the young and, over time, lead to fewer drug addicts. In this case, <strong>drug interdiction would increase drug-related crime in the short run while decreasing it in the long run</strong>.</p><h2><span id="the-distributional-effects-of-tax">The Distributional Effects of Tax</span></h2><p>Suppose this is the supply and demand curve of the gasoline market of Chicago without tax. The market price will be Â¥3 when there is no tax. So buyers pay Â¥3 to buy one gallon of gasoline and sellers receive Â¥3 for one gallon of gasoline.</p><p><img src="/images/elastic/DraggedImage-13.jpg"></p><p>Suppose the government imposes a tax of Â¥0.5 per gallon of gasoline and suppose the buyer will pay the tax. Then the demand curve will move left because there's a tax more. And that is changing the tax everywhere in the curve. So from any point, vertically in the curve, to the other point, we're going to have a distance of 50 cents. Letâ€™s say the new demand curve generate a new equilibrium at price Â¥2.75. So, what the buyers end up paying is at Â¥2.75, the buyer that goes to the Sellers, plus the 50 cents that goes to the government. So in the end, they're actually paying Â¥3.25 for a gallon of gasoline.</p><p><img src="/images/elastic/DraggedImage.png"></p><p>Now the buyers are paying Â¥3.25. So they are worse off because they have a higher price by Â¥0.25. And the sellers, while they were receiving Â¥3 before, now they're only getting Â¥2.75. So they are worse off by 25 cents too. Well, it looks like, in this particular situation, the buyers are sharing 25 cents, they're paying of the tax and sellers are putting up with 25 cents of the tax. So, <strong>this tax is equally distributed among the buyers and the sellers</strong>. And it doesn't matter if the sellers are the ones sending this tax to the government.</p><table><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;">No Tax</th><th style="text-align: center;">Tax Â¥0.5</th><th style="text-align: center;">Change</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Market Price</td><td style="text-align: center;">Â¥3.00</td><td style="text-align: center;">Â¥2.75</td><td style="text-align: center;">Â¥0.25</td></tr><tr class="even"><td style="text-align: center;">Buyers Pay</td><td style="text-align: center;">Â¥3.00</td><td style="text-align: center;">Â¥3.25</td><td style="text-align: center;">Â¥0.25</td></tr><tr class="odd"><td style="text-align: center;">Sellers Receive</td><td style="text-align: center;">Â¥3.00</td><td style="text-align: center;">Â¥2.75</td><td style="text-align: center;">Â¥0.25</td></tr></tbody></table><p>So what determined the distribution of the tax is which side of the market <em>has the most trouble adjusting to a tax</em>. And in this particular example, we're assuming that both have the same trouble and that is based on the elasticity. And the more inclined the curve is, the more inelastic that side of the market is.</p><p>Let's say the demand curve is like that below and the supply curve is a lot flatter. So this model here makes the assumption that the demand of gasoline is more inelastic than the supply of gasoline.</p><p><img src="/images/elastic/DraggedImage-14.jpg"></p><p>What happened? The market price went down to Â¥2.80. The buyers pays Â¥2.80 to the sellers, but then they pay 50 cents to the government. So they're actually paying effectively Â¥3.30 with this tax. So they're paying 30 cents more than they were paying before per gallon of gasoline. How about the sellers? The sellers were selling it for Â¥3 before. Now, they're getting Â¥2.80 from the buyers, so they're worse off 20 cents. And it's a whole different story, because now, of the 50 cents, 30 cents are shared by the buyers and only 20 cents by the sellers. So <em>the sellers are not sharing as much of the burden of this tax as the buyers are</em>.</p><table><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;">No Tax</th><th style="text-align: center;">Tax Â¥0.5</th><th style="text-align: center;">Change</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Market Price</td><td style="text-align: center;">Â¥3.00</td><td style="text-align: center;">Â¥2.80</td><td style="text-align: center;">Â¥0.20</td></tr><tr class="even"><td style="text-align: center;">Buyers Pay</td><td style="text-align: center;">Â¥3.00</td><td style="text-align: center;">Â¥3.30</td><td style="text-align: center;">Â¥0.30</td></tr><tr class="odd"><td style="text-align: center;">Sellers Receive</td><td style="text-align: center;">Â¥3.00</td><td style="text-align: center;">Â¥2.80</td><td style="text-align: center;">Â¥0.20</td></tr></tbody></table><p>So the seller has a lot more freedom here to adjust to this tax by perhaps charging a higher price to the buyers. The buyers cannot adjust as easily and they will have to put up with most of the burden. So in the end, <strong>the most inelastic side of the market is the one that actually shares most of the burden of the tax</strong> regardless of who send the tax to the government.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¾®è§‚ç»æµå‹åŸç† </tag>
            
            <tag> elasticity </tag>
            
            <tag> economic </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Microeconomics - The Market Forces of Supply and Demand</title>
      <link href="/2019/02/11/The%20Market%20Forces%20of%20Supply%20and%20Demand/"/>
      <url>/2019/02/11/The%20Market%20Forces%20of%20Supply%20and%20Demand/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#markets-and-competition">Markets and Competition</a><ul><li><a href="#what-is-a-market">What Is A Market?</a></li><li><a href="#what-is-competition">What is Competition?</a></li></ul></li><li><a href="#demand">Demand</a><ul><li><a href="#the-demand-curve-the-relationship-between-price-and-quantity-demand">The Demand Curve: The Relationship Between Price and Quantity Demand</a></li><li><a href="#market-demand-vs-individual-demand">Market Demand VS. Individual Demand</a></li><li><a href="#shifts-in-the-demand-curve">Shifts In the Demand Curve</a></li></ul></li><li><a href="#supply">Supply</a><ul><li><a href="#the-supply-curve-the-relationship-between-price-and-quantity-supplied">The Supply Curve: The Relationship Between Price and Quantity Supplied</a></li><li><a href="#market-supply-vs-individual-supply">Market Supply VS. Individual Supply</a></li><li><a href="#shifts-in-the-supply-curve">Shifts In The Supply Curve</a></li></ul></li><li><a href="#supply-and-demand-together">Supply And Demand Together</a><ul><li><a href="#equilibrium">Equilibrium</a></li><li><a href="#three-steps-to-analyzing-changes-in-equilibrium">Three Steps To Analyzing Changes In Equilibrium</a></li></ul></li><li><a href="#conclusion-how-prices-allocate-resources">Conclusion: How prices Allocate Resources</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="markets-and-competition">Markets and Competition</span></h2><h3><span id="what-is-a-market">What Is A Market?</span></h3><p>A <strong>market</strong> is a group of buyers and sellers of a particular good or service. Buyers decide the demand for the product while sellers decide the supply of the product.</p><h3><span id="what-is-competition">What is Competition?</span></h3><p>Economists use the term <strong>competitive market</strong> to describe a market in which there are so many buyers and so many sellers that each has a negligible impact on the market price.</p><p>Competition has various degrees, from <strong>perfectly competitive</strong> to <strong>monopoly</strong>.</p><p><em>Perfectly competitive</em> requires two characteristics: 1. the goods offered for sale are all exactly the same 2. the buyers and sellers are so numerous that no single buyer or seller has any influence over the market price.</p><p>However, some marketplace has only one seller, such a seller is called a <em>monopoly</em>.</p><h2><span id="demand">Demand</span></h2><p>We begin our study of markets by examining the behavior of buyers. To focus our thinking, letâ€™s keep in mind a particular good â€” ice cream.</p><h3><span id="the-demand-curve-the-relationship-between-price-and-quantity-demand">The Demand Curve: The Relationship Between Price and Quantity Demand</span></h3><p>The <strong>quantity demanded</strong> of any good is the amount of the good that buyers are willing and able to purchase. The relationship of price and quantity demanded follows the <strong>law of demand</strong>: Other things equal, when the price of a good rises, the quantity demanded of the good falls, and when the price falls, the quantity demanded rises. A table that shows the relationship between the price of a good and the quantity demanded is called <strong>demand schedule</strong>.</p><p><img src="/images/IMG_BD7E38AD92C1-1.jpg"></p><p>The graph in Figure 1 uses the numbers from the table to illustrate the law of demand. By convention, the quantity of ice cream demanded is on the horizontal axis. The downward-sloping line relating price and quantity demanded is called the <strong>demand curve</strong>.</p><h3><span id="market-demand-vs-individual-demand">Market Demand VS. Individual Demand</span></h3><p>Figure 1 shows the individual demand of ice-cream. However, most of the time, we want to focus on the <strong>market demand</strong> which is the sum of all individualâ€™s demands.</p><p><img src="/images/market/DraggedImage.jpg"></p><p>Figure 2 shows the Catherineâ€™s demand, Nicholasâ€™s demand as well as the market demand. At each price, the total quantity demand is the sum of Catherineâ€™s quantity demand and Nicholasâ€™s quantity demand. The market demand curve shows how the total quantity demanded of a good varies as the price of the good varies, while all the other factors are held constant.</p><h3><span id="shifts-in-the-demand-curve">Shifts In the Demand Curve</span></h3><p><img src="/images/market/DraggedImage-1.jpg"></p><p>Figure 3 illustrates shifts in the demand. There are many variables that can shift the demand curve. Here are the most important.</p><p><strong>Income</strong> If the demand for a good falls when income falls, the good is called a <strong>normal good</strong>. If the demand for a good rises when income falls, the good is called an <strong>inferior good</strong>, such as bus rides. As your income falls, you are less likely to buy a car or take a cab and more likely to ride a bus.</p><p><strong>Prices of Related Goods</strong> When a fall in the price of one good reduces the demand for another good, the two goods are called <strong>substitutes</strong>, such as ice cream and frozen yogurt, hot dogs and hamburgers. When a fall in the price of one good raises the demand for another good, the two goods are called <strong>complements</strong>, such as gasoline and automobiles, computers and software.</p><p><strong>Tastes</strong> If you like ice cream, you buy more of it. Economists examine what happens when tastes change.</p><p><strong>Expectations</strong> Your expectations about the future may affect your demand for a good or service today.</p><p><strong>Number of Buyers</strong> Market demand depends on the number of buyers.</p><p><strong>Summary</strong> <img src="/images/market/DraggedImage-2.jpg"></p><h2><span id="supply">Supply</span></h2><p>We now turn to the other side of the market and examine the behavior of sellers. Once again, to focus our thinking, letâ€™s consider the market for ice cream.</p><h3><span id="the-supply-curve-the-relationship-between-price-and-quantity-supplied">The Supply Curve: The Relationship Between Price and Quantity Supplied</span></h3><p><strong>Quantity supplied</strong> is the amount of a good that sellers are willing and able to sell. When other things equal, the quantity supplied of a good rises when the price of the good rises, which is called <strong>the law of supply</strong>.</p><p><strong>Supply schedule</strong> is a table that shows the relationship between the price of a good and the quantity supplied. The curve relating price and quantity supplied is called the <strong>supply curve</strong>.</p><p><img src="/images/market/DraggedImage-3.jpg"></p><h3><span id="market-supply-vs-individual-supply">Market Supply VS. Individual Supply</span></h3><p>Just as market demand is the sum of the demands of all buyers, market supply is the sum of the supplies of all sellers. As with demand curves, we sum the individual supply curves <em>horizontally</em> to obtain the market supply curves. <img src="/images/market/DraggedImage-4.jpg"></p><h3><span id="shifts-in-the-supply-curve">Shifts In The Supply Curve</span></h3><p><img src="/images/market/DraggedImage-5.jpg"></p><p>Figure 7 illustrate shifts in the supply curve. There are many variables that can shift the supply curve. Here are some of the most important.</p><p><strong>Input Prices</strong> When the price of one or more inputs rises, producing the good is less profitable, and firms supply less the good.</p><p><strong>Technology</strong> By reducing firmsâ€™ costs, the advanced technology raised the supply of goods.</p><p><strong>Expectations</strong> The amount of good a firm supplies today may depend on its expectations about the future.</p><p><strong>Number of Sellers</strong> In addition to the preceding factors, which influence the behavior of individual sellers, market supply depends on the number of these sellers.</p><p><strong>Summary</strong></p><p><img src="/images/market/DraggedImage-6.jpg"></p><h2><span id="supply-and-demand-together">Supply And Demand Together</span></h2><h3><span id="equilibrium">Equilibrium</span></h3><p>Figure 8 shows the market supply curve and market demand together. The intersection point is called <strong>equilibrium</strong>. Equilibrium is a situation in which the market price has reached the level at which quantity supplied equals quantity demanded. The price that balances quantity supplied and quantity demanded is called <strong>equilibrium</strong>.</p><p><img src="/images/market/DraggedImage-7.jpg"></p><p>At the equilibrium price, the quantity of the good that buyers are willing and able to buy exactly balances the quantity that sellers are willing and able to sell. The actions of buyers and sellers <strong>naturally move markets toward the equilibrium</strong> of supply and demand.</p><p><strong>Law of supply and demand</strong>: The price of any good adjusts to bring the quantity supplied and the quantity demanded for that good into balance.</p><p><img src="/images/market/DraggedImage-8.jpg"></p><h3><span id="three-steps-to-analyzing-changes-in-equilibrium">Three Steps To Analyzing Changes In Equilibrium</span></h3><ol type="1"><li>Decide whether the event shifts the supply or demand curve (or perhaps both).</li><li>Decide in which direction the curve shifts.</li><li>Use the supply-and-demand diagram to see how the shift changes the equilibrium price and quantity.</li></ol><p>Example 1:</p><p><img src="IMG_A9BD8FC2E549-1.jpeg"></p><p>In the ice-cream example, <strong>supply</strong> (which <em>refers to the position of the supply curve</em>) does not change because the weather does not alter firmsâ€™ desire to sell at any given price. Instead, the hot weather alters consumersâ€™ desire to buy at any given price and thereby shifts the demand curve to the right. The increase in demand causes the equilibrium price to rise. When the price rises, the <strong>quantity supplied</strong> rises. This increase in quantity supplied is represented by the <strong>movement along the supply curve</strong>.</p><p>Example 2: Shifts in Both Supply and Demand</p><p><img src="/images/market/DraggedImage-9.jpg"></p><p><strong>Summary</strong></p><p><img src="/images/market/DraggedImage-10.jpg"></p><h2><span id="conclusion-how-prices-allocate-resources">Conclusion: How prices Allocate Resources</span></h2><p>Consider the allocation of beachfront land. Because the amount of this land is limited, not everyone can enjoy the luxury of living by the beach. Who gets this resource? The answer is whoever is <strong>willing and able to pay the price</strong>. The price of beachfront land adjusts until the quantity of land demanded exactly balances the quantity supplied. Thus, in market economies, <strong>prices are the mechanism for rationing scarce resources</strong>.</p><p>Similarly, prices determine who produces each good and how much is produced. If an invisible hand guides market economies, as Adam Smith famously suggested, then the price system is the baton that the invisible hand uses to conduct the economic orchestra.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¾®è§‚ç»æµå‹åŸç† </tag>
            
            <tag> Supply Curve </tag>
            
            <tag> Demand Curve </tag>
            
            <tag> Equilibrium </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Vehicles</title>
      <link href="/2018/12/09/RS%20-%20Recognizing%20Vehicles/"/>
      <url>/2018/12/09/RS%20-%20Recognizing%20Vehicles/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 6. è¯†åˆ«ç³»ç»Ÿå¤ä¹ ç¬”è®°ã€‚</p><p>Vehicle recognition, including detection, tracking and identification, has been a research topic among automotive manufacturers, suppliers and universities for enhancing road safety.</p><p>For example, the <a href="http://www.argo.ce.unipr.it/ARGO/english/index.html" target="_blank" rel="noopener">ARGO</a> project, started in 1996 at the University of Parma and the University of Pavia, Italy, is aimed at developing a system for improving road safety by controlling and supervising the driver activity.</p><a id="more"></a><!-- toc --><ul><li><a href="#lane-detection">Lane Detection</a><ul><li><a href="#canny-edge-detector">Canny edge detector</a></li></ul></li><li><a href="#vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</a></li><li><a href="#visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</a></li><li><a href="#application-examples">Application Examples</a></li></ul><!-- tocstop --><h2><span id="lane-detection">Lane Detection</span></h2><p>For vehicle detection and tracking and intelligent transportation systems, lane marking detection is one of the key steps. Lane markings can be detected based on the camera inverse perspective mapping (IPM) and the assumption that the lane markings are represented by almost vertical bright lines of constant width, surrounded by a darker background.</p><p>The lanes can then be detected by using the camera <strong>inverse perspective mapping (IPM)</strong> and the <strong>Canny edge detector</strong>.</p><p><strong>Inverse perspective mapping</strong></p><p><img src="/images/impres.png"></p><p><img src="/images/ipmreason.png"></p><h3><span id="canny-edge-detector">Canny edge detector</span></h3><p><a href="http://en.wikipedia.org/wiki/Canny_edge_detector" target="_blank" rel="noopener">Canny edge detector</a> is one of the most popular detectors of edge pixels. The edge detection process serves to simplify the analysis of images by drastically <strong>reducing the amount of data to be processed</strong>, while at the same time <strong>preserving useful structural information</strong> about object boundaries.</p><p>There are three common criteria relevant to edge detector performance.</p><ul><li>It is important that edges that occur in the image should not be missed and that there be <em>no spurious responses</em>.</li><li>The edge points should be well localized. That is, the distance between the points marked by the detector and the true edge center should be minimized.</li><li>The last requirement is to circumvent the possibility of multiple responses to a single edge.</li></ul><p><img src="/images/cedbalala.jpg"></p><p>In the figure above, (a) is a noisy step edge; (b) is a difference of boxes operator; (c) is the output of filtering by box operator; (d) is the first derivative of Gaussian operator; and (e) is the first derivative of Gaussian applied to the edge.</p><p><img src="/images/cannysd.png"></p><p>The <strong>edge center</strong> is marked as <strong>red circle</strong> at a local maximum in the output of the filter responses. Within the region of the edge, the boxes operator exhibits more local maxima than the Gaussian operator. Therefore, <strong>the Gaussian operator is better</strong> than the boxes operator in this example.</p><p><strong>The three performance criteria</strong></p><ol type="1"><li><p>Good detection â†’ Detection Criterion</p><p>There should be a low probability of failing to mark real edge points, and low probability of falsely marking non-edge points. This is controlled by signal-to-noise ratio: <span class="math display">\[\text{SNR}=\frac{|\int_{-w}^{+w}G(-x)f(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f(x)^2dx}}\]</span></p></li><li><p>Good localization â†’ Localization Criterion</p><p>The points marked as edge points by the operator should be as close as possible to the true edge center. The localization is defined as the reciprocal of <span class="math inline">\(\delta x_0\)</span>: <span class="math display">\[\text{Localization}=\frac{|\int_{-w}^{+w}G(-x)f&#39;(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f&#39;(x)^2dx}}\]</span></p></li><li><p>Only one response to a single edge â†’ Multiple Response Constraint <span class="math display">\[x_{zc}(f)=\pi\left(\frac{\int_{-\infty}^{+\infty}f&#39;(x)^2dx}{\int_{-\infty}^{+\infty}f&#39;&#39;(x)^2dx}\right)^{1/2}\]</span></p></li></ol><p>It is very difficult to find the function <span class="math inline">\(f\)</span> (filter) which maximizes the detection and localization criteria subject to the multiple response constraint. Numerical optimization is therefore used.</p><p>The solution is of the form <span class="math display">\[f(x)=a_1e^{\alpha x}\sin\omega x+a_2e^{\alpha x}\cos\omega x+a_3e^{-\alpha x}\sin\omega x\\+a_4e^{-\alpha x}\cos\omega x+c\]</span> The variables are determined by the non-linear optimization with boundary conditions.</p><p>The numerically estimated optimal edge detector can be approximated by the <strong>first derivative of a Gaussian</strong> G, where <span class="math display">\[G(x)=\exp(-\frac{x^2}{2\sigma^2})\\f(x)=G&#39;(x)=-\frac{x}{\sigma^2}\exp(-\frac{x^2}{2\sigma^2})\]</span> For 2D, the solution proposed by Canny amounts to convolving the initial image with a Gaussian function followed by computation of the derivatives in <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> of the result.</p><p><img src="/images/firstderofgaus.png"></p><p>There are three main steps in the Canny edge detection</p><ol type="1"><li><p>Gradient calculation</p><p>compute <span class="math inline">\(M\)</span>: <span class="math display">\[I_x=\frac{\partial}{\partial x}(I\ast G(x,y))\\I_y=\frac{\partial}{\partial y}(I\ast G(x,y))\\M=\sqrt{I_x^2+I_y^2}\approx |I_x|+|I_y|\]</span></p></li><li><p>Non-maximum suppression</p><p>keep local maximum, set others to zero.</p></li><li><p>Hysteresis thresholding</p><p><img src="/images/hyposisthres.png"></p></li></ol><h2><span id="vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</span></h2><p>Vehicle detection is based on the assumption that the rear or frontal views of the vehicles are generally symmetric; can be characterized by a rectangular bounding box which satisfies specific aspect ratio constraints and is placed in a specific region of the image, e.g., within lanes.</p><p>These features are used to identify vehicles in the image.</p><ol type="1"><li>Area of interest is identified on the basis of road position and perspective constraints.</li><li>This area of interest is searched for possible vertical symmetries. Not only are the gray level symmetries considered, but also vertical and horizontal edge symmetries are considered.</li><li>Step 3: Once the symmetry axis has been detected, the lower part (the two bottom corners) of a rectangular bounding box is detected.</li><li>The top horizontal limit of the vehicle is then searched according to the pre-defined aspect ratio.</li></ol><p><img src="/images/vdbasedonsys.png"></p><p>Vertical and horizontal binary edges can help solve the problems of strong reflection areas in the vehicle images. The analysis of symmetry produces symmetry maps for gray-level intensity, edge (total), horizontal edge, vertical edge and total (combined) symmetry. The symmetry axis can be found from the total symmetry map.</p><p><strong>Bounding box detection</strong></p><p>After detecting the symmetry axis, the width of the symmetrical region is checked for the presence of two corners representing the bottom of the bounding box around the vehicle.</p><p>Once the two corners are detected, the top side of the rectangle box can be detected by searching.</p><p><img src="/images/boundingboxde.png"></p><h2><span id="visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</span></h2><p><strong>Visual saliency</strong> refers to the idea that certain parts of a scene are pre-attentively distinctive (pop-out) and create some form of immediate significant visual arousal within the early stages of the <strong>Human Visual System (HVS)</strong>. The figure below is an example.</p><p>In image analysis, an <strong>edge</strong> is a pop-out region (<strong>region of saliency</strong>) since the edge is more visually significant than the other parts of the image.</p><p><img src="/images/vsexamples.png"></p><p>The salient points are literally the points on the object which are almost unique. These points maximize the discrimination between objects. The visual saliency is defined in terms of <strong>local signal complexity</strong>.</p><p><strong>Shannon entropy</strong> of local attributes (called <strong>local entropy</strong>) is <span class="math display">\[H_{D,Rx}(x)=-\sum_{i\in D}P_{D,Rx}(x,d_i)\log_2P_{D,Rx}(x,d_i)\]</span> where <span class="math inline">\(x\)</span> is point location, <span class="math inline">\(Rx\)</span> is local neighborhood at <span class="math inline">\(x\)</span>, <span class="math inline">\(D\)</span> is descriptor (e.g. intensity), and <span class="math inline">\(P_{D,Rx}(x,d_i)\)</span> is histogram value at <span class="math inline">\(x\)</span>.</p><p><img src="/images/entropylsakdjad.jpg"></p><p>Below are sample frames from the processed sequences using a <strong>fixed scale</strong> based on local entropy. Red square boxes represent the most salient icons or parts of the image. The size of the local window or scale and threshold used were selected manually to give the most satisfactory results.</p><p><img src="/images/saliegsdas.png"></p><ul><li>Problem: the scale is fixed and global. For example, the scale is inappropriate for the pedestrians and the road markings in DT sequence.</li><li>Problem: Small salient regions are not picked up. Highly textured regions, e.g., large intensity variation regions, are picked up. For example, trees and bushes in Vicky sequence.</li></ul><p>Therefore, scale is an important and implicit part of the saliency detection problem.</p><p><strong>Scale selection for salient region detection</strong></p><p>Scale is selected based on the scale-space behavior of the saliency of a given feature.</p><p>For each pixel position <span class="math inline">\(x\)</span></p><ul><li><p>For each scale <span class="math inline">\(s\)</span> inside a range between <span class="math inline">\(s_\min\)</span> and <span class="math inline">\(s_\max\)</span> :</p><ul><li><p>Measure the local descriptor values (e.g.,intensity values) within a window of scale <span class="math inline">\(s\)</span>.</p></li><li><p>Estimate the local probability density function (PDF) from this (e.g. using histogram).</p></li><li><p>Calculate the local entropy <span class="math inline">\(H_D\)</span> <span class="math display">\[H_{D}(s,x)=-\sum_{i\in D}P_{D}(s,x,d_i)\log_2P_{D}(s,x,d_i)\]</span></p></li></ul></li><li><p>Select scales for which the entropy is peaked <span class="math display">\[s:\frac{\partial^2H_D(s,x)}{\partial s^2}&lt;0\]</span></p></li><li><p>Detection performance can be further improved if change of histogram is considered.</p></li></ul><p><img src="/images/salenscaleg.png"></p><p><strong>Vehicle Detection by using AdaBoost</strong></p><p>Vehicles can be detected by using <a href="https://www.52coding.com.cn/2018/12/06/RS%20-%20Recognizing%20Faces/#adaboost">AdaBoost</a>.</p><p><img src="/images/vehildabboo.png"></p><p>By using the AdaBoost, vehicles in their lateral view can be detected in real time.</p><p><strong>Vehicle Recognition</strong></p><p>After vehicle detection, the vehicle can be recognition by using PCA and classification methods, e.g., k-NN or Bayesian methods.</p><h2><span id="application-examples">Application Examples</span></h2><p><strong>Vehicle counting in traffic surveillance</strong></p><p><img src="/images/survelleg.png"></p><p><strong>Traffic jam detection and alarming</strong></p><p><img src="/images/trafficjamsdeg.png"></p><p><strong>Abnormal vehicle behavior detection</strong></p><p><img src="/images/abnormaldetec.png"></p><p><strong>Target tracking in night</strong></p><p><img src="/images/targetrackinni.png"></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Canny </tag>
            
            <tag> visual saliency </tag>
            
            <tag> lane detection </tag>
            
            <tag> vehicle detection </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing License Plates</title>
      <link href="/2018/12/08/RS%20-%20Recognizing%20License%20Plates/"/>
      <url>/2018/12/08/RS%20-%20Recognizing%20License%20Plates/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 5. è¯†åˆ«ç³»ç»Ÿå¤ä¹ ç¬”è®°ã€‚</p><p><a href="http://www.licenseplaterecognition.com/" target="_blank" rel="noopener">License Plate Recognition</a> is an image-processing technology which is used to identify vehicles by their license plates. This technology is used in various security and traffic applications, such as the access-control system, toll payment, parking fee payment, etc.</p><a id="more"></a><p>A number of license plate recognition units are installed in different locations and the passing vehicle plate numbers are matched between the points. The average speed and travel time between these points can be calculated and presented in order to monitor traffic loads. Additionally, the average speed may be used to issue a speeding ticket.</p><!-- toc --><ul><li><a href="#automatic-vehicle-identification-system">Automatic Vehicle Identification System</a></li><li><a href="#license-plate-detection">License Plate Detection</a><ul><li><a href="#global-search">Global Search</a></li><li><a href="#partial-image-analysis">Partial Image Analysis</a></li><li><a href="#sliding-concentric-windows">Sliding Concentric Windows</a></li><li><a href="#adaboost">Adaboost</a></li></ul></li><li><a href="#character-segmentation">Character Segmentation</a></li><li><a href="#character-recognition">Character Recognition</a></li></ul><!-- tocstop --><h2><span id="automatic-vehicle-identification-system">Automatic Vehicle Identification System</span></h2><p>The installation and responses of sensors help to frame a front-view/rear-view of a passing vehicle. <strong>Infra-red sensors</strong> are used for vehicle sensing.</p><p><img src="/images/infredsens.png"></p><p><strong>Anisotropic magneto-resistive (AMR) sensors</strong> for automated vehicle sensing.</p><p><img src="/images/amrsense.png"></p><p><strong>License plate recognition</strong> is generally composed of three steps.</p><ol type="1"><li>Location of the license plate region (License Plate Detection)</li><li>Segmentation of the plate characters (Character Segmentation)</li><li>Recognition of the plate characters (Character Recognition)</li></ol><p>The license plate recognition should operate fast enough to make sure that the system does not miss a single object of interest that moves through the scene.</p><p>With the growth of the computer processing power, the latest developments operate within less than 50ms for plate detection and recognition. It enables the processing of more than 20 frames per second for videos.</p><h2><span id="license-plate-detection">License Plate Detection</span></h2><p>There are several methods for detecting license plate in a vehicle image.</p><ul><li>Global search [Comelli-TVT-95$]$</li><li>Partial image analysis (vertical edge density)[Anagnostopoulos-TITS-08$]$</li><li>Sliding concentric windows [Anagnostopoulos-TITS-06$]$</li><li>AdaBoost [Dlagnekov-04$]$</li></ul><h3><span id="global-search">Global Search</span></h3><p>Comelli et al. presented a system called RITA. RITA can recognize automatically the characters written on the license plate placed on the rear-side of motor vehicles. The goal is to read only the Italian license plates and reject all the others. It is assumed that a Italian license plate is rectangular and the plate contains black characters over a white background.</p><p>The license plate detection algorithm is a <strong>global searching</strong> method because the algorithm picks within the vehicle image globally the area presenting the maximum local contrast based on <strong>gradient analysis</strong>. The picked area possibly corresponds to the rectangle that contains the license plate.</p><p>The algorithm selects the area that presents the <strong>maximum local contrast</strong> that (possibly) corresponds to the rectangle that contains the license plate.</p><p><img src="/images/globalsearch.png"></p><h3><span id="partial-image-analysis">Partial Image Analysis</span></h3><p>The vehicle image can be filtered to extract <strong>vertical edges</strong> and scanned with N-row distance. The number of the existing edges along each scan line is recorded.</p><p>If the number of the edges is greater than a threshold value, the presence of a plate can be assumed.</p><p><img src="/images/piasdsa.png"></p><p>Specifically, if the plate is not found in the first scanning processing, then the algorithm is repeated, reducing the threshold for counting edges or adjusting the threshold for finding vertical edges.</p><h3><span id="sliding-concentric-windows">Sliding Concentric Windows</span></h3><p>An adaptive image segmentation technique, called <strong>sliding concentric windows</strong> (SCW), was proposed for license plate detection. The SCW method was developed to describe the local irregularity in the vehicle image.</p><p>The method uses image statistics such as the standard deviation and the mean for finding possible plate locations.</p><p><img src="/images/slidingwc.png"></p><p>In two concentric windows A and B of different sizes (<span class="math inline">\(2X_1\times 2Y_1\)</span> and <span class="math inline">\(2X_2\times2Y_2\)</span> respectively), which scan the vehicle image from left to right and from top to bottom, the mean or the standard deviation is calculated.</p><p>If the ratio of the statistical measurements in the two windows exceeds a threshold set by the user, then the central pixel of the concentric windows is considered to belong to a license plate. <span class="math display">\[I_{output}=\begin{cases}0 &amp; \text{if }\frac{M_B}{M_A}\leq T,\\1 &amp; \text{if }\frac{M_B}{M_A}&gt; T\end{cases}\]</span> where <span class="math inline">\(M\)</span> is the statistical measurement, eigher mean or standard devation.</p><p>The result is a binary image <span class="math inline">\(I_{output}\)</span>, which eliminates all the redundant regions from the original vehicle image.</p><p>The result binary image is used as a <strong>mask for highlighting the license plate</strong> by computing the product between the binary mask and the input vehicle image. The license plate can then be found in the highlighted image based on the binary mask.</p><p><img src="/images/scwimg.png"></p><h3><span id="adaboost">Adaboost</span></h3><p>Adaptive boosting (AdaBoost) was used in conjunction with the rectangle features for training a strong classifier based on weak classifiers.</p><p>For detecting license plates, a total of 100 rectangle features can be applied to sub-regions sized 45(columns) Ã— 15(rows) pixels being scanned as the expected license plate areas in the original vehicle image.</p><p><img src="/images/recpladaboo.png"></p><p>Within the 100 rectangle features for detection, there are 37 variance based features, 40 x-derivative features, 18 y-derivative features, and 5 mean pixel intensity features.</p><p><img src="/images/plrecoadaboo.png"></p><p>When sliding the search window across the vehicle image to be analyzed, several matches can be found. Clustering method can be used to group detected windows that are close to each other and <strong>use the mean window as the detected location</strong>.</p><h2><span id="character-segmentation">Character Segmentation</span></h2><p>In most systems with a subsequent recognition module, the vertical resolution of the plate vary from 20 to 40 pixels. Prior to character recognition, the detected license plates are enhanced for <strong>improving plate image quality</strong>, e.g., image normalization and histogram equalization.</p><p><img src="/images/characseg.png"></p><p>Given the enhanced detected license plate image, the goal is to <strong>segment each character</strong> in the image. A global threshold can be found to segment the detected license plate. <a href="http://en.wikipedia.org/wiki/Otsu&#39;s_method" target="_blank" rel="noopener">Otsu's method</a> is one of widely used methods for image binarization.</p><p><strong>Otsu's method</strong></p><p>The method is designed for finding optimum global threshold for image binarization and is optimum in the sense that it maximizes the between-class variance.</p><p>There are six steps.</p><ol type="1"><li><p>Compute the normalized histogram of the input image. Denote the components of histogram by <span class="math display">\[p_i=\frac{n_i}{MN}, i=0, 1, ..., L-1\]</span> where <span class="math inline">\(L\)</span> is the number of gray levels; <span class="math inline">\(n_i\)</span> is the number of pixels with intensity <span class="math inline">\(i\)</span>; <span class="math inline">\(M\)</span> is the number of rows; and <span class="math inline">\(N\)</span> is the number of columns.</p></li><li><p>Compute the cumulative sums (the probability that a pixel is assigned to class <span class="math inline">\(C_1\)</span>) <span class="math display">\[P_1(k)=\sum_{i=0}^kp_i\]</span> where <span class="math inline">\(k\)</span> is current threshold for thresholding the input image into two classes <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>.</p></li><li><p>Compute the cumulative means <span class="math display">\[m(k)=\sum_{i=0}^kip_i,\ k=0,1,...,L-1\]</span></p></li><li><p>Compute the global intensity mean <span class="math display">\[m_G=\sum_{i=0}^{L-1}ip_i\]</span> where <span class="math inline">\(L\)</span> is the number of gray levels.</p></li><li><p>Compute the between-class variance <span class="math display">\[\sigma^2_B(k)=\frac{[m_GP_1(k)-m(k)]^2}{P_1(k)[1-P_1(k)]},\ k=0, 1, ..., L-1\]</span></p></li><li><p>Obtain the Otsu threshold, <span class="math inline">\(k^\ast\)</span>, as the value for <span class="math inline">\(k\)</span> for which the value of <strong>between-class variance is maximum</strong>. If the maximum is not unique, obtain <span class="math inline">\(k^\ast\)</span> by averaging the values of <span class="math inline">\(k\)</span> corresponding to the various maxima detected. <span class="math display">\[\sigma^2_B(k^\ast)=\max_{0\leq k\leq L-2}\sigma^2_B(k)\]</span></p></li></ol><p><img src="/images/otsuresukt.png"></p><p>Global thresholding on the entire image may not always produce useful results due to uneven lighting environment.</p><p><img src="/images/charseg.png"></p><p>Characters can be extracted from the license plate image. Each character can then be segmented by using the thresholding method. Instead of dividing the image into regular blocks, the shape (size) of each block is defined adaptively for each character.</p><p><img src="/images/characsegggg.png"></p><p>Projections of binary edge images are performed. Rows of strings are separated based on the horizontal pixel accumulation. Same for columns of characters.</p><p>After the blocks for characters are defined adaptively, the Otsu's method is applied for each blocks adaptively.</p><p><strong>Maximally stable extremal regions</strong></p><p>Characters can be extracted and segmented by thresholding the image with a variable brightness threshold, and using the enumeration of extremal regions which are stable for a large range of the threshold <span class="math inline">\(T\)</span>.</p><p>Extremal regions are connected components of an image binarized at certain threshold. When the threshold <span class="math inline">\(T\)</span> is increasing/decreasing, the behavior of the extremal regions is used for character classification and segmentation.</p><p><a href="http://en.wikipedia.org/wiki/Maximally_stable_extremal_regions" target="_blank" rel="noopener">Maximally stable extremal regions (MSERs)</a> are usually of arbitrary shape. The MSER detector is stable and invariant to affine transformations, which is useful for handling viewpoint changes.</p><p><img src="/images/msersss.png"></p><p><img src="/images/mseralgo.png"></p><p><img src="/images/mserrrr.png"></p><p><img src="/images/mserapp.png"></p><h2><span id="character-recognition">Character Recognition</span></h2><p>After the characters are segmented, the segmented characters will be matched against a set of pre-defined characters, e.g. ten numerals (zero to nine), alphabets, etc.</p><p>The pre-defined characters usually have single font, fixed character size, and are not rotated heavily. Therefore, pattern/template matching is a suitable technique for character recognition. Templates can be generated in advance for the matching tasks.</p><p><img src="/images/charrecogpatt.png"></p><p>The matching process can be done by computing the <strong>normalized cross-correlation</strong> values for all the translational shifts of each character template over the character block (sub-image).</p><p>The normalized cross-correlation is defined as <span class="math display">\[C_{fg}=\frac{\sum_{m=1}^M\sum_{n=1}^N(f(i,j)-\bar{f})(g(i,j)-\bar{g})}{\sqrt{\sum_{m=1}^M\sum_{n=1}^N(f(i,j)-\bar{f})^2(g(i,j)-\bar{g})^2}}\]</span> where <span class="math inline">\(g\)</span> is shifted template and <span class="math inline">\(f\)</span> is character block.</p><p>More advanced techniques, e.g. <a href="http://en.wikipedia.org/wiki/Shape_context" target="_blank" rel="noopener">shape context</a>, can be used for character recognition. ([Belongie-02, Treiber-10])</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Adaboost </tag>
            
            <tag> Otsu </tag>
            
            <tag> MSER </tag>
            
            <tag> sliding concentric windows </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Fingerprints</title>
      <link href="/2018/12/07/RS%20-%20Recognizing%20Fingerprints/"/>
      <url>/2018/12/07/RS%20-%20Recognizing%20Fingerprints/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 4. è¯†åˆ«ç³»ç»Ÿå¤ä¹ ç¬”è®°ã€‚</p><!-- toc --><ul><li><a href="#fingerprint-image-acquisition-systems">Fingerprint image acquisition systems</a></li><li><a href="#minutiae">Minutiae</a></li><li><a href="#fingerprint-enhancement">Fingerprint Enhancement</a><ul><li><a href="#normalization">Normalization</a></li><li><a href="#orientation-image-estimation">Orientation Image Estimation</a></li><li><a href="#ridge-frequency-estimation">Ridge Frequency Estimation</a></li><li><a href="#region-mask-estimation">Region mask estimation</a></li><li><a href="#gabor-filter">Gabor Filter*</a></li></ul></li><li><a href="#fingerprint-matching">Fingerprint Matching</a></li><li><a href="#fingercode">FingerCode</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="fingerprint-image-acquisition-systems">Fingerprint image acquisition systems</span></h2><p><a href="http://en.wikipedia.org/wiki/Fingerprint" target="_blank" rel="noopener">Fingerprint</a> matching (recognition) is the most popular biometric technique used in automatic personal identification. The main reason for the popularity of fingerprints as a form of identification is that the fingerprint of a person is unique and remains invariant with his or her age.</p><p>There are three kinds of sensing devices typically: <strong>optical sensors</strong>, <strong>solid-state sensors</strong> and <strong>ultrasound sensors</strong>.</p><p><strong>Optical sensors</strong></p><p>The finger touches the top side of a glass prism. The left side of the prism is illustrated through a diffused light. The light entering the prism is reflected at the valleys, and absorbed at the ridges. The lack of reflection allows the ridges to be discriminated from the valleys. The light rays exit from the right side of the prism and are focused through a lens onto an image sensor.</p><p><img src="/images/ridgeandvall.png"></p><p><strong>Solid-state sensors</strong></p><p>All silicon-based sensors consist of an array of pixels, each pixel being a tiny sensor itself. The user directly touches the surface of the silicon. The physical information is converted into <strong>electrical signals</strong> by using the capacitive sensor (other kinds of sensor can also be used, e.g., thermal, electric field and piezoelectric).</p><p>The capacitive sensor is a 2D array of micro-capacitor plates embedded in a chip. The other plate of each micro-capacitor is the finger skin itself.</p><p><img src="/images/ssdfinger.png"></p><p>Small electrical charges are created between the surface of the finger and each of the silicon plates when a finger is placed on the chip. The magnitude of these electrical charges depends on the distance between the fingerprint surface and the capacitance plates.</p><p><strong>Ultrasound sensors</strong></p><p>An ultrasound sensor is based on sending acoustic signals toward the fingertip and capturing the echo signal. The echo signal is used to compute the range image of the fingerprint and, subsequently, the ridge structure itself.</p><p><img src="/images/ultrasound.png"></p><h2><span id="minutiae">Minutiae</span></h2><p>An <strong>automatic fingerprint identification system</strong> (AFIS) consists of various processing stages.</p><p><img src="/images/afis.png"></p><p>In AFIS, the high-level structural features (<strong>ridges and valleys</strong>) are extracted from the fingerprint image for the purpose of representation and matching. The ridges and valleys in a fingerprint alternate, flowing in a local constant direction.</p><p><img src="/images/ridandval.png"></p><p>The ridges (or the valleys) exhibit anomalies of various kinds, such as ridge bifurcations, ridge endings, short ridges, and ridge crossovers. These features are called <a href="http://en.wikipedia.org/wiki/Minutiae" target="_blank" rel="noopener">minutiae</a>.</p><p>In a good quality rolled fingerprint image, there are about 70 to 80 minutia points and in a latent fingerprint the number of minutiae is much less (approximately 20 to 30 minutia points). Commercially available fingerprint identification systems typically use <strong>ridge bifurcations</strong> and <strong>ridge endings</strong> as features.</p><p><img src="/images/bifandending.png"></p><ul><li>A ridge ending is defined as the point where a ridge ends abruptly.</li><li>A ridge bifurcation is defined as the point where a ridge diverges into branch ridges.</li></ul><p>A critical step in fingerprint matching is to automatically and reliably <strong>extract minutiae</strong> from the input fingerprint images, which is a difficult task.</p><p><img src="/images/bifandend2.png"></p><h2><span id="fingerprint-enhancement">Fingerprint Enhancement</span></h2><p>Fingerprint images can be of very poor quality. An enhancement algorithm which can improve the clarity of the ridge structure is therefore necessary.</p><p>The flowchart of the fingerprint enhancement algorithm is shown below.</p><p><img src="/images/imgnorflow.png"></p><h3><span id="normalization">Normalization</span></h3><p>A gray-level fingerprint image <span class="math inline">\(I\)</span> is defined as an <span class="math inline">\(N \times N\)</span> matrix. At the <span class="math inline">\(i\)</span> th row and <span class="math inline">\(j\)</span> th column, the intensity of the pixel is <span class="math inline">\(I(i, j)\)</span>. It is assumed that the fingerprint images are scanned at a resolution of 500 dots per inch (dpi), which is the resolution recommended by FBI.</p><p>The mean and variance of a gray-level fingerprint image are defined as</p><p><img src="/images/imgnorma.png"></p><p>An input fingerprint image is normalized so that it has a pre-specified mean <span class="math inline">\(M_0\)</span> and variance <span class="math inline">\(\text{VAR}_0\)</span>.</p><p>The normalized image <span class="math inline">\(G(i,j)\)</span> is defined as <span class="math display">\[G(i,j)=\begin{cases}M_0+\sqrt{\frac{VAR_0(I(i,j)-M)^2}{VAR}} &amp;\text{if }I(i,j)&gt;M\\M_0-\sqrt{\frac{VAR_0(I(i,j)-M)^2}{VAR}}&amp;\text{otherwise}\\\end{cases}\]</span> <img src="/images/imgnor2.png"></p><h3><span id="orientation-image-estimation">Orientation Image Estimation</span></h3><p>The orientation image (field) is estimated from the normalized input fingerprint image. By viewing a fingerprint image as an oriented image, a <strong>least-mean-square orientation estimation</strong> algorithm is used to estimate the local orientation.</p><p>The main steps are as follows.</p><p>[1] Divide the normalized image <span class="math inline">\(G\)</span> into blocks of size <span class="math inline">\(w \times w\)</span>.</p><p>[2] For each block, compute the gradients <span class="math inline">\(I_x\)</span> and <span class="math inline">\(I_y\)</span> at each pixel <span class="math inline">\((i , j)\)</span>.</p><p>[3] Estimate the local orientation of each block centered at pixel <span class="math inline">\((i, j)\)</span> using the following equations. <span class="math display">\[\theta(i,j)=90^o+\frac{1}{2}\text{atan2}\left(\frac{V_1(i,j)}{V_2(i,j)}\right)\]</span> where <span class="math display">\[V_1(i,j)=\sum_{u=i-\frac{w}2}^{i+\frac{w}2}\sum_{v=j-\frac{w}2}^{j+\frac{w}2}2I_x(u,v)I_y(i,v)\\V_2(i,j)=\sum_{u=i-\frac{w}2}^{i+\frac{w}2}\sum_{v=j-\frac{w}2}^{j+\frac{w}2}(I_x(u,v)^2-I_y(u,v)^2)\\-180^oâ‰¤\text{atan2}(x)â‰¤180^o\]</span> [4] Due to the presence of noise, corrupted ridge and valley structures, minutiae, etc. in the input image, the estimated local ridge orientation may not always be correct. The local orientation image can be smoothed by using the low-pass smoothing filter and the concept of continuous vector field.</p><p><img src="/images/orienesti.png"></p><h3><span id="ridge-frequency-estimation">Ridge Frequency Estimation</span></h3><p>The gray levels along ridges and valleys can be modeled as a sinusoidal-shaped wave along a direction normal to the local ridge orientation.</p><p><img src="/images/ridgefreq.jpg"></p><p>Let <span class="math inline">\(G\)</span> be the normalized image and <span class="math inline">\(O\)</span> be the orientation image (field). For estimating the ridge frequency <span class="math inline">\(Î©\)</span> image,</p><ul><li><p>Step 1: divide <span class="math inline">\(G\)</span> into blocks of size <span class="math inline">\(w \times w\)</span>.</p></li><li><p>Step 2: for each block centered at pixel <span class="math inline">\((i, j)\)</span>, compute an oriented window of size <span class="math inline">\(w \times l\)</span> that is defined in the ridge coordinate system <span class="math inline">\((k, d)\)</span>. <img src="/images/ridgesys.png"></p></li><li><p>Step 3: for each block centered at pixel <span class="math inline">\((i, j)\)</span>, compute the x-signature, <span class="math inline">\(X[0], X[1], ..., X[l-1]\)</span>, of the ridges and valleys within the oriented window, where <span class="math display">\[X[k]=\frac{1}w\sum_{d=0}^{w-1}G(u,v)\\u=i+(d-\frac{w}2)\cos O(i,j)+(k+\frac{l}2)\sin O(i,j)\\v=i+(d-\frac{w}2)\sin O(i,j)+(\frac{l}2-k)\cos O(i,j)\]</span> <img src="/images/w2blabla.png"> <img src="/images/orientationdsa.png"></p></li></ul><p>The x-signature forms a discrete sinusoidal-shape wave, which has the same frequency as that of the ridges and valleys in the oriented window. Therefore, the <strong>frequency of ridges and valleys can be estimated from the x-signature</strong>.</p><p>Let <span class="math inline">\(T(i, j)\)</span> be the average number of pixels between two consecutive peaks in the x-signature, then the ridge frequency <span class="math inline">\(Î©(i, j)\)</span> is computed as <span class="math display">\[\Omega(i,j)=\frac{1}{T(i,j)}\]</span></p><h3><span id="region-mask-estimation">Region mask estimation</span></h3><p>A pixel (or a block) in an input fingerprint image can be either in a recoverable region or an unrecoverable region. Classification of pixels into recoverable and unrecoverable categories can be performed based on the assessment of the shape of the wave formed by the local ridges and valleys.</p><p><img src="/images/imgmaskest.png"></p><p>Three features are used to characterize the sinusoidal-shaped wave: amplitude, frequency, and variance.</p><p><img src="/images/imgmaskest2.png"></p><p>Typical fingerprint images where both recoverable and unrecoverable regions were manually labeled can be selected for region mask estimation. The above three features can be computed for each image.</p><p>Using the k-NN and clustering algorithms, each <span class="math inline">\(w \times w\)</span> block in an input fingerprint image can be classified into a recoverable or an unrecoverable block.</p><h3><span id="gabor-filter">Gabor Filter*</span></h3><p>The configurations of parallel ridges and valleys with well-defined frequency and orientation in a fingerprint image provide useful information which helps in removing undesired noise.</p><p>A special (bandpass) filter, namely <strong>Gabor filter</strong>, that is tuned to the corresponding frequency and orientation can efficiently remove the undesired noise and preserve the true ridge and valley structures.</p><p>Gabor filters have both frequency-selective and orientation-selective properties and are used for removing noise and preserving true ridge or valley structures.</p><p>The even-symmetric Gabor filter has the following general form:</p><p><img src="/images/gaborfilter.png"></p><p>The frequency of the filter <span class="math inline">\(f\)</span> is completely determined by the local ridge frequency and the Gabor filter orientation is determined by the local ridge orientation.</p><p><img src="/images/gabororien.png"></p><p>The ridge pixels are assigned a value '1' (white) and the remaining pixels are assigned a value '0' (black) in the resulting binary ridge image.</p><p><img src="/images/imgseg.png"></p><p>Once the ridges are located, <strong>directional smoothing</strong> is applied to smooth the ridges. A 3Ã—7 mask is placed along the orientation field for each window. The mask containing all '1's enables us to count the number of '1's in the mask area.If the count of '1's is more than 25% of the total number of pixels, the ridge point is retained.</p><p><strong>Extracting minutiae</strong></p><p>Locating minutia points in the thinned image is relatively easy.</p><p>A count of the number of 'on' neighbors at a point of interest in a <span class="math inline">\(3\times 3\)</span> window is sufficient for this purpose.</p><ul><li>A ridge end point has only neighbor in the window.</li><li>A ridge bifurcation has at least three neighbors.</li></ul><p>Some post-processing can be performed to further improve detection quality.</p><p><img src="/images/endandbif3.jpg"></p><p><img src="/images/minuextra.png"></p><h2><span id="fingerprint-matching">Fingerprint Matching</span></h2><p>Matching a query fingerprint and a database fingerprint is equivalent to matching their minutia sets. Each database fingerprint minutia, <span class="math inline">\(p\)</span>, is examined to determine whether there is a corresponding query fingerprint minutia, <span class="math inline">\(q\)</span>.</p><p>There are three steps.</p><ol type="1"><li>Registration</li><li>Minutia paring</li><li>Matching score computation</li></ol><p><strong>Registration via Hough Transform</strong></p><p>The input to the registration algorithm consists of two sets of minutia points <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>. <span class="math inline">\(|P|\)</span> and <span class="math inline">\(|Q|\)</span> represent the sizes of point sets <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> respectively. <span class="math display">\[P=\{(p_x^1,p_y^1,\alpha^1),...,(p_x^{|P|},p_y^{|P|},\alpha^{|P|})\}\\Q=\{(q_x^1,q_y^1,\beta^1),...,(q_x^{|Q|},q_y^{|Q|},\beta^{|Q|})\}\]</span> Each minutia has three components: x-coordinate, y-coordinate and orientation of the minutia. Each minutia in <span class="math inline">\(P\)</span> is <strong>rotated, scaled and translated</strong> for matching against a minutia in <span class="math inline">\(Q\)</span>.</p><p>The usual <strong>Hough transform</strong> for line detection can be generalized for point matching.</p><p><img src="/images/regishoughtra.png"></p><p>The transform has maximum value of <span class="math inline">\(A\)</span> means that it can match as much points as possible.</p><p><img src="/images/imgregriscomp.png"></p><p><strong>Minutia pairing and score computation</strong></p><p>After minutia registration, the minutiae need to be paired. Two minutiae are said to be paired or matched if their components <span class="math inline">\((x, y,Î¸)\)</span> are equal with some tolerance after registration.</p><p><img src="/images/minutiamatch.png"></p><p>The matching algorithm is based on finding the number of paired minutiae between each database fingerprint and the query fingerprint.</p><p>In order to reduce the amount of computation, the matching algorithm takes into account only those minutiae that fall within a common bounding box. The common bounding box is the intersection of the bounding box for query and reference (database) fingerprints. Once the count of matching minutiae is obtained, a matching score is computed. The matching score is used for deciding the degree of match. Finally, a set of top ten scoring reference fingerprints is obtained as a result of matching.</p><h2><span id="fingercode">FingerCode</span></h2><p><em>FingerCode</em> is a new representation for the fingerprints which yields a <strong>relatively short, fixed length code</strong> suitable for matching as well as storage on a smartcard.</p><p>The matching reduces to finding the <strong>Euclidean distance</strong> between these <em>FingerCodes</em> and hence the matching is very fast and the representation is amenable to indexing.</p><p>The FingerCode partitions the region of interest of the given fingerprint image with respect to a reference point. A feature vector is composed of an ordered enumeration of features extracted from the information contained in each sector specified by the tessellation.</p><p><img src="/images/fingercode1.png"></p><p>The feature elements capture the local information by using the <strong>Gabor filterbank</strong>. The ordered enumeration of the tessellation captures the <strong>invariant global relationships</strong> among the local patterns.</p><p>These features capture both the global pattern of ridges and valleys and the local characteristics. Matching is based on the Euclidean distance between the FingerCodes.</p><p>There are four steps for extracting the FingerCode.</p><ol type="1"><li>Determining the reference point for the fingerprint image.</li><li>Partitioning the region around the reference point.</li><li>Filtering the region of interest in eight different directions using a bank of Gabor filters.</li><li>Computing the <strong>average absolute deviation</strong> (AAD) from the mean of gray values in individual sectors in filtered images to define the <em>FingerCode</em> (the feature vector) for matching.</li></ol><p><strong>Determining the reference point</strong></p><p><img src="/images/fingercode2.png"></p><p>Given an input fingerprint image, there are seven steps for finding the reference point.</p><ol type="1"><li><p>Estimate the orientation field <span class="math inline">\(O\)</span> using a window size of <span class="math inline">\(w\times w\)</span>.</p></li><li><p>Smooth the orientation field.</p></li><li><p>Compute the sine component <span class="math inline">\(E\)</span> of the orientation field <span class="math inline">\(O\)</span>.<br><span class="math display">\[E(i,j)=\sin O(i,j)\]</span></p></li><li><p>Initialize <span class="math inline">\(A\)</span>, a label image used to indicate the reference point.</p></li><li><p>For each pixel <span class="math inline">\(E(i, j)\)</span>, integrate pixel intensities in regions <span class="math inline">\(R_I\)</span> and <span class="math inline">\(R_{II}\)</span>, and assign the corresponding pixels in <span class="math inline">\(A\)</span> according to the value of their difference. <span class="math display">\[A(i,j)=\sum_{R_I}E(i,j)-\sum_{R_{II}}E(i,j)\]</span> <img src="/images/fingercode4.png"></p></li><li><p>Find the maximum value in <span class="math inline">\(A\)</span> and assign its coordinate to the reference point.</p></li><li><p>Repeat steps 1-6 by using a window size <span class="math inline">\(w&#39;\times w&#39;\)</span>, where <span class="math inline">\(w&#39; &lt; w\)</span>, and restrict the search for the reference point in step 6 in a local neighborhood of the detected reference point.</p></li></ol><p>The geometry of regions <span class="math inline">\(R_I\)</span> and <span class="math inline">\(R_{II}\)</span> is designed to capture the maximum curvature in concave ridges.</p><p><img src="/images/fingercode3.png"></p><p><strong>Partitioning the region around the reference point</strong></p><p>Given the detected reference point, the input fingerprint image is partitioned into 80 sectors.</p><p><img src="/images/fingercode5.png"></p><p><strong>Filtering the region of interest</strong></p><p>A minutia point can be viewed as an anomaly in locally parallel ridges and it is the information that is captured by using the Gabor filters.</p><p>Before filtering the fingerprint image, <strong>image normalization</strong> is performed separately for each sector with <span class="math inline">\(M_0\)</span> and <span class="math inline">\(VAR_0\)</span>.</p><p>An even symmetric Gabor filter is given <a href="#gabor-filter*">the Gabor filer setction</a>. The filter frequency <span class="math inline">\(f\)</span> can be set to the average ridge frequency. The average ridge frequency is the reciprocal of the average inter-ridge distance, which is around 10 pixels in a 500 dpi fingerprint image. Eight different values (<span class="math inline">\(0^o\)</span>, <span class="math inline">\(22.5^o\)</span>, <span class="math inline">\(45^o\)</span>, <span class="math inline">\(67.5^o\)</span>, <span class="math inline">\(90^o\)</span>, <span class="math inline">\(112.5^o\)</span>, <span class="math inline">\(135^o\)</span> and <span class="math inline">\(157.5^o\)</span>) are used for the direction Î¸ with respect to the x-axis.</p><p>A fingerprint convolved with a <span class="math inline">\(0^o\)</span>-oriented filter accentuates those ridges which are parallel to the x-axis and smoothes the ridges in the other directions. These eight directional-sensitive filters capture <strong>most of the global ridge directionality information</strong> as well as the <strong>local ridge characteristics</strong> present in a fingerprint.</p><p><img src="/images/fingercode6.png"></p><p><strong>Compute AAD</strong></p><p>Let <span class="math inline">\(F_{iÎ¸}(x, y)\)</span> be the Î¸-direction filtered image for sector <span class="math inline">\(S_i\)</span>. The feature value <span class="math inline">\(V_{iÎ¸}\)</span> is the average absolute deviation (AAD) from the mean which is defined as <span class="math display">\[V_{i\theta}=\frac{1}{n_i}\sum_{(x,y)\in S_i}|F_{i\theta}(x,y)-P_{i\theta}|\]</span> where <span class="math inline">\(P_{i\theta}=\frac{1}{n_i}\sum_{(x,y)\in S_i}F_{i\theta}(x,y)\)</span>; <span class="math inline">\(n_i\)</span> is the number of pixels in <span class="math inline">\(S_i\)</span>.</p><p><img src="/images/fingercode7.png"></p><p>The average absolute deviation of each sector in each of the eight filtered images defines the components of the feature vector. Fingerprint matching is based on finding the <strong>Euclidean distance</strong> between the corresponding <em>FingerCodes</em>.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> fingerprints </tag>
            
            <tag> fingercode </tag>
            
            <tag> hough transform </tag>
            
            <tag> minutiae </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Faces</title>
      <link href="/2018/12/06/RS%20-%20Recognizing%20Faces/"/>
      <url>/2018/12/06/RS%20-%20Recognizing%20Faces/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 3. è¯†åˆ«ç³»ç»Ÿå¤ä¹ ç¬”è®°ã€‚</p><!-- toc --><ul><li><a href="#histogram-equalization">Histogram Equalization</a></li><li><a href="#image-pyramid-and-neural-networks">Image Pyramid and Neural Networks</a></li><li><a href="#integral-image">Integral Image</a></li><li><a href="#adaboost">Adaboost</a></li><li><a href="#face-recognition-pca">Face Recognition (PCA)</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="histogram-equalization">Histogram Equalization</span></h2><p><a href="http://en.wikipedia.org/wiki/Face_detection" target="_blank" rel="noopener">Face detection</a> is the first step in automated face recognition. Its reliability has a major influence on the performance and usability of the entire face recognition system.</p><p>Due to lighting or shadow, intensity can vary significantly in an image. Normalization of pixel intensity helps correct variations in imaging parameters in cameras as well as changes in illumination conditions. One widely used technique is <a href="http://en.wikipedia.org/wiki/Histogram_equalization" target="_blank" rel="noopener">histogram equalization</a>, which is based on image histogram. It helps reduce extreme illumination.</p><p><strong>Image histogram</strong></p><p>It is assumed that there is a digital image with <span class="math inline">\(L\)</span> gray levels <span class="math inline">\(r_k\)</span>. The probability of occurrence of gray level <span class="math inline">\(r_k\)</span> is given by <span class="math display">\[p_r(r_k)=\frac{n_k}{N}\]</span> where <span class="math inline">\(n_k\)</span> is number of pixels with gray level <span class="math inline">\(r_k\)</span>; <span class="math inline">\(N\)</span> is total number of pixels in an image; <span class="math inline">\(k = 0,1,2,...,L-1\)</span>.</p><p><img src="/images/imagehis.png"></p><p>We want an image with equally many pixels at every gray level, or the output intensity approx follows <strong>uniform distribution</strong>.</p><p>That is, a flat histogram, where each gray level, <span class="math inline">\(r_k\)</span>, appears equal number of times, i.e., <span class="math inline">\(N/L\)</span> times.</p><p><img src="/images/imgequ.png"></p><p>Assume that variable <span class="math inline">\(r\)</span> has been normalized between <span class="math inline">\([0,1]\)</span>. The intensity transformation is <span class="math inline">\(s = T(r)\)</span>, such that</p><ul><li><span class="math inline">\(T(r)\)</span> is single-valued and non-decreasing in the interval <span class="math inline">\(0â‰¤râ‰¤1\)</span>.</li><li><span class="math inline">\(0â‰¤T(r)â‰¤1\)</span> for <span class="math inline">\(0â‰¤râ‰¤1\)</span>.</li></ul><p><strong>Histogram equalization transform</strong></p><p>The intensity transformation is the cumulative distribution function (CDF) of <span class="math inline">\(r\)</span>, which is represented by <span class="math display">\[s=T(r)=\int_0^rp_r(w)dw\]</span> The discrete implementation is given by <span class="math display">\[s_k=T(r_k)=\sum_{j=0}^k\frac{n_j}{N}=\sum_{j=0}^kp_r(r_j)\]</span> where <span class="math inline">\(s_k\)</span> is the <strong>output intensity</strong>; <span class="math inline">\(r_k\)</span> is the input intensity; <span class="math inline">\(n_j\)</span> is the number of pixels with gray level <span class="math inline">\(r_j\)</span>.</p><p>Below are some examples:</p><p><img src="/images/hisequeg.png"></p><p><img src="/images/hisequeg2.png"></p><p>Histogram equalization can significantly improve image appearance</p><ul><li>Automatic</li><li>User doesnâ€™t have to perform windowing</li></ul><p>Nice pre-processing step before face detection</p><ul><li>Account for different lighting conditions</li><li>Account for different camera/device properties</li></ul><p>There are two methods for <strong>face detection</strong>:</p><ol type="1"><li>Method using image pyramid and neural networks [Rowley-Baluja-Kanade-98]</li><li>Method using integral image and AdaBoost learning [Viola-Jones-04]</li></ol><h2><span id="image-pyramid-and-neural-networks">Image Pyramid and Neural Networks</span></h2><p>With the neural networks, a classifier may be trained directly using preprocessed and normalized face and nonface training subwindows.</p><p><a href="http://www.cs.cmu.edu/~har/" target="_blank" rel="noopener">Rowley et al</a> use the preprocessed 20x20 subwindows as the input to a neural network. The final decision is made to classify the 20x20 subwindow into face and nonface. The architecture is shown below.</p><p><img src="/images/facepy.png"></p><p>Instead of upright, frontal faces, a <strong>router network</strong> can be trained to process each input window so that orientation can be estimated. Once the orientation is estimated, the input window can be prepared for detector neural network.</p><p><img src="/images/router.png"></p><p><strong>Rowley et al.</strong> proposed two neural networks, as presented in the previous slides. The first one is the router network which is trained to estimate the orientation of an assumed face in the 20x20 sub-window. The second one is the normal frontal, upright face detector. However, it only handles <strong>in-plane rotation</strong>.</p><p><strong>Huang et al.</strong> proposed a multi-view face tree structure for handling both in-plane and <strong>out-of-plane rotations</strong>. Every node corresponds to a strong classifier.</p><p><img src="/images/hung.png"></p><h2><span id="integral-image">Integral Image</span></h2><p><strong>Method using integral image and AdaBoost learning</strong></p><p>The <a href="http://en.wikipedia.org/wiki/Summed_area_table" target="_blank" rel="noopener">integral image</a> <span class="math inline">\(ii(x, y)\)</span> at location <span class="math inline">\((x, y)\)</span> contains the <strong>sum of the pixel intensity values above and to the left</strong> of the location <span class="math inline">\((x, y)\)</span>, inclusive.</p><p>The <span class="math inline">\(ii\)</span> is defined as <span class="math display">\[ii(x,y)=\sum_{x&#39;â‰¤x,y&#39;â‰¤y}i(x&#39;,y&#39;)\]</span> where <span class="math inline">\(ii(x,y)\)</span> is the integral image and <span class="math inline">\(i(x,y)\)</span> is the original input image.</p><p><img src="/images/integralimg.png"></p><p>Using the following pair of recurrences: <span class="math display">\[s(x, y)=s(x, y-1)+i(x,y)\\ii(x,y)=ii(x-1, y)+s(x,y)\]</span> where <span class="math inline">\(s(x,y)\)</span> is the cumulative row sum, <span class="math inline">\(s(x, -1) = 0\)</span>, and <span class="math inline">\(ii(-1, y)=0\)</span>, the integral image can be computed in one pass over the original image.</p><p>Using the integral image, any rectangular sum can be computed in four array references.</p><p><img src="/images/inteeg.png"></p><p><strong>Rectangle features</strong></p><p>The features for face detection are Haar-like functions. There are three kinds of features.</p><p>[1] Two-rectangle feature: The difference between the sum of the pixels within two rectangular regions.</p><p><img src="/images/recfea1.png"></p><p>[2] Three-rectangle feature: The feature is the sum within two outside rectangles subtracted from the sum in a center rectangle.</p><p><img src="/images/recfea2.png"></p><p>[3] Four-rectangle feature: The difference between diagonal pairs of rectangles.</p><p><img src="/images/recfea3.png"></p><p>The rectangle features are sensitive to the presence of edges, bars/lines, and other simple image structures in different scales and at different locations.</p><p>Given that the base resolution of the detector is 24 x 24 pixels, the exhaustive set of rectangle features is quite large, 160,000.</p><p>Given a feature set and a training set of positive and negative images, a classification function must be learned to classify a pattern into either face or non-face.</p><h2><span id="adaboost">Adaboost</span></h2><p>In this work, the classifier is designed based on the assumption that a very small number of features can be combined to form an effective classifier.</p><p>The <a href="http://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">AdaBoost</a> learning algorithm is used to boost the classification performance of a simple learning algorithm. The simple learning algorithm is applied to all rectangle features.</p><p>It does this by <strong>combining a collection of weak classification functions</strong> (weak classifiers with relatively high classification error) to form a stronger classifier. The final strong classifier takes the form of <strong>a weighted combination of weak classifiers followed by a threshold</strong>.</p><p>Weak classifier <span class="math inline">\(h_t\)</span> (each classifier compute one rectangle feature): <span class="math display">\[h_t(\vec{x})=\begin{cases}1\ \text{if }\vec{x}\text{ represents a face image }(f_t(\vec{x})&gt;\text{Threshold})\\-1\ \text{otherwise}\end{cases}\\f_t(\vec{x})=\sum_{white} x-\sum_{black} x\]</span> The strong classifier is <span class="math display">\[H(\vec{x})=\text{sgn}\left(\sum_{t=1}^T\alpha_th_t(\vec{x})\right)\]</span> where <span class="math inline">\(\alpha_t\)</span> is weight; and <span class="math inline">\(\text{sgn}(x)\)</span> is sign function: <span class="math display">\[\text{sgn}(x)=\begin{cases} -1,  &amp; \mbox{if }xâ‰¤0 \\1, &amp; \mbox{if }x&gt;0\end{cases}\]</span> <strong>Algorithm</strong></p><p>Given example images and classifications <span class="math inline">\((\vec{x}_i, y_i), i = 1, 2,..., N\)</span>, where <span class="math inline">\(N\)</span> is the total number of images.</p><p>Start with equal weights on each image <span class="math inline">\(\vec{x}_i\)</span>.</p><p>For <span class="math inline">\(t=1, ..., T\)</span>:</p><ul><li><p>Normalize all weights <span class="math inline">\(w_i = \frac{w_i}{\sum_{j=1}^Nw_j}\)</span> such that <span class="math inline">\(\sum_{i=1}^Nw_i=1\)</span>.</p></li><li><p>Select the weak classifier <span class="math inline">\(h_k\)</span> with minimum error: <span class="math display">\[e_k=\sum_{i=1}^Nw_i\left(\frac{1-h_k(\vec{x}_i)y_i}{2}\right)\]</span> where <span class="math inline">\(0â‰¤e_kâ‰¤1\)</span>.</p></li><li><p>Set weight for selected weak classifier <span class="math display">\[\alpha_t=\frac{1}{2}\ln\left(\frac{1-e_k}{e_k}\right)\]</span></p></li><li><p>Reweight the examples (boosting) <span class="math display">\[w_i=w_i\exp(-\alpha_iy_ih_k(\vec{x}_i))\]</span></p></li></ul><p>For the last step, if the weak classifier classify example <span class="math inline">\(i\)</span> correctly, i.e. <span class="math inline">\(h_k(\vec{x}_i)=y_i\)</span>, then the example weight <span class="math inline">\(w_i=w_ie^{-\alpha_t}\)</span> will decrease; if the weak classifier classify example <span class="math inline">\(i\)</span> wrongly, the weight <span class="math inline">\(w_i=w_i^{\alpha_t}\)</span> will increase.</p><p>Values of <span class="math inline">\(T\)</span> can be 200 for <span class="math inline">\(N=10^8\)</span> images and 180,000 filters. Given the above strong classifier, a new image can classified as either face or non-face.</p><h2><span id="face-recognition-pca">Face Recognition (PCA)</span></h2><p>Images of faces often belong to a manifold of intrinsically low dimension. For example, if there are three 3x1 images (see below), then each image has three intensity values. If each intensity value is viewed as a coordinate in a 3D space, then each image can be viewed as a point in a 3D space.</p><p><img src="/images/imgspace.png"></p><p>To represent these points effectively, the number of dimensions can be reduced from three to one. It is the concept of <a href="http://en.wikipedia.org/wiki/Dimension_reduction" target="_blank" rel="noopener">dimensionality reduction</a>.</p><p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">Principal component analysis</a> (PCA) is a method for performing dimensionality reduction of high dimensional face images.</p><p><strong>Eigenfaces</strong></p><p>Let us consider a set of <span class="math inline">\(N\)</span> sample images (image vectors) with <span class="math inline">\(m\times n\)</span> dimensions:</p><p><img src="/images/eigenface1.png"></p><p>Each image is represented by a 1D vector with dimensions <span class="math inline">\((m\times n) \times 1\)</span>. The <strong>mean image vector</strong> is given by <span class="math display">\[\vec{x}=\frac{1}{N}\sum_{i=1}^N\begin{bmatrix}x_{i,1}      \\\vdots \\x_{i,mn}\end{bmatrix}\]</span> The <strong>scatter matrix</strong> is given by <span class="math display">\[\vec{S}=[\vec{x_1}-\bar{x}\ \ \vec{x_2}-\bar{x}\ \dots\ \vec{x_N}-\bar{x}]\begin{bmatrix}(\vec{x_1}-\bar{x})^T     \\(\vec{x_2}-\bar{x})^T\\\vdots \\(\vec{x_N}-\bar{x})^T\end{bmatrix}\]</span> The corresponding <span class="math inline">\(t\)</span> eigenvectors with non-zero eigenvalues <span class="math inline">\(\lambda_i\)</span> are <span class="math display">\[\vec{e}_1\ \ \vec{e}_2\ \ \dots\ \ \vec{e}_t\]</span> where <span class="math inline">\(\lambda_1â‰¥\lambda_2â‰¥...â‰¥\lambda_t\)</span>.</p><p>Then the origin image vector can be approximated by <span class="math display">\[\vec{x}_j\approx\bar{x}+\sum_{i=1}^tg_{ji}\vec{e}_i\]</span> where <span class="math inline">\(g_{ji}=(\vec{x}_j-\bar{x})\cdot\vec{e}_i\)</span>.</p><p><img src="/images/egface.png"></p><p>Since the eigenvectors <span class="math inline">\(e\)</span> have the same dimension as the image vectors, the eigenvectors are referred as <a href="http://en.wikipedia.org/wiki/Eigenface" target="_blank" rel="noopener">Eigenfaces</a>. The value of <span class="math inline">\(t\)</span> is usually much smaller than the value of <span class="math inline">\(mn\)</span>. Therefore, the number of dimensions can be reduced significantly.</p><p>For each image <span class="math inline">\(\vec{x}_i\)</span>, the dimension reduced representation is <span class="math display">\[(g_{i1}, g_{i2}, ..., g_{it})\]</span> To detect if the new image <span class="math inline">\(\vec{x}\)</span> with <span class="math inline">\(t\)</span> coefficients <span class="math inline">\((g_1, g_2, ..., g_t)\)</span> is a face: <span class="math display">\[||\vec{x}-(\bar{x}+g_1\vec{e}_1+g_2\vec{e}_2+...+g_t\vec{e}_t)||&lt;\text{Threshold}\]</span> If it is a face, find the closest labeled face based on the nearest neighbor in the <span class="math inline">\(t\)</span>-dimensional space.</p><p><strong>Near-infrared images for face recognition</strong></p><p>Most current face recognition systems are based on face images captured in the visible light spectrum. The infrared imaging system is able to produce face images of good condition regardless of visible lights in the environment.</p><p><img src="/images/infared.png"></p><p><img src="/images/infeared2.png"></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PCA </tag>
            
            <tag> Recognition System </tag>
            
            <tag> Face Recognition </tag>
            
            <tag> histogram equalization </tag>
            
            <tag> Adaboost </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Irises</title>
      <link href="/2018/12/05/RS%20-%20Recognizing%20Irises/"/>
      <url>/2018/12/05/RS%20-%20Recognizing%20Irises/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 2. è¯†åˆ«ç³»ç»Ÿå¤ä¹ ç¬”è®°ã€‚</p><!-- toc --><ul><li><a href="#introduction">Introduction</a></li><li><a href="#image-acquisition-systems">Image Acquisition Systems</a></li><li><a href="#iris-localization">Iris localization</a></li><li><a href="#pattern-matching">Pattern Matching</a><ul><li><a href="#alignment-registration">Alignment (Registration)</a></li><li><a href="#representation">Representation</a></li><li><a href="#goodness-of-match">Goodness of Match</a></li><li><a href="#decision-fld">Decision (FLD)</a></li></ul></li><li><a href="#hough-transform">Hough Transform</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="introduction">Introduction</span></h2><p>Face recognition and iris recognition are non-invasive method for verification and identification of people. In particular, the spatial patterns that are apparent in the human iris are highly distinctive to an individual.</p><p><img src="/images/iries.png"></p><p><strong>Schematic diagram of iris recognition</strong></p><p><img src="/images/iries_recog.png"></p><h2><span id="image-acquisition-systems">Image Acquisition Systems</span></h2><p>One of the major challenges of automated iris recognition is to capture a high-quality image of the iris while remaining non-invasive to the human operator.</p><p>There are three concerns while acquiring iris images:</p><ul><li>To support recognition, it is desirable to acquire images of the iris with sufficient resolution and sharpness.</li><li>It is important to have good contrast in the interior iris pattern without resorting to a level of illumination that annoys the operator, i.e., adequate intensity of source constrained by operator comfort with brightness.</li><li>These images must be well framed (i.e., centered) without unduly constraining the operator.</li></ul><p><strong>The Daugman system</strong></p><p>The Daugman system captures images with the iris diameter typically between 100 and 200 pixels from a distance of 15-46cm.</p><p>The system makes use of an LED-based point light source in conjunction with a standard video. By carefully positioning of the point source below the operator, reflections of the light source off eyeglasses can be avoided in the imaged iris.</p><p><img src="/images/daugman.png"></p><p>The Daugman system provides the operator with live video feedback via a tiny liquidcrystal display placed in line with the camera's optics via a beam splitter. This allows the operator to see what the camera is capturing and to adjust his position accordingly.</p><p><strong>The Wildes system</strong></p><p>The Wildes system images the iris with approximately 256 pixels across the diameter from 20cm. The system makes use of a diffused source and polarization in conjunction with a low-light level camera.</p><p>The use of matched <strong>circular polarizer</strong> at the light source and camera essentially eliminates the specular reflection of the light source.</p><p><img src="/images/wildes.png"></p><p>The coupling of a low light level camera with a diffused illumination allows for a level of illumination that is entirely unobjectionable to human operators.</p><p>The relative sizes and positions of the square contours are chosen so that when the eye is in an appropriate position, the squares overlap and appear as one to the operator.</p><h2><span id="iris-localization">Iris localization</span></h2><p><img src="/images/iries_loc.png"></p><p>Image acquisition will capture the iris as part of a larger image that also contains data derived from the immediately surrounding eye region. For example, eyelashes, upper eyelid, lower eyelid and sclera. Therefore, prior to performing iris pattern matching, it is important to <strong>localize</strong> that portion of the acquired image that corresponds to an iris.</p><p><strong>The Wildes system</strong> makes use of the <strong>first derivatives</strong> of image intensity to signal the location of edges that correspond to the borders of the iris.</p><ul><li>Step 1: The image intensity information is converted into binary edge-map.</li><li>Step 2: The edge points vote to particular contour parameter values.</li></ul><p><strong>Step 1</strong></p><p>The edge map is recovered via <strong>gradient-based edge detection</strong>. This operation consists of thresholding the magnitude of the image intensity gradient magnitude. <span class="math inline">\(I\)</span> is the intensity and (x, y) are the image coordinates. <span class="math display">\[\text{Gradient magnitude }|\triangledown G(x, y)\ast I(x, y)|\\\text{2D Gaussian function } G(x, y)=\frac{1}{2\pi\sigma^2}\exp(\frac{(x-x_0)^2+(y-y_0)^2}{2\sigma^2})\]</span> <img src="/images/iris_edge.png"></p><p><strong>Step 2</strong></p><p>The voting procedure is realized via the <a href="#hough-transform">Hough transform</a>. For circular limbic or pupillary boundaries and a set of recovered edge points, a Hough transform is defined as follows.</p><p>Edge points <span class="math inline">\((x_j, y_j)\)</span> for <span class="math inline">\(j = 1, ..., n\)</span>: <span class="math display">\[H(x_c, y_c, r)=\sum_{j=1}^nh(x_j,y_j,x_c,y_c,r)\]</span> where <span class="math display">\[h(x_j, y_j, x_c, y_c, r)=\begin{cases}1, \text{ if }\ g(x_j, y_j, x_c, y_c, r)=0\\0, \text{ otherwise}\end{cases}\\g(x_j, y_j, x_c, y_c, r)=(x_j-x_c)^2+(y_j-y_c)^2-r^2\]</span> For every parameter triple <span class="math inline">\((x_c, y_c, r)\)</span> that represents a circle through the edge point <span class="math inline">\((x_j, y_j)\)</span>, <span class="math display">\[g(x_j, y_j, x_c, y_c, r)=0\]</span> <img src="/images/wildescir.png"></p><p>The parameter triple that <strong>maximizes</strong> the Hough space <span class="math inline">\(H\)</span> is common to the largest number of edge points and is a reasonable choice to represent the contour of interest.</p><hr><p>The limbus and pupil are modeled with <strong>circular contour models</strong>.</p><p><strong>The Daugman system</strong> fits the <strong>circular contours</strong> via gradient ascent on the parameters so as to maximize <span class="math display">\[\left|\frac{\partial}{\partial r}G(r)\ast\oint_{x_c,y_c,r}\frac{I(x,y)}{2\pi r}ds\right|\]</span> where <span class="math inline">\(G(r)=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(r-r_0)^2}{2\sigma^2})\)</span>; <span class="math inline">\(r_0\)</span> is the center.</p><p>The first part of the equation is to perform Gaussian smoothing; while the second part is computing the average intensity along the circle.</p><p><img src="/images/IMG_66247EE67551-1.jpg"></p><p>In order to incorporate directional tuning of the image derivative, the arc of integration <span class="math inline">\(ds\)</span> is restricted to the left and right quadrants (i.e., near vertical edges) when fitting the <em>limbic boundary</em>.</p><p>This arc is considered over a fuller range when fitting the <em>pupillary boundary</em>.</p><h2><span id="pattern-matching">Pattern Matching</span></h2><p>Having localized the region of an acquired image that corresponds to the iris, the final task is to decide if this pattern matches a previously stored iris pattern.</p><p>There are four steps:</p><ol type="1"><li>Alignment: bringing the newly acquired iris pattern into spatial alignment with a candidate data base entry.</li><li>Representation: choosing a representation of the aligned iris patterns that makes their distinctive patterns apparent.</li><li>Goodness of Match: evaluating the goodness of match between the newly acquired and data base representations.</li><li>Decision: deciding if the newly acquired data and the data base entry were derived from the same iris based on the goodness of match.</li></ol><h3><span id="alignment-registration">Alignment (Registration)</span></h3><p>To make a detailed comparison between two images, it is advantageous to establish a precise correspondence (or matching) between characteristic structures across the pair.</p><p>Both systems (Daugman and Wildes systems) compensate for image shift, scaling and rotation.</p><p><strong>The Daugman system for alignment</strong></p><p>The Daugman system uses <strong>radial scaling</strong> to compensate for overall size as well as a simple model pupil variation based on <strong>linear stretching</strong>.</p><p>The system maps the Cartesian image coordinates <span class="math inline">\((x, y)\)</span> to dimensionless polar image coordinates <span class="math inline">\((r, Î¸)\)</span> according to <span class="math display">\[x(r,\theta)=(1-r)x_p(0,\theta)+rx_l(1,\theta)\\y(r,\theta)=(1-r)y_p(0,\theta)+ry_l(1,\theta)\]</span> <img src="/images/daugalign.png"></p><p><img src="/images/daugali.png"></p><p><strong>The Wildes system for alignment</strong></p><p>The Wildes system uses an <strong>image-registration</strong> technique to compensate for both scaling and rotation.</p><p>This approach geometrically warps a newly acquired image <span class="math inline">\(I_a (x, y)\)</span> into alignment with a selected data base image <span class="math inline">\(I_d (x, y)\)</span> according to a mapping function <span class="math inline">\((u(x, y), v(x, y))\)</span> such that for all <span class="math inline">\((x, y)\)</span>, the image intensity value at <span class="math inline">\((x, y) â€“ (u(x, y), v(x, y))\)</span> is close to that at <span class="math inline">\((x, y)\)</span> at <span class="math inline">\(I_d\)</span>.</p><p>The mapping function is taken to minimize <span class="math display">\[\int_x\int_y\left(I_d(x,y)-I_a(x-u, y-v)\right)^2dxdy\]</span> under the constrains to capture similarity transformation of image coordinates <span class="math inline">\((x,y)\)</span> to <span class="math inline">\((x&#39;=x-u, y&#39;=y-v)\)</span>.</p><p><img src="/images/imgreg.jpg"></p><p><strong>Translation</strong> <span class="math display">\[\vec{x}&#39;=\vec{x}+\vec{d}\]</span> <img src="/images/imgtrans.png"></p><p><strong>Rotation</strong> <span class="math display">\[\vec{x}&#39;=R_\theta\vec{x}\\R_\theta=\begin{pmatrix}\cos\theta &amp; -\sin\theta \\\sin\theta &amp; \cos\theta\end{pmatrix}\]</span> <img src="/images/imgrot.png"></p><p><strong>Rotation + Translation</strong> <span class="math display">\[\vec{x}&#39;=R\vec{x}+\vec{d}\]</span> <strong>Scaling + Translation</strong> <span class="math display">\[\vec{x}&#39;=S\vec{x}+\vec{d}\]</span> <img src="/images/scatra.png"></p><p><strong>Shearing</strong> <span class="math display">\[\vec{x}&#39;=K\vec{x}\\K=\begin{bmatrix}1      &amp; k_{xy}     \\k_{yx}     &amp; 1\end{bmatrix}\]</span> <img src="/images/shearing.png"></p><p><strong>Affine</strong>: translation + rotation + scaling + shearing <span class="math display">\[\vec{x}&#39;=R_\theta S K\vec{x}+\vec{d}\]</span> Example: <span class="math display">\[\begin{bmatrix}x&#39; \\y&#39;\end{bmatrix}=\begin{bmatrix}\cos\theta &amp; -\sin\theta \\\sin\theta &amp; \cos\theta\end{bmatrix}\begin{bmatrix}s_x &amp; 0 \\0 &amp; s_y\end{bmatrix}\begin{bmatrix}1 &amp; k_{xy} \\k_{yx} &amp; 1\end{bmatrix}\begin{bmatrix}x \\y\end{bmatrix}+\begin{bmatrix}d_x \\d_y\end{bmatrix}\]</span></p><h3><span id="representation">Representation</span></h3><p>To represent the iris image for matching, both the Daugman and Wildes systems capture the multiscale information extracted from the image.</p><p>The Wildes system makes use of the Laplacian of Gaussian filters to construct a <strong>Laplacian pyramid</strong>.</p><p>The Laplacian of Gaussian (LoG) filter is given by <span class="math display">\[-\frac{1}{\pi\sigma^4}\left(1-\frac{\rho^2}{2\sigma^2}\right)\exp(-\frac{\rho^2}{2\sigma^2})\]</span> where <span class="math inline">\(\rho\)</span> is radial distance of a point from the filter's center; <span class="math inline">\(\sigma\)</span> is standard deviation.</p><p>A Laplacian pyramid is formed by collecting the LoG filtered images.</p><p><img src="/images/logpra.png"></p><h3><span id="goodness-of-match">Goodness of Match</span></h3><p>The Wildes system uses the <strong>normalized correlation</strong> between the acquired representation and data base representation. In discrete form, the normalized correlation can be defined as follows.</p><p>Let <span class="math inline">\(p_1[i, j]\)</span> and <span class="math inline">\(p_2[i, j]\)</span> be two image arrays of size <span class="math inline">\(n \times m\)</span>.</p><p><img src="/images/gom.png"></p><p>The normal correlation is <span class="math display">\[NC=\frac{\sum_{i=1}^n\sum_{j=1}^m(p_1[i,j]-\mu_1)(p_2[i,j]-\mu_2)}{nm\sigma_1\sigma_2}\]</span> <img src="/images/gompy.png"></p><h3><span id="decision-fld">Decision (FLD)</span></h3><p>The Wildes system combines four estimated normalized correlation values into a single <strong>accept/reject</strong> judgment.</p><p>In this application, the concept of <a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis" target="_blank" rel="noopener">Fisher's linear discriminant</a> is used for making binary decision. A <strong>weight vector</strong> is found such that <strong>the variance within a class of iris data is minimized</strong> while <strong>the variance between different classes of iris data is maximized</strong> for the transformed samples.</p><p>In iris recognition application, usually there are two classes: <strong>Authentic class (A)</strong> and <strong>Imposter class (I)</strong>.</p><p>To make a binary decision on a line, all points are projected onto the weight vector (or samples are transformed by using the weight vector).</p><p><img src="/images/fld1.png"></p><p>In iris recognition using the Wildes system, all samples are 4-dimensional vectors. Let there be n 4-dimensional samples.</p><p><img src="/images/fld2.png"></p><p>The total within class variance is <span class="math display">\[\vec{S}_w=\vec{S}_i+\vec{S}_a\]</span> Between class variance is <span class="math display">\[\vec{S}_b=(\vec{\mu}_a-\vec{\mu}_i)(\vec{\mu}_a-\vec{\mu}_i)^T\]</span> If all samples are transformed, the ratio of between class variance to total within class variance is <span class="math display">\[\frac{\vec{w}^T\vec{S}_b\vec{w}}{\vec{w}^T\vec{S}_w\vec{w}}\]</span> The ratio is maximized when <span class="math display">\[\vec{w}=\vec{S}_w^{-1}(\vec{\mu}_a-\vec{\mu}_i)\]</span> And the separation point for decision making is <span class="math display">\[\frac{1}{2}\vec{w}^T(\vec{\mu}_a+\vec{\mu}_i)\]</span> Therefore, values above this point will be taken as derived from class <span class="math inline">\(A\)</span>; values below this point will be taken as derived from class <span class="math inline">\(I\)</span>.</p><p><img src="/images/fld3.png"></p><h2><span id="hough-transform">Hough Transform</span></h2><p><strong>Detecting Lines</strong></p><p>Idea: if two edge points <span class="math inline">\((x_i, y_i)\)</span> and <span class="math inline">\((x_j, y_j)\)</span> lie on the same straight line, then they should have the same values of slope and y-intercepts on the xy-plane.</p><p><img src="/images/houghline.png"></p><p><strong>[1]</strong> For a point <span class="math inline">\((x_i,y_i)\)</span>, we set up a straight line equation: <span class="math display">\[y_i=ax_i+b\Leftrightarrow b=(-x_i)a+y_i\]</span> where <span class="math inline">\(a\)</span> = slope, <span class="math inline">\(b\)</span> = y-intercept, <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> are known and fixed.</p><p><strong>[2]</strong> We subdivide the a axis into <span class="math inline">\(K\)</span> increments between <span class="math inline">\([a_\min,a_\max]\)</span>. For each increment of <span class="math inline">\(a\)</span>, we evaluate the value of <span class="math inline">\(b\)</span>.</p><p><strong>[3]</strong> A relationship between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> can be plotted in a parameter space, i.e., ab-plane.</p><p><strong>[4]</strong> We partition the parameter space into a number of bins (accumulator cells), and increment the corresponding bin <span class="math inline">\(A(a,b)\)</span> by 1 (<span class="math inline">\(b\)</span> is rounded into the nearest integer).</p><p><img src="/images/houghbin.png"></p><p><strong>[5]</strong> For another point <span class="math inline">\((x_j,y_j)\)</span>, we set up another straight line equation: <span class="math display">\[y_j=ax_j+b\Leftrightarrow b=(-x_j)a+y_j\]</span> <strong>[6]</strong> Similarly, we subdivide the a axis into K increments between <span class="math inline">\([a_\min,a_\max]\)</span>. For each increment of <span class="math inline">\(a\)</span>, we evaluate the value of <span class="math inline">\(b\)</span>. We plot the relationship between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> in the same parameter space, and update bin values in the discrete parameter space.</p><p><strong>[7]</strong> The bin <span class="math inline">\(A(a,b)\)</span> having the highest count corresponds to the straight line passing through the points <span class="math inline">\((x_i,y_i)\)</span> and <span class="math inline">\((x_j,y_j)\)</span>.</p><p><img src="/images/hough2.png"></p><p><strong>[8]</strong> The same procedure can be applied to all points. The bin <span class="math inline">\(A(a,b)\)</span> having the <strong>highest count</strong> corresponds to the straight line passing through (or passing near) the largest number of points.</p><p>Problem: Values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> run from negative infinity to positive infinity. We need infinite number of bins!</p><p>Solution: use normal representation of a line: <span class="math display">\[x\cos(\theta)+y\sin(\theta)=\rho\]</span> <img src="/images/houghnormal.png"></p><p><span class="math inline">\(\theta\)</span> runs from <span class="math inline">\(â€“90^o\)</span> to <span class="math inline">\(90^o\)</span>. <span class="math inline">\(\rho\)</span> runs from <span class="math inline">\(-\sqrt{2}D\)</span> to <span class="math inline">\(\sqrt{2}D\)</span>, where <span class="math inline">\(D\)</span> is the distance between corners in the image (length and width).</p><p><strong>Circle Hough Transform (CHT)</strong></p><p>The Hough transform can be used to determine the parameters of a circle when a number of points that fall on the perimeter are known. A circle with radius <span class="math inline">\(R\)</span> and center <span class="math inline">\((a, b)\)</span> can be described with the parametric equations: <span class="math display">\[x=a+R\cos(\theta)\\y=b+R\sin(\theta)\]</span> When the angle <span class="math inline">\(Î¸\)</span> sweeps through the full 360 degree range the points <span class="math inline">\((x, y)\)</span> trace the perimeter of a circle.</p><p>If the circles in an image are of <strong>known radius</strong> <span class="math inline">\(R\)</span>, then the search can be reduced to 2D. The objective is to find the <span class="math inline">\((a, b)\)</span> coordinates of the centers.</p><p><img src="/images/cht1.png"></p><p>If the <strong>radius is not known</strong>, then the locus of points in parameter space will fall on the surface of a <strong>cone</strong>. Each point <span class="math inline">\((x, y)\)</span> on the perimeter of a circle will produce a cone surface in parameter space. The triplet <span class="math inline">\((a, b, R)\)</span> will correspond to the accumulation cell where the largest number of cone surfaces intersect.</p><p><img src="/images/cone.png">The drawing above illustrates the generation of a conical surface in parameter space for one <span class="math inline">\((x, y)\)</span> point. A circle with a different radius will be constructed at each level, <span class="math inline">\(r\)</span>.</p><p>The search for circles with unknown radius can be conducted by using a three dimensional accumulation matrix.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Iris </tag>
            
            <tag> FLD </tag>
            
            <tag> Daugman </tag>
            
            <tag> Wildes </tag>
            
            <tag> Hough Transform </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Image Features and Patterns</title>
      <link href="/2018/12/04/RS%20-%20Recognizing%20Image%20Features%20and%20Patterns/"/>
      <url>/2018/12/04/RS%20-%20Recognizing%20Image%20Features%20and%20Patterns/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 1. è¯†åˆ«ç³»ç»Ÿå¤ä¹ ç¬”è®°ã€‚</p><!-- toc --><ul><li><a href="#laplacian-point-detector">Laplacian Point Detector</a></li><li><a href="#line-detector">Line Detector</a></li><li><a href="#edge-detectors">Edge Detectors</a><ul><li><a href="#gradient-operator">Gradient Operator</a></li><li><a href="#marr-hildreth-edge-detector">Marr-Hildreth Edge Detector</a></li></ul></li><li><a href="#scale-invariant-feature-transform-sift">Scale Invariant Feature Transform (SIFT)</a></li><li><a href="#harris-corner-detector">Harris Corner Detector</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="laplacian-point-detector">Laplacian Point Detector</span></h2><p>There are three different types of intensity discontinuities in a digital image:</p><ul><li>Point (Isolated Point)</li><li>Line</li><li>Edge (Ideal, Ramp and Roof)</li></ul><p>Intensity discountinuity is detected based on the mask response <span class="math inline">\(R\)</span> within a pre-defined window, e.g. <span class="math inline">\(3\times3\)</span>: <span class="math display">\[R=\sum_{i=1}^9w_iz_i\]</span> where <span class="math inline">\(w_i\)</span> represent weights within a pre-defined window; <span class="math inline">\(z_i\)</span> represent intensity values.</p><p>If <span class="math inline">\(|R|â‰¥T\)</span> , then a point has been detected. This point is the location on which the mask is <strong>centred</strong>, where <span class="math inline">\(T\)</span> is a non-negative threshold.</p><p>The mask below is the <strong>Laplacian mask</strong> for detecting point. Sum of all weights is zero to make sure that there is no response at a flat region (constant intensity region).</p><table><thead><tr class="header"><th style="text-align: center;">1</th><th style="text-align: center;">1</th><th style="text-align: center;">1</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">-8</td><td style="text-align: center;">1</td></tr><tr class="even"><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;">1</td></tr></tbody></table><p>The Laplacian is given as (<span class="math inline">\(f\)</span> is input image): <span class="math display">\[\triangledown^2f(x,y)=\frac{\partial^2f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}\]</span> where <span class="math display">\[\frac{\partial^2f}{\partial x^2}=f(x+1,y)-2f(x,y)+f(x-1,y)\\\frac{\partial^2 f}{\partial y^2}=f(x,y+1)-2f(x,y)+f(x,y-1)\]</span> The discrete implementation of the Laplacian operator is given as: <span class="math display">\[\triangledown^2f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)\]</span> Below are several Laplacian masks:</p><p><img src="/images/pd.png"></p><h2><span id="line-detector">Line Detector</span></h2><p>A line is detected when more than one aligned, connected points are detected or, the <strong>response</strong> of line mask <strong>is greater than some threshold</strong>. The below are line masks for detecting lines (1 pixel thick) in 4 different specific directions:</p><p><img src="/images/ld.png"></p><p>If we want to detect a line in a specified direction, then we should use the mask associated with that direction and threshold its output responses.</p><p>If 4 line masks are used, then the final response is equal to the <strong>largest</strong> response among the masks: <span class="math display">\[R = \max\left(|R_{horizontal}|, |R_{45}|, |R_{vertical}|, |R_{-45}|\right)\]</span> Example code (Matlab):</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = imread(<span class="string">'xxx.png'</span>); <span class="comment">% read image</span></span><br><span class="line">w = [<span class="number">2</span> <span class="number">-1</span> <span class="number">-1</span>; <span class="number">-1</span> <span class="number">2</span> <span class="number">-1</span>; <span class="number">-1</span> <span class="number">-1</span> <span class="number">2</span>]; <span class="comment">% mask</span></span><br><span class="line">g = <span class="built_in">abs</span>(imfilter(double(f),w)); <span class="comment">% mask responses</span></span><br></pre></td></tr></table></figure><h2><span id="edge-detectors">Edge Detectors</span></h2><p>Edge is the boundary of regions. The boundary has meaningful discontinuities in grey intensity level. There are three types of edges: ideal edge (left), ramp edge (middle) and roof edge (right).</p><p><img src="/images/3t.png"></p><p>For an <strong>ideal edge</strong> (step edge, left), an edge is a collection of connected pixels on the region boundary. Ideal edges can occur over the distance of 1 pixel.</p><p><strong>Roof edges</strong> (right) are models of lines through a region, with the base (width) of a roof edge being determined by the thickness and sharpness of the line. In the limit, when its base is 1 pixel wide, a roof edge becomes a 1 pixel thick line running through a region in an image. Roof edges can represent thin features, e.g., roads, line drawings, etc.</p><p>For a <strong>ramp edge</strong> (middle):</p><ul><li>edge point is any point contained in the ramp</li><li>edge length is determined by the length of the ramp</li><li>the slope of the ramp is inversely proportional to the degree of blurring in the edge</li><li>the <strong>first derivative</strong> of the intensity profile is positive at the points of transition into and out of the ramp (we move from left to right)</li><li>the <strong>second derivative</strong> of the intensity profile is positive at the transition associated with the dark side of the edge, and negative at the transition associated with the light side of the edge</li></ul><p><img src="/images/ramp.png"></p><p>The <strong>magnitude of the first derivative</strong> can be used to detect the presence of an edge. The <strong>sign of the second derivative</strong> can be used to determine whether an edge pixel lies on the dark or light side of an edge. The <strong>zero-crossing property</strong> of the second derivative is very useful for <strong>locating</strong> the centres of thick edge.</p><p>However, fairly little noise can have a significant impact on the first and second derivatives used for edge detection in images. <strong>Image smoothing</strong> is commonly used prior to the edge detection so that the estimations of the two derivatives can be more accurate.</p><h3><span id="gradient-operator">Gradient Operator</span></h3><p>The computation of the gradient of an image is based on obtaining the partial derivatives <span class="math inline">\(G_x = \partial f/\partial x\)</span> and <span class="math inline">\(G_y = \partial f/\partial y\)</span> at every pixel location (x,y). The gradient direction and gradient magnitude are <span class="math display">\[\tan^{-1}\left(\frac{G_y}{G_x}\right)\\|\triangledown f|\approx|G_x|+|G_y|\]</span> <img src="/images/z.png"></p><p>The are several ways to approximate the partial derivatives:</p><ul><li>Roberts cross-gradient operators<ul><li><span class="math inline">\(G_x = (z_9-z_5)\)</span></li><li><span class="math inline">\(G_y=(z_8-z_6)\)</span></li></ul></li><li>Prewitt operators<ul><li><span class="math inline">\(G_x=(z_7+z_8+z_9)-(z_1+z_2+z_3)\)</span></li><li><span class="math inline">\(G_y=(z_3+z_6+z_9)-(z_1+z_4+z_7)\)</span></li></ul></li><li>Sobel operators<ul><li><span class="math inline">\(G_x=(z_7+2z_8+z_9)-(z_1+2z_2+z_3)\)</span></li><li><span class="math inline">\(G_y=(z_3+2z_6+z_9)-(z_1+2z_4+z_7)\)</span></li></ul></li></ul><p><img src="/images/ed.png"></p><p>Below are diagonal edge masks for detecting discontinuities in the <strong>diagonal directions</strong>.</p><p><img src="/images/diag.png"></p><h3><span id="marr-hildreth-edge-detector">Marr-Hildreth Edge Detector</span></h3><p>The Laplacian of an image f(x,y) at location (x,y) is defined as <span class="math display">\[\triangledown^2f(x,y)=\frac{\partial^2f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}\]</span> There are two approximations: <span class="math display">\[\triangledown^2f=4z_5-(z_2+z_4+z_6+z_8)\\\triangledown^2f=8z_5-(z_1+z_2+z_3+z_4+z_6+z_7+z_8+z_9)\]</span> The Laplacian generally is <strong>not</strong> used in its original form for edge detection (based on zero-crossing property) because it is <strong>unacceptably sensitive to noise</strong>. We smooth the image by using a Gaussian blurring function <span class="math inline">\(G(r)\)</span>, where <span class="math inline">\(r\)</span> = radius, before we apply the Laplacian operator: <span class="math display">\[G(r)=\exp(\frac{-r^2}{2\sigma^2})\]</span> The <strong>Laplacian of a Gaussian (LoG)</strong> operator is defined by <span class="math display">\[\text{LoG}(f)=\triangledown^2(f\ast G)=f\ast(\triangledown^2G)\]</span> Using the LoG, the location of edges can be detected reliably based on the zero-crossing values because image noise level is reduced by the Gaussian function.</p><p><strong>Marr-Hildreth algorithm</strong></p><ol type="1"><li><p>Filter the input with an n-by-n Gaussian blurring filter <span class="math inline">\(G(r)\)</span>.</p></li><li><p>Compute the Laplacian of the image resulting from Step 1 using one of the following 3-by-3 masks.</p><p><img src="/images/mha.png"></p></li><li><p>Find the <strong>zero crossings</strong> of the image from Step 2.</p><ol type="1"><li>A zero crossing at a pixel implies that the signs of at least two of its opposing neighboring pixels must be different.</li><li>There are four cases to test: left/right, up/down, and the two diagonals.</li><li>For testing, the signs of the two opposing neighboring pixels must be different and their absolute Laplacian values must be larger than or equal to some threshold.</li><li>If yes, we call the current pixel a zero-crossing pixel.</li></ol></li></ol><p><img src="/images/mhed.png"></p><h2><span id="scale-invariant-feature-transform-sift">Scale Invariant Feature Transform (SIFT)</span></h2><p>SIFT is useful for finding distinctive patches (<strong>keypoints</strong>) in images and transforming keypoints (locations) into <strong>features vectors</strong> for recognition tasks.</p><p>SIFT consists of four steps:</p><ol type="1"><li>Scale-space extrema detection</li><li>Keypoint localization</li><li>Orientation assignment</li><li>Keypoint descriptor</li></ol><p>SIFT feature is</p><ul><li>invariant to image rotation and scale</li><li>partially invariant to change in illumination and 3D camera viewpoint</li></ul><p>The method is a cascade (one step followed by the other step) filtering approach, in which more computationally expensive operations are applied only at locations that pass an initial test.</p><p><strong>[1] Scale-space extrema detection</strong></p><p>Candidate locations are identified by searching for stable features across all scales in the scale space. The <strong>scale space</strong> of an image is defined as <span class="math display">\[L(x,y,\sigma)=G(x,y,\sigma)\ast I(x,y)\\G(x,y,\sigma)=\frac{1}{2\pi\sigma^2}\exp(-\frac{x^2+y^2}{2\sigma^2})\]</span> , where <span class="math inline">\(\ast\)</span> is the convolution operator (filtering operation), the variable-scale Gaussian is <span class="math inline">\(G(x, y, \sigma)\)</span> and the image is <span class="math inline">\(I(s, y)\)</span>.</p><p>The difference between two nearby scales separated by a constant multiplicative factor <span class="math inline">\(k\)</span> is <span class="math display">\[\begin{align}D(x,y,\sigma)&amp;=L(x,y,k\sigma)-L(x,y,\sigma)\\&amp;=\left(G(x,y,k\sigma)-G(x,y,\sigma)\right)\ast I(x,y)\end{align}\]</span> The DoG function provides a close and efficient approximation to the scale-normalized Laplacian of Gaussian (LoG).</p><p><img src="/images/dog.jpg"></p><p>Local <strong>extrema</strong> (maxima and minima) of <span class="math inline">\(D( x, y, Ïƒ)\)</span> are detected by comparing the values of its 26 neighbors, including 9 from the above image, 9 from bottom image and 8 from the current image.It is selected only if the center pixel is larger than <strong>all</strong> of these neighbors (26 neighbors) or smaller than all of them.</p><p><img src="/images/extra.png"></p><p><img src="/images/exdet.png"></p><p><strong>[2] Keypoint localization</strong></p><p>Once a keypoint candidate has been found by comparing a pixel to its neighbors, the next step is to determine whether the keypoint is selected based on <strong>local contrast and localization along edge</strong>. Therefore, the keypoints will be rejected if these points have low contrast.</p><p>All extrema are discarded if <span class="math inline">\(|D(x)|&lt;0.03\)</span> (minimum contrast), where <span class="math inline">\(x\)</span> represents a relative image position with maximum value of <span class="math inline">\(D\)</span>. The keypoints will be rejected if these points are poorly localized along an edge (determined based on the <strong>ratio of principle curvatures</strong>).</p><p><img src="/images/kl.png"></p><p><strong>[3] Orientation assignment</strong></p><p>Each corresponding keypoint in <span class="math inline">\(L\)</span> is assigned a dominant orientation. The keypoint descriptor can be represented relative to this orientation and therefore achieve invariance to image rotation.</p><p>The gradient magnitude and orientation are <span class="math display">\[m(x,y)=\sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2}\\\theta(x,y)=\tan^{-1}\left(\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right)\]</span> An <strong>orientation histogram</strong> is formed from the gradient orientations within a region around the keypoint. The orientation histogram has 36 bins covering the 360 degree range of orientations, 10 degrees per bin. Each sample added to the histogram is weighted by its gradient magnitude and by a Gaussian-weighted circular window (with Ïƒ that is 1.5 times that of the scale of the keypoint, and it is related to effective window size). Peak in the orientation histogram corresponds to dominant direction of the local gradients.</p><p><img src="/images/IMG_2E4DF1ED416A-1.jpg"></p><p><strong>[4] Descriptor for local image region</strong></p><p><img src="/images/kd.png"></p><p>For each detected keypoint, a local image descriptor is computed. It is partially invariant to change in illumination and 3D viewpoint.</p><p>In order to achieve orientation invariance, the coordinates and the gradient orientations are rotated relative to the keypoint orientation. A Gaussian weighting function with Ïƒ equal to one half the width of the descriptor window is used to assign a weight to the magnitude of each sample point.</p><p>Each subregion generates an orientation histogram with 8 orientation bins. Therefore, for each keypoint, if <span class="math inline">\(2\times2\)</span> descriptor is used, a feature vector can be formed with <span class="math inline">\(2\times2\times8 = 32\)</span> elements; if <span class="math inline">\(4\times4\)</span> descriptor is used, there will be <span class="math inline">\(4\times4\times8 = 128\)</span> elements in a feature vector. The <strong>optimal</strong> setting is 4x4 subregions and 8 orientation bins (the above picture).</p><p><strong>Feature matching</strong></p><p><img src="/images/IMG_043BB8EF0160-1.jpg"></p><p>Matlab Implementation</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% num = match(image1, image2)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% This function reads two images, finds their SIFT features, and</span></span><br><span class="line"><span class="comment">%   displays lines connecting the matched keypoints.  A match is accepted</span></span><br><span class="line"><span class="comment">%   only if its distance is less than distRatio times the distance to the</span></span><br><span class="line"><span class="comment">%   second closest match.</span></span><br><span class="line"><span class="comment">% It returns the number of matches displayed.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Example: match('scene.pgm','book.pgm');</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">num</span> = <span class="title">match</span><span class="params">(image1, image2)</span></span></span><br><span class="line"><span class="comment">% Find SIFT keypoints for each image</span></span><br><span class="line">[im1, des1, loc1] = sift(image1);</span><br><span class="line">[im2, des2, loc2] = sift(image2);</span><br><span class="line"><span class="comment">% For efficiency in Matlab, it is cheaper to compute dot products between</span></span><br><span class="line"><span class="comment">%  unit vectors rather than Euclidean distances.  Note that the ratio of</span></span><br><span class="line"><span class="comment">%  angles (acos of dot products of unit vectors) is a close approximation</span></span><br><span class="line"><span class="comment">%  to the ratio of Euclidean distances for small angles.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% distRatio: Only keep matches in which the ratio of vector angles from the</span></span><br><span class="line"><span class="comment">%   nearest to second nearest neighbor is less than distRatio.</span></span><br><span class="line">distRatio = <span class="number">0.6</span>;</span><br><span class="line"><span class="comment">% For each descriptor in the first image, select its match to second image.</span></span><br><span class="line">des2t = des2';</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(des1,<span class="number">1</span>)</span><br><span class="line">    dotprods = des1(<span class="built_in">i</span>,:) * des2t; <span class="comment">% compute orientation of des1[i] and des2[j] for all j</span></span><br><span class="line">    [vals, indx] = <span class="built_in">sort</span>(<span class="built_in">acos</span>(dotprods)); <span class="comment">% Take inverse cosine and sort results</span></span><br><span class="line">    <span class="comment">% Check if nearest neighbor has angle less than distRatio times 2nd.</span></span><br><span class="line">    <span class="keyword">if</span> (vals(<span class="number">1</span>) &lt; distRatio * vals(<span class="number">2</span>))</span><br><span class="line">      match(<span class="built_in">i</span>) = indx(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      match(<span class="built_in">i</span>) = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><img src="/images/IMG_DAD55EC9C383-1.jpg"></p><h2><span id="harris-corner-detector">Harris Corner Detector</span></h2><p><strong>Basic Idea</strong></p><p>We should easily recognize the point by looking at intensity values within a small window. hifting the window in any direction should yield a large change in appearance.</p><p><img src="/images/cornersad1.png"></p><p>Harris corner detector gives a mathematical approach for determining which case holds.</p><p>Change of intensity for the shift <span class="math inline">\([u, v]\)</span>: <span class="math display">\[E(u,v)=\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]\]</span> where <span class="math inline">\(w(x,y)\)</span> is window function.</p><p>For nearly constant patches, this will be near 0. For very distinctive patches, this will be larger. Hence... we want patches where <span class="math inline">\(E(u,v)\)</span> is LARGE.</p><p><img src="/images/harriasequ.png"></p><p>For small shifts <span class="math inline">\([u, v]\)</span>, we have a bilinear approximation: <span class="math display">\[E(u,v)\approx [u,v]M[u,v]^T\]</span> where <span class="math inline">\(M\)</span> is a 2x2 matrix computed from image derivatives: <span class="math display">\[M=\sum_{x,y}w(x,y)\begin{bmatrix}I_x^2      &amp; I_xI_y      \\I_xI_y      &amp; I_y^2\end{bmatrix}\]</span> Treat gradient vectors as a set of <span class="math inline">\((dx,dy)\)</span> points with a center of mass defined as being at <span class="math inline">\((0,0)\)</span>. Fit an ellipse to that set of points via scatter matrix.</p><p><img src="/images/harrianaly.png"></p><p><img src="/images/harrrieclips.png"></p><p>Measure of corner response: <span class="math display">\[R=Det(M)-k(Trace(M))^2\]</span> where <span class="math display">\[Det(M)=\lambda_1\lambda_2\\Trace(M)=\lambda_1+\lambda_2\]</span> According to <span class="math inline">\(R\)</span>, we can detect corner:</p><p><img src="/images/harrieres.png"></p><p><span class="math inline">\(R\)</span> depends only on eigenvalues of <span class="math inline">\(M\)</span>. As we can see from figure above,</p><ul><li><span class="math inline">\(R\)</span> is large for a corner.</li><li><span class="math inline">\(R\)</span> is negative with large magnitude for an edge</li><li><span class="math inline">\(|R|\)</span> is small for a flat region</li></ul><p><strong>Harris Corner Detection Algorithm</strong></p><ol type="1"><li><p>Compute <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> derivatives of image: <span class="math display">\[I_x=G_\sigma^x\ast I\\I_y=G_\sigma^y\ast I\]</span></p></li><li><p>Compute products of derivatives at every pixel: <span class="math display">\[I_x^2=I_x\cdot I_x\\I_y^2=I_y\cdot I_y\\I_{xy}=I_x\cdot I_y\]</span></p></li><li><p>Compute the sums of the products of derrivatives at each pixel: <span class="math display">\[S_x^2=G_\sigma&#39;\ast I_x^2\\S_y^2=G_\sigma&#39;\ast I_y^2\\S_{xy}=G_\sigma&#39;\ast I_{xy}\]</span></p></li><li><p>Define at each pixel <span class="math inline">\((x,y)\)</span> the matrix: <span class="math display">\[M(x,y)=\begin{bmatrix}S_x^2(x,y)      &amp; S_{xy}(x,y)      \\S_{xy}(x,y)     &amp; S_y^2(x,y)\end{bmatrix}\]</span></p></li><li><p>Compute the response of the detector at each pixel: <span class="math display">\[R=Det(M)-k(Trace(M))^2\]</span></p></li><li><p>Threshold of value of <span class="math inline">\(R\)</span>. Compute nonmax suppression.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Prewitt </tag>
            
            <tag> Sobel </tag>
            
            <tag> Marr-Hildreth Edge Detector </tag>
            
            <tag> SIFT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Deep Deterministic Policy Gradient (DDPG)</title>
      <link href="/2018/11/30/RL%20-%20Deep%20Deterministic%20Policy%20Gradient/"/>
      <url>/2018/11/30/RL%20-%20Deep%20Deterministic%20Policy%20Gradient/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1509.02971" target="_blank" rel="noopener">Deep Deterministic Policy Gradient (DDPG)</a> æ˜¯ç”± DeepMind çš„ Lillicrap ç­‰äººäº2015å¹´æå‡ºçš„ç®—æ³•ï¼Œå‘è¡¨åœ¨ICLR 2016ä¸Šã€‚DDPG æ˜¯åŸºäº <a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener">DPG</a> ç®—æ³•çš„æ”¹è¿›ï¼Œå¯ä»¥çœ‹ä½œæ˜¯ Actor-critic å’Œ <a href="https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/">DQN</a> çš„ç»“åˆï¼Œå®ƒåŒæ—¶å­¦ä¹ ä¸€ä¸ª Q-function å’Œä¸€ä¸ªç­–ç•¥ï¼ˆpolicyï¼‰ï¼šç”¨ Q-learning çš„æ–¹æ³•å­¦ä¹  Q-functionï¼Œç„¶åç”¨ Q-function æ›´æ–°ç­–ç•¥ã€‚</p><a id="more"></a><h2><span id="dpg">DPG</span></h2><p><a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener">Deterministic Policy Gradient (DPG)</a> æ˜¯æŠŠç­–ç•¥æ¢¯åº¦ï¼ˆpolicy gradientï¼‰ç®—æ³•æ‰©å±•åˆ°ç¡®å®šæ€§ç­–ç•¥ï¼ˆdeterministic policyï¼‰ä¸Šã€‚äº‹å®ä¸Šï¼ŒDPG è¢«è¯æ˜æ˜¯éšæœºç­–ç•¥æ¢¯åº¦ï¼ˆstochastic policy gradientï¼‰çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µã€‚</p><blockquote><p>éšæœºç­–ç•¥æ¢¯åº¦ï¼š <span class="math display">\[\triangledown_\theta J(\pi_\theta)=\mathbb{E}_{s\sim\rho^\pi, a\sim\pi_\theta}[\triangledown_\theta\log\pi_\theta(a|s)Q^\pi(s,a)]\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\pi_\theta\)</span> æ˜¯ç”±å‚æ•°ä¸º <span class="math inline">\(\theta\)</span> çš„å‡½æ•°è¿‘ä¼¼çš„ç­–ç•¥ï¼Œ<span class="math inline">\(\rho^\pi\)</span> ä¸ºç­–ç•¥ <span class="math inline">\(\pi_\theta\)</span> çš„çŠ¶æ€åˆ†å¸ƒï¼ˆstate distributionï¼‰ã€‚</p></blockquote><p>å¤§éƒ¨åˆ† model-free çš„å¢å¼ºå­¦ä¹ ç®—æ³•å±äºæ³›åŒ–çš„<a href="https://www.52coding.com.cn/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/">ç­–ç•¥è¿­ä»£ï¼ˆpolicy iterationï¼‰</a>ç®—æ³•ï¼Œä¸€èˆ¬åˆ†ä¸ºä¸¤æ­¥ï¼šç­–ç•¥è¯„ä¼°ï¼ˆpolicy evaluationï¼‰ å’Œç­–ç•¥æ”¹è¿›ï¼ˆ policy improvementï¼‰ã€‚ç­–ç•¥è¯„ä¼°é€šå¸¸ä½¿ç”¨ <a href="https://www.52coding.com.cn/2017/12/16/RL%20-%20Model-Free%20Prediction/#monte-carlo-learning">Monte-Carlo evaluation</a> æˆ– <a href="https://www.52coding.com.cn/2017/12/16/RL%20-%20Model-Free%20Prediction/#temporal-difference-learning">temporal difference learning</a> æ¥è¿‘ä¼¼ <span class="math inline">\(Q^\pi(s, a)\)</span>ã€‚ç­–ç•¥æ”¹è¿›åˆ™é€šå¸¸é€šè¿‡æœ€å¤§åŒ–è¯„ä¼°çš„ action-value æ¥å¾—åˆ°ï¼š<span class="math inline">\(\mu^{k+1}(s) = \arg\max_aQ^{\mu^k}(s, a)\)</span>ã€‚</p><p>ç„¶è€Œï¼Œåœ¨è¿ç»­çš„åŠ¨ä½œç©ºé—´ï¼ˆcontinuous action spacesï¼‰é‡Œè¿™ç§æœ€å¤§åŒ–å´æ˜¯ä¸å¯è¡Œçš„ã€‚åœ¨ç¦»æ•£çš„åŠ¨ä½œç©ºé—´é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªactionè®¡ç®—ç›¸åº” Q-value ç„¶åè¿›è¡Œæ¯”è¾ƒï¼›ä½†æ˜¯åœ¨è¿ç»­çš„åŠ¨ä½œç©ºé—´ä¸­ï¼Œæˆ‘ä»¬ä¸å¯èƒ½æŠŠæ¯ä¸ªactionçš„ Q-value éƒ½è®¡ç®—å‡ºæ¥å†æ¯”è¾ƒï¼Œè€Œé€šè¿‡å¯¹ Q-function æ±‚å¯¼æ±‚çš„æ–¹å¼è®¡ç®—æœ€å¤§å€¼å¼€é”€åˆå¾ˆå¤§ã€‚æ‰€ä»¥ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯å•ç‹¬ç”¨ä¸€ä¸ªå‡½æ•°è¿‘ä¼¼ç­–ç•¥ï¼Œç„¶å<strong>ç”¨ Q-function çš„æ¢¯åº¦æ¥æ”¹è¿›è¯¥ç­–ç•¥</strong>ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸ªè®¿é—®è¿‡çš„çŠ¶æ€ <span class="math inline">\(s\)</span>ï¼Œç­–ç•¥å‡½æ•°çš„å‚æ•° <span class="math inline">\(\theta^{k+1}\)</span> æ ¹æ® <span class="math inline">\(\triangledown_\theta Q^{\mu_k}(s, \mu_\theta(s))\)</span> æ¥æ›´æ–°ï¼š <span class="math display">\[\begin{align}\theta^{k+1}&amp;=\theta^k+\alpha\mathbb{E}_{s\sim\rho^{\mu^k}}[\triangledown_\theta Q^{\mu^k}(s, \mu_\theta(s))]\\&amp;= \theta^k + \alpha\mathbb{E}_{s\sim\rho^{\mu^k}}[\triangledown_\theta \mu_\theta(s)\triangledown_aQ^{\mu^k}(s, a)|_{a=\mu_\theta(s)}]\end{align}\]</span></p><p>å¯ä»¥è¯æ˜ï¼Œä¸Šè¿°æ›´æ–°ä¹Ÿå±äºç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œè¿™å°±æ˜¯DPGç®—æ³•çš„ç­–ç•¥æ›´æ–°å…¬å¼ã€‚</p><h2><span id="ddpg">DDPG</span></h2><p>DDPGæ”¹è¿›äº† Q-function çš„å­¦ä¹ æ–¹å¼ï¼Œè€Œç­–ç•¥ç«¯çš„æ›´æ–°æ–¹å¼å’ŒDPGç›¸åŒï¼Œå³å¦‚å¼(1)æ‰€ç¤ºã€‚åœ¨ DPG ä¸­ï¼ŒQ-function æ˜¯é€šè¿‡ Q-learning çš„æ–¹å¼æ¥å­¦ä¹ çš„ï¼Œè€Œå½“ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¿‘ä¼¼ Q-function çš„æ—¶å€™ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼ŒDDPG åº”ç”¨äº† <a href="https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/#deep-q-network">DQN</a> ä¸­çš„ä¸¤ä¸ªtrickæ¥è§£å†³ä¸ç¨³å®šçš„é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯<strong>ç»éªŒæ± ï¼ˆreplay bufferï¼‰</strong>å’Œ<strong>ç›®æ ‡ç½‘ç»œï¼ˆtarget networkï¼‰</strong>ã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œç»éªŒæ±  <span class="math inline">\(D\)</span> æ¯æ¬¡æ¢ç´¢éƒ½ä¼šå­˜å‚¨å…ƒç»„ <span class="math inline">\((s, a, r, s&#39;, d)\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(d\)</span> ä¸ºä¸€ä¸ªå¸ƒå°”å˜é‡ï¼Œå¦‚æœ <code>d == True</code>ï¼Œå°±è¡¨æ˜ <span class="math inline">\(s&#39;\)</span> æ˜¯ç»ˆæ­¢çŠ¶æ€ï¼ˆterminal stateï¼‰ã€‚ æ¯æ¬¡æ›´æ–°æ—¶éƒ½ä¼šä»ç»éªŒæ± éšæœºé‡‡æ ·ä¸€æ‰¹æ•°æ®è¿›è¡Œæ›´æ–°ã€‚ç»éªŒæ± çš„å¤§å°æ˜¯ä¸€ä¸ªéœ€è¦å¾®è°ƒçš„è¶…å‚æ•°ï¼šå¦‚æœç»éªŒæ± è¿‡å°çš„è¯ï¼Œä¼šå¯¼è‡´å¯¹æ± å†…æ•°æ®è¿‡æ‹Ÿåˆï¼›å¦‚æœç»éªŒæ± å­˜å‚¨æ‰€æœ‰æ•°æ®çš„è¯ï¼Œåˆä¼šæ”¾æ…¢å­¦ä¹ çš„é€Ÿåº¦ã€‚</p><p>ç›®æ ‡ç½‘ç»œæ˜¯æŒ‡ç”¨å•ç‹¬çš„ç½‘ç»œå‚æ•°æ¥ç”Ÿæˆç›®æ ‡ï¼ˆq-targetï¼‰ï¼Œè®¾ç­–ç•¥å‡½æ•°çš„å‚æ•°ä¸º <span class="math inline">\(\theta\)</span>ï¼ŒQ-function çš„å‚æ•°ä¸º <span class="math inline">\(\phi\)</span>ï¼Œåˆ™å¯¹åº”çš„ç›®æ ‡ç½‘ç»œå‚æ•°ä¸º <span class="math inline">\(\theta_{tag}\)</span> å’Œ <span class="math inline">\(\phi_{tag}\)</span>ï¼Œç”Ÿæˆçš„ç›®æ ‡ä¸ºï¼š <span class="math display">\[r + \gamma(1-d)Q_{\phi_{tag}}(s&#39;, \mu_{\theta_{tag}}(s&#39;))\]</span> æ‰€ä»¥ Q-value ç«¯çš„æ›´æ–°å…¬å¼ä¸ºï¼š <span class="math display">\[\triangledown_\phi \mathbb{E}_{s,a,r,s&#39;,d\sim D}\left[\left(Q(s,a)-(r + \gamma(1-d)Q_{\phi_{tag}}(s&#39;, \mu_{\theta_{tag}}(s&#39;)))\right)^2\right]\]</span> ä¸DQNä¸åŒçš„æ˜¯ï¼ŒDDPGä¸­çš„ç›®æ ‡ç½‘ç»œä½¿ç”¨â€œè½¯æ›´æ–°â€çš„æ–¹å¼ï¼Œå³ç›®æ ‡ç½‘ç»œå¹¶ä¸æ˜¯éš”ä¸€å®šæ—¶é—´åä¸ä¸»ç½‘ç»œåŒæ­¥ï¼Œè€Œæ˜¯æœç€ä¸»ç½‘ç»œç¼“æ…¢ç§»åŠ¨ï¼š <span class="math display">\[\theta_{tag}\leftarrow\tau\theta+(1-\tau)\theta_{tag}\\\phi_{tag}\leftarrow\tau\phi+(1-\tau)\phi_{tag}\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\tau \in (0, 1)\)</span> æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œé€šå¸¸å–å€¼æ¥è¿‘ 1ã€‚</p><p>ä¸ºäº†å¢åŠ æ¢ç´¢èƒ½åŠ›ï¼Œè®­ç»ƒæ—¶åœ¨é€‰æ‹©æ¯ä¸ªåŠ¨ä½œçš„æ—¶å€™éƒ½ä¼šåŠ ä¸Šéšæœºå™ªå£° <span class="math inline">\(\mathcal{N}\)</span>ï¼Œè®ºæ–‡ä½œè€…å»ºè®®ä½¿ç”¨æ—¶é—´ç›¸å…³çš„ <a href="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process" target="_blank" rel="noopener">OUå™ªå£°</a>ï¼Œä½†æ˜¯æœ€è¿‘çš„ç ”ç©¶ç»“æœè¡¨æ˜ä½¿ç”¨ä¸ç›¸å…³çš„ã€zero-meançš„é«˜æ–¯å™ªå£°æ•ˆæœä¼šæ›´å¥½ã€‚åŒæ—¶ä¸ºäº†å–å¾—æ›´é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œå™ªå£°å¯ä»¥éšç€è®­ç»ƒè¿‡ç¨‹é€æ­¥å‡å°ã€‚å¦å¤–ï¼Œåœ¨è¯„æµ‹æ—¶åº”å»æ‰å™ªå£°ã€‚</p><p><strong>DDPGç®—æ³•</strong></p><p><img src="/images/ddpg_algo.svg"></p><h2><span id="æ€»ç»“">æ€»ç»“</span></h2><p><strong>ç‰¹ç‚¹</strong></p><ul><li>off-policyç®—æ³•</li><li>åªèƒ½ç”¨äºè¿ç»­çš„åŠ¨ä½œç©ºé—´</li><li>å¯ä»¥çœ‹ä½œæ˜¯æŠŠDQNåº”ç”¨åˆ°è¿ç»­åŠ¨ä½œç©ºé—´</li></ul><h2><span id="references">References</span></h2><p>[1] http://proceedings.mlr.press/v32/silver14.pdf</p><p>[2] https://arxiv.org/abs/1509.02971</p><p>[3] https://spinningup.openai.com/en/latest/algorithms/ddpg.html</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> DPG </tag>
            
            <tag> DDPG </tag>
            
            <tag> DQN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Proximal Policy Optimization (PPO)</title>
      <link href="/2018/11/25/RL%20-%20PPO/"/>
      <url>/2018/11/25/RL%20-%20PPO/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1707.06347" target="_blank" rel="noopener">Proximal Policy Optimization (PPO, PPO-Clip, PPO-Penalty)</a> æ˜¯ç”±<a href="https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/">TRPO</a>çš„ä½œè€…Schulmanç­‰äººäº2017å¹´æå‡ºçš„ç­–ç•¥æ¢¯åº¦ç±»ç®—æ³•ã€‚PPOç®—æ³•çš„æ€è·¯å’ŒTRPOä¸€è‡´ï¼Œéƒ½æ˜¯æƒ³åœ¨ä¼˜åŒ–æ—¶é‡‡å–å°½å¯èƒ½å¤§çš„æ­¥å¹…ä½†åˆä¸èƒ½å¤ªå¤§ä»¥è‡³äºäº§ç”Ÿå´©åã€‚ç›¸æ¯”äºæ¯”TRPOï¼ŒPPOå®ç°èµ·æ¥æ›´ç®€å•ï¼Œæ³›åŒ–èƒ½åŠ›æ›´å¼ºï¼Œå¯ä»¥ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰è¿›è¡Œä¼˜åŒ–ã€‚</p><a id="more"></a><h2><span id="èƒŒæ™¯">èƒŒæ™¯</span></h2><p>PPOçš„èƒŒæ™¯ä¸<a href="https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/#èƒŒæ™¯">TRPOçš„èƒŒæ™¯</a>ä¸€è‡´ï¼Œæœ€ç»ˆTRPOæ¨å¯¼å‡ºå¦‚ä¸‹çš„å¸¦çº¦æŸä¼˜åŒ–é—®é¢˜ï¼š <span class="math display">\[\max_{\theta}\mathbb{E}_t[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t]\\\text{subject to }\mathbb{E}_t[\text{KL}[\pi_{\theta_{old}}(\cdot|s_t), \pi_\theta(\cdot|s_t)]]\]</span> ä»¤ <span class="math inline">\(r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\)</span> ä¸ºæ–°æ—§ç­–ç•¥çš„æ¦‚ç‡æ¯”ï¼ˆæ˜“çŸ¥ <span class="math inline">\(r_t(\theta_{old}) = 1\)</span>ï¼‰ã€‚TRPOæœ€å¤§åŒ–çš„æ›¿ä»£ç›®æ ‡ï¼ˆsurrogate objectiveï¼‰å¯ä»¥å†™ä¸ºå¦‚ä¸‹å½¢å¼ï¼š <span class="math display">\[L^{CPI}(\theta)=\mathbb{E}_t[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t]=\mathbb{E}_t[r_t(\theta)A_t]\]</span> å¦‚æœä¸åŠ çº¦æŸçš„è¯ï¼Œç›´æ¥ä¼˜åŒ–è¯¥ç›®æ ‡ä¼šäº§ç”Ÿå·¨å¤§çš„æ›´æ–°ï¼Œå¯¼è‡´æ›´æ–°ä¸ç¨³å®šç”šè‡³å´©æºƒã€‚æ‰€ä»¥éœ€è¦è€ƒè™‘ä¸€ç§æƒ©ç½šæ–¹æ³•ï¼Œä½¿ <span class="math inline">\(r_t(\theta)\)</span> æ¥è¿‘ <span class="math inline">\(1\)</span>ã€‚</p><h2><span id="ppo-clip">PPO-Clip</span></h2><p>PPO-Clipçš„ç›®æ ‡å‡½æ•°ä¸ºï¼š <span class="math display">\[L^{CLIP}(\theta)=\mathbb{E}_t[\min(r_t(\theta)A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)A_t)]\]</span> å…¶ä¸­ <span class="math inline">\(\epsilon\)</span> ä¸ºè¶…å‚æ•°æ§åˆ¶æˆªæ–­ç‡ï¼Œå–å€¼é€šå¸¸æ¯”è¾ƒå°ï¼ˆ0.2å·¦å³ï¼‰ã€‚</p><p>ä¸Šè¿°ç›®æ ‡å‡½æ•°çš„ç¬¬ä¸€é¡¹ä¸ <span class="math inline">\(L^{CPI}\)</span> ä¸€è‡´ï¼Œç¬¬äºŒé¡¹åˆ™æ˜¯ä¸ºäº†é™åˆ¶æ›´æ–°å¹…åº¦ï¼ˆæ–½åŠ æƒ©ç½šï¼‰ï¼Œæ§åˆ¶ <span class="math inline">\(r_t(\theta) \in [1-\epsilon, 1+\epsilon]\)</span>ã€‚å¯è§ <span class="math inline">\(L^{CLIP}(\theta)\)</span> æ˜¯ <span class="math inline">\(L^{CPI}(\theta)\)</span> çš„ä¸€ä¸ªä¸‹ç•Œã€‚</p><p><img src="/images/lclip.png"></p><p>ä¸Šå›¾æ˜¾ç¤ºäº† <span class="math inline">\(\text{clip}\)</span> å‡½æ•°çš„å·¥ä½œæ–¹å¼ï¼š</p><ul><li>å½“ <span class="math inline">\(A &gt; 0\)</span> æ—¶ï¼Œå¦‚æœæƒ³ä½¿ç›®æ ‡å‡½æ•°å–å¾—æ›´å¤§çš„å€¼ï¼Œå°±éœ€è¦å¢å¤§ <span class="math inline">\(\pi_\theta(a_t|s_t)\)</span> çš„å€¼ï¼Œä¹Ÿå°±æ˜¯å¢å¤§ <span class="math inline">\(r_t(\theta)\)</span> ã€‚ä½†æ˜¯å¼ä¸­çš„ <span class="math inline">\(\min\)</span> å‡½æ•°é™åˆ¶äº† <span class="math inline">\(r_t(\theta)\)</span> æœ€å¤§å–åˆ° <span class="math inline">\(1+\epsilon\)</span>ï¼Œæ‰€ä»¥æ–°ç­–ç•¥å†è¿œç¦»æ—§ç­–ç•¥ï¼ˆ<span class="math inline">\(r_t(\theta)\)</span> ç»§ç»­å¢å¤§ï¼‰å¹¶ä¸ä¼šå¸¦æ¥æ›´å¤šåœ°å¥½å¤„ã€‚</li><li>å½“ <span class="math inline">\(A &lt; 0\)</span> æ—¶ï¼Œå¦‚æœæƒ³ä½¿ç›®æ ‡å‡½æ•°å–å¾—æ›´å¤§çš„å€¼ï¼Œå°±éœ€è¦å‡å° <span class="math inline">\(\pi_\theta(a_t|s_t)\)</span> çš„å€¼ï¼Œä¹Ÿå°±æ˜¯å‡å° <span class="math inline">\(r_t(\theta)\)</span> ã€‚ä½†æ˜¯å¼ä¸­çš„ <span class="math inline">\(\min\)</span> å‡½æ•°é™åˆ¶äº† <span class="math inline">\(r_t(\theta)\)</span> æœ€å°å–åˆ° <span class="math inline">\(1-\epsilon\)</span>ï¼Œæ‰€ä»¥æ–°ç­–ç•¥å†è¿œç¦»æ—§ç­–ç•¥ï¼ˆ<span class="math inline">\(r_t(\theta)\)</span> ç»§ç»­å‡å°ï¼‰å¹¶ä¸ä¼šå¸¦æ¥æ›´å¤šåœ°å¥½å¤„ã€‚</li></ul><p>åœ¨å®ç°ä¸­ï¼Œç›®æ ‡å‡½æ•°é€šå¸¸ä½¿ç”¨æ›´ç®€å•çš„å½¢å¼ï¼š <span class="math display">\[L^{CLIP}(s, a, \theta_k, \theta)=\min(\frac{\pi_\theta(a|s)}{\pi_{\theta_{k}}(a|s)}A^{\pi_{\theta_k}}(s, a), g(\epsilon, A^{\pi_{\theta_k}}(s, a)))\]</span> å…¶ä¸­ï¼Œ <span class="math display">\[g(\epsilon, A^{\pi_{\theta_k}}(s, a))=\begin{cases} (1+\epsilon)A,  &amp; \mbox{if }A â‰¥0 \\(1-\epsilon)A, &amp; \mbox{if }A&lt;0\end{cases}\]</span></p><blockquote><p>æ³¨ï¼šå³ä¾¿å¯¹ <span class="math inline">\(r_t(\theta)\)</span> åŠ ä¸Šæˆªæ–­ï¼Œæ–°ç­–ç•¥ä»æŸ“æœ‰å¯èƒ½åç¦»æ—§ç­–ç•¥å¾ˆè¿œï¼Œä¸è¿‡æœ‰å¾ˆå¤štrickæ¥å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚å…¶ä¸­ä¸€ä¸ªç‰¹åˆ«ç®€å•çš„å¤„ç†æ–¹å¼å°±æ˜¯ï¼šå¦‚æœæ–°ç­–ç•¥å’Œæ—§ç­–ç•¥çš„å¹³å‡KLè·ç¦»å¤§äºæŸä¸ªé˜ˆå€¼ï¼Œåˆ™åœæ­¢è¿›è¡Œæ›´æ–°ï¼ˆ<strong>early stopping</strong>ï¼‰ã€‚</p></blockquote><p>ç›¸æ¯”äºTRPOï¼Œç”±äºæ²¡æœ‰äº†KLçº¦æŸï¼ŒPPOå¯ä»¥ç”¨SGDæ¥è¿›è¡Œä¼˜åŒ–ï¼Œå®ç°ç®€å•å¾ˆå¤šã€‚</p><p><strong>PPO-Clipç®—æ³•</strong></p><p><img src="/images/ppo_algo.svg"></p><h2><span id="ppo-penalty">PPO-Penalty</span></h2><p>è¿™ç§æ–¹æ³•ä½¿ç”¨KLè·ç¦»ä½œä¸ºæƒ©ç½šé¡¹ï¼Œå…³é”®åœ¨äºæ±‚å‡ºèƒ½å¤Ÿè‡ªé€‚åº”å¤šç§ä»»åŠ¡çš„æƒ©ç½šå› å­ <span class="math inline">\(\beta\)</span>ã€‚ç®—æ³•çš„é€»è¾‘ä¸ºï¼Œåœ¨æ¯æ¬¡ç­–ç•¥è¿›è¡Œæ›´æ–°æ—¶ï¼š</p><ul><li><p>ä½¿ç”¨SGDä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼š <span class="math display">\[L^{KLPEN}(\theta)=\mathbb{E}_t\left[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t-\beta\cdot\text{KL}[\pi_{old}(a_t|s_t), \pi_\theta(a_t|s_t)]\right]\]</span></p></li><li><p>è®¡ç®— <span class="math inline">\(d = \mathbb{E}\left[\text{KL}[\pi_{\theta_{old}}(\cdot|s_t), \pi_\theta(\cdot|s_t)]\right]\)</span></p><ul><li>å¦‚æœ <span class="math inline">\(d &lt; d_{targ}/1.5\)</span>ï¼Œåˆ™ <span class="math inline">\(\beta \leftarrow \beta/2\)</span></li><li>å¦‚æœ <span class="math inline">\(d &gt; d_{targ} \times 1.5\)</span>ï¼Œåˆ™ <span class="math inline">\(\beta \leftarrow\beta \times 2\)</span></li></ul><p>å…¶ä¸­ï¼Œ<span class="math inline">\(d_{targ}\)</span> ä¸ºè¶…å‚æ•°ã€‚</p></li></ul><blockquote><p>æ³¨ï¼šPPO-Penalty æ²¡æœ‰ PPO-Clip æ•ˆæœå¥½ã€‚</p></blockquote><h2><span id="å®éªŒå’Œæ€»ç»“">å®éªŒå’Œæ€»ç»“</span></h2><p><strong>ç‰¹ç‚¹</strong></p><ul><li>è®­ç»ƒç¨³å®š</li><li>é€šè¿‡é™åˆ¶ <span class="math inline">\(r_t(\theta)\)</span> æ¥æ‰¾åˆ°å°½å¯èƒ½å¤§çš„å¹¶ä¸”åˆç†çš„æ­¥é•¿</li><li>on-policy ç®—æ³•</li><li>å¯ç”¨äºç¦»æ•£å’Œè¿ç»­çš„åŠ¨ä½œç©ºé—´</li><li>ç›¸æ¯”äºTRPOï¼ŒPPOå®ç°ç®€å•ï¼Œæ•ˆæœæ›´å¥½</li></ul><p><strong>å®éªŒæ€§èƒ½</strong></p><p>åœ¨å¤§éƒ¨åˆ† MuJoCo ç¯å¢ƒä¸­å¼ºäºå…¶ä»–ç­–ç•¥æ¢¯åº¦ç±»ç®—æ³•ï¼Œåœ¨Atariç¯å¢ƒä¸­ï¼Œè¡¨ç°ä»…æ¬¡äºACERï¼Œä½†æ˜¯å­¦ä¹ é€Ÿåº¦ä¼˜äºACERã€‚</p><p><img src="/images/ppo_mujoco.png"></p><p><img src="/images/ppo_atari.png"></p><h3><span id="ä»£ç ">ä»£ç </span></h3><p>è‡ªå·±ä¹Ÿå®ç°äº†ä¸€ä¸‹PPO-Clipç®—æ³•ï¼Œä»£ç åœ¨<a href="https://github.com/NeymarL/Pacman-RL/blob/master/src/ppo.py" target="_blank" rel="noopener">è¿™é‡Œ</a>ã€‚ä¸‹å›¾æ˜¾ç¤ºäº†åœ¨ OpenAI <a href="https://gym.openai.com/" target="_blank" rel="noopener">Gym</a> ä¸Šçš„ <code>MsPacman-ram-v0</code> ç¯å¢ƒä¸Šçš„æµ‹è¯•ç»“æœï¼š</p><p><img src="/images/ppo_pacman.png"></p><p><img src="/images/sample1.gif"></p><p><img src="/images/sample2.gif"></p><h2><span id="references">References</span></h2><p>[1] https://arxiv.org/abs/1707.06347</p><p>[2] https://spinningup.openai.com/en/latest/algorithms/ppo.html</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> PPO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Trust Region Policy Optimization (TRPO)</title>
      <link href="/2018/11/22/RL%20-%20TRPO/"/>
      <url>/2018/11/22/RL%20-%20TRPO/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1502.05477" target="_blank" rel="noopener">Trust Region Policy Optimization (TRPO)</a>ç®—æ³•æ˜¯ç”±ä¼¯å…‹åˆ©å¤§å­¦çš„Schulmanç­‰äººäº2015å¹´æå‡ºçš„ç­–ç•¥æ¢¯åº¦ï¼ˆPolicy Gradientsï¼‰ç®—æ³•ã€‚TRPOé€šè¿‡æœ€å¤§åŒ–æ–°ç­–ç•¥ç›¸å¯¹äºå½“å‰ç­–ç•¥çš„ä¼˜åŠ¿æ¥ä¿è¯æ¯æ¬¡æ›´æ–°éƒ½æ˜¯å•è°ƒé€’å¢çš„ï¼ˆç¨³å®šï¼‰ï¼ŒåŒæ—¶æ‰¾åˆ°å°½å¯èƒ½å¤§çš„æ›´æ–°æ­¥å¹…ã€‚ç®—æ³•æ¨å¯¼å‡ºçš„æœ€ç»ˆç»“æœæ˜¯åœ¨KLçº¦æŸä¸‹æœ€å¤§åŒ–æ›¿ä»£ä¼˜åŠ¿å‡½æ•°ã€‚</p><a id="more"></a><h2><span id="èƒŒæ™¯">èƒŒæ™¯</span></h2><p>è€ƒè™‘ç»å…¸çš„ MDP<span class="math inline">\(&lt;S, A, P, r, \rho_0, \gamma&gt;\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(S\)</span> æ˜¯æ‰€æœ‰çŠ¶æ€ï¼ˆstateï¼‰çš„é›†åˆï¼Œ<span class="math inline">\(A\)</span> æ˜¯æ‰€æœ‰åŠ¨ä½œï¼ˆactionï¼‰çš„é›†åˆï¼Œ<span class="math inline">\(P: S\times A\times S \rightarrow \mathbb{R}\)</span> æ˜¯è½¬ç§»æ¦‚ç‡åˆ†å¸ƒï¼Œ<span class="math inline">\(r\)</span> æ˜¯å¥–åŠ±ï¼ˆrewardï¼‰å‡½æ•°ï¼Œ<span class="math inline">\(\rho_0\)</span> æ˜¯åˆå§‹çŠ¶æ€ï¼ˆ<span class="math inline">\(s_0\)</span>ï¼‰åˆ†å¸ƒï¼Œ<span class="math inline">\(\gamma\)</span> æ˜¯æŠ˜æ‰£å› å­ï¼ˆ discount factorï¼‰ã€‚</p><p>å®šä¹‰ <span class="math inline">\(\pi\)</span> ä¸ºä¸€ä¸ªéšæœºç­–ç•¥ï¼š<span class="math inline">\(\pi: S\times A\rightarrow [0, 1]\)</span>ï¼Œå®šä¹‰ <span class="math inline">\(\eta(\pi)\)</span> æ¥è¡¡é‡ç­–ç•¥ <span class="math inline">\(\pi\)</span> çš„å¥½åï¼š <span class="math display">\[\eta(\pi)=\mathbb{E}_{s_0, a_0, ...\sim\pi}[\sum_{t=0}^\infty\gamma^tr(s_t)]\]</span> æ¥ç€å®šä¹‰ state-action value function <span class="math inline">\(Q_\pi\)</span>, value function <span class="math inline">\(V_\pi\)</span>, ä¼˜åŠ¿å‡½æ•°ï¼ˆadvantage functionï¼‰<span class="math inline">\(A_\pi\)</span>: <span class="math display">\[Q_\pi(s_t, a_t) = \mathbb{E}_{s_{t+1}, a_{t+1}, ...\sim\pi}[\sum_{l=0}^\infty\gamma^lr_{s_{t+l}}]\]</span></p><p><span class="math display">\[V_\pi(s_t) =\mathbb{E}_{a_t, s_{t+1}, ...\sim\pi}[\sum_{l=0}^\infty\gamma^lr_{s_{t+l}}]\]</span></p><p><span class="math display">\[A_\pi(s, a) = Q_\pi(s, a) - V_\pi(s)\]</span></p><p>ç„¶åå¯ä»¥é€šè¿‡ä¸‹å¼æ¥è¡¡é‡ç­–ç•¥ <span class="math inline">\(\tilde{\pi}\)</span> ç›¸å¯¹äºç­–ç•¥ <span class="math inline">\(\pi\)</span> çš„ä¼˜åŠ¿ï¼ˆè¯æ˜è¯¦è§è®ºæ–‡ï¼‰ï¼š <span class="math display">\[\begin{align}\eta(\tilde{\pi})&amp;=\eta(\pi)+\mathbb{E}_{s_0, a_0, ...\sim\color{red}{\tilde{\pi}}}[\sum_{t=0}^\infty\gamma^tA_\pi(s_t,a_t)]\\&amp;= \eta(\pi)+\sum_s\color{red}{\rho_\tilde{\pi}(s)}\sum_a\tilde{\pi}(a|s)A_\pi(s, a)\end{align}\]</span> å…¶ä¸­ <span class="math inline">\(\rho_\pi\)</span> ä¸ºç­–ç•¥ <span class="math inline">\(\pi\)</span> çš„æŠ˜æ‰£è®¿é—®é¢‘ç‡ï¼ˆdiscounted visitation frequencyï¼‰ï¼š <span class="math display">\[\rho_\pi(s) = P(s_0=s)+\gamma P(s_1=s) + \gamma^2 P(s_2=s)+...\]</span> é€šè¿‡ä¸Šå¼å¯çŸ¥ï¼Œåªè¦æ¯ä¸ªçŠ¶æ€ <span class="math inline">\(s\)</span> çš„æœŸæœ›ä¼˜åŠ¿éè´Ÿï¼Œå³ <span class="math inline">\(\sum_a\tilde{\pi}(a|s)A_\pi(s, a)&gt;0\)</span>ï¼Œå°±å¯ä»¥ä¿è¯æ›´æ–°æ˜¯å•è°ƒéé€’å‡çš„ï¼Œè¿™å…¶å®å°±æ˜¯ç»å…¸çš„<a href="https://www.52coding.com.cn/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/">ç­–ç•¥è¿­ä»£ï¼ˆpolicy iterationï¼‰</a>çš„æ›´æ–°æ–¹å¼ã€‚ç„¶è€Œï¼Œç”±äº <span class="math inline">\(\rho_\tilde{\pi}(s)\)</span> çš„å­˜åœ¨ï¼Œå¯¼è‡´ç›´æ¥ä¼˜åŒ–ä¸Šå¼å¾ˆå›°éš¾ï¼Œæ‰€ä»¥å¼•å…¥ä¸€ä¸ª<strong>æ›¿ä»£ä¼˜åŠ¿</strong>ï¼ˆsurrogate advantageï¼‰ï¼š <span class="math display">\[\begin{align}L_\pi(\tilde{\pi})&amp;=\eta(\pi)+\sum_s\color{red}{\rho_\pi(s)}\sum_a\tilde{\pi}(a|s)A_\pi(s, a)\\\end{align}\]</span> ç»è¿‡ä¸€ç³»åˆ—æ¨å¯¼ï¼Œå¯ä»¥å¾—åˆ°ç­–ç•¥ <span class="math inline">\(\tilde{\pi}\)</span> çš„ä¼˜åŠ¿ä¸‹ç•Œï¼š <span class="math display">\[\eta(\tilde{\pi})â‰¥L_\pi(\tilde{\pi})-C\cdot D_{KL}^\max(\pi, \tilde{\pi})\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(C=\frac{4\epsilon\gamma}{(1-\gamma)^2}\)</span>ï¼Œ<span class="math inline">\(D_{KL}^\max\)</span> æ˜¯æœ€å¤§çš„KLæ•£åº¦ã€‚</p><p>è¿™é‡Œç›¸å½“äºå¯¹ä¼˜åŒ–ç›®æ ‡ <span class="math inline">\(L_\pi(\tilde{\pi})\)</span> è¿›è¡Œäº†æƒ©ç½šï¼Œæƒ©ç½šå› å­ä¸º <span class="math inline">\(C\)</span>ï¼Œæƒ©ç½šé¡¹ä¸ºKLæ•£åº¦ï¼Œç›®çš„æ˜¯é™åˆ¶æ–°æ—§ç­–ç•¥çš„å·®è·ã€‚é€šè¿‡æœ€å¤§åŒ–ä¸Šè¿°å…¬å¼ï¼Œå°±èƒ½æœ€å¤§åŒ–æ–°ç­–ç•¥ <span class="math inline">\(\tilde{\pi}\)</span> æ‰€å¾—åˆ°çš„å¥–åŠ±ï¼ŒåŒæ—¶åˆä¸ä¼šç¦»æ—§ç­–ç•¥ <span class="math inline">\(\pi\)</span> å¤ªè¿œï¼ˆå¯¼è‡´å¯¹å½“å‰æ•°æ®è¿‡æ‹Ÿåˆï¼‰ï¼Œç®—æ³•å¦‚ä¸‹ï¼š</p><p><img src="/images/IMG_1925FD469BD9-1.jpeg"></p><h2><span id="trpo">TRPO</span></h2><p>ç”±äºDeep RLéƒ½æ˜¯ä½¿ç”¨å‚æ•°ä¸º <span class="math inline">\(\theta\)</span> çš„ç¥ç»ç½‘ç»œæ¥æ‹Ÿåˆç­–ç•¥ <span class="math inline">\(\pi_\theta\)</span>ï¼Œä¸ºäº†ä½¿å…¬å¼æ›´ç®€æ´ï¼ŒæŠŠç®—æ³•1ä¸­å…¬å¼çš„ <span class="math inline">\(\pi\)</span> æ›¿æ¢æˆ <span class="math inline">\(\theta\)</span>: <span class="math display">\[\theta = \arg\max_{\theta}[L(\theta_{old}, \theta)-C\cdot D_{KL}^\max(\theta_{old}|| \theta)]\]</span> å…¶ä¸­ï¼Œ <span class="math display">\[\begin{align}L(\theta_{old}, \theta) &amp;= \sum_s\rho_{\theta_{old}}(s)\sum_a\pi_\theta(a|s)A_{\theta_{old}}(s,a) \\&amp;= \mathbb{E}_{s,a\sim\pi_{\theta_{old}}}[\frac{\pi_\theta(a|s)}{\pi_{\theta_{old}}(a|s)}A_{\theta_{old}}(s,a)]\end{align}\]</span> TRPOæ˜¯ç®—æ³•1çš„è¿‘ä¼¼ï¼ŒåŒºåˆ«åœ¨äºï¼šTRPOæ²¡æœ‰ä½¿ç”¨æƒ©ç½šé¡¹ <span class="math inline">\(C\)</span>ï¼Œè€Œæ˜¯ä½¿ç”¨ KLæ•£åº¦çº¦æŸï¼ˆi.e. trust region constraintï¼‰ï¼š <span class="math display">\[\theta = \arg\max_\theta L(\theta_{old}, \theta)\\\text{ s.t. }\bar{D}_{KL}(\theta||\theta_{old})â‰¤\delta\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\bar{D}_{KL}\)</span> æ˜¯å¹³å‡KLæ•£åº¦ï¼š <span class="math display">\[\bar{D}_{KL}(\theta||\theta_{old})=\mathbb{E}_{s\sim\pi_{\theta_{old}}}[D_{KL}(\pi_{\theta}(\cdot|s)||\pi_{\theta_{old}}(\cdot|s))]\]</span> ç„¶è€Œä¸Šé¢çš„å¸¦çº¦æŸä¼˜åŒ–ä¹Ÿå¹¶éå®¹æ˜“ï¼Œæ‰€ä»¥TRPOå¯¹ä¸Šå¼è¿›è¡Œäº†ä¸€äº›è¿‘ä¼¼ï¼Œå¯¹ç›®æ ‡å‡½æ•°å’Œçº¦æŸè¿›è¡Œæ³°å‹’å±•å¼€å¯ä»¥å¾—åˆ°ï¼š <span class="math display">\[L(\theta_{old}, \theta) \approx g^T(\theta-\theta_{old})\]</span></p><p><span class="math display">\[\bar{D}_{KL}(\theta||\theta_{old})\approx \frac{1}{2}(\theta-\theta_{old})^TH(\theta-\theta_{old})\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(g\)</span> æ˜¯æ›¿ä»£å‡½æ•°çš„æ¢¯åº¦åœ¨ <span class="math inline">\(\theta=\theta_{old}\)</span> å¤„çš„å€¼ï¼Œå‡‘å·§çš„æ˜¯ï¼Œå®ƒå’Œç­–ç•¥æ¢¯åº¦çš„å€¼æ­£å¥½ç›¸ç­‰ï¼š<span class="math inline">\(g = \triangledown_\theta J(\pi_\theta)|_{\theta_{old}}\)</span>ï¼›<span class="math inline">\(H\)</span> æ˜¯å¯¹äº <span class="math inline">\(\theta\)</span> çš„æµ·æ£®çŸ©é˜µï¼ˆHessian matrixï¼‰ã€‚</p><p>äºæ˜¯å¾—åˆ°å¦‚ä¸‹çš„è¿‘ä¼¼ä¼˜åŒ–é—®é¢˜ï¼š <span class="math display">\[\theta_{k+1}=\arg\max_\theta g^T(\theta-\theta_k)\\\text{s.t. }\frac{1}{2}(\theta-\theta_k)^TH(\theta-\theta_k)â‰¤\delta\]</span> é€šè¿‡æ‹‰æ ¼æœ—æ—¥æ³•æ±‚è§£ä¸Šè¿°çº¦æŸä¼˜åŒ–é—®é¢˜å¾—ï¼š <span class="math display">\[\theta_{k+1}=\theta_k+\sqrt{\frac{2\delta}{g^TH^{-1}g}}H^{-1}g\]</span> è¿™ä¸ªå°±æ˜¯ <a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" target="_blank" rel="noopener">Natural Policy Gradient</a> çš„æ›´æ–°å…¬å¼ã€‚ä¸è¿‡ï¼Œç”±äºæ³°å‹’è¿‘ä¼¼å¼•å…¥äº†è¯¯å·®ï¼Œä¸Šå¼çš„è§£å¯èƒ½ä¸æ»¡è¶³ KL çº¦æŸï¼Œæ‰€ä»¥ TRPO å¢åŠ äº†ä¸€ä¸ªçº¿æ€§æœç´¢ï¼ˆbacktracking line searchï¼‰ï¼š <span class="math display">\[\theta_{k+1}=\theta_k+\alpha^j\sqrt{\frac{2\delta}{g^TH^{-1}g}}H^{-1}g\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\alpha\in(0,1)\)</span> æ˜¯å›æº¯ç³»æ•°ï¼ˆbacktracking coefficientï¼‰ï¼Œ<span class="math inline">\(j\)</span> æ˜¯æœ€å°çš„éè´Ÿæ•´æ•°ä½¿å¾— <span class="math inline">\(\pi_{\theta_{k+1}}\)</span> æ»¡è¶³ KL çº¦æŸå¹¶ä¸”äº§ç”Ÿ<strong>æ­£</strong>çš„æ›¿ä»£ä¼˜åŠ¿ï¼Œè¿™æ ·å°±å¯ä»¥ä¿è¯è®­ç»ƒè¿›æ­¥æ˜¯å•è°ƒçš„ã€‚</p><p>æœ€åï¼Œè®¡ç®—å’Œå­˜å‚¨ <span class="math inline">\(H^{-1}\)</span> çš„å¼€é”€æ˜¯å¾ˆå¤§çš„ï¼Œå°¤å…¶æ˜¯ç¥ç»ç½‘ç»œçš„å‚æ•°åŠ¨ä¸åŠ¨å°±å‡ Mã€‚TRPO ä½¿ç”¨<a href="https://www.wikiwand.com/en/Conjugate_gradient_method" target="_blank" rel="noopener">å…±è½­æ¢¯åº¦æ³•ï¼ˆconjugate gradientï¼‰</a>æ¥è§£ <span class="math inline">\(Hx = g\)</span>ï¼Œè¿™æ ·å°±ä¸ç”¨ç›´æ¥è®¡ç®—å’Œå­˜å‚¨ <span class="math inline">\(H\)</span>ã€‚</p><p>æœ€ç»ˆçš„æ›´æ–°å…¬å¼ä¸ºï¼š <span class="math display">\[\theta_{k+1}=\theta_k+\alpha^j\sqrt{\frac{2\delta}{\hat{x}^TH\hat{x}}}\hat{x}\]</span> å…¶ä¸­ï¼Œ <span class="math display">\[\begin{align}\hat{x}&amp;\approx H^{-1}g &amp; \text{(using conjugate gradient)}\end{align}\]</span></p><p><span class="math display">\[H\hat{x} = \triangledown_\theta((\triangledown_\theta\bar{D}_{KL}(\theta||\theta_k))^T\hat{x})\]</span></p><p><strong>TRPOç®—æ³•</strong></p><p><img src="/images/trpo.svg"></p><h2><span id="performance">Performance</span></h2><p><strong>TRPOçš„ä¸€äº›ç‰¹ç‚¹</strong></p><ul><li>ä¿è¯æ¯æ¬¡æ›´æ–°åœ¨å½“å‰è®­ç»ƒæ•°æ®ä¸Šéƒ½æ˜¯è¿›æ­¥çš„ï¼Œè®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®š</li><li>é€šè¿‡æ»¡è¶³KLçº¦æŸæ¥æ‰¾å°½å¯èƒ½å¤§çš„æ­¥é•¿</li><li>on-policy ç®—æ³•</li><li>å¯ç”¨äºç¦»æ•£å’Œè¿ç»­çš„åŠ¨ä½œç©ºé—´</li><li>ç®—æ³•è¾ƒä¸ºå¤æ‚</li></ul><p><strong>å®éªŒæ€§èƒ½</strong></p><p>åœ¨æ¨¡æ‹Ÿæœºå™¨äººèµ°è·¯ã€æ¸¸æ³³ç­‰ä»»åŠ¡ä¸­å–å¾—äº†åœ¨å½“æ—¶ä¸é”™çš„æ•ˆæœï¼›åœ¨é€šè¿‡è§†é¢‘è¾“å…¥ç©Atariæ¸¸æˆçš„ä»»åŠ¡ä¸­è¡¨ç°ä¸å¦‚DQNç­‰æ–¹æ³•ã€‚</p><p><img src="/images/trpo_per.jpg"></p><p>ä¸‹å›¾æ˜¯æˆ‘åœ¨ OpenAI <a href="https://gym.openai.com/" target="_blank" rel="noopener">Gym</a> çš„ <code>Walker2d-v2</code> å’Œ <code>MsPacman-ram-v0</code> ä¸­æµ‹è¯•çš„ç»“æœã€‚</p><p><img src="/images/walker.png"></p><p><img src="/images/pacman.png"></p><h2><span id="references">References</span></h2><p>[1] https://arxiv.org/abs/1502.05477</p><p>[2] https://spinningup.openai.com/en/latest/algorithms/trpo.html</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> TRPO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - DQN &amp; A3C &amp; GAE</title>
      <link href="/2018/11/16/RL%20-%20DQN%20and%20A3C/"/>
      <url>/2018/11/16/RL%20-%20DQN%20and%20A3C/</url>
      
        <content type="html"><![CDATA[<h2><span id="deep-q-network">Deep Q-Network</span></h2><p>Deep Q-Network (<a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" target="_blank" rel="noopener">DQN</a>) æ˜¯ç”±DeepMindçš„Mnihç­‰äººäº2013å¹´æå‡ºçš„ç®—æ³•ï¼Œè¯¥ç®—æ³•æˆåŠŸæŠŠæ·±åº¦å­¦ä¹ åº”ç”¨åˆ°äº†RLé¢†åŸŸï¼Œå¹¶ï¼ˆä¸€å®šç¨‹åº¦ä¸Šï¼‰è§£å†³äº†è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ï¼Œåœ¨ç©Atariæ¸¸æˆä¸­å–å¾—äº†éå¸¸å¥½çš„ç»“æœã€‚</p><p>æ–‡ç« æŒ‡å‡ºä½¿ç”¨éçº¿æ€§å‡½æ•°æ‹Ÿåˆ Q-value çš„RLç®—æ³•ä¸ç¨³å®šä¸»è¦å› ä¸ºï¼š</p><ol type="1"><li>åŒä¸€ä¸ªè§‚æµ‹åºåˆ—ä¸­çš„æ•°æ®ç›¸å…³æ€§è¾ƒå¤§</li><li>å½“ Q-value å‘ç”Ÿäº†å¾ˆå°çš„æ”¹å˜ï¼Œå¯èƒ½å¯¼è‡´æ•´ä¸ªç­–ç•¥ï¼ˆpolicyï¼‰å‘ç”Ÿè¾ƒå¤§å˜åŒ–ï¼Œä»è€Œå¯¼è‡´ Q-value å’Œç›®æ ‡ <span class="math inline">\(r + \gamma * \max_{a&#39;}Q(s&#39; ,a&#39;)\)</span> çš„å·®è·ä¸ç¨³å®š</li></ol><a id="more"></a><p>DQNä½¿ç”¨äº†ä¸¤ä¸ªtrickæ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼š</p><ul><li>Experience replay<ul><li>ä½¿ç”¨ç»éªŒæ± ç¼“å­˜æ•°æ®ï¼Œæ¯æ¬¡è®­ç»ƒæ—¶ä»ç»éªŒæ± é‡Œsampleæ•°æ®ï¼Œä»è€Œé™ä½è®­ç»ƒæ•°æ®ä¹‹é—´çš„ç›¸å…³æ€§</li></ul></li><li>Two Q networks<ul><li>ä¸€ä¸ªç½‘ç»œç”¨æ¥ç”Ÿæˆ Q-targetï¼Œå¦ä¸€ä¸ªç½‘ç»œè¿›è¡Œæ¢ç´¢ï¼›æ¯éš”ä¸€å®šæ—¶é—´ä¸¤ä¸ªç½‘ç»œè¿›è¡ŒåŒæ­¥</li><li>è¿™æ ·ä½¿å¾— Q-target ç›¸å¯¹ç¨³å®š</li></ul></li></ul><p><strong>æ•´ä½“ç®—æ³•</strong></p><p><img src="/images/dqn.jpg"></p><hr><h2><span id="asynchronous-actor-critic">Asynchronous Actor Critic</span></h2><p>Asynchronous Actor Critic (<a href="https://arxiv.org/abs/1602.01783" target="_blank" rel="noopener">A3C</a>) ä¹Ÿæ˜¯ç”±DeepMindçš„Mnihç­‰äººæå‡ºçš„ç®—æ³•ï¼Œäº2016å¹´å‘è¡¨åœ¨ICMLä¸Šã€‚ä¸åŒäºDQNçš„æ˜¯ï¼ŒA3Cå±äºç­–ç•¥æ¢¯åº¦ï¼ˆPolicy Gradientï¼‰ç±»ç®—æ³•ï¼Œè€ŒDQNæ˜¯åŸºäºvalueçš„ï¼›ç›¸åŒçš„æ˜¯ï¼ŒA3Cä¹Ÿåœ¨Atariæ¸¸æˆä¸Šå–å¾—äº†éå¸¸å¥½çš„ç»“æœï¼ˆå¼ºäºDQNï¼‰ã€‚</p><p>ä½¿ç”¨ä¸Šè¿°ç»éªŒæ± æœ‰ä»¥ä¸‹é—®é¢˜ï¼š</p><ol type="1"><li>ä½¿ç”¨æ›´å¤šçš„å†…å­˜å’Œè®¡ç®—èµ„æº</li><li>åªèƒ½ä½¿ç”¨ <strong>off-policy</strong> çš„RLç®—æ³•ï¼ˆå­¦ä¹  old policy äº§ç”Ÿçš„æ•°æ®ï¼‰</li></ol><p>ä¸ºäº†ä½¿ç”¨ on-policy ç®—æ³•ï¼Œæ–‡ç« æå‡ºäº†ä½¿ç”¨å¼‚æ­¥å­¦ä¹ ä»£æ›¿ç»éªŒæ± çš„æ–¹æ³•ï¼ŒåŒæ—¶ä¹Ÿèƒ½ä¿æŒç®—æ³•çš„ç¨³å®šæ€§ï¼Œå…¶ä¸­ä½¿ç”¨æœ€å¹¿æ³›çš„æ˜¯A3Cç®—æ³•ï¼Œå®ƒå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š</p><ul><li>å¹¶è¡Œåœ°ä½¿ç”¨å¤šä¸ª agent åœ¨å„è‡ªçš„ç¯å¢ƒé‡Œæ¢ç´¢ï¼Œæ¯ä¸ª agent åœ¨åŒä¸€æ—¶åˆ»æ¢ç´¢çš„å†…å®¹å„ä¸ç›¸åŒï¼Œä»è€Œé™ä½äº†æ•°æ®ç›¸å…³æ€§</li><li>åœ¨CPUä¸Šè®­ç»ƒæ›´åŠ é«˜æ•ˆ</li></ul><p><strong>æ•´ä½“ç®—æ³•</strong></p><ol type="1"><li>åŒæ­¥çº¿ç¨‹ä¸“å±ç½‘ç»œï¼ˆ<span class="math inline">\(\theta&#39;, \theta_v&#39;\)</span>ï¼‰å’Œå…¨å±€ç½‘ç»œï¼ˆ<span class="math inline">\(\theta, theta_v\)</span>ï¼‰</li><li>æ¯ä¸ª agent ä½¿ç”¨çº¿ç¨‹ä¸“å±ç½‘ç»œå„è‡ªè¿›è¡Œæ¢ç´¢</li><li>æ ¹æ®çº¿ç¨‹ä¸“å±ç½‘ç»œè®¡ç®—æ¢¯åº¦ï¼š<span class="math inline">\(d\theta, d\theta_v\)</span></li><li>ä½¿ç”¨ <span class="math inline">\(d\theta, d\theta_v\)</span> æ›´æ–°å…¨å±€ç½‘ç»œï¼ˆ<span class="math inline">\(\theta, theta_v\)</span>ï¼‰</li><li>å›åˆ°ç¬¬ä¸€æ­¥</li></ol><p><img src="/images/IMG_25EB14880DD1-1.jpeg"></p><p><strong>å…¶ä»–ç»†èŠ‚</strong></p><ul><li><strong>ä¸»çº¿ç¨‹å‘å­çº¿ç¨‹ä¼ å‚æ•°ï¼Œå­çº¿ç¨‹å‘ä¸»çº¿ç¨‹ä¼ æ¢¯åº¦</strong></li><li>agent å’Œ critic å…±ç”¨ä¸€ä¸ªç½‘ç»œï¼Œè¾“å‡ºåˆ†ä¸ºä¸¤å¤´</li><li>å¢åŠ äº†ç†µæ­£åˆ™åŒ–ï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰<ul><li><span class="math inline">\(\triangledown_{\theta&#39;}\log\pi(a_t|s_t;\theta&#39;)(R_t-V(s_t;\theta_v))+\beta\triangledown_{\theta&#39;}H(\pi(s_t; \theta&#39;))\)</span></li><li><span class="math inline">\(H(X) = E[-\log P(X)]\)</span></li></ul></li><li>ä»£ç å‚è€ƒï¼šhttps://github.com/NeymarL/Pacman-RL/blob/master/src/a3c.py<ul><li><strong>æ³¨</strong>ï¼šè®¡ç®— policy loss ä¸­çš„ advantage çš„æ—¶å€™ä¸èƒ½ä¿ç•™å…¶æ¢¯åº¦ï¼Œå¦åˆ™ policy çš„æ¢¯åº¦ä¼šæµå…¥ value network ä¸­ï¼Œäº§ç”Ÿbug</li></ul></li></ul><hr><h2><span id="generalized-advantage-estimator">Generalized Advantage Estimator</span></h2><p>Generalized Advantage Estimator (<a href="https://arxiv.org/abs/1506.02438" target="_blank" rel="noopener">GAE</a>) æ˜¯ç”±ä¼¯å…‹åˆ©å¤§å­¦çš„Schulmanç­‰äººäº2016å¹´æå‡ºçš„ä¸€ç§æ–°çš„ä¼°è®¡ä¼˜åŠ¿å‡½æ•°ï¼ˆAdvantage functionï¼‰çš„æ–¹æ³•ã€‚</p><p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å®šä¹‰ä¼˜åŠ¿å‡½æ•° <span class="math inline">\(A^\pi(s_t, a_t)\)</span> ä½¿å…¶ç”¨æ¥è®¡ç®—ç­–ç•¥æ¢¯åº¦ï¼š <span class="math display">\[\hat{g}=\mathbb{E}_{s_0, a_0...\sim\pi_\theta}[\sum_{t=0}^\infty A^\pi_t(s_t,a_t)\triangledown_\theta\pi_\theta(a_t|s_t)]\]</span> ä¼˜åŠ¿å‡½æ•°çš„å®šä¹‰ä¸ºï¼š <span class="math display">\[A^\pi(s_t, a_t) = Q^\pi(s_t, a_t) - V^\pi(s_t)\]</span> æˆ‘ä»¬ä½¿ç”¨ <span class="math inline">\(V\)</span> æ¥è¿‘ä¼¼ä»·å€¼å‡½æ•°ï¼ˆvalue functionï¼‰ï¼Œé‚£ä¹ˆ TD(0) error <span class="math inline">\(\delta_t^V = r_t +\gamma V(s_{t+1}-V(s_t))\)</span> å°±æ˜¯ä¼˜åŠ¿å‡½æ•°çš„ä¸€ä¸ªä¼°è®¡ï¼Œå¹¶ä¸”å¦‚æœ <span class="math inline">\(V = V^\pi\)</span>ï¼Œåˆ™ <span class="math inline">\(\delta_t^V\)</span> æ˜¯ <span class="math inline">\(A^\pi\)</span> çš„ä¸€ä¸ªæ— åä¼°è®¡ï¼š <span class="math display">\[\begin{align}\mathbb{E}_{s_{t+1}}[\delta_t^{V^\pi}]&amp;=\mathbb{E}_{s_{t+1}}[r_t+\gamma V^\pi(s_{t+1})-V^\pi(s_t)]\\&amp;= \mathbb{E}_{s_{t+1}}[Q^\pi(s_t,a_t)-V^\pi(s_t)]\\&amp;= A^\pi(s_t,a_t)\end{align}\]</span> åªè¦ <span class="math inline">\(V\)</span> æ˜¯è¿‘ä¼¼çš„ï¼ŒTD(0) errorå°±æ˜¯ä¼˜åŠ¿å‡½æ•°çš„ä¸€ä¸ªæœ‰åä¼°è®¡ï¼Œé‚£ä¹ˆTD(<span class="math inline">\(\lambda\)</span>) erroråˆå¦‚ä½•å‘¢ï¼Ÿ</p><p>é¡ºç€è¿™ä¸ªæ€è·¯ï¼Œæˆ‘ä»¬å¯ä»¥å¤šå¾€åçœ‹å‡ æ­¥ï¼š <span class="math display">\[\begin{array}{lcl}\hat{A}_t^{(1)}&amp;:=\delta_t^V&amp;=-V(s_t)+r_t+\gamma V(s_{t+1})\\\hat{A}_t^{(2)}&amp;:=\delta_t^V + \gamma\delta_{t+1}^V&amp;=-V(s_t)+r_t+\gamma r_{t+1}+\gamma^2 V(s_{t+2})\\\hat{A}_t^{(3)}&amp;:=\delta_t^V + \gamma\delta_{t+1}^V+\gamma^2\delta_{t+2}^V &amp;=-V(s_t)+r_t+\gamma r_{t+1}+\gamma^2 r_{t+2} +\gamma^2 V(s_{t+3}) \\\end{array}\]</span></p><p><span class="math display">\[\hat{A}_t^{k}:=\sum_{l=0}^{k-1}\gamma^l\delta_{t+l}^V=-V(s_t)+r_t+\gamma r_{t+1}+...+\gamma^{k-1}r_{t+k-1}+\gamma^kV(s_{t+k})\]</span></p><p>å¯ä»¥çœ‹åˆ°ï¼Œè™½ç„¶ <span class="math inline">\(\hat{A}_t^{(k)}\)</span> ä¾æ—§æ˜¯æœ‰åä¼°è®¡ï¼Œä½†æ˜¯åå·®éšç€ <span class="math inline">\(k\)</span> çš„å¢å¤§åœ¨é€æ¸å‡å°ï¼Œå› ä¸º <span class="math inline">\(\gamma^kV(s_{t+k})\)</span> è¿™ä¸€é¡¹è¡°å‡çš„è¶Šæ¥è¶Šå‰å®³ã€‚å½“ <span class="math inline">\(k\rightarrow\infty\)</span> æ—¶ï¼š <span class="math display">\[\hat{A}_t^{(\infty)}=\sum_{l=0}^\infty\gamma^l\delta_{t+l}^V=-V(s_t)+\sum_{l=0}^\infty\gamma^lr_{t+l}\]</span> å¯ä»¥çœ‹åˆ°å°±æ˜¯ return å‡å» baselineã€‚</p><p><span class="math inline">\(\text{GAE}(\lambda)\)</span> çš„å®šä¹‰ä¸ºè¿™äº› <span class="math inline">\(k\)</span> æ­¥ä¼°è®¡çš„æŒ‡æ•°å¹³å‡ï¼Œå³ TD(<span class="math inline">\(\lambda\)</span>) errorï¼š <span class="math display">\[\begin{align}\text{GAE}_t(\lambda)&amp;:=(1-\lambda)(\hat{A}_t^{(1)}+\lambda\hat{A}_t^{(2)}+\lambda^2\hat{A}_t^{(3)}+...)\\&amp;=(1-\lambda)(\delta_t^V+\lambda(\delta_t^V-\gamma\delta_{t+1}^V)+...)\\&amp;=\sum_{l=0}^\infty(\gamma\lambda)^l\delta_{t+l}^V\end{align}\]</span> ä»£ç å®ç°</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rews : rewards, vals: values, lam: lambda</span></span><br><span class="line">deltas = rews[:<span class="number">-1</span>] + gamma * vals[<span class="number">1</span>:] - vals[:<span class="number">-1</span>]</span><br><span class="line">adv_buf = discount_cumsum(deltas, gamma * lam)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discount_cumsum</span><span class="params">(x, discount)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    magic from rllab for computing discounted cumulative sums of vectors.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    input: </span></span><br><span class="line"><span class="string">        vector x, </span></span><br><span class="line"><span class="string">        [x0, </span></span><br><span class="line"><span class="string">         x1, </span></span><br><span class="line"><span class="string">         x2]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        [x0 + discount * x1 + discount^2 * x2,  </span></span><br><span class="line"><span class="string">         x1 + discount * x2,</span></span><br><span class="line"><span class="string">         x2]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> scipy.signal.lfilter([<span class="number">1</span>], [<span class="number">1</span>, float(-discount)], x[::<span class="number">-1</span>], axis=<span class="number">0</span>)[::<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><hr><h2><span id="å…¶ä»–">å…¶ä»–</span></h2><h3><span id="batch-normalization">Batch-Normalization</span></h3><p>è§£å†³ç½‘ç»œå±‚æ•°å˜å¤šæ¢¯åº¦<strong>æ¶ˆå¤±</strong>/çˆ†ç‚¸é—®é¢˜</p><ul><li>æ¢¯åº¦æˆªæ–­</li><li>åˆå§‹åŒ–</li><li>RELU</li></ul><p>å¯¹æ¯å±‚ç¥ç»å…ƒå¤„ç†ç»“æœè¿›è¡Œå½’ä¸€åŒ–ï¼Œä½†åˆä¸èƒ½ç ´åä¸Šä¸€å±‚æå–çš„ç‰¹å¾ï¼ˆå˜æ¢é‡æ„ï¼Œå¼•å…¥äº†å¯å­¦ä¹ å‚æ•°<span class="math inline">\(\gamma, \beta\)</span>ï¼‰</p><figure><img src="/images/bn.png" alt="bn"><figcaption>bn</figcaption></figure><p>Inferenceæ—¶ <span class="math inline">\(\mu_B\)</span> å’Œ <span class="math inline">\(\sigma^2_B\)</span> å›ºå®šã€‚</p><p>ä¸ºä»€ä¹ˆä¸ç”¨ç™½åŒ–ï¼Ÿ</p><ul><li>åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œç™½åŒ–æ“ä½œä¼šå¸¦æ¥è¿‡é«˜çš„è®¡ç®—ä»£ä»·å’Œè¿ç®—æ—¶é—´</li></ul><p>åœ¨BNä¸­ï¼Œæ˜¯é€šè¿‡å°†activationè§„èŒƒä¸ºå‡å€¼å’Œæ–¹å·®ä¸€è‡´çš„æ‰‹æ®µä½¿å¾—åŸæœ¬ä¼šå‡å°çš„activationçš„scaleå˜å¤§ã€‚ <span class="math display">\[\frac{\partial h_l}{\partial h_{l-1}} = \frac{\partial BN(w_l h_{l-1})}{\partial h_{l-1}} = \frac{\partial \alpha w_l h_{l-1}}{\partial h_{l-1}}\]</span> å…¶ä¸­ <span class="math inline">\(\alpha\)</span> æŒ‡ç¼©æ”¾ã€‚å¯ä»¥çœ‹åˆ°æ­¤æ—¶åå‘ä¼ æ’­ä¹˜ä»¥çš„æ•°ä¸å†å’Œ <span class="math inline">\(w\)</span> çš„å°ºåº¦ç›¸å…³ï¼Œä¹Ÿå°±æ˜¯è¯´å°½ç®¡æˆ‘ä»¬åœ¨æ›´æ–°è¿‡ç¨‹ä¸­æ”¹å˜ <span class="math inline">\(w\)</span> çš„å€¼ï¼Œä½†æ˜¯åå‘ä¼ æ’­çš„æ¢¯åº¦å´ä¸å—å½±å“ã€‚</p><h3><span id="activation-layers">Activation Layers</span></h3><h4><span id="relu">ReLU</span></h4><figure><img src="/images/relu.png" alt="relu"><figcaption>relu</figcaption></figure><p>æ•´æµçº¿æ€§å•å…ƒæ˜“äºä¼˜åŒ–ï¼Œå› ä¸ºå®ƒä»¬å’Œçº¿æ€§å•å…ƒéå¸¸ç±»ä¼¼ã€‚çº¿æ€§å•å…ƒå’Œæ•´æµçº¿æ€§å•å…ƒçš„å”¯ä¸€åŒºåˆ«åœ¨äºæ•´æµçº¿æ€§å•å…ƒåœ¨å…¶ä¸€åŠçš„å®šä¹‰åŸŸä¸Šè¾“å‡ºä¸ºé›¶ã€‚è¿™ä½¿å¾—åªè¦æ•´æµçº¿æ€§å•å…ƒå¤„äºæ¿€æ´»çŠ¶æ€ï¼Œå®ƒçš„å¯¼æ•°éƒ½èƒ½ä¿æŒè¾ƒå¤§ã€‚å®ƒçš„æ¢¯åº¦ä¸ä»…å¤§è€Œä¸”ä¸€è‡´ã€‚æ•´æµæ“ä½œçš„äºŒé˜¶å¯¼æ•°å‡ ä¹å¤„å¤„ä¸º 0ï¼Œå¹¶ä¸”åœ¨æ•´æµçº¿æ€§å•å…ƒå¤„äºæ¿€æ´»çŠ¶æ€æ—¶ï¼Œå®ƒçš„ä¸€é˜¶å¯¼æ•°å¤„å¤„ä¸º 1ã€‚è¿™æ„å‘³ç€ç›¸æ¯”äºå¼•å…¥äºŒé˜¶æ•ˆåº”çš„æ¿€æ´»å‡½æ•°æ¥è¯´ï¼Œå®ƒçš„æ¢¯åº¦æ–¹å‘å¯¹äºå­¦ä¹ æ¥è¯´æ›´åŠ æœ‰ç”¨ã€‚</p><p>ReLU çš„è¿‡ç¨‹æ›´æ¥è¿‘ç”Ÿç‰©ç¥ç»å…ƒçš„ä½œç”¨è¿‡ç¨‹</p><p><strong>Leaky ReLU</strong></p><p>ReLU åŠå…¶æ‰©å±•éƒ½æ˜¯åŸºäºä¸€ä¸ªåŸåˆ™ï¼Œé‚£å°±æ˜¯å¦‚æœå®ƒä»¬çš„è¡Œä¸ºæ›´æ¥è¿‘çº¿æ€§ï¼Œé‚£ä¹ˆæ¨¡å‹æ›´å®¹æ˜“ä¼˜åŒ–ã€‚ <span class="math display">\[g(z; \alpha) = \max(0, z) + \alpha \min(0, z)\]</span> <span class="math inline">\(\alpha\)</span> ä¸ºå›ºå®šå€¼æˆ–å¯å­¦ä¹ å‚æ•°ã€‚</p><h4><span id="sigmoid-amp-tanh">Sigmoid &amp; Tanh</span></h4><p><img src="/images/sigmoid.png" alt="sigmoid"> <span class="math display">\[g(z) = \frac{1}{1 + e^{-z}}\]</span></p><ul><li>sigmoid å¸¸ä½œä¸ºè¾“å‡ºå•å…ƒç”¨æ¥é¢„æµ‹äºŒå€¼å‹å˜é‡å–å€¼ä¸º 1 çš„æ¦‚ç‡</li><li>sigmoid å‡½æ•°åœ¨è¾“å…¥å–ç»å¯¹å€¼éå¸¸å¤§çš„æ­£å€¼æˆ–è´Ÿå€¼æ—¶ä¼šå‡ºç°<strong>é¥±å’Œ</strong>ï¼ˆsaturateï¼‰ç°è±¡ï¼Œåœ¨å›¾åƒä¸Šè¡¨ç°ä¸ºå¼€å§‹å˜å¾—å¾ˆå¹³ï¼Œæ­¤æ—¶å‡½æ•°ä¼šå¯¹è¾“å…¥çš„å¾®å°æ”¹å˜ä¼šå˜å¾—ä¸æ•æ„Ÿã€‚ä»…å½“è¾“å…¥æ¥è¿‘ 0 æ—¶æ‰ä¼šå˜å¾—æ•æ„Ÿã€‚ä»è€Œä½¿å¾—å­¦ä¹ å˜å›°éš¾ã€‚</li><li>å¦‚æœè¦ä½¿ç”¨ sigmoid ä½œä¸ºæ¿€æ´»å‡½æ•°æ—¶ï¼ˆæµ…å±‚ç½‘ç»œï¼‰ï¼Œtanh é€šå¸¸è¦æ¯” sigmoid å‡½æ•°è¡¨ç°æ›´å¥½ã€‚</li></ul><h3><span id="bagging">Bagging</span></h3><p>æ€æƒ³ï¼šå¤šä¸ªæ¨¡å‹å¹³å‡æ•ˆæœå¥½äºå•ä¸ªæ¨¡å‹</p><p><strong>Baggingï¼ˆbootstrap aggregatingï¼‰</strong>æ˜¯é€šè¿‡ç»“åˆå‡ ä¸ªæ¨¡å‹é™ä½æ³›åŒ–è¯¯å·®çš„æŠ€æœ¯ (Breiman, 1994)ã€‚</p><p>å…·ä½“æ¥è¯´ï¼ŒBagging æ¶‰åŠæ„é€  k ä¸ª<strong>ä¸åŒçš„æ•°æ®é›†</strong>ã€‚æ¯ä¸ªæ•°æ®é›†ä»åŸå§‹æ•°æ®é›†ä¸­<strong>é‡å¤é‡‡æ ·</strong>æ„æˆï¼Œå’ŒåŸå§‹æ•°æ®é›†å…·æœ‰<strong>ç›¸åŒæ•°é‡</strong>çš„æ ·ä¾‹ã€‚è¿™æ„å‘³ç€ï¼Œæ¯ä¸ªæ•°æ®é›†ä»¥é«˜æ¦‚ç‡ç¼ºå°‘ä¸€äº›æ¥è‡ªåŸå§‹æ•°æ®é›†çš„ä¾‹å­ï¼Œè¿˜åŒ…å«è‹¥å¹²é‡å¤çš„ä¾‹å­ï¼ˆæ›´å…·ä½“çš„ï¼Œå¦‚æœé‡‡æ ·æ‰€å¾—çš„è®­ç»ƒé›†ä¸åŸå§‹æ•°æ®é›†å¤§å°ç›¸åŒï¼Œé‚£æ‰€å¾—æ•°æ®é›†ä¸­å¤§æ¦‚æœ‰åŸå§‹æ•°æ®é›† <strong>2/3</strong> çš„å®ä¾‹ï¼‰</p><figure><img src="/images/bagging.png" alt="bagging"><figcaption>bagging</figcaption></figure><p>ç¬¬ä¸€ä¸ªåˆ†ç±»å™¨å­¦åˆ°ä¸Šé¢çš„åœ†åœˆå°±ä¼šè®¤ä¸ºæ•°å­—æ˜¯8ï¼Œç¬¬äºŒä¸ªåˆ†ç±»å™¨æ£€æµ‹åˆ°ä¸‹é¢çš„åœˆå°±ä¼šè®¤ä¸ºæ•°å­—æ˜¯8ï¼ŒæŠŠä¸¤ä¸ªç»“åˆèµ·æ¥å°±çŸ¥é“åªæœ‰å½“ä¸Šä¸‹éƒ½æœ‰åœˆï¼ˆç½®ä¿¡æ¦‚ç‡æœ€å¤§ï¼‰çš„æ—¶å€™æ•°å­—æ‰æ˜¯8ã€‚</p><h3><span id="dropout">Dropout</span></h3><p>ç®€å•æ¥è¯´ï¼ŒDropout (Srivastava et al., 2014) é€šè¿‡<strong>å‚æ•°å…±äº«</strong>æä¾›äº†ä¸€ç§å»‰ä»·çš„ <strong>Bagging</strong> é›†æˆè¿‘ä¼¼ï¼Œèƒ½å¤Ÿè®­ç»ƒå’Œè¯„ä¼°<strong>æŒ‡æ•°çº§æ•°é‡</strong>çš„ç¥ç»ç½‘ç»œã€‚</p><figure><img src="/images/dropout.png" alt="dropout"><figcaption>dropout</figcaption></figure><p><strong>Dropoutä¸Baggingçš„ä¸åŒç‚¹</strong>ï¼š</p><ul><li>Bagging ä¸ºä¸²è¡Œç­–ç•¥ï¼›Dropout ä¸ºå¹¶è¡Œç­–ç•¥</li><li>åœ¨ Bagging çš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½æ˜¯ç‹¬ç«‹çš„ï¼›è€Œåœ¨ Dropout çš„æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹<strong>å…±äº«å‚æ•°</strong>ï¼Œå…¶ä¸­æ¯ä¸ªæ¨¡å‹ç»§æ‰¿çˆ¶ç¥ç»ç½‘ç»œå‚æ•°çš„ä¸åŒå­é›†ã€‚</li><li>åœ¨ Bagging çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸€ä¸ªæ¨¡å‹éƒ½ä¼šåœ¨å…¶ç›¸åº”è®­ç»ƒé›†ä¸Šè®­ç»ƒåˆ°æ”¶æ•›ã€‚è€Œåœ¨ Dropout çš„æƒ…å†µä¸‹ï¼Œé€šå¸¸å¤§éƒ¨åˆ†æ¨¡å‹éƒ½æ²¡æœ‰æ˜¾å¼åœ°è¢«è®­ç»ƒï¼›å–è€Œä»£ä¹‹çš„æ˜¯ï¼Œåœ¨å•ä¸ªæ­¥éª¤ä¸­æˆ‘ä»¬è®­ç»ƒä¸€å°éƒ¨åˆ†çš„å­ç½‘ç»œï¼Œå‚æ•°å…±äº«ä¼šä½¿å¾—å‰©ä½™çš„å­ç½‘ç»œä¹Ÿèƒ½æœ‰å¥½çš„å‚æ•°è®¾å®šã€‚</li></ul>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> DQN </tag>
            
            <tag> Q-learning </tag>
            
            <tag> A3C </tag>
            
            <tag> GAE </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ä¸­å›½è±¡æ£‹ZeroæŠ€æœ¯è¯¦è§£</title>
      <link href="/2018/11/07/CCZero/"/>
      <url>/2018/11/07/CCZero/</url>
      
        <content type="html"><![CDATA[<p><a href="https://cczero.org/" target="_blank" rel="noopener">ä¸­å›½è±¡æ£‹Zeroï¼ˆCCZeroï¼‰</a>æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼ŒæŠŠ<a href="https://arxiv.org/abs/1712.01815" target="_blank" rel="noopener">AlphaZero</a>çš„ç®—æ³•åº”ç”¨åˆ°äº†ä¸­å›½è±¡æ£‹ä¸Šï¼Œæ—¨åœ¨å€ŸåŠ©å¹¿å¤§è±¡æ£‹çˆ±å¥½è€…ä¹‹åŠ›ä¸€èµ·è®­ç»ƒå‡ºä¸€ä¸ªå¯ä»¥æ‰“è´¥æ—‹é£åæ‰‹çš„â€œè±¡æ£‹ä¹‹ç¥â€ã€‚å› ä¸ºç§ç§åŸå› å§ï¼Œè¿™ä¸ªç›®æ ‡åˆ°ç›®å‰ï¼ˆ2018/11/07ï¼‰ä¸ºæ­¢æœªèƒ½å®ç°ï¼Œæˆ–è€…è¯´è¿˜å·®å¾—è¿œï¼Œè€Œè·‘è°±çš„äººä¹Ÿè¶Šæ¥è¶Šå°‘äº†ï¼Œå¾ˆå¯èƒ½åšæŒä¸äº†å¤šä¹…äº†ã€‚</p><p>è™½ç„¶æœªèƒ½å®ç°ç›®æ ‡ï¼Œä½†åœ¨æŠ€æœ¯ä¸Šè¿˜æ˜¯æœ‰ä¸€å®šæ„ä¹‰çš„ï¼Œ<a href="https://github.com/NeymarL/ChineseChess-AlphaZero" target="_blank" rel="noopener">GitHub</a>ä¸Šä¹Ÿæ—¶ä¸æ—¶æœ‰äººè¯¢é—®æŠ€æœ¯ç»†èŠ‚ï¼Œåœ¨æ­¤æ€»ç»“ä¸€ä¸‹ï¼Œè®°å½•ä¸€äº›å‘ä»¥åä¸è¦å†è¸©ã€‚</p><a id="more"></a><h2><span id="æ¨¡å—">æ¨¡å—</span></h2><p>ç¨‹åºä¸»è¦åˆ†ä¸ºä¸‰å¤§æ¨¡å—ï¼ˆæ¯ä¸ªæ¨¡å—å¯¹åº”ä¸€ä¸ªç›®å½•ï¼‰ï¼š</p><ul><li><code>agents</code>ï¼šæ ¸å¿ƒæ¨¡å—ï¼Œå†³å®šå¦‚ä½•ä¸‹æ£‹<ul><li><code>model.py</code>ï¼šç¥ç»ç½‘ç»œæ¨¡å‹</li><li><code>player.py</code>ï¼šMCTSï¼Œè¾“å‡ºèµ°æ³•</li><li><code>api.py</code>ï¼šä¾›å¤–ç•Œè°ƒç”¨model</li></ul></li><li><code>envrionment</code>ï¼šè±¡æ£‹è§„åˆ™<ul><li>è®­ç»ƒï¼ˆè·‘è°±ï¼‰ä½¿ç”¨<code>static_env.py</code>ï¼Œé€Ÿåº¦å¿«ä¸€äº›</li><li>ç”¨è‡ªå¸¦GUIä¸‹æ£‹æ—¶ä½¿ç”¨çš„æ˜¯<code>env.py</code>, <code>chessboard.py</code>è¿™äº›ï¼Œå¯ä»¥è¾“å‡ºPNGæ ¼å¼çš„æ£‹è°±</li></ul></li><li><code>worker</code>ï¼šæŠŠagentå’Œenvrionmentä¸²è”èµ·æ¥çš„è„šæœ¬<ul><li><code>self_play.py</code>ï¼šè‡ªæˆ‘åšå¼ˆ</li><li><code>compute_elo.py</code>ï¼šè¯„æµ‹å¹¶ä¸Šä¼ ç»“æœåˆ°å®˜ç½‘</li><li><code>optimize.py</code>ï¼šè®­ç»ƒæ£‹è°±</li><li><code>_windows</code>åç¼€è¡¨ç¤ºæ˜¯åœ¨Windowså¹³å°ä¸Šè¿è¡Œçš„ç›¸åº”åŠŸèƒ½ï¼Œä¹‹æ‰€ä»¥åˆ†å¼€æ˜¯å› ä¸ºä¸¤ä¸ªå¤šè¿›ç¨‹çš„å¯åŠ¨æ–¹å¼ä¸åŒï¼Œå¯¼è‡´ä»£ç ç»“æ„ä¹Ÿè¦å‘ç”Ÿä¸€äº›å˜åŒ–ï¼Œè¯¦è§<a href="#è‡ªæˆ‘åšå¼ˆ">è‡ªæˆ‘åšå¼ˆ</a>ã€‚</li></ul></li></ul><h3><span id="ç¥ç»ç½‘ç»œæ¨¡å‹">ç¥ç»ç½‘ç»œæ¨¡å‹</span></h3><p><strong>ç½‘ç»œè¾“å…¥</strong>ï¼š<span class="math inline">\(14\times10\times9\)</span></p><ul><li><span class="math inline">\(10 \times 9\)</span> æ˜¯ä¸­å›½è±¡æ£‹æ£‹ç›˜çš„å¤§å°</li><li><span class="math inline">\(14\)</span> æ˜¯æ‰€æœ‰æ£‹å­ç§ç±»ï¼ˆçº¢/é»‘ç®—ä¸åŒç§ç±»ï¼‰</li><li>æ•´ä½“çš„è¾“å…¥å°±æ˜¯14ä¸ªæ£‹ç›˜å †å åœ¨ä¸€èµ·ï¼Œæ¯ä¸ªæ£‹ç›˜è¡¨ç¤ºä¸€ç§æ£‹å­çš„ä½ç½®ï¼šæ£‹å­æ‰€åœ¨çš„ä½ç½®ä¸º1ï¼Œå…¶ä½™ä½ç½®ä¸º0ã€‚</li></ul><p><strong>ç½‘ç»œè¾“å‡º</strong></p><ul><li>ç­–ç•¥å¤´ï¼ˆpolicy headï¼‰è¾“å‡ºï¼š<span class="math inline">\(2086\)</span><ul><li><span class="math inline">\(2086\)</span> æ˜¯è¡ŒåŠ¨ç©ºé—´çš„å¤§å°ã€‚è¡ŒåŠ¨ç©ºé—´å°±æ˜¯è¯´æ ¹æ®ä¸­å›½è±¡æ£‹çš„è§„åˆ™ï¼Œä»»æ„æ£‹å­åœ¨ä»»æ„ä½ç½®çš„èµ°æ³•é›†åˆã€‚</li></ul></li><li>ä»·å€¼å¤´ï¼ˆvalue headï¼‰è¾“å‡ºï¼š<span class="math inline">\(1\)</span><ul><li>ä»·å€¼å¤´è¾“å‡ºä¸€ä¸ªæ ‡é‡è¡¡é‡å½“å‰å±€åŠ¿ <span class="math inline">\(v\in[-1, 1]\)</span>ï¼šå½“ <span class="math inline">\(v\)</span> æ¥è¿‘1æ—¶ï¼Œå±€åŠ¿å¤§å¥½ï¼›æ¥è¿‘0ä¸ºå‡åŠ¿ï¼›æ¥è¿‘-1ä¸ºè´¥åŠ¿ã€‚</li></ul></li></ul><p>é™„ï¼šæ£‹å­ç¼–å·è¡¨</p><table><thead><tr class="header"><th>æ£‹å­</th><th>ç¼–å·</th></tr></thead><tbody><tr class="odd"><td>å…µ/å’</td><td>0</td></tr><tr class="even"><td>ç‚®</td><td>1</td></tr><tr class="odd"><td>è½¦</td><td>2</td></tr><tr class="even"><td>é©¬</td><td>3</td></tr><tr class="odd"><td>ç›¸/è±¡</td><td>4</td></tr><tr class="even"><td>ä»•/å£«</td><td>5</td></tr><tr class="odd"><td>å¸…/å°†</td><td>6</td></tr></tbody></table><p><strong>ç½‘ç»œç»“æ„</strong></p><p>ç½‘ç»œä¸»ä½“æ˜¯ ResNetï¼Œè¾“å‡ºéƒ¨åˆ†åˆ†å‡ºä¸¤ä¸ªå¤´ï¼Œåˆ†åˆ«è¾“å‡º policy å’Œ valueã€‚ç°åœ¨çš„æ¶æ„æ˜¯ä¸­é—´æœ‰10ä¸ªæ®‹å‰å—ï¼ˆResidual Blockï¼‰ï¼Œæ¯ä¸ªå—é‡Œé¢æœ‰ä¸¤ä¸ªCNNï¼šå·ç§¯æ ¸å¤§å°ä¸º <span class="math inline">\(3 \times 3\)</span>ï¼Œè¿‡æ»¤å™¨ä¸ªæ•°ä¸º192ã€‚</p><h3><span id="è’™ç‰¹å¡æ´›æ ‘æœç´¢">è’™ç‰¹å¡æ´›æ ‘æœç´¢</span></h3><p><img src="/images/mcts0.png"></p><p>æœç´¢æ ‘ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½åŒ…å«æ‰€æœ‰åˆæ³•ç§»åŠ¨ a âˆˆ A(s) çš„è¾¹(sï¼Œa)ã€‚ æ¯æ¡è¾¹å­˜å‚¨ä¸€ç»„ç»Ÿè®¡æ•°æ®ï¼Œ <span class="math display">\[\{N(s,a) ,W(s,a) ,Q(s,a) ,P(s,a)\}\]</span> å…¶ä¸­ <span class="math inline">\(N(s,a)\)</span> æ˜¯è®¿é—®è®¡æ•°ï¼Œ<span class="math inline">\(W(s,a)\)</span> æ˜¯æ€»åŠ¨ä½œä»·å€¼ï¼Œ<span class="math inline">\(Q(s,a)\)</span> æ˜¯å¹³å‡åŠ¨ä½œä»·å€¼ï¼Œ<span class="math inline">\(P(s,a)\)</span> æ˜¯é€‰æ‹©è¯¥è¾¹çš„å…ˆéªŒæ¦‚ç‡ã€‚ å¤šä¸ªæ¨¡æ‹Ÿåœ¨å•ç‹¬çš„æœç´¢çº¿ç¨‹ä¸Šå¹¶è¡Œæ‰§è¡Œã€‚</p><ol type="1"><li><p>é€‰æ‹©</p><p>æ¯ä¸ªæ¨¡æ‹Ÿçš„ç¬¬ä¸€ä¸ª in-tree é˜¶æ®µå¼€å§‹äºæœç´¢æ ‘çš„æ ¹èŠ‚ç‚¹ <span class="math inline">\(s_0\)</span>ï¼Œå¹¶ä¸”åœ¨æ¨¡æ‹Ÿæ—¶åˆ» L å¤„åˆ°è¾¾å¶èŠ‚ç‚¹ <span class="math inline">\(s_L\)</span> æ—¶ç»“æŸã€‚åœ¨æ¯ä¸ªè¿™äº›æ—¶åˆ» <span class="math inline">\(t &lt; L\)</span> å¤„ï¼Œæ ¹æ®æœç´¢æ ‘ä¸­çš„ç»Ÿè®¡é‡é€‰æ‹©ä¸€ä¸ªç§»åŠ¨: <span class="math inline">\(a_t = \arg\max_a(Q(s_t,a) + U(s_t,a))\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(U(s_t,a)\)</span> ä½¿ç”¨PUCTç®—æ³•çš„å˜ä½“å¾—åˆ° <span class="math display">\[U(s,a)=c_{puct}P(s,a)\frac{\sqrt{\sum_bN(s,b)}}{1+N(s,a)}\]</span> å…¶ä¸­ <span class="math inline">\(c_{puct}â€‹\)</span> æ˜¯ä¸€ä¸ªå†³å®šæ¢ç´¢ç¨‹åº¦çš„å¸¸æ•°; è¿™ç§æœç´¢æ§åˆ¶ç­–ç•¥æœ€åˆå€¾å‘äºå…·æœ‰é«˜å…ˆéªŒæ¦‚ç‡å’Œä½è®¿é—®æ¬¡æ•°çš„è¡Œä¸ºï¼Œä½†åæœŸå€¾å‘äºå…·æœ‰é«˜åŠ¨ä½œä»·å€¼çš„è¡Œä¸ºã€‚</p></li><li><p>æ‰©å±•å’Œè¯„ä¼°</p><p>å¶å­ç»“ç‚¹ <span class="math inline">\(s_L\)</span> è¢«åŠ å…¥åˆ°ç­‰å¾…è¯„ä¼°é˜Ÿåˆ—è¿›è¡Œè¯„ä¼°: <span class="math inline">\((d_i(p),v)=f_\theta(d_i(s_L))\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(d_i\)</span>æ˜¯æ—‹è½¬æˆ–åå°„æ“ä½œã€‚ç¥ç»ç½‘ç»œä¸€æ¬¡è¯„ä¼°é˜Ÿåˆ—é‡Œçš„ 8 ä¸ªç»“ç‚¹;æœç´¢è¿›ç¨‹ç›´åˆ°è¯„ä¼°å®Œæ¯•æ‰èƒ½ç»§ç»­å·¥ä½œã€‚æ¯ä¸ªå¶å­ç»“ç‚¹å’Œæ¯æ¡è¾¹ <span class="math inline">\((s_L,a)\)</span> çš„ç»Ÿè®¡å€¼è¢«åˆå§‹åŒ–ä¸º <span class="math inline">\(\{N(s_L,a) = 0,W(s_L,a) = 0,Q(s_L,a) =0, P(s_L, a) = p_a\}\)</span>ï¼Œç„¶åä»·å€¼ v å¼€å§‹å›æº¯ã€‚</p></li><li><p>å›æº¯</p><p>æ¯æ¡è¾¹çš„ç»Ÿè®¡å€¼å»¶è·¯å¾„åå‘æ›´æ–°ï¼šè®¿é—®è®¡æ•°é€’å¢ <span class="math inline">\(N(s_t,ğ‘_t) = N(s_t,ğ‘_t) +1\)</span>ï¼Œç§»åŠ¨ä»·å€¼æ›´æ–°ä¸ºå¹³å‡å€¼ <span class="math inline">\(W(s_t,a_t)=W(s_t,a_t)+v\)</span>, <span class="math inline">\(Q(s_t,a_t)=\frac{W(s_t,a_t)}{N(s_t,a_t)}\)</span>ã€‚</p></li><li><p>ä¸‹æ£‹</p><p>åœ¨æœç´¢ç»“æŸæ—¶ï¼ŒAlphaGo Zero åœ¨æ ¹ä½ç½® <span class="math inline">\(s_0\)</span> é€‰æ‹©ç§»åŠ¨ aï¼Œä¸å…¶æŒ‡æ•°è®¿é—®è®¡æ•°æˆæ¯”ä¾‹ï¼Œ<span class="math inline">\(\pi(a|s_0) = \frac{N(s_0,a)^{1/\tau}}{\sum_bN(s,b)^{1/\tau}}\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(Ï„\)</span> æ˜¯æ§åˆ¶æ¢ç´¢æ°´å¹³çš„å‚æ•°ã€‚æœç´¢æ ‘å¯ä»¥åœ¨åé¢çš„æ—¶åˆ»é‡ç”¨ï¼šä¸æ‰€é€‰æ‹©çš„ç§»åŠ¨å¯¹åº”çš„å­èŠ‚ç‚¹æˆä¸ºæ–°çš„æ ¹èŠ‚ç‚¹; åœ¨è¿™ä¸ªèŠ‚ç‚¹ä¸‹é¢çš„å­æ ‘è¢«ä¿ç•™ä»¥åŠå®ƒçš„æ‰€æœ‰ç»Ÿè®¡æ•°æ®ï¼Œè€Œæ ‘çš„å…¶ä½™éƒ¨åˆ†è¢«ä¸¢å¼ƒã€‚</p></li></ol><h4><span id="å®ç°ç»†èŠ‚">å®ç°ç»†èŠ‚</span></h4><p><strong>åœ¨é€‰æ‹©çš„è¿‡ç¨‹ä¸­ï¼Œå‘ç°å½“å‰stateåœ¨historyä¸­å‡ºç°è¿‡ï¼ˆå½¢æˆå¾ªç¯ï¼‰æ€ä¹ˆåŠï¼Ÿ</strong></p><ul><li>æ ¹æ®æ¯”èµ›è§„åˆ™ï¼šé—²ç€å¾ªç¯3æ¬¡åˆ¤å’Œï¼›è¿è§„ï¼ˆé•¿æ‰ã€é•¿å°†ç­‰ï¼‰åˆ¤è´Ÿï¼›å¯¹æ–¹è¿è§„åˆ¤èƒœã€‚</li></ul><p><strong>Virtual Loss</strong></p><ul><li><p>å¤šçº¿ç¨‹æœç´¢æ—¶ï¼Œå½“æŸä¸€çº¿ç¨‹é€‰æ‹©äº†æŸä¸ªactionæ—¶ï¼Œä¸ºäº†é¼“åŠ±å…¶ä»–çº¿ç¨‹é€‰æ‹©å…¶ä»–actionï¼Œåº”è¯¥é™ä½è¯¥actionçš„ä»·å€¼ï¼ˆæ–½åŠ virtual lossï¼‰</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">self.tree[state].sum_n += <span class="number">1</span></span><br><span class="line">action_state = self.tree[state].a[sel_action]</span><br><span class="line">action_state.n += virtual_loss</span><br><span class="line">action_state.w -= virtual_loss</span><br><span class="line">action_state.q = action_state.w / action_state.n</span><br></pre></td></tr></table></figure></li><li><p>åœ¨å›æº¯æ—¶ï¼Œæ›´æ–°valueè¦è€ƒè™‘åˆ°virtual lossçš„å½±å“</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">node = self.tree[state]</span><br><span class="line">action_state = node.a[action]</span><br><span class="line">action_state.n += <span class="number">1</span> - virtual_loss</span><br><span class="line">action_state.w += v + virtual_loss</span><br><span class="line">action_state.q = action_state.w / action_state.n</span><br></pre></td></tr></table></figure></li></ul><p><strong>stateè¡¨ç¤º</strong></p><p>è™½ç„¶å¯¹äºç¥ç»ç½‘ç»œæ¥è¯´stateå°±æ˜¯<span class="math inline">\(14\times10\times9\)</span>çš„tensorï¼Œä½†æ˜¯å¯¹äºæœç´¢æ ‘æ¥è¯´ï¼Œæ˜¾ç„¶ä¸èƒ½ç”¨å®ƒæ¥è¡¨ç¤ºæ¯ä¸ªå±€é¢ã€‚</p><p>åœ¨åˆå§‹ç‰ˆæœ¬ä¸­ï¼Œè±¡æ£‹ç¯å¢ƒï¼ˆ<code>environment/chessboard.py</code>ï¼‰é‡Œæ˜¯ç”¨æ•°ç»„æ¥è¡¨ç¤ºæ£‹ç›˜çš„ï¼Œæ‰€ä»¥åœ¨æœç´¢ä¸­ä¹Ÿä½¿ç”¨ç›¸åº”çš„æ•°ç»„è¡¨ç¤ºstateï¼Œè¿™æ ·åšè™½ç„¶æ²¡ä»€ä¹ˆé—®é¢˜ï¼Œä½†æ˜¯åœ¨æœç´¢çš„è¿‡ç¨‹ä¸­éœ€è¦å¤§é‡çš„æ·±æ‹·è´æ“ä½œï¼ˆå› ä¸ºéœ€è¦å›æº¯ï¼‰ï¼Œå¢åŠ äº†è®¸å¤šå¼€é”€ã€‚</p><p>åæ¥ç‰ˆæœ¬è¿›è¡Œäº†æ”¹è¿›ï¼Œä½¿ç”¨<a href="https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation" target="_blank" rel="noopener">FEN string</a>ä½œä¸ºstateçš„è¡¨ç¤ºï¼Œé™ä½äº†æ‹·è´æ“ä½œçš„å¼€é”€ï¼›åŒæ—¶ä¹Ÿä¼˜åŒ–äº†è±¡æ£‹ç¯å¢ƒï¼ˆ<code>environment/static_env.py</code>ï¼‰ï¼Œå¯ä»¥ç›´æ¥å¯¹FENè¿›è¡Œæ“ä½œï¼Œæ— éœ€è®°å½•å¤æ‚çš„æ•°ç»„ã€‚</p><blockquote><p><strong>Forsythâ€“Edwards Notation</strong> (<strong>FEN</strong>) is a standard <a href="https://www.wikiwand.com/en/Chess_notation" target="_blank" rel="noopener">notation</a> for describing a particular board position of a <a href="https://www.wikiwand.com/en/Chess" target="_blank" rel="noopener">chess</a> game. The purpose of FEN is to provide all the necessary information to restart a game from a particular position.</p></blockquote><h3><span id="è‡ªæˆ‘åšå¼ˆ">è‡ªæˆ‘åšå¼ˆ</span></h3><p>ä¸ºäº†æé«˜CPU/GPUåˆ©ç”¨ç‡ï¼Œè¿™é‡Œä½¿ç”¨äº†å¤šè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹å„è‡ªè¿›è¡Œè‡ªæˆ‘åšå¼ˆã€‚Pythonçš„å¤šè¿›ç¨‹æœ‰ä¸‰ä¸ªå®ç°æ–¹å¼ï¼š<code>fork</code>, <code>spawn</code>, <code>forkserver</code>ã€‚</p><blockquote><p>On Windows only <code>'spawn'</code> is available. On Unix <code>'fork'</code> and <code>'spawn'</code> are always supported, with <code>'fork'</code> being the default.</p></blockquote><p>ç”±äºæˆ‘è‡ªå·±åœ¨macOS/Linuxä¸Šå¼€å‘å’Œæµ‹è¯•ï¼Œæ‰€ä»¥é¦–å…ˆå®ç°çš„æ˜¯åŸºäº<code>fork</code>çš„å¤šè¿›ç¨‹ï¼Œè€Œå½“æˆ‘åœ¨ç¨‹åºåŠ äº†<code>mp.set_start_method('spawn')</code>çš„æ—¶å€™ï¼Œç¨‹åºå°±è·‘ä¸äº†äº†ï¼Œä¼šæŠ¥pickling errorï¼ˆè²Œä¼¼æ˜¯å› ä¸ºä¼ ç»™å­è¿›ç¨‹çš„å‚æ•°é‡Œä¸èƒ½å‡ºç°queueçš„æ•°æ®ç»“æ„ï¼‰ï¼Œäºæ˜¯åªèƒ½æ¢ç§æ–¹å¼å®ç°æ¥ç»•è¿‡è¿™ä¸ªé—®é¢˜ã€‚</p><h2><span id="åˆ†å¸ƒå¼">åˆ†å¸ƒå¼</span></h2><p>èµ·åˆæˆ‘æ˜¯æ²¡æ‰“ç®—åšæˆåˆ†å¸ƒå¼çš„ï¼Œå®ç°å®Œä¸Šé¢è¯´è¿°æ¨¡å—ä¹‹åæˆ‘ç”¨å®éªŒå®¤çš„K80è¿›è¡Œè®­ç»ƒï¼Œç»ƒäº†å‡ å¤©ä¹‹åå‘ç°è¿›æ­¥å¹¶ä¸æ˜æ˜¾ï¼Œå‡ ä¹è¿˜æ˜¯éšæœºä¸‹ï¼Œå¾ˆå¼±æ™ºï¼Œè¿™æ˜¯æˆ‘æ‰æ„è¯†åˆ°å³ä½¿æŠŠå®ƒè®­ç»ƒåˆ°ä¸€ä¸ªä¸šä½™ç©å®¶çš„æ°´å¹³ä¹Ÿéœ€è¦å·¨å¤§çš„ç®—åŠ›ã€‚</p><p><img src="/images/issueouashd.png"></p><p>åæ¥æœ‰ä¸€å¤©æœ‰äººåœ¨GitHubä¸Šæäº†ä¸€ä¸ªissueè¯´ä½ å¯ä»¥æŠŠå®ƒåšæˆåˆ†å¸ƒå¼çš„ï¼ŒåƒLeelaZeroé‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å¸®ä½ ä¸€èµ·è®­ç»ƒã€‚<a href="https://zero.sjeng.org/" target="_blank" rel="noopener">LeelaZero</a>æ˜¯å›½å¤–ä¸€ä¸ªå¼€å‘è€…å¤ç°AlphaGoè®ºæ–‡æçš„å›´æ£‹AIï¼Œå› ä¸ºDeepMindå¹¶æ²¡æœ‰å…¬å¼€ç¨‹åºæˆ–ä»£ç ï¼Œæ‰€ä»¥ä»–æƒ³è®­ç»ƒå‡ºä¸€ä¸ªå…¬å¼€çš„å›´æ£‹ä¹‹ç¥ï¼Œç„¶åå°±é‚€è¯·ç½‘å‹å¸®ä»–ä¸€èµ·è®­ç»ƒï¼Œå…·ä½“çš„æ–¹æ³•å°±æ˜¯ï¼šç½‘å‹ä»¬åœ¨è‡ªå·±çš„æœºå™¨ä¸Šè¿›è¡Œè‡ªæˆ‘åšå¼ˆï¼Œç„¶åæŠŠåšå¼ˆçš„æ£‹è°±ä¸Šä¼ åˆ°ä»–çš„æœåŠ¡å™¨ä¸Šï¼Œç„¶åä»–æ”’å¤Ÿä¸€å®šæ£‹è°±ä¹‹åè¿›è¡Œè®­ç»ƒç¥ç»ç½‘ç»œï¼Œè®­ç»ƒå¥½ä¹‹ååˆ†å‘æ–°çš„æƒé‡ã€‚</p><p>åœ¨å›½å†…ä¹Ÿæœ‰å¾ˆå¤šäººå¸®ä»–è®­ç»ƒï¼ˆè·‘è°±ï¼‰ï¼Œç»™æˆ‘æissueçš„é‚£ä¸ªäººä¹Ÿæ˜¯å¸®LeelaZeroè®­ç»ƒä¸­çš„ä¸€å‘˜ã€‚å½“æ—¶æ­£å¥½ç¨‹åºå†™å®Œäº†æ²¡ä»€ä¹ˆäº‹åšï¼Œæ¯å¤©å°±åªèƒ½ç­‰è®­ç»ƒç»“æœï¼Œç„¶åå°±å†³å®šå°è¯•ä¸€ä¸‹è¿™ä¸ªæ¨¡å¼ã€‚å› ä¸ºä¹‹å‰æœ‰è¿‡Webå¼€å‘çš„ç»éªŒï¼Œæ‰€ä»¥æœåŠ¡å™¨å¾ˆå¿«å°±æ­å¥½äº†ï¼Œæµ‹è¯•åŸºæœ¬æ²¡é—®é¢˜ä¹‹åå°±å¼€å§‹è¿è¡Œã€‚</p><p><strong>æ¶æ„</strong></p><p><img src="/images/architecture.png"></p><p>åœ¨ç»´æŠ¤è¿™ä¸ªé¡¹ç›®æ­£å¸¸è¿è¡Œçš„è¿‡ç¨‹ä¸­é‡åˆ°å¾ˆå¤š<strong>å‘</strong>ï¼Œç¨‹åºä¹Ÿåšäº†å¾ˆå¤šæ”¹è¿›ï¼š</p><ol type="1"><li>é¦–å…ˆæ˜¯å¸®å¿™è·‘è°±çš„å¤§å¤šéƒ½æ˜¯è±¡æ£‹çˆ±å¥½è€…ï¼Œå¹¶éå¼€å‘è€…ï¼Œæ‰€ä»¥æˆ‘è¦æŠŠPythonä»£ç æ‰“åŒ…æˆexeæ–‡ä»¶åˆ†å‘ç»™ä»–ä»¬ä¸€é”®æ‰§è¡Œï¼Œæœ€ç»ˆä½¿ç”¨<a href="https://www.pyinstaller.org/" target="_blank" rel="noopener">PyInstaller</a>æ‰“åŒ…æˆåŠŸï¼Œè¿™å…¶ä¸­é‡åˆ°äº†å¾ˆå¤šå‘ï¼š<ul><li>å¸è½½cytoolzï¼›pandasçš„ç‰ˆæœ¬å¿…é¡»ä¸º0.20.3</li><li>ä»£ç é‡ŒåŠ ä¸Š<code>mp.freeze_support()</code>ï¼Œå¦åˆ™å¤šè¿›ç¨‹ä¸ä¼šæ­£å¸¸å·¥ä½œ</li></ul></li><li>æœåŠ¡å™¨å¸¦å®½æœ‰é™ï¼Œå®¢æˆ·ç«¯ä¸‹è½½æƒé‡å¤ªæ…¢ï¼Œè§£å†³åŠæ³•ï¼šæŠŠæƒé‡æ”¾åˆ°äº‘å­˜å‚¨æœåŠ¡ä¸­ï¼Œå¦‚è…¾è®¯äº‘/ä¸ƒç‰›äº‘çš„å¯¹è±¡å­˜å‚¨æœåŠ¡ã€‚</li><li>ä¸­å›½è±¡æ£‹æ£‹è§„çš„å®Œå–„ã€‚å¹¶ä¸æ˜¯è¯´åŸºç¡€çš„é©¬èµ°æ—¥è±¡èµ°ç”°è¿™ç§è§„åˆ™ï¼Œè€Œæ˜¯åƒé•¿å°†ã€é•¿æ‰ç­‰è¿™ç§æ¯”èµ›è§„åˆ™ï¼Œè¿™ä¸ªç®—æ˜¯å‘æœ€å¤§çš„ä¸€ä¸ªï¼Œç›´åˆ°ç°åœ¨è§„åˆ™è¿˜å­˜åœ¨å°‘è®¸é—®é¢˜ã€‚</li><li>éƒ¨åˆ†æ”¯æŒäº†UCIåè®®ã€‚è¿™æ ·å°±å¯ä»¥ä½¿ç”¨å…¶ä»–çš„è±¡æ£‹ç•Œé¢åŠ è½½è¿™ä¸ªå¼•æ“ï¼Œå¹¶ä¸”èƒ½å’Œå…¶ä»–å¼•æ“å¯¹å¼ˆã€‚</li><li>å› ä¸ºâ€œåŒè¡Œç«äº‰â€ï¼Œæˆ‘çš„æœåŠ¡å™¨åœ¨ä»Šå¹´æš‘å‡æœŸé—´æˆ‘çš„æœåŠ¡å™¨ç»å¸¸é­å—DDosæ”»å‡»ï¼Œç”±äºä¹°ä¸èµ·è…¾è®¯äº‘çš„é«˜é˜²æœåŠ¡ï¼Œåªèƒ½å°è¯•å…¶ä»–åŠæ³•ï¼ŒåŒ…æ‹¬é…ç½®å¼¹æ€§IPã€é…ç½®é˜²ç«å¢™ã€Cloudfare CDNç­‰ï¼Œä½†éƒ½ä¸å¥½ç”¨ã€‚æœ€ç»ˆæŠŠæœåŠ¡è½¬ç§»åˆ°<a href="https://www.ovh.com/" target="_blank" rel="noopener">OVH</a>æä¾›çš„VPSä¸Šæ‰è§£å†³äº†é—®é¢˜ï¼ˆOVHæä¾›å…è´¹çš„DDosé˜²æŠ¤ï¼‰ã€‚</li></ol><hr><h2><span id="alphazero-and-exit">AlphaZero and ExIt</span></h2><p><a href="https://arxiv.org/abs/1705.08439" target="_blank" rel="noopener">Expert Iterationï¼ˆExItï¼‰</a>æ˜¯ä¸€ç§æ¨¡ä»¿å­¦ä¹ ï¼ˆImitation Learning, ILï¼‰ç®—æ³•ï¼Œæ™®é€šçš„ IL ç®—æ³•ä¸­ï¼Œå¾’å¼Ÿæ¨¡ä»¿ä¸“å®¶çš„ç­–ç•¥åªèƒ½æé«˜è‡ªå·±çš„ç­–ç•¥ï¼Œä¸“å®¶æ˜¯ä¸ä¼šæœ‰ä»»ä½•æé«˜çš„ï¼Œè€Œ ExIt ç®—æ³•å°±æ˜¯æƒ³è®©å¸ˆå‚…æ•™å¾’å¼Ÿçš„æ—¶å€™è‡ªå·±ä¹Ÿæœ‰æé«˜ã€‚</p><p><strong>ExIt ç®—æ³•</strong> å¸ˆå‚…æ ¹æ®å¾’å¼Ÿçš„ç­–ç•¥è¿›è¡Œå‰å‘æœç´¢ï¼ˆä¾‹å¦‚MCTSï¼Œalpha-betaï¼Œè´ªå¿ƒæœç´¢ç­‰ï¼‰ï¼Œå¾—å‡ºæ¯”å¾’å¼Ÿæ›´å¥½çš„ç­–ç•¥ï¼Œç„¶åå¾’å¼Ÿå†å­¦ä¹ å¸ˆå‚…çš„ç­–ç•¥ï¼Œå¦‚æ­¤å¾ªç¯ï¼Œéšç€å¾’å¼Ÿçš„å¢å¼ºï¼Œå¸ˆå‚…ä¹Ÿä¼šè¶Šæ¥è¶Šå¼ºã€‚</p><p><img src="/images/exit.png"></p><p>å¯è§ï¼ŒAlphaZeroä¹Ÿå±äº ExIt ç®—æ³•ï¼Œå¸ˆå‚…ä¸º MCTSï¼Œå¾’å¼Ÿå°±æ˜¯ç¥ç»ç½‘ç»œã€‚</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaZero </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> CCZero </tag>
            
            <tag> MCTS </tag>
            
            <tag> ä¸­å›½è±¡æ£‹ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hexo æ­å»ºåšå®¢è¸©å‘è®°å½•</title>
      <link href="/2018/11/06/%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E8%AE%B0%E5%BD%95/"/>
      <url>/2018/11/06/%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>åšå®¢è¿ç§»è¿™ä¸ªäº‹æ—©å°±æƒ³åšäº†ï¼Œä½†åˆ°ç°åœ¨æ‰æœ‰æ—¶é—´å’Œç²¾åŠ›æ¥å®Œæˆã€‚ä»¥å‰å¤ªå¹´è½»ï¼Œå†™çš„åšå®¢ç³»ç»Ÿå¹¶ä¸æ–¹ä¾¿ç»´æŠ¤ï¼Œè¿ç§»çš„åŠ¨åŠ›ä¸»è¦æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š</p><ol type="1"><li>åŸåšå®¢æ›´æ–°ã€ç»´æŠ¤è¾ƒéº»çƒ¦ã€‚ä»¥å‰çš„åšå®¢æ˜¯ç”¨<a href="https://www.52coding.com.cn/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/">PHP</a>å†™çš„ï¼Œä¹‹å‰çš„å†™ä½œæ–¹å¼æ˜¯ç”¨Markdownå†™å¥½å¯¼å‡ºHTMLï¼Œå†ä¿®æ”¹HTMLä»£ç ä½¿å¾—é™æ€èµ„æºï¼ˆå›¾ç‰‡ç­‰ï¼‰åŠ è½½æ­£ç¡®ï¼Œè¿™å°±ä½¿å¾—ä¿®æ”¹åšå®¢å¾ˆéº»çƒ¦ï¼›æ›´æ¢ä¸»é¢˜ä¹Ÿå¾ˆéº»çƒ¦ï¼Œåšå®¢çš„ä¸»é¢˜å’ŒMarkdownçš„ä¸»é¢˜é€šå¸¸ä¼šæœ‰å†²çªï¼Œæ‰€ä»¥æƒ³æ¢ä¸ªæ ·å¼å°±è¦æ”¹åŠå¤©CSSã€‚</li><li>è§‰å¾—UIæœ‰äº›éš¾çœ‹ï¼Œæƒ³è¦ç®€æ´ä¸€äº›ï¼›</li><li>å®‰å…¨é—®é¢˜ã€‚</li></ol><p>ç°åœ¨çš„è§£å†³æ–¹æ¡ˆæ˜¯<a href="https://pages.github.com/" target="_blank" rel="noopener">Github Pages</a> + <a href="https://hexo.io/zh-cn/index.html" target="_blank" rel="noopener">Hexo</a>ï¼Œä¸»é¢˜é€‰çš„æ˜¯<a href="https://github.com/CodeDaraW/Hacker" target="_blank" rel="noopener">Hacker</a>ï¼Œè¿ç§»äº†ä¸¤å¤©ç»ˆäºæå®Œäº†ï¼Œåœ¨æ­¤ç®€å•è®°å½•ä¸€ä¸‹é‡åˆ°çš„å‘ã€‚</p><a id="more"></a><h3><span id="æ•°å­¦å…¬å¼æ¸²æŸ“">æ•°å­¦å…¬å¼æ¸²æŸ“</span></h3><p>ç”±äºè¿™æ¬¾ä¸»é¢˜å¹¶ä¸æ˜¯åŸç”Ÿæ”¯æŒæ•°å­¦å…¬å¼çš„ï¼Œæ‰€ä»¥è¦æ·»åŠ äº›ä»£ç æ¥ä½¿å…¶æ”¯æŒMathjaxï¼Œå‚è€ƒhttp://searene.me/2016/10/01/Let-hexo-support-mathjax/ã€‚</p><p>é¦–å…ˆåœ¨ä¸»é¢˜çš„<code>layout</code>ç›®å½•ä¸‹æ–°å»º<code>mathjax.ejs</code>ï¼Œæ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">%</span> <span class="attr">if</span> (<span class="attr">theme.mathjax.enable</span>)&#123; %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Config(&#123;</span></span><br><span class="line"><span class="undefined">      tex2jax: &#123;</span></span><br><span class="line"><span class="undefined">        inlineMath: [ ['$','$'], ["\\(","\\)"] ],</span></span><br><span class="line"><span class="undefined">        processEscapes: true</span></span><br><span class="line"><span class="undefined">      &#125;</span></span><br><span class="line"><span class="undefined">    &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Config(&#123;</span></span><br><span class="line"><span class="undefined">        tex2jax: &#123;</span></span><br><span class="line"><span class="undefined">          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined">      &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Queue(function() &#123;</span></span><br><span class="line"><span class="undefined">          var all = MathJax.Hub.getAllJax(), i;</span></span><br><span class="line"><span class="xml">          for(i=0; i <span class="tag">&lt; <span class="attr">all.length</span>; <span class="attr">i</span> += <span class="string">1)</span> &#123;</span></span></span><br><span class="line"><span class="undefined">              all[i].SourceElement().parentNode.className += ' has-jax';</span></span><br><span class="line"><span class="undefined">          &#125;</span></span><br><span class="line"><span class="undefined">      &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%</span> &#125; %&gt;</span></span><br></pre></td></tr></table></figure><p><strong>å‘1</strong>ï¼šä¹‹å‰åœ¨ç½‘ä¸ŠæŸ¥åˆ°çš„ä»£ç ç»™çš„MathJax.jsçš„é“¾æ¥å¤šæ˜¯è¿‡æœŸçš„ï¼Œå¦‚<code>https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML</code>ï¼Œç„¶åå°±è¢«å‘äº†ã€‚</p><p>ç„¶ååœ¨<code>layout.ejs</code>ä¸­åŠ ä¸Š<code>&lt;%- partial('mathjax') %&gt;</code>ï¼Œæ–‡ä»¶æ•´ä½“å†…å®¹ä¸ºï¼š</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE HTML&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">head</span>') %&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"blog"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"content"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">header</span>') %&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">main</span> <span class="attr">class</span>=<span class="string">"site-main posts-loop"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">%-</span> <span class="attr">body</span> %&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">main</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">footer</span>') %&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">googleanalytics</span>') %&gt;</span></span><br><span class="line">      <span class="comment">&lt;!-- æ–°åŠ çš„ --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">mathjax</span>') %&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>æœ€ååœ¨ä¸»é¢˜çš„<code>_config.yml</code>ä¸­åŠ ä¸Šï¼š <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mathjax:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>å¦‚æœæ²¡æœ‰å®‰è£…MathJaxæ’ä»¶çš„è¯éœ€è¦å®‰è£…ä¸€ä¸‹ï¼š</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-math --save</span><br></pre></td></tr></table></figure><p>é‡æ–°ç”Ÿæˆä¸€ä¸‹åº”è¯¥å°±å¯ä»¥æ¸²æŸ“æ•°å­¦å…¬å¼äº†ã€‚</p><p>ä¸è¿‡è¿˜æœ‰äº›é—®é¢˜ï¼Œå°±æ˜¯ä½ å†™åœ¨æ•°å­¦å…¬å¼é‡Œçš„ä¸‹åˆ’çº¿(<code>_</code>)ã€åæ–œæ (<code>\</code>)ã€å’Œæ˜Ÿå·(<code>*</code>)ä¼šè¢«å½“ä½œæ™®é€šMarkdownæ¥å¤„ç†ï¼Œæ¯”å¦‚æŠŠä¸‹åˆ’çº¿(<code>_</code>)å’Œæ˜Ÿå·(<code>*</code>)æ›¿æ¢æˆ<code>&lt;em&gt;</code>æ ‡ç­¾ç­‰å¯¼è‡´å…¬å¼æ¸²æŸ“é”™è¯¯ã€‚</p><p>è§£å†³æ–¹æ¡ˆæ¥è‡ªhttps://zhuanlan.zhihu.com/p/33857596ï¼Œæ‰“å¼€<code>nodes_modules/marked/lib/marked.js</code>:</p><ol type="1"><li><p>æ‰¾åˆ°ä¸‹é¢çš„ä»£ç :</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([\\`*&#123;&#125;\[\]()# +\-.!_&gt;])/</span>,</span><br></pre></td></tr></table></figure><p>æ”¹ä¸ºï¼š</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([`*&#123;&#125;\[\]()# +\-.!_&gt;])/</span>,</span><br></pre></td></tr></table></figure></li><li><p>æ‰¾åˆ°emçš„ç¬¦å·:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">em: <span class="regexp">/^\b((?:[^]|_)+?)\b|^*((?:**|[\s\S])+?)*(?!*)/</span>,</span><br></pre></td></tr></table></figure><p>æ”¹ä¸ºï¼š</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">em:<span class="regexp">/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span>,</span><br></pre></td></tr></table></figure></li></ol><p>è¿™æ ·å°±å»æ‰äº†<code>_</code>çš„æ–œä½“å«ä¹‰ï¼Œåœ¨å…¬å¼é‡Œä½¿ç”¨<code>_</code>å°±æ²¡æœ‰é—®é¢˜äº†ï¼Œä¸è¿‡è¦ä½¿ç”¨<code>*</code>çš„è¯è¦ç”¨<code>\ast</code>æ›¿ä»£ã€‚</p><h3><span id="è¯„è®º">è¯„è®º</span></h3><p>Hackerè¿™æ¬¾ä¸»é¢˜æ”¯æŒä¸¤ç§è¯„è®ºæ–¹å¼ï¼Œåˆ†åˆ«æ˜¯<a href="https://github.com/imsun/gitment" target="_blank" rel="noopener">Gitment</a>å’Œ<a href="https://disqus.com/" target="_blank" rel="noopener">Disqus</a>ã€‚ä¸€å¼€å§‹è¯•äº†è¯•Gitmentï¼Œé…ç½®å¥½ä¹‹åå‘ç°ä¸èƒ½ç”¨ï¼Œå…¶åŸå› æ˜¯æœ‰ä¸€ä¸ªæœåŠ¡è¿‡æœŸäº†è€Œä½œè€…ä¹Ÿå¼ƒå‘äº†æ²¡äººç®¡ï¼Œæˆ‘ä¹Ÿæ‡’å¾—æŠ˜è…¾å°±è½¬å‘äº†Disqusï¼Œæ³¨å†Œäº†ä¹‹åå°±å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œååˆ†æ–¹ä¾¿ï¼Œ<strong>ä½†æ˜¯</strong>å›½å†…è¦ç¿»å¢™æ‰èƒ½è®¿é—®ã€‚</p><p>æœ€åæ¢æˆäº†<a href="https://www.livere.com/" target="_blank" rel="noopener">æ¥å¿…åŠ›</a>è¯„è®ºï¼Œå›½å†…å¯ä»¥æ­£å¸¸è®¿é—®ï¼Œè™½ç„¶ä¸»é¢˜æ²¡æœ‰å†…ç½®æ”¯æŒï¼Œä½†æ˜¯æ“ä½œå¾ˆç®€å•ï¼Œåªéœ€æŠŠå®‰è£…ä»£ç æ”¾åˆ° <code>layout/components/comment.ejs</code> é‡Œå³å¯ã€‚</p><h3><span id="æœç´¢">æœç´¢</span></h3><p>ä¸»é¢˜å†…ç½®ä¸æ”¯æŒæœç´¢ï¼Œéœ€è¦è‡ªå·±åŠ¨æ‰‹ï¼Œä¸°è¡£è¶³é£Ÿã€‚</p><p>é¦–å…ˆå®‰è£…ç”Ÿæˆæœç´¢å†…å®¹çš„æ’ä»¶ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure></p><p>ç„¶ååœ¨<code>_config.yml</code>è¿›è¡Œå¦‚ä¸‹é…ç½®ï¼š <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">search:</span></span><br><span class="line"><span class="attr">  path:</span> <span class="string">search.xml</span></span><br><span class="line"><span class="attr">  field:</span> <span class="string">post</span></span><br><span class="line"><span class="attr">  content:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>é…ç½®é¡¹å…·ä½“å«ä¹‰å‚è€ƒ<a href="https://www.npmjs.com/package/hexo-generator-search" target="_blank" rel="noopener">è¿™é‡Œ</a>ï¼Œè¿™ä¸ªç½‘ç«™è¿˜è¯´äº†åº”è¯¥æ€ä¹ˆç”¨è¿™ä¸ªæ’ä»¶æ¥åœ¨åšå®¢ä¸­æ”¯æŒæœç´¢å¹¶ä¸”ç»™äº†demoï¼Œåˆ†ä¸ºä¸‰æ­¥ï¼š</p><ol type="1"><li><a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/layout/_widget/search.ejs#L8" target="_blank" rel="noopener">åˆ›å»ºæœç´¢æ¡†</a></li><li>ç¼–å†™<a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/source/js/search.js" target="_blank" rel="noopener">æœç´¢è„šæœ¬</a></li><li>åœ¨ Hexo ä¸»é¢˜ä¸­æŠŠä¸¤éƒ¨åˆ†<a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/layout/_partial/after_footer.ejs#L22" target="_blank" rel="noopener">ç»“åˆèµ·æ¥</a></li></ol><h4><span id="åˆ›å»ºæœç´¢æ¡†">åˆ›å»ºæœç´¢æ¡†</span></h4><p>æˆ‘çš„æ‰“ç®—æ˜¯æŠŠâ€œæœç´¢â€æ”¾åœ¨é¡¶éƒ¨ï¼Œå’Œâ€œä¸»é¡µâ€ã€â€œç›®å½•â€ç­‰ä¸€æ’ï¼Œæ˜¯ä¸€ä¸ªå•ç‹¬çš„é¡µé¢ã€‚æ‰€ä»¥è¦å…ˆåˆ›å»ºæ–°ç•Œé¢ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page &quot;search&quot;</span><br></pre></td></tr></table></figure><p>ä¿®æ”¹ <code>search</code> ç›®å½•ä¸‹çš„ <code>index.md</code>ï¼š</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: æœç´¢</span><br><span class="line">date: 2018-11-23 14:42:39</span><br><span class="line">layout: "search"</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>åœ¨ä¸»é¢˜çš„ <code>_config.yml</code> ä¸­åŠ ä¸Šï¼š</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="string">æœç´¢:</span> <span class="string">/search</span></span><br></pre></td></tr></table></figure><p>åœ¨ä¸»é¢˜çš„ <code>layout</code> ç›®å½•ä¸‹åˆ›å»º <code>search.ejs</code>ï¼š</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">article</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span> <span class="attr">class</span>=<span class="string">"article-title &lt;% if (page.category)&#123; %&gt; category&lt;% &#125; else if (page.category)&#123; %&gt; category&lt;% &#125; %&gt;"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">%=</span> <span class="attr">page.title</span> || <span class="attr">config.title</span> %&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"site_search"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"form-group"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">id</span>=<span class="string">"local-search-input"</span> <span class="attr">name</span>=<span class="string">"q"</span> <span class="attr">results</span>=<span class="string">"0"</span> <span class="attr">placeholder</span>=<span class="string">"è¾“å…¥å…³é”®è¯"</span> <span class="attr">class</span>=<span class="string">"st-search-input st-default-search-input form-control"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"archive"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"local-search-result"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">article</span>&gt;</span></span><br></pre></td></tr></table></figure><p>é‡æ–°buildå°±åº”è¯¥å¯ä»¥çœ‹åˆ°â€œæœç´¢â€æ ‡ç­¾å’Œæœç´¢æ¡†äº†ã€‚</p><h4><span id="ç¼–å†™æœç´¢è„šæœ¬">ç¼–å†™æœç´¢è„šæœ¬</span></h4><p>åœ¨ä¸»é¢˜ç›®å½•ä¸‹åˆ›å»º<code>source/js/search.js</code>ï¼Œæºç ç…§ https://github.com/wzpan/hexo-theme-freemind/blob/master/source/js/search.js ç¨ä½œä¿®æ”¹ã€‚åŒæ—¶ä¹Ÿä¸‹è½½jqueryåˆ°<code>js</code>æ–‡ä»¶å¤¹ã€‚</p><p>ç„¶ååœ¨ <code>layout/components/head.ejs</code>ä¸­æ·»åŠ ï¼š</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"&lt;%- config.root %&gt;js/search.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"&lt;%- config.root %&gt;js/jquery.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h4><span id="ç»“åˆ">ç»“åˆ</span></h4><p>åœ¨ <code>layout/search.ejs</code>é‡Œæ·»åŠ </p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    <span class="keyword">var</span> search_path = <span class="string">"&lt;%= config.search.path %&gt;"</span>;</span><br><span class="line">    <span class="keyword">if</span> (search_path.length == <span class="number">0</span>) &#123;</span><br><span class="line">        search_path = <span class="string">"search.xml"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> path = <span class="string">"&lt;%= config.root %&gt;"</span> + search_path;</span><br><span class="line">    searchFunc(path, <span class="string">'local-search-input'</span>, <span class="string">'local-search-result'</span>);</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>è¿™æ ·å°±å®Œå…¨å®ç°äº†æœç´¢åŠŸèƒ½ï¼</p><h3><span id="å…¶ä»–">å…¶ä»–</span></h3><p><strong>åˆ†å‰²çº¿</strong></p><p>Hexoä¸­å†™ä½œä¸èƒ½ä½¿ç”¨<code>___</code>ï¼ˆä¸‰ä¸ªä¸‹åˆ’çº¿ï¼‰æ¥å®ç°åˆ†å‰²çº¿ï¼Œç”¨äº†çš„è¯ä¼šgenerateå¤±è´¥ï¼Œè€Œä¸”æç¤ºçš„é”™è¯¯å¾ˆè¿·ï¼Œæ›¾ç»å›°æ‰°äº†æˆ‘å¾ˆä¹…ã€‚å¦‚æœè¦ç”¨åˆ†å‰²çº¿çš„è¯éœ€è¦å››ä¸ªä¸‹åˆ’çº¿ã€‚</p><p><strong>ä¿®æ”¹ç½‘ç«™Icon</strong></p><p>åœ¨ä¸»é¢˜ä¸­æ‰¾åˆ°<code>head.ejs</code>æ–‡ä»¶ï¼Œå…¶ä¸­æœ‰ä¸€è¡Œï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link href=&quot;&lt;%- config.root %&gt;favicon.ico&quot; rel=&quot;icon&quot;&gt;;</span><br></pre></td></tr></table></figure><p>æŒ‰ç†æ¥è¯´åªè¦å¾€æ ¹ç›®å½•ï¼ˆ<code>source</code>ï¼‰ä¸‹æ”¾ä¸€ä¸ª<code>favicon.ico</code>çš„æ–‡ä»¶å³å¯ã€‚</p><p>å¯æ˜¯æˆ‘çš„å°±ä¸è¡Œï¼Œä¸çŸ¥é“ä»€ä¹ˆåŸå› ï¼ŒæŠŠæ–‡ä»¶åæ¢äº†å°±å¯ä»¥äº†ï¼Œæ‰€ä»¥æˆ‘æ”¹æˆäº†ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link href=&quot;&lt;%- config.root %&gt;icon.png&quot; type=&quot;image/png&quot; rel=&quot;icon&quot;&gt;</span><br></pre></td></tr></table></figure><p>ç„¶åå¾€æ ¹ç›®å½•ä¸‹æ”¾ä¸€ä¸ª<code>icon.png</code>ï¼Œè§£å†³ã€‚</p><p><strong>åˆ†äº«</strong></p><p>åˆ†äº«æ¥å£ä½¿ç”¨<a href="https://github.com/overtrue/share.js" target="_blank" rel="noopener">Share.js</a>ï¼Œåªéœ€å¼•å…¥ç›¸åº”çš„csså’Œjsæ–‡ä»¶ï¼Œç…§æ–‡æ¡£ä½¿ç”¨å³å¯ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mathjax </tag>
            
            <tag> Hexo </tag>
            
            <tag> Disqus </tag>
            
            <tag> Gitment </tag>
            
            <tag> Github Pages </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Microeconomics - Interdependence and the Gains from Trade</title>
      <link href="/2018/11/03/Interdependence%20and%20the%20Gains%20from%20Trade/"/>
      <url>/2018/11/03/Interdependence%20and%20the%20Gains%20from%20Trade/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#a-parable-for-the-modern-economy">A Parable for the Modern Economy</a><ul><li><a href="#production-possibilities">Production Possibilities</a></li><li><a href="#specialization-and-trade">Specialization and Trade</a></li></ul></li><li><a href="#comparative-advance-the-driving-force-of-specialization">Comparative Advance: The Driving Force of Specialization</a><ul><li><a href="#absolute-advantage">Absolute Advantage</a></li><li><a href="#opportunity-cost-and-comparative-advantage">Opportunity Cost and Comparative Advantage</a></li><li><a href="#comparative-advantage-and-trade">Comparative Advantage and Trade</a></li><li><a href="#the-price-and-the-trade">The Price and The Trade</a></li></ul></li><li><a href="#applications-of-comparative-advantage">Applications of Comparative Advantage</a><ul><li><a href="#should-tiger-woods-mow-his-own-lawn">Should Tiger Woods Mow His Own Lawn?</a></li><li><a href="#should-the-united-states-trade-with-other-countries">Should the United States Trade With Other Countries?</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="a-parable-for-the-modern-economy">A Parable for the Modern Economy</span></h2><h3><span id="production-possibilities">Production Possibilities</span></h3><p>The graph shows the various mixes of output that an economy can produce and illustrate that people face trade-offs.</p><p><img src="/images/IMG_CBD807794C2B-1.png"> If the farmer and rancher do not trade, the production possibilities frontier is also the consumption possibilities frontier. However, the frontier shows trade-offs but do not show what they will choose to do. So letâ€™s suppose the choose the combinations identified in the graph by points A and B.</p><h3><span id="specialization-and-trade">Specialization and Trade</span></h3><p><img src="/images/IMG_FA9EF67DD902-1.png"> The farmer and rancher can both benefit because trade allows each of them to specialize in doing what they do best. The farmer will spend more time growing potatoes and less time raising cattle. The rancher will spend more time raising cattle and less time growing potatoes. As a result of specialization and trade, each of them can consume more meat and more potatoes without working any more hours.</p><h2><span id="comparative-advance-the-driving-force-of-specialization">Comparative Advance: The Driving Force of Specialization</span></h2><p>The puzzle is why the rancher does better in both fields, he still gain from trade? To solve this puzzle, we should answer first who has a lower cost to produce potatoes?</p><h3><span id="absolute-advantage">Absolute Advantage</span></h3><p>We can measure the cost through <em>absolute advantage</em> which is the ability to produce a good using fewer inputs than another producer. In our example, the only input is time. Because the rancher need fewer time to produce both items, he has the absolute advantage in producing both goods. Base on this the rancher has a lower cost to produce potatoes.</p><h3><span id="opportunity-cost-and-comparative-advantage">Opportunity Cost and Comparative Advantage</span></h3><p>Recall the <em>opportunity cost</em> is whatever must be given up to obtain some item. In our example, the opportunity cost of the rancher to produce 1 ounce potatoes is 1/2 ounce meat and the opportunity cost of him to produce 1 ounce meat is 2 ounce potatoes. Similarly, we can compute the opportunity cost for farmer which summarize in table 1. <img src="/images/IMG_857CB49E31D3-1.png"></p><p>We can also measure the cost through <em>comparative advantage</em>, which is the ability to produce a good at a lower opportunity cost than another producer. Through table 1 we can find out that farmer has comparative advantage in producing potatoes and rancher has comparative advantage in producing meat. Thatâ€™s why the rancher can gain from trade.</p><p>Although it is possible for one person to have an absolute advantage in both goods, it is impossible for one to have a comparative advantage in both goods. Because the opportunity cost of one good is inverse of the opportunity cost of the other.</p><h3><span id="comparative-advantage-and-trade">Comparative Advantage and Trade</span></h3><p>The gains from specialization and trade based on comparative advantage. By specialization in what he has a comparative advantage, the total production of the society raises which means increase the size of economic pie.</p><p>Also, the price of the goods should lower than their opportunity cost of producing it. For example, the farmer exchange 15 ounce potatoes for 5 ounce meat. The price of meat for the farmer is 3 ounce potatoes which is lower than his opportunity cost of producing meat (4 ounce potatoes). Similarly, for the rancher, the price of 1 ounce potatoes is 1/3 ounce meat which is also lower than his opportunity cost of producing potatoes (1/2 ounce meat).</p><p>Conclude: <strong>Trade can benefit everyone in society because it allows people to specialize in activities in which they have a comparative advantage</strong>.</p><h3><span id="the-price-and-the-trade">The Price and The Trade</span></h3><p><strong>For both parties to gain from trade, the price at which they trade must lie between the two opportunity costs</strong>.</p><h2><span id="applications-of-comparative-advantage">Applications of Comparative Advantage</span></h2><h3><span id="should-tiger-woods-mow-his-own-lawn">Should Tiger Woods Mow His Own Lawn?</span></h3><p>Say Tiger Woods can mow his own lawn in 2 hours while, Forrest, the boy next door, can mow the lawn in 4 hours. Should Tiger Woods mow his own lawn?</p><p>Clearly, Tiger Woods has an absolute advantage in mowing the lawn but he has a higher opportunity cost in doing it because he could spend 2 hours filming a commercial advertisement earning $10000 while Forrest can only earn $20 in 4 hours. So Tiger should hire Forrest to mow the lawn and both of them will better off as long as the payment is between $20 and $10000.</p><h3><span id="should-the-united-states-trade-with-other-countries">Should the United States Trade With Other Countries?</span></h3><p>International trade can make some individuals worse off, even as it makes the country as a whole better off. When the US exports food and imports cars, the impact on an American farmer is not the same as the impact on an American autoworker. Yet, international trade is not like war, in which some countries win and others lose. <em>Trade allows all countries to achieve greater prosperity</em>.</p><h2><span id="summary">Summary</span></h2><ul><li>Each person consumes goods and services produced by many other people both in the United States and around the world. Interdependence and trade are desirable because they allow everyone to enjoy a greater <strong>quantity and variety</strong> of goods and services.</li><li>There are two ways to compare the ability of two people in producing a good. The person who can produce the good with the smaller quantity of inputs is said to have an <em>absolute advantage</em> in producing the good. The person who has the smaller <em>opportunity cost</em> of producing the good is said to have a <em>comparative advantage</em>. The gains from trade are based on comparative advantage, not absolute advantage.</li><li>Trade makes everyone better off because it allows people to specialize in those activities in which they have a comparative advantage.</li><li>The principle of comparative advantage applies to countries as well as to people. Economists use the principle of comparative advantage to advocate free trade among countries.</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¾®è§‚ç»æµå‹åŸç† </tag>
            
            <tag> trade </tag>
            
            <tag> comparative advantage </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Unityå­¦ä¹ ç¬”è®°</title>
      <link href="/2018/11/01/Unity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/11/01/Unity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><strong>è®°å½•ä¸€äº›å°åŠŸèƒ½çš„å®ç°</strong></p><!-- toc --><ul><li><a href="#å®ç°ç›¸æœºè·Ÿéš">å®ç°ç›¸æœºè·Ÿéš</a></li><li><a href="#æ‹–åŠ¨å›¾æ ‡åœ¨åœºæ™¯ç”Ÿæˆç‰©ä½“">æ‹–åŠ¨å›¾æ ‡åœ¨åœºæ™¯ç”Ÿæˆç‰©ä½“</a></li><li><a href="#æŠ€èƒ½å†·å´æ•ˆæœ">æŠ€èƒ½å†·å´æ•ˆæœ</a></li><li><a href="#é¼ æ ‡ç‚¹å‡»é€‰ä¸­åœºæ™¯ä¸­çš„ç‰©ä½“">é¼ æ ‡ç‚¹å‡»é€‰ä¸­åœºæ™¯ä¸­çš„ç‰©ä½“</a></li><li><a href="#2däººç‰©æœå·¦æœå³">2Däººç‰©æœå·¦æœå³</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="å®ç°ç›¸æœºè·Ÿéš">å®ç°ç›¸æœºè·Ÿéš</span></h2><ul><li>æ–¹æ³•ä¸€<ul><li>æŠŠç›¸æœºè®¾ç½®ä¸ºç›®æ ‡çš„Child</li></ul></li><li>æ–¹æ³•äºŒ<ul><li>è®¾ç½®å¥½è·ç›®æ ‡çš„è·ç¦»å’Œè§’åº¦ï¼Œæ ¹æ®æ•°å­¦å…³ç³»è®¡ç®—å‡ºç›¸æœºä½ç½®</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">float distance = 15;// è·ç¦»</span><br><span class="line">float rot = 0;// æ¨ªå‘è§’åº¦</span><br><span class="line">GameObject target;// ç›®æ ‡ç‰©ä½“</span><br><span class="line">float roll = 30f * Mathf.PI * 2 / 360; // çºµå‘è§’åº¦</span><br><span class="line"></span><br><span class="line">void LateUpdate () &#123;</span><br><span class="line">Vector3 targetPos = target.transform.position;</span><br><span class="line">Vector3 cameraPos;</span><br><span class="line">float d = distance * Mathf.Cos (roll);</span><br><span class="line">float height = distance * Mathf.Sin (roll);</span><br><span class="line">cameraPos.x = targetPos.x + d * Mathf.Cos (rot);</span><br><span class="line">cameraPos.z = targetPos.z + d * Mathf.Sin (rot);</span><br><span class="line">cameraPos.y = targetPos.y + height;</span><br><span class="line">Camera.main.transform.position = cameraPos;</span><br><span class="line">Camera.main.transform.LookAt (target.transform);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>ç›¸æœºéšé¼ æ ‡æ—‹è½¬</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">void Rotate()</span><br><span class="line">&#123;</span><br><span class="line"> float w = Input.GetAxis (&quot;Mouse X&quot;) * rotSpeed;</span><br><span class="line">rot -= w;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Roll()</span><br><span class="line">&#123;</span><br><span class="line">float w = Input.GetAxis (&quot;Mouse Y&quot;) * rollSpeed * 0.5f;</span><br><span class="line">roll -= w;</span><br><span class="line">if (roll &gt; maxRoll) &#123;</span><br><span class="line">roll = maxRoll;</span><br><span class="line">&#125;</span><br><span class="line">if (roll &lt; minRoll) &#123;</span><br><span class="line">roll = minRoll;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void LateUpdate () &#123;</span><br><span class="line">Rotate();</span><br><span class="line">  Roll();</span><br><span class="line">....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="æ‹–åŠ¨å›¾æ ‡åœ¨åœºæ™¯ç”Ÿæˆç‰©ä½“">æ‹–åŠ¨å›¾æ ‡åœ¨åœºæ™¯ç”Ÿæˆç‰©ä½“</span></h2><p><strong>æ‹–åŠ¨UI</strong></p><p>æ–°å»º<code>Drag</code>ç±»ï¼Œç»§æ‰¿<code>IBeginDragHandler, IDragHandler, IEndDragHandler</code>ï¼Œå®ç°æ‹–åŠ¨UIåŠŸèƒ½æœ‰ä¸‰ä¸ªæ¥å£ï¼š</p><ul><li><code>public void OnBeginDrag (PointerEventData eventData)</code></li><li><code>public void OnDrag (PointerEventData eventData)</code></li><li><code>public void OnEndDrag (PointerEventData eventData)</code></li></ul><p>åœ¨<code>Drag</code>ç±»é‡Œå®ç°è¿™ä¸‰ä¸ªæ¥å£å³å¯å®ç°æƒ³è¦çš„æ‹–åŠ¨æ•ˆæœï¼Œæœ€åä¸ç”¨å¿˜äº†æŠŠ<code>Drag</code>è„šæœ¬æ·»åŠ åˆ°æƒ³è¦è¢«æ‹–åŠ¨çš„UIç‰©ä½“ä¸Šã€‚</p><p><strong>åœ¨åœºæ™¯ä¸­ç”Ÿæˆç‰©ä½“</strong></p><p>è¦å®ç°è¿™ä¸ªåŠŸèƒ½:</p><ul><li>é¦–å…ˆåœ¨<code>OnBeginDrag</code>ä¸­ç”Ÿæˆæ–°çš„<code>GameObject</code>ï¼›</li><li>ç„¶ååœ¨<code>OnDrag</code>ä¸­ï¼Œæ ¹æ®é¼ æ ‡åœ¨åœºæ™¯é‡Œçš„ä½ç½®è°ƒæ•´<code>GameObject</code>çš„ä½ç½®ï¼Œå†æ£€æµ‹<code>GameObject</code>çš„collideræœ‰æ— å’Œå…¶ä»–ç‰©ä½“ç¢°æ’ï¼›</li><li>æœ€ååœ¨<code>OnEndDrag</code>ä¸­ï¼Œå¦‚æœ<code>GameObject</code>çš„æœ€ç»ˆä½ç½®åˆæ³•ï¼Œåˆ™ä¸å†ç§»åŠ¨ï¼›å¦åˆ™é”€æ¯ç‰©ä½“ï¼Œç”Ÿæˆå¤±è´¥ã€‚</li></ul><h2><span id="æŠ€èƒ½å†·å´æ•ˆæœ">æŠ€èƒ½å†·å´æ•ˆæœ</span></h2><p><strong>å®šæ—¶å™¨</strong></p><p>å®ç°å†·å´æ•ˆæœè®¡æ—¶å™¨å¿…ä¸å¯å°‘ï¼Œå®ç°æ–¹æ³•ä¹Ÿå¾ˆç®€å•ï¼Œåªéœ€ä¸¤ä¸ªå˜é‡ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bool timerStarted = false;</span><br><span class="line">float remain = 10f;</span><br></pre></td></tr></table></figure><p>ç„¶ååœ¨<code>Update</code>ä¸­ä½œå¦‚ä¸‹æ›´æ–°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">void Update ()</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    if (timerStarted) &#123;</span><br><span class="line">remain -= Time.deltaTime;</span><br><span class="line">        if (remain &lt;= 0) &#123;</span><br><span class="line">            CloseTimer();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>UIæ•ˆæœ</strong></p><p>Buttonçš„å±‚æ¬¡å¦‚ä¸‹ï¼š</p><ul><li><p><code>Button</code></p><ul><li><p><code>Image</code>ï¼šæŒ‰é’®æ˜¾ç¤ºçš„å›¾æ ‡</p></li><li><p><code>Mask</code>ï¼šå¯ä»¥ç”¨æŒ‰é’®çš„é»˜è®¤èƒŒæ™¯ï¼›è°ƒæ•´é¢œè‰²å’Œé€æ˜åº¦ï¼›ImageTypeä¸ºfilledï¼›é€šè¿‡è°ƒæ•´Fill Amountæ¥å®ç°è½¬åŠ¨æ•ˆæœ</p><p><img src="/images/Screen%20Shot%202018-10-30%20at%204.09.00%20PM.png"></p></li><li><p><code>CD Text</code>ï¼šæ˜¾ç¤ºå‰©ä½™å†·å´æ—¶é—´</p></li></ul></li></ul><p><strong>Note</strong>ï¼šåœ¨å¼€å§‹å†·å´çš„åŒæ—¶ï¼Œåº”æŠŠè®¾ç½®<code>btn.interactable = false;</code>ï¼Œå¦åˆ™æŒ‰é’®å¯ä»¥åœ¨å†·å´è¿‡ç¨‹ä¸­å†æ¬¡è¢«ç‚¹å‡»ã€‚</p><p>è¿™é‡ŒButtonçš„<code>OnClick</code>ç»‘å®šäº†ä¸¤ä¸ªå‡½æ•°ï¼Œåˆ†åˆ«ç»™<code>CharacterController</code>å®ç°æŠ€èƒ½æ•ˆæœï¼Œå’Œç»™<code>UIManager</code>å®ç°UIåŠ¨æ•ˆï¼š</p><p><img src="/images/btnclick.png"></p><h2><span id="é¼ æ ‡ç‚¹å‡»é€‰ä¸­åœºæ™¯ä¸­çš„ç‰©ä½“">é¼ æ ‡ç‚¹å‡»é€‰ä¸­åœºæ™¯ä¸­çš„ç‰©ä½“</span></h2><p>æ€è·¯ï¼šä»ç‚¹å‡»ä½ç½®å‘åœºæ™¯å‘å°„å°„çº¿ï¼Œæ£€æµ‹æ˜¯å¦å‡»ä¸­ç‰©ä½“</p><p>å®ç°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">void MousePick () &#123;</span><br><span class="line">    if (Input.GetMouseButtonUp (0)) &#123;</span><br><span class="line">        // å‘å°„å°„çº¿</span><br><span class="line">        Ray myRay = Camera.main.ScreenPointToRay (Input.mousePosition);</span><br><span class="line">        // é€‰æ‹©æƒ³è¢«é€‰ä¸­çš„layer</span><br><span class="line">        int layerMask = LayerMask.GetMask (&quot;Building&quot;);</span><br><span class="line">        // æ£€æµ‹ç¢°æ’</span><br><span class="line">        RaycastHit2D hit = Physics2D.Raycast (new Vector2 (myRay.origin.x, myRay.origin.y),</span><br><span class="line">            Vector2.down, Mathf.Infinity, layerMask);</span><br><span class="line">        if (hit.collider) &#123;</span><br><span class="line">            // æ£€æµ‹åˆ°ç¢°æ’ï¼Œé€‰ä¸­è¯¥ç‰©ä½“</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="2däººç‰©æœå·¦æœå³">2Däººç‰©æœå·¦æœå³</span></h2><p>æ€è·¯ï¼šå¦‚æœåŸspriteæœå³ï¼Œé‚£ä¹ˆåªè¦æŠŠtransformçš„<code>scale.x</code>å˜æˆ<code>-1</code>å°±æ˜¯æœå·¦äº†ã€‚</p><p><img src="/images/facingside.png"></p><p>å®ç°ï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">void LateUpdate () &#123;</span><br><span class="line">    Vector3 localScale = _transform.localScale;</span><br><span class="line"></span><br><span class="line">    if (_vx &gt; 0) &#123; // moving right so face right</span><br><span class="line">        _facingRight = true;</span><br><span class="line">    &#125; else if (_vx &lt; 0) &#123; // moving left so face left</span><br><span class="line">        _facingRight = false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // check to see if scale x is right for the player</span><br><span class="line">    // if not, multiple by -1 which is an easy way to flip a sprite</span><br><span class="line">    if ((_facingRight) &amp;&amp; (localScale.x &lt; 0) || </span><br><span class="line">        ((localScale.x &gt; 0)) &#123;</span><br><span class="line">        localScale.x *= -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // update the scale</span><br><span class="line">    _transform.localScale = localScale;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>æœªå®Œå¾…ç»­</strong></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Unity </tag>
            
            <tag> C# </tag>
            
            <tag> Game Dev </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Microeconomics - Thinking Like an Economist</title>
      <link href="/2018/10/03/Thinking%20Like%20an%20Economist/"/>
      <url>/2018/10/03/Thinking%20Like%20an%20Economist/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#the-economist-as-scientist">The Economist as Scientist</a><ul><li><a href="#the-scientific-method-observation-theory-and-more-observation">The Scientific Method: Observation, Theory, and More Observation</a></li><li><a href="#the-role-of-assumptions">The Role of Assumptions</a></li><li><a href="#economic-models">Economic Models</a></li><li><a href="#our-first-model-the-circular-flow-diagram">Our First Model: The Circular-Flow Diagram</a></li><li><a href="#our-second-model-the-production-possibilities-frontier">Our Second Model: The Production Possibilities Frontier</a></li><li><a href="#microeconomics-and-macroeconomics">Microeconomics and Macroeconomics</a></li></ul></li><li><a href="#the-economist-as-policy-adviser">The Economist as Policy Adviser</a><ul><li><a href="#positive-versus-normative-analysis">Positive versus Normative Analysis</a></li><li><a href="#economists-in-washington">Economists in Washington</a></li><li><a href="#why-economists-advice-is-not-always-followed">Why Economistsâ€™ Advice Is Not Always Followed</a></li></ul></li><li><a href="#why-economists-disagree">Why Economists Disagree</a><ul><li><a href="#differences-in-scientific-judgments">Differences in Scientific Judgments</a></li><li><a href="#difference-in-values">Difference in Values</a></li><li><a href="#perception-versus-reality">Perception versus Reality</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="the-economist-as-scientist">The Economist as Scientist</span></h2><h3><span id="the-scientific-method-observation-theory-and-more-observation">The Scientific Method: Observation, Theory, and More Observation</span></h3><p>Invention an economic theory is just like in other scientific fields, which is <em>observation, summary to a theory and then collect data to test it</em>. However, it is often <em>difficult or impossible</em> for economists to <em>collect data</em> because you cannot change policies just for experiments. <strong>Therefore, economists often pay attention to the natural experiments offered by history</strong> which can not only give insight into the economy of the past, but also allow to illustrate and evaluate economic theories of the present.</p><h3><span id="the-role-of-assumptions">The Role of Assumptions</span></h3><p><strong>Make assumptions can simplify the question.</strong> e.g. once we understood the international trade in the simplified imaginary world, we are in a better position to understand international trader in the more complex world.</p><p>Also, the art in scientific thinking is <strong>deciding which assumptions to make</strong>. e.g. study short-run effect or long-run effect make different assumptions.</p><h3><span id="economic-models">Economic Models</span></h3><p>Economic models composed with graphs and equations which omit a lot of details to emphases the essence of economy. Each economic models make assumptions to simplify reality so as to improve our understanding of it.</p><h3><span id="our-first-model-the-circular-flow-diagram">Our First Model: The Circular-Flow Diagram</span></h3><p><img src="/images/IMG_9A38B6F35EC5-1.jpeg.jpg"></p><p>e.g. money in your wallet -&gt; buy coffee in markets for goods and services (local Starbucks) -&gt; revenue of the company -&gt; pay rental or wage -&gt; someoneâ€™s wallet</p><p>Because of its simplicity, this circular-flow diagram is useful to keep in mind when thinking about <strong>how the pieces of the economy fit together</strong>.</p><h3><span id="our-second-model-the-production-possibilities-frontier">Our Second Model: The Production Possibilities Frontier</span></h3><p><img src="/images/IMG_2122EF5B828A-1.jpeg.jpg"> The production possibilities frontier shows the <em>efficiency</em> of the society. Because resources are <em>scarce</em>, not every conceivable outcome is feasible. Points <strong>on</strong> the production possibilities frontier represent <em>efficient levels</em> of production.</p><p>It also reveals <em>trade-off</em> and <em>opportunity costs</em>: if produce more computers, means have to produce less cars. The <em>opportunity cost</em> is measured by the <strong>slope</strong> of the production possibilities frontier, which means point Fâ€™s opportunity cost of a car is lower and point Eâ€™ opportunity cost of producing a car is higher. Thatâ€™s because when at point E, the society has let all of car engineers to produce cars. Producing one more car means moving some of the best computer technicians out of the computer industry and making them autoworkers.</p><p>The production possibilities frontier also change with time, which shows <em>economic growth</em>. <img src="/images/IMG_0EA219852402-1.jpeg.jpg"></p><h3><span id="microeconomics-and-macroeconomics">Microeconomics and Macroeconomics</span></h3><p>Economics is studied on various levels, which is traditionally divided into two broad subfields:</p><ul><li><strong>Microeconomics</strong> is the study of how households and firms make decisions and how they interact in specific markets.</li><li><strong>Macroeconomics</strong> is the study of economy-wide phenomena, including inflation, unemployment, and economic growth.</li></ul><h2><span id="the-economist-as-policy-adviser">The Economist as Policy Adviser</span></h2><h3><span id="positive-versus-normative-analysis">Positive versus Normative Analysis</span></h3><p><strong>positive statements</strong>: claims that attempt to describe the world as it is <strong>normative statements</strong>: claims that attempt to prescribe how the world should be</p><p>Normative statements comes from positive statements as well as value judgements. Deciding what is good or bad policy is not just a matter of science. It also involves our views on ethics, religion, and political philosophy.</p><h3><span id="economists-in-washington">Economists in Washington</span></h3><p>Economists in Whitehouse also face trade-offs. The influence of economists on policy goes beyond their role as advisers: Their research and writings often affect policy indirectly.</p><h3><span id="why-economists-advice-is-not-always-followed">Why Economistsâ€™ Advice Is Not Always Followed</span></h3><p>Economists offer crucial input into the policy process, but their advice is only one ingredient of a complex recipe.</p><h2><span id="why-economists-disagree">Why Economists Disagree</span></h2><h3><span id="differences-in-scientific-judgments">Differences in Scientific Judgments</span></h3><p><strong>Economic is a young science and there is still much to be learned.</strong> They disagree because they have different hunches about the validity of alternative theories or about the size of important parameters that measure how economic variables are related.</p><h3><span id="difference-in-values">Difference in Values</span></h3><p>Economists give conflicting advice sometimes because they have different values.</p><h3><span id="perception-versus-reality">Perception versus Reality</span></h3><p>Why do policies such as rent control persist if the experts are united in their opposition? It may be that the realities of the <strong>political process</strong> stand as immovable obstacles. But it also may be that economists have <strong>not yet convinced</strong> enough of the public that these policies are undesirable.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¾®è§‚ç»æµå‹åŸç† </tag>
            
            <tag> Production Possibilities Frontier </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Microeconomics - Ten Principles of Economics</title>
      <link href="/2018/09/16/Chapter%201-%20Ten%20Principles%20of%20Economics/"/>
      <url>/2018/09/16/Chapter%201-%20Ten%20Principles%20of%20Economics/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#how-people-make-decisions">How People Make Decisions</a><ul><li><a href="#principle-1-people-face-trade-offs">Principle 1: People Face Trade-offs</a></li><li><a href="#principle-2-the-cost-of-something-is-what-you-give-up-to-get-it">Principle 2: The Cost of Something Is What You Give Up to Get It</a></li><li><a href="#principle-3-rational-people-think-at-the-margin">Principle 3: Rational People Think at the Margin</a></li><li><a href="#principle-4-people-respond-to-incentives">Principle 4: People Respond to Incentives</a></li></ul></li><li><a href="#how-people-interact">How People Interact</a><ul><li><a href="#principle-5-trade-can-make-everyone-better-off">Principle 5: Trade Can Make Everyone Better Off</a></li><li><a href="#principle-6-markets-are-usually-a-good-way-to-organize-economic-activity">Principle 6: Markets Are Usually a Good Way to Organize Economic Activity</a></li><li><a href="#principle-7-governments-can-sometimes-improve-market-outcomes">Principle 7: Governments Can Sometimes Improve Market Outcomes</a></li></ul></li><li><a href="#how-the-economy-as-a-whole-works">How the Economy as a Whole Works</a><ul><li><a href="#principle-8-a-countrys-standard-of-living-depends-on-its-ability-to-produce-goods-and-services">Principle 8: A Countryâ€™s Standard of Living Depends on Its Ability to Produce Goods and Services</a></li><li><a href="#principle-9-prices-rise-when-the-government-prints-too-much-money">Principle 9: Prices Rise When the Government Prints Too Much Money</a></li><li><a href="#principle-10-society-faces-a-short-run-trade-off-between-inflation-and-unemployment">Principle 10: Society Faces a Short-Run Trade-off between Inflation and Unemployment</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="how-people-make-decisions">How People Make Decisions</span></h2><p><strong>scarcity</strong>: the limited nature of societyâ€™s resources <strong>economics</strong>: the study of how society manages its <em>scarce</em> resources</p><h3><span id="principle-1-people-face-trade-offs">Principle 1: People Face Trade-offs</span></h3><p>To get one thing we like, we usually have to give up another thing that we like. <strong>Making decisions</strong> requires trading-off one goal against another.</p><ul><li>student cannot learn two or more things at the same time</li><li>how to spend family income</li><li>guns (defense) and butter (living conditions)</li></ul><p><strong>Efficiency</strong> and <strong>Â Equality</strong></p><ul><li><em>Efficiency</em> means the property of society getting the most it can from its scarce resources.</li><li><em>Equality</em> means the property of distributing economic prosperity uniformly among the members of society.</li><li>In other words, <em>efficiency</em> refers to the size of the economic pie, and <em>equality</em> refers to how the pie is divided into individual slices.</li><li>When government tries to cut the economic pie into more equal slices, the pie get smaller.</li></ul><p>Nonetheless, people are likely to make good decisions only if they understand the options they have available. Our study of economics, therefore, starts by acknowledging lifeâ€™s trade-offs.</p><h3><span id="principle-2-the-cost-of-something-is-what-you-give-up-to-get-it">Principle 2: The Cost of Something Is What You Give Up to Get It</span></h3><p><strong>Opportunity cost</strong>: whatever must be given up to obtain some item. When making any decision, decision makers should be aware of the opportunity costs that accompany each possible action.</p><h3><span id="principle-3-rational-people-think-at-the-margin">Principle 3: Rational People Think at the Margin</span></h3><p><strong>Rational people</strong> systematically and purposefully do the best they can to achieve their objectives, given the available opportunities. <strong>Â Marginal change</strong>: a small incremental adjustment to a plan of action. e.g. when exam around, study one more hour instead of playing games.</p><p>Rational people often make decisions by comparing <em>marginal benefits</em> and <em>marginal costs</em>.</p><ul><li>airline ticket</li><li>why is water so cheap, while diamonds are so expensive?<ul><li>water is plentiful -&gt; margin benefit is small</li><li>diamonds are so rare -&gt; margin benefit is large A rational decision maker takes an action if and only if the <em>marginal benefit</em> of the action <strong>exceeds</strong> the <em>marginal cost</em>.</li></ul></li></ul><h3><span id="principle-4-people-respond-to-incentives">Principle 4: People Respond to Incentives</span></h3><p>An <strong>incentive</strong> is something that induces a person to act, such as the prospect of a punishment or a reward. <em>People respond to incentives, the rest is commentary.</em></p><p>Auto safety</p><ul><li>1950s, no seat belt, accident is costly -&gt; seat belt law -&gt; accident is not that costly -&gt; people drive faster (cost less time) -&gt; few deaths per accident but more accidents -&gt; little change in driver deaths and an increase in the number of pedestrian deaths.</li></ul><p>When analyzing any policy, we must consider not only the direct effects but also the less obvious indirect effects that work through incentives. If the policy changes incentives, it will cause people to alter their behavior.</p><p><em>Incentive Pay</em> Chicago buses do not take the shortcut when around congestion, because they have no incentive to do so. If they are paid by passengers like taxi rather than by bus company, they will choose the shortcuts to get more passengers like other cars do. It will increase the bus driverâ€™s productivity but also increase the risk of having accidents.</p><h2><span id="how-people-interact">How People Interact</span></h2><h3><span id="principle-5-trade-can-make-everyone-better-off">Principle 5: Trade Can Make Everyone Better Off</span></h3><p><strong>Trade</strong> between two countries is not like a sports contest in which one side wins and the other side loses. In fact, the opposite is true: <em>Trade between two countries can make each country better off</em>.</p><p>Trade allows countries to specialize in what they do best and to enjoy a greater variety of goods and services.</p><h3><span id="principle-6-markets-are-usually-a-good-way-to-organize-economic-activity">Principle 6: Markets Are Usually a Good Way to Organize Economic Activity</span></h3><p><em>Communist</em> countries worked on the premise that government officials were in the best position to allocate the economyâ€™s scarce resources. The theory behind <em>central planning</em> was that only the government could organize economic activity in a way that promoted <em>economic well-being for the country as a whole</em>. <em>Central planners</em> failed because they tried to run the economy with one hand tied behind their backs â€” the invisible hand of the marketplace.</p><p>In a <strong>market economy</strong>, the decisions of a central planner are replaced by the decisions of millions of firms and households.</p><blockquote><p>Households and firms interacting in markets act as if they are guided by an â€œinvisible handâ€ that leads them to desirable market outcomes. â€” Adam Smith</p></blockquote><p>In any market, buyers look at the price when determining how much to demand, and sellers look at the price when deciding how much to supply. As a result of the decisions that buyers and sellers make, <em>market prices</em> reflect both <em>the value of a good to society</em> and <em>the cost to society of making the good</em>. Smithâ€™s great insight was that <strong>prices</strong> adjust to <strong>guide</strong> these individual buyers and sellers to reach outcomes that, in many cases, <em>maximize the well-being of society as a whole</em>.</p><h3><span id="principle-7-governments-can-sometimes-improve-market-outcomes">Principle 7: Governments Can Sometimes Improve Market Outcomes</span></h3><p><strong>property right</strong>: the ability of an individual to own and exercise control over scarce resources. <strong>market failure</strong>: a situation in which a market left on its own fails to allocate resources efficiently. <strong>externality</strong>: the impact of one personâ€™s actions on the well-being of a bystander. <strong>market power</strong>: the ability of a single economic actor (or a small group of actors) to have a substantial influence on market prices.</p><p><em>The invisible hand is powerful, but it is not omnipotent.</em> The economy needs the government to</p><ul><li>enforce the rules and maintain the institutions that are key to a market economy</li><li>enforce <strong>property right</strong><ul><li>We all rely on government-provided police and courts to enforce our rights over the things we produce â€” and the <em>invisible hand</em> counts on our ability to enforce our rights.</li></ul></li><li>promote <strong>efficiency</strong><ul><li><em>market failure</em> because <strong>externality</strong> (e.g. pollution) and <strong>market power</strong> (e.g. monopoly)</li></ul></li><li>promote <strong>equality</strong></li></ul><h2><span id="how-the-economy-as-a-whole-works">How the Economy as a Whole Works</span></h2><h3><span id="principle-8-a-countrys-standard-of-living-depends-on-its-ability-to-produce-goods-and-services">Principle 8: A Countryâ€™s Standard of Living Depends on Its Ability to Produce Goods and Services</span></h3><p>Why the differences in living standards among countries and over time are so large? Almost all variation in living standards is attributable to differences in countriesâ€™ <strong>productivity</strong> â€” that is, the amount of goods and services produced from each unit of labor input. When thinking about how any policy will affect our living standards, the key question is <em>how it will affect our ability to produce goods and services</em>.</p><h3><span id="principle-9-prices-rise-when-the-government-prints-too-much-money">Principle 9: Prices Rise When the Government Prints Too Much Money</span></h3><p><strong>inflation</strong>: an increase in the overall level of prices in the economy</p><p>What cause inflation? In almost all cases of large or persistent inflation, the culprit is <em>growth in the quantity of money</em>.</p><blockquote><p>The broken window fallacy Some teenagers, being the little beasts that they are, toss a brick through a bakery window. A crown gathers and laments, â€œWhat a shameâ€. But before you know it, someone suggests a silver lining to the situation: Now the baker will have to spend money to have the window repaired. This will add to the income of the repairman, who will spend his additional income, which will add to another sellerâ€™s income, and so on. The chain of spending will multiply and generate higher income and employment. If the broken window is large enough, it might produce an economic boom! But if the baker hadnâ€™t spent his money on window repair, he would have spent it on the new suit he was saving to buy. Then the tailor would have the new income to spend, and so on. <em>The broken window didnâ€™t create new spending; it just diverted spending from somewhere else.</em></p></blockquote><h3><span id="principle-10-society-faces-a-short-run-trade-off-between-inflation-and-unemployment">Principle 10: Society Faces a Short-Run Trade-off between Inflation and Unemployment</span></h3><p>Short-run effects of monetary injections as follows:</p><ul><li>Increasing the amount of money in the economy stimulates the overall level of spending and thus the demand for goods and services</li><li>Higher demand many over time cause firms to raise their prices, but in the meantime, it also encourage them to hire more workers and produce a larger quantity of goods and services.</li><li>More hiring means lower unemployment.</li></ul><p><strong>business cycle</strong>: fluctuations in economic activity, such as employment and production.</p><p>Case: 2008 deep economic downturn -&gt; Barack Obama: <em>stimulus package of reduced taxes and increased government spending</em> -&gt; Federal Reserve: <em>increased the supply of money</em> -&gt; <strong>reduce unemployment</strong> -&gt; might over time lead to an <strong>excessive level of inflation</strong>.</p><h2><span id="summary">Summary</span></h2><ol type="1"><li>The fundamental lessons about individual decision making are that people face trade-offs among alternative goals, that the cost of any action is measured in terms of forgone opportunities, that rational people make decisions by comparing marginal costs and marginal benefits, and that people change their behavior in response to the incentives they face.</li><li>The fundamental lessons about interactions among people are that trade and interdependence can be mutually beneficial, that markets are usually a good way of coordinating economic activity among people, and that the government can potentially improve market outcomes by remedying a market failure or by promoting greater economic equality.</li><li>The fundamental lessons about the economy as a whole are that productivity is the ultimate source of living standards, that growth in the quantity of money is the ultimate source of inflation, and that society faces a short-run trade-off between inflation and unemployment.</li></ol>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> å¾®è§‚ç»æµå‹åŸç† </tag>
            
            <tag> inflation </tag>
            
            <tag> marginal benefit </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>AlphaGo, AlphaGo Zero and AlphaZero</title>
      <link href="/2018/05/15/AlphaGo%20and%20AlphaGo%20Zero/"/>
      <url>/2018/05/15/AlphaGo%20and%20AlphaGo%20Zero/</url>
      
        <content type="html"><![CDATA[<h2><span id="go">Go</span></h2><p>å›´æ£‹èµ·æºäºå¤ä»£ä¸­å›½ï¼Œæ˜¯ä¸–ç•Œä¸Šæœ€å¤è€çš„æ£‹ç±»è¿åŠ¨ä¹‹ä¸€ã€‚åœ¨å®‹ä»£çš„ã€Šæ¢¦æºªç¬”è°ˆã€‹ä¸­æ¢è®¨äº†å›´æ£‹çš„å±€æ•°å˜åŒ–æ•°ç›®ï¼Œä½œè€…æ²ˆæ‹¬ç§°â€œå¤§çº¦è¿ä¹¦ä¸‡å­—å››åä¸‰ä¸ªï¼Œå³æ˜¯å±€ä¹‹å¤§æ•°â€ï¼Œæ„æ€æ˜¯è¯´å˜åŒ–æ•°ç›®è¦å†™43ä¸ªä¸‡å­—ã€‚æ ¹æ®å›´æ£‹è§„åˆ™ï¼Œæ²¡æœ‰æ°”çš„å­ä¸èƒ½å­˜æ´»ï¼Œæ‰£é™¤è¿™äº›çŠ¶æ€åçš„åˆæ³•çŠ¶æ€çº¦æœ‰ <span class="math inline">\(2.08Ã—10^{170}\)</span> ç§ã€‚Robertson ä¸ Munro åœ¨1978å¹´è¯å¾—å›´æ£‹æ˜¯ä¸€ç§ PSPACE-hard çš„é—®é¢˜ï¼Œå…¶å¿…èƒœæ³•ä¹‹è®°å¿†è®¡ç®—é‡åœ¨<span class="math inline">\(10^{600}\)</span> ä»¥ä¸Šï¼Œè¿™è¿œè¿œè¶…è¿‡å¯è§‚æµ‹å®‡å®™çš„åŸå­æ€»æ•° <span class="math inline">\(10^{75}\)</span>ï¼Œå¯è§å›´æ£‹å¯¹ä¼ ç»Ÿçš„æœç´¢æ–¹æ³•æ˜¯éå¸¸æœ‰æŒ‘æˆ˜çš„ã€‚ <a id="more"></a></p><p><img src="/images/go1.png"></p><h2><span id="alphago">AlphaGo</span></h2><p><img src="/images/alphago_ori.png"></p><p>AlphaGoæ˜¯ç¬¬ä¸€ä¸ªæ‰“è´¥äººç±»å† å†›çš„ç”µè„‘ç¨‹åºã€‚</p><p><strong>ç½‘ç»œç»“æ„</strong></p><p>å®ƒç”±ä¸¤ä¸ªå·ç§¯ç¥ç»ç½‘ç»œç»„æˆï¼Œåˆ†åˆ«æ˜¯ç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œã€‚</p><p><img src="/images/policynet.png"></p><p>ç­–ç•¥ç½‘ç»œ P æ¨èä¸‹ä¸€æ­¥æ€ä¹ˆèµ°ï¼›å®ƒçš„è¾“å…¥å°±æ˜¯æ£‹ç›˜çš„çŸ©é˜µï¼šç™½æ£‹å’Œé»‘æ£‹çš„ä½ç½®ã€‚è¿™ä¸ªç½‘ç»œç”±è®¸å¤šå·ç§¯å±‚ç»„æˆï¼Œé€æ¸å­¦ä¹ å›´æ£‹çŸ¥è¯†ï¼Œæœ€ç»ˆè¾“å‡ºè¡ŒåŠ¨ï¼ˆactionï¼‰çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ¥æ¨èä¸‹ä¸€æ­¥æ€ä¹ˆèµ°ã€‚</p><p><img src="/images/valuenet.png"></p><p>ä»·å€¼ç½‘ç»œä¹Ÿç”±å·ç§¯ç¥ç»ç½‘ç»œç»„æˆï¼Œå®ƒæ˜¯ç”¨æ¥é¢„æµ‹è¿™ç›˜æ£‹çš„èƒœè€…ã€‚å®ƒçš„è¾“å…¥ä¹Ÿæ˜¯æ£‹ç›˜çŸ©é˜µï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªå±äº <span class="math inline">\([-1, +1]\)</span> çš„æ ‡é‡ï¼Œ-1ä»£è¡¨AlphaGoä¸€å®šä¼šè¾“ï¼Œ+1ä»£è¡¨ä¸€å®šä¼šèµ¢ã€‚</p><p><strong>è®­ç»ƒæµç¨‹</strong></p><p><img src="/images/alphago_train.png"></p><p>é¦–å…ˆæ˜¯ç›‘ç£å­¦ä¹ ï¼Œè®©ç­–ç•¥ç½‘ç»œå­¦ä¹ äººç±»ä¸“å®¶çš„æ•°æ®é›†ï¼šæ¯ä¸€ä¸ªæ£‹é¢éƒ½æœ‰ä¸€ä¸ªæ ‡ç­¾ï¼Œå¯¹åº”äººç±»ä¸“å®¶çš„ä¸‹æ³•ï¼Œè®©AlphaGoé¦–å…ˆå­¦ä¹ ä¸“å®¶çš„èµ°æ³•ã€‚ç„¶åä½¿ç”¨ç­–ç•¥ç½‘ç»œè¿›è¡Œè‡ªæˆ‘åšå¼ˆï¼Œç”±äºæ¯å±€éƒ½ä¼šäº§ç”Ÿèƒœè€…ï¼Œç”¨è¿™äº›æ•°æ®æ¥è®­ç»ƒä»·å€¼ç½‘ç»œã€‚</p><p><strong>æœç´¢ç®—æ³•</strong></p><p><img src="/images/rebredth.png"></p><p>ä½¿ç”¨ç­–ç•¥ç½‘ç»œå‡å°‘æœç´¢å®½åº¦ï¼Œåªè€ƒè™‘ç½‘ç»œæ¨èçš„ä¸‹æ³•ã€‚</p><p><img src="/images/red_val.png"></p><p>è¿˜å¯ä»¥ä½¿ç”¨ä»·å€¼ç½‘ç»œæ¥é™ä½æœç´¢æ ‘çš„æ·±åº¦ï¼Œå¯ä»¥æŠŠæœç´¢å­æ ‘æ›¿æ¢ä¸ºä¸€ä¸ªå€¼æ¥è¡¨æ˜è¿™ä¸ªå±€é¢èµ¢çš„æ¦‚ç‡ã€‚</p><p><img src="/images/mcts_go.png"></p><p>ä¸è¿‡å®é™…ä¸Šè¿˜æ˜¯ç”¨çš„è’™ç‰¹å¡æ´›æœç´¢æ ‘ã€‚å®ƒåˆ†ä¸ºä¸‰æ­¥ï¼š</p><ol type="1"><li><p>é€‰æ‹©</p><p>é¦–å…ˆä»æ ‘æ ¹å‘ä¸‹éå†ï¼Œæ¯æ¬¡é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„èµ°æ³•ï¼Œç›´åˆ°å¶èŠ‚ç‚¹ã€‚ç½®ä¿¡åº¦æ˜¯ç”±æ¯ä¸ªèŠ‚ç‚¹ä¸­å­˜å‚¨çš„ Q-value å’Œç­–ç•¥ç½‘ç»œç»™çš„å…ˆéªŒæ¦‚ç‡ P ç»„æˆã€‚</p></li><li><p>æ‰©å±•å’Œè¯„ä¼°</p><p>åˆ°äº†å¶èŠ‚ç‚¹ä¹‹åå°±è¦æ‰©å±•è¿™é¢—æ ‘ï¼Œç”¨ç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œåˆ†åˆ«è¯„ä¼°å½“å‰å±€é¢ï¼ŒæŠŠæ¦‚ç‡æœ€å¤§çš„èŠ‚ç‚¹åŠ å…¥æœç´¢æ ‘ã€‚</p></li><li><p>å›æº¯</p><p>æŠŠæ–°åŠ å…¥èŠ‚ç‚¹çš„ä»·å€¼ v å›æº¯åˆ°è·¯å¾„ä¸Šçš„æ¯ä¸€ä¸ªèŠ‚ç‚¹çš„ Q-value ä¸Šã€‚</p></li></ol><p>è¿™å°±æ˜¯åˆå§‹ç‰ˆæœ¬çš„AlphaGoï¼Œè¿™ä¸ªç‰ˆæœ¬èµ¢äº†ä¸–ç•Œå† å†›æä¸–çŸ³ã€‚</p><p><img src="/images/leesd.png"></p><h2><span id="alphago-zero">AlphaGo Zero</span></h2><p>AlphaGo Zero é™¤äº†å›´æ£‹è§„åˆ™æœ¬èº«ä»¥å¤–å®Œå…¨ç§»é™¤äº†äººç±»çš„å›´æ£‹çŸ¥è¯†ï¼Œå®ƒä¸AlphaGoçš„ä¸»è¦åŒºåˆ«å¦‚ä¸‹ï¼š</p><ul><li>æ— äººç±»æ•°æ®<ul><li>å®Œå…¨ä»è‡ªæˆ‘åšå¼ˆä¸­å­¦ä¹ </li></ul></li><li>æ— æ‰‹åŠ¨ç¼–ç çš„ç‰¹å¾<ul><li>è¾“å…¥åªæ˜¯æ£‹ç›˜æœ¬èº«</li></ul></li><li>å•ä¸€çš„ç¥ç»ç½‘ç»œ<ul><li>ç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œåˆäºŒä¸ºä¸€ï¼Œå¹¶ä¸”ç»“æ„æ”¹è¿›ä¸ºResNet</li><li>è¾“å‡ºéƒ¨åˆ†åˆ†ä¸ºä¸¤å¤´ï¼Œåˆ†åˆ«è¾“å‡º policy å’Œ value</li></ul></li><li>æ›´ç®€å•çš„æœç´¢<ul><li>æ›´ç®€å•çš„MCTSï¼Œæ— éšæœºçš„å¿«é€Ÿèµ°å­ï¼Œåªç”¨ç¥ç»ç½‘ç»œè¿›è¡Œè¯„ä¼°</li></ul></li></ul><p><strong>å¢å¼ºå­¦ä¹ ç®—æ³•</strong></p><p><img src="/images/rl_zero.png"></p><p>ç›®æ ‡ï¼šä½¿ç”¨é«˜è´¨é‡ï¼ˆreally really high qualityï¼‰æ•°æ®æ¥è®­ç»ƒç¥ç»ç½‘ç»œï¼Œè€Œæœ€å¥½çš„æ•°æ®æ¥æºå°±æ˜¯AlphaGoè‡ªæˆ‘åšå¼ˆã€‚</p><p>æ‰€ä»¥æµç¨‹å°±æ˜¯è¿™æ ·çš„ï¼š</p><ol type="1"><li>è¾“å…¥å½“å‰çš„æ£‹å±€ï¼Œä½¿ç”¨å½“å‰çš„ç¥ç»ç½‘ç»œæ¥æŒ‡å¯¼è¿›è¡Œè’™ç‰¹å¡æ´›æœç´¢ï¼Œç„¶åä¸‹æœç´¢å‡ºçš„é‚£æ­¥æ£‹ï¼Œæ¥ç€è¾“å…¥åé¢çš„æ£‹å±€ã€æœç´¢â€¦.ç›´åˆ°ä¸€ç›˜æ£‹ç»“æŸã€‚</li></ol><p><img src="/images/train_zero.png"></p><ol start="2" type="1"><li>ä¸‹ä¸€æ­¥å°±æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œï¼Œä½¿ç”¨ä¹‹å‰è‡ªæˆ‘å¯¹å±€çš„æ•°æ®ï¼Œè®­ç»ƒç­–ç•¥çš„æ•°æ®çš„ç‰¹å¾å°±æ˜¯ä»»ä¸€æ£‹å±€ï¼Œæ ‡ç­¾å°±æ˜¯è’™ç‰¹å¡æ´›æœç´¢çš„ç»“æœï¼Œå³ç­–ç•¥æ›´è´´è¿‘äºAlphaGoå®é™…ä¸‹çš„ç­–ç•¥ï¼ˆMCTSçš„æœç´¢ç»“æœï¼‰</li></ol><p><img src="/images/train_zero_val.png"></p><ol start="3" type="1"><li>ä¸æ­¤åŒæ—¶ï¼Œä½¿ç”¨æ¯ç›˜å¯¹å±€çš„èƒœè€…è®­ç»ƒä»·å€¼ç½‘ç»œéƒ¨åˆ†ã€‚</li></ol><p><img src="/images/zero_iterate.png"></p><ol start="4" type="1"><li>æœ€åï¼Œç»è¿‡è®­ç»ƒçš„ç¥ç»ç½‘ç»œåˆå¯ä»¥ç»§ç»­è¿›è¡Œè‡ªæˆ‘åšå¼ˆï¼Œäº§ç”Ÿæ›´é«˜è´¨é‡çš„æ•°æ®ï¼Œç„¶åç”¨è¿™ä¸ªæ•°æ®ç»§ç»­è®­ç»ƒâ€¦. å¾ªç¯å¾€å¤ï¼Œå¾ªç¯çš„å…³é”®åœ¨äºï¼Œç»è¿‡æ¯ä¸ªå¾ªç¯ï¼Œæˆ‘ä»¬éƒ½ä¼šå¾—åˆ°æ›´å¼ºçš„æ£‹æ‰‹ï¼ˆç¥ç»ç½‘ç»œï¼‰ï¼Œæ‰€ä»¥ç»§ç»­ä¼šå¾—åˆ°æ›´é«˜è´¨é‡çš„æ•°æ®ã€‚æœ€åå°±äº§ç”Ÿäº†éå¸¸å¼ºçš„æ£‹æ‰‹ã€‚</li></ol><p><img src="/images/rl_policy_ite.png"></p><p>è¿™ä¸ªç®—æ³•å¯ä»¥è¢«çœ‹ä½œæ˜¯å¢å¼ºå­¦ä¹ é‡Œçš„ç­–ç•¥è¿­ä»£ï¼ˆPolicy Iterationï¼‰ç®—æ³•ï¼š</p><ul><li>Search-Based Policy Improvement ï¼ˆç­–ç•¥å¢å¼ºï¼‰<ul><li>ç”¨å½“å‰çš„ç½‘ç»œè¿›è¡ŒMCTS</li><li>MCTSæœç´¢å‡ºæ¥çš„ç»“æœ &gt; ç¥ç»ç½‘ç»œç›´æ¥é€‰æ‹©çš„ç»“æœï¼ˆå› ä¸ºæœç´¢çš„ç»“æœç»“åˆäº†å‰ç»ï¼‰</li></ul></li><li>Search-Based Policy Evaluation ï¼ˆç­–ç•¥è¯„ä¼°ï¼‰<ul><li>ä½¿ç”¨æœç´¢ç®—æ³•å’Œç¥ç»ç½‘ç»œè¿›è¡Œè‡ªæˆ‘åšå¼ˆ</li><li>è¯„ä¼°æ”¹è¿›åçš„ç­–ç•¥</li></ul></li></ul><p><strong>å­¦ä¹ æ›²çº¿</strong></p><p><img src="/images/gozero_curve.png"></p><p><strong>å®åŠ›</strong></p><p><img src="/images/gozero_rating.png"></p><h2><span id="alphazero">AlphaZero</span></h2><p><img src="/images/alphazero.png"></p><p>AlphaZeroä½¿ç”¨åŒä¸€ç§ç®—æ³•å­¦ä¹ ä¸‰ç§ä¸åŒçš„æ£‹ç±»ï¼Œå¹¶éƒ½å–å¾—äº†è¶…äººçš„æ°´å¹³ã€‚</p><p>æ£‹ç±»AIç ”ç©¶æƒ…å†µæ€»ç»“</p><ul><li>åœ¨AIçš„å†å²ä¸Šå¾ˆæ—©å°±å¼€å§‹ç ”ç©¶æ£‹ç±»ï¼Œå¦‚å›¾çµã€é¦™å†œã€å†¯è¯ºä¼Šæ›¼ç­‰</li><li>ä¸“ä¸€ç³»ç»Ÿæ›¾åœ¨å›½é™…è±¡æ£‹ä¸ŠæˆåŠŸè¿‡<ul><li>æ·±è“åœ¨1997å¹´å‡»è´¥å¡æ°</li><li>ç°åœ¨çš„è±¡æ£‹ç¨‹åºäººç±»å·²æ— æ³•å‡»è´¥</li></ul></li><li>å°†æ£‹ï¼ˆæ—¥æœ¬è±¡æ£‹ï¼‰æ¯”å›½é™…è±¡æ£‹æ›´éš¾<ul><li>æ›´å¤§çš„æ£‹ç›˜å’Œè¡ŒåŠ¨ç©ºé—´</li><li>åªæœ‰æœ€è¿‘çš„ç¨‹åºæ‰è¾¾åˆ°äº†é¾™ç‹çš„æ°´å¹³</li></ul></li><li>æœ€å‰æ²¿çš„å¼•æ“éƒ½æ˜¯æ ¹æ® alpha-beta æœç´¢<ul><li>äººç±»å¤§å¸ˆæ‰‹å·¥ä¼˜åŒ–çš„è¯„ä¼°å‡½æ•°</li><li>æœç´¢åŸŸé’ˆå¯¹ä¸åŒæ£‹ç±»ç–¯ç‹‚ä¼˜åŒ–</li></ul></li></ul><p><img src="/images/gochess.png"></p><p>ç”±ä¸Šå›¾å¯è§å›´æ£‹ä¸å°†æ£‹å’Œè±¡æ£‹è¿˜æ˜¯æœ‰å¾ˆå¤§ä¸åŒçš„ï¼Œä½†æ˜¯AlphaZeroçš„ä¸»è¦ç®—æ³•å’ŒAlphaGo Zeroä¸€æ ·ï¼Œéƒ½æ˜¯è‡ªæˆ‘åšå¼ˆçš„å¢å¼ºå­¦ä¹ ï¼Œåªæ˜¯æŠŠä¸€äº›åªé’ˆå¯¹å›´æ£‹çš„ç»†èŠ‚å»æ‰äº†ï¼ˆæ¯”å¦‚é€šè¿‡æ—‹è½¬è¿›è¡Œæ•°æ®å¢å¼ºï¼Œå› ä¸ºå›´æ£‹æ˜¯å¯¹ç§°çš„ï¼‰å’Œè¾“å…¥è¾“å‡ºç»´åº¦è¿›è¡Œäº†æ”¹å˜ã€‚</p><p>å®ƒçš„å­¦ä¹ æ›²çº¿å¦‚ä¸‹ï¼Œå‡è¾¾åˆ°äº†é¡¶å°–æ°´å¹³ï¼š</p><p><img src="/images/zero_curve2.png"></p><h2><span id="alphazero-and-exit">AlphaZero and ExIt</span></h2><p><a href="https://arxiv.org/abs/1705.08439" target="_blank" rel="noopener">Expert Iterationï¼ˆExItï¼‰</a>æ˜¯ä¸€ç§æ¨¡ä»¿å­¦ä¹ ï¼ˆImitation Learning, ILï¼‰ç®—æ³•ï¼Œæ™®é€šçš„ IL ç®—æ³•ä¸­ï¼Œå¾’å¼Ÿæ¨¡ä»¿ä¸“å®¶çš„ç­–ç•¥åªèƒ½æé«˜è‡ªå·±çš„ç­–ç•¥ï¼Œä¸“å®¶æ˜¯ä¸ä¼šæœ‰ä»»ä½•æé«˜çš„ï¼Œè€Œ ExIt ç®—æ³•å°±æ˜¯æƒ³è®©å¸ˆå‚…æ•™å¾’å¼Ÿçš„æ—¶å€™è‡ªå·±ä¹Ÿæœ‰æé«˜ã€‚</p><p><strong>ExIt ç®—æ³•</strong> å¸ˆå‚…æ ¹æ®å¾’å¼Ÿçš„ç­–ç•¥è¿›è¡Œå‰å‘æœç´¢ï¼ˆä¾‹å¦‚MCTSï¼Œalpha-betaï¼Œè´ªå¿ƒæœç´¢ç­‰ï¼‰ï¼Œå¾—å‡ºæ¯”å¾’å¼Ÿæ›´å¥½çš„ç­–ç•¥ï¼Œç„¶åå¾’å¼Ÿå†å­¦ä¹ å¸ˆå‚…çš„ç­–ç•¥ï¼Œå¦‚æ­¤å¾ªç¯ï¼Œéšç€å¾’å¼Ÿçš„å¢å¼ºï¼Œå¸ˆå‚…ä¹Ÿä¼šè¶Šæ¥è¶Šå¼ºã€‚</p><p><img src="/images/exit.png"></p><p>å¯è§ï¼ŒAlphaZeroä¹Ÿå±äº ExIt ç®—æ³•ï¼Œå¸ˆå‚…ä¸º MCTSï¼Œå¾’å¼Ÿå°±æ˜¯ç¥ç»ç½‘ç»œã€‚</p><h2><span id="summary">Summary</span></h2><p>ç°åœ¨æ£‹ç±»äººå·¥æ™ºèƒ½ç®—æ³•çš„å‘å±•è¶‹åŠ¿æ˜¯è¶Šæ¥è¶Šæ³›åŒ–ï¼Œè¶‹å‘äºå¤šåŠŸèƒ½ã€‚ä» AlphaGo çš„å­¦ä¹ äººç±»ä¸“å®¶çš„æ£‹è°±åˆ° AlphaGo Zero çš„ä»é›¶å¼€å§‹æ— éœ€äººç±»çŸ¥è¯†çš„è‡ªæˆ‘åšå¼ˆå­¦ä¹ å†åˆ° AlphaZero çš„åŒä¸€ç®—æ³•é€‚åº”ä¸åŒæ£‹ç±»å¹¶ä¸”éƒ½å–å¾—è¶…äººæ°´å¹³ã€‚å¯è§äººå·¥æ™ºèƒ½è¶Šæ¥è¶Šå‘é€šç”¨æ™ºèƒ½å‘å±•ï¼Œè™½ç„¶é•¿è·¯æ¼«æ¼«ï¼Œç°åœ¨çš„ç®—æ³•è¿œä¸å¤Ÿæ³›åŒ–ï¼Œä½†æ˜¯å¾ˆå¤šä¸œè¥¿ï¼Œæ¯”å¦‚ç¥ç»ç½‘ç»œç»“æ„éƒ½æ˜¯å¯ä»¥ç”¨åˆ°ä¸åŒé¢†åŸŸçš„ã€‚AlphaGo ç³»åˆ—çš„ä½œè€…ä¹‹ä¸€ David Silver æ›¾è¯´:â€œæ¯æ¬¡ä½ ä¸“é—¨åŒ–ä¸€äº›ä¸œè¥¿éƒ½ä¼šä¼¤å®³ä½ çš„æ³›åŒ–èƒ½åŠ›â€ (Every time you specialize something you hurt your generalization ability.)ã€‚äº‹å®ä¹Ÿçš„ç¡®å¦‚æ­¤ï¼ŒAlphaGo ç³»åˆ—æ¶æ„è¶Šæ¥è¶Šç®€å•ï¼Œè€Œå…¶æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›å´è¶Šæ¥è¶Šå¼ºå¤§ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> AlphaZero </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>è®ºæ–‡ç¿»è¯‘ï¼šåœ¨æ²¡æœ‰äººç±»çŸ¥è¯†çš„æƒ…å†µä¸‹æŒæ¡å›´æ£‹</title>
      <link href="/2018/03/10/%E5%9C%A8%E6%B2%A1%E6%9C%89%E4%BA%BA%E7%B1%BB%E7%9F%A5%E8%AF%86%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E6%8E%8C%E6%8F%A1%E5%9B%B4%E6%A3%8B/"/>
      <url>/2018/03/10/%E5%9C%A8%E6%B2%A1%E6%9C%89%E4%BA%BA%E7%B1%BB%E7%9F%A5%E8%AF%86%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E6%8E%8C%E6%8F%A1%E5%9B%B4%E6%A3%8B/</url>
      
        <content type="html"><![CDATA[<h4><span id="1-å‰è¨€">1. å‰è¨€</span></h4><p>â€‹ äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé•¿æœŸç›®æ ‡æ˜¯åœ¨ä¸€äº›æœ‰æŒ‘æˆ˜çš„é¢†åŸŸä¸­ä»é›¶å¼€å§‹å­¦ä¹ å‡ºè¶…äººç†Ÿç»ƒç¨‹åº¦çš„ç®—æ³•ã€‚æœ€è¿‘ï¼ŒAlphaGoæˆä¸ºç¬¬ä¸€ä¸ªåœ¨å›´æ£‹æ¯”èµ›ä¸­å‡»è´¥ä¸–ç•Œå† å†›çš„ç¨‹åºã€‚ AlphaGoä¸­çš„æ ‘æœç´¢ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œè¯„ä¼°ä½ç½®å’Œé€‰å®šçš„ç§»åŠ¨ã€‚è¿™äº›ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡ç›‘ç£å­¦ä¹ æ¥è‡ªäººç±»ä¸“å®¶çš„èµ°æ³•ä»¥åŠé€šè¿‡å¼ºåŒ–è‡ªæˆ‘å­¦ä¹ æ¥è¿›è¡Œè®­ç»ƒçš„ã€‚è¿™é‡Œæˆ‘ä»¬åªä»‹ç»ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç®—æ³•ï¼Œæ²¡æœ‰è¶…å‡ºæ¸¸æˆè§„åˆ™çš„äººç±»æ•°æ®ï¼ŒæŒ‡å¯¼æˆ–é¢†åŸŸçŸ¥è¯†ã€‚AlphaGoæˆä¸ºè‡ªå·±çš„è€å¸ˆï¼šä¸€ä¸ªç¥ç»ç½‘ç»œè®­ç»ƒé¢„æµ‹AlphaGoçš„ç§»åŠ¨é€‰æ‹©å’Œæ¸¸æˆçš„èƒœè€…ã€‚è¿™ä¸ªç¥ç»ç½‘ç»œæé«˜äº†æ ‘æœç´¢çš„å¼ºåº¦ï¼Œåœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­æ‹¥æœ‰æ›´é«˜è´¨é‡çš„ç§»åŠ¨é€‰æ‹©å’Œæ›´å¼ºçš„è‡ªæˆ‘å­¦ä¹ ã€‚æˆ‘ä»¬çš„æ–°ç¨‹åºAlphaGo Zeroä»é›¶å¼€å§‹å­¦ä¹ ï¼Œå®ç°äº†è¶…äººçš„è¡¨ç°ï¼Œä¸ä¹‹å‰å‘å¸ƒçš„å¤ºå† å† å†›AlphaGoç›¸æ¯”ä»¥100-0å–èƒœã€‚</p><a id="more"></a><h4><span id="2-æ¦‚è¿°">2. æ¦‚è¿°</span></h4><p>â€‹ å›´æ£‹ç¨‹åºåœ¨äººå·¥æ™ºèƒ½æ–¹é¢å·²ç»å–å¾—äº†å¾ˆå¤§çš„è¿›å±•ï¼Œä½¿ç”¨ç»è¿‡è®­ç»ƒçš„ç›‘ç£å­¦ä¹ ç³»ç»Ÿæ¥å¤åˆ¶äººç±»ä¸“å®¶çš„å†³å®šã€‚ä½†æ˜¯ï¼Œä¸“å®¶æ•°æ®é›†é€šå¸¸å¾ˆæ˜‚è´µï¼Œä¸å¯é æˆ–æ ¹æœ¬æ— æ³•ä½¿ç”¨ã€‚å³ä½¿æœ‰å¯é çš„æ•°æ®é›†ï¼Œå®ƒä»¬ä¹Ÿå¯èƒ½ä¼šå¯¹ä»¥è¿™ç§æ–¹å¼åŸ¹è®­çš„ç³»ç»Ÿçš„æ€§èƒ½æ–½åŠ ä¸Šé™ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¼ºåŒ–å­¦ä¹ ç³»ç»Ÿæ˜¯æ ¹æ®ä»–ä»¬è‡ªå·±çš„ç»éªŒè¿›è¡Œå­¦ä¹ çš„ï¼ŒåŸåˆ™ä¸Šå…è®¸ä»–ä»¬è¶…è¶Šäººç±»èƒ½åŠ›ï¼Œå¹¶åœ¨ç¼ºä¹äººåŠ›ä¸“ä¸šçŸ¥è¯†çš„é¢†åŸŸè¿ä½œã€‚æœ€è¿‘ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œæœç€è¿™ä¸ªç›®æ ‡å¿«é€Ÿå‘å±•ã€‚è¿™äº›ç³»ç»Ÿåœ¨è®¡ç®—æœºæ¸¸æˆä¸­èƒœè¿‡äººç±»ï¼Œå¦‚Atariæ¸¸æˆå’Œ3Dè™šæ‹Ÿç¯å¢ƒã€‚ç„¶è€Œï¼Œåœ¨äººç±»æ™ºåŠ›æ–¹é¢æœ€å…·æŒ‘æˆ˜æ€§çš„é¢†åŸŸ - æ¯”å¦‚è¢«å¹¿æ³›è®¤ä¸ºæ˜¯äººå·¥æ™ºèƒ½çš„å·¨å¤§æŒ‘æˆ˜çš„å›´æ£‹æ¸¸æˆ - åœ¨å¹¿é˜”çš„æœç´¢ç©ºé—´ä¸­éœ€è¦ç²¾ç¡®å’Œå¤æ‚çš„æœç´¢ã€‚ä»¥å‰çš„æ–¹æ³•æ²¡æœ‰åœ¨è¿™äº›é¢†åŸŸå®ç°è¾¾åˆ°äººç±»æ°´å¹³çš„è¡¨ç°ã€‚</p><p>â€‹ AlphaGo æ˜¯ç¬¬ä¸€ä¸ªåœ¨å›´æ£‹ä¸­å®ç°è¶…äººè¡¨ç°çš„ç¨‹åºã€‚ä¹‹å‰å‘å¸ƒçš„ç‰ˆæœ¬ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºAlphaGo Fanï¼Œäº2015å¹´10æœˆå‡»è´¥äº†æ¬§æ´²å† å†›èŒƒè¾‰ã€‚AlphaGo Fan ä½¿ç”¨äº†ä¸¤ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œï¼šè¾“å‡ºç§»åŠ¨æ¦‚ç‡çš„ç­–ç•¥ç½‘ç»œå’Œè¾“å‡ºä½ç½®è¯„ä¼°çš„ä»·å€¼ç½‘ç»œã€‚ç­–ç•¥ç½‘ç»œæœ€åˆæ˜¯é€šè¿‡ç›‘ç£å­¦ä¹ æ¥å‡†ç¡®åœ°é¢„æµ‹äººç±»ä¸“å®¶çš„è¡Œä¸ºï¼Œéšåé€šè¿‡ç­–ç•¥å‡çº§å¼ºåŒ–å­¦ä¹ è¿›è¡Œäº†æ”¹è¿›ã€‚ä»·å€¼ç½‘ç»œç»è¿‡è®­ç»ƒï¼Œå¯ä»¥é¢„æµ‹æ¸¸æˆçš„èƒœè€…ã€‚ä¸€æ—¦å¼€å§‹è®­ç»ƒï¼Œè¿™äº›ç½‘ç»œå°±ä¼šä¸è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ç»“åˆä½¿ç”¨ï¼Œä»è€Œæä¾›å…ˆè¡Œæœç´¢ï¼Œä½¿ç”¨ç­–ç•¥ç½‘ç»œå°†æœç´¢èŒƒå›´ç¼©å°ä¸ºé«˜æ¦‚ç‡ç§»åŠ¨ï¼Œå¹¶ä½¿ç”¨ä»·å€¼ç½‘ç»œæ¥è¯„ä¼°æ ‘ä¸­çš„ä½ç½®ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸º AlphaGo Lee çš„åç»­ç‰ˆæœ¬ä½¿ç”¨äº†ç±»ä¼¼çš„æ–¹æ³•ï¼Œå¹¶äº2016å¹´3æœˆå‡»è´¥äº†è·å¾—18ä¸ªå›½é™…å† å†›çš„Lee Sedolã€‚</p><p>â€‹ AlphaGo Zero ä¸ AlphaGo Fan å’Œ AlphaGo Lee åœ¨å‡ ä¸ªé‡è¦æ–¹é¢ä¸åŒã€‚é¦–å…ˆï¼Œå®ƒåªæ˜¯é€šè¿‡è‡ªæˆ‘å¢å¼ºå¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»éšæœºæ¯”èµ›å¼€å§‹ï¼Œæ²¡æœ‰ä»»ä½•ç›‘ç£æˆ–ä½¿ç”¨äººç±»æ•°æ®ã€‚å…¶æ¬¡ï¼Œå®ƒåªä½¿ç”¨é»‘ç™½æ£‹ä½ç½®ä½œä¸ºè¾“å…¥ã€‚ç¬¬ä¸‰ï¼Œå®ƒä½¿ç”¨å•ä¸€çš„ç¥ç»ç½‘ç»œï¼Œè€Œä¸æ˜¯å•ç‹¬çš„ç­–ç•¥å’Œä»·å€¼ç½‘ç»œã€‚æœ€åï¼Œå®ƒä½¿ç”¨æ›´ç®€å•çš„æœç´¢æ ‘ï¼Œè¯¥æœç´¢ä¾èµ–äºè¿™ä¸ªå•ä¸€çš„ç¥ç»ç½‘ç»œæ¥è¯„ä¼°ä½ç½®å’Œç§»åŠ¨ï¼Œè€Œæ— éœ€æ‰§è¡Œä»»ä½• Monte Carlo å›æº¯ã€‚ä¸ºäº†å®ç°è¿™äº›ç»“æœï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨è®­ç»ƒç¯å†…éƒ¨ç»“åˆäº†å‰ç»æœç´¢ï¼Œä»è€Œå®ç°äº†å¿«é€Ÿæ”¹è¿›å’Œç²¾ç¡®è€Œç¨³å®šçš„å­¦ä¹ ã€‚åœ¨æ–¹æ³•ä¸€æ ä¸­ä¸­æè¿°äº†æœç´¢ç®—æ³•ï¼Œè®­ç»ƒè¿‡ç¨‹å’Œç½‘ç»œä½“ç³»ç»“æ„ä¸­çš„å…¶ä»–æŠ€æœ¯å·®å¼‚ã€‚</p><h4><span id="3-alphago-zero-ä¸­çš„å¢å¼ºå­¦ä¹ ">3. AlphaGo Zero ä¸­çš„å¢å¼ºå­¦ä¹ </span></h4><p>â€‹ æˆ‘ä»¬çš„æ–°æ–¹æ³•ä½¿ç”¨å‚æ•°ä¸º <span class="math inline">\(\theta\)</span> çš„æ·±åº¦ç¥ç»ç½‘ç»œ <span class="math inline">\(f(\theta)\)</span>ã€‚è¯¥ç¥ç»ç½‘ç»œå°†ä½ç½®åŠå…¶å†å²çš„åŸå§‹å¹³é¢è¡¨ç¤º s ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºç§»åŠ¨æ¦‚ç‡å’Œä»·å€¼ <span class="math inline">\((p,v)=f_\theta(s)\)</span>ã€‚ ç§»åŠ¨æ¦‚ç‡ p çš„å‘é‡è¡¨ç¤ºé€‰æ‹©æ¯ä¸ªç§»åŠ¨ a çš„æ¦‚ç‡ï¼Œ<span class="math inline">\(P_a=Pr(a|s)\)</span> ã€‚ä»·å€¼ v æ˜¯ä¸€ä¸ªæ ‡é‡è¯„ä¼°ï¼Œç”¨äºä¼°è®¡å½“å‰ç©å®¶ä»ä½ç½® s è·èƒœçš„æ¦‚ç‡ã€‚è¿™ä¸ªç¥ç»ç½‘ç»œå°†ç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œç»“åˆåˆ°ä¸€ä¸ªç½‘ç»œä¸­ã€‚ç¥ç»ç½‘ç»œç”±å·ç§¯å±‚ï¼Œè®¸å¤šæ®‹å·®å—ç»„æˆï¼Œæ‰¹é‡å½’ä¸€åŒ–å’Œéçº¿æ€§æ•´æµå™¨ï¼ˆå‚è§æ–¹æ³•ï¼‰ç»„æˆã€‚</p><p>â€‹ AlphaGo Zero ä¸­çš„ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡ä¸€ç§æ–°å‹çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ä»è‡ªæˆ‘åšå¼ˆçš„æ¸¸æˆä¸­è®­ç»ƒå‡ºæ¥çš„ã€‚åœ¨æ¯ä¸ªä½ç½® <span class="math inline">\(s\)</span>ï¼Œæ‰§è¡Œ MCTS æœç´¢ï¼Œç”±ç¥ç»ç½‘ç»œ <span class="math inline">\(f(\theta)\)</span> æŒ‡å¯¼ã€‚MCTS æœç´¢è¾“å‡ºæ¯æ¬¡ç§»åŠ¨çš„æ¦‚ç‡ <span class="math inline">\(Ï€\)</span>ã€‚è¿™äº›æœç´¢æ¦‚ç‡é€šå¸¸é€‰æ‹©æ¯”ç¥ç»ç½‘ç»œçš„åŸå§‹ç§»åŠ¨æ¦‚ç‡ <span class="math inline">\(p\)</span> æ›´åŠ å¼ºå¤§;å› æ­¤ï¼ŒMCTS å¯è¢«è§†ä¸ºç­–ç•¥æ”¹è¿›çš„æ“ä½œã€‚ä½¿ç”¨æœç´¢è¿›è¡Œè‡ªæˆ‘åšå¼ˆ - ä½¿ç”¨æ”¹è¿›çš„åŸºäº MCTS çš„ç­–ç•¥æ¥é€‰æ‹©æ¯ä¸ªåŠ¨ä½œï¼Œç„¶åä½¿ç”¨æ¸¸æˆè·èƒœè€… <span class="math inline">\(z\)</span> ä½œä¸ºä»·å€¼çš„æ ·æœ¬ - å¯ä»¥è¢«è§†ä¸ºä¸€ä¸ªå¼ºå¤§çš„ç­–ç•¥è¯„ä¼°æ“ä½œã€‚æˆ‘ä»¬çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„ä¸»è¦æ€æƒ³æ˜¯åœ¨ç­–ç•¥è¿­ä»£è¿‡ç¨‹ä¸­é‡å¤ä½¿ç”¨è¿™äº›æ“ä½œï¼šæ›´æ–°ç¥ç»ç½‘ç»œçš„å‚æ•°ä»¥ä½¿ç§»åŠ¨æ¦‚ç‡å’Œå€¼ <span class="math inline">\((p,v)=f_\theta(s)\)</span> æ›´ç´§å¯†åŒ¹é…æ”¹è¿›çš„æœç´¢æ¦‚ç‡å’Œè·èƒœè€… <span class="math inline">\((\pi,z)\)</span>ï¼›è¿™äº›æ–°å‚æ•°å°†ç”¨äºä¸‹ä¸€æ¬¡è‡ªæˆ‘åšå¼ˆï¼Œä»¥ä½¿æœç´¢æ›´åŠ å¼ºå¤§ã€‚å›¾ 1è¯´æ˜äº†è‡ªæˆ‘åšå¼ˆè®­ç»ƒæµç¨‹ã€‚</p><p><img src="/images/selfplay.png"></p><p>â€‹ <em>å›¾1 AlphaGo Zeroä¸­çš„è‡ªæˆ‘åšå¼ˆä¸å¢å¼ºå­¦ä¹ è®­ç»ƒæµç¨‹</em></p><p>â€‹ MCTS ä½¿ç”¨ç¥ç»ç½‘ç»œ <span class="math inline">\(f(\theta)\)</span> æ¥æŒ‡å¯¼å…¶æ¨¡æ‹Ÿï¼ˆè§å›¾ 2ï¼‰ã€‚æœç´¢æ ‘ä¸­çš„æ¯ä¸ªè¾¹ <span class="math inline">\((s,a)\)</span> å­˜å‚¨å…ˆéªŒæ¦‚ç‡ <span class="math inline">\(P(s,a)\)</span>ï¼Œè®¿é—®è®¡æ•° <span class="math inline">\(N(s,a)\)</span> å’ŒåŠ¨ä½œä»·å€¼ <span class="math inline">\(Q(s,a)\)</span> ã€‚æ¯ä¸ªæ¨¡æ‹Ÿä»æ ¹çŠ¶æ€å¼€å§‹ï¼Œå¹¶ä¸”è¿­ä»£åœ°é€‰æ‹©ä½¿ç½®ä¿¡ä¸Šé™ <span class="math inline">\(Q(s,a)+U(s,a)\)</span> æœ€å¤§åŒ–çš„ç§»åŠ¨ï¼Œå…¶ä¸­<span class="math inline">\(U\propto \frac{P(s,a)}{1+N(s,a)}\)</span>ï¼Œç›´åˆ°é‡åˆ°å¶èŠ‚ç‚¹ <span class="math inline">\(s&#39;\)</span>ã€‚è¯¥å¶å­ä½ç½®è¢«ç½‘ç»œæ‰©å±•å’Œè¯„ä¼°ä¸€æ¬¡ï¼Œä»¥äº§ç”Ÿå…ˆéªŒæ¦‚ç‡å’Œè¯„ä¼°ï¼Œ<span class="math inline">\((P(s&#39;, \cdot), v(s&#39;))=f_\theta(s&#39;)\)</span>ã€‚åœ¨æ¨¡æ‹Ÿä¸­éå†çš„æ¯ä¸ªè¾¹ <span class="math inline">\((s,a)\)</span> è¢«æ›´æ–°ä»¥å¢åŠ å…¶è®¿é—®è®¡æ•° <span class="math inline">\(N(s,a)\)</span>ï¼Œå¹¶ä¸”å°†å…¶åŠ¨ä½œä»·å€¼æ›´æ–°ä¸ºåœ¨è¿™äº›æ¨¡æ‹Ÿä¸Šçš„å¹³å‡è¯„ä¼° <span class="math inline">\(Q(s,a) = \frac{1}{N(s,a)}\sum_{s&#39;|s,a\rightarrow s&#39;}V(s&#39;)\)</span>ï¼Œ å…¶ä¸­ <span class="math inline">\(s,a\rightarrow s&#39;\)</span> è¡¨ç¤ºåœ¨ä»ä½ç½® <span class="math inline">\(s\)</span> æ‰§è¡Œè¡ŒåŠ¨ <span class="math inline">\(a\)</span> åæ¨¡æ‹Ÿæœ€ç»ˆè¾¾åˆ°ä½ç½® <span class="math inline">\(s&#39;\)</span>ã€‚</p><p><img src="/images/mcts0.png"></p><p>â€‹ <em>å›¾2 AlphaGo Zeroä¸­çš„è’™ç‰¹å¡æ´›æœç´¢æ ‘</em></p><p>â€‹ MCTS å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ç§è‡ªæˆ‘åšå¼ˆç®—æ³•ï¼Œåœ¨ç»™å®šç¥ç»ç½‘ç»œå‚æ•° <span class="math inline">\(Î¸\)</span> å’Œæ ¹ä½ç½® <span class="math inline">\(s\)</span> çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—æ¨èç§»åŠ¨çš„æœç´¢æ¦‚ç‡çŸ¢é‡ï¼Œ<span class="math inline">\(\pi = a_\theta(s)\)</span>ï¼Œä¸æ¯æ¬¡ç§»åŠ¨çš„è®¿é—®è®¡æ•°çš„æŒ‡æ•°æˆæ¯”ä¾‹ï¼Œ<span class="math inline">\(\pi_a\propto N(s,a)^{1/\tau}\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(Ï„\)</span> æ˜¯æ¸©åº¦å‚æ•°ã€‚</p><p>â€‹ ç¥ç»ç½‘ç»œé€šè¿‡ä½¿ç”¨ MCTS é€‰æ‹©æ¯ä¸ªåŠ¨ä½œçš„è‡ªæˆ‘åšå¼ˆå¢å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œè®­ç»ƒã€‚é¦–å…ˆï¼Œç¥ç»ç½‘ç»œè¢«åˆå§‹åŒ–ä¸ºéšæœºæƒé‡ <span class="math inline">\(\theta_0\)</span>ã€‚åœ¨éšåçš„æ¯æ¬¡è¿­ä»£ <span class="math inline">\(iâ‰¥1\)</span> æ—¶ï¼Œäº§ç”Ÿè‡ªæˆ‘åšå¼ˆçš„æ•°æ®ï¼ˆå›¾ 1ï¼‰ã€‚åœ¨æ¯ä¸ªæ—¶åˆ» <span class="math inline">\(t\)</span>ï¼Œä½¿ç”¨å…ˆå‰çš„ç¥ç»ç½‘ç»œè¿­ä»£ <span class="math inline">\(f_{\theta_{i-1}}\)</span> æ‰§è¡Œ MCTS æœç´¢ï¼Œå¹¶ä¸”é€šè¿‡å¯¹æœç´¢æ¦‚ç‡ <span class="math inline">\(\pi_t\)</span> è¿›è¡Œé‡‡æ ·æ¥æ‰§è¡Œç§»åŠ¨ã€‚å½“ä¸¤ä¸ªç©å®¶éƒ½æ— è·¯å¯èµ°æ—¶æˆ–è€…å½“æœç´¢å€¼ä¸‹é™åˆ°ä½äºé˜ˆå€¼æˆ–å½“æ¸¸æˆè¶…è¿‡æœ€å¤§é•¿åº¦æ—¶ï¼Œæ¸¸æˆåœ¨æ—¶åˆ» <span class="math inline">\(T\)</span> ç»ˆæ­¢;ç„¶åå¯¹æ¸¸æˆè¿›è¡Œè¯„åˆ†ä»¥ç»™å‡º <span class="math inline">\(r_T\in\{-1,+1\}\)</span> çš„æœ€ç»ˆå¥–åŠ±ï¼ˆè¯¦è§æ–¹æ³•ï¼‰ã€‚æ¯ä¸ªæ—¶åˆ» <span class="math inline">\(t\)</span> çš„æ•°æ®å­˜å‚¨ä¸º <span class="math inline">\((s_t,\pi_t,z_t)\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(z_t = \pm r_T\)</span> æ˜¯æ—¶åˆ» <span class="math inline">\(t\)</span> ä»å½“å‰ç©å®¶è§’åº¦å‡ºå‘çš„æ¸¸æˆè·èƒœè€…ã€‚åŒæ—¶ï¼ˆå¦‚å›¾ 1ï¼‰ï¼Œæ–°çš„ç½‘ç»œå‚æ•° <span class="math inline">\(\theta_i\)</span> ä»æœ€åä¸€æ¬¡è‡ªæˆ‘åšå¼ˆçš„æ‰€æœ‰æ—¶é—´ä¸­ç»Ÿä¸€é‡‡æ ·çš„æ•°æ® <span class="math inline">\((s,\pi,t)\)</span> è¿›è¡Œè®­ç»ƒã€‚è°ƒæ•´ç¥ç»ç½‘ç»œ <span class="math inline">\((p,v)=f_{\theta_i}(s)\)</span> ä»¥æœ€å°åŒ–é¢„æµ‹å€¼ <span class="math inline">\(v\)</span> ä¸å®é™…èµ¢å¾—è€… <span class="math inline">\(z\)</span>ä¹‹é—´çš„è¯¯å·®ï¼Œå¹¶ä½¿ç¥ç»ç½‘ç»œç§»åŠ¨æ¦‚ç‡ <span class="math inline">\(p\)</span> ä¸æœç´¢æ¦‚ç‡ <span class="math inline">\(Ï€\)</span> çš„ç›¸ä¼¼æ€§æœ€å¤§åŒ–ã€‚å…·ä½“è€Œè¨€ï¼Œå‚æ•° <span class="math inline">\(Î¸\)</span> é€šè¿‡æ¢¯åº¦ä¸‹é™åœ¨æŸå¤±å‡½æ•° <span class="math inline">\(l\)</span> ä¸Šè¿›è¡Œè°ƒæ•´ï¼Œæ‰€è¿°æŸå¤±å‡½æ•° <span class="math inline">\(l\)</span> åˆ†åˆ«å¯¹å‡æ–¹è¯¯å·®å’Œäº¤å‰ç†µè¯¯å·®è¿›è¡Œæ±‚å’Œï¼š <span class="math display">\[(p,v)=f_\theta(s) \mbox{ and }l=(z-v)^2-\pi^T\log p+c||\theta||^2\]</span> å…¶ä¸­ <span class="math inline">\(c\)</span> æ˜¯æ§åˆ¶ L2 æ­£åˆ™åŒ–ç¨‹åº¦çš„è¶…å‚æ•°ï¼ˆä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼‰ã€‚</p><h4><span id="4-alphago-zero-çš„å®éªŒåˆ†æ">4. AlphaGo Zero çš„å®éªŒåˆ†æ</span></h4><p>â€‹ æˆ‘ä»¬ä½¿ç”¨ä¸Šè¿°å¼ºåŒ–å­¦ä¹ æµç¨‹æ¥è®­ç»ƒ AlphaGo Zeroã€‚è®­ç»ƒä»å®Œå…¨éšæœºçš„è¡Œä¸ºå¼€å§‹ï¼ŒæŒç»­çº¦ä¸‰å¤©ä¸”æ— äººä¸ºå¹²é¢„ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ª MCTS ä½¿ç”¨ 1,600 æ¬¡æ¨¡æ‹Ÿï¼Œæ¯æ¬¡ç§»åŠ¨çš„æ€è€ƒæ—¶é—´å¤§çº¦ä¸º 0.4sï¼Œä»è€Œäº§ç”Ÿäº† 490 ä¸‡å±€è‡ªæˆ‘åšå¼ˆã€‚ å‚æ•°ä» 700,000 ä¸ªåŒ…å« 2048 ä¸ªçŠ¶æ€çš„æ‰¹é‡ä¸­æ›´æ–°ã€‚ç¥ç»ç½‘ç»œåŒ…å« 20 ä¸ªæ®‹ä½™å—ã€‚</p><p>â€‹ å›¾ 3 æ˜¾ç¤ºäº† AlphaGo Zero åœ¨è‡ªæˆ‘åšå¼ˆè¿‡ç¨‹ä¸­çš„è¡¨ç°ï¼Œæ¨ªåæ ‡ä¸ºè®­ç»ƒæ—¶é—´ï¼Œçºµåæ ‡ä¸º Elo é‡ã€‚æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹è¿›å±•é¡ºåˆ©ï¼Œå¹¶ä¸”æ²¡æœ‰é­å—å…ˆå‰æ–‡çŒ®ä¸­æå‡ºçš„æŒ¯è¡æˆ–ç¾éš¾æ€§é—å¿˜ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼ŒAlphaGo Zero ä»…ä»… 36 å°æ—¶å°±èµ¢äº†AlphaGo Leeã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒAlphaGo Lee è®­ç»ƒäº†å‡ ä¸ªæœˆã€‚åœ¨ 72 å°æ—¶åï¼Œæˆ‘ä»¬æ ¹æ®åœ¨é¦–å°”äººæœºæ¯”èµ›ä¸­ä½¿ç”¨çš„ç›¸åŒçš„ 2 å°æ—¶æ—¶é—´æ§åˆ¶å’ŒåŒ¹é…æ¡ä»¶ï¼Œå¯¹ AlphaGo Zero ä¸ AlphaGo Lee çš„ç¡®åˆ‡ç‰ˆæœ¬è¿›è¡Œäº†è¯„ä¼°ï¼Œè¯¥ç‰ˆæœ¬å‡»è´¥äº† Lee Sedolã€‚AlphaGo Zero ä½¿ç”¨å¸¦æœ‰4ä¸ªå¼ é‡å¤„ç†å•å…ƒï¼ˆTPUï¼‰çš„å•å°æœºå™¨ï¼Œè€Œ AlphaGo Lee åˆ†å¸ƒåœ¨å¤šå°æœºå™¨ä¸Šå¹¶ä½¿ç”¨ 48 ä¸ªTPUã€‚AlphaGo Zero å°† AlphaGo Lee ä»¥ 100 æ¯” 0 å‡»è´¥ã€‚</p><p>â€‹ ä¸ºäº†è¯„ä¼°è‡ªæˆ‘å¼ºåŒ–å­¦ä¹ çš„ä¼˜ç‚¹ï¼Œä¸ä»äººç±»æ•°æ®ä¸­å­¦ä¹ ç›¸æ¯”ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ç¬¬äºŒä¸ªç¥ç»ç½‘ç»œï¼ˆä½¿ç”¨ç›¸åŒçš„ä½“ç³»ç»“æ„ï¼‰æ¥é¢„æµ‹ KGS æœåŠ¡å™¨æ•°æ®é›†ä¸­çš„ä¸“å®¶åŠ¨ä½œ; ä¸ä¹‹å‰çš„å·¥ä½œç›¸æ¯”ï¼Œè¿™å®ç°äº†é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚ ç›‘ç£å¼å­¦ä¹ çš„åˆå§‹è¡¨ç°æ›´å¥½ï¼Œå¹¶ä¸”æ›´å¥½åœ°é¢„æµ‹äººç±»èŒä¸šåŠ¨ä½œï¼ˆå›¾ 3ï¼‰ã€‚ å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡ç›‘ç£å­¦ä¹ è·å¾—äº†æ›´é«˜çš„ç§»åŠ¨é¢„æµ‹å‡†ç¡®åº¦ï¼Œä½†è‡ªå­¦è€…çš„æ•´ä½“è¡¨ç°æ›´å¥½ï¼Œåœ¨è®­ç»ƒçš„å‰ 24 å°æ—¶å†…å‡»è´¥äº†è®­ç»ƒæœ‰ç´ çš„é€‰æ‰‹ã€‚è¿™è¡¨æ˜ AlphaGo Zero å¯èƒ½æ­£åœ¨å­¦ä¹ ä¸€ç§ä¸äººç±»ä¸‹æ£‹ä¸åŒçš„ç­–ç•¥ã€‚</p><p><img src="/images/ag0em.png"></p><p>â€‹ <em>å›¾3 AlphaGo Zeroçš„å®éªŒè¯„ä¼°</em></p><p>â€‹ ä¸ºäº†åˆ†ç¦»æ¶æ„å’Œç®—æ³•çš„è´¡çŒ®ï¼Œæˆ‘ä»¬å°† AlphaGo Zero ä¸­çš„ç¥ç»ç½‘ç»œæ¶æ„çš„æ€§èƒ½ä¸ AlphaGo Lee ä¸­ä½¿ç”¨çš„ä»¥å‰çš„ç¥ç»ç½‘ç»œæ¶æ„è¿›è¡Œäº†æ¯”è¾ƒï¼ˆè§å›¾ 4ï¼‰ã€‚ æ–°è®­ç»ƒçš„AlphaGo Zero æœ‰å››ä¸ªç‰ˆæœ¬çš„ç¥ç»ç½‘ç»œï¼Œåˆ†åˆ«æ˜¯ï¼šä½¿ç”¨ AlphaGo Lee çš„å·ç§¯ç½‘ç»œæ¶æ„ï¼›AlphaGo Zero çš„å‰©ä½™ç½‘ç»œæ¶æ„ï¼›ä½¿ç”¨ AlphaGo Zero çš„å·ç§¯ç½‘ç»œæ¶æ„ï¼›ä½¿ç”¨AlphaGo Lee çš„å‰©ä½™ç½‘ç»œæ¶æ„ã€‚æ¯ä¸ªç½‘ç»œéƒ½ç»è¿‡è®­ç»ƒï¼Œä»¥æœ€å°åŒ–ç›¸åŒçš„æŸå¤±å‡½æ•°ï¼Œä½¿ç”¨ç”± AlphaGo Zero åœ¨è‡ªæˆ‘è®­ç»ƒ 72 å°æ—¶åäº§ç”Ÿçš„å›ºå®šæ•°æ®é›†ã€‚ä½¿ç”¨å‰©ä½™ç½‘ç»œæ›´å‡†ç¡®ï¼Œå®ç°äº†æ›´ä½çš„è¯¯å·®ï¼ŒAlphaGo çš„æ€§èƒ½æé«˜äº† 600 å¤š Eloã€‚å°†ç­–ç•¥å’Œä»·å€¼ç»„åˆåœ¨ä¸€èµ·æˆä¸ºä¸€ä¸ªç½‘ç»œï¼Œç•¥å¾®é™ä½äº†ç§»åŠ¨é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œä½†æ˜¯å°†é™ä½äº† AlphaGo çš„ä»·å€¼è¯¯å·®å’Œæé«˜äº†åšå¼ˆæ€§èƒ½çº¦ 600 ä¸ª Eloã€‚éƒ¨åˆ†åŸå› åœ¨äºæé«˜äº†è®¡ç®—æ•ˆç‡ï¼Œä½†æ›´é‡è¦çš„æ˜¯ï¼ŒåŒé‡ç›®æ ‡å°†ç½‘ç»œæ­£åˆ™åŒ–ä¸ºæ”¯æŒå¤šç§ç”¨ä¾‹çš„è¡¨ç¤ºã€‚</p><p><img src="/images/ag02.png"></p><p>â€‹ <em>å›¾4 AlphaGo Zeroå’ŒAlphaGo Leeçš„ç¥ç»ç½‘ç»œç»“æ„æ¯”è¾ƒ</em></p><h4><span id="5-alphago-zero-å­¦ä¹ åˆ°çš„å›´æ£‹çŸ¥è¯†">5. AlphaGo Zero å­¦ä¹ åˆ°çš„å›´æ£‹çŸ¥è¯†</span></h4><p>â€‹ AlphaGoZeroåœ¨å…¶è‡ªæˆ‘åšå¼ˆè®­ç»ƒè¿‡ç¨‹ä¸­å‘ç°äº†éå‡¡çš„å›´æ£‹çŸ¥è¯†æ°´å¹³ã€‚è¿™ä¸ä»…åŒ…æ‹¬äººç±»å›´æ£‹çŸ¥è¯†çš„åŸºæœ¬è¦ç´ ï¼Œè¿˜åŒ…æ‹¬è¶…å‡ºä¼ ç»Ÿå›´æ£‹çŸ¥è¯†èŒƒå›´çš„éæ ‡å‡†ç­–ç•¥ã€‚</p><p>â€‹ å›¾ 5æ˜¾ç¤ºäº†ä¸€ä¸ªæ—¶é—´çº¿ï¼Œè¡¨æ˜ä½•æ—¶å‘ç°äº†ä¸“ä¸š josekiï¼ˆè§’ç‚¹åºåˆ—ï¼‰;æœ€ç»ˆAlphaGo Zero æ›´å–œæ¬¢å…ˆå‰æœªçŸ¥çš„æ–°çš„ joseki å˜ä½“ï¼ˆå›¾5b ï¼‰ã€‚å›¾5c æ˜¾ç¤ºäº†å‡ ç§åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µè¿›è¡Œçš„å¿«é€Ÿè‡ªæˆ‘åšå¼ˆã€‚åœ¨æ•´ä¸ªè®­ç»ƒä¸­å®šæœŸè¿›è¡Œçš„é”¦æ ‡èµ›é•¿åº¦æ¯”èµ›åœ¨è¡¥å……ä¿¡æ¯ä¸­æ˜¾ç¤ºã€‚ AlphaGo Zero ä»å®Œå…¨éšæœºçš„ç§»åŠ¨è¿‡æ¸¡åˆ°å¯¹å›´æ£‹æ¦‚å¿µçš„å¤æ‚ç†è§£ï¼ŒåŒ…æ‹¬fusekiï¼ˆå¼€åœºï¼‰ï¼Œtesujiï¼ˆæˆ˜æœ¯ï¼‰ï¼Œç”Ÿä¸æ­»ï¼Œkoï¼ˆé‡å¤æ£‹å±€ï¼‰ï¼Œyoseï¼ˆç»ˆå±€ï¼‰ï¼Œæ•æ‰æ¯”èµ›ï¼Œsenteï¼ˆå€¡è®®ï¼‰ï¼Œå½¢çŠ¶ï¼Œå½±å“åŠ›å’Œé¢†åœŸï¼Œéƒ½æ˜¯ä»æœ€åˆçš„åŸåˆ™å‘ç°çš„ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼ŒShocho - äººç±»å­¦ä¹ çš„å›´æ£‹çŸ¥è¯†çš„ç¬¬ä¸€è¦ç´ ä¹‹ä¸€ - åªæœ‰åœ¨ AlphaGo Zero çš„è®­ç»ƒä¸­æ‰èƒ½è¢«ç†è§£ã€‚</p><p><img src="/images/ag05.png"></p><p>â€‹ <em>å›¾5 AlphaGo Zeroå­¦åˆ°çš„å›´æ£‹çŸ¥è¯†</em></p><h4><span id="6-alphago-zero-çš„æœ€ç»ˆæ°´å¹³">6. AlphaGo Zero çš„æœ€ç»ˆæ°´å¹³</span></h4><p>â€‹ éšåæˆ‘ä»¬ä½¿ç”¨æ›´å¤§çš„ç¥ç»ç½‘ç»œå’Œæ›´é•¿çš„æŒç»­æ—¶é—´å°†æˆ‘ä»¬çš„å¼ºåŒ–å­¦ä¹ ç®¡é“åº”ç”¨äºAlphaGo Zeroçš„ç¬¬äºŒä¸ªå®ä¾‹ã€‚å†æ¬¡è®­ç»ƒä»å®Œå…¨éšæœºè¡Œä¸ºå¼€å§‹å¹¶æŒç»­å¤§çº¦40å¤©ã€‚</p><p>â€‹ åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œäº§ç”Ÿäº† 2900 ä¸‡æ¬¡è‡ªæˆ‘åšå¼ˆã€‚å‚æ•°ä»æ¯ä¸ª 2,048 ä¸ªä½ç½®çš„ 310 ä¸‡ä¸ªå°å‹æ‰¹é‡ä¸­æ›´æ–°ã€‚ç¥ç»ç½‘ç»œåŒ…å« 40 ä¸ªæ®‹ä½™å—ã€‚å­¦ä¹ æ›²çº¿å¦‚å›¾ 6a æ‰€ç¤ºã€‚åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸè¿›è¡Œçš„æ¯”èµ›æ˜¾ç¤ºåœ¨è¡¥å……ä¿¡æ¯ä¸­ã€‚</p><p><img src="/images/ag06.png"></p><p>â€‹ <em>å›¾6 AlphaGo Zeroçš„è¯„ä¼°</em></p><p>â€‹ æˆ‘ä»¬ä½¿ç”¨ AlphaGo Fanï¼ŒAlphaGo Lee å’Œä¹‹å‰çš„å‡ ä¸ªå›´æ£‹ç¨‹åºçš„å†…éƒ¨æ¯”èµ›è¯„ä¼°äº†è®­ç»ƒæœ‰ç´ çš„ AlphaGo Zeroã€‚æˆ‘ä»¬è¿˜ä¸æœ€å¼ºå¤§çš„ç°æœ‰ç¨‹åº AlphaGo Master è¿›è¡Œäº†æ¸¸æˆï¼Œè¯¥ç¨‹åºåŸºäºæœ¬æ–‡æä¾›çš„ç®—æ³•å’Œä½“ç³»ç»“æ„ï¼Œä½†ä½¿ç”¨äº†äººç±»æ•°æ®å’Œç‰¹å¾ï¼ˆè¯·å‚é˜…æ–¹æ³•ï¼‰ - å®ƒåœ¨ 60-0 åœ¨çº¿æ¸¸æˆä¸­å‡»è´¥äº†æœ€å¼ºçš„äººç±»èŒä¸šç©å®¶ã€‚åœ¨æˆ‘ä»¬çš„è¯„ä¼°ä¸­ï¼Œæ‰€æœ‰ç¨‹åºéƒ½å…è®¸æ¯ä¸ªåŠ¨ä½œæœ‰5ç§’çš„æ€è€ƒæ—¶é—´; AlphaGo Zero å’Œ AlphaGo Master æ¯å°åœ¨å¸¦æœ‰ 4 ä¸ª TPU çš„å•å°æœºå™¨ä¸Šåšå¼ˆ; AlphaGo Fan å’Œ AlphaGo Lee åˆ†åˆ«åˆ†å¸ƒæœ‰ 176 ä¸ªGPUå’Œ 48 ä¸ªTPUã€‚æˆ‘ä»¬è¿˜åŒ…æ‹¬ä¸€ä¸ªå®Œå…¨åŸºäº AlphaGo Zero åŸå§‹ç¥ç»ç½‘ç»œçš„é€‰æ‰‹; è¯¥é€‰æ‰‹åªæ˜¯ä»¥æœ€å¤§çš„æ¦‚ç‡é€‰æ‹©ç§»åŠ¨ï¼ˆä¸è¿›è¡Œ MCTS æœç´¢ï¼‰ã€‚</p><p>â€‹ å›¾ 6bæ˜¾ç¤ºäº†æ¯ä¸ªç¨‹åºåœ¨Eloè§„æ¨¡ä¸Šçš„è¡¨ç°ã€‚æœªä½¿ç”¨ä»»ä½•é¢„æµ‹çš„åŸå§‹ç¥ç»ç½‘ç»œå®ç°äº†3,055çš„Eloè¯„çº§ã€‚ AlphaGo Zero è·å¾—äº†5,185çš„è¯„åˆ†ï¼Œè€Œ AlphaGo Master çš„4,858ï¼ŒAlphaGo Lee çš„ 3,739å’Œ AlphaGo Fan çš„3,144ã€‚</p><p>â€‹ æœ€åï¼Œæˆ‘ä»¬è¯„ä¼°äº† AlphaGo Zero å¯¹é˜µ AlphaGo Masterï¼Œåœ¨æ¯åœº2å°æ—¶çš„æ—¶é—´é™å®šå†…è¿›è¡Œäº†100åœºæ¯”èµ›ï¼ŒAlphaGo Zero èµ¢å¾—äº†å…¶ä¸­çš„89åœºã€‚</p><h4><span id="7-ç»“è®º">7. ç»“è®º</span></h4><p>â€‹ æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå…¨é¢è¯æ˜ï¼Œå³ä½¿åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„é¢†åŸŸä¸­ï¼Œçº¯ç²¹çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¹Ÿæ˜¯å®Œå…¨å¯è¡Œçš„ï¼šåœ¨ä¸è¶…å‡ºåŸºæœ¬è§„åˆ™çš„æƒ…å†µä¸‹ï¼Œæ²¡æœ‰å…³äºé¢†åŸŸçš„çŸ¥è¯†ï¼Œå°±å¯ä»¥è®­ç»ƒåˆ°è¶…äººçš„æ°´å¹³ï¼Œæ²¡æœ‰äººç±»çš„ä¾‹å­æˆ–æŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œä¸ç”¨äººç±»ä¸“å®¶æ•°æ®è®­ç»ƒçš„ç¨‹åºç›¸æ¯”ï¼Œçº¯ç²¹çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åªéœ€è¦å‡ ä¸ªå°æ—¶çš„è®­ç»ƒæ—¶é—´å°±èƒ½è¾¾åˆ°æ›´å¥½çš„æ€§èƒ½ã€‚ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼ŒAlphaGo Zero å¤§å¹…åº¦å‡»è´¥äº†ä½¿ç”¨äººå·¥æ•°æ®è®­ç»ƒçš„ AlphaGo æœ€å¼ºå¤§çš„å…ˆå‰ç‰ˆæœ¬ã€‚</p><p>â€‹ äººç±»å·²ç»ç§¯ç´¯äº†å‡ åƒå¹´æ¥çš„å›´æ£‹çŸ¥è¯†ï¼Œå‘å±•æˆå›ºå®šçš„æ¨¡å¼ï¼Œæ€»ç»“æˆè°šè¯­å’Œä¹¦ç±ã€‚åœ¨å‡ å¤©çš„æ—¶é—´é‡Œï¼ŒAlphaGo Zero ä»é›¶å­¦èµ·ï¼Œå°±èƒ½å¤Ÿé‡æ–°å‘ç°è®¸å¤šçš„å›´æ£‹çŸ¥è¯†ï¼Œå¹¶èƒ½ä¸ºè¿™ä¸ªå¤è€çš„æ¸¸æˆæä¾›æ–°è§è§£ã€æ–°ç­–ç•¥ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> AlphaZero </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Integrating Learning and Planning</title>
      <link href="/2018/01/09/RL%20-%20Integrating%20Learning%20and%20Planning/"/>
      <url>/2018/01/09/RL%20-%20Integrating%20Learning%20and%20Planning/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>In last lecture, we learn <strong>policy</strong> directly from experience. In previous lectures, we learn <strong>value function</strong> directly from experience. In this lecture, we will learn <strong>model</strong> directly from experience and use <strong>planning</strong> to construct a value function or policy. Integrate learning and planning into a single architecture.</p><p>Model-Based RL</p><ul><li>Learn a model from experience</li><li><strong>Plan</strong> value function (and/or policy) from model</li></ul><a id="more"></a><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#model-based-reinforcement-learning">Model-Based Reinforcement Learning</a></li><li><a href="#integrated-architectures">Integrated Architectures</a></li><li><a href="#simulation-based-search">Simulation-Based Search</a></li></ul><!-- tocstop --><h2><span id="model-based-reinforcement-learning">Model-Based Reinforcement Learning</span></h2><p><img src="/images/mbrl.png"></p><p>Advantages of Model-Based RL</p><ul><li>Can efficiently learn model by supervised learning methods</li><li>Can reason about model uncertainty</li></ul><p>Disadvantages</p><ul><li>First learn a model, then construct a value function -&gt; two source of approximation error</li></ul><p><strong>What is a Model?</strong></p><p>A model <span class="math inline">\(\mathcal{M}\)</span> is a representation of an MDP <span class="math inline">\(&lt;\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}&gt;\)</span> parametrized by <span class="math inline">\(\eta\)</span>.</p><p>We will assume state space <span class="math inline">\(\mathcal{S}\)</span> and action space <span class="math inline">\(\mathcal{A}\)</span> are known. So a model <span class="math inline">\(\mathcal{M}=&lt;\mathcal{P}_, \eta\mathcal{R}_\eta&gt;\)</span> represents state transitions <span class="math inline">\(\mathcal{P}_\eta \approx \mathcal{P}\)</span> and rewards <span class="math inline">\(\mathcal{R}_\eta\approx \mathcal{R}\)</span>. <span class="math display">\[S_{t+1}\sim\mathcal{P}_\eta(S_{t+1}|S_t, A_t)\\R_{t+1}=\mathcal{R}_\eta(R_{t+1}|S_t, A_t)\]</span> Typically assume conditional independence between state transitions and rewards.</p><p>Goal: estimate model <span class="math inline">\(\mathcal{M}_\eta\)</span> from experience <span class="math inline">\(\{S_1, A_1, R_2, â€¦, S_T\}\)</span>.</p><p>This is a supervised learning problem: <span class="math display">\[S_1, A_1 \rightarrow R_2, S_2 \\S_2, A_2 \rightarrow R_3, S_3 \\...\\S_{T-1}, A_{T-1} \rightarrow R_T, S_T \\\]</span> Learning <span class="math inline">\(s, a\rightarrow r\)</span> is a <em>regression</em> problem; learning <span class="math inline">\(s, a\rightarrow s&#39;\)</span> is a <em>density</em> estimation problem. Pick loss function, e.g. mean-squared error, KL divergence, â€¦ Find parameters <span class="math inline">\(\eta\)</span> that minimise empirical loss.</p><p>Examples of Models</p><ul><li>Table Lookup Model</li><li>Linear Expectation Model</li><li>Linear Gaussian Model</li><li>Gaussian Process Model</li><li>Deep Belief Network Model</li></ul><p><strong>Table Lookup Model</strong></p><p>Model is an explicit MDP. Count visits <span class="math inline">\(N(s, a)\)</span> to each state action pair: <span class="math display">\[\hat{\mathcal{P}}^a_{s,s&#39;}=\frac{1}{N(s,a)}\sum^T_{t=1}1(S_t,A_t,S_{t+1}=s, a, s&#39;)\\\hat{\mathcal{R}}^a_{s,s&#39;}=\frac{1}{N(s,a)}\sum^T_{t=1}1(S_t,A_t=s, a)R_t\]</span> Alternatively, at each time-step <span class="math inline">\(t\)</span>, record experience tuple <span class="math inline">\(&lt;S_t, A_t, R_{t+1}, S_{t+1}&gt;\)</span>. To sample model, randomly pick tuple matching <span class="math inline">\(&lt;s, a, \cdot, \cdot&gt;\)</span>.</p><p><strong>AB Example</strong></p><p><img src="/images/ab2.png"></p><p>We have contrusted a <strong>table lookup model</strong> from the experience. Next step, we will planning with a model.</p><p><strong>Planning with a model</strong></p><p>Given a model <span class="math inline">\(\mathcal{M}_\eta=&lt;\mathcal{P}_\eta, \mathcal{R}_\eta&gt;\)</span>, solve the MDP <span class="math inline">\(&lt;\mathcal{S}, \mathcal{A}, \mathcal{P}_\eta, \mathcal{R}_\eta&gt;\)</span> using favorite planning algorithms</p><ul><li>Value iteration</li><li>Policy iteration</li><li>Tree search</li><li>â€¦.</li></ul><p><strong>Sample-Based Planning</strong></p><p>A simple but powerful approach to planning is to use the model <strong>only</strong> to generate samples.</p><p><strong>Sample</strong> experience from model <span class="math display">\[S_{t+1}\sim\mathcal{P}_\eta(S_{t+1}|S_t,A_t)\\R_{t+1}=\mathcal{R}_\eta(R_{t+1}|S_t,A_t)\]</span> Apply <strong>model-free</strong> RL to samples, e.g.:</p><ul><li>Monte-Carlo control</li><li>Sarsa</li><li>Q-learning</li></ul><p>Sample-based planning methods are often more efficient.</p><p><strong>Back to AB Example</strong></p><p><img src="/images/ab3.png"></p><p>We can use our model to sample more experience and apply model-free RL to them.</p><p><strong>Planning with an Inaccurate Model</strong></p><p>Given an imperfect model <span class="math inline">\(&lt;\mathcal{P}_\eta, \mathcal{R}_\eta&gt; â‰  &lt;\mathcal{P}, \mathcal{R}&gt;\)</span>. Performance of model-based RL is limited to optimal policy for approximate MDP <span class="math inline">\(&lt;\mathcal{S}, \mathcal{A}, \mathcal{P}_\eta, \mathcal{R}_\eta&gt;\)</span> i.e. Model-based RL is only as good as the estimated model.</p><p>When the model is inaccurate, planning process will compute a suboptimal policy.</p><ul><li>Solution1: when model is wrong, use model-free RL</li><li>Solution2: reason explicitly about model uncertainty</li></ul><h2><span id="integrated-architectures">Integrated Architectures</span></h2><p>We consider two sources of experience:</p><ul><li><p>Real experience: Sampled from environment (true MDP) <span class="math display">\[S&#39;\sim \mathcal{P}^a_{s,s&#39;}\\R=\mathcal{R}^a_s\]</span></p></li><li><p>Simulated experience: Sampled from model (approximate MDP) <span class="math display">\[S&#39;\sim \mathcal{P}_\eta(S&#39;|S, A)\\R=\mathcal{R}_\eta(R|S, A)\]</span></p></li></ul><p><strong>Integrating Learning and Planning</strong></p><p>Dyna Architecture</p><ul><li>Learn a model from real experience</li><li>Learn and plan value function (and/or policy) from real and simulated experience</li></ul><p><img src="/images/dyna.png"></p><p>The simplest dyna algorithm is <em>Dyna-Q Algorithm</em>:</p><p><img src="/images/dynaq.png"></p><p><img src="/images/dynaqres.png"></p><p>From the experiments, we can see that using planning is more efficient than direct RL only.</p><p><strong>Dyna-Q with an Inaccurate Model</strong></p><p>The changed envrionment is <strong>harder</strong>:</p><p><img src="/images/dynaqhard.png"></p><p>There is a <strong>easier</strong> change:</p><p><img src="/images/dynaqeasy.png"></p><h2><span id="simulation-based-search">Simulation-Based Search</span></h2><p>Let's back to planning problems. Simulation-based search is another approach to solve MDP.</p><p><strong>Forward Search</strong></p><p>Forward search algorithms select the best action by <strong>lookahead</strong>. They build a <strong>search tree</strong> with the current state <span class="math inline">\(s_t\)</span> at the root using a model of the MDP to look ahead.</p><p><img src="/images/ftree.png"></p><p>We don't need to solve the whole MDP, just sub-MDP starting from <strong>now</strong>.</p><p><strong>Simulation-Based Search</strong></p><p>Simulation-based search is forward search paradigm using sample-based planning. Simulate episodes of experience from <strong>now</strong> with the model. Apply <strong>model-free</strong> RL to simulated episodes.</p><p><img src="/images/sbsearch.png"></p><p>Simulate episodes of experience from <strong>now</strong> with the model: <span class="math display">\[\{s_t^k, A^k_t,R^k_{t+1}, ..., S^k_T\}^K_{k=1}\sim\mathcal{M}_v\]</span> Apply <strong>model-free</strong> RL to simulated episodes</p><ul><li>Monte-Carlo control <span class="math inline">\(\rightarrow\)</span> Monte-Carlo search</li><li>Sarsa <span class="math inline">\(\rightarrow\)</span> TD search</li></ul><p><strong>Simple Monte-Carlo Search</strong></p><p>Given a model <span class="math inline">\(\mathcal{M}_v\)</span> and a simulation policy <span class="math inline">\(\pi\)</span>.</p><p>For each action <span class="math inline">\(a\in\mathcal{A}\)</span></p><ul><li><p>Simulate <span class="math inline">\(K\)</span> episodes from current (real) state <span class="math inline">\(s_t\)</span> <span class="math display">\[\{s_t, a, R^k_{t+1},S^k_{t+1},A^k_{t+1}, ..., S^k_T \}^K_{k=1}\sim \mathcal{M}_v, \pi\]</span></p></li><li><p>Evaluate actions by mean return (<strong>Monte-Carlo evaluation</strong>) <span class="math display">\[Q(s_t, a)=\frac{1}{K}\sum^k_{k=1}G_t\rightarrow q_\pi(s_t, a)\]</span></p></li></ul><p>Select current (real) action with maximum value <span class="math display">\[a_t=\arg\max_{a\in\mathcal{A}}Q(s_t, a)\]</span> <strong>Monte-Carlo Tree Search</strong></p><p>Given a model <span class="math inline">\(\mathcal{M}_v\)</span>. Simulate <span class="math inline">\(K\)</span> episodes from current state <span class="math inline">\(s_t\)</span> using current simulation policy <span class="math inline">\(\pi\)</span>. <span class="math display">\[\{s_t, A_t^k, R^k_{t+1},S^k_{t+1},A^k_{t+1}, ..., S^k_T \}^K_{k=1}\sim \mathcal{M}_v, \pi\]</span> Build a search tree containing visited states and actions. <strong>Evaluate</strong> states <span class="math inline">\(Q(s, a)\)</span> by mean return of episodes from <span class="math inline">\(s, a\)</span>: <span class="math display">\[Q(s, a)=\frac{1}{N(s,a)}\sum^K_{k=1}\sum^T_{u=t}1(S_u, A_u=s,a)G_u \to q_\pi(s,a)\]</span> After search is finished, select current (real) action with maximum value in search tree: <span class="math display">\[a_t=\arg\max_{a\in\mathcal{A}}Q(s_t, a)\]</span> In MCTS, the simulation policy <span class="math inline">\(\pi\)</span> <strong>improves</strong>.</p><p>Each simulation consists of two phases (in-tree, out-of-tree)</p><ul><li><strong>Tree policy</strong> (improves): pick actions to maximise <span class="math inline">\(Q(S,A)\)</span></li><li><strong>Default policy</strong> (fixed): pick actions randomly</li></ul><p>Repeat (each simulation)</p><ul><li><span class="math inline">\(\color{red}{\mbox{Evaluate}}\)</span> states <span class="math inline">\(Q(S,A)\)</span> by Monte-Carlo evaluation</li><li><span class="math inline">\(\color{red}{\mbox{Improve}}\)</span> tree policy, e.g. by <span class="math inline">\(\epsilon\)</span>-greedy(Q)</li></ul><p>MCTS is <strong>Monte-Carlo control</strong> applied to <strong>simulated experience</strong>.</p><p>Converges on the optimal search tree, <span class="math inline">\(Q(S, A) \to q_*(S, A)\)</span>.</p><p><strong>Case Study: the Game of Go</strong></p><p><img src="/images/go_2.png"></p><p><em>Rules of Go</em></p><ul><li>Usually played on 19$<span class="math inline">\(19, also 13\)</span><span class="math inline">\(13 or 9\)</span>$9 board</li><li>Black and white place down stones alternately</li><li>Surrounded stones are captured and removed</li><li>The player with more territory wins the game</li></ul><p><img src="/images/ruleofgo.png"></p><p><em>Position Evaluation in Go</em></p><p>The key problem is how good is a position <span class="math inline">\(s\)</span>?</p><p>So the reward function is if Black wins, the reward of the final position is 1, otherwise 0: <span class="math display">\[R_t = 0 \mbox{ for all non-terminal steps } t&lt;T\\R_T=\begin{cases} 1,  &amp; \mbox{if }\mbox{ Black wins} \\0, &amp; \mbox{if }\mbox{ White wins}\end{cases}\]</span> Policy <span class="math inline">\(\pi=&lt;\pi_B,\pi_W&gt;\)</span> selects moves for both players.</p><p>Value function (how good is position <span class="math inline">\(s\)</span>): <span class="math display">\[v_\pi(s)=\mathbb{E}_\pi[R_T|S=s]=\mathbb{P}[Black wins|S=s]\\v_*(s)=\max_{\pi_B}\min_{\pi_w}v_\pi(s)\]</span> <em>Monte Carlo Evaluation in Go</em></p><p><img src="/images/mcego.png"></p><p><img src="/images/amcts1.png"></p><p><img src="/images/amcts2.png"></p><p><img src="/images/amcts3.png"></p><p><img src="/images/amcts4.png"></p><p><img src="/images/amcts5.png"></p><p>So, MCTS will expand the tree towards the node that is most promising and ignore the useless parts.</p><p><strong>Advantages of MC Tree Search</strong></p><ul><li>Highly selective best-first search</li><li>Evaluates states <em>dynamically</em></li><li>Uses sampling to break curse of dimensionality</li><li>Works for &quot;black-box&quot; models (only requires samples)</li><li>Computationally efficient, anytime, parallelisable</li></ul><p><strong>Temporal-Difference Search</strong></p><ul><li>Simulation-based search</li><li>Using TD instead of MC (bootstrapping)</li><li>MC tree search applies MC control to sub-MDP from now</li><li>TD search applies Sarsa to sub-MDP from now</li></ul><p><strong>MC vs. TD search</strong></p><p>For model-free reinforcement learning, bootstrapping is helpful</p><ul><li>TD learning reduces variance but increase bias</li><li>TD learning is usually more efficient than MC</li><li>TD(<span class="math inline">\(\lambda\)</span>) can be much more efficient than MC</li></ul><p>For simulation-based search, bootstrapping is also helpful</p><ul><li>TD search reduces variance but increase bias</li><li>TD search is usually more efficient than MC search</li><li>TD(<span class="math inline">\(\lambda\)</span>) search can be much more efficient than MC search</li></ul><p><strong>TD Search</strong></p><p>Simulate episodes from the current (real) state <span class="math inline">\(s_t\)</span>. Estimate action-value function <span class="math inline">\(Q(s, a)\)</span>. For each step of simulation, update action-values by Sarsa: <span class="math display">\[\triangle Q(S,A)=\alpha (R+\gamma Q(S&#39;,A&#39;)-Q(S,A))\]</span> Select actions based on action-value <span class="math inline">\(Q(s,a)\)</span>, e.g. <span class="math inline">\(\epsilon\)</span>-greedy. May also use function approximation for <span class="math inline">\(Q\)</span>.</p><p><strong>Dyna-2</strong></p><p>In Dyna-2, the agent stores two sets of feature weights:</p><ul><li><strong>Long-term</strong> memory</li><li><strong>Short-term</strong> (working) memory</li></ul><p>Long-term memory is updated from <strong>real experience</strong> using TD learning</p><ul><li>General domain knowledge that applies to any episode</li></ul><p>Short-term memory is updated from <strong>simulated experience</strong> using TD search</p><ul><li>Specific local knowledge about the current situation</li></ul><p>Over value function is sum of long and short-term memories.</p><p>End.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> MCTS </tag>
            
            <tag> TD Search </tag>
            
            <tag> Dyna </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Policy Gradient</title>
      <link href="/2018/01/06/RL%20-%20Policy%20Gradient/"/>
      <url>/2018/01/06/RL%20-%20Policy%20Gradient/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>This lecture talks about methods that optimise policy directly. Instead of working with value function as we consider so far, we seek experience and use the experience to update our policy in the direction that makes it better.</p><p>In the last lecture, we approximated the value or action-value function using parameters <span class="math inline">\(\theta\)</span>, <span class="math display">\[V_\theta(s)\approx V^\pi(s)\\Q_\theta(s, a)\approx Q^\pi(s, a)\]</span> A policy was generated directly from the value function using <span class="math inline">\(\epsilon\)</span>-greedy.</p><p>In this lecture we will directly parametrise the policy <span class="math display">\[\pi_\theta(s, a)=\mathbb{P}[a|s, \theta]\]</span> We will focus again on <span class="math inline">\(\color{red}{\mbox{model-free}}\)</span> reinforcement learning.</p><a id="more"></a><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#finite-difference-policy-gradient">Finite Difference Policy Gradient</a></li><li><a href="#monte-carlo-policy-gradient">Monte-Carlo Policy Gradient</a></li><li><a href="#actor-critic-policy-gradient">Actor-Critic Policy Gradient</a></li><li><a href="#summary-of-policy-gradient-algorithms">Summary of Policy Gradient Algorithms</a></li></ul><!-- tocstop --><p><strong>Value-Based and Policy-Based RL</strong></p><ul><li>Value Based<ul><li>Learnt Value Function</li><li>Implicit policy (e.g. <span class="math inline">\(\epsilon\)</span>-greedy)</li></ul></li><li>Policy Based<ul><li>No Value Function</li><li>Learnt Policy</li></ul></li><li>Actor-Critic<ul><li>Learnt Value Function</li><li>Learnt Policy</li></ul></li></ul><p><img src="/images/vfp.png"></p><p><strong>Advantages of Policy-Based RL</strong></p><p>Advantages:</p><ul><li>Better convergence properties</li><li>Effective in high-dimensional or contimuous action spaces (<em>without computing max</em>)</li><li>Can learn stochastic policies</li></ul><p>Disadvantages:</p><ul><li>Typically converge to a local rather than global optimum</li><li>Evaluating a policy is typically inefficient and high variance</li></ul><p>Deterministic policy or taking max is not also the best. Take the rock-paper-scissors game for example.</p><p><img src="/images/rps.png"></p><p>Consider policies <em>iterated</em> rock-paper-scissors</p><ul><li>A deterministic policy is easily exploited</li><li>A uniform random policy is optimal (according to Nash equilibrium)</li></ul><p><strong>Aliased Gridworld Example</strong></p><p><img src="/images/agw.png"></p><p>The agent cannot differentiate the grey states.</p><p>Consider features of the following form (for all N, E, S, W) <span class="math display">\[\phi(s, a)=1(\mbox{wall to N, a = move E})\]</span> Compare value-based RL, using an approximate value function <span class="math display">\[Q_\theta(s, a)=f(\phi(s, a), \theta)\]</span> To policy-based RL, using a parametrised policy <span class="math display">\[\pi_\theta(s, a)=g(\phi(s, a), \theta)\]</span> Since the agent cannot differentiate the grey states given the feature, if you take a <strong>deterministic</strong> policy, you must pick the same action at two grey states.</p><p><img src="/images/deagw.png"></p><p>Under aliasing, an optimal <span class="math inline">\(\color{red}{\mbox{deterministic}}\)</span> policy will either</p><ul><li>move W in both grey states (as shown by red arrows)</li><li>move E in both grey states</li></ul><p>Either way, it can get stuck and never reach the money.</p><p>Value-based RL learns a near-deterministic policy, so it will traverse the corridor for a long time.</p><p><img src="/images/ranagw.png"></p><p>An optimal <span class="math inline">\(\color{red}{\mbox{stochastic}}\)</span> policy will randomly move E or W in grey states: <span class="math display">\[\pi_\theta(\mbox{wall to N and S, move E}) = 0.5\\\pi_\theta(\mbox{wall to N and S, move W}) = 0.5\\\]</span> It will reach the goal state in a few steps with high probability. Policy-based RL can learn the optimal stochastic policy.</p><p>These examples show that a stochastic policy can be better than the deterministic policy, especially in the case that the MDP is <strong>partialy observed</strong> or cannot fully represent the state.</p><p><strong>Policy Objective Functions</strong></p><p>Goal: given policy <span class="math inline">\(\pi_\theta(s, a)\)</span> with parameters <span class="math inline">\(\theta\)</span>, find best <span class="math inline">\(\theta\)</span>. But how do we measure the quality of a policy <span class="math inline">\(\pi_\theta\)</span>?</p><ul><li><p>In episodic environments we can use the <strong>start value</strong> <span class="math display">\[J_1(\theta)=V^{\pi_\theta}(s_1)=\mathbb{E}_{\pi_\theta}[v_1]\]</span></p></li><li><p>In continuing environments we can use the <strong>average value</strong> <span class="math display">\[J_{av}v(\theta)=\sum_s d^{\pi_\theta}(s)V^{\pi_\theta}(s)\]</span></p></li><li><p>Or the <strong>average reward per time-step</strong></p><p>â€‹ <span class="math display">\[J_{av}R(\theta)=\sum_s d^{\pi_\theta}(s)\sum_a\pi_\theta(s, a)\mathcal{R}^a_s\]</span></p></li><li><p>where <span class="math inline">\(d^{\pi_\theta}(s)\)</span> is <strong>stationary distribution</strong> of Markov chain for <span class="math inline">\(\pi_\theta\)</span>.</p></li></ul><p><strong>Policy Optimisation</strong></p><p>Policy based reinforcement learning is an <strong>optimisation</strong> problem. Find <span class="math inline">\(\theta\)</span> that maximises <span class="math inline">\(J(\theta)\)</span>.</p><p>Some approaches do not use gradient</p><ul><li>Hill climbing</li><li>Simplex / amoeba / Nelder Mead</li><li>Genetic algorithms</li></ul><p>However, greater efficiency often possible using gradient</p><ul><li>Gradient descent</li><li>Conjugate gradient</li><li>Quasi-newton</li></ul><p>We focus on gradient descent, many extensions possible. And on methods that exploit sequential structure.</p><h2><span id="finite-difference-policy-gradient">Finite Difference Policy Gradient</span></h2><p><strong>Policy Gradient</strong></p><p>Let <span class="math inline">\(J(\theta)\)</span> be any policy objective function. Policy gradient algorithms search for a local maximum in <span class="math inline">\(J(\theta)\)</span> by ascending the gradient of the policy, w.r.t. parameters <span class="math inline">\(\theta\)</span> <span class="math display">\[\triangle\theta = \alpha\nabla_\theta J(\theta)\]</span> Where <span class="math inline">\(\bigtriangledown_\theta J(\theta)\)</span> is the <span class="math inline">\(\color{red}{\mbox{policy gradient}}\)</span>, <span class="math display">\[\nabla_\theta J(\theta)=\begin{pmatrix}\frac{\partial J(\theta)}{\partial \theta_1}  \\\vdots\\\frac{\partial J(\theta)}{\partial \theta_n}\end{pmatrix}\]</span> and <span class="math inline">\(\alpha\)</span> is a step-size parameter.</p><p><strong>Computing Gradients By Finite Differences (Numerical)</strong></p><p>To evaluate policy gradient of <span class="math inline">\(\pi_\theta(s, a)\)</span>.</p><ul><li>For each dimension <span class="math inline">\(k\in[1, n]\)</span>:<ul><li><p>Estimate <span class="math inline">\(k\)</span>th partial derivative of objective function w.r.t. <span class="math inline">\(\theta\)</span></p></li><li><p>By perturbing <span class="math inline">\(\theta\)</span> by small amount <span class="math inline">\(\epsilon\)</span> in <span class="math inline">\(k\)</span>th dimension <span class="math display">\[\frac{\partial J(\theta)}{\partial \theta_k}\approx \frac{J(\theta+\epsilon u_k)-J(\theta)}{\epsilon}\]</span> where <span class="math inline">\(u_k\)</span> is unit vector with 1 in <span class="math inline">\(k\)</span>th component, 0 elsewhere</p></li></ul></li><li>Uses <span class="math inline">\(n\)</span> evaluations to compute policy gradient in <span class="math inline">\(n\)</span> dimensions</li></ul><p>This is a simple, noisy, inefficient, but sometimes effective method. It works for <strong>arbitrary</strong> policies, even if policy is <strong>not</strong> differentiable.</p><p>The algorithm is efficient when the dimension of <span class="math inline">\(\theta\)</span> is low.</p><h2><span id="monte-carlo-policy-gradient">Monte-Carlo Policy Gradient</span></h2><p><strong>Score Function</strong></p><p>We now compute the policy gradient <em>analytically</em>.</p><p>Assume policy <span class="math inline">\(\pi_\theta\)</span> is differentiable whenever it is non-zero and we know the gradient <span class="math inline">\(\nabla_\theta\pi_\theta(s, a)\)</span>.</p><p><span class="math inline">\(\color{red}{\mbox{Likelihood ratios}}\)</span> exploit the following identity <span class="math display">\[\begin{align}\nabla_\theta\pi_\theta(s, a) &amp; =\pi_\theta(s, a) \frac{\nabla_\theta\pi_\theta(s, a) }{\pi_\theta(s, a) } \\&amp; = \pi_\theta(s, a) \nabla_\theta\log \pi_\theta(s, a)  \\\end{align}\]</span> The <span class="math inline">\(\color{red}{\mbox{score function}}\)</span> is $<em></em>(s, a) $. Let's take two examples to see what the score function looks like.</p><p><em>Softmax Policy</em></p><p>We will use a softmax policy as a running example. Weight actions using linear combination of features <span class="math inline">\(\phi(s, a)^T\theta\)</span>. Probability of action is proportional to exponentiated weight: <span class="math display">\[\pi_\theta(s, a)\varpropto e^{\phi(s, a)^T\theta}\]</span> The score function is <span class="math display">\[\nabla_\theta\log\pi_\theta(s, a)=\phi(s, a)-\mathbb{E}_{\pi_\theta}[\phi(s, \cdot)]\]</span> (Intuition: log gradient = the feature for the action that we actually took minus the average feature for all actions.)</p><p><em>Gaussian Policy</em></p><p>In continuous action spaces, a Gaussian policy is natural.</p><ul><li>Mean is a linear combination of state features <span class="math inline">\(\mu(s) = \phi(s)^T\theta\)</span>.</li><li>Variance may be fixed <span class="math inline">\(\sigma^2\)</span>, or can also parametrised</li></ul><p>Policy is Gaussian, <span class="math inline">\(a\sim \mathcal{N}(\mu(s), \sigma^2)\)</span>. The score function is <span class="math display">\[\nabla_\theta\log\pi_\theta(s, a)=\frac{(a-\mu(s))\phi(s)}{\sigma^2}\]</span> So far we just have a sense of what does the score function look like. Now we step into policy gradient theorem.</p><p><strong>One-Step MDPs</strong></p><p>Consider a simple class of one-step MDPs:</p><ul><li>Starting in state <span class="math inline">\(s\sim d(s)\)</span></li><li>Terminating after one time-step with reward <span class="math inline">\(r=\mathcal{R}_{s,a}\)</span></li></ul><p>Use likelihood ratios to compute the policy gradient <span class="math display">\[\begin{align}J(\theta) &amp;=\mathbb{E}_{\pi_\theta}[r]\\&amp;=\sum_{s\in\mathcal{S}}d(s)\sum_{a\in\mathcal{A}}\pi_\theta(s, a)\mathcal{R}_{s,a}\end{align}\]</span></p><p><span class="math display">\[\begin{align}\nabla_\theta J(\theta) &amp;=\sum_{s\in\mathcal{S}}d(s)\sum_{a\in\mathcal{A}}\pi_\theta(s, a)\nabla_\theta\log\pi_\theta(s, a)\mathcal{R}_{s,a}\\&amp;=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s, a)r]\end{align}\]</span></p><p>The policy gradient theorem generalises the likelihood ratio approach to multi-step MDPs.</p><ul><li>Replaces instantaneous reward <span class="math inline">\(r\)</span> with long-term value <span class="math inline">\(Q^\pi(s, a)\)</span></li></ul><p>Policy gradient theorem applies to start state objective, average reward, and average value objective.</p><blockquote><p>Theorem</p><p>For any differentiable policy <span class="math inline">\(\pi_\theta(s,a)\)</span>, for any of the policy objective functions mentioned earlier, the policy gradient is <span class="math display">\[\nabla_\theta J(\theta)=\color{red}{\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s, a)Q^{\pi_\theta}(s, a)]}\]</span></p></blockquote><p><strong>Demonstration</strong></p><blockquote><p>Settings: The initial state <span class="math inline">\(s_0\)</span> is sampled from distribution <span class="math inline">\(\rho_0\)</span>. A trajectory <span class="math inline">\(\tau = (s_0, a_0, s_1, a_1, ..., s_{t+1})\)</span> is sampled from policy <span class="math inline">\(\pi_\theta\)</span>.</p><p>The target function would be <span class="math display">\[J(\theta) = E_{\tau\sim\pi}[R(\tau)]\]</span> The probability of trajectory <span class="math inline">\(\tau\)</span> is sampled from <span class="math inline">\(\pi\)</span> is <span class="math display">\[P(\tau|\theta) = \rho_0(s_0)+\prod_{t=0}^TP(s_{t+1}|s_t, a_t)\pi_\theta(a_t|s_t)\]</span> Using the log prob trick: <span class="math display">\[\triangledown_\theta P(\tau|\theta) = P(\tau|\theta)\triangledown_\theta\log P(\tau|\theta)\]</span> Expand the trajectory: <span class="math display">\[\begin{align}\require{cancel}\triangledown_\theta \log P(\tau|\theta) &amp;= \cancel{\triangledown_\theta \log\rho_0(s_0)}+\sum_{t=0}^T\cancel{\triangledown_\theta \log P(s_{t+1}|s_t,a_t)}+ \triangledown_\theta\log\pi_\theta(a_t|s_t)\\&amp;= \sum_{t=0}^T\triangledown_\theta\log\pi_\theta(a_t|s_t)\end{align}\]</span> The gradient of target function <span class="math display">\[\begin{align}\triangledown_\theta J(\theta) &amp;= \triangledown_\theta E_{\tau\sim\pi}[R(\tau)]\\&amp;= \int_\tau \triangledown_\theta P(\tau|\theta)R(\tau)\\&amp;= \int_\tau P(\tau|\theta)\triangledown_\theta \log P(\tau|\theta)R(\tau)\\&amp;= E_{\tau\sim\pi}[\triangledown_\theta \log P(\tau|\theta)R(\tau)]\\&amp;= E_{\tau\sim\pi}[\sum_{t=0}^T\triangledown_\theta\log\pi_\theta(a_t|s_t)R(\tau)]\\&amp;= E_{\tau\sim\pi}[\sum_{t=0}^T \color{red}{\Phi_t}\triangledown_\theta\log\pi_\theta(a_t|s_t)]\end{align}\]</span></p></blockquote><p><strong>Monte-Carlo Policy Gradient (REINFORCE)</strong></p><p>Update parameters by stochastic gradient ascent using policy gradient theorem. And using return <span class="math inline">\(v_t\)</span> as an <strong>unbiased sample</strong> of <span class="math inline">\(Q^{\pi_\theta}(s_t,a_t)\)</span>: <span class="math display">\[\triangle\theta_t=\alpha\nabla_\theta\log\pi_\theta(s_t, a_t)v_t\]</span> <img src="/images/mcpseudo.png"></p><p>(Note: MCPG is slow.)</p><h2><span id="actor-critic-policy-gradient">Actor-Critic Policy Gradient</span></h2><p><strong>Reducing Variance Using a Critic</strong></p><p>Monte-Carlo policy gradient still has high variance, we use a <span class="math inline">\(\color{red}{critic}\)</span> to estimate the action-value function: <span class="math display">\[Q_w(s, a)\approx Q^{\pi_\theta}(s, a)\]</span> Actor-critic algorithms maintain two sets of parameters:</p><ul><li>Critic: Updates action-value function parameters <span class="math inline">\(w\)</span></li><li>Actor: Updates policy parameters <span class="math inline">\(\theta\)</span>, in direction suggested by critic</li></ul><p>Actor-critic algorithms follow an <em>approximate</em> policy gradient: <span class="math display">\[\nabla_\theta J(\theta)\approx \mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s, a)Q_w(s, a)]\\\triangle\theta= \alpha\nabla_\theta\log\pi_\theta(s, a)Q_w(s, a)\]</span> The critic is solving a familiar problem: policy evaluation. This problem was explored in previous lectures:</p><ul><li>Monte-Carlo policy evaluation</li><li>Temporal-Difference learning</li><li>TD(<span class="math inline">\(\lambda\)</span>)</li><li>Least Squares policy evaluation</li></ul><p>Simple actor-critic algorithm based on action-value critic using linear value function approximation. <span class="math inline">\(Q_w(s, a)=\phi(s,a)^Tw\)</span></p><ul><li>Critic: Updates <span class="math inline">\(w\)</span> by linear TD(0)</li><li>Actor: Updates <span class="math inline">\(\theta\)</span> by policy gradient</li></ul><p><img src="/images/qacpseudo.png"></p><p><strong>Bias in Actor-Critic Algorithms</strong></p><p>Approximating the policy gradient introduces bias. A biased policy gradient may not find the right solution. Luckily, if we choose value function approximation carefully, then we can avoid introducing any bias. That is we can still follow the exact policy gradient.</p><blockquote><p><strong>Compatible Function Approximation Theorem</strong></p><p>If the following two conditions are satisdied:</p><ol type="1"><li><p>Value function approximator is <strong>compatible</strong> to the policy <span class="math display">\[\nabla_w Q_w(s, a)=\nabla_\theta \log\pi_\theta(s, a)\]</span></p></li><li><p>Value function parameters <span class="math inline">\(w\)</span> minimise the mean-squared error <span class="math display">\[\epsilon=\mathbb{E}_{\pi_\theta}[(Q^{\pi_\theta}(s, a)-Q_w(s, a))^2]\]</span></p></li></ol><p>Then the policy gradient is exact, <span class="math display">\[\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)Q_w(s,a)]\]</span></p></blockquote><p><strong>Trick: Reducing Variance Using a Baseline</strong></p><p>We substract a baseline function <span class="math inline">\(B(s)\)</span> from the policy gradient. This can <strong>reduce variance, without changing expectation</strong>: <span class="math display">\[\begin{align}\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)B(s)]&amp;=\sum_{s\in\mathcal{S}}d^{\pi_\theta}(s)\sum_a\nabla_\theta\pi_\theta(s,a)B(s)\\&amp;= \sum_{s\in\mathcal{S}}d^{\pi_\theta}B(s)\nabla_\theta\sum_{a\in\mathcal{A}}\pi_\theta(s,a)\\&amp;=  \sum_{s\in\mathcal{S}}d^{\pi_\theta}B(s)\nabla_\theta 1 \\&amp;=0\end{align}\]</span> A good baseline is the state value function <span class="math inline">\(B(s)=V^{\pi_\theta}(s)\)</span>. So we can rewrite the policy gradient using the <span class="math inline">\(\color{red}{\mbox{advantage function}}\ A^{\pi_\theta}(s,a)\)</span>. <span class="math display">\[A^{\pi_\theta}(s,a)=Q^{\pi_\theta}(s,a)-V^{\pi_\theta}(s)\\\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)\color{red}{A^{\pi_\theta}(s,a)}]\]</span> where <span class="math inline">\(V^{\pi_\theta}(s)â€‹\)</span> is the state value function of <span class="math inline">\(sâ€‹\)</span>.</p><p><strong>Intuition</strong>: The advantage function <span class="math inline">\(A^{\pi_\theta}(s,a)\)</span> tells us how much better than usual is it to take action <span class="math inline">\(a\)</span>.</p><p><strong>Estimating the Advantage Function</strong></p><p>How do we know the state value function <span class="math inline">\(V\)</span>?</p><p>One way to do that is to estimate both <span class="math inline">\(V^{\pi_\theta}(s)\)</span> and <span class="math inline">\(Q^{\pi_\theta}(s,a)\)</span>. Using two function approximators and two parameter vectors, <span class="math display">\[V_v(s)\approx V^{\pi_\theta}(s)\\Q_w(s,a)\approx Q^{\pi_\theta}(s,a)\\A(s,a)=Q_w(s,a)-V_v(s)\]</span> And updating both value functions by e.g. TD learning.</p><p>Another way is to use the TD error to compute the policy gradient. For the true value function <span class="math inline">\(V^{\pi_\theta}(s)\)</span>, the TD error <span class="math inline">\(\delta^{\pi_\theta}\)</span> <span class="math display">\[\delta^{\pi_\theta}=r+\gamma V^{\pi_\theta}(s&#39;)-V^{\pi_\theta}(s)\]</span> is an unbiased estimate of the advantage function: <span class="math display">\[\begin{align}\mathbb{E}_{\pi_\theta}[\delta^{\pi_\theta}|s, a] &amp;= \mathbb{E}_{\pi_\theta}[r+\gamma V^{\pi_\theta}(s&#39;)|s, a]-V^{\pi_\theta}(s)\\&amp;= Q^{\pi_\theta}(s, a) - V^{\pi_\theta}(s)\\&amp;= \color{red}{A^{\pi_\theta}(s,a)}\end{align}\]</span> So we can use the TD error to compute the policy gradient <span class="math display">\[\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)\color{red}{\delta^{\pi_\theta}}]\]</span> In practice we can use an approximate TD error: <span class="math display">\[\delta_v=r+\gamma V_v(s&#39;)-V_v(s)\]</span> This approach only requires one set of critic parameters <span class="math inline">\(v\)</span>.</p><p><strong>Critics and Actors at Different Time-Scales</strong></p><p>Critic can estimate value function <span class="math inline">\(V_\theta(s)\)</span> from many targets at different time-scales</p><ul><li><p>For MC, the target is return <span class="math inline">\(v_t\)</span> <span class="math display">\[\triangle \theta=\alpha(\color{red}{v_t}-V_\theta(s))\phi(s)\]</span></p></li><li><p>For TD(0), the target is the TD target <span class="math inline">\(r+\gamma V(s&#39;)\)</span> <span class="math display">\[\triangle \theta=\alpha(\color{red}{r+\gamma V(s&#39;)}-V_\theta(s))\phi(s)\]</span></p></li><li><p>For forward-view TD(<span class="math inline">\(\lambda\)</span>), the target is the return <span class="math inline">\(_vt^\lambda\)</span> <span class="math display">\[\triangle \theta=\alpha(\color{red}{v_t^\lambda}-V_\theta(s))\phi(s)\]</span></p></li><li><p>For backward-view TD(<span class="math inline">\(\lambda\)</span>), we use eligibility traces <span class="math display">\[\begin{align}\delta_t &amp;= r_{t+1}+\gamma V(s_{t+1})-V(s_t) \\e_t&amp; = \gamma\lambda e_{t-1} +\phi(s_t) \\\triangle\theta&amp;=\alpha\delta_te_t\end{align}\]</span></p></li></ul><p>The policy gradient can also be estimated at many time-scales <span class="math display">\[\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)\color{red}{A^{\pi_\theta}(s,a)}]\]</span></p><ul><li><p>MC policy gradient uses error from complete return <span class="math display">\[\triangle\theta=\alpha(\color{red}{v_t}-V_v(s_t))\nabla_\theta\log\pi_\theta(s_t,a_t)\]</span></p></li><li><p>Actor-critic policy gradient uses the one-step TD error <span class="math display">\[\triangle\theta=\alpha(\color{red}{r+\gamma V_v(s_{t+1})}-V_v(s_t))\nabla_\theta\log\pi_\theta(s_t,a_t)\]</span></p></li><li><p>Just like forward-view TD(<span class="math inline">\(\lambda\)</span>), we can mix over time-scale <span class="math display">\[\triangle \theta=\alpha(\color{red}{v_t^\lambda}-V_v(s_t))\nabla_\theta\log\pi_\theta(s_t,a_t)\]</span> where <span class="math inline">\(v_t^\lambda-V_v(s_t)\)</span> is a biased estimate of advantage function.</p></li><li><p>Like backward-view TD(<span class="math inline">\(\lambda\)</span>), we can also use eligibility traces by substituting <span class="math inline">\(\phi(s)=\nabla_\theta\log\pi_\theta(s,a)\)</span> <span class="math display">\[\begin{align}\delta_t &amp;= r_{t+1}+\gamma V_v(s_{t+1})-V_v(s_t) \\e_{t+1}&amp; = \gamma\lambda e_{t} +\nabla_\theta\log\pi_\theta(s,a) \\\triangle\theta&amp;=\alpha\delta_te_t\end{align}\]</span></p></li></ul><h2><span id="summary-of-policy-gradient-algorithms">Summary of Policy Gradient Algorithms</span></h2><p>The policy gradient has many equivalent forms</p><p><img src="/images/sumpg.png"></p><p>Each leads a stochastic gradient ascent algorithm. Critic uses policy evaluation to estimate <span class="math inline">\(Q^\pi(s, a)\)</span>, <span class="math inline">\(A^\pi(s, a)\)</span> or <span class="math inline">\(V^\pi(s)\)</span>.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> REINFORCE </tag>
            
            <tag> Actor-Critic </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Value Function Approximation</title>
      <link href="/2018/01/03/RL%20-%20Value%20Function%20Approximation/"/>
      <url>/2018/01/03/RL%20-%20Value%20Function%20Approximation/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>This lecture will introduce how to scale up our algorithm to real practical RL problems by value function approximation.</p><p>Reinforcement learning can be used to solve <em>large</em> problems, e.g.</p><ul><li>Backgammon: <span class="math inline">\(10^{20}\)</span> states</li><li>Computer Go: <span class="math inline">\(10^{170}\)</span> states</li><li>Helicopter: continuous state space</li></ul><a id="more"></a><p>How can we scale up the model-free methods for prediction and control from the last two lectures?</p><p>So far we have represented value function by a <strong>lookup</strong> table:</p><ul><li>Every state <span class="math inline">\(s\)</span> has an entry <span class="math inline">\(V(s)\)</span></li><li>Or every state-action pair <span class="math inline">\(s, a\)</span> has an entry <span class="math inline">\(Q(s, a)\)</span></li></ul><p>Problems with large MDPs:</p><ul><li>There are too many states and/or actions to store in memory</li><li>It is too slow to learn the value of each state individually</li></ul><p>Solution for large MDPs: Estimate value function with <em>function approximation</em> <span class="math display">\[\hat{v}(s, \mathbb{w})\approx v_\pi(s)\\\mbox{or }\hat{q}(s, a, \mathbb{w})\approx q_\pi(s, a)\]</span> where <span class="math inline">\(\hat{v}\)</span> or <span class="math inline">\(\hat{q}\)</span> are function approximations of real <span class="math inline">\(v_\pi\)</span> or <span class="math inline">\(q_\pi\)</span>, and <span class="math inline">\(\mathbb{w}\)</span> are the parameters. This apporach has a major advantage:</p><ul><li><strong>Generalise</strong> from seen state to unseen states</li></ul><p>We can fit the <span class="math inline">\(\hat{v}\)</span> or <span class="math inline">\(\hat{q}\)</span> to <span class="math inline">\(v_\pi\)</span> or <span class="math inline">\(q_\pi\)</span> by MC or TD learning.</p><p><strong>Types of Value Function Approximation</strong></p><p><img src="/images/vftypes.png"></p><p>We consider <span class="math inline">\(\color{red}{\mbox{differentiable}}\)</span> function approximators, e.g.</p><ul><li>Linear combinations of features</li><li>Neural network</li></ul><p>Futhermore, we require a training method that is suitable for <span class="math inline">\(\color{red}{\mbox{non-stationary}}\)</span>, <span class="math inline">\(\color{red}{\mbox{non-idd}}\)</span> (idd = independent and identical distributed) data.</p><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#incremental-methods">Incremental Methods</a><ul><li><a href="#value-function-approximation">Value Function Approximation</a></li><li><a href="#action-value-function-approximation">Action-Value Function Approximation</a></li></ul></li><li><a href="#batch-methods">Batch Methods</a><ul><li><a href="#least-square-prediction">Least Square Prediction</a></li><li><a href="#least-squares-control">Least Squares Control</a></li></ul></li></ul><!-- tocstop --><h2><span id="incremental-methods">Incremental Methods</span></h2><h3><span id="value-function-approximation">Value Function Approximation</span></h3><p><strong>Gradient Descent</strong></p><p>Let <span class="math inline">\(J(\mathbb{w})\)</span> be a differentiable function of parameter vector <span class="math inline">\(\mathbb{w}\)</span>.</p><p>Define the gradient of <span class="math inline">\(J(\mathbb{w})\)</span> to be <span class="math display">\[\bigtriangledown_wJ(\mathbb{w})=\begin{pmatrix}\frac{\partial J(\mathbb{w})}{\partial \mathbb{w}_1} \\\vdots\\\frac{\partial J(\mathbb{w})}{\partial \mathbb{w}_n} \end{pmatrix}\]</span> To find a local minimum of <span class="math inline">\(J(\mathbb{w})\)</span>, adjust <span class="math inline">\(\mathbb{w}\)</span> in direction of -ve gradient <span class="math display">\[\triangle \mathbb{w}=-\frac{1}{2}\alpha \bigtriangledown_\mathbb{w}J(\mathbb{w})\]</span> where <span class="math inline">\(\alpha\)</span> is a step-size parameter.</p><p>So let's apply the <em>stochastic gradient descent</em> to <strong>value fucntion approximation</strong>.</p><p>Goal: find parameter vector <span class="math inline">\(\mathbb{w}\)</span> minimising mean-squared error between approximate value function <span class="math inline">\(\hat{v}(s, \mathbb{w})\)</span> and true value function <span class="math inline">\(v_\pi(s)\)</span>. <span class="math display">\[J(\mathbb{w})=\mathbb{E}_\pi[(v_\pi(S)-\hat{v}(S, \mathbb{w}))^2]\]</span> Gradient descent finds a local minimum <span class="math display">\[\begin{align}\triangle\mathbb{w}&amp;=-\frac{1}{2}\alpha \bigtriangledown_\mathbb{w}J(\mathbb{w})\\&amp; = \alpha\mathbb{E}_\pi[(v_\pi(S)-\hat{v}(S, \mathbb{w}))\bigtriangledown_\mathbb{w}\hat{v}(S, \mathbb{w})] \\\end{align}\]</span> Stochastic gradient descent <em>samples</em> the gradient <span class="math display">\[\triangle\mathbb{w}=\alpha(v_\pi(S)-\hat{v}(S, \mathbb{w}))\bigtriangledown_\mathbb{w}\hat{v}(S, \mathbb{w})\]</span> Expected update is equal to full gradient update.</p><p><strong>Feature Vectors</strong></p><p>Let's make this idea more concrete.</p><p>Represent state by a <em>feature vector</em>: <span class="math display">\[x(S) =\begin{pmatrix}x_1(S) \\\vdots\\x_n(S)\end{pmatrix}\]</span> For example:</p><ul><li>Distance of robot from landmarks</li><li>Trend in the stock market</li><li>Piece and pawn configurations in chess</li></ul><p><strong>Linear Value Function Approximation</strong></p><p>Represent value function by a linear combination of features <span class="math display">\[\hat{v}(S, \mathbb{w})=x(S)^T\mathbb{w}=\sum^n_{j=1}x_j(S)\mathbb{w}_j\]</span> Objective function is quadratic in parameters <span class="math inline">\(\mathbb{w}\)</span> <span class="math display">\[J(\mathbb{w})=\mathbb{E}_\pi[(v_\pi(S)-x(S)^T\mathbb{w})^2]\]</span> Stochastic gradient descent converges on global optimum.</p><p>Update rule is particularly simple <span class="math display">\[\bigtriangledown_\mathbb{w}\hat{v}(S, \mathbb{w})=x(S)\\\triangle \mathbb{w}=\alpha(v_\pi(S)-\hat{v}(S, \mathbb{w}))x(S)\]</span> Update = step-size <span class="math inline">\(\times\)</span> prediction error <span class="math inline">\(\times\)</span> feature value.</p><p>So far we have assumed true value function <span class="math inline">\(v_\pi(s)\)</span> given by supervisor. But in RL there is <strong>no supervisor, only rewards</strong>.</p><p>In practice, we substitute a <em>target</em> for <span class="math inline">\(v_\pi(s)\)</span>:</p><ul><li><p>For MC, the target is return <span class="math inline">\(G_tâ€‹\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{G_t}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w})\]</span></p></li><li><p>For TD(0), the target is the TD target <span class="math inline">\(R_{t+1}+\gamma\hat{v}(S_{t+1}, \mathbb{w})\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{R_{t+1}+\gamma\hat{v}(S_{t+1}, \mathbb{w})}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w})\]</span></p></li><li><p>For TD(<span class="math inline">\(\lambda\)</span>), the target is the return <span class="math inline">\(G_t^\lambda\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{G_t^\lambda}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w})\]</span></p></li></ul><p><strong>Monte-Carlo with Value Function Approximation</strong></p><p>Return <span class="math inline">\(G_t\)</span> is unbiased, noisy sample of true value <span class="math inline">\(v_\pi(S_t)\)</span>. We can build our &quot;training data&quot; to apply supervised learning: <span class="math display">\[&lt;S_1, G_1&gt;, &lt;S_2, G_2&gt;, ..., &lt;S_T, G_T&gt;\]</span> For example, using <em>linear Monte-Carlo policy evaluation</em> <span class="math display">\[\begin{align}\triangle \mathbb{w}&amp;=\alpha(\color{red}{G_t}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w}) \\&amp; = \alpha(G_t-\hat{v}(S_t, \mathbb{w}))x(S_t)\\\end{align}\]</span> Monte-Carlo evaluation converges to a local optimum even when using non-linear value function approximation.</p><p><strong>TD Learning with Value Function Approximation</strong></p><p>The TD-target <span class="math inline">\(R_{t+1}+\gamma \hat{v}(S_{t+1}, \mathbb{w})\)</span> is a biased sample of true value <span class="math inline">\(v_\pi(S_t)\)</span>. We can still apply supervised learning to &quot;traning data&quot;: <span class="math display">\[&lt;S_1, R_2 +\gamma\hat{v}(S_2, \mathbb{w})&gt;,&lt;S_2, R_3 +\gamma\hat{v}(S_3, \mathbb{w})&gt;,...,&lt;S_{T-1}, R_T&gt;\]</span> For example, using <em>linear TD(0)</em> <span class="math display">\[\begin{align}\triangle \mathbb{w}&amp;=\alpha(\color{red}{R+\gamma\hat{v}(S&#39;, \mathbb{w})}-\hat{v}(S, \mathbb{w}))\bigtriangledown_w \hat{v}(S, \mathbb{w}) \\&amp; = \alpha\delta x(S)\\\end{align}\]</span> Linear TD(0) converges (close) to global optimum.</p><p><strong>TD(<span class="math inline">\(\lambda\)</span>) with Value Function Approximation</strong></p><p>The <span class="math inline">\(\lambda\)</span>-return <span class="math inline">\(G_t^\lambda\)</span> is also a biased sample of true value <span class="math inline">\(v_\pi(s)\)</span>. We can also apply supervised learning to &quot;training data&quot;: <span class="math display">\[&lt;S_1, G_1^\lambda&gt;, &lt;S_2, G_2^\lambda&gt;, ..., &lt;S_{T-1}, G_{T-1}^\lambda&gt;\]</span> Can use either forward view linear TD(<span class="math inline">\(\lambda\)</span>): <span class="math display">\[\begin{align}\triangle \mathbb{w}&amp;=\alpha(\color{red}{G_t^\lambda}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w}) \\&amp; = \alpha(G_t-\hat{v}(S_t, \mathbb{w}))x(S_t)\\\end{align}\]</span> or backward view linear TD(<span class="math inline">\(\lambda\)</span>): <span class="math display">\[\begin{align}\delta_t &amp;= R_{t+1}+\gamma \hat{v}(S_{t+1}, \mathbb{w})-\hat{v}(S_t, \mathbb{w}) \\E_t&amp; = \gamma\lambda E_{t-1} +x(S_t) \\\triangle\mathbb{w}&amp;=\alpha\delta_tE_t\end{align}\]</span></p><h3><span id="action-value-function-approximation">Action-Value Function Approximation</span></h3><p><img src="/images/avfa.png"></p><p>Approximate the action-value function: <span class="math display">\[\hat{q}(S, A, \mathbb{w}) \approx q_\pi(S, A)\]</span> Minimise mean-squared error between approximate action-value function <span class="math inline">\(\hat{q}(S, A, \mathbb{w})\)</span> and true action-value function <span class="math inline">\(q_\pi(S, A)\)</span>: <span class="math display">\[J(\mathbb{w})=\mathbb{E}_\pi[(q_\pi(S, A)-\hat{q}(S, A, \mathbb{w}))^2]\]</span> Use stochastic gradient descent to find a local minimum: <span class="math display">\[-\frac{1}{2}\bigtriangledown_w J(\mathbb{w})=(q_\pi(S, A)-\hat{q}(S, A, \mathbb{w}))\bigtriangledown_w\hat{q}(S, A, \mathbb{w})\\\triangle\mathbb{w}=\alpha (q_\pi(S, A)-\hat{q}(S, A, \mathbb{w}))\bigtriangledown_w\hat{q}(S, A, \mathbb{w})\]</span> Represent state and action by a feature vector: <span class="math display">\[\mathbb{x}(S, A)=\begin{pmatrix}x_1(S, A) \\\vdots\\x_n(S, A)\end{pmatrix}\]</span> Represent action-value function by linear combination of features: <span class="math display">\[\hat{q}(S, A, \mathbb{w})=\mathbb{x}(S, A)^T\mathbb{w}=\sum^n_{j=1}x_j (S, A)\mathbb{w}_j\]</span> Stochastic gradient descent update: <span class="math display">\[\bigtriangledown_w\hat{q}(S, A, \mathbb{w})=\mathbb{x}(S, A)\\\triangle \mathbb{w}=\alpha(q_\pi(S, A)-\hat{q}(S,  A, \mathbb{w}))\mathbb{x}(S, A)\]</span> Like prediction, we must subsitute a target for <span class="math inline">\(q_\pi(S, A)\)</span>:</p><ul><li><p>For MC, the target is the return <span class="math inline">\(G_t\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{G_t}-\hat{q}(S_t,  A_t, \mathbb{w}))\bigtriangledown_w\hat{q}(S_t, A_t, \mathbb{w})\]</span></p></li><li><p>For TD(0), the target is the TD target <span class="math inline">\(R_{t+1}+\gamma Q(S_{t+1}, A_{t+1})â€‹\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{R_{t+1}+\gamma \hat{q}(S_{t+1},  A_{t+1}, \mathbb{w})}-\hat{q}(S_t,  A_t, \mathbb{w}))\bigtriangledown_w\hat{q}(S_t, A_t, \mathbb{w})\]</span></p></li><li><p>For forward-view TD(<span class="math inline">\(\lambda\)</span>), target is the action-value <span class="math inline">\(\lambda\)</span>-return <span class="math display">\[\triangle\mathbb{w}=\alpha(\color{red}{q_t^\lambda}-\hat{q}(S_t, A_t,\mathbb{w}))\bigtriangledown\hat{q}(S_t, A_t, \mathbb{w})\]</span></p></li><li><p>For backward-view TD(<span class="math inline">\(\lambda\)</span>), equivalent update is <span class="math display">\[\begin{align}\delta_t&amp; =R_{t+1}+\gamma\hat{q}(S_{t+1}, A_{t+1}, \mathbb{w})-\hat{q}(S_t, A_t, \mathbb{w}) \\E_t&amp; = \gamma\lambda E_{t-1}+\bigtriangledown_w\hat{q}(S_t, A_t, \mathbb{w}) \\\triangle\mathbb{w}&amp;= \alpha\delta_t E_t\end{align}\]</span></p></li></ul><p><strong>Linear Sarsa with Coarse Coding in Mountain Car</strong></p><p><img src="/images/linsarsa.png"></p><p>The goal is to control our car to reach the top of the mountain. We represent state by the car's position and velocity. The height of the diagram shows the value of each state. Finally, the value function is like:</p><p><img src="/images/linsarfin.png"></p><p><strong>Study of <span class="math inline">\(\lambda\)</span>: Should We Bootstrap?</strong></p><p><img src="/images/lambdastudy.png"></p><p>The answer is <strong>yes</strong>. We can see from above picture, choose some approprite <span class="math inline">\(\lambda\)</span> can certainly reduce the training steps as well as the cost.</p><p>However, temporal-difference learning in many cases doesn't guarantee to converge. It may also diverge.</p><p><strong>Convergence of Prediction Algorithms</strong></p><p><img src="/images/converge.png"></p><p>TD dose not follow the gradient of <em>any</em> objective function. This is why TD can diverge when off-policy or using non-linear function approximation. <strong>Gradient TD</strong> follows true gradient of projected Bellman error.</p><p><img src="/images/gtd.png"></p><p><strong>Convergence of Control Algorithms</strong></p><p><img src="/images/convca.png"></p><h2><span id="batch-methods">Batch Methods</span></h2><p>Gradient descent is simple and appealing. But it is not <strong>sample efficient</strong>. Batch methods seek to find the best fitting value function given the agent's experience.</p><h3><span id="least-square-prediction">Least Square Prediction</span></h3><p>Give value function approximation <span class="math inline">\(\hat{v}(s, \mathbb{w})\approx v_\pi(s)\)</span> and experience <span class="math inline">\(\mathcal{D}\)</span> consisting of <em>&lt;state, value&gt;</em> pairs: <span class="math display">\[\mathcal{D} = \{&lt;s_1, v_1^\pi&gt;, &lt;s_2, v_2^\pi&gt;, ..., &lt;s_T, v_T^\pi&gt; \}\]</span> Which parameters <span class="math inline">\(\mathbb{w}\)</span> give the best fitting value function <span class="math inline">\(\hat{v}(s, \mathbb{w})\)</span> ?</p><p><span class="math inline">\(\color{red}{\mbox{Least squares}}\)</span> algorithms find parameter vector <span class="math inline">\(\mathbb{w}\)</span> minimising sum-squared error between <span class="math inline">\(\hat{v}(s_t, \mathbb{w})\)</span> and target values <span class="math inline">\(v_t^\pi\)</span>, <span class="math display">\[\begin{align}LS(\mathbb{w}) &amp; = \sum^T_{t=1}(v_t^\pi-\hat{v}(s_t, \mathbb{w}))^2 \\&amp; = \mathbb{E}_\mathcal{D}[(v^\pi-\hat{v}(s, \mathbb{w}))^2] \\\end{align}\]</span> Given experience consisting of <em>&lt;state, value&gt;</em> pairs <span class="math display">\[\mathcal{D}=\{&lt;s_1, v_1^\pi&gt;, &lt;s_2, v_2^\pi&gt;, ..., &lt;s_T, v_T^\pi&gt;\}\]</span> Repeat:</p><ol type="1"><li><p>Sample state, value from experience <span class="math display">\[&lt;s, v^\pi&gt; \sim \mathcal{D}\]</span></p></li><li><p>Apply stochastic gradient descent update <span class="math display">\[\triangle \mathbb{w}=\alpha(v^\pi-\hat{v}(s, \mathbb{w}))\bigtriangledown_w\hat{v}(s, w)\]</span></p></li></ol><p>Converges to least squares solution <span class="math display">\[\mathbb{w}^\pi=\arg\min_w LS(w)\]</span> <strong>Deep Q-Networks (DQN)</strong></p><p>DQN uses <span class="math inline">\(\color{red}{\mbox{experience replay}}\)</span> and <span class="math inline">\(\color{red}{\mbox{fixed Q-targets}}\)</span>:</p><ul><li><p>Take action <span class="math inline">\(a_t\)</span> according to <span class="math inline">\(\epsilon\)</span>-greedy policy</p></li><li><p>Store transition <span class="math inline">\((s_t, a_t, r_{t+1}, s_{t+1})\)</span> in replay memory <span class="math inline">\(\mathcal{D}\)</span></p></li><li><p>Sample random mini-batch of transitions <span class="math inline">\((s, a, r, s&#39;)\)</span> from <span class="math inline">\(\mathcal{D}\)</span></p></li><li><p>Compute Q-learning targets w.r.t. old, fixed parameters <span class="math inline">\(w^-\)</span></p></li><li><p>Optimise MSE between Q-network and Q-learning target <span class="math display">\[\mathcal{L}(w_i)=\mathbb{E}_{s,a,r,s&#39;\sim\mathcal{D}_i}[(r+\gamma\max_{a&#39;}Q(s&#39;,a&#39;;w^-_i)-Q(s, a;w_i))^2]\]</span></p></li><li><p>Using variant of stochastic gradient descent</p></li></ul><p>Note: <span class="math inline">\(\color{red}{\mbox{fixed Q-targets}}\)</span> means we use two Q-networks. One of it using fixed old parameters to generate the Q-target to update the fresh Q-network, which can keep the update <strong>stable</strong>. Otherwise, when you update the Q-network, you also update the Q-target, which can cause diverge.</p><p>DQN in Atari</p><ul><li>End-to-end learning of values <span class="math inline">\(Q(s, a)\)</span> from pixels <span class="math inline">\(s\)</span></li><li>Input state <span class="math inline">\(s\)</span> is stack of raw pixels from last 4 frames</li><li>Output is <span class="math inline">\(Q(s, a)\)</span> for 18 joystick/button positions</li><li>Rewards is change in score for that step</li></ul><p><img src="/images/ataridqn.png"></p><p>Results</p><p><img src="/images/dqnres.png"></p><p>How much does DQN help?</p><p><img src="/images/dqnhelp.png"></p><p><strong>Linear Least Squares Prediction - Normal Equation</strong></p><p>Experience replay finds least squares solution but it may take many iterations. Using <em>linear value function approximation</em> <span class="math inline">\(\hat{v}(s, w) = x(s)^Tw\)</span>, we can solve squares soluton directly.</p><p>At minimum of <span class="math inline">\(LS(w)\)</span>, the expected update must be zero:</p><p><img src="/images/llsp.png"></p><p>For <span class="math inline">\(N\)</span> features, direct solution time is <span class="math inline">\(O(N^3)\)</span>. Incremental solution time is <span class="math inline">\(O(N^2)\)</span> using Shermann-Morrison.</p><p>We do not know true values <span class="math inline">\(v_t^\pi\)</span>. In practice, our &quot;training data&quot; must be noisy or biased samples of <span class="math inline">\(v_t^\pi\)</span>:</p><p><img src="/images/llspa.png"></p><p>In each case solve directly for fixed point of MC / TD / TD(<span class="math inline">\(\lambda\)</span>).</p><p><strong>Convergence of Linear Least Squares Prediction Algorithms</strong></p><p><img src="/images/cllspa.png"></p><h3><span id="least-squares-control">Least Squares Control</span></h3><p><strong>Least Squares Policy Iteration</strong></p><p><img src="/images/lspi.png"></p><p><strong>Least Squares Action-Value Function Approximation</strong></p><p>Approximate action-value function <span class="math inline">\(q_\pi(s, a)\)</span> using linear combination of features <span class="math inline">\(\mathbb{x}(s, a)\)</span>: <span class="math display">\[\hat{q}(s, a, \mathbb{w})=\mathbb{x}(s, a)^T\mathbb{w}\approx q_\pi(s, a)\]</span> Minimise least squares error between <span class="math inline">\(\hat{q}(s, a, \mathbb{w})\)</span> and <span class="math inline">\(q_\pi(s, a)\)</span> from experience generated using policy <span class="math inline">\(\pi\)</span> consisting of <em>&lt;(state, action), value&gt;</em> pairs: <span class="math display">\[\mathcal{D}=\{&lt;(s_1,a_1),v_1^\pi&gt;,&lt;(s_2,a_2),v_2^\pi&gt;,...,&lt;(s_T,a_T),v_T^\pi&gt;\}\]</span> <strong>Least Squares Control</strong></p><p>For policy evaluation, we want to efficiently use all experience. For control, we also want to improve the policy. This experience is generated from many policies. So to evaluate <span class="math inline">\(q_\pi(S, A)\)</span> we must learn <span class="math inline">\(\color{red}{\mbox{off-policy}}\)</span>.</p><p>We use the same idea as Q-learning:</p><ul><li>Use experience generated by old policy <span class="math inline">\(S_t, A_t, R_{t+1}, S_{t+1} \sim \pi_{old}\)</span></li><li>Consider alternative successor action <span class="math inline">\(A&#39;=\pi_{new}(S_{t+1})\)</span></li><li>Update <span class="math inline">\(\hat{q}(S_t, A_t,\mathbb{w})\)</span> towards value of alternative action <span class="math inline">\(R_{t+1}+\gamma \hat{q}(S_{t+1}, A&#39;, \mathbb{w})\)</span></li></ul><p>Consider the following linear Q-learning update <span class="math display">\[\delta=R_{t+1}+\gamma \hat{q}(S_{t+1}, \color{red}{\pi(S_{t+1})}, \mathbb{w})-\hat{q}(S_t, A_t, \mathbb{w})\\\triangle \mathbb{w}=\alpha\delta\mathbb{x}(S_t, A_t)\]</span> LSTDQ algorithm: solve for total update = zero:</p><p><img src="/images/lstdq.png"></p><p>The following pseudocode uses LSTDQ for policy evaluation. It repeatedly re-evaluates experience <span class="math inline">\(\mathcal{D}\)</span> with different policies.</p><p><img src="/images/lspipseudo.png"></p><p><strong>Convergence of Control Algorithms</strong></p><p><img src="/images/ccal.png"></p><p>End.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> DQN </tag>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Model-Free Control</title>
      <link href="/2017/12/21/RL%20-%20Model-Free%20Control/"/>
      <url>/2017/12/21/RL%20-%20Model-Free%20Control/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>Last lecture:</p><ul><li>Model-free prediction</li><li><em>Estimate</em> the value function of an <em>unknown</em> MDP</li></ul><p>This lecture:</p><ul><li>Model-free control</li><li><strong>Optimise</strong> the value function of an unknown MDP</li></ul><a id="more"></a><p>Why we care about model-free control? So, let's see some example problems that can be modelled as MDPs:</p><ul><li>Helicopter, Robocup Soccer, Quake</li><li>Portfolio management, Game of Go...</li></ul><p>For most of these problems, either:</p><ul><li>MDP model is <strong>unknown</strong>, but experience can be sampled</li><li>MDP model is known, but is <strong>too big to use</strong>, except by samples</li></ul><p><span class="math inline">\(\color{red}{\mbox{Model-free control}}\)</span> can sovlve these problems.</p><p>There are two branches of model-free control:</p><ul><li><span class="math inline">\(\color{red}{\mbox{On-policy}}\)</span> learning<ul><li>&quot;Learn on the job&quot;</li><li>Learn about policy <span class="math inline">\(\pi\)</span> from experience sampled from <span class="math inline">\(\pi\)</span></li></ul></li><li><span class="math inline">\(\color{red}{\mbox{Off-policy}}\)</span> learning<ul><li>&quot;Look over someone's shoulder&quot;</li><li>Learn about policy <span class="math inline">\(\pi\)</span> from experience sampled from <span class="math inline">\(\mu\)</span></li></ul></li></ul><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#on-policy-monte-carlo-control">On-Policy Monte-Carlo Control</a></li><li><a href="#on-policy-temporal-difference-learning">On-Policy Temporal-Difference Learning</a><ul><li><a href="#sarsalambda">Sarsa(<span class="math inline">\(\lambda\)</span>)</a></li></ul></li><li><a href="#off-policy-learning">Off-Policy Learning</a><ul><li><a href="#q-learning">Q-Learning</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><h2><span id="on-policy-monte-carlo-control">On-Policy Monte-Carlo Control</span></h2><p>In previous lectures, we have seen that using policy iteration to find the best policy. Today, we also use this central idea plugging in MC or TD algorithm.</p><p><img src="/images/pi.png"></p><p><strong>Generalised Policy Iteration With Monte-Carlo Evaluation</strong></p><p>A simple idea is</p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(V = v_\pi\)</span>?</li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: Greedy policy improvement?</li></ul><p>Well, this idea has two major problems:</p><ul><li><p>Greedy policy improvement over <span class="math inline">\(V(s)\)</span> requires <strong>model of MDP</strong> <span class="math display">\[\pi^\prime(s) = \arg\max_{a\in\mathcal{A}}\mathcal{R}^a_s+\mathcal{P}^a_{ss&#39;}V(s&#39;)\]</span> since, we do not know the state transition probability matrix <span class="math inline">\(\mathcal{P}\)</span>.</p></li><li><p>Exploration issue: cannot guarantee to explore all states</p></li></ul><p>So, the alternative is to use action-value function <span class="math inline">\(Q\)</span>:</p><ul><li>Greedy policy improvement over <span class="math inline">\(Q(s, a)\)</span> is model-free <span class="math display">\[\pi^\prime=\arg\max_{a\in\mathcal{A}}Q(s,a)\]</span></li></ul><p>Let's replace it in the algorithm:</p><p><img src="/images/avf.png"></p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(\color{red}{Q = q_\pi}\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: Greedy policy improvement?</li></ul><p>We still have one problems about the algorithm, which is exploration issue. Here is a example of greedy action selection:</p><p><img src="/images/gaseg.png"></p><p>The reward of the two doors are stochastic. However, because of the greedy action selection, we always choose the right door without exploring the value of the left one.</p><p>One simple algorithm to ensure keeping exploration is <strong><span class="math inline">\(\epsilon\)</span>-greedy exploration</strong>.</p><p><strong><span class="math inline">\(\epsilon\)</span>-Greedy Exploration</strong></p><p>All <span class="math inline">\(m\)</span> actions are tried with non-zero probalility,</p><ul><li>With probability <span class="math inline">\(1-\epsilon\)</span> choose the greedy action</li><li>With probability <span class="math inline">\(\epsilon\)</span> choose an action at <strong>random</strong></li></ul><p><span class="math display">\[\pi(a|s)=\begin{cases} \epsilon/m+1-\epsilon,  &amp; \mbox{if } a^* = \arg\max_{a\in\mathcal{A}}Q(s,a) \\\epsilon/m, &amp; \mbox{otherwise }\end{cases}\]</span></p><blockquote><p>Theorem</p><p>For any <span class="math inline">\(\epsilon\)</span>-greedy policy <span class="math inline">\(\pi\)</span>, the <span class="math inline">\(\epsilon\)</span>-greedy policy <span class="math inline">\(\pi^\prime\)</span> with respect to <span class="math inline">\(q_\pi\)</span> is an improvement, <span class="math inline">\(v_{\pi^\prime}â‰¥v_\pi(s)\)</span>.</p></blockquote><p><img src="/images/egpi.png"></p><p>Therefore from policy improvement theorem, <span class="math inline">\(v_{\pi^\prime}(s) â‰¥ v_\pi(s)\)</span>.</p><p><strong>Monte-Carlo Policy Iteration</strong></p><p><img src="/images/mcpi.png"></p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(Q = q_\pi\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: <span class="math inline">\(\color{red}{\epsilon}\)</span>-greedy policy improvement</li></ul><p><strong>Monte-Carlo Control</strong></p><p><img src="/images/mcc.png"></p><p><span class="math inline">\(\color{red}{\mbox{Every episode}}\)</span>:</p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(\color{red}{Q \approx q_\pi}\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: <span class="math inline">\(\epsilon\)</span>-greedy policy improvement</li></ul><p>The method is once evaluate over an episode, immediately improve the policy. The idea is since we already have a better evaluation, why waiting to update the policy after numerous episodes. That is improving the policy right after evaluating one episode.</p><p><strong>GLIE</strong></p><blockquote><p>Definition</p><p><strong>Greedy in the Limit with Infinite Exploration</strong> (GLIE)</p><ul><li><p>All state-action pairs are explored infinitely many times, <span class="math display">\[\lim_{k\rightarrow\infty}N_k(s,a)=\infty\]</span></p></li><li><p>The policy converges on a greedy policy, <span class="math display">\[\lim_{k\rightarrow\infty}\pi_k(a|s)=1(a=\arg\max_{a^\prime \in\mathcal{A}}Q_k(s, a^\prime))\]</span></p></li></ul></blockquote><p>For example, <span class="math inline">\(\epsilon\)</span>-greedy is GLIE if <span class="math inline">\(\epsilon\)</span> reduces to zero at <span class="math inline">\(\epsilon_k=\frac{1}{k}\)</span>.</p><p><strong>GLIE Monte-Carlo Control</strong></p><p>Sample <span class="math inline">\(k\)</span>th episode using <span class="math inline">\(\pi\)</span>: <span class="math inline">\(\{S_1, A_1, R_2, â€¦, S_T\} \sim \pi\)</span></p><ul><li><p><span class="math inline">\(\color{red}{\mbox{Evaluation}}\)</span></p><ul><li>For each state <span class="math inline">\(S_t\)</span> and action <span class="math inline">\(A_t\)</span> in the episode, <span class="math display">\[\begin{array}{lcl}N(S_t, A_t) \leftarrow N(S_t, A_t)+1 \\Q(S_t, A_t) \leftarrow Q(S_t, A_t)+\frac{1}{N(S_t, A_t)}(G_t-Q(S_t, A_t))\end{array}\]</span></li></ul></li><li><p><span class="math inline">\(\color{red}{\mbox{Improvement}}\)</span></p><ul><li>Improve policy based on new action-value function <span class="math display">\[\begin{array}{lcl}\epsilon\leftarrow \frac{1}{k} \\\pi \leftarrow \epsilon\mbox{-greedy}(Q)\end{array}\]</span></li></ul></li></ul><p>GLIE Monte-Carlo control converges to the optimal action-value function, <span class="math inline">\(Q(s,a) \rightarrow q_*(s,a)\)</span>.</p><p><strong>Blackjack Example</strong></p><p><img src="/images/mccb.png"></p><p>Using Monte-Carlo control, we can get the optimal policy above.</p><h2><span id="on-policy-temporal-difference-learning">On-Policy Temporal-Difference Learning</span></h2><p>Temporal-difference (TD) learning has several advantages over Monte-Carlo (MC):</p><ul><li>low variance</li><li>Online</li><li>Incomplete sequences</li></ul><p>A natural idea is using TD instead of MC in our control loop:</p><ul><li>Apply TD to <span class="math inline">\(Q(S, A)\)</span></li><li>Use <span class="math inline">\(\epsilon\)</span>-greedy policy improvement</li><li>Update every <em>time-step</em></li></ul><p><strong>Sarsa Update</strong></p><p><img src="/images/sarsa.png"></p><p>Updating action-value functions with Sarsa: <span class="math display">\[Q(S,A) \leftarrow Q(S, A) + \alpha(R+\gamma Q(S^\prime, A^\prime)-Q(S, A))\]</span> <img src="/images/mcc.png"></p><p>So, the full algorithm is:</p><ul><li>Every <span class="math inline">\(\color{red}{\mbox{time-step}}\)</span>:<ul><li><span class="math inline">\(\color{blue}{\mbox{Policy evaluation}}\)</span> <span class="math inline">\(\color{red}{\mbox{Sarsa}}\)</span>, <span class="math inline">\(Q\approx q_\pi\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span> <span class="math inline">\(\epsilon\)</span>-greedy policy improvement</li></ul></li></ul><p><img src="/images/pesedotd.png"></p><p><strong>Windy Gridworld Example</strong></p><p><img src="/images/wweg.png"></p><p>The 'S' represents start location and 'G' marks the goal. There is a number at the bottom of each column which represents the wind will blow the agent up how many grids if the agent stays at that column.</p><p>The result of apply Sarsa to the problem is</p><p><img src="/images/wwegres.png"></p><h3><span id="sarsalambda">Sarsa(<span class="math inline">\(\lambda\)</span>)</span></h3><p><strong>n-Step Sarsa</strong></p><p>Consider the following <span class="math inline">\(n\)</span>-step returns for <span class="math inline">\(n=1,2,..\infty\)</span>:</p><p><img src="/images/nsarsa.png"></p><p>Define the <span class="math inline">\(n\)</span>-step <span class="math inline">\(Q\)</span>-return <span class="math display">\[q_t^{(n)}=R_{t+1}+\gamma R_{t+2}+...+\gamma^{n-1}R_{t+n}+\gamma^n Q(S_{t+n})\]</span> <span class="math inline">\(n\)</span>-step Sarsa updates <span class="math inline">\(Q(s, a)\)</span> towards the <span class="math inline">\(n\)</span>-step <span class="math inline">\(Q\)</span>-return <span class="math display">\[Q(S_t, A_t)\leftarrow Q(S_t, A_t)+\alpha(q_t^{(n)}-Q(S_t,A_t))\]</span> <strong>Forward View Sarsa(<span class="math inline">\(\lambda\)</span>)</strong></p><p><img src="/images/sarsalam.png"></p><p>The <span class="math inline">\(q^\lambda\)</span> return combines all <span class="math inline">\(n\)</span>-step Q-returns <span class="math inline">\(q_t^{(n)}\)</span> using weight <span class="math inline">\((1-\lambda)\lambda^{n-1}\)</span>: <span class="math display">\[q_t^\lambda = (1-\lambda)\sum^\infty_{n=1}\lambda^{n-1}q_t^{(n)}\]</span> Forward-view Sarsa(<span class="math inline">\(\lambda\)</span>): <span class="math display">\[Q(S_t, A_t)\leftarrow Q(S_t, A_t)+\alpha(q_t^\lambda-Q(S_t, A_t))\]</span> <strong>Backward View Sarsa(<span class="math inline">\(\lambda\)</span>)</strong></p><p>Just like TD(<span class="math inline">\(\lambda\)</span>), we use <span class="math inline">\(\color{red}{\mbox{eligibility traces}}\)</span> in an online algorithm, but Sarsa(<span class="math inline">\(\lambda\)</span>) has one eligibility trace for each state-action pair: <span class="math display">\[E_0(s, a) = 0\]</span></p><p><span class="math display">\[E_t(s, a) = \gamma\lambda E_{t-1}(s,a)+1(S_t=s, A_t=a)\]</span></p><p><span class="math inline">\(Q(s, a)\)</span> is updated for every state <span class="math inline">\(s\)</span> and action <span class="math inline">\(a\)</span> in proportion to TD-error <span class="math inline">\(\delta_t\)</span> and eligibility trace <span class="math inline">\(E_t(s, a)\)</span>: <span class="math display">\[\delta_t=R_{t+1}+\gamma Q(S_{t+1}, A_{t+1})-Q(S_t, A_t)\]</span></p><p><span class="math display">\[Q(s, a) \leftarrow Q(s, a) +\alpha \delta_t E_t(s, a)\]</span></p><p><img src="/images/sarcode.png"></p><p>The difference between Sarsa and Sarsa(<span class="math inline">\(\lambda\)</span>):</p><p><img src="/images/sarsadiff.png"></p><p>If we initial all <span class="math inline">\(Q(s, a) = 0\)</span>, then we first do a random walk and reach the goal. Using Sarsa, we can only update the Q-value of the previous state before reaching the goal since all other <span class="math inline">\(Q\)</span> are zero. So the reward can only propagate one state. On the contrary, if we using Sarsa(<span class="math inline">\(\lambda\)</span>), the reward can propagate from the last state to the first state with a exponential decay.</p><h2><span id="off-policy-learning">Off-Policy Learning</span></h2><p>Evaluate target policy <span class="math inline">\(\pi(a|s)\)</span> to compute <span class="math inline">\(v_\pi(s)\)</span> or <span class="math inline">\(q_\pi(s, a)\)</span> while following behaviour policy <span class="math inline">\(\mu(a|s)\)</span> <span class="math display">\[\{S_1, A_1, R_2, ..., S_T\}\sim \mu\]</span> So, why is this important? There are several reasons:</p><ul><li>Learn from observing hunman or other agents</li><li>Re-use experience generated from old policies <span class="math inline">\(\pi_1, \pi_2, â€¦, \pi_{t-1}\)</span></li><li>Learn about <strong>optimal</strong> policy while following <span class="math inline">\(\color{red}{\mbox{exploratory policy}}\)</span></li><li>Learn about <strong>multiple</strong> policies while following one policy</li></ul><p><strong>Importance Sampling</strong></p><p>Estimate the expectation of a different distribution <span class="math display">\[\mathbb{E}_{X\sim P}[f(X)] = \sum P(X)f(X)=\sum Q(X)\frac{P(X)}{Q(X)}f(X)=\mathbb{E}_{X\sim Q}[\frac{P(X)}{Q(X)}f(X)]\]</span> <strong>Off-Policy Monte-Carlo</strong></p><p>Use returns generated from <span class="math inline">\(\mu\)</span> to evaluate <span class="math inline">\(\pi\)</span>. Weight return <span class="math inline">\(G_t\)</span> according to <strong>similarity</strong> between policies. Multiply importance sampling corrections along whole episode: <span class="math display">\[G_t^{\pi/\mu}=\frac{\pi(A_t|S_t)}{\mu(A_t|S_t)}\frac{\pi(A_{t+1}|S_{t+1})}{\mu(A_{t+1}|S_{t+1})}...\frac{\pi(A_T|S_T)}{\mu(A_T|S_T)}G_t\]</span> Update value towards <em>corrected</em> return: <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha (\color{red}{G_t^{\pi/\mu}}-V(S_t))\]</span> But it has two major problems:</p><ul><li>Cannot use if <span class="math inline">\(\mu\)</span> is zero when <span class="math inline">\(\pi\)</span> is non-zero</li><li>Importance sampling can dramatically increase variance, so it is useless in practice</li></ul><p><strong>Off-Policy TD</strong></p><p>Use TD targets generated from <span class="math inline">\(\mu\)</span> to evaluate <span class="math inline">\(\pi\)</span>. Weight TD target <span class="math inline">\(R+\gamma V(S&#39;)\)</span> by importance sampling. Only need a single importance sampling correction: <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha \left(\color{red}{\frac{\pi(A_t|S_t)}{\mu(A_t|S_t)}(R_{t+1}+\gamma V(S_{t+1}))}-V(S_t)\right)\]</span> This algorithm has much lower variance than Monte-Carlo importance sampling because policies only need to be similar over a single step.</p><h3><span id="q-learning">Q-Learning</span></h3><p>We now consider off-policy learning of action-values <span class="math inline">\(Q(s, a)\)</span>. The benefit of it is no importance sampling is required.</p><p>The next action is chosen using <strong>behaviour</strong> policy <span class="math inline">\(A_{t+1}\sim\mu(\cdot|S_t)\)</span>. But we consider <strong>alternative</strong> successor action <span class="math inline">\(A&#39;\sim \pi(\cdot|S_t)\)</span>. And update <span class="math inline">\(Q(S_t, A_t)\)</span> towards value of alternative action <span class="math display">\[Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \alpha (R_{t+1}+\gamma Q(S_{t+1}, \color{red}{A&#39;})-Q(S_t, A_t))\]</span> We now allow both behaviour and target policies to <strong>improve</strong>.</p><p>The <strong>target</strong> policy <span class="math inline">\(\pi\)</span> is <span class="math inline">\(\color{red}{\mbox{greedy}}\)</span> w.r.t <span class="math inline">\(Q(s, a)\)</span>: <span class="math display">\[\pi(S_{t+1})=\arg\max_{a&#39;}Q(S_{t+1}, a&#39;)\]</span> The <strong>behaviour</strong> policy <span class="math inline">\(\mu\)</span> is e.g. <span class="math inline">\(\color{red}{\epsilon \mbox{-greedy}}\)</span> w.r.t. <span class="math inline">\(Q(s,a)\)</span>.</p><p>The <strong>Q-learning</strong> target then simplifies: <span class="math display">\[\begin{align}\mbox{Q-learning Target} &amp;= R_{t+1}+\gamma Q(S_{t+1}, A&#39;) \\&amp; = R_{t+1}+\gamma Q(S_{t+1}, \arg\max_{a&#39;}Q(S_{t+1}, a&#39;)) \\&amp;= R_{t+1}+\max_{a&#39;}\gamma Q(S_{t+1}, a&#39;)\end{align}\]</span> So the Q-learning control algorithm is</p><p><img src="/images/qlalg.png"></p><p>Of course, the Q-learning control still converges to the optimal action-value function, <span class="math inline">\(Q(s, a)\rightarrow q_*(s,a)\)</span>.</p><p><img src="/images/qlcode.png"></p><h2><span id="summary">Summary</span></h2><p><strong>Relationship Between DP and TD</strong></p><p><img src="/images/rbtddp.png"></p><p><img src="/images/rbtddp2.png"></p><p>In a word, TD backup can be seen as the sample of corresponding DP backup. This lecture introduces model-free control which is optimise the value function of an unknown MDP with on-policy and off-policy methods. Next lecture will introduce function approximation which is easy to scale up and can be applied into big MDPs.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> Q-learning </tag>
            
            <tag> Monte-Carlo Control </tag>
            
            <tag> Sarsa </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Model-Free Prediction</title>
      <link href="/2017/12/16/RL%20-%20Model-Free%20Prediction/"/>
      <url>/2017/12/16/RL%20-%20Model-Free%20Prediction/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>Last lecture, David taught us how to solve a <em>known</em> MDP, which is <em>planning by dynamic programming</em>. In this lecture, we will learn how to estimate the value function of an <strong>unknown</strong> MDP, which is <em>model-free prediction</em>. And in the next lecture, we will <em>optimise</em> the value function of an unknown MDP.</p><a id="more"></a><p>In summary:</p><ul><li>Planning by dynamic programming<ul><li>Solve a <em>known MDP</em></li></ul></li><li><strong>Model-Free prediction</strong><ul><li>Estimate the value function of an <em>unknown</em> MDP</li></ul></li><li>Model-Free control<ul><li>Optimise the value function of an <em>unknown</em> MDP</li></ul></li></ul><p>We have two major methods to estimate the value function of an unknown MDP:</p><ul><li>Monte-Carlo Learning</li><li>Temporal-Difference Learning</li></ul><p>We will introduce the two methods and combine them to a general method.</p><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#monte-carlo-learning">Monte-Carlo Learning</a></li><li><a href="#temporal-difference-learning">Temporal-Difference Learning</a><ul><li><a href="#unified-view">Unified View</a></li></ul></li><li><a href="#tdlambda">TD(<span class="math inline">\(\lambda\)</span>)</a><ul><li><a href="#forward-view-tdlambda">Forward View TD(<span class="math inline">\(\lambda\)</span>)</a></li><li><a href="#backward-view-tdlambda">Backward View TD(<span class="math inline">\(\lambda\)</span>)</a></li><li><a href="#relationship-between-forward-and-backward-td">Relationship Between Forward and Backward TD</a></li></ul></li></ul><!-- tocstop --><h2><span id="monte-carlo-learning">Monte-Carlo Learning</span></h2><p>MC (Monte-Carlo) methods learn directly from <strong>episodes of experience</strong>, which means:</p><ul><li>MC is <em>model-free</em>: no knowledge of MDP transitions / rewards</li><li>MC learns from complete episodes: no bootstrapping</li><li>MC uses the simplest possible idea: value = mean return</li><li>Can only apply MC to <em>episodic</em> MDPs: all episodes must terminate</li></ul><p><strong>Goal</strong>: learn <span class="math inline">\(v_\pi\)</span> from episodes of experience under policy <span class="math inline">\(\pi\)</span> <span class="math display">\[S_1, A_1, R_2, ..., S_k \sim \pi\]</span> Recall that the <strong>return</strong> is the total discounted reward: <span class="math display">\[G_t = R_{t+1}+\gamma R_{t+2} + ... + \gamma^{T-1}R_T\]</span> Recall that the <strong>value function</strong> is the expected return: <span class="math display">\[v_\pi(s) = \mathbb{E}_\pi[G_t|S_t=s]\]</span> Monte-Carlo policy evaluation uses <em>empirical mean</em> return instead of <em>expected</em> return.</p><p><strong>First-Visit Monte-Carlo Policy Evaluation</strong></p><p>To evaluate state <span class="math inline">\(s\)</span>, the <strong>first</strong> time-step <span class="math inline">\(t\)</span> that state <span class="math inline">\(s\)</span> is visited in <strong>an episode</strong>:</p><ul><li>Increment counter <span class="math inline">\(N(s) \leftarrow N(s) + 1\)</span></li><li>Increment total return <span class="math inline">\(S(s) \leftarrow S(s) + G_t\)</span></li></ul><p>Value is estimated by mean return <span class="math inline">\(V(s) = S(s) / N(s)\)</span>, by <em>law of large numbers</em>, <span class="math inline">\(V(s) \rightarrow v_\pi(s)\)</span> as <span class="math inline">\(N(s) \rightarrow \infty\)</span>.</p><p><strong>Every-Visit Monte-Carlo Policy Evaluation</strong></p><p>To evaluate state <span class="math inline">\(s\)</span>, <strong>every</strong> time-step <span class="math inline">\(t\)</span> that state <span class="math inline">\(s\)</span> is visited in <strong>an episode</strong>:</p><ul><li>Increment counter <span class="math inline">\(N(s) \leftarrow N(s) + 1\)</span></li><li>Increment total return <span class="math inline">\(S(s) \leftarrow S(s) + G_t\)</span></li></ul><p>Value is estimated by mean return <span class="math inline">\(V(s) = S(s) / N(s)\)</span>. Again, by <em>law of large numbers</em>, <span class="math inline">\(V(s) \rightarrow v_\pi(s)\)</span> as <span class="math inline">\(N(s) \rightarrow \infty\)</span>.</p><p><strong>Blackjack Example</strong></p><p>Please refer to https://www.wikiwand.com/en/Blackjack to learn the rule of <em>Blackjack</em>.</p><p>If we build an RL agent to play blackjack, the <strong>states</strong> would have 3-dimension:</p><ul><li>Current sum (12 - 21)<ul><li>We just consider this range because if the current sum is lower than 12, we will always take another card.</li></ul></li><li>Dealer's showing card (ace - 10)</li><li>Do I have a &quot;useable&quot; ace? (yes - no)</li></ul><p>So there would be 200 different states.</p><p>The actions are:</p><ul><li><strong>Stick</strong>: stop receiving cards and terminate</li><li><strong>Twist</strong>: take another card (no replacement)</li></ul><p>And <em>reward</em> for action</p><ul><li><strong>Stick</strong><ul><li><span class="math inline">\(+1\)</span> if sum of cards <span class="math inline">\(&gt;\)</span> sum of dealer cards</li><li><span class="math inline">\(0\)</span> if sum of cards <span class="math inline">\(=\)</span> sum of dealer cards</li><li><span class="math inline">\(-1\)</span> if sum of cards <span class="math inline">\(&lt;\)</span> sum of dealer cards</li></ul></li><li><strong>Twist</strong><ul><li><span class="math inline">\(-1\)</span> if sum of cards <span class="math inline">\(&gt; 21\)</span> and terminate</li><li><span class="math inline">\(0\)</span> otherwise</li></ul></li></ul><p>Transitions: automatically <em>twist</em> if sum of cards &lt; 12.</p><p>Policy: <strong>stick</strong> if sum of cards <span class="math inline">\(â‰¥ 20\)</span>, otherwise <strong>twist</strong>.</p><p><img src="/images/backjack.png"></p><p>In the above diagrams, the height represents the value function of that point. Since it's a simple policy, the value funtion achieves high value only if player sum is higher than 20.</p><p><strong>Incremental Mean</strong></p><p>The mean <span class="math inline">\(\mu_1, \mu_2, â€¦\)</span> of a sequence <span class="math inline">\(x_1, x_2, â€¦\)</span> can be computed incrementally, <span class="math display">\[\begin{align}\mu_k &amp; = \frac{1}{k}\sum^k_{j=1}x_j \\&amp; = \frac{1}{k}(x_k+\sum^{k-1}_{j=1}x_j) \\&amp;= \frac{1}{k}(x_k+(k-1)\mu_{k-1}) \\&amp;= \mu_{k-1}+\frac{1}{k}(x_k-\mu_{k-1}) \\\end{align}\]</span> which means the current mean equals to previous mean plus some error. The error is <span class="math inline">\(x_k - \mu_{k-1}\)</span> and the step-size is <span class="math inline">\(\frac{1}{k}\)</span>, which is dynamic.</p><p><strong>Incremental Monte-Carlo Updates</strong></p><p>Update <span class="math inline">\(V(s)\)</span> incrementally after episode <span class="math inline">\(S_1, A_1, R_2, â€¦, S_T\)</span>, for each state <span class="math inline">\(S_t\)</span> with return <span class="math inline">\(G_t\)</span>, <span class="math display">\[N(S_t) \leftarrow N(S_t) + 1\]</span></p><p><span class="math display">\[V(S_t)\leftarrow V(S_t)+\frac{1}{N(S_t)}(G_t-V(S_t))\]</span></p><p>In non-stationary problems, it can be useful to track a running mean, i.e. forget old episodes, <span class="math display">\[V(S_t)\leftarrow V(S_t) + \alpha(G_t-V(S_t))\]</span> So, that's the part for Monte-Carlo learning. It's a very simple idea: you run out an episode, look the complete return and update the mean value of the sample return for each state you have visited.</p><h2><span id="temporal-difference-learning">Temporal-Difference Learning</span></h2><p>Temporal-Difference (TD) methods learn directly from episodes of experiences, which means</p><ul><li>TD is <em>model-free</em>: no knowledge of MDP transitions / rewards</li><li>TD learns from <strong>incomplete</strong> episodes, by <em>bootstrapping</em>. (A major difference from MC method)</li><li>TD updates a guess towards a guess.</li></ul><p>Goal: learn <span class="math inline">\(v_\pi\)</span> online from experience under policy <span class="math inline">\(\pi\)</span>.</p><p><em>Incremental every-visit Monte-Carlo</em></p><ul><li>Update value <span class="math inline">\(V(S_t)\)</span> toward actual return <span class="math inline">\(\color{Red}{G_t}\)</span> <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha (\color{Red}{G_t}-V(S_t))\]</span></li></ul><p>Simplest temporal-difference learning algorithm: <strong>TD(0)</strong></p><ul><li><p>Update value <span class="math inline">\(V(S_t)\)</span> towards <em>estimated</em> return <span class="math inline">\({\color{Red}{R_{t+1}+\gamma V(S_{t+1})}}\)</span> <span class="math display">\[V(S_t)\leftarrow V(S_t)+ \alpha ({\color{Red}{R_{t+1}+\gamma V(S_{t+1})}}-V(S_t))\]</span></p></li><li><p><span class="math inline">\(R_{t+1}+\gamma V(S_{t+1})â€‹\)</span> is called the <em>TD target</em>;</p></li><li><p><span class="math inline">\(\delta = R_{t+1}+\gamma V(S_{t+1})-V(S_t)\)</span> is called the <em>TD error</em>.</p></li></ul><p>Let's see a concret <strong>driving home example</strong>.</p><p><img src="/images/dheg.png"></p><p>The <em>Elapsed Time</em> shows the actual time that has spent, the <em>Predicted Time to Go</em> represents the predicted time to arrive home from current state, and the <em>Predicted Total Time</em> means the predicted time to arrive home from leaving office.</p><p><strong>Advantages and Disadvantages of MC vs. TD</strong></p><p>TD can learn <em>before</em> knowing the final outcome</p><ul><li>TD can learn online after every step</li><li>MC must wait until end of episode before return is known</li></ul><p>TD can learn <em>without</em> the final outcome</p><ul><li>TD can learn from incomplete sequences</li><li>MC can only learn from complete sequences</li><li>TD works in continuing (non-terminating) environments</li><li>MC only works for episodic (terminating) environments</li></ul><p>MC has high variance, zero bias</p><ul><li>Good convergence properties (even with function approximation)</li><li>Not very sensitive to initial value</li><li>Very simple to understand and use</li></ul><p>TD has low variance, some bias</p><ul><li>Usually more efficient than MC</li><li>TD(0) converges to <span class="math inline">\(v_\pi(s)\)</span> (but not always with function approximation)</li><li>More sensitive to initial value</li></ul><p><strong>Bias/Variance Trade-Off</strong></p><p>Return <span class="math inline">\(G_t = R_{t+1} + \gamma R_{t+2}+â€¦+\gamma^{T-1}R_T\)</span> is <strong>unbiased</strong> estimate of <span class="math inline">\(v_\pi(S_t)\)</span>.</p><p>True TD target <span class="math inline">\(R_{t+1}+\gamma v_\pi(S_{t+1})\)</span> is <strong>unbiased</strong> estimate of <span class="math inline">\(v_\pi(S_t)\)</span></p><blockquote><p>Explanation of bias and variance:</p><ul><li>The <a href="https://www.wikiwand.com/en/Bias_of_an_estimator" target="_blank" rel="noopener">bias of an estimator</a> is the difference between an estimator's expected value and the true value of the parameter being estimated.</li><li>A <strong>variance</strong> value of zero indicates that all values within a set of numbers are identical; all variances that are non-zero will be positive numbers. A large variance indicates that numbers in the set are far from the mean and each other, while a small variance indicates the opposite. Read more: <a href="https://www.investopedia.com/terms/v/variance.asp#ixzz51J8RTueh" target="_blank" rel="noopener">Variance</a></li></ul></blockquote><p>While TD target <span class="math inline">\(R_{t+1}+\gamma V(S_{t+1})\)</span> is <strong>biased</strong> estimate of <span class="math inline">\(v_\pi(S_t)\)</span>.</p><p>However, TD target is much lower <em>variance</em> than the return, since</p><ul><li>Return depends on <em>many</em> random actions, transitions, rewards</li><li>TD target depends on <em>one</em> random actions, transition, reward</li></ul><p><strong>Random Walk Example</strong></p><p><img src="/images/rweg.png"></p><p>There are several states on a street, the black rectangles are terminate states. Each transition has 0.5 probability and the reward is marked on the line. The question is what is the value function of each state?</p><p>Using <em>TD</em> to solve the problem:</p><p><img src="/images/rwtd.png"></p><p>The x-axis represents each state, y-axis represent the estimated value. Each line represents the result of TD algorithm that run different episodes. We can see, at the begining, all states have initial value <span class="math inline">\(0.5\)</span>. After 100 episodes, the line converges to diagonal, which is the true values.</p><p>Using <em>MC</em> to solve the problem:</p><p><img src="/images/rwmc.png"></p><p>The x-axis represents the number of episodes that algorithm takes. The y-axis shows the error of the algorithm. The black lines shows using MC methods with different step-size, while the grey lines below represents using TD methods with different step-size. We can see TD methods are more efficient than MC methods.</p><p><strong>Batch MC and TD</strong></p><p>We know that MC and TD converge: <span class="math inline">\(V(s) \rightarrow v_\pi(s)\)</span> as experience <span class="math inline">\(\rightarrow \infty\)</span>. But what about batch solution for finite experience? If we <strong>repeatly</strong> train some <em>finite</em> sample episodes with MC and TD respectively, do the two algorithms give <strong>same</strong> result?</p><p><em>AB Example</em></p><p>To get more intuition, let's see the <em>AB</em> example.</p><p>There are two states in a MDP, <span class="math inline">\(A, B\)</span> with no discounting. And we have 8 episodes of experience:</p><ul><li>A, 0, B, 0</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 0</li></ul><p>For example, the first episode means we in state <span class="math inline">\(A\)</span> and get <span class="math inline">\(0\)</span> reward, then transit to state <span class="math inline">\(B\)</span> getting <span class="math inline">\(0\)</span> reward, and then terminate.</p><p>So, What is <span class="math inline">\(V(A), V(B)\)</span> ?</p><p>First, let's consider <span class="math inline">\(V(B)\)</span>. <span class="math inline">\(B\)</span> state shows 8 times and 6 of them get reward <span class="math inline">\(1\)</span>, 2 of them get reward <span class="math inline">\(0\)</span>. So <span class="math inline">\(V(B) = \frac{6}{8} = 0.75\)</span> according to TD and MC.</p><p>However, if we consider <span class="math inline">\(V(A)\)</span>, MC method will give <span class="math inline">\(V(A) = 0\)</span>, since <span class="math inline">\(A\)</span> just shows in one episode and the reward of that episode is <span class="math inline">\(0\)</span>. TD method will give <span class="math inline">\(V(A) = 0 + V(B) = 0.75\)</span>.</p><p>The MDP of these experiences can be illustrated as</p><p><img src="/images/abmdp.png"></p><p><strong>Certainty Equivalence</strong></p><p>As we show above,</p><ul><li><p><strong>MC</strong> converges to solution with <strong>minimum mean-squared error</strong></p><ul><li><p>Best fit to the <strong>observed returns</strong> <span class="math display">\[\sum^K_{k=1}\sum^{T_k}_{t=1}(G^k_t-V(s^k_t))^2\]</span></p></li><li><p>In the AB example, <span class="math inline">\(V(A) = 0\)</span></p></li></ul></li><li><p><strong>TD(0)</strong> converges to solution of <strong>max likelihood Markov model</strong></p><ul><li><p>Solution to the <strong>MDP <span class="math inline">\(&lt;\mathcal{S, A, P, R, }\gamma&gt;\)</span> that best fits the data</strong></p><p><img src="/images/cemath.png"></p><p>(First, count the transitions. Then compute rewards.)</p></li><li><p>In the AB example, <span class="math inline">\(V(A) = 0.75\)</span></p></li></ul></li></ul><p><strong>Advantages and Disadvantages of MC vs. TD (2)</strong></p><ul><li>TD exploits <strong>Markov property</strong><ul><li>Usually more efficient in Markov environments</li></ul></li><li>MC does <strong>not</strong> exploit Markov property<ul><li>Usually more effective in non-Markov environments</li></ul></li></ul><h3><span id="unified-view">Unified View</span></h3><p><strong>Monte-Carlo Backup</strong></p><p><img src="/images/mcbackup.png"></p><p>We start from <span class="math inline">\(S_t\)</span> to look-ahead and build a look-ahead tree. What Monte-Carlo do is to sample a episode until it terminates and use the episode to update the value of state <span class="math inline">\(S_t\)</span>.</p><p><strong>Temporal-Difference Backup</strong></p><p><img src="/images/tdbackup.png"></p><p>On the contrary, TD backup just sample one-step ahead and use the value of <span class="math inline">\(S_{t+1}\)</span> to update <span class="math inline">\(S_t\)</span>.</p><p><strong>Dynamic Programming Backup</strong></p><p><img src="/images/dpbackup.png"></p><p>In dynamic programming backup, we do not sample. Since we know the environment, we look all possible one-step ahead and weighted them to update the value of <span class="math inline">\(S_t\)</span>.</p><p><strong>Bootstrapping and Sampling</strong></p><ul><li><strong>Bootstrapping</strong>: update involves an estimate<ul><li>MC does not bootstrap</li><li>DP bootstraps</li><li>TD bootstraps</li></ul></li><li><strong>Sampling</strong>: update samples an expectation<ul><li>MC samples</li><li>DP does not sample</li><li>TD samples</li></ul></li></ul><p><strong>Unified View of Reinforcement Learning</strong></p><p><img src="/images/uvrl.png"></p><h2><span id="tdlambda">TD(<span class="math inline">\(\lambda\)</span>)</span></h2><p>Let TD target look <span class="math inline">\(n\)</span> steps into the future,</p><figure><img src="/images/tdlam.png" alt="ds"><figcaption>ds</figcaption></figure><p>Consider the following <span class="math inline">\(n\)</span>-step returns for <span class="math inline">\(n = 1, 2, â€¦, \infty\)</span>:</p><p><img src="/images/tdlamret.png"></p><p>Define the <span class="math inline">\(n\)</span>-step return <span class="math display">\[G_t^{(n)} = R_{t+1}+\gamma R_{t+2}+...+\gamma^{n-1}R_{t+n}+\gamma^n V(S_{t+n})\]</span> <span class="math inline">\(n\)</span>-step temporal-difference learning: <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha (G_t^{(n)}-V(S_t))\]</span> We know that <span class="math inline">\(n \in [1, \infty)\)</span>, but which <span class="math inline">\(n\)</span> is the best?</p><p>There are some experiments about that:</p><p><img src="/images/rmn.png"></p><p>So, you can see that the optimal <span class="math inline">\(n\)</span> changes with on-line learning and off-line leanring. If the MDP changes, the best <span class="math inline">\(n\)</span> also changes. Is there a robust algorithm to fit any different situation?</p><h3><span id="forward-view-tdlambda">Forward View TD(<span class="math inline">\(\lambda\)</span>)</span></h3><p><strong>Averaging n-step Returns</strong></p><p>We can average n-step returns over different <span class="math inline">\(n\)</span>, e.g. average the 2-step and 4-step returns: <span class="math display">\[\frac{1}{2}G^{(2)}+\frac{1}{2}G^{(4)}\]</span> But can we efficiently combine information from all time-steps?</p><p>The answer is yes.</p><p><strong><span class="math inline">\(\lambda\)</span>-return</strong></p><p><img src="/images/tdlambda.png"></p><p>The <span class="math inline">\(\lambda\)</span>-return <span class="math inline">\(G_t^{\lambda}\)</span> combines all n-step returns <span class="math inline">\(G_t^{(n)}\)</span> using weight <span class="math inline">\((1-\lambda)\lambda^{n-1}\)</span>: <span class="math display">\[G_t^\lambda = (1-\lambda)\sum^\infty_{n=1}\lambda^{n-1}G_t^{(n)}\]</span> <strong>Forward-view</strong> <span class="math inline">\(TD(\lambda)\)</span>, <span class="math display">\[V(S_t) \leftarrow V(S_t) + \alpha (G_t^\lambda-V(S_t))\]</span> <img src="/images/tdgeo.png"></p><p>We can see the weight decay geometrically and the weights sum to 1.</p><p>The reason we use geometrical decay rather than other weight because it's efficient to compute, we can compute TD(<span class="math inline">\(\lambda\)</span>) as efficient as TD(0).</p><p><img src="/images/forwardtd.png"></p><p><strong>Forward-view</strong> <span class="math inline">\(TD(\lambda)\)</span></p><ul><li>Updates value function towards the <span class="math inline">\(\lambda\)</span>-return</li><li>Looks into the future to compute <span class="math inline">\(G_t^\lambda\)</span></li><li>Like MC, can only be computed from <strong>complete episodes</strong></li></ul><p><img src="/images/fortdlam.png"></p><h3><span id="backward-view-tdlambda">Backward View TD(<span class="math inline">\(\lambda\)</span>)</span></h3><p><strong>Eligibility Traces</strong></p><p><img src="/images/bellexe.png"></p><p>Recall the <a href="https://www.52coding.com.cn/index.php?/Articles/single/69#header-n50">rat example</a> in lecture 1, credit assignment problem: did bell or light cause shock?</p><ul><li><strong>Frequency heuristic</strong>: assign credit to most frequent states</li><li><strong>Recency heuristic</strong>: assign credit to most recent states</li></ul><p><em>Eligibility traces</em> combine both heuristics.</p><p><img src="/images/egt.png"></p><p>If visit state <span class="math inline">\(s\)</span>, <span class="math inline">\(E_t(s)\)</span> plus <span class="math inline">\(1\)</span>; otherwise <span class="math inline">\(E_t(s)\)</span> decay exponentially.</p><p><strong>Backward View TD(<span class="math inline">\(\lambda\)</span>)</strong></p><ul><li>Keep an eligibility trace for every state <span class="math inline">\(s\)</span></li><li>Update value <span class="math inline">\(V(s)\)</span> for every state <span class="math inline">\(s\)</span> in proportion to TD-error <span class="math inline">\(\delta_t\)</span> and eligibility trace <span class="math inline">\(E_t(s)\)</span></li></ul><p><span class="math display">\[\delta_t=R_{t+1}+\gamma V(S_{t+1})-V(S_t)\]</span></p><p><span class="math display">\[V(s)\leftarrow V(s)+\alpha \delta_tE_t(s)\]</span></p><p><img src="/images/bvtdlam.png"></p><p>When <span class="math inline">\(\lambda = 0\)</span>, only current state is updated, which is exactly equivalent to TD(0) update: <span class="math display">\[E_t(s) = 1(S_t = s)\]</span></p><p><span class="math display">\[V(s)\leftarrow V(s)+\alpha\delta_tE_t(s) = V(S_t)+\alpha\delta_t\]</span></p><p>When <span class="math inline">\(\lambda = 1\)</span>, credit is deferred until end of episode, total update for TD(1) is the same as total update for MC.</p><h3><span id="relationship-between-forward-and-backward-td">Relationship Between Forward and Backward TD</span></h3><blockquote><p><strong>Theorem</strong></p><p>The sum of offline updates is identical for forward-view and backward-view TD(<span class="math inline">\(\lambda\)</span>) <span class="math display">\[\sum^T_{t=1}\alpha\delta_tE_t(s)=\sum^T_{t=1}\alpha(G_t^\lambda-V(S_t))1(S_t=s)\]</span></p></blockquote><p><strong>MC and TD(1)</strong></p><p>Consider an episode where <span class="math inline">\(s\)</span> is visited once at time-step <span class="math inline">\(k\)</span>, TD(1) eligiblity trace discounts time since visit, <span class="math display">\[E_t(s) = \gamma E_{t-1}(s)+1(S_t = s) = \begin{cases} 0,  &amp; \mbox{if }t&lt;k \\\gamma^{t-k}, &amp; \mbox{if }tâ‰¥k\end{cases}\]</span> TD(1) updates accumulate error <em>online</em> <span class="math display">\[\sum^{T-1}_{t=1}\alpha\delta_tE_t(s)=\alpha\sum^{T-1}_{t=k}\gamma^{t-k}\delta_t\]</span> By end of episode it accumulates total error <span class="math display">\[\begin{align}\mbox{TD(1) Error}&amp;= \delta_k+\gamma\delta_{k+1}+\gamma^2\delta_{k+2}+...+\gamma^{T-1-k}\delta_{T-1} \\&amp; = R_{t+1}+\gamma V(S_{t+1}) -V(S_t) \\&amp;+ \gamma R_{t+2}+\gamma^2V(S_{t+2}) - \gamma V(S_{t+1})\\&amp;+ \gamma^2 R_{t+3}+\gamma^3V(S_{t+3}) - \gamma^2 V(S_{t+2})\\&amp;+\ ... \\&amp;+ \gamma^{T-1-t}R_T+\gamma^{T-t}V(S_T)-\gamma^{T-1-t}V(S_{T-1})\\&amp;= R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3} ... + \gamma^{T-1-t}R_T-V(S_t)\\&amp;= G_t-V(S_t)\\&amp;= \mbox{MC Error}\end{align}\]</span> TD(1) is roughly equivalent to every-visit Monte-Carlo, error is accumulated online, step-by-step.</p><p>If value function is only updated offline at end of episode, then total update is exactly the same as MC.</p><p><strong>Forward and Backward Equivalence</strong></p><p>For general <span class="math inline">\(\lambda\)</span>, TD errors also telescope to <span class="math inline">\(\lambda\)</span>-error, <span class="math inline">\(G_t^\lambda-V(S_t)\)</span></p><p><img src="/images/teltdlam.png"></p><p>Consider an episode where <span class="math inline">\(s\)</span> is visited once at time-step <span class="math inline">\(k\)</span>, TD(<span class="math inline">\(\lambda\)</span>) eligibility trace discounts time since visit, <span class="math display">\[E_t(s) = \gamma\lambda E_{t-1}(s)+1(S_t = s) = \begin{cases} 0,  &amp; \mbox{if }t&lt;k \\(\gamma\lambda)^{t-k}, &amp; \mbox{if }tâ‰¥k\end{cases}\]</span> Backward TD(<span class="math inline">\(\lambda\)</span>) updates accumulate error <em>online</em> <span class="math display">\[\sum^{T-1}_{t=1}\alpha\delta_tE_t(s)=\alpha\sum^{T-1}_{t=k}(\gamma\lambda)^{t-k}\delta_t = \alpha(G_k^\lambda-V(S_k))\]</span> By end of episode it accumulates total error for <span class="math inline">\(\lambda\)</span>-return.</p><p>For multiple visits to <span class="math inline">\(s\)</span>, <span class="math inline">\(E_t(s)\)</span> accumulates many errors.</p><p><strong>Offline</strong> Updates</p><ul><li>Updates are accumulated within episode but applied in batch at the end of episode</li></ul><p><strong>Online</strong> Updates</p><ul><li>TD(<span class="math inline">\(\lambda\)</span>) updates are applied online at each step within episode, forward and backward view TD(<span class="math inline">\(\lambda\)</span>) are slightly different.</li></ul><p>In summary,</p><p><img src="/images/tdsum.png"></p><ul><li>Forward view provides <strong>theory</strong></li><li>Backward view provids <strong>mechanism</strong><ul><li>update online, every step, from incomplete sequences</li></ul></li></ul><p>This lecture just talks about how to evaluate a policy given an unknown MDP. Next lecture will introduce Model-free Control.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> Model-Free </tag>
            
            <tag> Monte-Carlo Learning </tag>
            
            <tag> TD </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Planning by Dynamic Programming</title>
      <link href="/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/"/>
      <url>/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#introduction">Introduction</a></li><li><a href="#policy-evaluation">Policy Evaluation</a></li><li><a href="#policy-iteration">Policy Iteration</a></li><li><a href="#value-iteration">Value Iteration</a></li><li><a href="#extentions-to-dynamic-programming">Extentions to Dynamic Programming</a></li><li><a href="#contraction-mapping">Contraction Mapping</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="introduction">Introduction</span></h2><p><strong>What is Dynamic Programming?</strong></p><p><strong>Dynamic</strong>: sequential or temporal component to the problem <strong>Programming</strong>: optimising a &quot;program&quot;, i.e. a policy</p><ul><li>c.f. linear programming</li></ul><p>So, Dynamic Programming is a method for solving complex problems by breaking them down into <strong>subproblems</strong>.</p><ul><li>Solve the subproblems</li><li>Combine solutions to subproblems</li></ul><p>Dynamic Programming is a very general solution method for problems which have two properties:</p><ul><li><strong>Optimal substructure</strong><ul><li><em>Principle of optimality applies</em></li><li>Optimal solution can be decomposed into subproblems</li></ul></li><li><strong>Overlapping subproblems</strong><ul><li>Subproblems recur many times</li><li>Solution can be cached and reused</li></ul></li></ul><p><strong>Markov decision processes</strong> satisfy both properties:</p><ul><li><strong>Bellman euqtion</strong> gives recursive decomposition</li><li><strong>Value function</strong> stores and reuses solutions</li></ul><p><strong>Planning by Dynamic Programming</strong></p><p><strong>Planning</strong> means dynamic programming assumes full knowledge of the MDP.</p><ul><li>For prediction (Policy Evaluation):<ul><li>Input: MDP<span class="math inline">\(&lt;S,A,P,R,\gamma&gt;\)</span> and policy <span class="math inline">\(\pi\)</span></li><li>Output: value function <span class="math inline">\(v_{\pi}\)</span></li></ul></li><li>For <strong>control</strong>:<ul><li>Input: MDP<span class="math inline">\(&lt;S,A,P,R,\gamma&gt;\)</span></li><li>Output: optimal value function <span class="math inline">\(v_*\)</span> and optimal policy <span class="math inline">\(\pi_*\)</span></li></ul></li></ul><p>We first learn how to evaluate a policy and then put it into a loop to find the optimal policy.</p><h2><span id="policy-evaluation">Policy Evaluation</span></h2><ul><li><p>Problem: evaluate a given policy <span class="math inline">\(\pi\)</span></p></li><li><p>Solution: iterative application of <strong>Bellman expectation equation</strong></p></li><li><p><span class="math inline">\(v_1\)</span> -&gt; <span class="math inline">\(v_2\)</span> -&gt; <span class="math inline">\(v_3\)</span> -&gt; â€¦ -&gt; <span class="math inline">\(v_\pi\)</span></p></li><li><p><em>Synchronous</em> backups</p><ul><li><p>At each iteration <span class="math inline">\(k+1\)</span></p></li><li><p>For all states <span class="math inline">\(s \in S\)</span></p></li><li><p>Update <span class="math inline">\(v_{k+1}(s)\)</span> from <span class="math inline">\(v_k(s&#39;)\)</span>, where <span class="math inline">\(s&#39;\)</span> is a successor state of <span class="math inline">\(s\)</span></p><p><img src="/images/vpi2.png"> <span class="math display">\[v_{k+1}(s)=\sum_{a\in\mathcal{A}}\pi(a|s)(\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}v_k(s&#39;))\]</span></p><p><span class="math display">\[v^{k+1}=\mathcal{R}^\pi+\gamma \mathcal{P}^\pi v^k\]</span></p></li></ul></li></ul><p><em>Example</em>: Evaluating a Random Policy in the Small Gridworld</p><p><img src="/images/grid.png"></p><ul><li><p>Actions are move North/East/South/West for one grid.</p></li><li><p>Undiscounted episodic MDP (<span class="math inline">\(\gamma = 1\)</span>)</p></li><li><p>Nontermial states <span class="math inline">\(1, â€¦, 14\)</span></p></li><li><p>One terminal State (shown twice as shaded squares)</p></li><li><p>Reward is <span class="math inline">\(-1\)</span> until the terminal state is reahed</p></li><li><p>Agent follows uniform random policy <span class="math display">\[\pi(n|\cdot)=\pi(e|\cdot)=\pi(s|\cdot)=\pi(w|\cdot) = 0.25\]</span></p></li></ul><p>Let's use dynamic programming to solve the MDP.</p><p><img src="/images/ipe1.png"></p><p><img src="/images/ipe2.png"></p><p>The grids on the left show the value function of each state, the update rule shown by the illustration. Finally, it converges to the true value function of the policy. It basically tell us <em>if we take the random walk under the policy, how much reward on average we will get when we reach the terminal state</em>.</p><p>The right-hand column shows how to find better policy with respect to the value funtions.</p><h2><span id="policy-iteration">Policy Iteration</span></h2><p>How to improve a Policy</p><ul><li><p>Given a policy <span class="math inline">\(\pi\)</span></p><ul><li><p><strong>Evaluate</strong> the policy <span class="math inline">\(\pi\)</span> <span class="math display">\[v_\pi(s) = E[R_{t+1}+\gamma R_{t+2} + ... | S_t = s]\]</span></p></li><li><p><strong>Improve</strong> the policy by acting <em>greedily</em> with respect to <span class="math inline">\(v_\pi\)</span> <span class="math display">\[\pi&#39;=greddy(v_\pi)\]</span></p></li></ul></li><li><p>In general, need more iterations of improvement / evaluation</p></li><li><p>But this process of <em>policy iteration</em> always converges to <span class="math inline">\(\pi_*\)</span></p></li></ul><p><img src="/images/pi.png"></p><p><strong>Demonstration</strong></p><p>Consider a deterministic policy <span class="math inline">\(a = \pi(s)\)</span>, we can improve the policy by acting greedily <span class="math display">\[\pi&#39;(s) = \arg\max_{a\in\mathcal{A}}q_\pi(s, a)\]</span> (Note: <span class="math inline">\(q_\pi\)</span> is the action value function following policy <span class="math inline">\(\pi\)</span>)</p><p>This improves the value from any state <span class="math inline">\(s\)</span> over one step, <span class="math display">\[q_\pi(s, \pi&#39;(s)) = \max_{a\in\mathcal{A}}q_\pi(s,a)â‰¥q_\pi(s, \pi(s))=v_\pi(s)\]</span> (Note: <span class="math inline">\(q_\pi(s, \pi&#39;(s))\)</span> means the action value of taking one step following policy <span class="math inline">\(\pi&#39;\)</span> then following policy <span class="math inline">\(\pi\)</span> forever.)</p><p>If therefore improves the value function, <span class="math inline">\(v_{\pi&#39;}(s) â‰¥ v_\pi (s)\)</span> <span class="math display">\[\begin{align}v_\pi(s) &amp; â‰¤ q_\pi(s, \pi&#39;(s))=E_{\pi&#39;}[R_{t+1}+\gamma v_\pi(S_{t+1})|S_t = s]  \\&amp; â‰¤ E_{\pi&#39;}[R_{t+1} + \gamma q_\pi(S_{t+1}, \pi&#39;(S_{t+1}))|S_t=s] \\&amp;â‰¤ E_{\pi&#39;}[R_{t+1} + \gamma R_{t+2} + \gamma^2q_\pi(S_{t+2}, \pi&#39;(S_{t+2}))|S_t = s]\\&amp;â‰¤ E_{\pi&#39;}[R_{t+1} + \gamma R_{t+2} + ..... | S_t = s] = v_{\pi&#39;}(s)\end{align}\]</span> (Unroll the equation to the second, third â€¦ step by taking the Bellman euqation into it.)</p><p>If improvements stop, <span class="math display">\[q_\pi(s, \pi&#39;(s)) = \max_{a\in\mathcal{A}}q_\pi(s,a) = q_\pi(s, \pi(s)) = v_\pi(s)\]</span> Then the <strong>Bellman optimality</strong> equation has been satisfied <span class="math display">\[v_\pi(s) = \max_{a\in\mathcal{A}}q_\pi(s, a)\]</span> Therefore <span class="math inline">\(v_\pi(s) = v_*(s)\)</span> for all <span class="math inline">\(s \in \mathcal{S}\)</span>, so <span class="math inline">\(\pi\)</span> is an optimal policy.</p><p><strong>Early Stopping</strong></p><p>Question: Does policy evaluation need to converge to <span class="math inline">\(v_\pi\)</span> ?</p><ul><li>e.g. in the small gridworld <span class="math inline">\(k = 3\)</span> was sufficient to acheive optimal policy</li></ul><p>Or shoule we introduce a stopping condition</p><ul><li>e.g. <span class="math inline">\(\epsilon\)</span>-convergence of value function</li></ul><p>Or simply stop after <span class="math inline">\(k\)</span> iterations of iterative policy evaluation?</p><h2><span id="value-iteration">Value Iteration</span></h2><p><strong>Principle of Optimality</strong></p><p>Any optimal policy can be subdivided into two components:</p><ul><li>An optimal first action <span class="math inline">\(A_*\)</span></li><li>Followed by an optimal policy from successor state <span class="math inline">\(S&#39;\)</span></li></ul><blockquote><p>Theorem: Principle of Optimality</p><p>A policy <span class="math inline">\(\pi(a|s)\)</span> achieves the optimal value from state <span class="math inline">\(s\)</span>, <span class="math inline">\(v_\pi(s) = v_*(s)\)</span> if and only if</p><ul><li>For any state <span class="math inline">\(s&#39;\)</span> reachable from <span class="math inline">\(s\)</span>, <span class="math inline">\(\pi\)</span> achieves the optimal value from state <span class="math inline">\(s&#39;\)</span></li></ul></blockquote><p>If we know the solution to subproblems <span class="math inline">\(v_\ast(s&#39;)\)</span>, then solution <span class="math inline">\(v_\ast(s)\)</span> can be found by one-step look ahead: <span class="math display">\[v_\ast(s) \leftarrow \max_{a\in\mathcal{A}}\mathcal{R}^a_s+\gamma \sum_{s&#39;\in \mathcal{S}}P^a_{ss&#39;}v_\ast(s&#39;)\]</span> The idea of value iteration is to apply these updates iteratively.</p><ul><li>Intuition: start with final rewards and work backwards</li><li>Still works with loopy, stochatis MDPs</li></ul><p><strong>Example: Shortest Path</strong></p><p><img src="/images/grid2.png"></p><ul><li>The goal state is on the left-up corner</li><li>Each step get -1 reward</li><li>The number showed in each grid is the value of that state</li><li>At each iteration, update all states</li></ul><p><strong>Value Iteration</strong></p><ul><li>Problem: find optimal policy <span class="math inline">\(\pi\)</span></li><li>Solution: iterative application of Bellman optimality backup</li><li><span class="math inline">\(v_1 \rightarrow v_2 \rightarrow â€¦ \rightarrow v_*\)</span></li><li><em>Synchronous</em> backups<ul><li>At each iteration <span class="math inline">\(k+1\)</span></li><li>For all states <span class="math inline">\(s\in \mathcal{S}\)</span></li><li>Update <span class="math inline">\(v_{k+1}(s)\)</span> from <span class="math inline">\(v_k(s&#39;)\)</span></li></ul></li><li>Convergence to <span class="math inline">\(v_*\)</span> will be proven later</li><li>Unlike policy iteration, there is no explicit policy</li><li>Intermediate value functions may not correspond to any policy</li></ul><p><strong>Synchronous Dynamic Programming Algorithms</strong></p><table><colgroup><col style="width: 12%"><col style="width: 51%"><col style="width: 35%"></colgroup><thead><tr class="header"><th>problem</th><th>bellman equation</th><th>algorithm</th></tr></thead><tbody><tr class="odd"><td>Prediction</td><td>Bellman Expectation Equation</td><td>Iterative Policy Evaluation</td></tr><tr class="even"><td>Control</td><td>Bellman Expectation Equation + Greedy Policy Improvement</td><td>Policy Iteration</td></tr><tr class="odd"><td>Control</td><td>Bellman Optimatility Equation</td><td>Value Iteration</td></tr></tbody></table><p>Algorithms are based on state-value function <span class="math inline">\(v_\pi(s)\)</span> or <span class="math inline">\(v_*(s)\)</span></p><ul><li><span class="math inline">\(O(mn^2)\)</span> per iteration, for <span class="math inline">\(m\)</span> actions and <span class="math inline">\(n\)</span> states</li></ul><p>Could also apply to action-value function <span class="math inline">\(q_\pi(s, a)\)</span> or <span class="math inline">\(q_*(s, a)\)</span></p><ul><li><span class="math inline">\(O(m^2n^2)\)</span> per iteration</li></ul><h2><span id="extentions-to-dynamic-programming">Extentions to Dynamic Programming</span></h2><p><strong>Asynchronous Dynamic Programming</strong></p><p><em>Asynchronous DP</em> backs up states individually, in any order. For each selected state, apply the appropriate backup, which can significantly reduce computation. It also guaranteed to converge if all states continue to be selected.</p><p>Three simple ideas for asynchronous dynamic programming:</p><ul><li><p><em>In-place</em> dynamic programming</p><p><img src="/images/in-place.png"></p></li><li><p><em>Prioritised sweeping</em></p><p><img src="/images/ps.png"></p></li><li><p><em>Real-time</em> dynamic programming</p><p><img src="/images/real-time.png"></p></li></ul><p><strong>Full-Width Backups</strong></p><p>DP uses <em>full-width</em> backups</p><ul><li><em>full-width</em> means when we look aheah, we consider all branches(actions) that could happen</li><li>For each backup (sync or async)<ul><li>Every successor state and action is considered</li><li>Using knowledge of the MDP transitions and reward function</li></ul></li></ul><p><img src="/images/fw.png"></p><h2><span id="contraction-mapping">Contraction Mapping</span></h2><p>Information about <em>contraction mapping theorem</em>, please refer to http://www.math.uconn.edu/~kconrad/blurbs/analysis/contraction.pdf</p><p>Consider the vector space <span class="math inline">\(\mathcal{V}\)</span> over value functions. There are <span class="math inline">\(|\mathcal{S}|\)</span> dimensions.</p><ul><li>Each point in this space fully specifies a value function <span class="math inline">\(v(s)\)</span></li></ul><p>We will measure distance between state-value functions <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> by the <span class="math inline">\(\infty\)</span>-norm. <span class="math display">\[||u-v||_\infty = \max_{s\in\mathcal{S}}|u(s)-v(s)|\]</span> <em>Bellman Expectation Backup is a Contraction</em></p><p>Define the <em>Bellman expectation backup operator</em> <span class="math inline">\(T^\pi\)</span>, <span class="math display">\[T^\pi(v) = \mathcal{R}^\pi + \gamma\mathcal{P}^\pi v\]</span> This operator is a <span class="math inline">\(\gamma\)</span>-contraction, it makes value functions closer bt at least <span class="math inline">\(\gamma\)</span>, <span class="math display">\[\begin{align}||T^\pi(u)-T^\pi(v)||_\infty &amp;= ||(\mathcal{R}^\pi + \gamma\mathcal{P}^\pi v) - (\mathcal{R}^\pi + \gamma\mathcal{P}^\pi u)||_\infty \\&amp;= ||\gamma P^\pi(u-v)||_\infty\\&amp;â‰¤||\gamma P^\pi||u-v||_\infty||_\infty\\&amp;â‰¤\gamma||u-v||_\infty\end{align}\]</span></p><blockquote><p>Theorem: <strong>Contraction Mapping Theorem</strong></p><p>For any metric space <span class="math inline">\(\mathcal{V}\)</span> that is complete (closed) under an operator <span class="math inline">\(T(v)\)</span>, where <span class="math inline">\(T\)</span> is a <span class="math inline">\(\gamma\)</span>-contraction,</p><ul><li><span class="math inline">\(T\)</span> converges to a unique fixed point</li><li>At a linear convergence rate of <span class="math inline">\(\gamma\)</span></li></ul></blockquote><p><strong>Convergence of Iterative Policy Evaluation and Policy Iteration</strong></p><p>The Bellman expectation operator <span class="math inline">\(T^\pi\)</span> has a unique fixed point <span class="math inline">\(v_\pi\)</span>.</p><p>By contraction mapping theorem,</p><ul><li>Iterative policy evaluation converges on <span class="math inline">\(v_\pi\)</span>;</li><li>Policy iteration converges on <span class="math inline">\(v_*\)</span>.</li></ul><p><em>Bellman Optimality Backup is a Contraction</em></p><p>Define the <em>Bellman Optimality backup operator</em> <span class="math inline">\(T^\ast\)</span>, <span class="math display">\[T^\ast(v) = \max_{a\in\mathcal{A}}\mathcal{R}^a+\gamma \mathcal{P}^av\]</span> This operator is a <span class="math inline">\(\gamma\)</span>-contraction, it makes value functions closer by at least <span class="math inline">\(\gamma\)</span>, <span class="math display">\[||T^\ast(u)-T\ast(v)||_\inftyâ‰¤\gamma ||u-v||_\infty\]</span> <strong>Convergence of Value Iteration</strong></p><p>The Bellman optimality operator <span class="math inline">\(T^âˆ—\)</span> has a unique fixed point <span class="math inline">\(v_*\)</span>.</p><p>By contraction mapping theorem, value iteration converges on <span class="math inline">\(v_*\)</span>.</p><p>In summary, what does a Bellman backup do to points in value function space is to bring value functions <em>closer</em> to a unique fixed point. And therefore the backups must converge on a unique solution.</p><p>This lecture (note) introduces how to use dynamic programming to solve <em>planning</em> problems. Next lecture will introduce model-free prediction, which is a really RL problem.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> MDP </tag>
            
            <tag> Dynamic Programming </tag>
            
            <tag> Policy Iteration </tag>
            
            <tag> Value Iteration </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Markov Decision Processes</title>
      <link href="/2017/08/18/RL%20-%20Markov%20Decision%20Processes/"/>
      <url>/2017/08/18/RL%20-%20Markov%20Decision%20Processes/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#markov-processes">Markov Processes</a></li><li><a href="#markov-reward-process">Markov Reward Process</a></li><li><a href="#markov-decision-process">Markov Decision Process</a></li></ul><!-- tocstop --><h2><span id="markov-processes">Markov Processes</span></h2><p>Basically, <strong>Markov decision processes</strong> formally describe an environment for reinforcement learning, where the environment is <strong>fully observable</strong>, which means the current state completely characterises the process.</p><a id="more"></a><p>Almost all RL problems can be formalised as MDPs, e.g.</p><ul><li>Optimal control primarily deals with continuous MDPs</li><li>Partially observable problems can be converted into MDPs</li><li>Bandits are MDPs with one state</li></ul><p>So, if we solve MDP, we can solve all above RL problems.</p><p><strong>Markov Property</strong></p><p>Markov Property is &quot;The future is independent of the past given the present&quot;, like <a href="https://www.52coding.com.cn/index.php?/Articles/single/69">last note</a> said. The formal definition is: <span class="math display">\[P[S_{t+1}|S_t]=P[S_{t+1}|S_1, ..., S_t]\]</span> where <span class="math inline">\(S\)</span> represents a state.</p><p>The formula means the current can capture all relevant information from the history. Once the state is known, the history may be thrown away, i.e. the state is a sufficient statistic of the future.</p><p><strong>State Transition Matrix</strong></p><p>We know that given the current state, we can use its information to reach the next state, but how? â€” It is characterized by the <em>state transition probability</em>.</p><p>For a Markov state <span class="math inline">\(s\)</span> and successor state <span class="math inline">\(s&#39;\)</span> , the state transition probability is deï¬ned by <span class="math display">\[P_{ss&#39;}=P[S_{t+1}=s&#39;|S_t=s]\]</span> We can put all of the probabities into a matrix called transition matrix, denoted by <span class="math inline">\(P\)</span> : <span class="math display">\[P = \begin{bmatrix}P_{11}     &amp; \cdots &amp; P_{1n}      \\\vdots &amp; \ddots &amp; \vdots \\P_{n1}     &amp; \cdots &amp; P_{nn}\end{bmatrix}\]</span> where each row of the matrix sums to 1.</p><p><strong>Markov Process</strong></p><p>Formally, a Markov process is a <strong>memoryless</strong> random process, i.e. a sequence of random states <span class="math inline">\(S_1, S_2, â€¦\)</span> with the <strong>Markov property</strong>.</p><blockquote><p>Definition</p><p><strong>A Markov Process (or Markov Chain) is tuple</strong> <span class="math inline">\(&lt;S, P&gt;\)</span></p><ul><li><strong><span class="math inline">\(S\)</span> is a (finite) set of states</strong></li><li><strong><span class="math inline">\(P\)</span> is a state transition probability matrix, <span class="math inline">\(P_{ss&#39;} = P[S_{t+1}=s&#39;|S_t=s]\)</span></strong></li></ul></blockquote><p><em>Example</em></p><p><img src="/images/markov.png"></p><p>The above figure show a markov chains of a student's life. Process starts from <em>Class 1</em>, taking class 1 may be boring, so he have either 50% probability to look <em>Facebook</em> or to move to <em>Class 2</em>. â€¦. And finally, he reach the final state <em>Sleep</em>. It's a final state just because it is a self-loop with probability 1 which is nothing special.</p><p>We can sample sequences from such process. Sample <strong>episodes</strong> for Student Markov Chain starting from <span class="math inline">\(S_1 = C_1\)</span>: <span class="math display">\[S_1, S_2, ..., S_T\]</span></p><ul><li>C1 C2 C3 Pass Sleep</li><li>C1 FB FB C1 C2 Sleep</li><li>C1 C2 C3 Pub C2 C3 Pass Sleep</li><li>C1 FB FB C1 C2 C3 Pub C1 FB FB FB C1 C2 C3 Pub C2 Sleep</li></ul><p>Also, we can make the transition matrix from such markov chain:</p><p><img src="/images/trans_mat.png"></p><p>If we have this matrix, we can fully describe the Markov process.</p><h2><span id="markov-reward-process">Markov Reward Process</span></h2><p>So far, we have never talked about Reinforcement Learning, there is no reward at all. So, let's talk about the <em>Markov Reward Process</em>.</p><p>The most important is adding reward to Markov process, so a Markov reward process is a Markov chain with values.</p><blockquote><p>Definition</p><p>A Markov Reward Process is tuple <span class="math inline">\(&lt;S, P, R, \gamma&gt;\)</span></p><ul><li><span class="math inline">\(S\)</span> is a (finite) set of states</li><li><span class="math inline">\(P\)</span> is a state transition probability matrix, <span class="math inline">\(P_{ss&#39;} = P[S_{t+1}=s&#39;|S_t=s]\)</span></li><li><strong><span class="math inline">\(R\)</span> is a reward function, <span class="math inline">\(R_s=E[R_{t+1}|S_t=s]\)</span></strong></li><li><strong><span class="math inline">\(\gamma\)</span> is a discount factor, <span class="math inline">\(\gamma \in [0, 1]\)</span></strong></li></ul></blockquote><p>Note that <span class="math inline">\(R\)</span> is the <strong>immediate reward</strong>, it characterize the reward you will get if you currently stay on state <span class="math inline">\(s\)</span>.</p><p><em>Example</em></p><p>Let's back to the student example:</p><p><img src="/images/mrp.png"></p><p>At each state, we have corresponding reward represents the goodness/badness of that state.</p><p><strong>Return</strong></p><p>We don't actually care about the immediate reward, we care about the whole random sequence's total reward. So we define the term <em>return</em>:</p><blockquote><p>Definition</p><p><strong>The return <span class="math inline">\(G_t\)</span> is the total dicounted reward from time-step <span class="math inline">\(t\)</span>.</strong> <span class="math display">\[G_t=R_{t+1}+\gamma R_{t+2}+...=\sum_{k=0}^\infty \gamma^kR_{t+k+1}\]</span></p></blockquote><p>The discount <span class="math inline">\(\gamma \in [0,1]\)</span> is the present value of future rewards. So the value of receiving reward <span class="math inline">\(R\)</span> after <span class="math inline">\(k+1\)</span> time-steps is <span class="math inline">\(\gamma^k R\)</span>.</p><p><strong>Note</strong>: <span class="math inline">\(R_{t+1}\)</span> is the immediate reward of state <span class="math inline">\(S_t\)</span>.</p><p>This values <strong>immediate reward</strong> above <strong>delayed reward</strong>:</p><ul><li><span class="math inline">\(\gamma\)</span> closes to <span class="math inline">\(0\)</span> leads to &quot;myopic&quot; evaluation</li><li><span class="math inline">\(\gamma\)</span> closes to <span class="math inline">\(1\)</span> leads to &quot;far-sighted&quot; evaluation</li></ul><p>Most Markov reward and decision processes are discounted. <strong>Why?</strong></p><ul><li><strong>Mathematically convenient</strong> to discount rewards</li><li><strong>Avoids inï¬nite returns</strong> in cyclic Markov processes</li><li><strong>Uncertainty</strong> about the future may not be fully represented</li><li>If the reward is ï¬nancial, immediate rewards may earn more interest than delayed rewards</li><li><strong>Animal/human behaviour</strong> shows preference for immediate reward</li><li>It is sometimes possible to use undiscounted Markov reward processes (i.e. Î³ = 1), e.g. if all sequences terminate.</li></ul><p><strong>Value Function</strong></p><p>The value function <span class="math inline">\(v(s)\)</span> gives the long-term value of state <span class="math inline">\(s\)</span>.</p><blockquote><p>Definition</p><p><strong>The state value funtion <span class="math inline">\(v(s)\)</span> of an MRP is the expected return starting from state <span class="math inline">\(s\)</span></strong> <span class="math display">\[v(s) = E[G_t|S_t=s]\]</span></p></blockquote><p>We use expectation because it is a random process, we want to figure out the expected value of a state, not such a sequence sampled starts it.</p><p><em>Example</em></p><p>Sample <strong>returns</strong> from Student MRP, starting from <span class="math inline">\(S_1 = C1\)</span> with <span class="math inline">\(\gamma = \frac{1}{2}\)</span>: <span class="math display">\[G_1=R_2+\gamma R_3+...+\gamma^{T-2}R_T\]</span> <img src="/images/samret.png"></p><p>The <em>return</em> is random, but the <em>value function</em> is not random, rather, it is expectation of all samples' return.</p><p>Let's see the example of state <em>value function</em>:</p><p><img src="/images/svf.png"></p><p>When <span class="math inline">\(\gamma = 0\)</span>, the value function just consider the reward of current state no matter how it changes future.</p><p><img src="/images/gamma0.9.png"></p><p><img src="/images/gamma1.png"></p><p><strong>Bellman Equation for MRPs</strong></p><p>The value function can be decomposed into two parts:</p><ul><li>immediate reward <span class="math inline">\(R_{t+1}\)</span></li><li>discounted value of successor state <span class="math inline">\(\gamma v(S_{t+1})\)</span></li></ul><p>So as to we can apply dynamic programming to solve the value function.</p><p>Here is the demonstration: <span class="math display">\[\begin{align}v(s) &amp; = \mathbb{E}[G_t|S_t=s] \\&amp; = \mathbb{E}[R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+...|S_t=s] \\&amp;= \mathbb{E}[R_{t+1}+\gamma(R_{t+2}+\gamma R_{t+3}+...)|S_t=s]\\&amp;= \mathbb{E}[R_{t+1}+\gamma G_{t+1}|S_t=s]\\&amp;= \mathbb{E}[R_{t+1}+\gamma v(S_{t+1})|S_t=s]\end{align}\]</span> Here we get: <span class="math display">\[v(s) =\mathbb{E}[R_{t+1}+\gamma v(S_{t+1})|S_t=s]=R_{t+1}+\gamma\mathbb{E}[ v(S_{t+1})|S_t=s]\]</span> We look ahead one-step, and averaging all value function of next possible state:</p><p><img src="/images/bf2.png"> <span class="math display">\[v(s) = R_s+\gamma\sum_{s&#39;\in S}P_{ss&#39;}v(s&#39;)\]</span> We can use the Bellman equation to vertify a MRP:</p><p><img src="/images/verMRP.png"></p><p><em>Bellman Equation in Matrix Form</em></p><p>The Bellman equation can be expressed concisely using matrices, <span class="math display">\[v = R + \gamma Pv\]</span> where <span class="math inline">\(v\)</span> is a column vector with one entry per state: <span class="math display">\[\begin{bmatrix}v(1)         \\\vdots  \\v(n)    \end{bmatrix}=\begin{bmatrix}R_1         \\\vdots  \\R_n   \end{bmatrix}+\gamma \begin{bmatrix}P_{11}     &amp; \cdots &amp; P_{1n}      \\\vdots &amp; \ddots &amp; \vdots \\P_{n1}     &amp; \cdots &amp; P_{nn}\end{bmatrix}\begin{bmatrix}v(1)         \\\vdots  \\v(n)    \end{bmatrix}\]</span> Because the Bellman equation is a linear equation, it can be solved directly: <span class="math display">\[\begin{align}v &amp; = R+\gamma Pv \\(I-\gamma P)v&amp; =R \\v &amp;= (I-\gamma P)^{-1}R\end{align}\]</span> However, the Computational complexity is <span class="math inline">\(O(n^3)\)</span> for <span class="math inline">\(n\)</span> states, because of the inverse operation. This method can be applied to solve small MRPs.</p><p>There are many iterative methods for large MRPs, e.g.</p><ul><li>Dynamic programming</li><li>Monte-Carlo evaluation</li><li>Temporal-Diï¬€erence learning</li></ul><p>So far with MRP, all we want to do is to make decisions, so let's move on <em>Markov Decision Process</em>, which we actually using in RL.</p><h2><span id="markov-decision-process">Markov Decision Process</span></h2><p>A <strong>Markov decision process (MDP)</strong> is a Markov reward process with decisions. It is an <em>environment</em> in which all states are Markov.</p><blockquote><p>Definition</p><p><strong>A Markov Decision Process is a tuple</strong> <span class="math inline">\(&lt;S, A,P,R,\gamma&gt;\)</span></p><ul><li><span class="math inline">\(S\)</span> is a finite set of states</li><li><span class="math inline">\(A\)</span> <strong>is a finite set of actions</strong></li><li><span class="math inline">\(P\)</span> is a state transition probability matrix, <span class="math inline">\(P^a_{ss&#39;}=\mathbb{P}[S_{t+1}=s&#39;|S_t=s, A_t=a]\)</span></li><li><span class="math inline">\(R\)</span> is a reward function, <span class="math inline">\(R^a_s=\mathbb{E}[R_{t+1}|S_t=s,A_t=t]\)</span></li><li><span class="math inline">\(\gamma\)</span> is a discount factor <span class="math inline">\(\gamma \in[0,1]\)</span></li></ul></blockquote><p><em>Example</em></p><p><img src="/images/mdpstu.png"></p><p>Red marks represents the actions or decisions, what we want to do is to find the best path that maximize the value function.</p><p><strong>Policy</strong></p><p>Formally, the decision can be defined as <em>policy</em>:</p><blockquote><p>Definition</p><p><strong>A policy Ï€ is a distribution over actions given states,</strong> <span class="math display">\[\pi(a|s)=\mathbb{P}[A_t=a|S_t=s]\]</span></p></blockquote><p>A policy fully deï¬nes the behaviour of an agent.</p><p>Note that MDP policies depend on the current state (not the history), i.e. policies are stationary (time-independent), <span class="math inline">\(A_t~\pi(\cdot|S_t), \forall t&gt;0\)</span>.</p><p>An MDP can transform into a Markov process or an MRP:</p><ul><li><p>Given an MDP <span class="math inline">\(\mathcal{M}=&lt;\mathcal{S,A,P,R}, \gamma&gt;\)</span> and a policy <span class="math inline">\(\pi\)</span></p></li><li><p>The state sequence <span class="math inline">\(&lt;S_1 , S_2 , ... &gt;\)</span> is a Markov process <span class="math inline">\(&lt;\mathcal{S, P}^Ï€&gt;\)</span></p></li><li><p>The state and reward sequence <span class="math inline">\(&lt;S_1 , R_2 , S_2 , â€¦&gt;\)</span> is a Markov reward process <span class="math inline">\(&lt;\mathcal{S,P}^\pi,\mathcal{R}^\pi,\gamma&gt;\)</span> where, <span class="math display">\[\mathcal{P}^\pi_{s,s&#39;}=\sum_{a\in\mathcal{A}}\pi(a|s)P^a_{ss&#39;}\]</span></p><p><span class="math display">\[\mathcal{R}^\pi_s=\sum_{a\in\mathcal{A}}\pi(a|s)\mathcal{R}^a_s\]</span></p></li></ul><p><strong>Value Function</strong></p><p>There are two value functions: the first one is called <em>state-value function</em> which represents the expected return following policy <span class="math inline">\(\pi\)</span>, the other is called <em>action-value function</em> which measures the goodness/badness of an action following policy <span class="math inline">\(\pi\)</span>.</p><blockquote><p>Definition</p><p>The <strong>state-value function</strong> <span class="math inline">\(v_Ï€ (s)\)</span> of an MDP is the expected return starting from state <span class="math inline">\(s\)</span>, and then following policy Ï€ <span class="math display">\[v_\pi(s)=\mathbb{E}_\pi[G_t|S_t=s]\]</span></p></blockquote><blockquote><p>Definition</p><p>The <strong>action-value function</strong> <span class="math inline">\(q_Ï€ (s, a)\)</span> is the expected return starting from state <span class="math inline">\(s\)</span>, taking action <span class="math inline">\(a\)</span>, and then following policy <span class="math inline">\(Ï€\)</span> <span class="math display">\[q_\pi(s,a)=\mathbb{E}_\pi[G_t|S_t=s,A_t=a]\]</span></p></blockquote><p><em>Example</em></p><p><img src="/images/svformdp.png"></p><p><strong>Bellman Expectation Equation</strong></p><p>The <strong>state-value function</strong> can again be decomposed into immediate reward plus discounted value of successor state, <span class="math display">\[v_\pi(s)=\mathbb{E}_\pi[R_{t+1}+\gamma v_\pi(S_{t+1})|S_t=s]\]</span> The <strong>action-value function</strong> can similarly be decomposed, <span class="math display">\[q_\pi(s,a)=\mathbb{E}_\pi[R_{t+1}+\gamma q_\pi (S_{t+1},A_{t+1})|S_t=s,A_t=a]\]</span> <em>Bellman Expectation Equation for <span class="math inline">\(V_Ï€\)</span></em></p><p><img src="/images/vpi.png"> <span class="math display">\[v_\pi(s)=\sum_{a\in\mathcal{A}}\pi(a|s)q_\pi(s,a)\]</span> The look-ahead approach is taking an action and computing its reward, all we need to do is to averaging all possible actions' rewards, which is equal to current state-value.</p><p><em>Bellman Expectation Equation for <span class="math inline">\(Q_Ï€\)</span></em></p><p><img src="/images/qpi.png"> <span class="math display">\[q_\pi(s,a)=\mathcal{R}_s^a + \gamma \sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}v_\pi(s&#39;)\]</span> It is identical to the immediate reward of taking action <span class="math inline">\(a\)</span> plus the average of the reward/value of all possible states which the action could lead to.</p><p><em>Bellman Expectation Equation for <span class="math inline">\(V_Ï€\)</span></em></p><p><img src="/images/vpi2.png"> <span class="math display">\[v_\pi(s)=\sum_{a\in\mathcal{A}}\pi(a|s)(\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}v_\pi(s&#39;))\]</span> This is a two-step look-ahead approach, just combining the last two equations.</p><p><img src="/images/qpi2.png"> <span class="math display">\[q_\pi(s,a)=\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}\sum_{a&#39;\in\mathcal{A}}\pi(a&#39;|s&#39;)q_\pi(s&#39;,a&#39;)\]</span> <em>Example</em>: State-value function</p><p><img src="/images/qgbee.png"></p><p><em>Bellman Expectation Equation (Matrix Form)</em></p><p>The Bellman expectation equation can be expressed concisely using the induced MRP, <span class="math display">\[v_\pi=R^\pi+\gamma P^\pi v_\pi\]</span> with direct solution <span class="math display">\[v_\pi=(I-\gamma P^{\pi-1})^{-1}R^\pi\]</span> <strong>Optimal Value Function</strong></p><blockquote><p>Definition</p><p><strong>The optimal state-value function <span class="math inline">\(v_âˆ—(s)\)</span> is the maximum value function over all policies</strong> <span class="math display">\[v_\ast(s)=\max_{\pi}v_\pi(s)\]</span> <strong>The optimal action-value function <span class="math inline">\(q_âˆ— (s, a)\)</span> is the maximum action-value function over all policies</strong> <span class="math display">\[q_\ast(s,a)=\max_\pi q_\pi(s,a)\]</span></p></blockquote><p>The optimal value function speciï¬es the best possible performance in the MDP.</p><p>If we know the <span class="math inline">\(q_*(s,a)\)</span>, we &quot;solve&quot; MDP because we know what actions should take at each state to maximize the reward.</p><p><em>Example</em></p><p><img src="/images/egvalue.png"></p><p><img src="/images/egstar.png"></p><p><strong>Optimal Policy</strong></p><p>Deï¬ne a partial ordering over policies <span class="math display">\[\piâ‰¥\pi&#39;\ if\ v_\pi(s)â‰¥v_{\pi&#39;}, \forall s\]</span></p><blockquote><p>Theorem</p><ul><li><strong>There exists an optimal policy <span class="math inline">\(Ï€_âˆ—\)</span> that is better than or equal to all other policies,</strong>, <span class="math inline">\(\pi_* â‰¥ \pi, \forall \pi\)</span></li><li><strong>All optimal policies achieve the optimal value function,</strong> <span class="math inline">\(v_{pi_*}=v_*(s)\)</span></li><li><strong>All optimal policies achieve the optimal action-value function,</strong> <span class="math inline">\(q_{\pi_*}(s,a)=q_*(s,a)\)</span></li></ul></blockquote><p><em>Finding an Optimal Policy</em></p><p>An optimal policy can be found by maximising over <span class="math inline">\(q_âˆ— (s, a)\)</span>,</p><p><span class="math display">\[\pi_\ast(a|s)=\begin{cases}1\ if\ a=\arg\max_{a\in\mathcal{A}}q_\ast(s,a) \\0 \ otherwise\end{cases}\]</span></p><p>There is always a deterministic optimal policy for any MDP. So if we know <span class="math inline">\(q_âˆ— (s, a)\)</span>, we immediately have the optimal policy.</p><p><img src="/images/optpol.png"></p><p>The optimal policy is highlight in red.</p><p><strong>Bellman Optimality Equation</strong></p><p>The optimal value functions are recursively related by the Bellman optimality equations:</p><p><img src="/images/boev.png"></p><p><span class="math display">\[v_\ast(s)=\max_aq_\ast(s,a)\]</span></p><p><img src="/images/boeq.png"></p><p><span class="math display">\[q_\ast(s,a)=\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}\mathcal{P}^a_{ss&#39;}v_\ast(s&#39;)\]</span></p><p><img src="/images/boev2.png"></p><p><span class="math display">\[v_\ast(s)=\max_a\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}\mathcal{P}^a_{ss&#39;}v_\ast(s&#39;)\]</span></p><p><img src="/images/boeq2.png"></p><p><span class="math display">\[q_\ast(s,a)=\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}\max_{a&#39;}q_\ast(s&#39;,s)\]</span></p><p><em>Example</em></p><p><img src="/images/boe_in_stu_mdp.png"></p><p><em>Solving the Bellman Optimality Equation</em></p><p>Bellman Optimality Equation is non-linear, so it is not able to be sovle as solving linear equation. And there is no closed from solution (in general).</p><p>Many <strong>iterative</strong> solution methods</p><ul><li>Value Iteration</li><li>Policy Iteration</li><li>Q-learning</li><li>Sarsa</li></ul><p>End. Next note will introduce how to solve the Bellman Optimality Equation by dynamic programming.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> MDP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Introduction to Reinforcement Learning</title>
      <link href="/2017/08/15/RL%20-%20Introduction%20to%20Reinforcement%20Learning/"/>
      <url>/2017/08/15/RL%20-%20Introduction%20to%20Reinforcement%20Learning/</url>
      
        <content type="html"><![CDATA[<p>RL, especially DRL (Deep Reinforcement Learning) has been an fervent research area during these years. One of the most famous RL work would be AlphaGo, who has beat <a href="https://www.wikiwand.com/en/Lee_Sedol" target="_blank" rel="noopener">Lee Sedol</a>, one of the best players at Go, last year. And in this year (2017), AlphaGo won three games with Ke Jie, the world No.1 ranked player. Not only in Go, AI has defeated best human play in many games, which illustrates the powerful of the combination of Deep Learning and Reinfocement Learning. However, despite AI plays better games than human, AI takes more time, data and energy to train which cannot be said to be very intelligent. Still, there are numerous unexplored and unsolved problems in RL research, that's also why we want to learn RL.</p><p>This is the first note of David Silver's <a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" target="_blank" rel="noopener">RL course</a>.</p><a id="more"></a><!-- toc --><ul><li><a href="#about-reinforcement-learning">About Reinforcement Learning</a></li><li><a href="#the-reinforcement-learning-problem">The Reinforcement Learning Problem</a></li><li><a href="#inside-an-rl-agent">Inside An RL Agent</a></li><li><a href="#problems-within-reinforcement-learning">Problems within Reinforcement Learning</a></li></ul><!-- tocstop --><h2><span id="about-reinforcement-learning">About Reinforcement Learning</span></h2><p>Reinforcement Learning is one of the three major branches of Machine Learning, and is also the intersect of many different disciplines, as the following two figure illustrated.</p><p><img src="/images/branches.png"></p><p><img src="/images/faces.png"></p><p>There are several reasons that makes reinforcement learning different from other machine learning paradigms:</p><ul><li>There is no supervisor, only a <em>reward</em> signal</li><li>Feedback is delayed, not instantaneous</li><li>Time really matters (sequential, non i.i.d data)</li><li>Agent's actions affect the subsequent data it receives</li></ul><p>There are some examples of Reinforcement Learning:</p><ul><li>Fly stunt manoeuvres in a helicopter</li><li>Defeat the world champion at Backgammon</li><li>Manage an investment portfolio</li><li>Control a power station</li><li>Make a humanoid robot walk</li><li>Play many diï¬€erent Atari games better than humans</li></ul><h2><span id="the-reinforcement-learning-problem">The Reinforcement Learning Problem</span></h2><p><strong>Rewards</strong></p><p>We say RL do not have a supervisor, just a <em>reward</em> signal. Then what is <em>reward</em> ?</p><ul><li>A <strong>reward</strong> <span class="math inline">\(R_t\)</span> is a scalar feedback signal</li><li>Indicates how well agent is doing at step <span class="math inline">\(t\)</span></li><li>The agent's job is to maximise cumulative reward</li></ul><p>Reinforcement Learning is based on the <strong>reward hypothesis</strong>, which is</p><blockquote><p>Definition of reward hypothesis</p><p><strong>All goals can be described by the maximisation of expected cumulative reward.</strong></p></blockquote><p>There are some examples of <em>rewards</em> :</p><ul><li>Fly stunt manoeuvres in a helicopter<ul><li>+ve reward for following desired trajectory</li><li>âˆ’ve reward for crashing</li></ul></li><li>Defeat the world champion at Backgammon<ul><li>+/âˆ’ve reward for winning/losing a game</li></ul></li><li>Manage an investment portfolio<ul><li>+ve reward for each $ in bank</li></ul></li><li>Control a power station<ul><li>+ve reward for producing power</li><li>âˆ’ve reward for exceeding safety thresholds</li></ul></li><li>Make a humanoid robot walk<ul><li>+ve reward for forward motion</li><li>âˆ’ve reward for falling over</li></ul></li><li>Play many diï¬€erent Atari games better than humans<ul><li>+/âˆ’ve reward for increasing/decreasing score</li></ul></li></ul><p><strong>Sequential Decision Making</strong></p><p>So, according to the <em>reward hypothesis</em>, our goal is to <strong>select actions to maximise total future reward</strong>. Actions may have long term consequences as well as reward may be delayed. It may be better to sacrifice immediate reward to gain more long-term reward. For instance, a ï¬nancial investment may take months to mature and a helicopter might prevent a crash in several hours.</p><p><strong>Agent and Environment</strong></p><p><img src="/images/aae.png"></p><p>Agents and envrionments are big concepts in RL. They have following relationships:</p><ul><li>At each step <span class="math inline">\(t\)</span> the agent:<ul><li>Excutes action <span class="math inline">\(A_t\)</span></li><li>Receives observation <span class="math inline">\(O_t\)</span></li><li>Receives scalar reward <span class="math inline">\(R_t\)</span></li></ul></li><li>The environment:<ul><li>Receives action <span class="math inline">\(A_t\)</span></li><li>Emits observation <span class="math inline">\(O_{t+1}\)</span></li><li>Emits scalar reward <span class="math inline">\(R_{t+1}\)</span></li></ul></li><li><span class="math inline">\(t\)</span> increments at env. step</li></ul><p><strong>State</strong></p><p><em>History and State</em></p><p>The <strong>history</strong> is the sequence of observations, actions, rewards: <span class="math display">\[H_t = O_1, R_1, A_1, ..., A_{t-1}, O_t, R_t\]</span> which means all observable variables up to time <span class="math inline">\(t\)</span>, i.e. the sensorimotor stream of a robot or embodied agent.</p><p>What happens next depends on the history:</p><ul><li>The agent selects actions</li><li>The environments select observations/rewards</li></ul><p><strong>State</strong> is the information used to determine what happens next. Formally, state is a function of the history: <span class="math display">\[S_t = f(H_t)\]</span> <em>Environment State</em></p><p>The <strong>environment state</strong> <span class="math inline">\(S^e_t\)</span> is the environment's private representation, i.e. whatever data the environment uses to pick the next observation /reward. The environment state is not usually visible to the agent. Even if <span class="math inline">\(S^e_t\)</span> is visible, it may contain irrelevant information.</p><p><em>Agent State</em></p><p>The <strong>agent state</strong> <span class="math inline">\(S^a_t\)</span> is the agent's internal representation, i.e. whatever information the agent uses to pick the next action. It is the information used by reinforcement learning algotithms. It can be any function of history: <span class="math display">\[S^a_t=f(H_t)\]</span> <em>Information State</em></p><p>An <strong>information state</strong> (a.k.a. <strong>Markov state</strong>) contains all useful information from the history.</p><blockquote><p>Definition</p><p><strong>A state <span class="math inline">\(S_t\)</span> is Markov if and only if</strong> <span class="math display">\[P[S_{t+1}|S_t]=P[S_{t+1}|S_1,...,S_t]\]</span></p></blockquote><p>The above formular means:</p><ul><li><p>&quot;The future is independent of the past given the present&quot; <span class="math display">\[H_{1:t}\rightarrow S_t\rightarrow H_{t+1:\infty}\]</span></p></li><li><p>Once the state is known, the history may be thrown away.</p></li><li><p>The state is a sufficient statistic of the future</p></li><li><p>The environment state <span class="math inline">\(S^e_t\)</span> is Markov</p></li><li><p>The history <span class="math inline">\(H_t\)</span> is Markov</p></li></ul><p><em>Rat Example</em></p><p>Here is an example to explain what is state, imagine you are a rat and your master would decide whether to excuted you or give you a pice of cheese. The master makes decisions according to a sequence of signals, the first two sequence and the result are shown in the figure below:</p><p><img src="/images/firsttwo.png"></p><p>The question is, what would you get if the sequence is like below:</p><p><img src="/images/que.png"></p><p>Well, the answer you may give is decided by what is your agent stateï¼š</p><ul><li>If agent state = last 3 items in sequence, then the answer would be being excuted.</li><li>If agent state = counters for lights, bells and levers, then the answer would be given a piece of cheese.</li><li>What if agent state = complete sequence?</li></ul><p><em>Fully Observable Environments</em></p><p><strong>Full observability</strong>: agent <strong>directly</strong> observes environment state: <span class="math display">\[O_t = S^a_t=S^e_t\]</span></p><ul><li>Agent state = environment state = information state</li><li>Formally, this is a <strong>Markov decision process</strong> (MDP)</li></ul><p><em>Partially Observable Environments</em></p><p><strong>Partial observability</strong>: agent <strong>indirectly</strong> observes environment:</p><ul><li>A robot with camera vision isn't told its absolute location</li><li>A trading agent only observes current prices</li><li>A poker playing agent only observes public cards</li></ul><p>With partial observability, agent state â‰  environment state, formally this is a <strong>partially observable Markov decision process</strong> (POMDP).</p><p>In this situation, agent must construct its own state representation <span class="math inline">\(S^a_t\)</span>, e.g.</p><ul><li>Complete history: <span class="math inline">\(S^a_t = H_t\)</span></li><li><strong>Beliefs</strong> of environment state: <span class="math inline">\(S_t^a = (P[S^e_t=s^1], â€¦, P[S^e_t=s^n])\)</span></li><li>Recurrent neural network: <span class="math inline">\(S^a_t=\sigma(S^a_{t-1}W_s+O_tW_o)\)</span></li></ul><h2><span id="inside-an-rl-agent">Inside An RL Agent</span></h2><p>There are three major components of an RL agent, actually, an agent may include one or more of these:</p><ul><li>Policy: agent's behaviour function</li><li>Value functionï¼šhow good is each state and/or action</li><li>Modelï¼šagent's representation of the environment</li></ul><p><strong>Policy</strong></p><p>A <strong>Policy</strong> is the agent's behaviour, it is a map from state to action, e.g.</p><ul><li>Deterministic policyï¼š<span class="math inline">\(a = \pi(s)\)</span></li><li>Stochastic policy: <span class="math inline">\(\pi(a|s)=P[A_t=a|S_t=s]\)</span></li></ul><p><strong>Value Function</strong></p><p>Value function is a prediction of future reward, it is used to evaluate the goodness/badness of states. And therefore to select between actions: <span class="math display">\[v_\pi(s)=E_\pi[R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+...|S_t=s]\]</span> <strong>Model</strong></p><p>A <strong>model</strong> predicts what the environment will do next, denoted by <span class="math inline">\(P\)</span> which predicts the next state and by <span class="math inline">\(R\)</span> predicts the next (immediate) reward: <span class="math display">\[P^a_{ss&#39;}=P[S_{t+1}=s&#39;|S_t=s,A_t=a]\]</span></p><p><span class="math display">\[R^a_s=E[R_{t+1}|S_t=s, A_t=a]\]</span></p><p><em>Maze Example</em></p><p><img src="/images/maze.png"></p><p>Let an RL agent to solve the maze, the parameters are:</p><ul><li>Rewards: -1 per time-step</li><li>Actions: N, E, S, W</li><li>States: Agent's location</li></ul><p>Then the policy map would be (arrows represent policy <span class="math inline">\(\pi(s)\)</span> for each state <span class="math inline">\(s\)</span>):</p><p><img src="/images/mpolicy.png"></p><p>And the value function at each state would be (numbers represent value <span class="math inline">\(v_\pi(s)\)</span> of each state <span class="math inline">\(s\)</span>):</p><p><img src="/images/mvf.png"></p><p>Model could be visualize as following:</p><ul><li>Grid layout represents transition model <span class="math inline">\(P^a_{ss&#39;}\)</span></li><li>Numbers represent immediate reward <span class="math inline">\(R^a_s\)</span> from each state <span class="math inline">\(s\)</span> (same for all <span class="math inline">\(a\)</span>)</li></ul><p><img src="/images/mm.png"></p><ul><li>Agent may have an internal model of the environment</li><li>Dynamics: how actions change the state</li><li>Rewards: how much reward from each state</li><li>The model may be imperfect</li></ul><p><strong>Categorizing RL agents</strong></p><p>RL agents could be categorized into several categories:</p><ul><li>Value Based<ul><li>No Policy (Implicit)</li><li>Value Function</li></ul></li><li>Policy Based<ul><li>Policy</li><li>No Value Function</li></ul></li><li>Actor Critic<ul><li>Policy</li><li>Value Function</li></ul></li><li>Model Free<ul><li>Policy and/or Value Function</li><li>No Model</li></ul></li><li>Model Based<ul><li>Policy and/or Value Function</li><li>Model</li></ul></li></ul><p><img src="/images/agcat.png"></p><h2><span id="problems-within-reinforcement-learning">Problems within Reinforcement Learning</span></h2><p>This section only proposes questions without providing the solutions.</p><p><strong>Learning and Planning</strong></p><p>Two fundamental problems in sequential decision making:</p><ul><li>Reinforcement Learning<ul><li>The environment is initially unknown</li><li>The agent interacts with the environment</li><li>The agent improves its policy</li></ul></li><li>Planning:<ul><li>A model of the environment is known</li><li>The agent performs computations with its model (without any external interaction)</li><li>The agent improves its policy a.k.a. deliberation, reasoning, introspection, pondering, thought, search</li></ul></li></ul><p><em>Atari Example: Reinforcement Learning</em></p><p><img src="/images/atari.png"></p><p>In atari games, rules of the game are unknown, the agent learns directly from interactive game-play by picking actions on joystick and seeing pixels and scores.</p><p><em>Atari Example: Planning</em></p><p><img src="/images/plan.png"></p><p>In such case, rules of the game are known, which means the agent could query the emulator as known as a perfect model inside agent's brain. Agents need plan ahead to ï¬nd optimal policy, e.g. tree search.</p><p><strong>Exploration and Exploitation</strong></p><ul><li>Reinforcement learning is like trial-and-error learning</li><li>The agent should discover a good policy</li><li>From its experiences of the environment</li><li>Without losing too much reward along the way</li><li><strong>Exploration</strong> ï¬nds more information about the environment</li><li><strong>Exploitation</strong> exploits known information to maximise reward</li><li>It is usually important to explore as well as exploit</li></ul><p><em>Examples</em></p><ul><li>Restaurant Selection<ul><li>Exploitation Go to your favourite restaurant</li><li>Exploration Try a new restaurant</li></ul></li><li>Online Banner Advertisements<ul><li>Exploitation Show the most successful advert</li><li>Exploration Show a diï¬€erent advert</li></ul></li><li>Game Playing<ul><li>Exploitation Play the move you believe is best</li><li>Exploration Play an experimental move</li></ul></li></ul><p><strong>Prediction and Control</strong></p><p><strong>Prediction</strong>: evaluate the future</p><ul><li>Given a policy</li></ul><p><strong>Control</strong>: optimise the future</p><ul><li>Find the best policy</li></ul><p>End. Next note will introduce the Markov Decision Processes.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> å¢å¼ºå­¦ä¹  </tag>
            
            <tag> DRL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Stacked Attention Networks for Image QA</title>
      <link href="/2017/08/15/SAN%20for%20Image%20QA/"/>
      <url>/2017/08/15/SAN%20for%20Image%20QA/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Zichao Yang, Xiaodong He, Jianfeng Gao , Li Deng , Alex Smola <a href="https://arxiv.org/abs/1511.02274" target="_blank" rel="noopener">Stacked Attention Networks for Image Question Answering</a></p></blockquote><p>è¿™ç¯‡æ–‡ç« å‘è¡¨åœ¨CVPR2016ï¼Œä½œè€…æŠŠ attention æœºåˆ¶åº”ç”¨åœ¨ Visual QAï¼Œä¸ä½†èƒ½ç†è§£ç¥ç»ç½‘ç»œç”Ÿæˆç­”æ¡ˆçš„ multiple resoningï¼Œè€Œä¸”è·å¾—äº†å½“æ—¶æœ€å¥½çš„æ•ˆæœã€‚</p><p>SANæ€»å…±ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼š</p><ul><li>Image Modelï¼šç”¨æ¥ç¼–ç å›¾ç‰‡ä¿¡æ¯</li><li>Question Moelï¼šç”¨æ¥ç¼–ç é—®é¢˜ä¿¡æ¯</li><li>Stacked Attention Networksï¼šé€šè¿‡å¤šå±‚ attention layer ä¸æ–­ä¼˜åŒ–å¯¹é—®é¢˜çš„ç¼–ç </li></ul><a id="more"></a><p><img src="/images/san.png"></p><h2><span id="image-model">Image Model</span></h2><p>Image model ä½¿ç”¨ VGGNet å¤„ç†æºå›¾ç‰‡ï¼Œç”¨æœ€åä¸€ä¸ªæ± åŒ–å±‚ä½œä¸ºæå–çš„å›¾ç‰‡ç‰¹å¾: <span class="math display">\[f_I = CNN_{vgg}(I)\]</span> æŠŠè¾“å…¥å›¾ç‰‡è½¬åŒ–ä¸º <span class="math inline">\(448 \times 448\)</span> å¤§å°ï¼Œ è¾“å‡ºçš„ç‰¹å¾å³ä¸º <span class="math inline">\(512 \times 14 \times 14\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(512\)</span> ä¸ºç‰¹å¾å‘é‡ï¼ˆfeature vectorï¼‰ <span class="math inline">\(f_i\)</span> çš„ç»´åº¦ï¼Œ<span class="math inline">\(14 \times 14\)</span> æ˜¯åŒºåŸŸï¼ˆç‰¹å¾å‘é‡ï¼‰çš„ä¸ªæ•°ï¼Œæ¯ä¸ªç‰¹å¾å‘é‡ <span class="math inline">\(f_i\)</span> ä»£è¡¨æºå›¾ç‰‡ä¸­ <span class="math inline">\(32 \times 32\)</span> å¤§å°çš„åŒºåŸŸã€‚</p><p><img src="/images/vgg.png"></p><p>ä¸ºäº†åé¢æ–¹ä¾¿å¤„ç†ï¼Œé€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚æŠŠå›¾ç‰‡ç‰¹å¾è½¬åŒ–ä¸ºå’Œé—®é¢˜ç‰¹å¾ä¸€æ ·çš„ç»´åº¦ï¼š <span class="math display">\[v_I = \tanh(W_If_I + b_I)\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(v_I\)</span> æ˜¯ä¸ªçŸ©é˜µï¼Œå®ƒçš„ç¬¬ <span class="math inline">\(i\)</span> åˆ— <span class="math inline">\(v_i\)</span> æ˜¯åŒºåŸŸ <span class="math inline">\(i\)</span> çš„ç‰¹å¾å‘é‡ï¼ˆfeature vectorï¼‰ã€‚</p><h2><span id="question-model">Question Model</span></h2><p>ä½œè€…é‡‡ç”¨äº†ä¸¤ç§æ¨¡å‹å¯¹é—®é¢˜è¿›è¡Œç¼–ç ï¼Œåˆ†åˆ«åŸºäº LSTM å’Œ CNNã€‚</p><h3><span id="lstm-based-question-model">LSTM based question model</span></h3><p>åŸºäº LSTM çš„æ¨¡å‹å¾ˆç®€å•ï¼Œå°±æ˜¯ç”¨ä¸€ä¸ªæ™®é€šçš„ LSTM å¯¹é—®é¢˜è¿›è¡Œç¼–ç ï¼ˆæ²¡å‡†æ‰©å±•æˆbi-LSTMæ•ˆæœä¼šæ›´å¥½ä¸€äº›ï¼‰ï¼Œæ¯ä¸ªæ—¶åˆ»å¤„ç†ä¸€ä¸ªè¯ï¼ŒæŠŠæœ€åä¸€ä¸ªè¯å¯¹åº”çš„ hidden state ä½œä¸ºç¼–ç ç»“æœ: <span class="math display">\[\begin{alignat}{3}x_t &amp;= W_eq_t, \ t\in\{1, 2, ... T\} \\h_t &amp;= LSTM(x_t), \ t\in\{1, 2, ... T\}\\v_Q &amp;= h_T\end{alignat}\]</span> å…¶ä¸­ï¼Œ <span class="math inline">\(q_t\)</span> ä¸ºè¯çš„ one-hot encodingï¼Œ<span class="math inline">\(W_e\)</span> ä¸º embedding çŸ©é˜µï¼Œ<span class="math inline">\(x_t\)</span> å°±ä¸ºè¯çš„ word embeddingï¼ˆæ€»è§‰å¾—è¿™æ ·çš„è¯ç¼–ç å¤ªç®€å•äº†ï¼‰ï¼Œ<span class="math inline">\(v_Q\)</span> ä¸ºå¯¹é—®é¢˜çš„ç¼–ç ã€‚</p><p><img src="/images/lstmq.png"></p><h3><span id="cnn-based-question-model">CNN based question model</span></h3><p><img src="/images/cnn_basedq.png"></p><p>è¿™åº”è¯¥ç®—æ˜¯CNNçš„ä¸€ä¸ªå˜ç§ï¼Œå®ƒçš„ filter æœ‰ä¸‰ç§ï¼Œåˆ†åˆ«ä¸º unigram, bigram, trigramï¼Œåˆ†åˆ«å¯¹åº”çª—å£å¤§å° <span class="math inline">\(c = 1, 2, 3\)</span>ã€‚å®šä¹‰ç¬¦å· <span class="math inline">\(x_{i:j}\)</span> ä¸º <span class="math inline">\(x_i, x_{i+1}, â€¦, x_j\)</span> çš„è¿æ¥ï¼Œæ‰€ä»¥é—®é¢˜å‘é‡å¯è¡¨ç¤ºä¸º: <span class="math display">\[x_{1:T} = [x1, x2, ..., x_T]\]</span></p><p>ç„¶åå¯¹æ¯ä¸€ä¸ª filter åˆ†åˆ«åœ¨ <span class="math inline">\(x_{1:T}\)</span> ä¸Šè¿›è¡Œå·ç§¯æ“ä½œï¼Œç¬¬ <span class="math inline">\(t\)</span> æ¬¡å·ç§¯æ“ä½œçš„è¾“å‡ºä¸ºï¼š <span class="math display">\[h_{c,t} = \tanh(W_cx_{t:t+c-1}+b_c)\]</span> çª—å£å¤§å°ä¸º <span class="math inline">\(c\)</span> çš„ feature map ä¸ºï¼š <span class="math display">\[h_c = [h_{c,1}, h_{c,2}, ..., h_{c,T-c+1}]\]</span> ç„¶åå¯¹æ¯ä¸ª feature map è¿›è¡Œ max poolingï¼Œå¾—åˆ°æœ€ç»ˆçš„é—®é¢˜ç‰¹å¾ï¼š <span class="math display">\[\hat{h}_c = \max_t(h_{c,1}, h_{c, 2} ..., h_{c,T-c+1})\]</span></p><p><span class="math display">\[v_Q = h = [\hat{h}_1,\hat{h}_2,\hat{h}_3]\]</span></p><h2><span id="stacked-attention-networks">Stacked Attention Networks</span></h2><p><strong>ç¬¬ä¸€å±‚ attention network</strong></p><p><img src="/images/san1st.png"></p><p>é¦–å…ˆæ ¹æ®å›¾åƒç‰¹å¾çŸ©é˜µ <span class="math inline">\(v_I\)</span> å’Œé—®é¢˜ç‰¹å¾å‘é‡ <span class="math inline">\(v_Q\)</span> è®¡ç®— attention mapï¼š <span class="math display">\[\begin{alignat}{3}h_A &amp;= \tanh(W_{I,A}v_I\oplus (W_{Q,A}v_Q+b_A))\\p_I &amp;= softmax(W_Ph_A+b_P)\end{alignat}\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(v_I\in R^{d\times m}\)</span>, <span class="math inline">\(d\)</span> æ˜¯å›¾åƒç‰¹å¾çš„ç»´åº¦ï¼Œ<span class="math inline">\(m\)</span> æ˜¯å›¾åƒåŒºåŸŸä¸ªæ•°ï¼›<span class="math inline">\(v_Q \in R^d\)</span>ï¼›<span class="math inline">\(W_{I, A}, W_{Q,A} \in R^{k \times d}\)</span>ï¼Œ<span class="math inline">\(b_A \in R^{k}\)</span>ï¼›å®šä¹‰ <span class="math inline">\(\oplus\)</span> ä¸ºçŸ©é˜µå’Œå‘é‡çš„åŠ æ³•ï¼Œå…¶è¿ç®—è§„åˆ™ä¸ºçŸ©é˜µçš„æ¯ä¸€åˆ—åˆ†åˆ«å’Œè¯¥å‘é‡ç›¸åŠ ï¼Œæ‰€ä»¥ <span class="math inline">\(h_A \in R^{k\times m}\)</span>ã€‚<span class="math inline">\(W_P \in R^{1\times k}, b_P\in R^{1\times m}\)</span>ï¼Œ<span class="math inline">\(p_I \in R^{1\times m}\)</span> ä¸º attention vectorï¼Œå®ƒæ¯ä¸€é¡¹éƒ½æ˜¯ä¸€ä¸ªæ¦‚ç‡ï¼Œè¡¨ç¤ºè¯¥é—®é¢˜çš„ç­”æ¡ˆæ‰€åœ¨æŸä¸ªåŒºåŸŸçš„æ¦‚ç‡ï¼Œæˆ–è€…è¯´é—®äº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæ³¨æ„åŠ›åº”è¯¥é›†ä¸­åœ¨å“ªé‡Œã€‚</p><p>ä¹‹åç”¨ attention vector è®¡ç®— å›¾åƒç‰¹å¾çš„åŠ æƒå’Œï¼Œç„¶åä¸é—®é¢˜ç‰¹å¾ç›¸åŠ ï¼Œå¾—åˆ°<strong>ä¼˜åŒ–çš„é—®é¢˜ç‰¹å¾</strong>ï¼š <span class="math display">\[\begin{alignat}{3}\widehat{v}_I &amp;= \sum_ip_iv_i \\u &amp;= \hat{v}_I+v_Q\end{alignat}\]</span> åé¢çš„æ¯å±‚ attention network ç»“æ„éƒ½æ˜¯ä¸€æ ·çš„ï¼ŒåŒºåˆ«åœ¨äºä¸å†ä½¿ç”¨åŸå§‹çš„é—®é¢˜ç‰¹å¾ <span class="math inline">\(v_Q\)</span>ï¼Œè€Œæ˜¯ç”¨ä¼˜åŒ–åçš„ <span class="math inline">\(u\)</span>:</p><p><img src="/images/san2nd.png"></p><p><strong>ç¬¬ k å±‚ attention network</strong> <span class="math display">\[\begin{alignat}{3}h_A^k &amp;= \tanh(W_{I,A}^kv_I\oplus (W_{Q,A}^ku_{k-1}+b_A^k))\\p_I^k &amp;= softmax(W_P^kh_A^k+b_P^k)\\\widehat{v}_I^k &amp;= \sum_ip_i^kv_i \\u^k &amp;= \hat{v}_I^k+u^{k-1}\end{alignat}\]</span> ä½œè€…é€šè¿‡å®éªŒå‘ç°ï¼Œç¬¬ä¸€å±‚ attention å¯ä»¥è¯†åˆ«é—®é¢˜ä¸­å‡ºç°çš„å®ä½“ï¼Œç¬¬äºŒå±‚åˆ™å¯ä»¥æ¶ˆé™¤æ— å…³çš„ï¼Œåªå…³å¿ƒä¸ç­”æ¡ˆç›¸å…³çš„å®ä½“ï¼Œå¤šåŠ å‡ å±‚å¯¹è¯†åˆ«æ•ˆæœæ²¡æœ‰æ˜æ˜¾æå‡ã€‚</p><p><strong>è¾“å‡ºå±‚</strong></p><p><img src="/images/vqa_out.png"></p><p>ç”±äºè¾“å‡ºåªæ˜¯ä¸€ä¸ªè¯ï¼Œæ‰€ä»¥å¯ä»¥è½¬åŒ–ä¸ºåˆ†ç±»é—®é¢˜ï¼Œåœ¨æ‰€æœ‰å€™é€‰ç­”æ¡ˆé‡ŒæŒ‘ä¸€ä¸ªè¯å‡ºæ¥ï¼š <span class="math display">\[p_{ans} = softmax(W_uu^K+b_u)\]</span> å…¶ä¸­ <span class="math inline">\(K\)</span> ä¸º attention çš„å±‚æ•°ã€‚</p><h2><span id="å¯è§†åŒ–-attention-layer">å¯è§†åŒ– Attention Layer</span></h2><ul><li>æ­£ç¡®ç»“æœ</li></ul><p><img src="/images/true_vqa.png"></p><ul><li>é”™è¯¯ç»“æœ</li></ul><p><img src="/images/false_vqa.png"></p><h2><span id="æ€»ç»“">æ€»ç»“</span></h2><p>è¿™ç¯‡æ–‡ç« çš„ä¸»è¦å·¥ä½œåœ¨äºæŠŠ attention æœºåˆ¶åº”ç”¨åœ¨ Visual QA é—®é¢˜ä¸­ï¼Œæ•ˆæœå“ç¾¤ï¼Œå¯è§£é‡Šæ€§å¼ºã€‚ä½†ä¹Ÿæœ‰å¯æ”¹è¿›çš„åœ°æ–¹ï¼Œå¦‚å›¾ç‰‡ç¼–ç é€‰æ‹© ResNet è€Œä¸æ˜¯ VGGNetï¼›é—®é¢˜çš„ word embedding é‡‡ç”¨ word2vecï¼›å¯¹é—®é¢˜çš„ç¼–ç é‡‡ç”¨ bi-LSTM ç­‰ï¼Œä¹Ÿè®¸ä¼šè¿›ä¸€æ­¥æé«˜æ•´ä½“çš„è¡¨ç°ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Attention </tag>
            
            <tag> CV </tag>
            
            <tag> CNN </tag>
            
            <tag> VQA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Neural Machine Translation In Linear Time (ByteNet)</title>
      <link href="/2017/08/14/Neural%20Machine%20Translation%20In%20Linear%20Time%20(ByteNet)/"/>
      <url>/2017/08/14/Neural%20Machine%20Translation%20In%20Linear%20Time%20(ByteNet)/</url>
      
        <content type="html"><![CDATA[<p>ByteNet å¯ç”¨äº<strong>å­—ç¬¦çº§</strong>çš„æœºå™¨ç¿»è¯‘æ¨¡å‹å¹¶ä¸”æœ‰ç€å¾ˆå¥½çš„è¡¨ç°ï¼Œå®ƒçš„ç‰¹ç‚¹åœ¨äºå¯ä»¥åœ¨çº¿æ€§æ—¶é—´ (linear time) å®Œæˆç¿»è¯‘è€Œä¸”èƒ½å¤Ÿå¤„ç†é•¿è·ç¦»ä¾èµ–ã€‚å®ƒä¹Ÿé‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå¹¶ä¸”ç¼–ç å™¨å’Œè§£ç å™¨éƒ½ç”±CNNç»„æˆã€‚</p><p>ByteNet ä¹‹æ‰€ä»¥æœ‰ä¸Šè¿°çš„è¿™äº›ç‰¹æ€§ï¼Œæ˜¯å› ä¸ºä½¿ç”¨äº†å¦‚ä¸‹ä¸€äº›æŠ€æœ¯ï¼š</p><ul><li>Dynamic Unfolding<ul><li>è§£å†³äº†ç”Ÿæˆä¸åŒé•¿åº¦ç¿»è¯‘çš„é—®é¢˜</li></ul></li><li>Dilated Convolution<ul><li>ç¼©çŸ­äº†ä¾èµ–ä¼ æ’­çš„è·ç¦»</li></ul></li><li>Masked 1D Convolution<ul><li>ä¿è¯è®­ç»ƒæ—¶åªç”¨è¿‡å»çš„ä¿¡æ¯ç”Ÿæˆå½“å‰å­—ç¬¦</li></ul></li><li>Residual Blocks<ul><li>è§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜</li></ul></li></ul><a id="more"></a><p><img src="/images/byte.png"></p><h2><span id="dynamic-unfolding">Dynamic Unfolding</span></h2><p><img src="/images/dy_unfold.png"></p><p>Encoder çš„è¾“å‡ºçš„å¥å­ç¼–ç çš„é•¿åº¦å›ºå®šä¸º <span class="math inline">\(|\hat{t}|\)</span> (ä¸å¤Ÿä¼šè¡¥é›¶)ï¼Œæ˜¯ç›®æ ‡å¥å­é•¿åº¦ <span class="math inline">\(|t|\)</span> çš„ä¸Šç•Œï¼Œå¯ä»¥é€šè¿‡ä¸‹å¼å¾—åˆ°ï¼š <span class="math display">\[|\hat{t}| = a|s| + b\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(|s|\)</span> è¡¨ç¤ºæºå¥å­é•¿åº¦ï¼Œé€šè¿‡é€‰æ‹©é€‚å½“çš„å‚æ•° <span class="math inline">\(a\)</span> å’Œ <span class="math inline">\(b\)</span>ï¼Œä½¿å¾— <span class="math inline">\(|\hat{t}|\)</span> åŸºæœ¬éƒ½å¤§äºå®é™…é•¿åº¦ <span class="math inline">\(|t|\)</span>ï¼Œå¹¶ä¸”æ²¡æœ‰å¤ªå¤šå†—ä½™ã€‚</p><p>åœ¨æ¯ä¸€æ­¥ï¼Œdecoder æ ¹æ®å½“å‰è¾“å…¥å­—ç¬¦å’Œå¥å­ç‰¹å¾è¾“å‡ºä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œç›´åˆ°ç”ŸæˆEOSã€‚è‡³äº decoder æ€ä¹ˆæ¥æ”¶è¾“å…¥å¹¶ conditioned on ç¼–ç å™¨çš„è¾“å‡ºï¼Œè®ºæ–‡åœ¨å¹¶æ²¡æœ‰æåŠï¼Œä¸è¿‡ä»ä¸€ä¸ª<a href="https://github.com/paarthneekhara/byteNet-tensorflow/blob/master/ByteNet/model.py" target="_blank" rel="noopener">å¼€æºå®ç°</a>ä¸­çœ‹å‡ºæ˜¯ç›´æ¥æŠŠè¾“å…¥å’Œç¼–ç å™¨åœ¨å¯¹åº”ä½ç½®çš„è¾“å‡ºè¿æ¥èµ·æ¥ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚</p><h2><span id="dilated-convolution">Dilated Convolution</span></h2><p>ä¸€ç»´ç¦»æ•£å·ç§¯çš„å®šä¹‰ä¸ºï¼š <span class="math display">\[(f*g)[n] = \sum_{m=-\infty}^{\infty}f[m]g[n-m] = \sum_{m=-M}^Mf[n - m]g[m]\]</span> ä¾‹ï¼šå¦‚æœ <span class="math inline">\(f = [0, 1, 2, -1, 1, -3, 0]\)</span>, <span class="math inline">\(g = [1, 0, -1]\)</span>ï¼Œåˆ™æŒ‰ç…§ä¸Šå¼ï¼Œå·ç§¯è®¡ç®—å¦‚ä¸‹æ‰€ç¤ºï¼š <span class="math display">\[\begin{array}{lcl}(f*g)[2]        &amp; = &amp; f[2]g[0] + f[1]g[1] + f[0]g[2] = -2 \\(f*g)[3]  &amp; = &amp; f[3]g[0] + f[2]g[1] + f[1]g[2] = 2 \\...\\(f*g)[6]  &amp; = &amp; f[6]g[0] + f[5]g[1] + f[4]g[2] = 1 \\\end{array}\]</span> å’Œ stride = 1 çš„æ™®é€šå·ç§¯ç½‘ç»œè®¡ç®—ä¸€è‡´ã€‚</p><p><img src="/images/stride.jpeg"></p><p><strong>Dilated Convolution</strong>çš„å®šä¹‰ä¸ºï¼š <span class="math display">\[(f*_lg)[n] = \sum_{m=-\infty}^{\infty}f[m]g[n-lm] = \sum_{m=-M}^Mf[n - lm]g[m]\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(l\)</span> ä¸º dilation factorï¼Œæ§åˆ¶æ‰©å¼ å¤§å°ï¼Œè¿™æ · <span class="math inline">\(l = 2\)</span> æ—¶ä¸Šé¢ä¾‹å­ä¸­çš„å·ç§¯å°±å˜æˆäº†ï¼š <span class="math display">\[\begin{array}{lcl}(f*_2g)[4]        &amp; = &amp; f[4]g[0] + f[2]g[1] + f[0]g[2]  \\(f*_2g)[5]  &amp; = &amp; f[5]g[0] + f[3]g[1] + f[1]g[2] \\(f*_2g)[6]  &amp; = &amp; f[6]g[0] + f[4]g[1] + f[2]g[2]  \\\end{array}\]</span> å½“ <span class="math inline">\(l = 3\)</span> æ—¶ï¼Œç›¸åº”å·ç§¯å°±ä¸º: <span class="math display">\[(f*_3g)[6] = f[6]g[0] + f[3]g[1] + f[0]g[2]\]</span> è¿™æ ·è™½ç„¶å·ç§¯æ ¸éƒ½ä¸º3ï¼Œä½† receptive field çš„å¤§å°å´å¤§äº†å¾ˆå¤šï¼Œæ‰€ä»¥ä½¿ç”¨ dialted conv èƒ½ä½¿ <strong>receptive field</strong> çš„å¤§å°å‘ˆ<strong>æŒ‡æ•°å¢é•¿</strong>ï¼Œè€Œç›¸åº”<strong>å‚æ•°</strong>å´æ˜¯<strong>çº¿æ€§å¢é•¿</strong>çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ä½¿ç”¨ dilated conv å°±å¯ä»¥æœ‰æ•ˆåœ°ç¼©çŸ­ä¾èµ–ä¼ æ’­çš„è·ç¦»ã€‚</p><p><img src="/images/dilated.png"></p><p>å‚è€ƒï¼š<a href="https://arxiv.org/abs/1511.07122" target="_blank" rel="noopener">MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS</a></p><h2><span id="residual-block">Residual Block</span></h2><p><img src="/images/residual.png"></p><p>æ¯ä¸€å±‚ï¼ˆåŒ…æ‹¬ Encoder å’Œ Decoderï¼‰éƒ½å°è£…äº†ä¸€ä¸ª residual blockï¼ˆä¸Šå›¾ï¼‰ï¼Œå…¶ä¸­æ¯ä¸ªé»„è‰²çš„æ ¼å­ä»£è¡¨ä¸€ä¸ªå·ç§¯å±‚ï¼Œé‡Œé¢çš„æ•°å­—æ˜¯ç›¸åº”çš„ filter sizeã€‚ä¸­é—´çš„ Masked 1 x K æ˜¯è¿™å±‚çš„ä¸»åŠ›ï¼Œå…¶ä»–éƒ½æ˜¯ä¸ºäº†ä½¿ä»–å‘æŒ¥æ›´å¤§æ•ˆæœçš„é™ªè¡¬ã€‚</p><h2><span id="linear-time">Linear Time</span></h2><p><img src="/images/lt.png"></p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> NMT </tag>
            
            <tag> CNN </tag>
            
            <tag> ByteBet </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Attention Is All You Need</title>
      <link href="/2017/08/13/Attention%20Is%20All%20You%20Need/"/>
      <url>/2017/08/13/Attention%20Is%20All%20You%20Need/</url>
      
        <content type="html"><![CDATA[<p>Googleçš„<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">è¿™ç¯‡è®ºæ–‡</a>æå‡ºäº†ä¸€ä¸ªåªä½¿ç”¨Attentionæœºåˆ¶çš„ç¥ç»ç¿»è¯‘æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¾æ—§é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨ï¼ˆEncoder-Decoderï¼‰æ¶æ„ï¼Œä½†æœªä½¿ç”¨RNNå’ŒCNNã€‚æ–‡ç« çš„ä¸»è¦ç›®çš„æ˜¯åœ¨å‡å°‘è®¡ç®—é‡å’Œæé«˜å¹¶è¡Œæ•ˆç‡çš„åŒæ—¶ä¸æŸå®³æœ€ç»ˆçš„å®éªŒç»“æœï¼Œåˆ›æ–°ä¹‹å¤„åœ¨äºæå‡ºäº†ä¸¤ä¸ªæ–°çš„Attentionæœºåˆ¶ï¼Œåˆ†åˆ«å«åš Scaled Dot-Product Attention å’Œ Multi-Head Attention.</p><a id="more"></a><h2><span id="æ•´ä½“æ¡†æ¶">æ•´ä½“æ¡†æ¶</span></h2><figure><img src="/images/at_all.png" alt="æ•´ä½“æ¡†æ¶"><figcaption>æ•´ä½“æ¡†æ¶</figcaption></figure><ul><li>è¾“å…¥ï¼šä¸€ä¸ªå¥å­ <span class="math inline">\(z = (z_1, â€¦, z_n)\)</span>ï¼Œå®ƒæ˜¯åŸå§‹å¥å­ <span class="math inline">\(x = (x_1, â€¦, x_n)\)</span> çš„ Embeddingï¼Œå…¶ä¸­ <span class="math inline">\(n\)</span> æ˜¯å¥å­é•¿åº¦ã€‚</li><li>è¾“å‡ºï¼šç¿»è¯‘å¥½çš„å¥å­ <span class="math inline">\((y_1, â€¦, y_m)\)</span></li></ul><h3><span id="encoder">Encoder</span></h3><ul><li>è¾“å…¥ <span class="math inline">\(z \in R^{n \times d_{model}}\)</span></li><li>è¾“å‡ºå¤§å°ä¸å˜</li><li>Positional Encoding</li><li>6ä¸ªBlock<ul><li>Multi-Head Self-Attention</li><li>Position-wise Feed Forward</li><li>Residual connection<ul><li>LayerNorm(x + Sublayer(x))</li><li>å¼•å…¥äº†æ®‹å·®ï¼Œå°½å¯èƒ½ä¿ç•™åŸå§‹è¾“å…¥xçš„ä¿¡æ¯</li></ul></li><li><span class="math inline">\(d_{model} = 512\)</span></li></ul></li></ul><h3><span id="decoder">Decoder</span></h3><ul><li>Positional Encoding</li><li>6ä¸ªBlock<ul><li>Multi-Head Self Attention (with mask)<ul><li>é‡‡ç”¨ 0-1mask æ¶ˆé™¤å³ä¾§å•è¯å¯¹å½“å‰å•è¯ attention çš„å½±å“</li></ul></li><li>Multi-Head Self Attention (with encoder)<ul><li>ä½¿ç”¨Encoderçš„è¾“å‡ºä½œä¸ºä¸€éƒ¨åˆ†è¾“å…¥</li></ul></li><li>Position-wise Feed Forward</li><li>Residual connection</li></ul></li></ul><h3><span id="multi-head-self-attention">Multi-Head Self Attention</span></h3><p><img src="/images/at_attention.png"></p><p><strong>Multi-Head Attention</strong></p><p>è¾“å…¥ <span class="math inline">\(Q \in R^{n \times d_{model}}\)</span>ã€<span class="math inline">\(K \in R^{n \times d_{model}}\)</span>ã€<span class="math inline">\(V \in R^{n \times d_{model}}\)</span>ï¼Œåˆ†åˆ«ä»£è¡¨queryã€key-value pairã€‚è¿™é‡Œçš„ key, value, å’Œ query éœ€è¦è§£é‡Šä¸€ä¸‹ï¼Œè¿™é‡ŒæŠŠ attention æŠ½è±¡ä¸ºå¯¹ value (<span class="math inline">\(V\)</span>) çš„æ¯ä¸ª token è¿›è¡ŒåŠ æƒï¼Œè€ŒåŠ æƒçš„ weightå°±æ˜¯ attention weightï¼Œè€Œ attention weight å°±æ˜¯æ ¹æ® query å’Œ key è®¡ç®—å¾—åˆ°ï¼Œå…¶æ„ä¹‰ä¸ºï¼š<strong>ä¸ºäº†ç”¨ value æ±‚å‡º query çš„ç»“æœ, æ ¹æ® query å’Œ key æ¥å†³å®šæ³¨æ„åŠ›åº”è¯¥æ”¾åœ¨ value çš„å“ªéƒ¨åˆ†</strong>ã€‚ä»¥å‰çš„ attention æ˜¯ç”¨ LSTM åš encoderï¼Œä¹Ÿå°±æ˜¯ç”¨å®ƒæ¥ç”Ÿæˆ key å’Œ value ï¼Œç„¶åç”± decoder æ¥ç”Ÿæˆ queryã€‚å…·ä½“åˆ° Bahdanau çš„è®ºæ–‡ Neural machine translation by jointly learning to align and translateï¼Œkey å’Œ value æ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯æ–‡ä¸­çš„ <span class="math inline">\(h\)</span>ï¼Œè€Œ query æ˜¯æ–‡ä¸­çš„ <span class="math inline">\(s\)</span>ã€‚è€Œåœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼š</p><ul><li>åœ¨encoderå—ä¸­ï¼Œkey, value, query åŒä¸º<code>encoder_input</code>ï¼ˆä¸Šä¸€å±‚çš„è¾“å‡ºï¼‰ï¼Œå› ä¸ºæ˜¯<a href="https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/self_attention_embedding.md" target="_blank" rel="noopener">self-attention</a>ï¼Œå¯ä»¥ç†è§£ä¸ºç”Ÿæˆå¯¹è¿™ä¸ªå¥å­çš„ç¼–ç ï¼Œå¯ä»¥å…¨é¢è·å–è¾“å…¥åºåˆ—ä¸­positionsä¹‹é—´ä¾èµ–å…³ç³»ã€‚</li><li>åœ¨decoderå—ä¸­ï¼Œç¬¬ä¸€å±‚Multi-Head Attentionçš„è¾“å…¥éƒ½ä¸º<code>decoder_input</code>ï¼›ç¬¬äºŒå±‚çš„ <span class="math inline">\(Q\)</span> ä¸ºå‰ä¸€å±‚çš„è¾“å‡ºï¼Œ<span class="math inline">\(K, V\)</span> ä¸ºencoderçš„è¾“å‡ºã€‚å¯ä»¥ç†è§£ä¸ºï¼Œæ¯”å¦‚åˆšç¿»è¯‘å®Œä¸»è¯­ï¼Œæ¥ä¸‹æ¥æƒ³è¦æ‰¾è°“è¯­ï¼Œã€æ‰¾è°“è¯­ã€‘è¿™ä¸ªä¿¡æ¯å°±æ˜¯ queryï¼Œç„¶å key æ˜¯æºå¥å­çš„ç¼–ç ï¼Œé€šè¿‡ query å’Œ key è®¡ç®—å‡º attention weight ï¼ˆåº”è¯¥å…³æ³¨çš„è°“è¯­çš„ä½ç½®ï¼‰ï¼Œæœ€åå’Œ value ï¼ˆæºå¥å­ç¼–ç ï¼‰è®¡ç®—åŠ æƒå’Œã€‚</li></ul><p>ç„¶åæŠŠ <span class="math inline">\(Q, K, V\)</span> çº¿æ€§æ˜ å°„ <span class="math inline">\(h\)</span> æ¬¡ï¼Œåˆ†åˆ«æ˜ å°„åˆ° <span class="math inline">\(d_k, d_k, d_v\)</span> ç»´åº¦ï¼Œæ€»çš„attentionä¸ºæ¯ä¸ªæ˜ å°„çš„attentionè¿æ¥èµ·æ¥ï¼ˆè¿™ <span class="math inline">\(h\)</span> ä¸ªattentionå¯ä»¥å¹¶è¡Œè®¡ç®—ï¼‰ï¼Œå³ï¼š</p><p><img src="/images/at_multi.png"></p><p>å…¶ä¸­ï¼ŒæŠ•å½±çš„å‚æ•°çŸ©é˜µ <span class="math inline">\(W^Q_i \in R^{d_{model} \times d_k}\)</span>, <span class="math inline">\(W^K_i \in R^{d_{model} \times d_k}\)</span>, <span class="math inline">\(W^V_i \in R^{d_{model} \times d_v}\)</span>. åœ¨è®ºæ–‡ä¸­ <span class="math inline">\(h = 8\)</span>ï¼Œ<span class="math inline">\(d_k = d_v = \frac{d_{model}}{h} = 64\)</span>ï¼Œæ‰€ä»¥è¿™å±‚çš„è¾“å‡ºå’Œè¾“å…¥å¤§å°ç›¸åŒã€‚</p><p>è¿™äº›çº¿æ€§æ˜ å°„ä½¿å¾—æ¨¡å‹å¯ä»¥ä»ä¸åŒçš„å­ç©ºé—´çš„ä¸åŒä½ç½®ä¸­å­¦ä¹ æ³¨æ„åŠ›ï¼</p><p><strong>Scaled Dot-Product Attention</strong></p><p>ä¸Šå¼ä¸­çš„attentionæ­£æ˜¯Scaled Dot-Product Attentionï¼Œå®ƒä¹Ÿæ¥æ”¶ <span class="math inline">\(Q, K, V\)</span> ä¸‰ä¸ªå‚æ•°ï¼Œè®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š <span class="math display">\[Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span> Dot-ProductæŒ‡çš„æ˜¯ <span class="math inline">\(QK^T\)</span>ï¼Œscaledæ˜¯æŒ‡é™¤ä»¥äº† <span class="math inline">\(\sqrt{d_k}\)</span> ï¼ˆå› ä¸ºå‡è®¾ä¸¤ä¸ª <span class="math inline">\(d_k\)</span> ç»´å‘é‡æ¯ä¸ªåˆ†é‡éƒ½æ˜¯ä¸€ä¸ªç›¸äº’ç‹¬ç«‹çš„æœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„éšæœºå˜é‡ï¼Œé‚£ä¹ˆä»–ä»¬çš„ç‚¹ä¹˜çš„æ–¹å·®å°±æ˜¯ <span class="math inline">\(d_k\)</span>ï¼Œæ¯ä¸€ä¸ªåˆ†é‡é™¤ä»¥ <span class="math inline">\(\sqrt{d_k}\)</span> å¯ä»¥è®©ç‚¹ä¹˜çš„æ–¹å·®å˜æˆ 1ï¼‰ã€‚</p><p>æ€»å…±æœ‰ä¸¤ç§æµè¡Œçš„attentionè®¡ç®—æ–¹æ³•ï¼š</p><ul><li>additive attention<ul><li>é€šè¿‡ä¸€ä¸ªå°å‹ç¥ç»ç½‘ç»œè®¡ç®—æ³¨æ„åŠ›</li></ul></li><li>dot-product attention<ul><li>ä¸Šé¢çš„æ–¹æ³•</li></ul></li></ul><p>å…¶ä¸­ç¬¬äºŒç§æ–¹æ³•æ¯”ç¬¬ä¸€ç§æ–¹æ³•å¿«å¾ˆå¤šï¼Œç¬¬ä¸€ç§æ–¹æ³•åœ¨ <span class="math inline">\(d_k\)</span> è¾ƒå¤§æ—¶æ¯”ç¬¬äºŒç§æ–¹æ³•è¡¨ç°å¥½ï¼Œè®ºæ–‡ä½œè€…è§‰å¾—å¯èƒ½æ˜¯å› ä¸ºdot-productä½¿æ¢¯åº¦å˜å¾—å¾ˆå¤§ä»¥è‡³äºå¤±å»ä½œç”¨ï¼Œæ‰€ä»¥è¿›è¡Œäº†scaleã€‚</p><p><strong>å¯è§†åŒ– self-attention</strong></p><p><img src="/images/attn_vis.png"></p><p><img src="/images/attn_vis2.png"></p><h3><span id="position-wise-feed-forward-networks">Position-wise Feed-Forward Networks</span></h3><p><span class="math display">\[FFN(x) = \max(0, xW_1 + b_1)W_2 + b_2\]</span></p><p>è¿™æ˜¯ä¸€ä¸ª MLP ï¼ˆå¤šå±‚ï¼‰ç½‘ç»œï¼Œä¸Šå±‚çš„è¾“å‡ºä¸­ï¼Œæ¯ä¸ª <span class="math inline">\(d_{model}\)</span> ç»´å‘é‡ <span class="math inline">\(x\)</span> åœ¨æ­¤å…ˆç”± <span class="math inline">\(xW_1+b_1\)</span> å˜ä¸º <span class="math inline">\(d_{ff}\)</span> ç»´çš„ <span class="math inline">\(x&#39;\)</span>ï¼Œå†ç»è¿‡ <span class="math inline">\(\max(0, x&#39;)W_2+b_2\)</span> å›å½’ <span class="math inline">\(d_{model}\)</span> ç»´ã€‚ä¹‹åå†æ˜¯ä¸€ä¸ª residual connectionã€‚è¾“å‡ºå¤§å°å’Œè¾“å…¥å¤§å°ä¸€æ ·ï¼Œéƒ½ <span class="math inline">\(\in R^{n \times d_{model}}\)</span>.</p><h3><span id="positional-encoding">Positional Encoding</span></h3><p>å› ä¸ºè¿™ä¸ªç½‘ç»œæ²¡æœ‰ recurrenceï¼ˆå› ä¸ºdecoderåœ¨è®­ç»ƒæ—¶ç»™ground truthåšä¸ºè¾“å…¥ï¼Œè¿™æ ·ç”Ÿæˆä¸åŒä½ç½®çš„è¯æ˜¯å¯ä»¥å¹¶è¡Œçš„ï¼‰å’Œ convolutionï¼Œä¸ºäº†è¡¨ç¤ºè¯åœ¨åºåˆ—ä¸­çš„ä½ç½®ä¿¡æ¯ï¼Œè¦ç”¨ä¸€ç§ç‰¹æ®Šçš„ä½ç½®ç¼–ç ã€‚</p><p>æœ¬ç¯‡è®ºæ–‡ä¸­ä½¿ç”¨ <span class="math inline">\(\sin\)</span> å’Œ <span class="math inline">\(\cos\)</span> æ¥ç¼–ç ï¼š <span class="math display">\[\begin{array}{lcl}PE_{(pos, 2i)}        &amp; = &amp; \sin(\frac{pos}{10000^{2i/d_{model}}})\\PE_{(pos, 2i+1)}        &amp; = &amp; \cos(\frac{pos}{10000^{2i/d_{model}}})\end{array}\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(pos\)</span> ä»£è¡¨ä½ç½®ï¼Œ<span class="math inline">\(i\)</span> ä»£è¡¨ç»´åº¦ï¼ˆ<span class="math inline">\([0, d_{model}-1]\)</span>ï¼‰ã€‚</p><p>è¿™æ ·åšçš„ç›®çš„æ˜¯å› ä¸ºæ­£å¼¦å’Œä½™å¼¦å‡½æ•°å…·æœ‰å‘¨æœŸæ€§ï¼Œå¯¹äºå›ºå®šé•¿åº¦åå·® <span class="math inline">\(k\)</span>ï¼ˆç±»ä¼¼äºå‘¨æœŸï¼‰ï¼Œ<span class="math inline">\(pos+k\)</span> ä½ç½®çš„ PE å¯ä»¥è¡¨ç¤ºæˆå…³äº <span class="math inline">\(pos\)</span> ä½ç½® PE çš„ä¸€ä¸ªçº¿æ€§å˜æ¢ï¼ˆ<span class="math inline">\(\sin(pos + k) =\sin(pos)\cos(k)+\sin(k)\cos(pos)\)</span>ï¼‰ï¼Œè¿™æ ·å¯ä»¥æ–¹ä¾¿æ¨¡å‹å­¦ä¹ è¯ä¸è¯ä¹‹é—´çš„ä¸€ä¸ªç›¸å¯¹ä½ç½®å…³ç³»ã€‚</p><p>å¦ä¸€ç§è§£é‡Šï¼Œæ¥è‡ª <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728452&amp;idx=4&amp;sn=fcc845a7ff15e6ceb331161d71899402&amp;chksm=871b2c7ab06ca56c9d746a2c2977578ec391ed526ec05d7b1da1910d1987597b5801ac6f98d1&amp;mpshare=1&amp;scene=23&amp;srcid=0701ZtSHzIyPmVKwYJdpsdvM%23rd" target="_blank" rel="noopener">WarBean</a> ï¼š</p><blockquote><p>æ¯ä¸¤ä¸ªç»´åº¦æ„æˆä¸€ä¸ªäºŒç»´çš„å•ä½å‘é‡ï¼Œæ€»å…±æœ‰ <span class="math inline">\(d_{model} / 2\)</span> ç»„ã€‚æ¯ä¸€ç»„å•ä½å‘é‡ä¼šéšç€ <span class="math inline">\(pos\)</span> çš„å¢å¤§è€Œæ—‹è½¬ï¼Œä½†æ˜¯æ—‹è½¬å‘¨æœŸä¸åŒï¼ŒæŒ‰ç…§è®ºæ–‡é‡Œé¢çš„è®¾ç½®ï¼Œæœ€å°çš„æ—‹è½¬å‘¨æœŸæ˜¯ <span class="math inline">\(2\pi\)</span>ï¼Œæœ€å¤§çš„æ—‹è½¬å‘¨æœŸæ˜¯ <span class="math inline">\(10000 \times 2\pi\)</span>ã€‚è‡³äºä¸ºä»€ä¹ˆè¯´ç›¸é‚» <span class="math inline">\(k\)</span> æ­¥çš„ position embedding å¯ä»¥ç”¨ä¸€ä¸ªçº¿æ€§å˜æ¢å¯¹åº”ä¸Šï¼Œæ˜¯å› ä¸ºä¸Šè¿°æ¯ç»„å•ä½å‘é‡çš„æ—‹è½¬æ“ä½œå¯ä»¥ç”¨è¡¨ç¤ºä¸ºä¹˜ä»¥ä¸€ä¸ª 2 x 2 çš„æ—‹è½¬çŸ©é˜µã€‚</p></blockquote><h3><span id="ç‰¹ç‚¹">ç‰¹ç‚¹</span></h3><ol type="1"><li><p>è®­ç»ƒé˜¶æ®µå®Œå…¨å¯å¹¶è¡Œï¼ˆå› ä¸ºdecoderåœ¨è®­ç»ƒæ—¶ç»™ground truthåšä¸ºè¾“å…¥ï¼Œè¿™æ ·ç”Ÿæˆä¸åŒä½ç½®çš„è¯æ˜¯å¯ä»¥å¹¶è¡Œçš„ï¼Œè€Œencoderä¸€æ¬¡å¤„ç†ä¸€æ•´ä¸ªå¥å­ï¼‰</p></li><li><p>è§£å†³ long dependency çš„é—®é¢˜</p><blockquote><p>ä¼ ç»Ÿçš„ç”¨RNNå»ºæ¨¡è¯­è¨€çš„æ—¶åºç‰¹å¾ï¼Œå‰é¢çš„å•è¯ä¿¡æ¯éƒ½ä¾æ¬¡feedåˆ°åé¢ä¸€ä¸ªå•è¯ï¼Œè¿™ç§ä¿¡æ¯çš„å †å æ„Ÿè§‰æœ‰ç‚¹æµªè´¹ï¼Œè€Œä¸”åè€ŒæŠŠä¿¡æ¯ç³…æ‚åœ¨ä¸€èµ·ä¸å¥½åŒºåˆ†ï¼Œè™½ç„¶decoderé˜¶æ®µå¯¹æ¯ä¸ªå•è¯å¯¹åº”çš„encoderè¾“å‡ºä½ç½®åšattentionï¼Œä½†æ¯ä¸ªencoderè¾“å‡ºå·²ç»å¤¹æ‚äº†å‰é¢å•è¯çš„ä¿¡æ¯ã€‚åŒæ—¶å‰é¢å•è¯ä¿¡æ¯å¾€åä¼ ï¼Œèµ°çš„è·¯å¾„æ¯”è¾ƒé•¿ï¼Œä¹Ÿå°±æ˜¯long dependencyçš„é—®é¢˜ï¼Œè™½ç„¶LSTM/GRUè¿™ç§ç»“æ„èƒ½ä¸€å®šç¨‹åº¦ä¸Šè§£å†³ï¼Œä½†æ˜¯æ¯•ç«Ÿä¸èƒ½å®Œå…¨å»æ‰ long dependencyã€‚è€Œconvåœ¨å¤„ç†dependencyé—®é¢˜æ—¶ï¼Œåˆ©ç”¨å·ç§¯çš„æ„Ÿå—é‡receptive fieldï¼Œé€šè¿‡å †å å·ç§¯å±‚æ¥æ‰©å¤§æ¯ä¸ªencoderè¾“å‡ºä½ç½®æ‰€è¦†ç›–å•è¯çš„èŒƒå›´ï¼Œæ¯ä¸ªå•è¯èµ°çš„è·¯å¾„å¤§è‡´æ˜¯logk(n)æ­¥ï¼Œç¼©çŸ­äº†dependencyçš„é•¿åº¦ã€‚è€Œè¿™ç¯‡è®ºæ–‡çš„åšæ³•æ˜¯ç›´æ¥ç”¨encoderæˆ–è€…decoderçš„å±‚ä¸å±‚ä¹‹é—´ç›´æ¥ç”¨attentionï¼Œå¥å­ä¸­çš„å•è¯dependencyé•¿åº¦æœ€å¤šåªæœ‰1ï¼Œå‡å°‘äº†ä¿¡æ¯ä¼ è¾“è·¯å¾„ã€‚è€Œä¸”è¿™ç§attentionçš„æ–¹å¼ç›´æ¥å¯ä»¥æŒ–æ˜å¥å­å†…éƒ¨å•è¯ä¸å•è¯çš„è¯­ä¹‰ç»„åˆå…³ç³»ï¼Œå°†å®ƒä½œä¸ºä¸€ä¸ªè¯­ä¹‰æ•´ä½“ï¼Œä½¿å¾—ç¿»è¯‘æ—¶æ›´å¥½åœ°åˆ©ç”¨å•è¯ç»„åˆç”šè‡³æ˜¯çŸ­è¯­çš„ä¿¡æ¯ï¼Œæ›´å¥½åœ°decodeå‡ºè¯­ä¹‰åŒ¹é…çš„ç›®æ ‡è¯­è¨€å•è¯ï¼ˆè½¬è‡ª<a href="https://www.zhihu.com/question/61077555/answer/183884003" target="_blank" rel="noopener">è°­æ—­</a>ï¼‰</p></blockquote></li></ol><p><img src="/images/path_table.png"></p><h3><span id="å¼€æºä»£ç åˆ†æ">å¼€æºä»£ç åˆ†æ</span></h3><p>ä»£ç æ¥è‡ªï¼šhttps://github.com/jadore801120/attention-is-all-you-need-pytorch</p><p>ä½¿ç”¨ PyTorch æ¡†æ¶</p><p><strong>Encoder</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' A encoder model with self attention mechanism. '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_src_vocab, n_max_seq, n_layers=<span class="number">6</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_head=<span class="number">8</span>, d_k=<span class="number">64</span>, d_v=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         d_word_vec=<span class="number">512</span>, d_model=<span class="number">512</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                 d_inner_hid=<span class="number">1024</span>, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># .....</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src_seq, src_pos)</span>:</span></span><br><span class="line">        <span class="comment"># Word embedding look up</span></span><br><span class="line">        enc_input = self.src_word_emb(src_seq)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Position Encoding addition</span></span><br><span class="line">        enc_input += self.position_enc(src_pos)</span><br><span class="line">        enc_outputs, enc_slf_attns = [], []</span><br><span class="line"></span><br><span class="line">        enc_output = enc_input</span><br><span class="line">        enc_slf_attn_mask = </span><br><span class="line">        get_attn_padding_mask(src_seq, src_seq)</span><br><span class="line">        <span class="comment"># å¯¹æ¯ä¸€å±‚è®¡ç®— encoder output å’Œ self-attention</span></span><br><span class="line">        <span class="keyword">for</span> enc_layer <span class="keyword">in</span> self.layer_stack:</span><br><span class="line">            enc_output, enc_slf_attn = enc_layer(</span><br><span class="line">                enc_output, slf_attn_mask=enc_slf_attn_mask)</span><br><span class="line">            <span class="comment"># æŠŠæ¯å±‚çš„è¾“å‡ºæ·»åŠ åˆ°æ€»è¾“å‡ºåˆ—è¡¨</span></span><br><span class="line">            enc_outputs += [enc_output]</span><br><span class="line">            enc_slf_attns += [enc_slf_attn]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> enc_outputs, enc_slf_attns</span><br></pre></td></tr></table></figure><p><strong>Positional Encoding</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">position_encoding_init</span><span class="params">(n_position, d_pos_vec)</span>:</span></span><br><span class="line">    <span class="string">''' Init the sinusoid position encoding table '''</span></span><br><span class="line"><span class="comment"># å¯¹æ¯ä¸ªä½ç½®è¿›è¡Œç¼–ç ï¼Œä½ç½®0ä¸ºå…¨0ï¼Œå…¶ä»–ä½ç½®æŒ‰ç…§ç›¸åº”å…¬å¼è®¡ç®—</span></span><br><span class="line">    position_enc = np.array([</span><br><span class="line">        [pos / np.power(<span class="number">10000</span>, <span class="number">2</span>*i/d_pos_vec) </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(d_pos_vec)]</span><br><span class="line">        <span class="keyword">if</span> pos != <span class="number">0</span> <span class="keyword">else</span> np.zeros(d_pos_vec) </span><br><span class="line">        <span class="keyword">for</span> pos <span class="keyword">in</span> range(n_position)])</span><br><span class="line"><span class="comment"># dim 2i</span></span><br><span class="line">    position_enc[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(position_enc[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>]) </span><br><span class="line">    <span class="comment"># dim 2i+1</span></span><br><span class="line">    position_enc[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(position_enc[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>]) </span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(position_enc)</span><br></pre></td></tr></table></figure><p><strong>Scaled Dot-Product Attention</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScaledDotProductAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' Scaled Dot-Product Attention '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, attn_dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(ScaledDotProductAttention, self).__init__()</span><br><span class="line">        self.temper = np.power(d_model, <span class="number">0.5</span>)</span><br><span class="line">        self.dropout = nn.Dropout(attn_dropout)</span><br><span class="line">        self.softmax = BottleSoftmax()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, q, k, v, attn_mask=None)</span>:</span></span><br><span class="line">        attn = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>)) / self.temper</span><br><span class="line">        ...</span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        attn = self.dropout(attn)</span><br><span class="line">        output = torch.bmm(attn, v)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attn</span><br></pre></td></tr></table></figure><p>ä»ä¸­å¯è§ï¼Œself-attention æŒ‡ softmax æ“ä½œä¹‹åçš„éƒ¨åˆ†ï¼Œå±‚è¾“å‡ºæ˜¯ <span class="math inline">\(attention \times V\)</span>ã€‚</p><p><strong>Encoder layer</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' Compose with two layers '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_inner_hid, n_head, d_k, d_v,</span></span></span><br><span class="line"><span class="function"><span class="params">                 dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(EncoderLayer, self).__init__()</span><br><span class="line">        self.slf_attn = MultiHeadAttention(</span><br><span class="line">            n_head, d_model, d_k, d_v, dropout=dropout)</span><br><span class="line">        self.pos_ffn = PositionwiseFeedForward(d_model, </span><br><span class="line">                                              d_inner_hid, </span><br><span class="line">                                              dropout=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, enc_input, slf_attn_mask=None)</span>:</span></span><br><span class="line">        <span class="comment"># Q, K, V éƒ½æ˜¯ enc_input</span></span><br><span class="line">        enc_output, enc_slf_attn = self.slf_attn(</span><br><span class="line">            enc_input, enc_input, enc_input,</span><br><span class="line">            attn_mask=slf_attn_mask)</span><br><span class="line">        enc_output = self.pos_ffn(enc_output)</span><br><span class="line">        <span class="keyword">return</span> enc_output, enc_slf_attn</span><br></pre></td></tr></table></figure><p>å¯è§ï¼Œä¼ ç»™ <code>MultiHeadAttention</code> çš„<span class="math inline">\(Q, K, V\)</span> éƒ½æ˜¯ <code>enc_input</code>ã€‚</p><p><strong>Decoder Layer</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' Compose with three layers '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># ....</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, dec_input, enc_output, </span></span></span><br><span class="line"><span class="function"><span class="params">                slf_attn_mask=None, dec_enc_attn_mask=None)</span>:</span></span><br><span class="line">        <span class="comment"># ç¬¬ä¸€ä¸ªattentionå±‚æ¥æ”¶çš„ Q, K, V éƒ½æ˜¯ dec_input</span></span><br><span class="line">        dec_output, dec_slf_attn = self.slf_attn(</span><br><span class="line">            dec_input, dec_input, dec_input, </span><br><span class="line">            attn_mask=slf_attn_mask)</span><br><span class="line">        <span class="comment"># ç¬¬äºŒä¸ªattentionå±‚æ¥æ”¶çš„ Q æ˜¯ dec_outputï¼Œ</span></span><br><span class="line">        <span class="comment"># K å’Œ V æ˜¯ enc_output</span></span><br><span class="line">        dec_output, dec_enc_attn = self.enc_attn(</span><br><span class="line">            dec_output, enc_output, enc_output, </span><br><span class="line">            attn_mask=dec_enc_attn_mask)</span><br><span class="line">        dec_output = self.pos_ffn(dec_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dec_output, dec_slf_attn, dec_enc_attn</span><br></pre></td></tr></table></figure><p><strong>Transformer</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' å®Œæ•´çš„ transformer '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            self, n_src_vocab, n_tgt_vocab, n_max_seq,</span></span></span><br><span class="line"><span class="function"><span class="params">        n_layers=<span class="number">6</span>, n_head=<span class="number">8</span>, d_word_vec=<span class="number">512</span>, d_model=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        d_inner_hid=<span class="number">1024</span>, d_k=<span class="number">64</span>, d_v=<span class="number">64</span>, dropout=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        proj_share_weight=True, embs_share_weight=True)</span>:</span></span><br><span class="line"></span><br><span class="line">        super(Transformer, self).__init__()</span><br><span class="line">        <span class="comment"># åˆå§‹åŒ– encoder</span></span><br><span class="line">        self.encoder = Encoder(</span><br><span class="line">            n_src_vocab, n_max_seq, n_layers=n_layers,</span><br><span class="line">            n_head=n_head, d_word_vec=d_word_vec, </span><br><span class="line">            d_model=d_model, d_inner_hid=d_inner_hid,</span><br><span class="line">            dropout=dropout)</span><br><span class="line">        <span class="comment"># åˆå§‹åŒ– decoder</span></span><br><span class="line">        self.decoder = Decoder(</span><br><span class="line">            n_tgt_vocab, n_max_seq, n_layers=n_layers,</span><br><span class="line">            n_head=n_head, d_word_vec=d_word_vec, </span><br><span class="line">            d_model=d_model, d_inner_hid=d_inner_hid,</span><br><span class="line">            dropout=dropout)</span><br><span class="line">      <span class="comment"># ....</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src, tgt)</span>:</span></span><br><span class="line">        src_seq, src_pos = src</span><br><span class="line">        tgt_seq, tgt_pos = tgt</span><br><span class="line"></span><br><span class="line">        tgt_seq = tgt_seq[:, :<span class="number">-1</span>]</span><br><span class="line">        tgt_pos = tgt_pos[:, :<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># ç¼–ç </span></span><br><span class="line">        enc_outputs, enc_slf_attns = self.encoder(src_seq,</span><br><span class="line">                                                  src_pos)</span><br><span class="line">        <span class="comment"># è§£ç </span></span><br><span class="line">        dec_outputs, dec_slf_attns, dec_enc_attns =</span><br><span class="line">        self.decoder( tgt_seq, tgt_pos, src_seq,</span><br><span class="line">                         enc_outputs)</span><br><span class="line">        dec_output = dec_outputs[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">        seq_logit = self.tgt_word_proj(dec_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> seq_logit.view(<span class="number">-1</span>, seq_logit.size(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> Attention </tag>
            
            <tag> NMT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Question Answering</title>
      <link href="/2017/08/12/Deep%20NLP%20-%20Question%20Answering/"/>
      <url>/2017/08/12/Deep%20NLP%20-%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<p>Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.</p><a id="more"></a><!-- toc --><ul><li><a href="#semantic-parsing">Semantic Parsing</a></li><li><a href="#reading-comprehension">Reading Comprehension</a></li><li><a href="#answer-sentence-selection">Answer Sentence Selection</a></li><li><a href="#visual-question-answering">Visual Question Answering</a></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><p><strong>Questions</strong></p><table><colgroup><col style="width: 46%"><col style="width: 53%"></colgroup><thead><tr class="header"><th style="text-align: left;">Question</th><th style="text-align: left;">answer</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">When were the ï¬rst pyramids built?</td><td style="text-align: left;">2630 BC</td></tr><tr class="even"><td style="text-align: left;">Jean-Claude Juncker</td><td style="text-align: left;">Jean-Claude Juncker is a Luxembourgish politician. Since 2014, Juncker has been President of the European Commission.</td></tr><tr class="odd"><td style="text-align: left;">How old is Keir Starmer?</td><td style="text-align: left;">54 years</td></tr><tr class="even"><td style="text-align: left;">What is the current price for AAPL?</td><td style="text-align: left;">136.50 USD</td></tr><tr class="odd"><td style="text-align: left;">Whatâ€™s the weather like in London?</td><td style="text-align: left;">7 degrees Celsius. Clear with some clouds.</td></tr><tr class="even"><td style="text-align: left;">Whom did Juncker meet with?</td><td style="text-align: left;">The European Commission president was speaking after meeting with Irish Taoiseach Enda Kenny in Brussels.</td></tr><tr class="odd"><td style="text-align: left;">When did you get to this lecture?</td><td style="text-align: left;">Five minutes after it started.</td></tr><tr class="even"><td style="text-align: left;">Why do we yawn?</td><td style="text-align: left;">When weâ€™re bored or tired we donâ€™t breathe as deeply as we normally do. This causes a drop in our blood-oxygen levels and yawning helps us counter-balance that.</td></tr></tbody></table><p><strong>Why do we care about QA ?</strong></p><p>Because <strong>QA is awesome</strong></p><ol type="1"><li><p><strong>QA is an AI-complete problem.</strong></p><p>If we solve QA, we have solved every other problem, too.</p></li><li><p>Many immediate and obvious applications</p><p>Search, dialogue, information extraction, summarisation, ...</p></li><li><p>Some pretty nice results already</p><p>IBM Watson and Jeopardy!, Siri, Google Search ...</p></li><li><p>Lots left to do!</p><p>Plenty of interesting research and hard problems as well as low-hanging fruit.</p></li></ol><p><strong>Data</strong></p><table><colgroup><col style="width: 25%"><col style="width: 37%"><col style="width: 37%"></colgroup><thead><tr class="header"><th>question</th><th>context/source</th><th>answer</th></tr></thead><tbody><tr class="odd"><td>Factual questions</td><td>Sets of documents (corpus)</td><td>A single fact</td></tr><tr class="even"><td>Complex/narrative questions</td><td>A single document</td><td>An explanation</td></tr><tr class="odd"><td>Information Retrieval</td><td>Knowledge Base</td><td>A document</td></tr><tr class="even"><td>Library Reference</td><td>Non-linguistic types of data (GPS, images, sensors, ...)</td><td>A sentence or paragraph extracted from somewhere</td></tr><tr class="odd"><td></td><td></td><td>An image or other type of object</td></tr><tr class="even"><td></td><td></td><td>Another question</td></tr></tbody></table><p><strong>Question Taxonomy</strong></p><p>Many possible taxonomies for questions:</p><ul><li>Wh- words</li><li>Subject of question</li><li>The form of expected answers</li><li>Types of sources from which answers may be drawn</li></ul><p>For the purposes of building QA systems it is useful to start by considering the sources an answer may be drawn from. <strong>Focus on the answer</strong> rather than the question.</p><p><em>Three Questions for building a QA System</em></p><ul><li>What do the answers look like?</li><li>Where can I get the answers from?</li><li>What does my training data look like?</li></ul><p><strong>Areas in Question Answering</strong></p><ul><li>Reading Comprehension<ul><li>Answer based on a document</li><li>Context is a speciï¬c document</li></ul></li><li>Semantic Parsing<ul><li>Answer is a logical form, possible executed against a KB</li><li>Context is a Knowledge Base</li></ul></li><li>Visual QA<ul><li>Answer is simple and factual</li><li>Context is one/multiple image(s)</li></ul></li><li>Information Retrieval<ul><li>Answer is a document/paragraph/sentence</li><li>Context is a corpus of documents</li></ul></li><li>Library Reference<ul><li>Answer is another question</li><li>Context is the structured knowledge available in the library and the librarians view of it.</li></ul></li></ul><h2><span id="semantic-parsing">Semantic Parsing</span></h2><p>Semantic Parsing is the process of mapping natural language into a formal representation of its meaning. Depending on the chosen formalism this <strong>logical representation</strong> can be used to query a <strong>structured knowledge base</strong>.</p><p><img src="/images/NLP/se_par.png"></p><p><em>Semantic Parsing</em> is <strong>Questionâ†’Logical Form.</strong></p><p>We (often mistakenly) then assume that <strong>LFâ†’Answer</strong> is trivial.</p><p><strong>Knowledge Bases for QA with Semantic Parsing</strong></p><p>Knowledge bases typically represent their data as triplesï¼š</p><ul><li>Generally: <em>(relation, entity1, entity2)</em></li><li>(married-to, Michelle Obama, Barack Obama)</li><li>(member-of, United Kingdom, European Union)</li></ul><p>There are several (large) databases freely available to use, e.g.:</p><ul><li><strong>Freebase</strong>: 1.9 billion triples on general knowledge. Defunct as of 2016 and replaced by Google Knowledge Graph</li><li><strong>WikiData</strong>: Information on 25 million entities</li><li><strong>OpenStreetMap</strong>: 3 billion triples on geography</li><li><strong>GeoQuery</strong>: 700 facts about US geography. Tiny dataset, but frequently used in semantic parsing work.</li></ul><p><strong>Supervised Data is expensive!</strong></p><ul><li><strong>Free917</strong>: 917 freebase annotated questions</li><li><strong>GeoQuery</strong>: 880 questions on US geography</li><li><strong>NLMaps</strong>: 2,380 natural language queries on the OSM data</li></ul><p>These kinds of datasets are incredibly expensive to create as they require experts for the manual annotation process, who are trained in using a given database schema:</p><ul><li><p>â€œ<em>Where are kindergartens in Hamburg?</em>â€</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query(area(keyval(name,Hamburg)), nwr(keyval(amenity,kindergarten)), qtype(latlong))</span><br></pre></td></tr></table></figure></li></ul><p><strong>A Deep Learning Approach to Semantic Parsing</strong></p><p>Semantic parsing can be viewed as a sequence to sequence model, not unlike <strong>machine translation</strong>.</p><p><img src="/images/NLP/dl_sen.png"></p><p>Details</p><ul><li>âœ… Encode sentence with sequence models</li><li>âœ… Decode with standard mechanisms from MT</li><li>âŒ Supervised training data hard to come by</li><li>âŒ Depending on formalism used, highly complex target side</li><li>âŒ How to deal with proper nouns and numbers?</li></ul><p><strong>One Solution to Sparsity: Avoid Logical Forms</strong></p><p>Semantic parsing frequently reduce the reliance on supervised data (language-logical form) by exploiting other types of data such as <strong>question-answer pairs</strong> or corpora of <strong>questions only</strong>.</p><blockquote><p>Berant et al. (2013): Semantic Parsing on Freebase from QA Pairs Reddy et al. (2014): Large-scale Semantic Parsing without QA Pairs</p></blockquote><p><img src="/images/NLP/graph.png"></p><p><strong>Improved Neural Semantic Parsing</strong></p><p>We can apply the same idea to neural semantic parsing, and further take mechanisms from <strong>machine translation</strong> to improve performance and data eï¬ƒciency:</p><ul><li>Like in MT, using attention can be helpful<ul><li>Dong and Lapata (2016): Language to Logical Form with Neural Attention</li></ul></li><li>Exploit the highly rigid structure in the target side to constrain generation<ul><li>Liang et al. (2016): Neural Symbolic Machines</li><li>Ling et al. (2016): Latent predictor networks for code generation</li></ul></li><li>Make use of semi-supervised training to counter sparsity<ul><li>Kocisky et al. (2016): Semantic Parsing with Semi-Supervised Sequential Autoencoders</li></ul></li></ul><p><em>Generation with multiple sources</em></p><blockquote><p>Ling et al. (2016): Latent predictor networks for code generation</p></blockquote><p><img src="/images/NLP/multi_src.png"></p><p><strong>Semantic Parsing Summary</strong></p><ul><li>âœ… LF instead of answer makes system robust</li><li>âœ… Answer independent of question and parsing mechanism</li><li>âœ… Can deal with rapidly changing information</li><li>âŒ Constrained to queriable questions in DB schema</li><li>âŒ No database is large enough</li><li>âŒ Training data hard to ï¬nd</li></ul><p><em>Questions</em></p><ul><li>âœ… When were the pyramids built?</li><li>â“ Jean-Claude Juncker</li><li>âœ… How old is Keir Starmer?</li><li>âœ… What is the price for AAPL?</li><li>âœ… Whatâ€™s the weather in London?</li><li>âŒ Whom did Juncker meet with?</li><li>âŒ When did you get here?</li><li>âŒ Why do we yawn?</li></ul><p>Caveat: Each of these examples requires a <strong>diï¬€erent</strong> underlying KB!</p><h2><span id="reading-comprehension">Reading Comprehension</span></h2><p>Answer a question related to a given document.</p><p><strong>Corpora for Reading Comprehension</strong></p><ul><li><strong>CNN/DailyMail</strong>: Over 1 million cloze form QA pairs with articles from CNN and Mail online for context. Pick an anonymised entity.</li><li><strong>CBT</strong>: 700k QA pairs, childrenâ€™s books as context. Pick one of 10 candidates.</li><li><strong>SQuAD</strong>: 100k manual QA pairs with 500 Wikipedia articles for context. Answer is a span.</li></ul><p>Assumptions made in all of the above tasks</p><ul><li>Context is read on the ï¬‚y and unknown during training phase</li><li>Answer is contained in the context as a single word or span</li><li>This constraint does not hold for reading comprehension in general!</li></ul><p><em>CNN article Example</em></p><ul><li>Document<ul><li>The BBC producer allegedly struck by Jeremy Clarkson will not press charges against the â€œTop Gearâ€ host, his lawyer said Friday. Clarkson, who hosted one of the most-watched television shows in the world, was dropped by the BBC Wednesday after an internal investigation by the British broadcaster found he had subjected producer Oisin Tymon â€œto an unprovoked physical and verbal attack.â€ . . .</li></ul></li><li>Query<ul><li>Producer X will not press charges against Jeremy Clarkson, his lawyer says.</li></ul></li><li>Answer<ul><li>Oisin Tymon</li></ul></li></ul><p>We formulate <em>Cloze style</em> queries from the story paraphrases.</p><p>Out of vocabulary (OOV) and proper nouns are dealt with by <strong>replacing all entities with anonymised markers</strong>. This greatly reduces the vocabulary size.</p><ul><li><p>Document</p><ul><li><p>the ent381 producer allegedly struck by ent212 will not press</p><p>charges against the â€œ ent153 â€ host , his lawyer said friday . ent212 , who hosted one of the most - watched television shows in the world , was dropped by the ent381 wednesday after an internal investigation by the ent180 broadcaster found he had subjected producer ent193 â€œ to an unprovoked physical and verbal attack . â€ . . .</p></li></ul></li><li><p>Query</p><ul><li>Producer X will not press charges against ent212 , his lawyer says .</li></ul></li><li><p>Answer</p><ul><li>ent193</li></ul></li></ul><p><strong>A Generic Neural Model for Reading Comprehension</strong></p><p>Given context <span class="math inline">\(d\)</span> and question <span class="math inline">\(q\)</span>, the probability of an answer <span class="math inline">\(a\)</span> can be represented as: <span class="math display">\[p(a|q, d) \varpropto \exp(W(a)g(q, d)), \ \ s.t.a \in V\]</span> Details</p><ul><li>âœ… Encode question and context with sequence models</li><li>âœ… Combine <span class="math inline">\(q\)</span> and <span class="math inline">\(d\)</span> with an MLP or attention <span class="math inline">\(g\)</span></li><li>âœ… Select answer from attention map, by using a classiï¬er, or with generative setup</li><li>âŒ How to deal with out of vocabulary (OOV) terms?</li><li>âŒ How to deal with proper nouns and numbers?</li></ul><p><img src="/images/NLP/rc_attn.png"></p><ul><li>Read (encode) context document and question</li><li>Use question to attend to context</li><li>Use joint representation to generate answer<ul><li>Predict based on attention map</li><li>Generate conditioned on joint representation</li><li>Classify over set of candidate answers</li></ul></li></ul><p>Denote the outputs of a bidirectional LSTM as <span class="math inline">\(\overrightarrow{y(t)}\)</span> and <span class="math inline">\(\overleftarrow{y(t)}\)</span>. Form two encodings, one for the query and one for each token in the document, <span class="math display">\[u = \overrightarrow{y_q}(|q|)\ ||\ \overleftarrow{y_q}(1),\ \ y_d(t) = \overrightarrow{y_d}(t)\ ||\ \overleftarrow{y_d}(t)\]</span> The representation <span class="math inline">\(r\)</span> of the document <span class="math inline">\(d\)</span> is formed by a weighted sum of the token vectors. The weights are interpreted as the modelâ€™s attention, <span class="math display">\[\begin{alignat}{3}m(t) &amp;= \tanh(W_{ym}y_d(t)+W_{um}u) \\s(t) &amp;\varpropto \exp(w_{ms}^Tm(t)) \\r &amp;= y_ds \\\end{alignat}\]</span> Deï¬ne the joint document and query embedding via a non-linear combination: <span class="math display">\[g^{AR}(d, q) = \tanh(W_{rg}r+W_{ug}u)\]</span> Training</p><p><img src="/images/NLP/traing.png"></p><p>Models were trained using asynchronous minibatch stochastic gradient descent (RMSProp) on approximately 25 GPUs.</p><p><em>Attention Sum Reader</em></p><blockquote><p>Kadlec et al. (2016), Text Understanding with the Attention Sum Reader Network</p></blockquote><p>The model can be modiï¬ed to make use of the fact that <strong>the answer is a word from the context document</strong>. Now we calculate the probability of the answer being in position <span class="math inline">\(i\)</span> of the context: <span class="math display">\[p(i|q, d)  \varpropto \exp(f_i(d)\cdot g(q))\]</span> Positional probabilities can then be summed to form token-based probabilities: <span class="math display">\[P(w|q, d) \varpropto \sum_{i(w,d)}P(i|q,d)\]</span> The rest of the model is equivalent to the attentive reader model presented before.</p><p><strong>Reading Comprehension Summary</strong></p><ul><li>âœ… Ask questions in context</li><li>âœ… Easily used in discriminative and generative fashion</li><li>âœ… Large datasets available</li><li>âŒ Constraint on context often artiï¬cial</li><li>âŒ Many types of questions unanswerable</li></ul><p><em>Questions</em></p><ul><li>â“ When were the pyramids built?</li><li>â“ Jean-Claude Juncker</li><li>â“ How old is Keir Starmer?</li><li>â“ What is the price for AAPL?</li><li>â“ Whatâ€™s the weather in London?</li><li>âœ… Whom did Juncker meet with?</li><li>âŒ When did you get here?</li><li>âŒ Why do we yawn?</li></ul><p>Caveat: Need context for any of these, and incredibly up-to-date context for some of these.</p><h2><span id="answer-sentence-selection">Answer Sentence Selection</span></h2><p><img src="/images/NLP/trump.jpg"></p><p><strong>Answer Sentence Selection</strong> describes the task of picking a suitable sentence from a corpus that can be used to answer a question.</p><ul><li><strong>Questions</strong>: Factual questions, possibly with context</li><li><strong>Data Source</strong>: â€œThe Webâ€ or the output of some IR system</li><li><strong>Answer</strong>: One or several excerpts pertinent to the answer</li></ul><p>The answer is <strong>guaranteed to be extracted</strong>, while in reading comprehension it could be either generated or extracted.</p><p><strong>Data Corpora</strong></p><ul><li><strong>TREC QA track (8-13)</strong>: Several hundred manually-annotated question answer pairs with around 20 candidates per instance.</li><li><strong>MS MARCO</strong>: 100k question-answer pairs with 10 contextual passages each. Can also be used as a QA dataset for reading comprehension.</li></ul><p>Likewise, answer sentence selection plays a role in any information retrieval setup, and datasets from IR and other QA tasks can easily be converted into answer selection style datasets.</p><p><em>A Neural Model for Answer Sentence Selection</em></p><blockquote><p>Yu et al., 2014</p></blockquote><p>We need to compute the probability of an answer candidate <span class="math inline">\(a\)</span> and a question <span class="math inline">\(q\)</span> matching. Note that this is diï¬€erent from the previous task as we now calculate that score independently of all other candidates: <span class="math display">\[p(y=1|q, a) = \sigma(q^TMa + b)\]</span> <img src="/images/NLP/ass.png"></p><p><strong>Evaluation</strong></p><p>Unlike single entity style QA where we can use a simple accuracy measure, tasks such as answer sentence selection require more specialised metrics for evaluating model performance.</p><table><colgroup><col style="width: 20%"><col style="width: 40%"><col style="width: 40%"></colgroup><thead><tr class="header"><th>measure</th><th>description</th><th>formula</th></tr></thead><tbody><tr class="odd"><td>Accuracy</td><td>Binary measure</td><td>#true/#toal</td></tr><tr class="even"><td>Mean Reciprocal Rank</td><td>Measures position of ï¬rst relevant document in return set.</td><td><span class="math inline">\(\frac{1}{\|Q\|}\sum_{i=1}^{\|Q\|}\frac{1}{rank_i}\)</span></td></tr><tr class="odd"><td>BLEU Score</td><td>Machine Translation measure for translation accuracy</td><td>complicated</td></tr></tbody></table><p><strong>Answer Selection Summary</strong></p><ul><li>âœ… Designed to deal with large amounts of context</li><li>âœ… More robust than â€˜trueâ€™ QA systems as it turns provides context with its answers</li><li>âœ… Obvious pipeline step between IR and QA</li><li>âŒ Does not provide answers, provides context only</li><li>âŒ Real-world use depends on underlying IR pipeline</li></ul><p><em>Questions</em></p><ul><li>âœ… When were the pyramids built?</li><li>âœ… Jean-Claude Juncker</li><li>âœ… How old is Keir Starmer?</li><li>âŒ What is the price for AAPL?</li><li>âŒ Whatâ€™s the weather in London?</li><li>â“ Whom did Juncker meet with?</li><li>âŒ When did you get here?</li><li>âœ… Why do we yawn?</li></ul><p>Note: Things like age or stock price may produce answers, but with no guarantee of accuracy (any mention of any AAPL price might be a good ï¬t).</p><h2><span id="visual-question-answering">Visual Question Answering</span></h2><p>Sometimes questions require context outside of pure language.</p><p><img src="/images/NLP/visual.jpg"></p><p><strong>Task and Corpora</strong></p><p>In recent years a number of visual QA datasets have sprung up. Some of the more popular ones include:</p><ul><li><strong>VisualQA</strong>: Agrawal et al. (2015)</li><li><strong>VQA 2.0</strong> Goyal et al. (2016)</li><li><strong>COCO-QA</strong> Ren et al. (2015)</li></ul><p>Details between these datasets vary, but the basic organisation remains the same of images paired with simple questions and answers (either free form or from a list of options).</p><p>All of these are reasonably large (100ks of images, over 1M questions).</p><p><strong>Visual QA</strong></p><ul><li>Question is language â†’ some encoder</li><li>Context is a single picture â†’ convolutional network</li><li>Answer is a single word â†’ classiï¬er function</li></ul><p>We have covered all the components already:</p><p><img src="/images/NLP/visualQA.jpg"></p><p><strong>Blind Model</strong></p><blockquote><p>Goyal et al. (2016)</p></blockquote><p><em>Ignoring the images is a good baseline!</em></p><ul><li>What colour is the cat?</li><li>How many chairs are around the table?</li><li>What furniture is in the bedroom?</li><li>Where is the person sleeping?</li></ul><p>We can get reasonably good guesses in at many of these questions without seeing an image for context.</p><p><strong>Attention Methods for Visual QA</strong></p><blockquote><p>Yang et al. (2015): Stacked Attention Networks for Image Question Answering</p></blockquote><p>Viewing VQA from the perspective of our default QA paradigm, there is signiï¬cant overlap with reading comprehension style models. We use similar techniques to improve performance.</p><p>We can use attention on visual representations:</p><p><img src="/images/NLP/attn_vqa.png"></p><p><img src="/images/NLP/vqa_eg.jpg"></p><p><strong>VIisual Question Answering Summary</strong></p><ul><li>âœ… Extra modality â€˜for freeâ€™</li><li>âœ… Plenty of training data available as of recently</li><li>âŒ Currently quite gimmicky</li><li>âŒ Still a long way to go</li></ul><p><em>Questions</em></p><ul><li>âŒ When were the pyramids built?</li><li>âŒ Jean-Claude Juncker</li><li>âŒ How old is Keir Starmer?</li><li>âŒ What is the price for AAPL?</li><li>â“ Whatâ€™s the weather in London?</li><li>âŒ Whom did Juncker meet with?</li><li>âŒ When did you get here?</li><li>âŒ Why do we yawn?</li></ul><h2><span id="summary">Summary</span></h2><p><strong>How to build your own QA system ?</strong></p><p>Build a QA model in seven questions</p><ul><li>What is the task?</li><li>What do question, answer and context look like?</li><li>Where does the data come from?</li><li>Can you augment the data?</li><li>How to encode question and context?</li><li>How to combine question and context?</li><li>How to predict or generate an answer?</li></ul><p>There are plenty of open questions left in QA. Just remember to <strong>start with the data</strong>!</p><p><em>Sources and Further Reading</em></p><ul><li><strong>Question Answering Theory and Datasets</strong><ul><li>Pomerantz (2005), A Linguistic Analysis of Question Taxonomies</li><li>Nguyen et al. (2016), MS MARCO: A Human Generated Machine Reading Comprehension Dataset</li><li>Haas and Riezler (2016), A Corpus and Semantic Parser for Multilingual Natural Language Querying of OpenStreetMap</li></ul></li><li><strong>Semantic Parsing</strong><ul><li>Artzi et al. (2013), Semantic Parsing with CCG</li><li>Berant et al. (2013), Semantic Parsing on Freebase from Question-Answer Pairs</li><li>http://nlp.stanford.edu/software/sempre/</li></ul></li><li><strong>Reading Comprehension</strong><ul><li>Hermann et al. (2015), Teaching Machines to Read and Comprehend</li><li>Kadlec et al. (2016), Text Understanding with the Attention Sum Reader Network</li></ul></li><li><strong>Visual QA</strong><ul><li>Yang et al. (2015), Stacked Attention Networks for Image Question Answering</li><li>Ren et al. (2015), Exploring Models and Data for Image Question Answering</li><li>Goyal et al. (2016), Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering.</li><li>https://avisingh599.github.io/deeplearning/visual-qa/</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> Attention </tag>
            
            <tag> QA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Speech Recognition</title>
      <link href="/2017/08/10/Deep%20NLP%20-%20Speech%20Recognition/"/>
      <url>/2017/08/10/Deep%20NLP%20-%20Speech%20Recognition/</url>
      
        <content type="html"><![CDATA[<p>Speech recognition (SR) is the inter-disciplinary sub-field of computational linguistics that develops methodologies and technologies that enables the recognition and translation of spoken language into text by computers. <a id="more"></a></p><!-- toc --><ul><li><a href="#speech-recognition">Speech recognition</a><ul><li><a href="#acoustic-representation">Acoustic representation</a></li><li><a href="#phonetic-representation">Phonetic representation</a></li><li><a href="#history">History</a></li><li><a href="#probabilistic-speech-recognition">Probabilistic speech recognition</a></li></ul></li><li><a href="#neural-network-speech-recognition">Neural network speech recognition</a><ul><li><a href="#hybrid-neural-networks">Hybrid neural networks</a></li><li><a href="#traning-losses">Traning losses</a></li><li><a href="#sequence-discriminative-training">Sequence discriminative training</a></li><li><a href="#new-architectures">New architectures</a></li></ul></li></ul><!-- tocstop --><h2><span id="speech-recognition">Speech recognition</span></h2><p>Speech problems</p><ul><li><strong>Automatic speech recognition</strong><ul><li>Spontaneous vs read speech</li><li>Large vocabulary</li><li>In noise</li><li>Low resource</li><li>Far-field</li><li>Accent-independent</li><li>Speaker-adaptive</li></ul></li><li>Text to speech<ul><li>Low resource</li><li>Realistic prosody</li></ul></li><li>Speaker identification</li><li>Speech enhancement</li><li>Speech separation</li></ul><h3><span id="acoustic-representation">Acoustic representation</span></h3><p><strong>Speech physical realization</strong></p><ul><li>Waves of changing air pressure.</li><li>Realised through excitation from the vocal cords</li><li>Modulated by the vocal tract.</li><li>Modulated by the articulators (tongue, teeth, lips)</li><li>Converted to Voltage with a microphone</li><li>Sampled with an <em>Analogue to Digital Converter</em></li><li>Human hearing is 50Hz-20kHz</li><li>Human speech is 85Hzâ€“8kHz</li><li>Contemporary speech processing mostly around 16kHz 16bits/sample</li></ul><p>We want a <strong>low-dimensionality</strong> representation, invariant to speaker, background noise, rate of speaking etc.</p><ul><li>Fourier analysis shows energy in diï¬€erent frequency bands</li><li>windowed short-term fast Fourier transform (FFT)</li><li>e.g. FFT on overlapping 25ms windows (400 samples) taken every 10ms<ul><li>Energy vs frequency [discrete] vs time [discrete]</li><li>can hadle it as images</li></ul></li></ul><p><img src="/images/NLP/fft.png"></p><p><strong>Mel frequency representation</strong></p><ul><li><p>FFT is still too high-dimensional for conventional ASR system</p></li><li><p>Downsample by local weighted averages on <a href="https://www.wikiwand.com/zh-hans/%E6%A2%85%E5%B0%94%E5%88%BB%E5%BA%A6" target="_blank" rel="noopener">mel scale</a> non-linear spacing, and take a log. <span class="math display">\[m = 1127\ln(1+\frac{f}{700})\]</span></p></li><li><p>Result in log-mel features (default for neural network speech modelling.)</p></li><li><p>40+ dimensional features per frame</p><p><img src="/images/NLP/freq.png"></p></li></ul><p><strong>MFCC</strong></p><p><strong>Mel Frequency Cepstral Coeï¬ƒcients</strong> - MFCCs are the <a href="https://www.wikiwand.com/zh-hans/%E9%9B%A2%E6%95%A3%E9%A4%98%E5%BC%A6%E8%BD%89%E6%8F%9B" target="_blank" rel="noopener">discrete cosine transformation</a> of the mel ï¬lterbank energies. Whitened and low-dimensional.</p><ul><li>Similar to Principal Components of log spectra</li><li>GMM speech recognition systems may use 13 MFCCs</li></ul><p><strong>Perceptual Linear Prediction</strong> â€“ a common alternative representation.</p><p><strong>Frame stacking</strong>- itâ€™s common to concatenate several consecutive frames.</p><ul><li>e.g. 26 for fully-connected DNN. 8 for LSTM.</li></ul><p>GMMs used local diï¬€erences (deltas) and second-order diï¬€erences (delta-deltas) to capture dynamics. (13 + 13 + 13 dimensional). Ultimately use <strong>39 dimensional</strong> <a href="https://www.wikiwand.com/zh-hans/%E7%B7%9A%E6%80%A7%E5%88%A4%E5%88%A5%E5%88%86%E6%9E%90" target="_blank" rel="noopener">linear discriminant analysis</a> ( class-aware PCA) projection of 9 stacked MFCC vectors.</p><h3><span id="phonetic-representation">Phonetic representation</span></h3><p>Speech evolved as communication to convey information, consists of sentences (in ASR we usually talk about â€œutterancesâ€). Sentences composed of words.</p><p>Minimal unit is a â€œ<strong>phoneme</strong>â€</p><ul><li>Minimal unit that distinguishes one word from another</li><li>Set of 40-60 distinct sounds</li><li>Vary per language</li><li>Universal representations<ul><li>IPA: international phonetic alphabet</li><li>X-SAMPA (ASCII)</li></ul></li></ul><p>Homophones</p><ul><li>distinct words with the same pronunciation: â€œthereâ€ vs â€œtheirâ€</li></ul><p>Prosody</p><ul><li>How something is said can convey meaning.</li></ul><p><strong>Datasets</strong></p><ul><li>TIMIT<ul><li>Hand-marked phone boundaries given</li><li>630 speakers Ã— 10 utterances</li></ul></li><li>Wall Street Journal (WSJ) 1986 Read speech. WSJ0 1991, 30k vocab</li><li>Broadcast News (BN) 1996 104 hours</li><li>Switchboard (SWB) 1992. 2000 hours spontaneous telephone speech 500 speakers</li><li>Google voice search<ul><li>anonymized live traï¬ƒc 3M utterances 2000 hours</li><li>hand-transcribed 4M vocabulary.</li><li>Constantly refreshed, synthetic reverberation + additive noise</li></ul></li><li>DeepSpeech 5000h read (Lombard) speech + SWB with additive noise.</li><li>YouTube 125,000 hours aligned captions (Soltau et al., 2016)</li></ul><h3><span id="history">History</span></h3><ul><li>1960s Dynamic Time Warping</li><li>1970s Hidden Markov Models</li><li>Multi-layer perceptron 1986</li><li>Speech recognition with neural networks 1987â€“1995</li><li>Superseded by GMMs 1995â€“2009</li><li>Neural network features 2002â€“</li><li>Deep networks 2006â€“ (Hinton, 2002)</li><li>Deep networks for speech recognition<ul><li>Good results on TIMIT (Mohamed et al., 2009)</li><li>Results on large vocabulary systems 2010 (Dahl et al., 2011)</li><li>Google lunches DNN ASR product 2011</li><li>Dominant paradigm for ASR 2012 (Hinton et al., 2012)</li></ul></li><li>Recurrent networks for speech recognition 1990, 2012-<ul><li>New models (attention, LAS, neural transducer)</li></ul></li></ul><h3><span id="probabilistic-speech-recognition">Probabilistic speech recognition</span></h3><p>Speech signal represented as an observation sequence <span class="math inline">\(o = \{o_t\}\)</span>, we want to ï¬nd the <strong>most likely</strong> word sequence <span class="math inline">\(\hat{w}\)</span>.</p><p>We model this with a <strong>Hidden Markov Model</strong>.</p><ul><li><p>The system has a set of discrete states, transitions from state to state according to <strong>transition probabilities</strong> (Markovian: memoryless)</p></li><li><p>Acoustic observation when making a transition is conditioned on state alone. <span class="math inline">\(P(o_t|c_t)\)</span></p></li><li><p>We seek to recover the <strong>state sequence</strong> and consequently the phoneme sequence and consequently the word sequence.</p><p><img src="/images/NLP/hmm.png"></p></li></ul><p>We choose the decoder output as the most likely sequence <span class="math inline">\(\hat{w}\)</span> from all possible sequences, <span class="math inline">\(Î£âˆ—\)</span>, for an observation sequence <span class="math inline">\(o\)</span>: <span class="math display">\[\begin{align}\hat{w} &amp; = \arg\max_{w\in\sum*}P(w|o) \\&amp; = \arg\max_{w\in\sum*}P(o|w)P(w) \\\end{align}\]</span> A product of <em>Acoustic model</em> and <em>Language model</em> scores. <span class="math display">\[P(o|w) = \sum_{d,c,p}P(o|c)P(c|p)P(p|w)\]</span> Where <span class="math inline">\(p\)</span> is the phone sequence and <span class="math inline">\(c\)</span> is the state sequence.</p><p>We can model word sequences with a language model: <span class="math display">\[P(w_1, w_2, ..., w_N) = P(w_0)\prod P(w_i|w_0, ..., w_{i-1})\]</span> <strong>Speech recognition as transduction</strong></p><p><img src="/images/NLP/tranduction.png"></p><p><strong>Lexicon</strong>: phoneme to word</p><p>Construct graph using <strong>Weighted Finite State Transducers (WFST)</strong>.</p><p><img src="/images/NLP/lexicon.png"></p><p>Compose Lexicon FST with Grammar FST <span class="math inline">\(L \circ G\)</span>.</p><p><img src="/images/NLP/FST.png"></p><p><em>Phonetic Unites</em></p><ul><li>Phonemes: â€œcatâ€ â†’ /K/, /AE/, /T/</li><li>Context independent HMM states <span class="math inline">\(k1, k2...\)</span></li><li>Context dependent states</li><li>Context dependent phones</li><li>Diphones (pairs of half-phones)</li><li>Syllables</li><li>Word-parts cf Machine translation (Wu et al., 2016)</li><li>Characters (graphemes)</li><li>Whole words Sak et al. (2014a, 2015); Soltau et al. (2016)<ul><li>Hard to generalize to rare words</li></ul></li></ul><p>Choice depends on language, size of dataset, task, resources available.</p><p><strong>The difference between Phone and Phoneme</strong></p><blockquote><p>A <a href="http://en.wikipedia.org/wiki/Phoneme" target="_blank" rel="noopener"><strong>phoneme</strong></a> is the <strong>smallest structural unit</strong> that distinguishes <strong>meaning in a language</strong>. Phonemes are not the physical segments themselves, but are cognitive abstractions or categorizations of them.</p><p>On the other hand, <a href="http://en.wikipedia.org/wiki/Phone_(phonetics)" target="_blank" rel="noopener"><strong>phones</strong></a> refer to the instances of phonemes in the actual <strong>utterances</strong> - i.e. the physical segments.</p><p>For example:</p><blockquote><p>the words &quot;madder&quot; and &quot;matter&quot; obviously are composed of distinct <em>phonemes</em>; however, in american english, both words are pronounced almost identically, which means that their <em>phones</em> are the same, or at least very close in the acoustic domain.</p></blockquote></blockquote><p><strong>Context dependent phonetic clustering</strong></p><p>A phoneâ€™s realization depends on the preceding and following context, could improve discrimination if we model diï¬€erent contextual realizations separately:</p><ul><li>AE preceded by K, followed by T: AE+T-K</li></ul><p>But, if we have 42 phones, and 3 states per phone, there are <span class="math inline">\(3 Ã— 42^3\)</span> context-dependent phones, But most of these won't be observed.</p><p>So <em>cluster</em> â€“ group together similar distributions and train a joint model. Have a â€œback-oï¬€â€ rule to determine which model to use for unobserved contexts. Usually a decision tree.</p><p><strong>Gaussian Mixture Models (GMM)</strong></p><ul><li>Dominant paradigm for ASR from 1990 to 2010</li></ul><p>Model the probability distribution of the acoustic features for each state: <span class="math display">\[P(o_t|c_i) = \sum_j w_{ij}N(o_t;\mu_{ij}, \sigma_{ij})\]</span> Often use <strong>diagonal covariance Gaussians</strong> to keep number of parameters under control.</p><p>Train by the E-M algorithm (Dempster et al., 1977) alternating:</p><ul><li>M: <em>forced alignment</em> computing the maximum-likelihood state sequence for each utterance</li><li>E: parameter <span class="math inline">\((Âµ, Ïƒ)\)</span> estimation</li></ul><p>Complex training procedures to incrementally ï¬t increasing numbers of components per mixture.</p><ul><li>More components, better ï¬t. 79 parameters / component.</li></ul><p>Given an alignment mapping audio frames to states, this is parallelizable by state. But hard to share parameters / data across states.</p><p><em>Forced alignment</em></p><p>Forced alignment uses a model to compute the <strong>maximum likelihood alignment</strong> between speech features and phonetic states. For each training utterance, construct the set of phonetic states for the ground truth transcription. Use Viterbi algorithm to ï¬nd ML monotonic state sequence under constraints such as at least one frame per state. Results in a phonetic label for each frame, which can give hard or soft segmentation.</p><p><img src="/images/NLP/force.png"></p><p>With a transducer with states <span class="math inline">\(ci\)</span>:</p><p><img src="/images/NLP/HMM.png"></p><p>Compute state likelihoods at time <span class="math inline">\(t\)</span>: <span class="math display">\[P(o_{1, ...., t}|c_i) = \sum_j P(o_t|c_j)P(o_{1, ..., t}|c_j)P(c_j|c_i)\]</span> With transition probabilities: <span class="math inline">\(P(c_i|c_j)\)</span>, find the best path: <span class="math display">\[P(o_{1, ..., t}|c_i) = \max_j P(o_t|c_j)P(o_{1, ..., t}|c_j)P(c_i|c_j)\]</span> I do not quite understand the image below actually:</p><p><img src="/images/NLP/fa.png"></p><p><strong>Decoding</strong></p><p>Speech recognition <strong>unfolds</strong> in much the same way. Now we have a graph instead of a straight-through path.</p><ul><li>Optional silences between words</li><li>Alternative pronunciation paths.</li></ul><p>Typically use max probability, and work in the log domain. Hypothesis space is huge, so we only keep a â€œbeamâ€ of the best paths, and can lose what would end up being the true best path.</p><p><img src="/images/NLP/unfolds.png"></p><h2><span id="neural-network-speech-recognition">Neural network speech recognition</span></h2><p><strong>Two main paradigms</strong></p><ul><li>Use neural networks to compute nonlinear feature representations.<ul><li>â€œBottleneckâ€ or â€œtandemâ€ features (Hermansky et al., 2000)</li><li>Low-dimensional representation is modelled conventionally with GMMs.</li><li>Allows all the GMM machinery and tricks to be exploited.</li></ul></li><li>Use neural networks to estimate phonetic unit probabilities.</li></ul><p><strong>Neural network features</strong></p><p>Train a neural network to <strong>discriminate classes</strong>. Use output or a low-dimensional <em>bottleneck layer</em> representation as features.</p><p><img src="/images/NLP/bottn.png"></p><ul><li>TRAP: Concatenate PLP-HLDA features and NN features.</li><li>Bottleneck outperforms posterior features (Grezl et al., 2007)</li><li>Generally DNN features + GMMs reach about the same performance as hybrid DNN-HMM systems, but are much more complex.</li></ul><h3><span id="hybrid-neural-networks">Hybrid neural networks</span></h3><p>Train the network as a classiï¬er with a softmax across the phonetic units. Train with cross-entropy. Softmax will converge to posterior across phonetic states: <span class="math inline">\(P(c_i|o_i)\)</span>.</p><p>Now we model <span class="math inline">\(P(o|c)\)</span> with a Neural network instead of a Gaussian Mixture model. Everything else stays the same. <span class="math display">\[P(o|c) = \prod_{t}P(o_t|c_t)\]</span></p><p><span class="math display">\[\begin{align}P(o_t|c_t) &amp; = \frac{P(c_t|o_t)P(o_t)}{P(c_t)} \\&amp; \varpropto  \frac{P(c_t|o_t)}{P(c_t)} \\\end{align}\]</span></p><p>For observations <span class="math inline">\(o_t\)</span> at time <span class="math inline">\(t\)</span> and a CD state sequence <span class="math inline">\(c_t\)</span>. We can ignore <span class="math inline">\(P(o_t)\)</span> since it is the same for all decoding paths.</p><p>The last term is called the â€œ<strong>scaled posterior</strong>â€: <span class="math display">\[\log P(o_t|c_t) = \log P(c_t|o_t) - \alpha \log P(c_t)\]</span> Empirically (by cross validation) we actually ï¬nd better results with a â€œ<strong>prior smoothing</strong>â€ term <span class="math inline">\(Î± â‰ˆ 0.8\)</span>.</p><p><strong>Input features</strong></p><p>Neural networks can handle high-dimensional features with correlated features. Use (26) stacked ï¬lterbank inputs. (40-dimensional mel-spaced ï¬lterbanks).</p><p>Example ï¬lters learned in the ï¬rst layer of a fully-connected network:</p><p><img src="/images/NLP/eg_inp.png"></p><ul><li>(33 x 8 ï¬lters. Each subimage 40 frequency vs 26 time.)</li></ul><p><strong>Network architectures</strong></p><ul><li>Fully connected</li><li>CNN<ul><li>Time delay neural networks<ul><li>Waibel et al. (1989)</li><li>Dilated convolutions</li></ul></li><li>CNNs in time or frequency domain. Abdel-Hamid et al. (2014); Sainath et al. (2013)</li><li>Wavenet (van den Oord et al., 2016)</li></ul></li><li>RNN<ul><li>RNN (Robinson and Fallside, 1991)</li><li>LSTM Graves et al. (2013)</li><li>Deep LSTM-P Sak et al. (2014b)</li><li>CLDNN (right) (Sainath et al., 2015a)</li><li>GRU. DeepSpeech 1/2 (Amodei et al., 2015)</li><li>Bidirectional (Schuster and Paliwal, 1997) helps, but introduces latency.</li><li>Dependencies not long at speech frame rates (100Hz).</li><li>Frame stacking and down-sampling help.</li></ul></li></ul><p><em>Human parity in speech recognition (Xiong et al., 2016)</em></p><ul><li>Ensemble of BLSTMs</li><li>i-vectors for speaker normalization<ul><li>i-vector is an embedding of audio trained to discriminate between speakers. (Speaker ID)</li></ul></li><li>Interpolated n-gram + LSTM language model.</li><li>5.8% WER on SWB (vs 5.9% for human).</li></ul><h3><span id="traning-losses">Traning losses</span></h3><p><em>Cross Entropy Training</em></p><ul><li><p>GMMs were trained with <em>Maximum Likelihood</em></p></li><li><p>Conventional training uses Cross-Entropy loss. <span class="math display">\[L_{X\ ENT}(o_t, \theta) = \sum_{i=1}^Ny_t(i)\log\frac{y_t(i)}{\hat{y_t}(i)}\]</span></p></li><li><p>With large data we can use Viterbi (binary) targets: <span class="math inline">\(y_t âˆˆ {0, 1}\)</span></p><ul><li>âˆ’ i.e. a hard alignment.</li></ul></li><li><p>Can also use a soft (Baum-Welch) alignment (Senior and Robinson, 1994)</p></li></ul><p><em>Connectionist Temporal Classiï¬cation (Graves et al., 2006)</em></p><p>CTC is a bundle of alternatives to conventional system:</p><ul><li><p>CTC introduces an optional <strong>blank symbol</strong> between the â€realâ€ labels.</p></li><li><p>Simple to implement in the FST framework</p><p><img src="/images/NLP/ctc.png"></p></li><li><p>Continuous realignment â€” no need for a bootstrap model</p></li><li><p>Always use soft targets.</p></li><li><p>Donâ€™t scale by posterior.</p></li><li><p>Similar results to conventional training.</p></li></ul><p><img src="/images/NLP/ctc_align.png"></p><h3><span id="sequence-discriminative-training">Sequence discriminative training</span></h3><p>Conventional training uses <em>Cross-Entropy</em> loss</p><ul><li>Tries to <strong>maximize probability of the true state sequence</strong> given the data.</li></ul><p>We care about Word Error Rate of the complete system. Design a loss thatâ€™s diï¬€erentiable and closer to what we care about.</p><ul><li>Applied to neural networks (Kingsbury, 2009).</li><li>Posterior scaling gets learnt by the network.</li><li>Improves conventional training and CTC by 15% relative.</li><li>bMMI, sMBR(Povey et al., 2008)</li></ul><p><span class="math display">\[P(S_r|X_r) = \frac{p(X_r, S_r)}{\sum_S p(X_r, S)} = \frac{p(X_r|S_r)P(S_r)}{\sum_Sp(X_r|S)P(S)}\]</span></p><p><span class="math display">\[L_{mmi}(\theta) = -\sum_{r=1}^R\log P(S_r|X_r)\]</span></p><p><img src="/images/NLP/new_loss.png"></p><h3><span id="new-architectures">New architectures</span></h3><p><strong>Seq2seq</strong></p><p>Basic sequence2sequence not that good for speech</p><ul><li>Utterances are too long to memorize</li><li>Monotonicity of audio (vs Machine Translation)</li></ul><p>Models</p><ul><li>Attention + seq2seq for speech (Chorowski et al., 2015)</li><li>Listen, Attend and Spell (Chan et al., 2015)</li></ul><p>Output characters until EOS, incorporates language model of training set. Harder to incorporate a separately-trained language model. (e.g. trained on trillions of tokens)</p><p><em>Watch, Listen, Attend and Spell (Chung et al., 2016)</em></p><p>Apply LAS to audio and video streams simultaneously.</p><p><img src="/images/NLP/wlas.png"></p><p>Train with scheduled sampling (Bengio et al., 2015)</p><p><img src="/images/NLP/sche_sam.png"></p><p><em>Neural transducer (Jaitly et al., 2015)</em></p><p>Seq2seq models require the whole sequence to be available. Introduce latency compared to unidirectional.</p><p>Solution: Transcribe monotonic chunks at a time with attention.</p><p><img src="/images/NLP/chunk.png"></p><p><img src="/images/NLP/transducer.png"></p><p><strong>Raw waveform speech recognition</strong></p><p>We typically train on a much-reduced dimensional signal.</p><ul><li>Would like to train end-to-end.</li><li>Learn ï¬lterbanks, instead of hand-crafting.</li></ul><p>A conventional RNN at audio sample rate canâ€™t learn long-enough dependencies.</p><ul><li>Add a convolutional ï¬lter to a conventional system e.g. CLDNN (Sainath et al., 2015b)</li><li>WaveNet-style architecture</li><li>Clockwork RNN (KoutnÂ´Ä±k et al., 2014)<ul><li>Run a hierarchical RNN at multiple rates.</li></ul></li></ul><p>Frequency distribution of learned ï¬lters diï¬€ers from hand-initialization:</p><p><img src="/images/NLP/raw_wave.png"></p><p><strong>Speech recognition in noise</strong></p><ul><li>Multi-style training (â€œMTSâ€)<ul><li>Collect noisy data.</li><li>Or, add realistic but randomized noise to utterances during training.</li><li>e.g. Through a â€œroom simulatorâ€ to add reverberation.</li><li>Optionally add a clean-reconstruction loss in training.</li></ul></li><li>Train a denoiser</li><li>NB <em>Lombard</em> eï¬€ect â€“ voice changes in noise.</li></ul><p><strong>Multi-microphone speech recognition</strong></p><p>Multiple microphones give a richer representation, â€œclosest to the speakerâ€ has better SNR.</p><p>Beamforming</p><ul><li>Given geometry of microphone array and speed of sound</li><li>Compute Time Delay of Arrival at each microphone</li><li>Delay-and-sum: Constructive interference of signal in chosen direction.</li><li>Destructive interference depends on direction / frequency of noise.</li></ul><p>More features for a neural network to exploit.</p><ul><li>Important to preserve phase information to enable beam-forming</li></ul><p><em>Factored multichannel raw waveform CLDNN (Sainath et al., 2016)</em></p><p><img src="/images/NLP/factor.png"></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> Speech Recognition </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Conditional Language Model with Attention</title>
      <link href="/2017/08/09/Deep%20NLP%20-%20Conditional%20Language%20Model%20with%20Attention/"/>
      <url>/2017/08/09/Deep%20NLP%20-%20Conditional%20Language%20Model%20with%20Attention/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#machine-translation-with-attention">Machine translation with attention</a><ul><li><a href="#with-concatenation">With Concatenation</a></li><li><a href="#with-convolutional-nets">With Convolutional Nets</a></li><li><a href="#with-bidirectional-rnns">With Bidirectional RNNS</a></li><li><a href="#attention">Attention</a></li></ul></li><li><a href="#image-caption-generation-with-attention">Image caption generation with attention</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="machine-translation-with-attention">Machine translation with attention</span></h2><p><strong>Problems about conditioning with vectors</strong></p><ul><li>We are compressing a lot of information in a finite-sized vector.</li><li>Gradients have a long way to travel. Even LSTMs forget!</li></ul><p><strong>Solution</strong></p><ul><li>Represent a source sentence as a matrix<ul><li>Solve the capacity problem</li></ul></li><li>Generate a target sentence from a matrix<ul><li>Solve the gradient flow problem</li></ul></li></ul><p><strong>Sentences as Matrices</strong></p><p><img src="/images/NLP/sentence_mat.png"></p><p>Question: <strong>How do we build these matrices?</strong></p><h3><span id="with-concatenation">With Concatenation</span></h3><ul><li>Each word type is represented by an n-dimensional vector</li><li>Take all of the vectors for the sentence and concatenate them into a matrix</li><li>Simplest possible model<ul><li>So simple that no one publish how well/badly it works!</li></ul></li></ul><p><img src="/images/NLP/With_Concatenation.png"></p><h3><span id="with-convolutional-nets">With Convolutional Nets</span></h3><ul><li>Apply convolutional networks to transform the naive concatenated matrix to obtain a context-dependent matrix</li><li>Note: convnets usually have a &quot;pooling&quot; operation at the top level that results in a fixed-sized representation. For sentences, leave this out.</li><li>Papers<ul><li><strong>Gehring et al., ICLR 2016</strong></li><li><strong>Kalchbrenner and Blunsom, 2013</strong></li></ul></li></ul><p><img src="/images/NLP/With%20CNN.png"></p><h3><span id="with-bidirectional-rnns">With Bidirectional RNNS</span></h3><ul><li>By far the most widely used matrix representation, due to <strong>Bahdanau et al (2015)</strong></li><li>One column per word</li><li>Each column (word) has two halves concatenated together:<ul><li>a â€œforward representationâ€, i.e., a word and its left context</li><li>a â€œreverse representationâ€, i.e., a word and its right context</li></ul></li><li>Implementation: bidirectional RNNs (GRUs or LSTMs) to read f from left to right and right to left, concatenate representations</li></ul><p><img src="/images/NLP/With_BiRNN.png"></p><p><strong>Where are we in 2017?</strong></p><p>There are lots of ways to construct <span class="math inline">\(F\)</span></p><ul><li><p>Very little systematic work comparing them</p></li><li><p>There are many more undiscovered things out there</p><ul><li>convolutions are particularly interesting and under-explored</li><li><strong>syntactic</strong> information can help (<strong>Sennrich &amp; Haddow, 2016</strong>; <strong>Nadejde et al., 2017</strong>), but many more integration stregration strategies are possible</li></ul></li><li><p>try something with phrase types instead of word types?</p><p>Multi-word expressions are a pain in the neck .</p></li></ul><h3><span id="attention">Attention</span></h3><p>Bahdanau et al. (2015) were the ï¬rst to propose using <strong>attention</strong> for translating from matrix-encoded sentences.</p><p><strong>High-Level Idea</strong></p><ul><li>Generate the output sentence word by word using an RNN</li><li>At each output position <span class="math inline">\(t\)</span>, the RNN receives two inputs (in addition to any recurrent inputs)<ul><li>a ï¬xed-size vector embedding of the previously generated output symbol <span class="math inline">\(e_{t-1}\)</span></li><li>a ï¬xed-size vector encoding a â€œviewâ€ of the input matrix</li></ul></li><li>How do we get a ï¬xed-size vector from a matrix that changes over time?<ul><li>Bahdanau et al: do <strong>a weighted sum of the columns</strong> of <span class="math inline">\(F\)</span> (i.e., words) based on how important they are at the current time step. (i.e., just a matrix-vector product <span class="math inline">\(Fa_t\)</span> )</li><li>The weighting of the input columns at each time-step (<span class="math inline">\(a_t\)</span>) is called <strong>attention</strong></li></ul></li></ul><p><img src="/images/NLP/BA.png"></p><p><strong>Compute Attention</strong></p><p>At each time step (one time step = one output word), we want to be able to â€œattendâ€ to different words in the source sentence</p><ul><li>We need a weight for every column: this is an |<span class="math inline">\(f\)</span>|-length vector a <span class="math inline">\(a_t\)</span></li><li>Here is Bahdanau et al.â€™s solution<ul><li>Use an RNN to predict model output, call the hidden states <span class="math inline">\(s_t\)</span></li><li>At time <span class="math inline">\(t\)</span> compute the <strong>expected input embedding</strong> <span class="math inline">\(r_t = Vs_{t-1}\)</span></li><li>Take the dot product with every column in the source matrix to compute the <strong>nonlinear attention energy</strong>. <span class="math inline">\(e_t = v^T\tanh(WF+r_t)\)</span></li><li>Exponentiate and normalize to 1: <span class="math inline">\(a_t = softmax(u_t)\)</span></li><li>Finally, the input source vector for time t is <span class="math inline">\(c_t = Fa_t\)</span></li></ul></li></ul><p>The overall algorithm:</p><p><img src="/images/NLP/algorithm.png"></p><p>Add attention to seq2seq translation: <strong>+11 BLEU</strong></p><p><em>Model Variant</em></p><p><img src="/images/NLP/variant.png"></p><p><strong>Summary</strong></p><ul><li>Attention is closely related to â€œpoolingâ€ operations in convnets (and other architectures)</li><li>Bahdanauâ€™s attention model seems to only cares about â€œcontentâ€<ul><li>No obvious bias in favor of diagonals, short jumps, fertility, etc.</li><li>Some work has begun to add other â€œstructuralâ€ biases (Luong et al., 2015; Cohn et al., 2016), but there are lots more opportunities</li></ul></li><li>Attention weights provide interpretation you can look at</li></ul><h2><span id="image-caption-generation-with-attention">Image caption generation with attention</span></h2><p><img src="/images/NLP/imggen.png"></p><p><strong>Regions in ConvNets</strong></p><p>Each point in a â€œhigherâ€ level of a convnet deï¬nes spatially localised feature vectors(/matrices).</p><p>Xu et al. calls these â€œ<em>annotation vectors</em>â€, <span class="math inline">\(a_i\)</span> , <span class="math inline">\(i\in \{1, . . . , L\}\)</span></p><p><img src="/images/NLP/a1.png"></p><p><img src="/images/NLP/a2.png"></p><p>Attention â€œweightsâ€ ( <span class="math inline">\(a_t\)</span> ) are computed using exactly the <strong>same</strong> technique as discussed above.</p><ul><li><p>Deterministic <strong>soft</strong> attention (Bahdanau et al., 2014)</p><p><span class="math inline">\(c_t = Fa_t\)</span></p></li><li><p>Stochastic <strong>hard</strong> attention (Xu et al., 2015)</p><p><span class="math inline">\(s_t \sim Categorical(a_t)\)</span></p><p><span class="math inline">\(c_t = F_{:,s_t}\)</span></p></li></ul><p><em>Learning Hard Attention</em></p><p>The loss is computed by following equation: <span class="math display">\[\begin{align}L &amp; = -\log p(w|x) \\&amp; = -\log\sum_s p(w,s|x) \\&amp;= -\log\sum_sp(s|x)p(w|x, s)\end{align}\]</span> where <span class="math inline">\(x\)</span> is the input image, <span class="math inline">\(s\)</span> is the generated context, and <span class="math inline">\(w\)</span> is the caption.</p><p>According to <em>Jensen's inequality</em>, <span class="math display">\[\begin{align}L &amp;= -\log\sum_sp(s|x)p(w|x, s)\\&amp;â‰¤-\sum_s p(s|x)\log p(w|x, s)\\&amp;\approx -\frac{1}{N}\sum_{i=1}^Np(s^{(i)}|x)\log p(w|x, s)\end{align}\]</span> Sample <span class="math inline">\(N\)</span> sequences of attention decisions from the model, the gradient is the probability of this sequence scaled by the log probability of generating the target words using that sequence of attention decisions.</p><p>This is equivalent to using the <strong>REINFORCE</strong> algorithm (Williams, 1992) using the log probability of the observed words as a â€œ<strong>reward function</strong>â€. REINFORCE a <em>policy gradient</em> algorithm used for reinforcement learning.</p><p><img src="/images/NLP/imgeg.png"></p><p><strong>Summary</strong></p><ul><li>Signiï¬cant performance improvements<ul><li>Better performance over vector-based encodings</li><li>Better performance with smaller training data sets</li></ul></li><li>Model interpretability</li><li>Better gradient ï¬‚ow</li><li>Better capacity (especially obvious for translation)</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> Attention </tag>
            
            <tag> Machine Translation </tag>
            
            <tag> NMT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Conditional Language Model</title>
      <link href="/2017/08/08/Deep%20NLP%20-%20Conditional%20Language%20Modeling/"/>
      <url>/2017/08/08/Deep%20NLP%20-%20Conditional%20Language%20Modeling/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#kalchbrenner-and-blunsom-2013">Kalchbrenner and Blunsom 2013</a></li><li><a href="#sutskever-et-al-2014">Sutskever et al. (2014)</a></li><li><a href="#kiros-et-al2013">Kiros et al.(2013)</a></li></ul><!-- tocstop --><a id="more"></a><p>A <strong>conditional language model</strong> assigns probabilities to sequences of words, <span class="math inline">\(w = (w_1, w_2, â€¦, w_l)\)</span>, given some conditioning context, <strong>x</strong>.</p><p>As with unconditional models, it is again helpful to use the chain rule to decompose this probability: <span class="math display">\[p(w|x) = \prod_{t=1}^lp(w_t|x, w_1, w_2, ..., w_{t-1})\]</span></p><table><thead><tr class="header"><th>x &quot;input&quot;</th><th>w &quot;text output&quot;</th></tr></thead><tbody><tr class="odd"><td>An author</td><td>A document written by that author</td></tr><tr class="even"><td>A topic label</td><td>An article about that topic</td></tr><tr class="odd"><td>{SPAM, NOT_SPAM}</td><td>An email</td></tr><tr class="even"><td>A sentence in French</td><td>Its English translation</td></tr><tr class="odd"><td>A sentence in English</td><td>Its French translation</td></tr><tr class="even"><td>A sentence in English</td><td>Its Chinese translation</td></tr><tr class="odd"><td>An image</td><td>A text description of the image</td></tr><tr class="even"><td>A question + a document</td><td>Its answer</td></tr><tr class="odd"><td>A question + an image</td><td>Its answer</td></tr></tbody></table><p>To <strong>train</strong> contitional language models, we need paired samples, <span class="math inline">\(\{(x_i, w_i)\}\)</span>.</p><p><strong>Algorighmic challenges</strong></p><p>We often want to find the most likely <span class="math inline">\(w\)</span> given some <span class="math inline">\(x\)</span>. This is unfortunately generally and <em>intractable problem</em>. <span class="math display">\[w^* = \arg \max_wp(w|x)\]</span> We therefore approximate it using a <strong>beam search</strong> or with Monte Carlo methods since <span class="math inline">\(w^{(i)} \approx p(w|x)\)</span> is often computationally easy.</p><p><strong>Evaluating conditional LMs</strong></p><p>We can use <strong>cross entropy</strong> or <strong>preplexity</strong>, it's okay to implement, but hard to interpret.</p><p><strong>Task-specific evaluation</strong>. Compare the model's most likely output to human-generated expected output using a task-specific evaluation metric <span class="math inline">\(L\)</span>. <span class="math display">\[w^* = \arg \max_wp(w|x)\ \ \ \ \ L(w^*, w_{ref})\]</span> Examples of <span class="math inline">\(L\)</span>: BLUE, METEOR, WER, ROUGE, easy to implement, okay to interpret.</p><p><strong>Encoder-Decoder</strong></p><p><img src="/images/NLP/ed1.png"></p><p><img src="/images/NLP/ed2.png"></p><p>Two questions</p><ul><li>How do we encode <span class="math inline">\(x\)</span> as a fixed-size vector, <span class="math inline">\(c\)</span> ?</li><li>How do we condition on <span class="math inline">\(c\)</span> in the decoing model?</li></ul><h2><span id="kalchbrenner-and-blunsom-2013">Kalchbrenner and Blunsom 2013</span></h2><p>Encoder <span class="math display">\[c = embed(x)\]</span></p><p><span class="math display">\[s = Vc\]</span></p><p>Recurrent decoder <span class="math display">\[h_t = g(W[h_{t-1}; w_{t-1}] + s + b)\]</span></p><p><span class="math display">\[u_t = Ph_t + b&#39;\]</span></p><p><span class="math display">\[p(W_t|x, w&lt;t) = softmax(u_t)\]</span></p><p><strong>CSM Encoder</strong></p><p>How should we define <span class="math inline">\(c = embed(x)\)</span> ?</p><p>Convolutional sentence model(CSM)</p><p><img src="/images/NLP/CSM.png"></p><p>Good</p><ul><li>By stacking them, longer range dependencies can be learnt</li><li>Convolutions learn interactions among features in a local context</li><li>Deep ConvNets have a branching structure similar to trees, but no parser is required</li></ul><p>Bad</p><ul><li>Sentences have different lengths, need different depth trees; convnets are not usually so dynamic, but see Kalchbrenner et al. (2014). A convolutional neural network for modelling sentences. In Proc. ACL.</li></ul><p><img src="/images/NLP/RNNdecoder.png"></p><h2><span id="sutskever-et-al-2014">Sutskever et al. (2014)</span></h2><p>LSTM encoder</p><ul><li><span class="math inline">\((c_0, h_0)\)</span> are parameters</li><li><span class="math inline">\((c_i, h_i)\)</span> = LSTM(<span class="math inline">\(x_i, c_{i-1}, h_{i-1}\)</span>)</li></ul><p>The encoding is <span class="math inline">\((c_l, h_l)\)</span> where <span class="math inline">\(l = |x|\)</span></p><p>LSTM decoder</p><ul><li><span class="math inline">\(w_0 = &lt;s&gt;\)</span></li><li><span class="math inline">\((c_{t+l}, h_{t+l}) = LSTM(w_{t-1}, c_{t+l-1}, h_{t+l-1})\)</span></li><li><span class="math inline">\(u_t = Ph_{t+l} + b\)</span></li><li><span class="math inline">\(P(W_t|x, w&lt;t) = softmax(u_t)\)</span></li></ul><p><img src="/images/NLP/sea.png"></p><p>Good</p><ul><li>RNNs deal naturally with sequences of various lengths</li><li>LSTMs in principle can propagate gradients a long</li><li>Very simple architecture</li></ul><p>Bad</p><ul><li>The hidden state has to remember a lot of information!</li></ul><p><strong>Tricks</strong></p><p>Read the input sequence &quot;backwards&quot; : <strong>+4 BLEU</strong></p><p><img src="/images/NLP/backsea.png"></p><p>Use an ensemble of J <strong>independently trained</strong> models.</p><ul><li>Ensemble of 2 models: <strong>+3 BLEU</strong></li><li>Ensemble of 5 models; <strong>+4.5 BLEU</strong></li></ul><p><strong>A word about decoding</strong></p><p>In general, we want to find the most probable (MAP) output given the input, i.e. <span class="math display">\[\begin{align}w^* = \arg\max_{w}p(w|x) = \arg \max_w\sum_{t=1}^{|w|}\log p(w_t|x, w_{&lt;t})\end{align}\]</span> This is, for general RNNs, a hard problem. We therefore approximate it with a <strong>greedy search</strong>ï¼š <span class="math display">\[\begin{array}{lcl}w_1^* = \arg\max_{w_1}p(w_1|x)\\w_2^* = \arg\max_{w_2}p(w_2|x, w_1^*)\\...\\w^*_t = \arg\max_{w_t}p(w_t|x, w^*_{&lt;t})\end{array}\]</span> A slightly better approximation is to use a <strong>beam search</strong> with beam size <span class="math inline">\(b\)</span>. Key idea: <strong>keep track of top b hypothesis</strong>. Use beam search: <strong>+1 BLEU</strong></p><p><img src="/images/NLP/beam.png"></p><h2><span id="kiros-et-al2013">Kiros et al.(2013)</span></h2><p><strong>Image caption generation</strong></p><ul><li>Neural networks are great for working with multiple modalities - <strong>Everything is a vector!</strong></li><li>Image caption generation can therefore use the same techniques as translation modeling</li><li>A word about data<ul><li>Relatively few captioned images are avaliable</li><li>Pre-train image embedding model using another task, like image identification (e.g., ImageNet)</li></ul></li></ul><p>Look a lot like Kalchbrenner and Blunsom(2013)</p><ul><li>convolutional network on the input</li><li>n-gram language model on the output</li></ul><p>Innovation: <strong>multiplicative interactions</strong> in the decoder n-gram model</p><p>Encoder <strong>x</strong> = enbed(<span class="math inline">\(x\)</span>)</p><p>Simple conditional n-gram LM: <span class="math display">\[\begin{array}{lcl}h_t = W[w_{t-n+1}; w_{t-n+2};...; w_{t-1}] + Cx\\u_t = Ph_t+b\\p(W_t|x, w_{t-n+1}^{t-1}) = softmax(u_t)\end{array}\]</span> Multiplicative n-gram LM:</p><ul><li><span class="math inline">\(w_i = r_{i,j,w}x_j\)</span></li><li><span class="math inline">\(w_i = u_{w,i}v_{i,j}\ \ \ \ \ \ \ \ (U\in R^{|V|*d}, V \in R^{d*k})\)</span></li><li><span class="math inline">\(r_t = W[w_{t-n+1}; w_{t-n+2};...; w_{t-1}] + Cx\)</span></li><li><span class="math inline">\(h_t = (W^{fr}r_t)\odot (W^{fx}x)\)</span></li><li><span class="math inline">\(u_t = Ph_t + b\)</span></li><li><span class="math inline">\(p(W_t|x, w_{&lt;t}) = softmax(u_t)\)</span></li></ul><p>Two messages:</p><ul><li>Feed-forward n-gram models can be used in place of RNNs in conditional models</li><li>Modeling interactions between input modalities holds a lot of promise<ul><li>Although MLP-type models can approximate higher order tensors, multiplicative models appear to make learning interactions easier</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> Machine Translation </tag>
            
            <tag> NMT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Text Classification</title>
      <link href="/2017/08/07/Deep%20NLP%20-%20Text%20Classification/"/>
      <url>/2017/08/07/Deep%20NLP%20-%20Text%20Classification/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#generative-and-discriminative-models">Generative and discriminative models</a></li><li><a href="#naive-bayes-classifier">Naive Bayes classifier</a></li><li><a href="#feature-representations">Feature Representations</a></li><li><a href="#logistic-regression">Logistic Regression</a></li><li><a href="#representing-text-with-a-rnn">Representing Text with a RNN</a></li><li><a href="#convolutional-neural-network">Convolutional Neural Network</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="generative-and-discriminative-models">Generative and discriminative models</span></h2><p><strong>Generative (joint) models</strong> <span class="math inline">\(P(c, d)\)</span></p><ul><li>Model the distribution of individual classes and place probabilities over both observed data and hidden variables (such as labels)</li><li>E.g. n-gram models, hidden Markov models, probabilistic context-free grammars, IBM machine translation models, Naive Bayes...</li></ul><p><strong>Discriminative (conditional) models</strong> <span class="math inline">\(P(c|d)\)</span></p><ul><li>Learn <strong>boundaries</strong> between classes. Take data as given and put probability over the hidden structure give the data.</li><li>E.g. logistic regression, maximum entropy models, conditional random fields, support-vector machines...</li></ul><h2><span id="naive-bayes-classifier">Naive Bayes classifier</span></h2><p>Bayes' Rule: <span class="math display">\[P(c|d) = \frac{P(c)P(d|c)}{P(d)}\]</span> This estimates the probility of document <span class="math inline">\(d\)</span> being in class <span class="math inline">\(c\)</span>, assuming document length <span class="math inline">\(n_d\)</span> and tokens <span class="math inline">\(t\)</span>: <span class="math display">\[P(c|d)  = P(c)P(d|c) = P(c)\prod_{1 â‰¤iâ‰¤n_d}P(t_i|c)\]</span> <strong>Independence Assumptions</strong></p><p>Note that we assume <span class="math inline">\(P(t_i|c) = P(t_j|c)\)</span> independent of token position. This is the <strong>naive</strong> part of Naive Bayes.</p><p>The best class is the <strong>maximum a posteriori (MAP)</strong> clss: <span class="math display">\[c_{map} = \arg\max_{c\in C}P(c|d) = \arg\max_{c\in C}P(c)\prod_{1â‰¤iâ‰¤n_d}P(t_i|c)\]</span> Multiplying tons of small probabilities is tricky, so <strong>log space</strong> it: <span class="math display">\[c_{map} = \arg\max_{c\in C}(\log P(c) + \sum_{1â‰¤iâ‰¤n_d}\log P(t_i|c))\]</span> Finally: zero probabilities are bad. Add <strong>smoothing</strong>: <span class="math display">\[P(t|c) = \frac{T_{ct}}{\sum_{t&#39;\in V}T_{ct&#39;}} =&gt; P(t|c) = \frac{T_{ct} + 1}{\sum_{t&#39;\in V}T_{ct&#39;}+|V|}\]</span> This is Laplace or add-1 smoothing.</p><p><strong>Advantages</strong></p><ul><li>Simple</li><li>Interpretable</li><li>Fast (linear in size of training set and test document)</li><li>Text representation trivial (bag of words)</li></ul><p><strong>Drawbacks</strong></p><ul><li>Independence assumptions often too strong</li><li>Sentence/document structure not taken into account</li><li>Naive classifier has zero probabilities; smoothing is awkward</li></ul><p><strong>Naive Bayes is a generative model!!!</strong> <span class="math display">\[P(c|d)P(d) = P(d|c)P(c) = P(d, c)\]</span> While we are using a conditional probability <span class="math inline">\(P(c|d)\)</span> for classification, we model the joint probability of <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>.</p><p>This meas it is trivial to invert the process and generate new text given a class label.</p><h2><span id="feature-representations">Feature Representations</span></h2><p>A feature representation (of text) can be viewed as a vector where each element indicates the presence or absence of a given feature in a document.</p><p>Note: features can be binary (presence/absence), multinomial (count) or continuous (eg. TF-IDF weighted).</p><h2><span id="logistic-regression">Logistic Regression</span></h2><p>A general framework for learning <span class="math inline">\(P(c|d)\)</span> is <strong>logistic regression</strong></p><ul><li>logistic : because is uses a logistic function</li><li>regression : combines a feature vector (<span class="math inline">\(d\)</span>) with weights (<span class="math inline">\(\beta\)</span>) to compute an answer</li></ul><p>Binary case: <span class="math display">\[P(true|d) = \frac{1}{1 + \exp(\beta_0 + \sum_i\beta_iX_i)}\]</span></p><p><span class="math display">\[P(false|d) = \frac{\exp(\beta_0 + \sum_i\beta_iX_i)}{1 + \exp(\beta_0+\sum_i\beta_iX_i)}\]</span></p><p>Multinomial case: <span class="math display">\[P(c|d) = \frac{\exp(\beta_{c,0} + \sum_i\beta_{c,i}X_i)}{\sum_{c&#39;}\exp(\beta_{c&#39;,0} +  \sum_i\beta_{c&#39;,i}X_i)}\]</span> The binary and general functions for the logistic regression can be simplified as follows: <span class="math display">\[P(c|d) = \frac{1}{1+\exp(-z)}\]</span></p><p><span class="math display">\[P(c|d) = \frac{\exp(z_c)}{\sum_{c&#39;}\exp(z_{c&#39;})}\]</span></p><p>which are referred to as the <strong>logistic</strong> and <strong>softmax</strong> function.</p><p>Given this model formulation, we want to learn parameters <span class="math inline">\(Î²\)</span> that maximise the conditional likelihood of the data according to the model.</p><p>Due to the softmax function we not only construct a classifier, but learn <strong>probability distributions</strong> over classifications.</p><p>There are many ways to chose weights <span class="math inline">\(Î²\)</span>:</p><ul><li>Perceptron Find misclassified examples and move weights in the direction of their correct class</li><li>Margin-Based Methods such as Support Vector Machines can be used for learning weights</li><li>Logistic Regression Directly maximise the conditional log-likelihood via gradient descent.</li></ul><p><strong>Advantages</strong></p><ul><li>Still reasonably simple</li><li>Results are very interpretable</li><li>Do not assume statistical independence between features!</li></ul><p><strong>Drawbacks</strong></p><ul><li>Harder to learn than Naive Bayes</li><li>Manually designing features can be expensive</li><li>Will not necessarily generalise well due to hand-craftedfeatures</li></ul><h2><span id="representing-text-with-a-rnn">Representing Text with a RNN</span></h2><p><img src="/images/NLP/RNNre.png"></p><ul><li><span class="math inline">\(h_i\)</span> is a function of <span class="math inline">\(x\{0:i\}\)</span> and <span class="math inline">\(h\{0:iâˆ’1\}\)</span></li><li>It contains information about all text read up to point <span class="math inline">\(i\)</span>.</li><li>The first half of this lecture was focused on learning a representation <span class="math inline">\(X\)</span> for a given text</li></ul><p>So in order to classify text we can simply take a trained language model and extract text representations from the final hidden state <span class="math inline">\(c_n\)</span>.</p><p>Classification as before using a logistic regression: <span class="math display">\[P(c|d) = \frac{\exp(\beta_{c,0} + \sum_i\beta_{c,i}h_{ni})}{\sum_{c&#39;}\exp(\beta_{c&#39;,0} +  \sum_i\beta_{c&#39;,i}h_{ni})}\]</span> âœ… Can use RNN + Logistic Regression out of the box âœ… Can in fact use any other classifier on top of <span class="math inline">\(h\)</span> ! âŒ How to ensure that <span class="math inline">\(h\)</span> pays attention to relevant aspects of data?</p><p><strong>Move the classification function inside the network</strong></p><p><img src="/images/NLP/RNNtext.png"></p><p>This is a simple <strong>Multilayer Perceptron (MLP)</strong>. We can train the model using the cross-entropy loss: <span class="math display">\[L_i = -\sum_c y_c \log P(c|d_i) = -\log (\frac{\exp(m_c)}{\sum_j\exp(m_j)})\]</span></p><ul><li>Cross-entropy is designed to deal with errors on <strong>probabilities</strong>.</li><li>Optimizing means minimizing the cross-entropy between the estiated class probabilities (<span class="math inline">\(P(c|d)\)</span>) and the ture distribution.</li><li>There are many alternative losses (hinge-loss, square error, L1 loss).</li></ul><p><strong>Dual Objective RNN</strong></p><p>In practice it may make sense to combine an LM objective with classifier training and to optimise the two losses jointly.</p><p><img src="/images/NLP/DualRNN.png"> <span class="math display">\[J = \alpha J_{class} + (1-\alpha)J_{lm}\]</span> Such a joint loss enables making use of text beyond labelled data.</p><p><strong>Bi-Directional RNNs</strong></p><p>Another way to add signal is to process the input text both in a forward and in a backward sequence.</p><p><img src="/images/NLP/BiRNN.png"></p><p>The update rules for this directly follow the regular forward-facing RNN arhitecture. In practice, bidirectional networks have shown to be more robust than unidirectional networks.</p><p>A bidirectional network can be used as a classifier simply by redefining <span class="math inline">\(d\)</span> to be the <strong>concatenation</strong> of both final hidden states: <span class="math display">\[d = (\rightarrow{h_n}||h_0\leftarrow)\]</span> <strong>RNN Classifier can be either a generative or a discriminative model</strong></p><p><img src="/images/NLP/seq2seq.png"></p><p>Encoder: discriminative (it does not model the probability of the text) Joint-model: generative (learns both <span class="math inline">\(P(c)\)</span> and <span class="math inline">\(P(d)\)</span>).</p><h2><span id="convolutional-neural-network">Convolutional Neural Network</span></h2><p>Reasons to consider CNNs for Text:</p><ul><li>âœ… Really fast (GPU)</li><li>âœ… BOW is often sufficient</li><li>âœ… Actually can take some structure into account</li><li>âŒ Not sequential in its processing of input data</li><li>âŒ Easier to discriminate than to generate variably sized data</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> LSTM </tag>
            
            <tag> Naive Bayes </tag>
            
            <tag> Text Classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Recurrent Neural Networks and Language Modelling</title>
      <link href="/2017/08/06/Deep%20NLP%20-%20RNNs%20and%20Language%20Modelling/"/>
      <url>/2017/08/06/Deep%20NLP%20-%20RNNs%20and%20Language%20Modelling/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#count-based-n-gram-language-models">Count based N-Gram Language Models</a></li><li><a href="#neural-n-gram-language-models">Neural N-Gram Language Models</a></li><li><a href="#recurrent-neural-network-language-models">Recurrent Neural Network Language Models</a><ul><li><a href="#long-short-term-memory-lstm">Long Short Term Memory (LSTM)</a></li><li><a href="#deep-rnn-lms">Deep RNN LMs</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><p>A language model assigns a <strong>probability</strong> to a sequence of words, given the observed training text, how probable is this new utterance?</p><p>Most language models employ the chain rule to decompose the joint probability into a sequence of conditional probabilities: <span class="math display">\[p(w_1, w_2, w_3, ..., w_N) = p(w_1)p(w_2|w_1)p(w_3|w_1,w_2)*...*p(w_N|w_1,..w_{N-1})\]</span> <strong>Evaluating a Language Model</strong></p><p>A good model assigns real utterances <span class="math inline">\(w_1^N\)</span> from a language a high probability. This can be measured with <em>cross entropy</em>: <span class="math display">\[H(w_1^N) = -\frac{1}{N}\log_2p(w_1^N)\]</span> <em>Intuition</em> : Cross entropy is a measure of how many bits are needed to encode text with our model.</p><p><strong>Data</strong></p><p>Language modelling is a time series prediction problem in which we must be careful to <strong>train on the past</strong> and <strong>test on the future</strong>.</p><p>If the corpus is composed of articles, it is best to ensure the <strong>test data</strong> is drawn from <strong>a disjoint set of articles</strong> to the training data.</p><h2><span id="count-based-n-gram-language-models">Count based N-Gram Language Models</span></h2><p><strong>Markov assumption</strong></p><ul><li>only previous history matters</li><li>limited memory: only last <span class="math inline">\(k - 1\)</span> words are included in history(older words less relevant)</li><li><span class="math inline">\(k\)</span>-th order Markov model</li></ul><p>e.g. 2-gram language model: <span class="math display">\[p(w_1, w_2, ..., w_n) \approx p(w_1)p(w_2|w_1)p(w_3|w_2)...p(w_n|w_{n-1})\]</span> <strong>Estimating Probabilities</strong></p><p>Maximum likelihood estimation for 3-grams: <span class="math display">\[p(w_3|w_1, w_2) = \frac{count(w_1,w_2,w_3)}{count(w_1,w_2)}\]</span> In our training corpus we may never observe this trigrams:</p><ul><li>Oxford Pimm's eater</li><li>Oxford Pimm's drinker</li></ul><p>If both have count 0 our smoothing methods will assign the same probability to them.</p><p>A better solution is to interpolate with the bigram probability.</p><ul><li>Pimm's eater</li><li>Pimm's drinker</li></ul><p>A simple approach is linear interpolation: <span class="math display">\[p_l(w_n|w_{n-1}, w_{n-2}) = \lambda_3p(w_n|w_{n-1}, w_{n-2})+\lambda_2p(w_n|w_{n-1})+\lambda_1p(w_n)\]</span> where <span class="math inline">\(\lambda_3 + \lambda_2 + \lambda_1 = 1\)</span>.</p><p><strong>Summary</strong></p><p>Good</p><ul><li>Count based n-gram models are exceptionally scalable and able to be trained on trillions of words of data</li><li>fast constant time evaluation of probabilities at best time</li><li>sophisticated smoothing techniques match the empirical distribution of language</li></ul><p>Bad</p><ul><li>Large ngrams are sparse, so hard to capture long dependencies</li><li>symbolic nature does not capture correlations between semantically similary word distributions, e.g. cat &lt;-&gt; dog.</li><li>similarly morphological regularities, running &lt;-&gt; jumping, or gender.</li></ul><h2><span id="neural-n-gram-language-models">Neural N-Gram Language Models</span></h2><p>Trigram NN language model <span class="math display">\[h_n = g(V[w_{n-1};w_{n-2}] + c) \]</span></p><p><span class="math display">\[\hat{p_n} = softmax(Wh_n + b)\]</span></p><p><span class="math display">\[softmax(u)_i = \frac{\exp(u_i)}{\sum_j\exp u_j}\]</span></p><p>where</p><ul><li><span class="math inline">\(w_i\)</span> are one hot vetors and <span class="math inline">\(\hat{p_i}\)</span> are distributions</li><li><span class="math inline">\(|w_i| = |\hat{p_i}| = V\)</span> (words in the vocabulary)</li><li><span class="math inline">\(V\)</span> is usually very large <span class="math inline">\(&gt; 1e5\)</span></li></ul><p><img src="/images/NLP/NLM1.png"></p><p><strong>Training</strong></p><p>The usual training objective is the cross entropy of the data given the model (MLE): <span class="math display">\[F = -\frac{1}{N}\sum_ncost_n(w_n,\hat{p_n})\]</span> The cost function is simply the model's estimated log-probability of <span class="math inline">\(w_n\)</span>: <span class="math display">\[cost(a, b) = a^T\log b\]</span> <img src="/images/NLP/NLM1T.png"></p><p>Calculating the gradients is straightforward with back propagation: <span class="math display">\[\frac{\partial F}{\partial W} = -\frac{1}{N}\sum_n \frac{\partial cost_n}{\partial \hat{p_n}}\frac{\partial \hat{p_n}}{\partial W}\]</span></p><p><span class="math display">\[\frac{\partial F}{\partial W} = -\frac{1}{N} \sum_n\frac{\partial cost_n}{\partial \hat{p_n}}\frac{\partial\hat{p_n}}{\partial h_n}\frac{\partial h_n}{\partial V}\]</span></p><p><strong>Comparison with Count Based N-Gram LMs</strong></p><p>Good</p><ul><li><p>Better generalisation on unseen n-grams, poorer on seen n-grams.</p><p>Solution: direct (linear) ngram features</p></li><li><p>Simple NLMs are often an order magnitude smaller in memory footprint than their vanilla n-gram cousins (though not if you use the linear features suggested above!)</p></li></ul><p>Bad</p><ul><li>The number of parameters in the model scales with the n-gram size and thus the length of the history captured.</li><li>The n-gram history is finite and thus there is limit on the longest dependencies that an be captured.</li><li>Mostly trained with Maximum Likelihood based objectives which do not encode the expected frequencies of words a priori.</li></ul><h2><span id="recurrent-neural-network-language-models">Recurrent Neural Network Language Models</span></h2><p>The major difference between RNN and Neural N-Gram model is RNN not only forward propagate the previous input (<span class="math inline">\(y_{n-1}\)</span>) to next layer but also forward propagate the previous <strong>state</strong> (<span class="math inline">\(h_{n-1}\)</span>).</p><p><img src="/images/NLP/RNN.png"></p><p><strong>BPTT</strong></p><p><strong>Back Propagation Through Time</strong> (BPTT) note the dependence of derivatives at time <span class="math inline">\(n\)</span> with those at time <span class="math inline">\(n + \alpha\)</span>.</p><p><img src="/images/NLP/BPTT.png"></p><p><strong>TBPTT</strong></p><p>If we break these dependencies after a fixed number of time steps we get <strong>Truncated Back Propagation Through Time</strong> (TBPTT).</p><p>![(/images/NLP/TBPTT.png)</p><p><strong>Comparison with N-Gram LMs</strong></p><p>Good</p><ul><li>RNNs can represent unbounded dependencies, unlike models with a fixed n-gram order.</li><li>RNNs compress history of words into a fixed size hidden vector.</li><li>The number of parameters does not grow with the length of dependencies captured, but they do grow with the amount of information stored in the hidden layer.</li></ul><p>Bad</p><ul><li>RNNs are hard to learn and often will not discover long range dependencies present in the data.</li><li>Increasing the size of the hidden layer, and thus memory, increases the computation and memory quadratically.</li><li>Mostly trained with Maximum Likelihood based objectives which do not encode the expected frequencies of words a priori.</li></ul><p><strong>Exploding and Vanishing Gradients</strong></p><p>Consider the path of partial derivatives linking a change in <span class="math inline">\(cost_N\)</span> to changes in <span class="math inline">\(h_1\)</span>:</p><p><img src="/images/eqq.png"></p><p>where</p><p><span class="math display">\[h_n  = g(V_xx_n + V_hh_{n-1} + c) = g(z_n)\]</span></p><p><span class="math display">\[\frac{\partial h_n}{\partial z_n} = diag(g&#39;(z_n))\]</span></p><p>The core of the recurrent product is the repeated multiplication of <span class="math inline">\(V_h\)</span>. If the <strong>largest eigenvalue</strong> of <span class="math inline">\(V_h\)</span> is:</p><ul><li><span class="math inline">\(1\)</span>, then gradient will <strong>propagate</strong>,</li><li><span class="math inline">\(&gt;1\)</span>, the product will grow exponentially (<strong>explode</strong>),</li><li><span class="math inline">\(&lt;1\)</span>, the prodcut shrinks exponentially (<strong>vanishes</strong>).</li></ul><p>Most of the time the spectral radius of <span class="math inline">\(V_h\)</span> is <strong>small</strong>. The result is that the gradient vanishes and <strong>long range dependencies</strong> are <strong>not</strong> learnt.</p><h3><span id="long-short-term-memory-lstm">Long Short Term Memory (LSTM)</span></h3><p>The original RNN is:</p><p><img src="/images/NLP/origin.png"></p><p>Then adding a linear layer of current input and previous state and then going through a tanh non-linearity before passing to the current state:</p><p><img src="/images/NLP/2nd.png"></p><p>The next step is to introduce an extra hidden layer called cell-state (<span class="math inline">\(c\)</span>), and think it as our memory. The really cool thing is that propagation is <strong>additive</strong>. The <strong>key innovation</strong> of LSTM is replacing the <strong>multiplication</strong> with <strong>sum</strong>.</p><p><img src="/images/NLP/3rd.png"></p><p>How to balance the grow of addition?</p><p>The method is called <strong>Gating</strong>. So we are going to do is gating the input of the hidden layer, which is called <em>input gate</em>, represented by <span class="math inline">\(i\)</span>. The gate in neural network, is to compute a non-linearity, which is bound between 0 and 1. We think it like a <strong>switch</strong>, if 1, we turn on the connection and if 0, we shut off the connection. The key thing is the gate is <strong>not</strong> a <strong>decret binary</strong> function <strong>but</strong> a <strong>continuous</strong> function, thus we can differentiate and back propagation through it.</p><p>If the gate is 1, the input would contribute to the current state, if the gate is 0, the input would not affect the current state, so the gate gives <strong>state</strong> ability to <strong>ignore the input</strong>.</p><p><img src="/images/NLP/4th.png"></p><p>We already have the ability to include or ignore the input, but we can't forget things. So next we are going to add a <strong>forget gate</strong>, represented by <span class="math inline">\(f\)</span>.</p><p><img src="/images/NLP/5th.png"></p><p>So given the <span class="math inline">\(i\)</span> and <span class="math inline">\(f\)</span>, our network has the ability to include something new and decide what to remember depend on the input to the next cell state.</p><p>The final step is to add a <em>output gate</em>, represented by <span class="math inline">\(o\)</span>, between the cell state to the current state.</p><p><img src="/images/NLP/6th.png"></p><p><img src="/images/NLP/LSTM.png"></p><p>The LSTM cell : <span class="math display">\[c_n = f_n \circ c_{n-1} + i_n \circ \hat{c_n}\]</span></p><p><span class="math display">\[\begin{align}\hat{c_n} &amp;= \tanh (W_c[w_{n-1};h_{t-1}] + b_c)\\h_n &amp;= o_n \circ \tanh (W_h c_n + b_h)\\i_n &amp;= \sigma (W_i[w_{n-1}; h_{t-1}] + b_i)\\f_n &amp;= \sigma (W_f[w_{n-1}; h_{t-1}] + b_f)\\o_n &amp;= \sigma (W_o[w_{n-1}; h_{t-1}] + b_o)\end{align}\]</span></p><p><strong>Gated Recurrent Unit (GRU)</strong></p><p><img src="/images/NLP/GRU.png"></p><p><strong>LSTMs and GRUs</strong></p><p>Good</p><ul><li>Careful initialisation and optimisation of vanilla RNNs can enable then to learn long(ish) dependencies, but gated additive cells, like the LSTM and GRU, often just work.</li><li>The (re)introduction of LSTMs has been key to many recent developments, e.g. Neural Machine Translation, Speech Recognition, TTS, etc.</li></ul><p>Bad</p><ul><li>LSTMs and GRUs have considerably more parameters and computation per memory cell than a vanilla RNN, as such they have less memory capacity per parameter.</li></ul><h3><span id="deep-rnn-lms">Deep RNN LMs</span></h3><p>The memory capacity of an RNN can be increased by employing a larger hidden layer <span class="math inline">\(h_n\)</span>, but a linear increase in <span class="math inline">\(h_n\)</span> results in quadratic increase in model size and compution:</p><p><img src="/images/NLP/DRNN11.png"></p><p>Alternatively we can increase depth in the time dimension. This improves the representational ability, but not the memory capacity.</p><p><img src="/images/NLP/DRNN2.png"></p><p><strong>Regularisation : Dropout</strong></p><p>Large recurrent networks often overfit their training data by memorising the sequences observed. Such models generalise poorly to novel sequences.</p><p>A common approach in Deep Learning is to overparametrise a model, such that it could easily memorise the training data, and then heavily regularise it to facilitate generalisation.</p><p>The regularisation method of choice is often Dropout.</p><p>Dropout is ineffective when applied to recurrent connections, as repeated random masks zero all hidden units in the limit. The most common solution is to only apply dropout to <strong>non-recurrent</strong> connections.</p><p><img src="/images/NLP/Dropout.png"></p><p><strong>Summary</strong></p><p>Long Range Dependencies</p><ul><li>The repeated multiplication of the recurrent weights <span class="math inline">\(V\)</span> lead to vanishing (or exploding) gradients,</li><li>additive gated architectures, such as LSTMs, significantly reduce this issue.</li></ul><p>Deep RNNs</p><ul><li>Increasing the size of the recurrent layer increases memory capacity with a quadratic slow down,</li><li>deepening networks in both dimensions can improve their representational efficiency and memory capacity with a linear complexity cost.</li></ul><p>Large Vocabularies</p><ul><li>Large vocabularies, <span class="math inline">\(V &gt; 10^4\)</span>, lead to slow softmax calculations,</li><li>reducing the number of vector matrix products evaluated,by factorising the softmax or sampling, reduces the training overhead significantly.</li><li>Different optimisations have different training and evaluation complexities which should be considered.</li></ul><p><strong>Readings</strong></p><p>Textbook</p><ul><li>Deep Learning, Chapter 10</li></ul><p>Blog Posts</p><ul><li>Andrej Karpathy: <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li><li>Yoav Goldberg: <a href="http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139" target="_blank" rel="noopener">The unreasonable effectiveness of Character-level Language Models</a></li><li>Stephen Merity: <a href="http://smerity.com/articles/2016/orthogonal_init.html" target="_blank" rel="noopener">Explaining and illustrating orthogonal initialization for recurrent neural networks</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> LSTM </tag>
            
            <tag> RNN </tag>
            
            <tag> Language Model </tag>
            
            <tag> N-Gram </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Word Level Semantics</title>
      <link href="/2017/08/05/DeepNLP-Word%20Level%20Semantics/"/>
      <url>/2017/08/05/DeepNLP-Word%20Level%20Semantics/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#word-level-semantics">Word Level Semantics</a><ul><li><a href="#count-based-methods">Count-based methods</a></li><li><a href="#neural-embedding-models">Neural Embedding Models</a><ul><li><a href="#cw">C&amp;W</a></li><li><a href="#cbow">CBoW</a></li><li><a href="#skip-gram">Skip-gram</a></li></ul></li><li><a href="#task-based-embedding-learning">Task-based Embedding Learning</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="word-level-semantics">Word Level Semantics</span></h2><h3><span id="count-based-methods">Count-based methods</span></h3><ul><li>Define a <strong>basis vocabulary</strong> <span class="math inline">\(C\)</span> of context words</li><li>Define a <strong>word window</strong> size <span class="math inline">\(w\)</span></li><li><strong>Count the basis vocabulary words</strong> occurring <span class="math inline">\(w\)</span> words to the left or right of each instance of a <strong>target</strong> word in the corpus.</li><li>Form a <strong>vector representation</strong> of the target word based on these counts.</li></ul><p><strong>Example</strong>:</p><ul><li>... and the cute kitten purred and then ...</li><li>... the cute furry cat purred and miaowed ...</li><li>... that the small kitten miaowed and she ...</li><li>... the loud furry dog ran and bit ...</li></ul><p>Example <strong>basis vocabulary</strong>: {bit, cute, furry, loud, miaowed, purred, ran, small}.</p><ul><li><strong>kitten</strong> context words: {cute, purred, small, miaowed}.</li><li><strong>cat</strong> context words: {cute, furry, miaowed}.</li><li><strong>dog</strong> context words: {loud, furry, ran, bit}.</li></ul><p>Therefore</p><ul><li><span class="math inline">\(kitten = [0, 1, 0, 0, 1, 1, 0, 1]^T\)</span></li><li><span class="math inline">\(cat = [0, 1, 1, 0, 1, 0, 0, 0]^T\)</span></li><li><span class="math inline">\(dog = [1, 0, 1, 1, 0, 0, 1, 0]^T\)</span></li></ul><h3><span id="neural-embedding-models">Neural Embedding Models</span></h3><ul><li><p>Learning count based vetors produces an <strong>embedding matrix</strong> <span class="math inline">\(E\)</span> in <span class="math inline">\(R^{|vocab|*|context|}\)</span>.</p><p><img src="/images/NLP/embed.png"></p></li><li><p>Rows are word vectors = <strong>one hot vector</strong></p><ul><li><span class="math inline">\(cat = onehot^T_{cat}E\)</span></li></ul></li></ul><p>General idea behind embedding learning:</p><ol type="1"><li>Collect instances <span class="math inline">\(t_i \in inst(t)\)</span> of a word <span class="math inline">\(t\)</span> of vocab <span class="math inline">\(V\)</span></li><li>For each instance, collect its context words <span class="math inline">\(c(t_i)\)</span> (e.g. k-word window)</li><li>Define some score function <span class="math inline">\(socre(t_i, c(t_i); \theta, E)\)</span> with upper bound on output</li><li>Define a loss</li><li>Estimate</li><li>Use the estimated <span class="math inline">\(E\)</span> as your embedding matrix</li></ol><h4><span id="campw">C&amp;W</span></h4><p><img src="/images/NLP/C&amp;W.png"></p><h4><span id="cbow">CBoW</span></h4><p><img src="/images/NLP/CBoW.png"></p><p>word2vecè¯¦è§£ï¼šhttp://blog.csdn.net/itplus/article/details/37969979</p><h4><span id="skip-gram">Skip-gram</span></h4><p><img src="/images/NLP/Skip-Gram.png"></p><h3><span id="task-based-embedding-learning">Task-based Embedding Learning</span></h3><p>Neural network parameters are updated using gradients on loss <span class="math inline">\(L(x, y, \theta)\)</span> <span class="math display">\[\theta_{t+1} = update(\theta_t, \triangledown_\theta L(x, y, \theta_t))\]</span> If <span class="math inline">\(E \in \theta\)</span> then this update can modify <span class="math inline">\(E\)</span> : <span class="math display">\[E_{t+1} = update(E_t, \triangledown_E L(x, y, \theta_t))\]</span> General intuition: learn to classify/predict/generate based on features, but also the <strong>features themselves</strong>.</p><ul><li>Bow Classifiers</li><li>Bilingual Features</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> NLP </tag>
            
            <tag> Word2Vec </tag>
            
            <tag> CBoW </tag>
            
            <tag> Skip-gram </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Regularization for Deep Learning</title>
      <link href="/2017/07/13/Regularization%20for%20Deep%20Learning/"/>
      <url>/2017/07/13/Regularization%20for%20Deep%20Learning/</url>
      
        <content type="html"><![CDATA[<p>å®šä¹‰ï¼šAny modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.</p><!-- toc --><ul><li><a href="#parameter-norm-penalties">Parameter Norm Penalties</a><ul><li><a href="#l2-parameter-regularzation"><span class="math inline">\(L^2\)</span> Parameter Regularzation</a></li><li><a href="#l1-regularization"><span class="math inline">\(L^1\)</span> Regularization</a></li></ul></li><li><a href="#regularization-and-under-constrained-problems">Regularization and Under-Constrained Problems</a></li><li><a href="#dataset-augmentation">Dataset Augmentation</a></li><li><a href="#noise-robustness">Noise Robustness</a></li><li><a href="#multi-task-learning">Multi-Task Learning</a></li><li><a href="#early-stopping">Early Stopping</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="parameter-norm-penalties">Parameter Norm Penalties</span></h2><p>é€šè¿‡é™åˆ¶æ¨¡å‹çš„èƒ½åŠ›æ¥æ­£åˆ™åŒ–ï¼Œé€šå¸¸åœ¨ç›®æ ‡å‡½æ•°ä¸­åŠ å…¥æƒ©ç½šé¡¹ <span class="math inline">\(\Omega(\theta)\)</span>: <span class="math display">\[\hat{J}(\theta; X, y) = J(\theta; X, y) + \alpha \Omega(\theta)\]</span> è¿™æ ·æ¨¡å‹åœ¨è®­ç»ƒçš„æ—¶å€™ä¸ä½†ä¼šå‡å°åŸæ¥çš„ <span class="math inline">\(J\)</span> ï¼Œä¹Ÿä¼šå°½é‡å‡å°æƒ©ç½šé¡¹ <span class="math inline">\(\Omega\)</span>ï¼Œä»è€Œè¾¾åˆ°é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ•ˆæœã€‚</p><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç¥ç»ç½‘ç»œä¸­åªéœ€è¦æ­£åˆ™åŒ–ç½‘ç»œä¸­çš„<strong>æƒé‡ï¼ˆweightsï¼‰</strong>ï¼Œè€Œåç½®ä¸éœ€è¦æ­£åˆ™åŒ–ï¼Œä¸€æ–¹é¢æ˜¯å› ä¸ºç›¸å¯¹äºæƒé‡ï¼Œåç½®å¾ˆå®¹æ˜“è¢«æ‹Ÿåˆï¼ˆä½¿ç”¨è¾ƒå°‘çš„æ•°æ®ï¼‰ï¼Œä¹Ÿæ²¡æœ‰æƒé‡é‡è¦ï¼Œæƒé‡éœ€è¦è§‚å¯Ÿä¸¤ä¸ªå˜é‡åœ¨å„ç§æ¡ä»¶ä¸‹çš„æƒ…å†µæ¥è¿›è¡Œæ‹Ÿåˆï¼Œè€Œåç½®åªéœ€è€ƒè™‘ä¸€ä¸ªå˜é‡ï¼Œæ‰€ä»¥ä¸æƒ©ç½šåç½®ä¹Ÿä¸ä¼šå¯¹è¿‡æ‹Ÿåˆé€ æˆå¤šå¤§å½±å“ï¼›å¦ä¸€æ–¹é¢æ˜¯å› ä¸ºå¦‚æœå¯¹åç½®ä¸šä¹Ÿè¿›è¡Œæƒ©ç½šåˆ™å®¹æ˜“é€ æˆæ¬ æ‹Ÿåˆã€‚æ‰€ä»¥ä¹‹åç”¨ <span class="math inline">\(w\)</span> è¡¨ç¤ºæ‰€æœ‰æƒé‡ï¼Œè€Œ <span class="math inline">\(\theta\)</span> è¡¨ç¤ºå…¨éƒ¨å‚æ•°ã€‚</p><h3><span id="l2-parameter-regularzation"><span class="math inline">\(L^2\)</span> Parameter Regularzation</span></h3><p><span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–åˆå« weight decayï¼Œå²­å›å½’ï¼ˆridge regressionï¼‰å’Œ Tikhonov regularizationã€‚å®ƒåœ¨ç›®æ ‡å‡½æ•°ååŠ ä¸Šæƒ©ç½šé¡¹ <span class="math inline">\(\Omega(\theta) = \frac{1}{2}||w||^2_2\)</span>ï¼Œè¿™ä½¿å¾—æƒé‡è¶‹è¿‘äºå‘åŸç‚¹æ–¹å‘æ›´æ–°ã€‚</p><p>æˆ‘ä»¬å¯ä»¥ä»æ¢¯åº¦æ›´æ–°çš„è§’åº¦æ¥ç†è§£æ­£åˆ™åŒ–æ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Œä¸ºäº†ç®€åŒ–ï¼Œå‡è®¾æ¨¡å‹é‡Œæ— åç½®å‚æ•°ï¼Œå³ <span class="math inline">\(\theta = w\)</span>ï¼Œæ‰€ä»¥ç›®æ ‡å‡½æ•°å¦‚ä¸‹ï¼š <span class="math display">\[\hat{J}(w;X,y) = \frac{\alpha}{2}w^Tw + J(w;X,y)\]</span> å¯¹ <span class="math inline">\(w\)</span> æ±‚æ¢¯åº¦ï¼š <span class="math display">\[\bigtriangledown_w\hat{J}(w; X, y) = \alpha w+\bigtriangledown_wJ(w; X,y)\]</span> æ‰€ä»¥æ¢¯åº¦æ›´æ–°å…¬å¼ä¸ºï¼š <span class="math display">\[\begin{align}w &amp;\leftarrow w - \epsilon(\alpha w + \bigtriangledown_wJ(w;X,y)) \\w&amp; \leftarrow (1-\epsilon\alpha)w - \epsilon\bigtriangledown_wJ(w;X,y)\end{align}\]</span> å¯ä»¥è§å¾—ï¼Œæ¯æ¬¡æ›´æ–°æ¢¯åº¦æ—¶éƒ½å…ˆä¼šæŒ‰ç…§ä¸€å®šçš„å› å­ç¼©å° <span class="math inline">\(w\)</span>ï¼Œç„¶ååœ¨æ‰§è¡Œæ­£å¸¸çš„æ¢¯åº¦ä¸‹é™ã€‚</p><p>è¿™æ˜¯æ‰§è¡Œä¸€æ­¥æ¢¯åº¦ä¸‹é™å‘ç”Ÿçš„äº‹æƒ…ï¼Œè‹¥åœ¨æ•´ä¸ª training æœŸé—´éƒ½æ‰§è¡Œæ­¤è§„åˆ™ä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ</p><blockquote><p>çº¿æ€§é€¼è¿‘ï¼ˆLinear approximationï¼‰</p><blockquote><p>å‡½æ•° <span class="math inline">\(f(x)\)</span> åœ¨ç‚¹ <span class="math inline">\(a\)</span> å¤„çš„æœ€ä½³çº¿æ€§é€¼è¿‘ <span class="math inline">\(L_a(x)\)</span> è¦æ»¡è¶³: <span class="math inline">\(L_a(a) = f(a)\)</span> ä¸” <span class="math inline">\(L_a&#39;(a) = f&#39;(a)\)</span>ï¼Œè¿™æ ·å¯ä»¥æ„é€ å‡º <span class="math inline">\(L_a(x) = f(a) + f&#39;(a)(x-a)\)</span>ã€‚</p></blockquote><p>äºŒæ¬¡é€¼è¿‘ï¼ˆQuadratic approximationï¼‰</p><blockquote><p>å‡½æ•° <span class="math inline">\(f(x)\)</span> åœ¨ç‚¹ <span class="math inline">\(a\)</span> å¤„çš„æœ€ä½³äºŒæ¬¡é€¼è¿‘ <span class="math inline">\(Q_a(x)\)</span> è¦æ»¡è¶³ï¼š</p><ul><li><span class="math inline">\(Q_a(a) = f(a)\)</span></li><li><span class="math inline">\(Q_a&#39;(a) = f&#39;(a)\)</span></li><li><span class="math inline">\(Q_a&#39;&#39;(a) = f&#39;&#39;(a)\)</span></li></ul><p>é€šè¿‡è¿™ä¸‰ä¸ªæ¡ä»¶å¯ä»¥æ„é€ å‡º <span class="math inline">\(Q_a(x) = f(a) + f&#39;(a)(x-a)+\frac{1}{2}f&#39;&#39;(a)(x-a)^2\)</span></p><p>ä¹Ÿå¯ä»¥æ ¹æ®æ³°å‹’å…¬å¼ç†è§£ï¼ŒæŠŠ <span class="math inline">\(f(x)\)</span> åœ¨ <span class="math inline">\(a\)</span> ç‚¹è¿›è¡Œæ³°å‹’å±•å¼€ï¼Œåªä¿ç•™åˆ°äºŒé˜¶å¯¼ã€‚</p></blockquote></blockquote><p>ä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨æœ€ä¼˜ç‚¹ <span class="math inline">\(w^* = \arg\min_wJ(w)\)</span> ç”¨äºŒæ¬¡é€¼è¿‘ï¼ˆquadratic approximationï¼‰æ‹ŸåˆåŸç›®æ ‡å‡½æ•°ï¼Œå¾—åˆ°æ–°çš„è¿‘ä¼¼ç›®æ ‡å‡½æ•°ï¼š <span class="math display">\[\hat{J}(w) = J(w^*)+\frac{1}{2}(w-w^*)^TH(w-w*)\]</span> å…¶ä¸­ <span class="math inline">\(Hâ€‹\)</span> ä¸º <span class="math inline">\(Jâ€‹\)</span> å¯¹ <span class="math inline">\(wâ€‹\)</span> çš„æµ·æ£®çŸ©é˜µï¼ˆHessian matrixï¼‰ï¼Œå®ƒæ˜¯ç”±äºŒé˜¶åå¯¼æ•°ç»„æˆçš„æ–¹é˜µï¼Œè‹¥ <span class="math inline">\(w = [w_1, w_2, â€¦, w_n]â€‹\)</span>ï¼Œåˆ™ï¼š <span class="math display">\[H = \begin{bmatrix}\frac{\partial^2J}{\partial w_1^2}    &amp; \frac{\partial^2J}{\partial w_1\partial w_2}  &amp; \cdots &amp; \frac{\partial^2J}{\partial w_1\partial w_n}      \\\vdots &amp; \ddots &amp; \vdots \\\frac{\partial^2J}{\partial w_n\partial w_1} &amp; \frac{\partial^2J}{\partial w_n\partial w_2}      &amp; \cdots &amp; \frac{\partial^2J}{\partial w_n^2}\end{bmatrix}\]</span> æˆ‘ä»¬å‘ç°ä¸Šå¼ä¸­æ²¡æœ‰ä¸€é˜¶åå¯¼æ•°ï¼Œé‚£æ˜¯å› ä¸º <span class="math inline">\(J\)</span> çš„ä¸€é˜¶å¯¼æ•°åœ¨æœ€ä¼˜ç‚¹ <span class="math inline">\(w^*\)</span> çš„å€¼ä¸º <span class="math inline">\(0\)</span>ï¼Œå³ <span class="math inline">\(J&#39;(w^*) = 0\)</span>ã€‚</p><p>å½“ <span class="math inline">\(\hat{J}\)</span> å–å¾—æœ€å°å€¼æ—¶ï¼Œå®ƒçš„æ¢¯åº¦ <span class="math display">\[\bigtriangledown_w\hat{J}(w) = H(w - w^*)\]</span> ç­‰äº <span class="math inline">\(0â€‹\)</span>ã€‚</p><p>ä¸ºäº†ç ”ç©¶æ­£åˆ™åŒ–çš„å½±å“ï¼Œæˆ‘ä»¬ä¿®æ”¹ä¸Šå¼ï¼ŒåŠ å…¥ weight decay gradientï¼Œæˆ‘ä»¬ç”¨ <span class="math inline">\(\hat{w}\)</span> è¡¨ç¤ºæ­£åˆ™åŒ–åçš„ <span class="math inline">\(\hat{J}\)</span> çš„æœ€å°å€¼çš„ä½ç½®ï¼Œå¯ä»¥è§£å¾—ï¼š <span class="math display">\[\alpha\hat{w} + H(\hat{w}-w^*) = 0\]</span></p><p><span class="math display">\[(H+\alpha I)\hat{w} = Hw^*\]</span></p><p><span class="math display">\[\hat{w} = (H+\alpha I)^{-1}Hw^*\]</span></p><p>å¯ä»¥çœ‹å‡ºï¼Œå½“ <span class="math inline">\(\alpha\)</span> è¶‹è¿‘äº <span class="math inline">\(0\)</span> æ—¶ï¼Œ<span class="math inline">\(\hat{w} \approx w^*\)</span>ï¼Œé‚£å½“ <span class="math inline">\(\alpha\)</span> è¾ƒå¤§æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆå‘¢ï¼Ÿ</p><p>å› ä¸º <span class="math inline">\(H\)</span> ç”±å®æ•°ç»„æˆä¸”å¯¹ç§°ï¼Œæ‰€ä»¥ <span class="math inline">\(H\)</span> å¯ä»¥åˆ†è§£ä¸ºä¸€ä¸ªå¯¹è§’é˜µ <span class="math inline">\(\Lambda\)</span> å’Œæ­£äº¤çŸ©é˜µ <span class="math inline">\(Q\)</span> çš„ä¹˜ç§¯ï¼š <span class="math display">\[H = Q\Lambda Q^T\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\Lambda\)</span> ä¸­å¯¹è§’çº¿çš„å…ƒç´ ä¸º <span class="math inline">\(H\)</span> çš„ç‰¹å¾å€¼ï¼Œ<span class="math inline">\(Q\)</span> çš„æ¯ä¸€åˆ—ä¸ºå¯¹åº”çš„ç‰¹å¾å‘é‡ã€‚</p><p>ç”±æ­¤å¯ä»¥è¿›ä¸€æ­¥åŒ–ç®€ï¼š <span class="math display">\[\begin{align}\hat{w} &amp; = (Q\Lambda Q^T+\alpha I)^{-1}Q\Lambda Q^Tw^* \\&amp; = [Q(\Lambda+\alpha I)Q^T]^{-1}Q\Lambda Q^T w^* \\&amp; = (Q^{T})^{-1}(\Lambda+\alpha I)^{-1}Q^{-1}Q\Lambda Q^T w^* \\&amp; = Q(\Lambda+\alpha I)^{-1}\Lambda Q^T w^* \\\end{align}\]</span> ä»¤ $ =Q(+I)<sup>{-1}Q</sup>T $ï¼Œåˆ™ <span class="math inline">\(\hat{H}\)</span> çš„ä»»æ„ç‰¹å¾å€¼ <span class="math inline">\(\hat{\lambda_i}\)</span> ä¸ <span class="math inline">\(H\)</span> é‡Œå¯¹åº”çš„ç‰¹å¾å€¼ <span class="math inline">\(\lambda_i\)</span> æœ‰å¦‚ä¸‹å…³ç³»ï¼š <span class="math display">\[\hat{\lambda_i} = \frac{\lambda_i}{\lambda_i+\alpha}\]</span> æ‰€ä»¥ <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–çš„æ•ˆæœå°±æ˜¯æŠŠ <span class="math inline">\(w^*\)</span> æ²¿ç€ <span class="math inline">\(H\)</span> (æˆ– <span class="math inline">\(\hat{H}\)</span>) çš„ç‰¹å¾å‘é‡æ‰€å®šä¹‰çš„æ–¹å‘é‡æ–°è°ƒæ•´å¤§å°ï¼ˆrescaleï¼‰ã€‚å…¶ä¸­ï¼Œ<span class="math inline">\(w^*\)</span> ä¸­æ²¿ç€ <span class="math inline">\(H\)</span> çš„ç¬¬ <span class="math inline">\(i\)</span> ä¸ªç‰¹å¾å‘é‡æ–¹å‘çš„æˆåˆ†è¢«æ‰©å¤§äº† <span class="math inline">\(\frac{\lambda_i}{\lambda_i+\alpha}\)</span> å€ã€‚</p><blockquote><p><img src="/images/f2.3.png"></p></blockquote><p>é‚£äº›å¤§ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡çš„æ–¹å‘ï¼Œ<span class="math inline">\(\lambda_i\gg \alpha\)</span>ï¼Œæ­£åˆ™åŒ–çš„æ•ˆæœå¾ˆå°ï¼›è€Œé‚£äº›å°ç‰¹å¾å€¼å¯¹åº”çš„æ–¹å‘ï¼Œ<span class="math inline">\(\lambda_i \ll \alpha\)</span>ï¼Œ<span class="math inline">\(w^*\)</span> ç›¸åº”æ–¹å‘çš„æˆåˆ†å°±å¾ˆå®¹æ˜“ç¼©å°åˆ° <span class="math inline">\(0\)</span>ï¼Œæ­£åˆ™åŒ–æ•ˆæœå¾ˆæ˜æ˜¾ã€‚</p><p>å¾—å‡ºåé¢çš„ç»“è®ºè¿˜æœ‰ä¸€ä¸ªå‰æï¼Œå°±æ˜¯æ¢¯åº¦å¤§çš„æ–¹å‘å¯¹åº”çš„ <span class="math inline">\(H\)</span> çš„ç‰¹å¾å€¼ä¹Ÿå¤§ï¼Œç”±æ­¤å¯å¾—ï¼š<strong>åªæœ‰é‚£äº›å¯¹å‡å°ç›®æ ‡å‡½æ•°æ¢¯åº¦å½±å“å¾ˆå¤§çš„æ–¹å‘çš„æˆåˆ†æ‰ä¸å—æ­£åˆ™åŒ–å½±å“ï¼›é‚£äº›å¯¹æ¢¯åº¦ä¸‹é™å½±å“ä¸å¤§çš„æ–¹å‘ï¼Œä¼šå¾—åˆ°ä¸€ä¸ªè¾ƒå°çš„ç‰¹å¾å€¼ï¼Œä»è€Œä½¿é‚£äº›ä¸é‡è¦æ–¹å‘çš„æˆåˆ†åœ¨è®­ç»ƒä¸­ä¸€ç›´åœ¨ç¼©å°</strong>ã€‚</p><p><img src="/images/f7.1.png"></p><p>ä¸Šé¢æˆ‘ä»¬è®¨è®ºäº†æ³›åŒ–çš„ã€é€šç”¨çš„æƒ…å†µä¸‹ <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–çš„ä½œç”¨ï¼Œä¸‹é¢æ¥çœ‹ä¸€ä¸ªçº¿æ€§å›å½’çš„å…·ä½“å®ä¾‹ã€‚çº¿æ€§å›å½’çš„å‡æ–¹è¯¯å·®ç›®æ ‡å‡½æ•°ä¸ºï¼š <span class="math display">\[(Xw-y)^T(Xw-y)\]</span> å¢åŠ  <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–ä¹‹åå˜æˆï¼š <span class="math display">\[(Xw-y)^T(Xw-y)+\frac{1}{2}\alpha w^Tw\]</span> è§£å‡º <span class="math inline">\(w\)</span> çš„æ­£è§„æ–¹ç¨‹ä¹Ÿä» <span class="math display">\[w = (X^TX)^{-1}X^Ty\]</span> å˜ä¸ºï¼š <span class="math display">\[w=(X^TX+\alpha I)^{-1}X^Ty\]</span> å¯è§ï¼Œä¸‹é¢çš„å¼å­åªæ˜¯æŠŠ <span class="math inline">\((X^TX)^{-1}\)</span> æ¢æˆäº† <span class="math inline">\((X^TX+\alpha I)^{-1}\)</span>ï¼Œ åœ¨ <span class="math inline">\(X^TX\)</span> çš„å¯¹è§’çº¿ä¸Šå¤šåŠ äº† <span class="math inline">\(\alpha\)</span> ã€‚ä½†æ˜¯ <span class="math inline">\(X^TX\)</span> å¯¹è§’çº¿ä¸Šçš„å…ƒç´ å¯¹åº”çš„å°±æ˜¯è¾“å…¥ç‰¹å¾çš„æ–¹å·®ï¼Œä¹Ÿå°±æ˜¯<span class="math inline">\(L^2\)</span>æ­£åˆ™åŒ–å¢åŠ äº†è¾“å…¥ç‰¹å¾çš„æ–¹å·®ï¼Œä»è€Œè¿«ä½¿æ¨¡å‹å»é™ä½é‚£äº›æ²¡æœ‰ç”¨ï¼ˆä¸è¾“å‡ºç›®æ ‡çš„åæ–¹å·®å¾ˆä½ï¼‰çš„ç‰¹å¾çš„æƒé‡ã€‚</p><h3><span id="l1-regularization"><span class="math inline">\(L^1\)</span> Regularization</span></h3><p>å¯¹äº <span class="math inline">\(L^1\)</span> æ­£åˆ™åŒ–ï¼Œå®ƒçš„æƒ©ç½šé¡¹å°±æ˜¯æƒé‡ <span class="math inline">\(w\)</span> çš„1èŒƒæ•°ï¼š <span class="math display">\[\Omega(\theta) = ||w||_1 = \sum_i|w_i|\]</span> è¿˜åƒä¸Šé¢ä¸€æ ·ä¸è€ƒè™‘åç½®å‚æ•°ï¼Œ<span class="math inline">\(\alpha\)</span> ä¸ºæ­£åˆ™åŒ–å› å­ï¼Œåˆ™ä½¿ç”¨ <span class="math inline">\(L^1\)</span> æ­£åˆ™åŒ–çš„ç›®æ ‡å‡½æ•°ä¸ºï¼š <span class="math display">\[\hat{J}(w;X,y) = \alpha||w||_1 + J(w;X,y)\]</span> ç›¸åº”çš„æ¢¯åº¦ä¸ºï¼š <span class="math display">\[\bigtriangledown_w\hat{J}(w;X,y) = \alpha sign(w) + \bigtriangledown_wJ(w;X,y)\]</span> å…¶ä¸­ <span class="math inline">\(sign\)</span> ä¸ºç¬¦å·å‡½æ•°ï¼Œå¤§äº <span class="math inline">\(0\)</span> å€¼ä¸º <span class="math inline">\(1\)</span>ï¼Œå°äº <span class="math inline">\(0\)</span> å€¼ä¸º <span class="math inline">\(-1\)</span>ï¼Œç­‰äº <span class="math inline">\(0\)</span> å€¼ä¸º <span class="math inline">\(0\)</span> ã€‚</p><p>è¿™é‡Œå¯ä»¥çœ‹å‡ºï¼Œ<span class="math inline">\(L^1\)</span> æ­£åˆ™åŒ–ä¸æ˜¯åœ¨æŒ‰ç…§ä¸€å®šæ¯”ä¾‹æ¥ç¼©å°å‚æ•° <span class="math inline">\(w\)</span>ï¼Œè€Œæ˜¯æ¯æ­¥å¢åŠ æˆ–å‡å°‘ä¸€ä¸ªå¸¸é‡ã€‚</p><p>ä¸ºäº†è§‚å¯Ÿæ•´ä½“è®­ç»ƒè¿‡ç¨‹ä¸­æ­£åˆ™åŒ–çš„å½±å“ï¼Œæˆ‘ä»¬ç»§ç»­ç”¨åœ¨æœ€ä¼˜ç‚¹ <span class="math inline">\(w^*\)</span> çš„äºŒæ¬¡é€¼è¿‘æ¥æ‹Ÿåˆç›®æ ‡å‡½æ•°ï¼š <span class="math display">\[\hat{J}(w) = J(w^*)+\frac{1}{2}(w-w^*)^TH(w-w*)\]</span> ç›¸åº”çš„æ¢¯åº¦ä¸ºï¼š <span class="math display">\[\bigtriangledown_w\hat{J}(w) = H(w - w^*)\]</span> è¿™é‡Œçš„ <span class="math inline">\(H\)</span> ä¾æ—§æ˜¯æµ·æ£®çŸ©é˜µï¼Œç”±äº <span class="math inline">\(L^1\)</span> æƒ©ç½šç›¸ä¸ä¿è¯å¯ä»¥ç”¨ä¸€ä¸ªä»£æ•°å¼è¡¨ç¤ºï¼ˆclean algebraic expressionï¼‰ï¼Œæ‰€ä»¥å‡è®¾ <span class="math inline">\(H\)</span> æ˜¯ä¸ªå¯¹è§’é˜µï¼Œ<span class="math inline">\(H = diag([H_{1,1}, â€¦, H_{n,n}])\)</span>ï¼Œå¹¶ä¸”æ¯ä¸ª <span class="math inline">\(H_{i,i} &gt; 0\)</span>ã€‚åªè¦ Linear Regression çš„è¾“å…¥ç‰¹å¾ç›´æ¥æ²¡æœ‰å…³è”ï¼ˆcorrelationï¼‰å°±å¯ä»¥ä¿è¯ä¸Šè¿°å‡è®¾æˆç«‹ï¼Œè€Œè¿™ä¸€ç‚¹å¯ä»¥é€šè¿‡PCAåšåˆ°ã€‚</p><p>åŠ ä¸Š <span class="math inline">\(L^1\)</span> æ­£åˆ™åŒ–çš„ç›®æ ‡å‡½æ•°ä¸ºï¼š <span class="math display">\[\hat{J}(w;X,y) = J(w^*; X,y) + \sum_i\left[ \frac{1}{2}H_{i,i}(w_i-w^*_i)^2+\alpha|w_i| \right]\]</span> æœ€å°åŒ–è¯¥ç›®æ ‡å‡½æ•°å¯å¾—ï¼š <span class="math display">\[w_i = sign(w^*_i)\max\left\{|w^*_i| - \frac{\alpha}{H_{i,i}}, 0\right\}\]</span> è€ƒè™‘æ‰€æœ‰ <span class="math inline">\(w_i^* &gt; 0\)</span>ï¼Œæœ‰ä¸¤ç§å¯èƒ½ç»“æœï¼š</p><ol type="1"><li>å½“ <span class="math inline">\(w_i^*â‰¤\frac{\alpha}{H_{i,i}}\)</span> æ—¶ï¼Œ<span class="math inline">\(w_i\)</span> çš„æœ€ä¼˜è§£ä¸º <span class="math inline">\(0\)</span>ã€‚This occurs because the contribution of <span class="math inline">\(J(w;X,y)\)</span> to the regularized objective <span class="math inline">\(\hat{J}(w;X,y)\)</span> is overwhelmedâ€”in direction <span class="math inline">\(i\)</span> â€”by the <span class="math inline">\(L^1\)</span> regularization which pushes the value of <span class="math inline">\(w_i\)</span> to zero.</li><li>å½“ <span class="math inline">\(w_i^*â‰¥\frac{\alpha}{H_{i,i}}\)</span> æ—¶ï¼Œè¿™æ˜¯æœ€ä¼˜çš„ <span class="math inline">\(w_i\)</span> ä¸ä¼šä¸º <span class="math inline">\(0\)</span>ï¼Œè€Œæ˜¯ä¼šå‘ <span class="math inline">\(0\)</span> çš„æ–¹å‘ç§»åŠ¨ <span class="math inline">\(\frac{\alpha}{H_{i,i}}\)</span> çš„è·ç¦»ã€‚</li></ol><p>å½“æ‰€æœ‰ <span class="math inline">\(w^*_1 &lt; 0\)</span> æ—¶ä¹Ÿæœ‰ç±»ä¼¼çš„ç»“æœã€‚</p><p>å’Œ <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–ç›¸æ¯”ï¼Œ<span class="math inline">\(L^1\)</span> æ­£åˆ™åŒ–è¶‹å‘äºä½¿æƒé‡å˜çš„ç¨€ç–ï¼ˆsparseï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´ä¸€éƒ¨åˆ†å‚æ•°çš„æœ€ä¼˜å€¼ä¸º <span class="math inline">\(0\)</span>ã€‚å¦‚æœæˆ‘ä»¬ç”¨åŒæ ·çš„å‡è®¾åˆ†æ <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–ï¼Œåˆ™ä¼šå¾—åˆ° <span class="math inline">\(\hat{w}_i = \frac{H_{i,i}}{H_{i,i}+\alpha}w^*_i\)</span>ï¼Œåªè¦ <span class="math inline">\(w_i^*\)</span> éé›¶ï¼Œ<span class="math inline">\(\hat{w}_i\)</span> ä¸€å®šä¹Ÿéé›¶ã€‚æ‰€ä»¥ <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–ä¸ä¼šä½¿å‚æ•°å˜ç¨€ç–ï¼Œè€Œ <span class="math inline">\(L^1\)</span> æ­£åˆ™åŒ–åœ¨ <span class="math inline">\(\alpha\)</span> å¾ˆå¤§çš„æƒ…å†µä¸‹ä¼šã€‚</p><p><span class="math inline">\(L^1\)</span> æ­£åˆ™åŒ–çš„è¿™ä¸ªæ€§è´¨å¯ä»¥ç”¨æ¥åš<strong>ç‰¹å¾é€‰æ‹©ï¼ˆfeature selectionï¼‰</strong>ï¼Œå¦‚æœæŸä¸ªç‰¹å¾å¯¹æ¨¡å‹æ”¶æ•›å¸®åŠ©ä¸å¤§ï¼Œåˆ™å®ƒå¯¹åº”çš„æƒé‡ä¼šæ”¶ç¼©åˆ° <span class="math inline">\(0\)</span>ï¼Œæˆ‘ä»¬å°±å¯ä»¥å»æ‰é‚£äº›ç”¨å¤„ä¸å¤§çš„ç‰¹å¾ã€‚</p><blockquote><p>Maximum A Posteriori (MAP) Estimation <span class="math display">\[\theta_{MAP} = \arg\max_\theta p(\theta|x) = \arg\max_\theta \log p(x|\theta)+\log p(\theta)\]</span> Maximum Likelihood Estimator (MLE) <span class="math display">\[\theta_{ML} = \arg\max_\theta p(X;\theta)\]</span></p></blockquote><p><strong>æ­£åˆ™åŒ–ä¸å‚æ•°ä¼°è®¡ä¹‹é—´çš„å…³ç³»</strong></p><p>ä½¿ç”¨å‡æ–¹è¯¯å·®çš„çº¿æ€§å›å½’å¯ä»¥çœ‹ä½œæ˜¯å¯¹å‚æ•° <span class="math inline">\(w\)</span> ï¼ˆå¦‚æœ <span class="math inline">\(w\)</span> çš„å…ˆéªŒæœä» <span class="math inline">\(N(w;0,\frac{1}{\lambda}I^2)\)</span>ï¼‰çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰ï¼Œå¦‚æœåŠ ä¸Š <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–é¡¹ <span class="math inline">\(\lambda w^T w\)</span> çš„è¯ï¼Œåˆ™å˜æˆäº†å¯¹å‚æ•° <span class="math inline">\(w\)</span> çš„æœ€å¤§åéªŒä¼°è®¡ï¼ˆMAPï¼‰ï¼Œå› ä¸ºï¼š <span class="math display">\[\log p(w) = \log N(w;0,\frac{1}{\lambda}I^2)=\log\frac{\lambda}{\sqrt{2\pi}} - \frac{1}{2}\lambda w^Tw\]</span> è€Œ <span class="math inline">\(L^1â€‹\)</span> æ­£åˆ™åŒ–åˆ™ç›¸å½“äº <span class="math inline">\(wâ€‹\)</span> çš„å…ˆéªŒä¼°è®¡æœä»å„å‘åŒæ€§æ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒï¼ˆisotropic Laplace distributionï¼‰ï¼š <span class="math display">\[\log p(w) = \sum_i\log Laplace(w_i; 0, \frac{1}{\alpha}) = -\alpha ||w||_1 + n\log\alpha -n\log2\]</span> æˆ‘ä»¬å¯ä»¥å¿½ç•¥ <span class="math inline">\(n\log\alpha -n\log2\)</span> å› ä¸ºå®ƒä»¬ä¸ä¾èµ–äº <span class="math inline">\(w\)</span>ã€‚</p><h2><span id="regularization-and-under-constrained-problems">Regularization and Under-Constrained Problems</span></h2><p>æ­£åˆ™åŒ–ä¸å…‰å¯ä»¥è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œè¿˜å¯ä»¥è§£å†³å…¶ä»–å¾ˆå¤šé—®é¢˜ã€‚</p><p>æ¯”å¦‚æ±‚è§£çº¿æ€§å›å½’ä¸­ï¼Œæ­£è§„æ–¹ç¨‹ä¸º <span class="math inline">\(w = (X^TX)^{-1}X^Ty\)</span>ï¼Œä½† <span class="math inline">\(X^TX\)</span> æœ‰å¯èƒ½æ˜¯ä¸å¯é€†çš„ï¼Œæ¯”å¦‚ç‰¹å¾å¤šä½†æ ·æœ¬å°‘çš„æ—¶å€™ï¼Œ <span class="math inline">\(X^TX\)</span> å°±ä¸å¯é€†ï¼Œè¿™æ—¶å€™å¦‚æœåŠ ä¸Š <span class="math inline">\(L^2\)</span> æ­£åˆ™é¡¹ï¼Œå˜æˆ <span class="math inline">\(X^TX+\alpha I\)</span>ï¼Œè¿™å¯ä»¥ä¿è¯ä¸€å®šæ˜¯å¯é€†çš„ã€‚</p><p>è¿˜æœ‰ä¸€ç§æƒ…å†µï¼Œåœ¨ Logistic å›å½’ä¸­ï¼Œå‡è®¾æ•°æ®é›†æ˜¯çº¿å½¢å¯åˆ†çš„ï¼Œå¦‚æœå‚æ•° <span class="math inline">\(w\)</span> å¯ä»¥å®Œç¾çš„è¿›è¡Œåˆ†ç±»ï¼Œé‚£ä¹ˆ <span class="math inline">\(2w\)</span> ä¸€å®šä¹Ÿå¯ä»¥ï¼Œè€Œä¸”ä¼šæœ‰æ›´å¤§çš„ä¼¼ç„¶ã€‚è¿™æ ·å¾ªç¯æ›´æ–°çš„ç®—æ³•ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰å°±ä¼šä½¿ <span class="math inline">\(w\)</span> ä¸æ–­å¢å¤§ï¼Œç›´åˆ°å‘ç”Ÿæº¢å‡ºã€‚è€ŒåŠ ä¸Šæ­£åˆ™åŒ–å¯ä»¥é˜²æ­¢è¿™ç§æƒ…å†µçš„å‘ç”Ÿï¼Œæ¯”å¦‚åŠ ä¸Š <span class="math inline">\(L^2\)</span> æ­£åˆ™é¡¹ï¼Œå½“æƒé‡è¡°å‡çš„æŒ‡æ•°å’Œä¼¼ç„¶çš„å¡åº¦æŒå¹³æ—¶ï¼Œå°±ä¼šåœæ­¢å¢å¤§å‚æ•°ã€‚ï¼ˆFor example, weight decay will cause gradient descent to quit increasing the magnitude of the weights when the slope of the likelihood is equal to the weight decay coeï¬ƒcient.ï¼‰</p><p>å†æ¯”å¦‚æ±‚ Moore-Penrose ä¼ªé€†ï¼š <span class="math display">\[X^+ = \lim_{\alpha\rightarrow0}(X^TX+\alpha I)^{-1}X^T\]</span> æˆ‘ä»¬ç°åœ¨å¯ä»¥è®¤ä¸ºä¸Šå¼æ˜¯åœ¨æ±‚å¸¦ <span class="math inline">\(L2\)</span> æ­£åˆ™é¡¹çš„çº¿æ€§å›å½’ï¼Œä¹Ÿå°±å¯ä»¥æŠŠå®ƒè§£é‡Šä¸ºç”¨æ­£åˆ™åŒ–è§£å†³æ¬ é—®é¢˜ï¼ˆunderdetermined problemsï¼‰ã€‚</p><h2><span id="dataset-augmentation">Dataset Augmentation</span></h2><p>æ•°æ®é›†å¢å¼ºæ˜¯æé«˜æœºå™¨å­¦ä¹ æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„ä¸€ç§æ–¹æ³•ï¼Œä¸»è¦åº”ç”¨äºåˆ†ç±»ç®—æ³•ä¸­ï¼Œæ“ä½œé€šå¸¸åŒ…æ‹¬å¯¹è¾“å…¥æ·»åŠ ç™½å™ªå£°ã€å¯¹è¾“å…¥è¿›è¡Œå˜æ¢ã€å¯¹ç¥ç»ç½‘ç»œä¸­é—´æ·»åŠ å™ªå£°ç­‰ï¼Œä½†æ³¨æ„å¯¹è¾“å…¥å˜æ¢æ—¶ä¸è¦æ”¹å˜æ ‡ç­¾å€¼ã€‚è¿™ç§æ•°æ®é›†å¢å¼ºçš„æ–¹æ³•è¢«è¯æ˜åœ¨ç‰©ä½“è¯†åˆ«å’Œè¯­éŸ³è¯†åˆ«æ–¹é¢å¾ˆæœ‰ä½œç”¨ã€‚</p><p>ä½†åœ¨æ¯”è¾ƒä¸¤ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹å¥½åæ—¶ï¼Œä¸€å®šè¦åœ¨ç›¸åŒçš„æ•°æ®é›†å’Œæ•°æ®é›†å¢å¼ºæ“ä½œçš„æƒ…å†µä¸‹è¿›è¡Œæ¯”è¾ƒã€‚</p><h2><span id="noise-robustness">Noise Robustness</span></h2><p><strong>Injecting Noise at the Output Targets</strong></p><p>å› ä¸ºå¤§å¤šæ•°æ•°æ®é›†éƒ½åŒ…å«é”™è¯¯æ ‡ç­¾ï¼Œè‹¥ <span class="math inline">\(y\)</span> æ˜¯é”™è¯¯çš„åˆ™æœ€å¤§åŒ– <span class="math inline">\(\log p(y|x)\)</span> å°†ä¼šå¸¦æ¥å¾ˆå¤§å±å®³ã€‚ä¸€ä¸ªè§£å†³åŠæ³•æ˜¯ç»™æ ‡ç­¾æ·»åŠ å™ªå£°ï¼Œæ¯”å¦‚å‡è®¾ä¸€ä¸ªå°å¸¸é‡ <span class="math inline">\(\epsilon\)</span> ï¼Œè®­ç»ƒé›†ä¸­ <span class="math inline">\(1-\epsilon\)</span> çš„æ¦‚ç‡çš„æ ‡ç­¾æ˜¯æ­£ç¡®çš„ï¼Œå‰©ä¸‹ <span class="math inline">\(\epsilon\)</span> æ¦‚ç‡çš„æ ‡ç­¾åˆ™ä¸ä¸€å®šã€‚æˆ‘ä»¬ä¸ç”¨å®é™…åœ¨æ ·æœ¬ä¸­åŠ å…¥å™ªå£°ï¼Œè€Œæ˜¯ç›´æ¥æŠŠ <span class="math inline">\(\epsilon\)</span> åµŒå…¥åˆ°ç›®æ ‡å‡½æ•°ä¸­ã€‚æ¯”å¦‚ <strong>label smoothing</strong> æŠ€æœ¯æŠŠhard target <span class="math inline">\(0\)</span> å’Œ <span class="math inline">\(1\)</span> æ›¿æ¢æˆ <span class="math inline">\(\frac{\epsilon}{k-1}\)</span> å’Œ <span class="math inline">\(1-\epsilon\)</span>ï¼Œæ ‡å‡†çš„äº¤å‰ç†µæŸå¤±å°±æ˜¯ä¸ºäº†å¤„ç†è¿™ç§ soft targetã€‚è€Œäº‹å®ä¸Šï¼Œæœ€å¤§ä¼¼ç„¶å­¦ä¹  + softmax + hard target æ ¹æœ¬ä¸ä¼šæ”¶æ•›ï¼Œå› ä¸º softmax è‚¯å®šä¸ä¼šè¾“å‡ºç»å¯¹åœ° <span class="math inline">\(0\)</span> æˆ– <span class="math inline">\(1\)</span>ã€‚</p><h2><span id="multi-task-learning">Multi-Task Learning</span></h2><p>å¤šä»»åŠ¡å­¦ä¹ ä¹Ÿæ˜¯ä¸€ç§æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„æ–¹æ³•ï¼Œå¤šä¸ªä»»åŠ¡ä½¿ç”¨ç›¸åŒçš„è¾“å…¥ï¼Œä½†è¾“å‡ºä¸åŒï¼Œæ•´ä¸ªæ¨¡å‹çš„å‚æ•°åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š</p><ol type="1"><li>ä»»åŠ¡ç›¸å…³çš„å‚æ•°ï¼Œåªä»ä»»åŠ¡ç›¸å…³çš„æ ·æœ¬ä¸­ä¼˜åŒ–å‚æ•°ï¼Œåœ¨ä¸‹å›¾ä¸­çš„ä¸Šå±‚</li><li>ä¸€èˆ¬çš„å‚æ•°ï¼Œä¸ä¸ä»»åŠ¡ç›¸å…³ï¼Œå¯ä»¥ä»æ‰€æœ‰æ ·æœ¬ä¸­æ›´æ–°å‚æ•°ï¼Œåœ¨ä¸‹å›¾ä¸­çš„åº•å±‚ï¼ˆ<span class="math inline">\(h^{(shared)}\)</span>ï¼‰ã€‚</li></ol><p><img src="/images/f7.2.png"></p><p>ä»æ·±åº¦å­¦ä¹ çš„è§’åº¦æ¥è¯´ï¼š<em>among the factors that explain the variations observed in the data associated with the diï¬€erent tasks, some are shared across two or more tasks</em>.</p><h2><span id="early-stopping">Early Stopping</span></h2><p>å¦‚æœæˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹æ‹Ÿåˆèƒ½åŠ›è¿‡å¼ºçš„è¯ï¼Œå°±ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œè®­ç»ƒè¯¯å·®ä¸€ç›´å‡å°ï¼Œä½†äº¤å‰éªŒè¯çš„è¯¯å·®å…ˆå‡å°ï¼Œç„¶ååœ¨æŸä¸ªå€¼è¾¾åˆ°æœ€å°ï¼Œåæ¥åˆå¢å¤§ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><p><img src="/images/f7.3.png"></p><p>è¿™æ—¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <strong>early stopping ç­–ç•¥</strong>ï¼Œåœ¨æ¯æ¬¡è®¡ç®— validation loss ä¹‹åï¼ŒæŠŠè¯¥ loss ä¸è¾¾åˆ°çš„æœ€å°å€¼æ¯”è¾ƒï¼Œè‹¥å®ƒå°äºæœ€å°å€¼ï¼Œåˆ™æ›´æ–°æœ€å°å€¼å¹¶æ‹·è´ä¸€ä»½å½“å‰çš„å‚æ•°ï¼›å¦åˆ™ç»§ç»­ä¸‹ä¸€è½®è®­ç»ƒã€‚è®­ç»ƒç»“æŸè¿”å›æ‹·è´çš„å‚æ•°è€Œä¸æ˜¯æœ€åä¸€è½®è®­ç»ƒçš„å‚æ•°ã€‚</p><p>Early stopping ç­–ç•¥æ˜¯ä¸€ç§å¾ˆå¸¸ç”¨æ­£åˆ™åŒ–æ–¹æ³•ï¼Œå› ä¸ºå®ƒæ—¢æœ‰æ•ˆåˆç®€å•ã€‚å®ƒä¹Ÿå¯ä»¥çœ‹åšæ˜¯è¶…å‚æ•°é€‰æ‹©çš„æ–¹æ³•ï¼Œå› ä¸ºè®­ç»ƒçš„è½®æ•°ä¹Ÿæ˜¯ä¸ªè¶…å‚æ•°ï¼Œè€Œåº”ç”¨ early stopping ç­–ç•¥å°±å¯ä»¥è‡ªåŠ¨é€‰æ‹©è¿™ä¸ªå€¼ï¼Œè€Œä¸éœ€è¦å¤§é‡çŒœæµ‹ã€‚</p><p><strong>How early stopping acts as a regularizer</strong></p><p>Early stopping ä¼šé™åˆ¶æƒé‡æ›´æ–°æ¬¡æ•°ï¼Œå³é™åˆ¶äº†æƒé‡ï¼ˆå‚æ•°ï¼‰è¿œç¦»åˆå§‹æƒé‡çš„è·ç¦»ï¼Œå¦‚æœæœ€ä½³é‡‡å– <span class="math inline">\(\tau\)</span> è½®è¿­ä»£ï¼Œå­¦ä¹ é€Ÿç‡ä¸º <span class="math inline">\(\epsilon\)</span> ï¼Œé‚£ä¹ˆå®ƒä¿©çš„ä¹˜ç§¯ <span class="math inline">\(\epsilon\tau\)</span> å°±ç±»ä¼¼äº <span class="math inline">\(L^2\)</span> æ­£åˆ™åŒ–ä¸­çš„ç³»æ•°ï¼</p><p><img src="/images/f7.4.png"></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Regularization </tag>
            
            <tag> L1 Norm </tag>
            
            <tag> L2 Norm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç‰©è”ç½‘å®‰å…¨æ¦‚è®º</title>
      <link href="/2017/07/06/%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%89%E5%85%A8%E6%A6%82%E8%AE%BA/"/>
      <url>/2017/07/06/%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%89%E5%85%A8%E6%A6%82%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#æ¦‚è®º">æ¦‚è®º</a></li><li><a href="#å¯†ç å­¦åŸºç¡€">å¯†ç å­¦åŸºç¡€</a></li><li><a href="#ç°ä»£å¸¸è§„å¯¹ç§°åŠ å¯†æŠ€æœ¯">ç°ä»£å¸¸è§„å¯¹ç§°åŠ å¯†æŠ€æœ¯</a><ul><li><a href="#des">DES</a></li><li><a href="#triple-des">Triple DES</a></li><li><a href="#aes">AES</a></li></ul></li><li><a href="#å…¬é’¥å¯†ç ">å…¬é’¥å¯†ç </a><ul><li><a href="#éšæœºæ•°äº§ç”Ÿ">éšæœºæ•°äº§ç”Ÿ</a></li><li><a href="#å…¬é’¥å¯†ç ç®—æ³•">å…¬é’¥å¯†ç ç®—æ³•</a><ul><li><a href="#diffie-hellmanå¯†é’¥äº¤æ¢">Diffie-Hellmanå¯†é’¥äº¤æ¢</a></li><li><a href="#èƒŒåŒ…ç®—æ³•">èƒŒåŒ…ç®—æ³•</a></li><li><a href="#rsaç®—æ³•">RSAç®—æ³•</a></li></ul></li></ul></li><li><a href="#hashå‡½æ•°-æ•°å­—ç­¾åä¸èº«ä»½è®¤è¯">Hashå‡½æ•°ã€æ•°å­—ç­¾åä¸èº«ä»½è®¤è¯</a><ul><li><a href="#hashå‡½æ•°">Hashå‡½æ•°</a></li><li><a href="#æ•°å­—ç­¾å">æ•°å­—ç­¾å</a></li><li><a href="#èº«ä»½è®¤è¯">èº«ä»½è®¤è¯</a></li></ul></li><li><a href="#pki">PKI</a></li><li><a href="#åŸºäºèº«ä»½åŠ å¯†ä½“åˆ¶">åŸºäºèº«ä»½åŠ å¯†ä½“åˆ¶</a></li><li><a href="#ç‰©è”ç½‘å®‰å…¨">ç‰©è”ç½‘å®‰å…¨</a><ul><li><a href="#å¯†ç å­¦åœ¨åˆ†å¸ƒå¼ä¼ æ„Ÿå™¨ç½‘ç»œdsnä¸­çš„åº”ç”¨">å¯†ç å­¦åœ¨åˆ†å¸ƒå¼ä¼ æ„Ÿå™¨ç½‘ç»œï¼ˆDSNï¼‰ä¸­çš„åº”ç”¨</a></li><li><a href="#åŸºäºå¯†ç å­¦çš„rfidè®¤è¯">åŸºäºå¯†ç å­¦çš„RFIDè®¤è¯</a></li><li><a href="#åŸºäºpkeçš„rfidè®¤è¯">åŸºäºPKEçš„RFIDè®¤è¯</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="æ¦‚è®º">æ¦‚è®º</span></h2><p><em>ä¿¡æ¯å®‰å…¨çš„å«ä¹‰</em></p><blockquote><p>ä¿¡æ¯å®‰å…¨æ˜¯ä¸€é—¨æ¶‰åŠè®¡ç®—æœºç§‘å­¦ã€ç½‘ç»œæŠ€æœ¯ã€é€šä¿¡æŠ€æœ¯ã€å¯†ç æŠ€æœ¯ã€ä¿¡æ¯å®‰å…¨æŠ€æœ¯ã€åº”ç”¨æ•°å­¦ã€æ•°è®ºã€ä¿¡æ¯è®ºç­‰å¤šç§å­¦ç§‘çš„ç»¼åˆæ€§ç§‘å­¦ã€‚</p></blockquote><p>ä¿¡æ¯å®‰å…¨çš„æ•´ä½“ç›®æ ‡</p><ul><li>ç‰©ç†å®‰å…¨<ul><li>é˜²ç›—ã€é˜²ç«ã€é˜²é™ç”µã€é˜²é›·å‡»ã€é˜²ç”µç£æ³„æ¼</li></ul></li><li><em>é€»è¾‘å®‰å…¨</em><ul><li>è®¡ç®—æœºçš„é€»è¾‘å®‰å…¨éœ€è¦ç”¨å£ä»¤å­—ã€æ–‡ä»¶è®¸å¯ã€æŸ¥è´¦ç­‰æ–¹æ³•æ¥å®ç°</li></ul></li><li>æ“ä½œç³»ç»Ÿå®‰å…¨</li><li>è”ç½‘å®‰å…¨</li></ul><p><strong>å®‰å…¨å››è¦ç´ </strong></p><ul><li>ä¿å¯†æ€§<ul><li>ä¿è¯ä¿¡æ¯ä¸ºæˆæƒè€…äº«ç”¨è€Œä¸æ³„æ¼ç»™æœªç»æˆæƒè€…</li></ul></li><li>å®Œæ•´æ€§<ul><li>æ•°æ®å®Œæ•´æ€§ï¼Œæœªè¢«æœªæˆæƒç¯¡æ”¹æˆ–è€…æŸå</li><li>ç³»ç»Ÿå®Œæ•´æ€§ï¼Œç³»ç»Ÿæœªè¢«éæˆæƒæ“çºµï¼ŒæŒ‰æ—¢å®šçš„åŠŸèƒ½è¿è¡Œ</li></ul></li><li><em>å¯ç”¨æ€§</em><ul><li>ä¿è¯ä¿¡æ¯å’Œä¿¡æ¯ç³»ç»Ÿéšæ—¶ä¸ºæˆæƒè€…æä¾›æœåŠ¡;ä¸è¦å‡ºç°ç”±äºéæˆæƒè€…çš„æ»¥ç”¨ï¼Œå´å¯¹æˆæƒè€…æ‹’ç»æœåŠ¡çš„æƒ…å†µ</li></ul></li><li><em>å¯é æ€§</em><ul><li>ç‰¹å®šè¡Œä¸ºå’Œç»“æœçš„ä¸€è‡´æ€§</li><li>å¯é æ€§æ˜¯æŒ‡ç³»ç»Ÿåœ¨è§„å®šæ¡ä»¶ä¸‹å’Œè§„å®šæ—¶é—´å†…ã€å®Œæˆè§„å®šåŠŸèƒ½çš„æ¦‚ç‡ã€‚å¯é æ€§æ˜¯â½¹ç½‘ç»œå®‰å…¨æœ€åŸºæœ¬çš„è¦æ±‚ä¹‹ä¸€ï¼Œç½‘ç»œï¥§å¯é ï¼Œäº‹æ•…ï¥§æ–­ï¼Œä¹Ÿå°±è°ˆä¸ä¸Šç½‘ç»œçš„å®‰å…¨ã€‚ç›®å‰ï¼Œå¯¹äºâ½¹ç»œå¯é æ€§çš„ç ”ç©¶åŸºæœ¬ä¸Šåé‡äºç¡¬ä»¶å¯é æ€§â½…é¢ã€‚ç ”åˆ¶â¾¼é«˜å¯é æ€§å…ƒå™¨ä»¶è®¾å¤‡ï¼Œé‡‡å–åˆï§¤çš„å†—ä½™å¤‡ä»½æªæ–½ä»æ˜¯æœ€åŸº æœ¬çš„å¯é æ€§å¯¹ç­–ï¼Œç„¶è€Œï¼Œæœ‰è®¸å¤šæ•…éšœå’Œäº‹æ•…ï¼Œåˆ™ä¸è½¯ä»¶å¯é æ€§ã€â¼ˆå‘˜å¯é æ€§å’Œç¯å¢ƒå¯é æ€§æœ‰å…³ã€‚</li><li>åŒºåˆ†</li></ul></li></ul><p><em>å¨èƒæ¥æº</em></p><ul><li><em>ç‰©ç†å¨èƒ</em><ul><li>å·çªƒã€åºŸç‰©æœç´¢ã€é—´è°è¡Œä¸ºã€èº«ä»½è¯†åˆ«é”™è¯¯</li></ul></li><li><em>ç³»ç»Ÿæ¼æ´é€ æˆçš„å¨èƒ</em><ul><li>ä¹˜è™šè€Œå…¥ã€ä¸å®‰å…¨æœåŠ¡ã€é…ç½®å’Œåˆå§‹åŒ–</li></ul></li><li><em>èº«ä»½é‰´åˆ«å¨èƒ</em><ul><li>å£ä»¤åœˆå¥—ï¼ˆé’“é±¼ï¼‰</li><li>å£ä»¤ç ´è§£</li><li>ç®—æ³•è€ƒè™‘ä¸å‘¨</li><li>ç¼–è¾‘å£ä»¤</li><li>çº¿ç¼†è¿æ¥å¨èƒ<ul><li>çªƒå¬</li><li>æ‹¨å·è¿›å…¥</li><li>å†’åé¡¶æ›¿</li></ul></li></ul></li><li><em>æœ‰å®³ç¨‹åºå¨èƒ</em><ul><li>ç—…æ¯’</li><li>ä»£ç ç‚¸å¼¹</li><li>ç‰¹æ´›ä¼Šæœ¨é©¬</li><li>æ›´æ–°æˆ–ä¸‹è½½</li></ul></li></ul><p><em>å®‰å…¨å¨èƒçš„åˆ†ç±»</em></p><ul><li><em>ä¸­æ–­</em>ï¼šç³»ç»Ÿçš„è½¯ã€ç¡¬ä»¶èµ„æºç”±äºå„ç§å„æ ·çš„åŸå› é­åˆ°ç ´åï¼Œä½¿å¾—ç¨‹åºçš„æ­£å¸¸è¿â¾è¡Œè¡Œè¢«ä¸­æ–­æˆ–é€šä¿¡çº¿è·¯è·¯ ä¸Šæ•°æ®çš„ä¼ é€è¢«ä¸­æ–­ã€‚</li><li><em>çªƒå–</em>ï¼šæœªç»å…è®¸çš„â½¤ç”¨æˆ·â¾®éæ³•è·å¾—äº†äº†å¯¹ç³»ç»Ÿèµ„æºçš„è®¿é—®æƒï¼Œä»ä¸­çªƒå–äº†äº†å¯¹ä»–æœ‰â½¤ç”¨çš„æ•°æ®ï¼Œæˆ–è€…éª—å–è®¡ ç®—æœºä¸ºä»–ä¾›äº†äº†æŸç§æœåŠ¡ã€‚</li><li><em>ç¯¡æ”¹</em>ï¼šâ¾®éæ³•â½¤ç”¨æˆ·åœ¨è·å¾—äº†äº†å¯¹æŸé¡¹ä¿¡æ¯çš„è®¿é—®æƒåï¼Œå¯ä»¥å¯¹å®ƒè¿›â¾è¡Œè¡Œç¯¡æ”¹ï¼Œä¾‹ä¾‹å¦‚ä¿®æ”¹ç¨‹åºä½¿å®ƒå®Œæˆâ¾®éæ³• æ“ä½œè€…ç‰¹å®šçš„åŠŸèƒ½ï¼Œæˆ–è€…æ›´æ›´æ”¹æ•°æ®ï¼Œä½¿â¾ƒè‡ªâ¼°å·±è·åˆ©åˆ©ã€‚åœ¨â½¹ç½‘ç»œä¸Šä¼ é€çš„ä¿¡æ¯ä¹Ÿå¯èƒ½é­åˆ°ç¯¡æ”¹ã€æ·»åŠ ï¼Œä½¿ å…¶ç»“æœå¯¹æ”»å‡»è€…æœ‰åˆ©åˆ©ï¼Œâ½½è€Œåˆæ³•â½¤ç”¨æˆ·â½†æ— æ³•è·å¾—å‡†ç¡®æœ‰â½¤ç”¨çš„ä¿¡æ¯ã€‚</li><li><em>ä¼ªé€ </em>ï¼šæ”»å‡»è€…åœ¨æœªç»è®¸å¯çš„æƒ…å½¢ä¸‹ï¼Œåœ¨ç³»ç»Ÿä¸­äº§â½£ç”Ÿå‡ºè™šå‡çš„æ•°æ®æˆ–è™šå‡çš„æœåŠ¡ï¼Œä¾‹ä¾‹å¦‚åœ¨ç”µâ¼¦å­å•†åŠ¡ä¸­ï¼Œæ”»å‡»è€…å¯èƒ½å¸Œæœ›åœ¨â½¹ç½‘ç»œé€šä¿¡ç³»ç»Ÿä¸ŠåŠ ä¸Šâ¼€ä¸€äº›å‡çš„äº¤æ˜“æ˜“ï¼Œæˆ–åœ¨æ•°æ®åº“ä¸­å¢åŠ â¼€ä¸€æ­¤ä¼ªé€ çš„è®°å½•ï¼Œå¦ å¤–åœ¨â½¹ç½‘ç»œé€šä¿¡ä¸­é‡æ”¾ä»¥å‰è¿‡æ—¶çš„ä¿¡æ¯ç­‰ï¼Œä½¿â½¹ç½‘ç»œä½¿â½¤ç”¨è€…è½â¼Šå…¥æ”»å‡»è€…çš„é™·äº•ã€‚</li><li><em>å†’å……</em>ï¼šå‡å†’â½¤ç”¨æˆ·èº«ä»½æ˜¯â¼€ä¸€ç§å¸¸â»…è§çš„â½¹ç½‘ç»œæ”»å‡»â¼¿æ‰‹æ®µï¼Œä¾‹ä¾‹å¦‚åœ¨ç”²ã€â¼„ä¹™åŒâ½…æ–¹é€šä¿¡æ—¶ï¼Œå¯èƒ½æ˜¯ä¸™åœ¨å†’å……â¼„ä¹™çš„ èº«ä»½ä¸ç”²é€šä¿¡ï¼Œæ­¤æ—¶ç”²å—åˆ°äº†äº†æ¬ºéª—ï¼Œç”±æ­¤å¼•èµ·ç”²å—åˆ°ç»æµç”šâ¾„è‡³æ”¿æ²»ä¸Šçš„æŸå¤±ã€‚</li><li><em>æŠµèµ–</em>ï¼šæŸäº›â½¤ç”¨æˆ·ä¸ºäº†äº†â¾ƒè‡ªâ¼°å·±çš„åˆ©åˆ©ç›Šï¼Œå¦è®¤â¾ƒè‡ªâ¼°å·±æ›¾ç»å‘å‡ºçš„ä¿¡æ¯(å¦‚å¦è®¤ä»–å‘å‡ºçš„è½¬å¸ä¿¡æ¯)æˆ–è€…å¦è®¤ä»– â¾ƒè‡ªâ¼°å·±æ”¶åˆ°äº†äº†ä¿¡æ¯ã€‚</li></ul><p><em>å¨èƒåŸå› </em></p><ul><li><em>è–„å¼±çš„è®¤è¯ç¯èŠ‚</em>ï¼šç½‘ç»œä¸Šçš„è®¤è¯é€šå¸¸æ˜¯ä½¿â½¤ç”¨å£ä»¤æ¥å®ç°çš„ï¼Œä½†å£ä»¤æœ‰å…¬è®¤çš„è–„å¼±æ€§ã€‚ç½‘ä¸Šå£ä»¤å¯ä»¥é€šè¿‡è®¸å¤šæ–¹æ³•ç ´è¯‘ï¼Œå…¶ä¸­æœ€å¸¸ç”¨çš„ä¸¤ç§æ–¹æ³•æ˜¯æŠŠåŠ å¯†çš„å£ä»¤è§£å¯†å’Œé€šè¿‡ä¿¡é“çªƒå–å£ä»¤ã€‚</li><li><em>ç³»ç»Ÿçš„æ˜“ï§ è¢«ç›‘è§†æ€§</em>ï¼šâ½¤æˆ·ä½¿â½¤Telnetæˆ–FTPè¿æ¥ä»–åœ¨è¿œç¨‹ ä¸»æœºä¸Šçš„è´¦æˆ·ï¼Œåœ¨ç½‘ä¸Šä¼ çš„å£ä»¤æ˜¯æ²¡æœ‰åŠ å¯†çš„ã€‚å…¥ä¾µè€…å¯ä»¥é€šè¿‡ç›‘è§†æºå¸¦ç”¨æˆ·åå’Œå£ä»¤çš„IPåŒ…è·å–å®ƒä»¬ï¼Œç„¶åä½¿â½¤è¿™äº›ç”¨æˆ·åå’Œâ¼ä»¤é€šè¿‡æ­£å¸¸æ¸ é“ç™»å½•åˆ°ç³»ç»Ÿã€‚å¦‚æœè¢«æˆªè·çš„æ˜¯ç®¡ï§¤å‘˜çš„â¼ä»¤ï¼Œé‚£ä¹ˆè·å–ç‰¹æƒçº§è®¿é—®å°±å˜å¾—æ›´å®¹ï§ ï¦ºã€‚æˆåƒä¸Šä¸‡çš„ç³»ç»Ÿå°±æ˜¯è¢«è¿™ç§â½…æ–¹å¼ä¾µâ¼Šå…¥çš„ã€‚</li><li><em>ï§ æ¬ºéª—æ€§</em>ï¼šTCPæˆ–UDPæœåŠ¡ç›¸ä¿¡ä¸»æœºçš„åœ°å€ã€‚å¦‚æœä½¿â½¤â€œIP Source Routingâ€ï¼Œé‚£ä¹ˆæ”»å‡»è€…çš„ä¸»æœºå°±å¯ä»¥å†’å……ä¸€ä¸ªè¢«ä¿¡ä»»çš„ä¸»æœºæˆ–å®¢æˆ·ã€‚</li><li><em>æœ‰ç¼ºé™·çš„ç½‘ç»œæœåŠ¡å’Œç›¸äº’ä¿¡ä»»çš„ä¸»æœº</em>ï¼šä¸»æœºçš„å®‰å…¨ç®¡ï§¤æ—¢å›°éš¾æœ‰è´¹æ—¶ã€‚ä¸ºï¦ºé™ä½ç®¡ï§¤è¦æ±‚å¹¶å¢å¼ºå±€åŸŸç½‘ï¼Œä¸€äº›ç«™ç‚¹ä½¿â½¤ï¦ºè¯¸å¦‚NISå’ŒNFSä¹‹ç±»çš„æœåŠ¡ã€‚è¿™äº›æœåŠ¡é€šè¿‡å…è®¸ä¸€äº›æ•°æ®åº“(å¦‚â¼ä»¤æ–‡ä»¶)ä»¥åˆ†å¸ƒå¼â½…å¼ç®¡ï§¤ä»¥åŠå…è®¸ç³»ç»Ÿå…±äº«â½‚ä»¶å’Œæ•°æ®ï¼Œåœ¨å¾ˆâ¼¤ç¨‹åº¦ä¸Šå‡è½»ï¦ºè¿‡å¤šçš„ç®¡ç†å·¥ä½œï¥¾ã€‚ä½†è¿™äº›æœåŠ¡å¸¦æ¥ï¦ºä¸ï¥§å®‰å…¨å› ç´ ï¼Œå¯ä»¥è¢«æœ‰ç»éªŒé—¯å…¥è€…åˆ©ç”¨ä»¥è·å¾—è®¿é—®æƒã€‚</li><li><em>å¤æ‚çš„è®¾ç½®å’Œæ§åˆ¶</em>ï¼šä¸»æœºç³»ç»Ÿçš„è®¿é—®æ§åˆ¶é…ç½®å¤æ‚ä¸”éš¾äºéªŒè¯ã€‚å› æ­¤å¶ç„¶çš„é…ç½®é”™è¯¯ä¼šä½¿é—¯å…¥è€…è·å–è®¿é—®æƒã€‚ä¸€äº›ä¸»è¦çš„Unixç»é”€å•†ä»ç„¶æŠŠUnixé…ç½®æˆå…·æœ‰æœ€å¤§è®¿é—®æƒçš„ç³»ç»Ÿï¼Œè¿™å°†å¯¼è‡´æœªç»è®¸å¯çš„è®¿é—®ã€‚</li><li><em>æ— æ³•ä¼°è®¡ä¸»æœºçš„å®‰å…¨æ€§</em>ï¼šä¸»æœºç³»ç»Ÿçš„å®‰å…¨æ€§â½†æ³•å¾ˆå¥½çš„ä¼°è®¡:éšç€ä¸€ä¸ªç«™ç‚¹çš„ä¸»æœºæ•°é‡ï¥¾çš„å¢åŠ ï¼Œç¡®ä¿æ¯å°ä¸»æœºçš„å®‰å…¨æ€§éƒ½å¤„åœ¨â¾¼â½”å¹³çš„èƒ½ï¦Šå´åœ¨ä¸‹é™ã€‚åªâ½¤ç®¡ï§¤â¼€å°ç³»ç»Ÿçš„èƒ½ï¦Šæ¥ç®¡ç†ï§¤å¦‚æ­¤å¤šçš„ç³»ç»Ÿå°±å®¹æ˜“çŠ¯é”™è¯¯ã€‚å¦ä¸€å› ç´ æ˜¯ç³»ç»Ÿç®¡ï§¤çš„ä½œâ½¤ç»å¸¸å˜æ¢å¹¶ï¨ˆåŠ¨è¿Ÿç¼“ã€‚è¿™å¯¼è‡´â¼€äº›ç³»ç»Ÿçš„å®‰å…¨æ€§â½å¦ä¸€äº›è¦ä½ã€‚è¿™äº›ç³»ç»Ÿå°†æˆä¸ºè–„å¼±ç¯èŠ‚ï¼Œæœ€ç»ˆå°†ç ´åè¿™ä¸ªå®‰å…¨é“¾ã€‚</li></ul><p><em>å®‰å…¨æœºåˆ¶</em></p><ul><li>åŠ å¯†æœºåˆ¶<ul><li>åŠ å¯†æ˜¯æä¾›ä¿¡æ¯ä¿å¯†çš„æ ¸â¼¼æ–¹æ³•</li></ul></li><li><em>è®¿é—®æ§åˆ¶æœºåˆ¶</em><ul><li>è®¿é—®æ§åˆ¶å¯ä»¥é˜²æ­¢æœªç»æˆæƒçš„ç”¨æˆ·éæ³•ä½¿ç”¨ç³»ç»Ÿèµ„æºï¼Œè¿™ç§æœåŠ¡ä¸ä»…å¯ä»¥ä¾›ç»™å•ä¸ªç”¨æˆ·ï¼Œä¹Ÿå¯ä»¥ä¾›ç»™ç”¨æˆ·ç»„çš„æ‰€æœ‰ç”¨æˆ·ã€‚</li><li>åˆ†ç±»<ul><li>è‡ªä¸»è®¿é—®æ§åˆ¶<ul><li>â¾ƒè‡ªä¸»è®¿é—®æ§åˆ¶æ˜¯æŒ‡æ•°æ®çš„æ‹¥æœ‰è€…æœ‰æƒå†³å®šç³»ç»Ÿä¸­çš„å“ªäº›â½¤ç”¨æˆ·å¯¹ä»–çš„æ•°æ®å…·æœ‰è®¿é—®æƒï¼Œä»¥åŠå…·æœ‰ä»€ä¹ˆæ ·çš„è®¿é—®æƒã€‚</li></ul></li><li>å¼ºåˆ¶è®¿é—®æ§åˆ¶<ul><li>è®¡ç®—æœºç³»ç»Ÿæ ¹æ®äº‹å…ˆç¡®å®šçš„å®‰å…¨ç­–ç•¥ï¼Œå¯¹â½¤ç”¨æˆ·çš„è®¿é—®æƒé™è¿›â¾å¼ºåˆ¶æ€§çš„æ§åˆ¶</li></ul></li><li>åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶<ul><li>ä¸ºäº†åæ˜ å®é™…å·¥ä½œä¸­çš„éœ€è¦ï¼Œ<em>å¯æ ¹æ®ç”¨æˆ·çš„å·¥ä½œèŒè´£è®¾ç½®è‹¥å¹²è§’è‰²</em>ï¼Œä¸åŒçš„ç”¨æˆ·å¯ä»¥å…·æœ‰ç›¸åŒçš„è§’è‰²ï¼Œåœ¨ç³»ç»Ÿä¸­äº«æœ‰ç›¸åŒçš„æƒåŠ›ï¼ŒåŒä¸€ä¸ªç”¨æˆ·åˆå¯ä»¥åŒæ—¶å…·æœ‰å¤šä¸ªä¸åŒçš„è§’è‰²ï¼Œåœ¨ç³»ç»Ÿä¸­è¡Œä½¿å¤šä¸ªè§’è‰²çš„æƒåŠ›ã€‚</li></ul></li></ul></li></ul></li><li><em>æ•°æ®å®Œæ•´æ€§æœºåˆ¶</em><ul><li>æ•°æ®å•å…ƒçš„å®Œæ•´æ€§<ul><li>æ˜¯æŒ‡ç»„æˆä¸€ä¸ªå•å…ƒçš„ä¸€æ®µæ•°æ®ä¸è¢«ç ´åå’Œå¢åˆ ç¯¡æ”¹</li></ul></li><li>æ•°æ®åºåˆ—çš„å®Œæ•´æ€§<ul><li>æ˜¯æŒ‡å‘å‡ºçš„æ•°æ®åˆ†å‰²ä¸ºæŒ‰åºåˆ—å·ç¼–æ’çš„è®¸å¤šå•å…ƒæ—¶ï¼Œåœ¨æ¥æ”¶æ—¶è¿˜èƒ½æŒ‰åŸæ¥çš„åºåˆ—æŠŠæ•°æ®ä¸²è”èµ·æ¥ï¼Œè€Œä¸è¦å‘ç”Ÿæ•°æ®å•å…ƒçš„ä¸¢å¤±ã€é‡å¤ã€ä¹±åºã€å‡å†’ç­‰æƒ…å†µã€‚</li></ul></li></ul></li><li>æ•°å­—ç­¾åæœºåˆ¶<ul><li>è§£å†³ï¼šå¦è®¤ã€ä¼ªé€ ã€å†’å……ã€ç¯¡æ”¹</li></ul></li><li>äº¤æ¢é‰´åˆ«æœºåˆ¶<ul><li>å£ä»¤ã€å¯†ç æŠ€æœ¯ã€ç‰¹å¾å®ç‰©</li></ul></li><li>å…¬è¯æœºåˆ¶<ul><li>ä¸ºäº†å…å¾—äº‹åè¯´ä¸æ¸…ï¼Œå¯ä»¥æ‰¾ä¸€ä¸ªå¤§å®¶éƒ½ä¿¡ä»»çš„å…¬è¯æœºæ„ï¼Œå„æ–¹çš„äº¤æ¢çš„ä¿¡æ¯éƒ½é€šè¿‡å…¬è¯æœºæ„æ¥ä¸­è½¬ã€‚å…¬è¯æœºæ„ä»ä¸­è½¬çš„ä¿¡æ¯é‡Œ å–å¿…è¦çš„è¯æ®ï¼Œæ—¥åä¸€æ—¦å‘ç”Ÿçº çº·ï¼Œå°±å¯ä»¥æ®æ­¤åšå‡ºä»²è£</li></ul></li><li>æµé‡å¡«å……æœºåˆ¶<ul><li>æµé‡å¡«å……æœºåˆ¶èƒ½å¤Ÿä¿æŒæµé‡åŸºæœ¬æ’å®šï¼Œå› æ­¤è§‚æµ‹è€…ä¸èƒ½è·å–ä»»ä½•ä¿¡æ¯ã€‚æµé‡å¡«å……çš„å®ç°æ–¹æ³•æ˜¯:éšæœºç”Ÿæˆæ•°æ®å¹¶å¯¹å…¶åŠ å¯†ï¼Œå†é€šè¿‡ç½‘ç»œå‘é€</li></ul></li><li>è·¯ç”±æ§åˆ¶æœºåˆ¶<ul><li>è·¯ç”±æ§åˆ¶æœºåˆ¶ä½¿å¾—å¯ä»¥æŒ‡å®šé€šè¿‡ç½‘ç»œå‘é€æ•°æ®çš„è·¯å¾„</li></ul></li><li>å®¡è®¡<ul><li>å®¡è®¡æ˜¯æ¨¡æ‹Ÿç¤¾ä¼šç›‘å¯Ÿæœºæ„åœ¨è®¡ç®—æœºç³»ç»Ÿä¸­ç”¨æ¥ç›‘è§†ã€ è®°å½•å’Œæ§åˆ¶ç”¨æˆ·æ´»åŠ¨çš„ä¸€ç§æœºåˆ¶ï¼Œå®ƒä½¿å½±å“ç³»ç»Ÿå®‰å…¨ çš„è®¿é—®å’Œè®¿é—®ä¼å›¾ç•™ä¸‹çº¿ç´¢ï¼Œä»¥ä¾¿äº‹ååˆ†æå’Œè¿½æŸ¥ã€‚ ç°ä»£å®‰å…¨è®¡ç®—æœºç³»ç»Ÿï¼Œé™¤äº†è¦æ±‚æœ‰èº«ä»½é‰´åˆ«ã€è®¿é—®æ§åˆ¶ã€åŠ å¯†ç­‰å®‰å…¨æªæ–½å¤–ï¼Œè¿˜è¦æ±‚ç³»ç»Ÿèƒ½å¯¹ç”¨æˆ·çš„è¡Œä¸ºè¿›è¡Œæœ‰æ•ˆçš„ç›‘æ§å’Œè®°å½•ï¼Œå³è¦æ±‚æœ‰å®¡è®¡åŠŸèƒ½</li></ul></li></ul><h2><span id="å¯†ç å­¦åŸºç¡€">å¯†ç å­¦åŸºç¡€</span></h2><p><em>å¯†ç å­¦èƒŒæ™¯</em></p><ul><li><em>é€šä¿¡ä¿å¯†</em>ï¼š60-70å¹´ä»£<ul><li>ä¿¡æ¯ä¿å¯†</li></ul></li><li><em>ä¿¡æ¯å®‰å…¨</em>ï¼š80-90å¹´ä»£<ul><li>æœºå¯†æ€§ã€å®Œæ•´æ€§ã€å¯ç”¨æ€§ã€ä¸å¯å¦è®¤æ€§</li></ul></li><li><em>ä¿¡æ¯ä¿éšœ</em>ï¼š90å¹´ä»£-2004<ul><li>å…¨ç”Ÿå‘½å‘¨æœŸçš„ä¿æŠ¤</li><li>ä¿¡æ¯ä¿éšœæ˜¯ä¸€ç§ä¿è¯ä¿¡æ¯å’Œä¿¡æ¯ç³»ç»Ÿèƒ½å¤Ÿå®‰å…¨è¿è¡Œçš„é˜²æŠ¤æ€§è¡Œä¸ºï¼Œæ˜¯ä¿¡æ¯å®‰å…¨åœ¨å½“å‰ä¿¡æ¯æ—¶ä»£çš„æ–°å‘å±•</li><li>ç›®çš„æ˜¯é‡‡å–æŠ€æœ¯ã€ç®¡ç†ç­‰ç»¼åˆæ€§æ‰‹æ®µï¼Œä½¿ä¿¡æ¯å’Œä¿¡æ¯ç³»ç»Ÿå…·å¤‡æœºå¯†æ€§ã€å®Œæ•´æ€§ã€å¯ç”¨æ€§ã€å¯è®¤è¯æ€§ã€ä¸å¯å¦è®¤æ€§ï¼Œä»¥åŠåœ¨é­å—æ”»å‡»åçš„å¯æ¢å¤æ€§</li><li><strong>å¯æ¢å¤æ€§</strong>ï¼ˆçƒ­å›æ»šï¼‰</li></ul></li><li><strong>å¯†ç å­¦ä¸è®¿é—®æ§åˆ¶çš„ç»Ÿä¸€</strong>ï¼š2005-<ul><li>åŸºç¡€æˆåŠŸï¼š<strong>åŸºäºèº«ä»½å¯†ç å­¦</strong></li><li>æ ¸å¿ƒæˆæœ<ul><li>åŸºäºå±æ€§å¯†ç å­¦(å…·æœ‰ç‰¹å®šå±æ€§å¯è§£å¯†)</li><li>ä»£ç†é‡åŠ å¯†(æ•°æ®æ‹¥æœ‰è€…å¯æŒ‡å®šçš„è§£å¯†)</li><li>å¯æœç´¢åŠ å¯†(æ•°æ®æ‹¥æœ‰è€…å¯å§”æ‰˜çš„å¯†æ–‡æ£€ç´¢)</li><li>å‡½æ•°åŠ å¯†(æ»¡è¶³ç‰¹å®šå‡½æ•°å¯è§£å¯†)</li><li>åŒæ€åŠ å¯†/ç­¾å(å¯è®¡ç®—çš„å¯†æ–‡/ç­¾å)</li></ul></li><li>é‡è¦åº”ç”¨<ul><li>äº‘å­˜å‚¨å®‰å…¨</li><li>åŸºäºå¯†ç å­¦çš„è®¿é—®æ§åˆ¶</li></ul></li></ul></li></ul><p><em>å¯†ç å­¦åŸºæœ¬æ¦‚å¿µ</em></p><ul><li>çŸ›ï¼šå¯†ç ç¼–ç å­¦</li><li>ç›¾ï¼šå¯†ç åˆ†æå­¦</li></ul><p><strong>å¯†ç ç®—æ³•åˆ†ç±»</strong></p><ul><li>å¤å…¸ï¼šå—é™åˆ¶çš„ç®—æ³•<ul><li>ç®—æ³•çš„ä¿å¯†æ€§åŸºäº<em>ä¿æŒç®—æ³•çš„ç§˜å¯†</em></li></ul></li><li>ç°ä»£ï¼šåŸºäºå¯†é’¥ï¼ˆkey-basedï¼‰çš„ç®—æ³•<ul><li>ç®—æ³•çš„ä¿å¯†æ€§åŸºäº<em>å¯¹å¯†é’¥çš„ä¿å¯†</em></li><li>å¯¹ç§°åŠ å¯†<ul><li>å‘é€æ–¹å’Œæ¥æ”¶æ–¹æœ‰ç›¸åŒçš„å¯†é’¥<ul><li>é¢å¯¹é¢åå•†-&gt;å°èŒƒå›´</li><li><strong>ä½¿ç”¨å…¬é’¥å¯†ç åå•†</strong></li></ul></li></ul></li><li>éå¯¹ç§°åŠ å¯†<ul><li>å…¬é’¥å¯†ç ç®—æ³•<ul><li>åŠ å¯†å¯†é’¥ï¼ˆå…¬é’¥ï¼‰å’Œè§£å¯†å¯†é’¥ï¼ˆç§é’¥ï¼‰ä¸åŒ</li></ul></li></ul></li></ul></li><li>åˆ†ç»„å¯†ç ï¼šä¸€æ¬¡åŠ å¯†ä¸€å— * å®é™…åº”ç”¨</li><li>æµå¯†ç ï¼›ä¸€æ¬¡ä¸€ä½æˆ–ä¸€å­èŠ‚ * å¤šç”¨äºç ”ç©¶<ul><li>ä¸ºä»€ä¹ˆï¼Ÿ<ul><li><strong>ç ”ç©¶å¾ˆéš¾ä¸€æ­¥åˆ°ä½æå‡ºåˆ†ç»„çš„æ–°å‹å…¬é’¥å¯†ç ç®—æ³•</strong>ï¼Œä¸ºäº†ç®€åŒ–éš¾åº¦ï¼Œå…ˆåšæµå¼çš„ï¼Œå†æ‰©å±•åˆ°åˆ†ç»„å¼</li></ul></li></ul></li></ul><p><em>å‘å±•</em></p><ul><li>1949å‰ï¼šè‰ºæœ¯ğŸ¨ * <strong>å¯†ç ç®—æ³•çš„å®‰å…¨æ€§æ²¡æœ‰ç†è®ºä¾æ®</strong>ï¼Œæ— æ³•å›ç­”åˆ°åº•æœ‰å¤šå®‰å…¨</li><li>1949-1975ï¼šç§‘å­¦ğŸ”¬ * ä¿¡æ¯è®ºçš„å‡ºç°-&gt;ç†è®ºä¾æ® * å®ç”¨æ€§ï¼Ÿ * <strong>æ²¡æœ‰åŠæ³•æœ‰æ•ˆç”Ÿæˆè¶³å¤Ÿå¤šçš„éšæœºæ•°</strong></li><li><strong>1976åï¼šå…¬é’¥å¯†ç å­¦</strong> * åŸºäº<strong>è®¡ç®—å¤æ‚æ€§ç†è®º</strong>çš„å¯†ç ç®—æ³• * ç†è®ºä¸Šå¯è¢«ç ´è§£ï¼Œä½†è®¡ç®—ä»£ä»·å·¨å¤§<ul><li>1976ï¼š<em>Diffie &amp; Hellman</em>æå‡ºå…¬é’¥å¯†ç ï¼Œä»¥å…¬é’¥å¯†ç å®ç°ä¼šè¯å¯†é’¥çš„åå•†</li><li>1977ï¼šRivest,Shamir &amp; Adlemanæå‡ºäº†<em>RSA</em>å…¬é’¥ç®—æ³•ï¼Œå› æ­¤è·å¾—å›¾çµå¥–</li><li>90å¹´ä»£é€æ­¥å‡ºç°äº†<em>åŸºäºæ¤­åœ†æ›²çº¿</em>çš„å…¬é’¥ç®—æ³•ï¼šæ¯”RSAæ›´å®‰å…¨æ›´é«˜æ•ˆï¼Œä½†å®é™…åº”ç”¨ä¾ç„¶è¾ƒå°‘</li><li>2000å¹´å·¦å³å‡ºç°äº†<em>åŸºäºåŒçº¿æ€§æ˜ å°„</em>çš„å…¬é’¥ç®—æ³•ï¼š<strong>åŸºäºèº«ä»½å¯†ç å­¦</strong>çš„é‡è¦æ•°å­¦åŸºç¡€</li><li>2000å¹´å·¦å³å‡ºç°äº†<em>åŸºäºæ ¼ä»£æ•°</em>çš„å…¬é’¥ç®—æ³•ï¼šåé‡å­æ—¶ä»£çš„åˆ©å™¨</li><li>2005å¹´ä»¥å<em>å…¬é’¥å¯†ç ä¸è®¿é—®æ§åˆ¶çš„èåˆ</em>ï¼šå®ç°äº†åŸºäºä¸å¯ä¿¡å­˜å‚¨ç¬¬ä¸‰æ–¹çš„åŠ å¯†æ•°æ®å…±äº«</li><li>2005å¹´ä»¥åå‡ºç°äº†<em>å…¨åŒæ€åŠ å¯†</em>ï¼šå®ç°äº†å¯†æ–‡çš„åŒæ€åŠ æ³•å’Œä¹˜æ³•è¿ç®—</li><li>å®‰å…¨é€šè®¯-&gt;å®‰å…¨æ§åˆ¶-&gt;å®‰å…¨è®¡ç®—</li></ul></li></ul><p>å¯†ç åˆ†æ</p><ol type="1"><li>å”¯å¯†ï¼šæ”»å‡»è€…è¢«åŠ¨åœ°(çªƒå¬)å…·æœ‰å¯†â½‚ï¤…yï¼Œä½†æ²¡æœ‰ç›¸åº”çš„æ˜æ–‡x</li><li>å·²çŸ¥æ˜æ–‡ï¼šæ”»å‡»è€…è¢«åŠ¨åœ°(çªƒå¬)å…·æœ‰æ˜â½‚xå’Œç›¸åº”çš„å¯†æ–‡y.</li><li>é€‰æ‹©æ˜æ–‡ï¼šï¼šæ”»å‡»è€…å¯è·å¾—å¯¹åŠ å¯†æœºçš„æš‚æ—¶è®¿é—®ï¼Œå› æ­¤å¯ä¸»åŠ¨é€‰æ‹©æ˜æ–‡xï¼Œå¹¶å¾—åˆ°ç›¸åº”çš„å¯†æ–‡y</li><li>é€‰æ‹©å¯†æ–‡ï¼šæ”»å‡»è€…å¯è·å¾—å¯¹è§£å¯†æœºçš„æš‚æ—¶è®¿é—®ï¼Œå› æ­¤å¯ä¸»åŠ¨é€‰æ‹©å¯†â½‚ï¤…yï¼Œå¹¶å¾—åˆ°ç›¸åº”çš„æ˜æ–‡x</li></ol><p>ç°ä»£å¯†ç å­¦è¦æ±‚ï¼š</p><ol type="1"><li>ä¸èƒ½ç ´è§£å¯†é’¥</li><li>ä¸èƒ½ç ´è§£æ˜æ–‡</li><li>ä¸èƒ½ç ´è§£æ˜æ–‡çš„è¯­ä¹‰</li></ol><p><strong>å¯†ç ç®—æ³•çš„å®‰å…¨æ€§åº¦é‡</strong></p><ul><li>æ— æ¡ä»¶å®‰å…¨<ul><li>æ— è®ºç ´è¯‘è€…æœ‰å¤šå°‘å¯†æ–‡ï¼Œä»–ä¹Ÿæ— æ³•è§£å‡ºå¯¹åº”çš„æ˜æ–‡ï¼Œå³ä½¿ä»–è§£å‡ºäº†ï¼Œä»–ä¹Ÿæ— æ³•éªŒè¯ç»“æœçš„æ­£ç¡®æ€§</li><li>å¸¸ç”¨äºè¯„ä¼°<em>åŸºäºä¿¡æ¯è®º</em>çš„å¯†ç å­¦ç®—æ³•</li></ul></li><li><em>è®¡ç®—ä¸Šå®‰å…¨</em><ul><li>ç ´è¯‘çš„ä»£ä»·è¶…å‡ºä¿¡æ¯æœ¬èº«çš„ä»·å€¼ï¼›<em>ç ´è¯‘çš„æ—¶é—´è¶…å‡ºäº†ä¿¡æ¯çš„æœ‰æ•ˆæœŸ</em></li><li>å¸¸ç”¨äº<em>åŸºäºè®¡ç®—å¤æ‚æ€§</em>çš„å¯†ç å­¦ç®—æ³•</li></ul></li></ul><p><em>å¤å…¸å¯†ç ï¼ˆè®¡ç®—é¢˜ï¼‰</em></p><ul><li>ä»£æ›¿å¯†ç  * æ˜æ–‡ç©ºé—´æ¢ä¸ºå¯†æ–‡ç©ºé—´<ul><li><em>ç®€å•ä»£æ›¿å¯†ç ï¼å•å­—æ¯å¯†ç </em><ul><li>æ˜æ–‡çš„ä¸€ä¸ªå­—ç¬¦ç”¨ç›¸å¯¹å›ºå®šçš„ä¸€ä¸ªå¯†æ–‡å­—ç¬¦ä»£æ›¿</li></ul></li><li><em>å¤šå­—æ¯å¯†ç </em><ul><li>æ˜æ–‡ä¸­çš„å­—ç¬¦æ˜ å°„åˆ°å¯†æ–‡ç©ºé—´çš„å­—ç¬¦<em>è¿˜ä¾èµ–äºå®ƒåœ¨ä¸Šä¸‹æ–‡ä¸­çš„ä½ç½®</em></li></ul></li></ul></li><li>åŒä½™ï¼šè‹¥æ•´æ•°aå’Œbæœ‰<code>(a mod q) = (b mod q)</code>ï¼Œåˆ™ç§°aä¸båœ¨mod qä¸‹åŒä½™<ul><li><strong>ç§»ä½å¯†ç </strong><ul><li>å¯†é’¥<code>k in Z26</code></li><li>åŠ å¯†ç®—æ³•ï¼š<code>e(x) = x + k mod 26</code></li><li>è§£å¯†ç®—æ³•ï¼š<code>d(y) = y - k mod 26</code></li><li>æ³¨ï¼š26ä¸ªè‹±æ–‡å­—æ¯ä¸æ¨¡26å‰©ä½™ç±»é›†åˆ<code>{0, ..., 25}</code>ä¸€ä¸€å¯¹åº”</li></ul></li><li><strong>ä¹˜æ•°å¯†ç </strong>ï¼ˆå¯¹ç§°åŠ å¯†ï¼‰<ul><li>å¯†é’¥<code>k</code>ä¸26äº’ç´ ï¼Œå³<code>K={1,3,5,7,9,11,15,17,19,21,23,25}</code></li><li>åŠ å¯†ç®—æ³•ï¼š<code>e(x) = kx mod 26</code></li><li>è§£å¯†ç®—æ³•ï¼š<code>d(y) = k-1 y mod 26</code></li><li>ä¸ºä»€ä¹ˆKè¦ä¸26äº’ç´ ï¼Ÿ<ul><li>ä¿è¯åŠ å¯†å˜æ¢æ˜¯ä¸€ä¸€æ˜ å°„çš„</li><li>ä¿è¯Kæœ‰é€†å…ƒï¼Œä½¿è§£å¯†ç®—æ³•æˆç«‹</li></ul></li><li><em>Ké€†è®¡ç®—</em><ul><li>å¯¹äºæ•´æ•°aã€pï¼Œå¦‚æœå­˜åœ¨æ•´æ•°bï¼Œæ»¡è¶³<code>ab mod p =1</code>ï¼Œåˆ™è¯´ï¼Œbæ˜¯açš„æ¨¡pä¹˜æ³•é€†å…ƒ</li></ul></li><li>æ›´å®¹æ˜“å—å”¯å¯†æ–‡æ”»å‡»</li></ul></li><li><strong>ä»¿å°„å¯†ç </strong><ul><li>å¯†é’¥<code>a,b in {0, 25}</code>å¹¶ä¸”<code>a</code>ä¸26äº’ç´ </li><li>åŠ å¯†ç®—æ³•ï¼š<code>e(x) = ax + b mod 26</code></li><li>è§£å¯†ç®—æ³•ï¼š<code>d(y) = a-1 (y - b) mod 26</code></li></ul></li><li>å¤šåä»£æ›¿å¯†ç <ul><li>æ˜ å°„æ˜¯ä¸€å¯¹å¤šçš„ï¼Œæ©ç›–æ˜æ–‡çš„é¢‘ç‡å·®å¼‚</li><li><strong>é‡è¦ï¼šåŠ ä¸Šäº†æŠ›å¸çš„éšæœºæ•°ï¼</strong></li></ul></li><li>å¤šè¡¨ä»£æ›¿å¯†ç <ul><li>æ˜¯ä»¥ä¸€ç³»åˆ—ä»£æ¢è¡¨ä¾æ­¤å¯¹æ˜æ–‡æ¶ˆæ¯çš„å­—æ¯è¿›è¡Œä»£æ¢çš„æ–¹æ³•</li><li>éå‘¨æœŸï¼šæ‰€æœ‰æ˜æ–‡å­—ç¬¦ï¼Œæ¯ä¸ªæ˜æ–‡å­—ç¬¦æœ‰ä¸€ä¸ªä¸åŒçš„å•è¡¨åŠ å¯†</li><li>å‘¨æœŸï¼šç”¨ä¸€å®šæ•°é‡çš„å•è¡¨å¾ªç¯åŠ å¯†<ul><li>ä¾ç„¶ä¿ç•™ä¸€å®šé¢‘ç‡</li><li>é‡ç åˆ†ææ³•</li></ul></li><li><strong>VigenÃ©reå¯†ç </strong> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage.png"></li><li><strong>Vernamå¯†ç </strong><ul><li>åŠ å¯†ï¼š<code>Ci = Pi ^ Ki</code></li><li>è§£å¯†ï¼š<code>Pi = Ci ^ Ki</code></li></ul></li><li><strong>Playfairå¯†ç </strong> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-1.png"></li><li><strong>Hillå¯†ç </strong> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-2.png"></li></ul></li></ul></li><li><strong>å¤å…¸å¯†ç çš„å®‰å…¨æ€§ç¼ºé™·</strong><ul><li>é¢‘ç‡æ”»å‡»</li><li>æ— éšæœº</li></ul></li></ul><p><strong>ç”±ã€Šé£è¯­è€…ã€‹çœ‹å¯†ç æ— å¤„ä¸åœ¨</strong></p><ul><li>è¯­è¨€æœ¬èº«ä¹Ÿæ˜¯ä¸€ç§å¯†ç ï¼Œå—é™çš„å¯†ç ç®—æ³•</li><li><em>åŠ å¯†ï¼šåå•†å‡ºä¸€ç§åªæœ‰å‘é€æ–¹å’Œæ¥æ”¶æ–¹çœ‹å¾—æ‡‚çš„è¯­è¨€</em></li></ul><p><strong>ç”±â€œä¿¡ä»»â€çœ‹å¦‚ä½•è¯´æ˜å¯†ç ç®—æ³•çš„å®‰å…¨æ€§</strong></p><ul><li>åˆ°åº•ä»€ä¹ˆæ˜¯å®‰å…¨ï¼Ÿ<ul><li>æ°´çš„å®‰å…¨æ€§ï¼Ÿ<ul><li>ä¸ºä»€ä¹ˆè®¤ä¸ºæ²¡æ¯’ï¼Ÿ<ul><li>å› ä¸ºå–è¿‡</li><li>æ­£è§„å‚å•†</li><li>æ­£è§„æ¸ é“</li><li>ç›¸ä¿¡ç»™ä½ è¯´çš„äººä¸ä¼šå®³ä½ </li><li>ç›¸ä¿¡å‚å®¶ä¸ä¼šå®³ä½ </li><li>â€¦.</li></ul></li><li>å› ä¸ºç›¸ä¿¡äº†xxxï¼Œæ‰€ä»¥ç›¸ä¿¡è¿™ç“¶æ°´æ˜¯å®‰å…¨çš„</li></ul></li><li>ä¸èƒ½ä¿è¯ç»å¯¹å®‰å…¨<ul><li>å¦‚æœä¿è¯ç»å¯¹å®‰å…¨ï¼Œä¸€å®šè¦è¯•ä¸€ä¸‹</li></ul></li><li><strong>å®‰å…¨åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹æ— æ³•å®è¯</strong></li><li>å®‰å…¨æ¥æºäº<strong>ä¿¡ä»»</strong>ï¼Œä¾æ‰˜äºå·²çŸ¥<strong>ä¿¡ä»»æº</strong>ï¼Œä½¿å¾—æŸä¸€ä¸ªåœºæ™¯æ˜¯å®‰å…¨çš„</li><li><strong>ä¿¡ä»»æºæœ‰ä¿¡ä»»ç¨‹åº¦çš„å·®å¼‚</strong><ul><li>å¯¹å®‰å…¨é€ æˆå½±å“</li></ul></li><li>ç›´è§‚æ„Ÿè§‰åŒä¸€ç“¶æ°´å®‰å…¨æ€§æ˜¯å¸¸é‡ï¼Œä½†é€šè¿‡ç»™æ°´çš„æ–¹å¼å˜äº†ï¼Œå¯¼è‡´æ°´çš„å®‰å…¨æ€§çš„æ”¹å˜ã€‚<ul><li>å› ä¸ºä¿¡ä»»æºå˜äº†ï¼</li></ul></li><li><strong>ä¿¡ä»»æºæ˜¯åŠ¨æ€çš„</strong></li><li>å¦‚æœå¸Œæœ›äº§å“è¾¾åˆ°å¾ˆå¥½çš„å®‰å…¨æ€§ï¼Œåˆ™<em>ä¿¡ä»»æºè¦ä¿¡ä»»ç¨‹åº¦é«˜è€Œä¸”ç¨³å¥</em></li><li><em>ç°ä»£å¯†ç å­¦ä¿¡ä»»æº</em>ï¼šæ•°å­¦å…¬ç†ï¼ˆ<strong>å…¬è®¤çš„æ•°å­¦éš¾é¢˜</strong>ï¼‰</li><li>å¯†ç å»ºç«‹è¿‡ç¨‹ï¼Ÿ<ul><li>å‡è®¾-è¯æ˜</li><li>è¯æ˜å¦‚æœå­˜åœ¨æ”»å‡»è€…èƒ½å¤Ÿç ´è§£æˆ‘çš„åŠ å¯†ç®—æ³•ï¼Œé‚£ä¹ˆæˆ‘èƒ½ç”¨å®ƒè§£å†³å…¬è®¤çš„æ•°å­¦éš¾é¢˜</li><li>é€†å¦-&gt;ä¸æˆç«‹</li></ul></li><li>ä»€ä¹ˆæ˜¯æ±‚è§£æ•°å­¦é—®é¢˜ï¼Ÿ<ul><li>å‰æï¼šæœ‰è§£</li><li>æ•°å­¦é—®é¢˜ï¼šè§£åœ¨é—®é¢˜ä¸­ï¼Œå…³é”®åœ¨äºèƒ½ä¸èƒ½å±•ç¤ºå‡ºæ¥</li><li>æ•°å­¦éš¾é¢˜ï¼šè§£åœ¨é—®é¢˜æœ¬èº«ï¼Œä½†æ²¡åŠæ³•æœ‰æ•ˆå±•ç¤ºå‡ºæ¥<ul><li>ä½†æœ‰æ—¶é¢å¤–å¢åŠ ä¸€ä¸ªé‡ï¼Œå°±å¾ˆå¥½è§£</li><li>å¢åŠ çš„é‡-&gt;è§£å¯†å¯†é’¥</li><li>åŸå§‹é—®é¢˜-&gt;åŠ å¯†å¯†é’¥</li></ul></li></ul></li></ul></li></ul><h2><span id="ç°ä»£å¸¸è§„å¯¹ç§°åŠ å¯†æŠ€æœ¯">ç°ä»£å¸¸è§„å¯¹ç§°åŠ å¯†æŠ€æœ¯</span></h2><ul><li>DES</li><li>Triple DES</li><li>AES</li></ul><p><em>åˆ†ç»„å¯†ç </em></p><ul><li>åŸºæœ¬æ€æƒ³ï¼šå¯†æ–‡çš„ç»Ÿè®¡ç‰¹æ€§ä¸å¯†é’¥ç‹¬ç«‹</li><li><strong>è®¾è®¡åŸåˆ™</strong><ul><li><em>æ‰©æ•£ï¼ˆDiffusionï¼‰</em><ul><li>æ˜æ–‡ä¸­çš„å•ä¸ªæ•°å­—å½±å“å¯†æ–‡ä¸­çš„å¤šä¸ªæ•°å­—ï¼Œä»â½½ä½¿æ˜æ–‡çš„ç»Ÿè®¡ç‰¹å¾åœ¨å¯†æ–‡ä¸­æ¶ˆå¤±ï¼Œç›¸å½“äºæ˜æ–‡çš„ç»Ÿè®¡ç»“æ„è¢«æ‰©æ•£</li><li><em>ä½¿ç ´è§£æ˜æ–‡å˜å¾—å›°éš¾</em></li></ul></li><li><em>æ··ä¹±ï¼ˆConfusionï¼‰</em><ul><li>å¯†é’¥ä¸å¯†æ–‡ä¹‹é—´çš„ç»Ÿè®¡ä¿¡æ¯çš„å…³ç³»å˜å¾—å¤æ‚ï¼Œä»â½½å¢åŠ é€šè¿‡ç»Ÿè®¡â½…æ³•è¿›â¾æ”»å‡»çš„éš¾åº¦</li><li><em>ä½¿ç ´è§£å¯†é’¥å˜å¾—å›°éš¾</em></li></ul></li></ul></li><li>è½¯ä»¶è¦æ±‚<ul><li>ä½¿ç”¨å­å—ï¼ˆ8, 16, 32bitï¼‰å’Œç®€å•ï¼ˆCPUç›´æ¥æ”¯æŒçš„ï¼‰çš„æ“ä½œ</li></ul></li><li>ç¡¬ä»¶è¦æ±‚<ul><li>åŠ å¯†ç®—æ³•å’Œè§£å¯†ç®—æ³•å°½å¯èƒ½ä¸€æ ·-&gt;æˆæœ¬é™ä½</li></ul></li></ul><h3><span id="des">DES</span></h3><p><strong>å¦‚ä½•ä¿éšœåŠ è§£å¯†æ­£ç¡®æ€§</strong></p><ul><li>ä¾èµ–äº<strong>Feistelç»“æ„</strong>å®ç°åŠ è§£å¯†çš„æ­£ç¡®æ€§</li></ul><p><em>å¯†é’¥é•¿åº¦</em></p><ul><li>48bitï¼šå­å¯†é’¥é•¿åº¦</li><li>56bitï¼šçœŸæ­£ç”¨åŠ å¯†å’Œè§£å¯†çš„å¯†é’¥é•¿åº¦</li><li>64bitï¼šå…¶ä¸­æœ‰8æ¯”ç‰¹ä¸ç”¨åšåŠ è§£å¯†ï¼Œæ˜¯ç”¨æ¥åšå¥‡å¶æ ¡éªŒçš„</li></ul><p><em>Feistel</em>ç»“æ„</p><ul><li>ä¸ç®¡Få‡½æ•°æ€ä¹ˆè®¾è®¡ï¼Œä¸€å®šå¯ä»¥ä¿è¯<strong>åŠ å¯†è¿‡ç¨‹å’Œè§£å¯†è¿‡ç¨‹ä¸€æ¨¡ä¸€æ ·</strong></li><li>ç»“æ„ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-3.png"></li></ul><p><strong>S-Box</strong></p><ul><li>Sç›’æ— æ³•æ±‚é€†</li><li>åªä¾èµ–äº<strong>Feistelç»“æ„</strong>å®ç°åŠ è§£å¯†çš„æ­£ç¡®æ€§</li><li><em>æœ€â¼¤ä¿éšœå®‰å…¨æ€§</em></li></ul><p><em>DESç¼ºé™·</em></p><ul><li>å¼±å¯†é’¥<ul><li>å¯¼è‡´æ¯ä¸€è½®ä½¿ç”¨ç›¸åŒçš„å­å¯†é’¥</li></ul></li><li>åŠå¼±å¯†é’¥<ul><li>ä½¿ç”¨ä¸åŒå¯†é’¥åŠ å¯†ç›¸åŒæ˜æ–‡æ—¶ä¼šå¾—åˆ°ç›¸åŒå¯†æ–‡</li></ul></li></ul><p><strong>åˆ†ç»„å¯†ç çš„æ“ä½œæ¨¡å¼</strong></p><ol type="1"><li>ç”µå­å¯†ç æœ¬ï¼ˆECBï¼‰ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-4.png"><ul><li>åˆ†å—ï¼Œå•ç‹¬å¯¹æ¯ä¸€å—è¿›è¡ŒDESåŠ è§£å¯†</li><li>ä¼˜ç‚¹<ul><li>å¯å¹¶è¡Œ</li></ul></li><li>ç¼ºç‚¹<ul><li>å®‰å…¨æ€§ä¸å¤Ÿé«˜</li><li>ç¯¡æ”¹å¯†æ–‡å—ä½ç½®</li><li>æ— éšæœº-&gt;ç›¸åŒæ˜æ–‡ä¸€å®šå¾—åˆ°ç›¸åŒå¯†æ–‡-&gt;å­˜åœ¨é¢‘ç‡åˆ†æçš„å¯èƒ½æ€§</li></ul></li><li><em>æœ€ç›´è§‚ï¼Œå°±æ˜¯â½¤ç”¨DESåŠ å¯†é•¿æ–‡ä»¶ï¼ŒæŠŠâ»“æ–‡ä»¶åˆ‡å—ï¼Œä½†å®‰å…¨æ€§å¾ˆå·®</em></li></ul></li><li>å¯†ç åˆ†ç»„é“¾æ¥ï¼ˆCBCï¼‰ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-5.png"><ul><li>å¼•å…¥éšæœºæ•°-&gt;åˆå§‹å‘é‡-&gt;è§£å†³é¢‘ç‡åˆ†æ</li><li>å‰ä¸€å—å¯¹åä¸€å—æœ‰å½±å“-&gt;è§£å†³ç¯¡æ”¹å¯†æ–‡</li><li>ä¼˜ç‚¹<ul><li>æ— æ³•ç¯¡æ”¹å¯†æ–‡å—ä½ç½®</li></ul></li><li>ç¼ºç‚¹<ul><li>æ— æ³•å¹¶è¡Œ</li></ul></li><li><em>å¼•â¼Šå…¥éšæœºæ•°ï¼Œå¼•â¼Šå…¥å‰åå—çš„å…³è”å…³ç³»ï¼Œä½†ä¸ï¥§èƒ½å®ç°æµå¼</em></li></ul></li><li>å¯†ç åé¦ˆæ¨¡å¼ï¼ˆCFBï¼‰ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-6.png"><ul><li>æµå¼åŠ å¯†-&gt;åŠ å¯†æœ€å°å•ä½è‡ªå®šä¹‰</li><li>ä¼˜ç‚¹<ul><li>åŠ å¯†æœ€å°å•ä½è‡ªå®šä¹‰</li><li>é˜²ç¯¡æ”¹ï¼ˆé“¾æ¥æ¨¡å¼ï¼‰</li></ul></li><li>ç¼ºç‚¹<ul><li>åŠ å¯†é€Ÿåº¦æ²¡å‡†è¾¾ä¸åˆ°æµå¤±æ•°æ®äº§ç”Ÿçš„é€Ÿåº¦</li><li>æ— æ³•å¹¶è¡Œ</li></ul></li><li><em>æµå¼åŠ å¯†è¿‡ç¨‹ï¼Œä½†â½†æ— æ³•åº”å¯¹â¼¤å¤§é‡ï¥¾æµå¼æ•°æ®çŸ­æ—¶é—´åˆ°è¾¾</em></li></ul></li><li>è¾“å‡ºåé¦ˆï¼ˆOFBï¼‰ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-7.png"><ul><li>æŠŠä¸­é—´ç»“æœåé¦ˆå›å»-&gt;<strong>å¯ä»¥é¢„å¤„ç†</strong>-&gt;åŠ å¿«é€Ÿåº¦ï¼Œè§£å†³å¹¶è¡Œé—®é¢˜ <strong>è¿›åŒ–åŸå› </strong>ï¼šå…‹æœç¼ºç‚¹</li></ul></li></ol><h3><span id="triple-des">Triple DES</span></h3><p><strong>ä¸ºä»€ä¹ˆå‡ºç°</strong></p><ul><li>å› ä¸ºDESçš„56bitçš„ç§˜é’¥é•¿åº¦ï¥§è¶³ä»¥æŠµå¾¡ç©·ä¸¾æ”»å‡»</li><li>é—®é¢˜ï¼šDESå®‰å…¨æ€§ä¸é«˜-&gt; å†ç°æœ‰åŸºç¡€ä¸Šæ”¹è¿› or å®Œå…¨åšä¸€ä¸ªæ–°çš„</li></ul><p>é«˜å®‰å…¨æ€§çš„å¿…è¦æ€§ï¼š<strong>å¤šæ¬¡DESåŠ å¯†ä¸å•æ¬¡DESåŠ å¯†ä¸ç­‰ä»·</strong></p><p><strong>Triple DES</strong></p><ol type="1"><li>DES-EEE3ï¼šä¸‰ä¸ªä¸åŒçš„å¯†é’¥åŠ å¯†</li><li>DES-EDE3ï¼šåŠ å¯†-è§£å¯†-åŠ å¯†</li><li>DES-EEE2ï¼šK1 = K3</li><li>DES-EDE2: K1 = K3<ul><li>å…¼å®¹å¸¸è§„DESï¼šè‹¥K1=K2ï¼Œç›¸å½“äºä¸€æ¬¡DES<ul><li>ä¸ºä»€ä¹ˆè¦å…¼å®¹ï¼šæœ‰å¾ˆå¤šå·²ç”¨å•æ¬¡DESåŠ å¯†çš„æ•°æ®</li></ul></li><li>æ²¡æœ‰æœ‰æ•ˆæ”»å‡»æ–¹æ³•</li></ul></li></ol><h3><span id="aes">AES</span></h3><p><em>ï¼ˆä¸ºä»€ä¹ˆä¼šæœ‰AESï¼‰æå‡ºå…¨æ–°çš„å¯†ç ç®—æ³•</em> * æ¯”ä¸‰é‡DESå¿« * è‡³å°‘ä¸€æ ·å®‰å…¨ * æ•°æ®åˆ†ç»„é•¿åº¦ä¸º128æ¯”ç‰¹ * <strong>å¯†é’¥é•¿åº¦ä¸º128/192/256æ¯”ç‰¹</strong></p><p><strong>Rijindeal</strong></p><ul><li>ä¸å±äºFeistelç»“æ„-&gt;åŠ è§£å¯†ç®—æ³•ä¸åŒ</li><li>æœ‰è¾ƒå¥½çš„æ•°å­¦ç†è®ºä½œä¸ºåŸºç¡€</li><li>ç»“æœç®€å•ã€é€Ÿåº¦å¿«</li><li><em>AESéœ€è¦å¤šå°‘è½®å¯†é’¥ï¼š11ä¸ª</em></li><li><em>AESç¬¬10è½®æ²¡æœ‰åˆ—ï¦œæ··æ“ä½œ</em></li></ul><p><strong>AESå¦‚ä½•ä¿è¯åŠ è§£å¯†çš„æ­£ç¡®æ€§</strong></p><ul><li>è§£å¯†æ˜¯åŠ å¯†çš„<em>é€†å˜æ¢</em>ï¼ŒåŠ å¯†è¿‡ç¨‹ä¸­ä¸å­˜åœ¨ä¸å¯é€†å˜æ¢</li></ul><p><em>ä¸DESçš„Sç›’æ¯”è¾ƒ</em></p><ul><li>ç›¸åŒç‚¹<ul><li>éçº¿æ€§æ›¿ä»£</li><li>æä¾›<em>æ··ä¹±ä½œç”¨</em></li></ul></li><li>ä¸åŒç‚¹<ul><li>å¯é€†</li><li>ä¸ä¼šä¸¢å¤±ä¿¡æ¯</li></ul></li></ul><p><strong>åˆ—æ··åˆå˜æ¢</strong>ï¼ˆå…·æœ‰æ•°å­¦ç‰¹å¾ï¼‰</p><ul><li>çŸ©é˜µä¹˜æ³•ï¼Œå…¶ä¸­åŠ æ³•å˜æˆå¼‚æˆ–ï¼Œä¹˜æ³•å˜ä¸º<strong>å¤šé¡¹å¼ä¹˜æ³•</strong></li><li>ä»£æ›¿æ“ä½œï¼Œå°†çŠ¶æ€çš„åˆ—çœ‹ä½œæœ‰é™åŸŸGFä¸Šçš„4ç»´å‘é‡å¹¶è¢«æœ‰é™åŸŸGFä¸Šçš„ä¸€ä¸ªå›ºå®šå¯é€†æ–¹é˜µAä¹˜ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-8.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-9.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-10.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-11.png"></li><li>ä¸¾ä¾‹ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-12.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-13.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-14.png"></li></ul><p>Rijndaelå®‰å…¨æ€§</p><ul><li>æ²¡æœ‰å‘ç°å¼±å¯†é’¥æˆ–è¡¥å¯†é’¥</li><li>èƒ½æœ‰æ•ˆæŠµæŠ—ç›®å‰å·²çŸ¥çš„æ”»å‡»ç®—æ³•<ul><li>çº¿æ€§æ”»å‡»</li><li>å·®åˆ†æ”»å‡»</li></ul></li></ul><h2><span id="å…¬é’¥å¯†ç ">å…¬é’¥å¯†ç </span></h2><h3><span id="éšæœºæ•°äº§ç”Ÿ">éšæœºæ•°äº§ç”Ÿ</span></h3><p><em>éšæœºæ•°çš„åŸºæœ¬ç‰¹ç‚¹</em></p><ul><li><em>éšæœºæ€§</em><ul><li>å‡åŒ€åˆ†å¸ƒ</li><li>ç‹¬ç«‹æ€§</li></ul></li><li><em>ä¸å¯é¢„æµ‹æ€§</em></li></ul><p><em>ä¼ªéšæœºæ•°</em>ï¼šæ”»å‡»è€…åœ¨æœ‰æ•ˆæ—¶é—´å†…åˆ†è¾¨ä¸å‡ºæ˜¯çœŸéšæœºçš„è¿˜æ˜¯ä¼ªéšæœºçš„</p><p>æŠŠå¾ªç¯åŠ å¯†æ¢æˆDESï¼Œåœ¨ç°ä»£æœ‰å•¥é—®é¢˜ï¼Ÿ</p><ul><li>ç§˜é’¥â»“åº¦ï¥§å¤Ÿï¼Œæ˜“è¢«æš´åŠ›ç ´è§£ä»è€Œä¸§å¤±ï¥§å¯é¢„æµ‹æ€§</li></ul><p>BBSäº§ç”Ÿå™¨ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-15.png"></p><ul><li>åŸºäºå¤§æ•°åˆ†è§£</li><li><em>æœ€åä¸€æ­¥å»æ‰æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ</em><ul><li><em>å¯é¢„æµ‹</em>ï¼Œæ ¹æ®å‰ä¸€ä¸ªå¯é¢„æµ‹ä¸‹ä¸€ä¸ª</li></ul></li><li><em>ä¸ºä»€ä¹ˆé€‰æœ€å1æ¯”ç‰¹ï¼Ÿ</em><ul><li>Xiçš„æ¯ä¸ªæ¯”ç‰¹çš„éšæœºæ€§æœ‰å·®å¼‚ï¼Œè€Œ<em>éšæœºæ€§æœ€å¼ºçš„æ¯”ç‰¹æ˜¯æœ€ä½ä½</em>ï¼Œæ‰€ä»¥Biå–æœ€ä½æ¯”ç‰¹</li></ul></li></ul><h3><span id="å…¬é’¥å¯†ç ç®—æ³•">å…¬é’¥å¯†ç ç®—æ³•</span></h3><p><em>èµ·æºï¼ˆä¸ºä»€ä¹ˆä¼šå‡ºç°å…¬é’¥åŠ å¯†ç®—æ³•ï¼Ÿï¼‰</em></p><ul><li>åœ¨å¹¿åŸŸç½‘æƒ…å†µä¸‹ï¼Œå‘é€æ–¹å¦‚ä½•è®©æ¥æ”¶æ–¹æå‰çŸ¥é“å¯¹ç§°å¯†ç çš„å¯†é’¥æ˜¯ä»€ä¹ˆï¼Ÿ<ul><li><em>è§£å†³ï¦ºå¯¹ç§°åŠ å¯†çš„å¯†é’¥çš„åå•†ã€å‘é€é—®é¢˜</em></li></ul></li></ul><p>å…¬é’¥å¯†ç ç‰¹å¾</p><ul><li>å…¬é’¥ï¼šåŠ å¯†ï¼ˆå…¬å¼€çš„ï¼‰</li><li>ç§é’¥ï¼šè§£å¯†</li><li>ä¸èƒ½ä»å…¬é’¥æ¨å¯¼å‡ºç§é’¥</li></ul><p>åŠ å¯†è¿‡ç¨‹</p><ul><li>å‘é€æ–¹ç”¨<strong>æ¥æ”¶æ–¹çš„å…¬é’¥</strong>æ¥åŠ å¯†ï¼ˆå¯¹ç§°å¯†é’¥ï¼‰</li><li>ä¸ºä»€ä¹ˆä¸ç›´æ¥åŠ å¯†æ–‡ä»¶ï¼Ÿ<ul><li>å…¬é’¥å¯†ç å¼€é”€å¤§ï¼Œé€Ÿåº¦æ…¢</li></ul></li><li>å‘é€æ–¹å¦‚ä½•çŸ¥é“å‘é€æ¥æ”¶æ–¹çš„å…¬é’¥ï¼Ÿ</li></ul><p><strong>æ•°å­¦å®šç†</strong></p><ul><li>å¼•ç†1ï¼šè‹¥<code>ac = bc mod m</code>, ä¸”cå’Œmäº’ç´ ï¼Œåˆ™<code>a = b mod m</code></li><li>å¼•ç†2ï¼šè‹¥aå’Œmäº’ç´ ï¼Œåˆ™ <code>a, 2a, 3a, ..., (m-1)a</code>çš„æœ€å°å‰©ä½™ï¼ˆ<code>mod m</code>ï¼‰æŒ‰ç…§æŸç§æ¬¡åºæ’åˆ—åä¸ºï¼š<code>1, 2, 3, ...., m-1</code></li><li><em>Fermatå®šç†</em>ï¼š<code>p</code>ä¸ºç´ æ•°ï¼Œ<code>a</code>æ˜¯æ•´æ•°ä¸”ä¸èƒ½è¢«<code>p</code>æ•´é™¤ï¼Œåˆ™ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-16.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-17.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-18.png"></li><li><em>Euleræ•°</em>ï¼š<code>o|o(n)</code>å°äº<code>n</code>ä¸”ä¸<code>n</code>äº’ç´ çš„æ­£æ•´æ•°<em>ä¸ªæ•°</em><ul><li>è‹¥<code>p</code>æ˜¯ç´ æ•°ï¼Œ<code>o|o(p) = p - 1</code> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-19.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-20.png"></li></ul></li><li><em>Eulerå®šç†</em>ï¼šè‹¥<code>a</code>ä¸<code>n</code>ä¸ºäº’ç´ çš„æ­£æ•´æ•°ï¼Œåˆ™ï¼š <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-21.png"><ul><li>ä¸¾ä¾‹ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-22.png"></li><li>è¯æ˜ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-23.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-24.png"><ul><li><strong>æ³¨</strong>ï¼šå¦‚æœæœ‰<code>m | (a - b)</code>ï¼Œå³<code>m</code>æ˜¯<code>a - b</code>çš„å› å­</li></ul></li><li>æ¨è®ºï¼šè‹¥<code>n = pq, pâ‰ q</code>éƒ½æ˜¯ç´ æ•°ï¼Œ<code>k</code>æ˜¯ä»»æ„æ•´æ•°ï¼Œåˆ™ï¼š <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-25.png"></li></ul></li><li><em>åŸæ ¹</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-26.png"></li><li><em>ç¦»æ•£å¯¹æ•°</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-27.png"></li><li><strong>ç¦»æ•£å¯¹æ•°é—®é¢˜</strong> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-28.png"><ul><li>ç»™å®šä¸Šå¼ï¼Œå·²çŸ¥<code>g, y, p</code>ï¼Œè®¡ç®—<code>x</code>ï¼</li></ul></li></ul><h4><span id="diffie-hellmanå¯†é’¥äº¤æ¢">Diffie-Hellmanå¯†é’¥äº¤æ¢</span></h4><ul><li>åŸºäºç¦»æ•£å¯¹æ•°é—®é¢˜ <em>ç›®çš„</em>ï¼šå…è®¸ä¸¤ä¸ªç”¨æˆ·å¯ä»¥<em>å®‰å…¨åœ°äº¤æ¢ä¸€ä¸ªç§˜å¯†ä¿¡æ¯</em>ï¼Œç”¨äºåç»­çš„é€šè®¯è¿‡ç¨‹</li></ul><p>ç®—æ³• <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-29.png"></p><p><em>å®‰å…¨æ€§ä¿éšœ</em>ï¼šâ€œç›´è§‚ä¸Šâ€ä¾èµ–äºè®¡ç®—<em>ç¦»æ•£å¯¹æ•°</em>çš„éš¾åº¦</p><p><em>ä¸­é—´äººæ”»å‡»</em></p><ul><li>æ”»å‡»è€…å¿…é¡»å®æ—¶æˆªè·å¹¶å†’å……è½¬å‘ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-30.png"></li></ul><p>ä¸ºä»€ä¹ˆé€‰å–aæ˜¯<strong>åŸæ ¹</strong>ï¼Ÿ</p><ul><li>ä¸ºäº†ä¿è¯ä¸¤ä¸¤ä¸ç›¸ç­‰ï¼Œå¦‚æœä¸é€‰åŸæ ¹ï¼Œå¯¹äºæ”»å‡»è€…ç ´è§£éš¾åº¦é™ä½</li></ul><h4><span id="èƒŒåŒ…ç®—æ³•">èƒŒåŒ…ç®—æ³•</span></h4><p>MHå…¬é’¥ç®—æ³• <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-31.png"> å…¬é’¥ = ç§é’¥ * w mod m</p><ul><li>ä¸¾ä¾‹<ul><li>è®¡ç®—å…¬é’¥ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-32.png"></li><li>åŠ å¯† <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-33.png"></li><li>è§£å¯† <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-34.png"></li></ul></li></ul><p><em>èƒŒåŒ…ç®—æ³•é—®é¢˜</em></p><ul><li><strong>åŠ å¯†æ— éšæœº</strong>-&gt;å®¹æ˜“ç ´è§£</li><li>å®é™…ä¸­ä¸é‡‡ç”¨</li></ul><h4><span id="rsaç®—æ³•">RSAç®—æ³•</span></h4><p>å®é™…ç”¨çš„RSAç®—æ³•ä¸º<em>RSA-OAEP</em> ä¸ºä»€ä¹ˆå®é™…ç”¨çš„ä¸ç†è®ºç”¨çš„ä¸ä¸€æ ·ï¼Ÿ</p><ul><li>æ•™ç§‘ä¹¦ä¸­è®²çš„åŠ å¯†è¿‡ç¨‹<em>æ²¡æœ‰ç”¨åˆ°éšæœºæ•°</em></li></ul><p>RSAå®‰å…¨æ€§ä¾æ®</p><ul><li>xçš„eæ¬¡æ–¹mod n æ˜¯ä¸€ä¸ªå•å‘å‡½æ•° -&gt; æ— æ³•æ±‚å‡ºx</li><li>æ”»å‡»è€…æ— æ³•åˆ†è§£ï¼šn = pq</li></ul><p><em>RSAç®—æ³•</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-35.png"></p><p>ä¸¾ä¾‹ <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-36.png"></p><p>å¯†é’¥é•¿åº¦</p><ul><li>95ï¼š512bit</li><li>99ï¼š1024bit</li><li>ç°åœ¨ï¼š2048bit</li><li>è¶‹åŠ¿ï¼šä½¿ç”¨åŸºäºæ¤­åœ†æ›²çº¿çš„åŠ å¯†ç®—æ³•<ul><li>å› ä¸ºåŸºäºæ¯”å¤§æ•°åˆ†è§£éš¾é¢˜æ›´éš¾çš„éš¾é¢˜</li></ul></li><li>ä¸ºä»€ä¹ˆé€‰1024â½æ¯”ç‰¹ï¼Ÿ<ul><li>è®¡ç®—å¤æ‚åº¦<strong>Â è¾¾åˆ°2^80Â </strong></li><li>å› ä¸ºç°åœ¨å¯†ç å­¦è®¤ä¸ºè¶…è¿‡2^80å°±æ˜¯å®‰å…¨çš„</li></ul></li></ul><p><strong>å¯¹RSAçš„é€‰æ‹©å¯†æ–‡æ”»å‡»</strong></p><ul><li>æ”»å‡»è€…å¯ä»¥è‡ªå·±é€‰æ‹©ä¸€äº›å¯†æ–‡ï¼Œå¹¶è·å¾—å¯¹åº”çš„æ˜æ–‡</li><li><em>é€‰å¯†æ”»å‡»ä»ä¸è€ƒè™‘ä¸ç›´æ¥è§£å¯†ï¼Ÿ</em><ul><li>ç­‰åŒäºç”¨æˆ·æŠŠè‡ªå·±ç§é’¥æš´éœ²å‡ºå»</li><li>è¿™æ ·æ‰€æœ‰å¯†ç ä½“åˆ¶éƒ½æ— æ³•ä¿è¯å®‰å…¨æ€§</li></ul></li><li>æ€ä¹ˆä¿è¯ç”¨æˆ·ä¸€å®šä¼šæä¾›è§£å¯†æœåŠ¡ï¼Ÿ<ul><li>ç”¨æˆ·å¦‚æœä¸è§£å¯†ï¼Œå¯†æ–‡ä¹Ÿçœ‹ä¸æ‡‚ï¼›è§£å¯†å®Œå‘ç°çœ‹ä¸æ‡‚ï¼Œå°±ä»€ä¹ˆä¹Ÿä¸åš-&gt;é—´æ¥æä¾›ç»™æ”»å‡»è€…æ˜æ–‡ä¿¡æ¯</li><li>è¿™ä¹ˆå‡è®¾<em>ä¸ºäº†ä¿è¯åŠ å¯†ç®—æ³•çš„å®‰å…¨æ€§</em></li></ul></li></ul><p><em>å…¬å…±æ¨¡æ”»å‡»</em></p><ul><li><strong>èƒ½ä¸èƒ½å»ç›¸åŒçš„æ¨¡æ•°ï¼Ÿ</strong><ul><li>ä¸å¯ä»¥ <em>å°åŠ å¯†æŒ‡æ•°æ”»å‡»</em> <em>å°è§£å¯†æŒ‡æ•°æ”»å‡»</em></li></ul></li></ul><p><strong>åŠ å¯†æŒ‡æ•°é€‰æ‹©ï¼Œèƒ½ä¸èƒ½ç”¨å°æŒ‡æ•°ï¼Œä¸ºä»€ä¹ˆï¼Ÿ</strong></p><ul><li><em>å¯ä»¥</em>ï¼Œå› ä¸ºå®é™…åº”ç”¨ä¸­éƒ½æ˜¯RSA-OAEPï¼ŒåŠ å¯†å‰å°†æ¶ˆæ¯ä¸éšæœºå€¼æ··åˆï¼Œå¹¶ä¿è¯mä¸næœ‰ç›¸åŒçš„é•¿åº¦ã€‚å°åŠ å¯†æŒ‡æ•°æ”»å‡»æ— æ³•å®æ–½ã€‚å®é™…ä¸Šä¸ºäº†æé«˜åŠ å¯†é€Ÿåº¦ï¼Œé€šå¸¸å–eä¸ºç‰¹å®šçš„æ•´æ•°ï¼ŒISO/IEC9796ä¸­ç”šè‡³å…è®¸å–e=3</li></ul><h2><span id="hashå‡½æ•°-æ•°å­—ç­¾åä¸èº«ä»½è®¤è¯">Hashå‡½æ•°ã€æ•°å­—ç­¾åä¸èº«ä»½è®¤è¯</span></h2><h3><span id="hashå‡½æ•°">Hashå‡½æ•°</span></h3><p><em>Hashå‡½æ•°èƒ½ä¸èƒ½ç›´æ¥ç”¨ä½œæ•°æ®å®Œæ•´æ€§æ ¡éªŒï¼Ÿ</em></p><ul><li>ï¥§èƒ½ï¼Œå› ä¸ºhashå‡½æ•°ç»“æœä¹Ÿï§ è¢«ç¯¡æ”¹</li></ul><p><em>MAC</em></p><ul><li>å¦‚æœè¦åœ¨ä¸å®‰å…¨çš„ä¿¡é“ä¸­ä¿è¯æ¶ˆæ¯çš„å®Œæ•´æ€§ï¼Œå¯ä»¥åœ¨Hashå‡½æ•°ä¸­å¼•å…¥ä¸€ä¸ªå¯†é’¥ï¼Œå…¶ç»“æœè¢«ç§°ä¸º<em>æ¶ˆæ¯éªŒè¯ç (MAC)</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-37.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-38.png"></li><li>Hashå‡½æ•°åŸºæœ¬è¦æ±‚<ul><li>å¿«é€Ÿ<ul><li>å› ä¸ºè¾“å…¥é•¿åº¦ä¸å›ºå®š</li></ul></li><li>å•å‘<ul><li>æ ¹æ®H(M)=hæ— æ³•è®¡ç®—å‡ºM</li><li>åœ¨MACä¸­é˜²æ­¢è§£å‡ºå¯†é’¥</li></ul></li><li>é˜²ç¢°æ’</li></ul></li><li><em>å®‰å…¨æ€§</em><ul><li><em>åŸåƒç¨³å›º</em>ï¼šç»™å®šæ¶ˆæ¯æ‘˜è¦yï¼Œèƒ½å¦æ‰¾åˆ°xä½¿å¾—<code>h(x)=y</code><ul><li>å•å‘æ€§</li></ul></li><li><em>ç¬¬äºŒåŸåƒç¨³å›º</em>ï¼šç»™å®šä¸€ä¸ªæ¶ˆæ¯xï¼Œèƒ½å¦æ‰¾åˆ°xâ€™ =Ì¸x ï¼Œä½¿å¾—<code>h(x)=h(xâ€™)</code><ul><li>é˜²ç¢°æ’</li></ul></li><li><em>ç¢°æ’ç¨³å›º</em>ï¼šå¯»æ‰¾ä»»æ„xâ€™ =Ì¸xï¼Œä½¿å¾—<code>h(x)=h(xâ€™)Â </code><ul><li>ä»»æ„å¯»æ‰¾ä¸¤ä¸ªä¸åŒçš„xï¼Œä½¿å¾—å“ˆå¸Œç»“æœç›¸åŒçš„å¯èƒ½æ€§ä¸º0</li></ul></li></ul></li></ul><h3><span id="æ•°å­—ç­¾å">æ•°å­—ç­¾å</span></h3><p><em>æ•°å­—ç­¾åæ˜¯ä¼ ç»Ÿç­¾åçš„æ•°å­—åŒ–</em>,åŸºæœ¬è¦æ±‚: Â</p><ul><li>èƒ½ä¸æ‰€ç­¾æ–‡ä»¶â€œç»‘å®šâ€ Â‚</li><li>ç­¾åè€…ä¸èƒ½å¦è®¤è‡ªå·±çš„ç­¾å</li><li>ç­¾åä¸èƒ½è¢«ä¼ªé€ </li><li>å®¹æ˜“è¢«è‡ªåŠ¨éªŒè¯</li></ul><p>ä¸MACçš„åŒºåˆ«ï¼š<em>MACä¸èƒ½ä¿è¯åŒæ–¹è‡ªèº«çš„ç›¸äº’æ¬ºéª—</em></p><p>å¿…é¡»ä¿è¯çš„æ€§è´¨</p><ul><li><em>å¯éªŒè¯</em>:ç­¾å­—æ˜¯å¯ä»¥è¢«ç¡®è®¤çš„</li><li><em>é˜²æŠµèµ–</em>:å‘é€è€…äº‹åä¸æ‰¿è®¤å‘é€æŠ¥æ–‡å¹¶ç­¾å;</li><li><em>é˜²å‡å†’</em>:æ”»å‡»è€…å†’å……å‘é€è€…å‘æ”¶æ–¹å‘é€æ–‡ä»¶;</li><li><em>é˜²ç¯¡æ”¹</em>:æ”¶æ–¹å¯¹æ”¶åˆ°çš„æ–‡ä»¶è¿›è¡Œç¯¡æ”¹;</li><li><em>é˜²ä¼ªé€ </em>:æ”¶æ–¹ä¼ªé€ å¯¹æŠ¥æ–‡çš„ç­¾å</li></ul><p>ä¸‰ä¸ªè¿‡ç¨‹</p><ul><li>ç³»ç»Ÿçš„åˆå§‹åŒ–è¿‡ç¨‹<ul><li>åœ¨ç³»ç»Ÿçš„åˆå§‹åŒ–è¿‡ç¨‹ä¸­è¦äº§ç”Ÿçš„æ•°å­—ç­¾åæ–¹æ¡ˆä¸­ç”¨åˆ°çš„ä¸€åˆ‡å‚æ•°ï¼Œæœ‰å…¬å¼€çš„ï¼Œä¹Ÿæœ‰ç§˜å¯†çš„</li></ul></li><li>ç­¾åäº§ç”Ÿè¿‡ç¨‹<ul><li>åœ¨ç­¾åäº§ç”Ÿçš„è¿‡ç¨‹ä¸­ç”¨æˆ·åˆ©ç”¨ç»™å®šçš„ç®—æ³•å¯¹æ¶ˆæ¯äº§ç”Ÿç­¾åï¼Œè¿™ç§ç­¾åè¿‡ç¨‹å¯ä»¥å…¬å¼€ä¹Ÿå¯ä»¥ä¸å…¬å¼€</li></ul></li><li>ç­¾åéªŒè¯è¿‡ç¨‹<ul><li>åœ¨ç­¾åéªŒè¯è¿‡ç¨‹ä¸­ï¼ŒéªŒè¯è€…åˆ©ç”¨å…¬å¼€éªŒè¯æ–¹æ³•å¯¹ç»™å®šæ¶ˆæ¯çš„ç­¾åè¿›è¡ŒéªŒè¯ï¼Œå¾—å‡ºç­¾åçš„æœ‰æ•ˆæ€§</li></ul></li></ul><p><em>æ•°å­—ç­¾åé—®é¢˜</em></p><ul><li>ç­¾ååæ–‡ä»¶å¯èƒ½è¢«é‡å¤åˆ©ç”¨<ul><li>ç­¾å­—åçš„æ–‡ä»¶å¯èƒ½è¢«Bé‡å¤ä½¿ç”¨ã€‚å¦‚æœç­¾å­— åçš„æ–‡ä»¶æ˜¯ä¸€å¼ æ”¯ç¥¨ï¼ŒBå¾ˆå®¹æ˜“å¤šæ¬¡ç”¨è¯¥ç”µå­æ”¯ ç¥¨å…‘æ¢ç°é‡‘ï¼Œä¸ºæ­¤Aéœ€è¦åœ¨æ–‡ä»¶ä¸­åŠ ä¸Šä¸€äº›è¯¥æ”¯ç¥¨çš„ç‰¹æœ‰çš„å‡­è¯ï¼Œå¦‚timestampç­‰ï¼Œä»¥é˜²æ­¢ä¸Šè¿°æƒ…å†µå‘ç”Ÿ</li></ul></li><li>å…¬é’¥ç®—æ³•æ•ˆç‡ä½</li></ul><p><em>RSAæ•°å­—ç­¾å</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-39.png"></p><ul><li><strong>ä¸åŠ è§£å¯†çš„å¼‚åŒï¼Ÿ</strong><ul><li><em>åˆ©ç”¨ç§é’¥ç­¾åï¼Œå…¬é’¥éªŒè¯</em>ï¼Œè€ŒRSAåŠ å¯†æ˜¯â½¤å…¬é’¥åŠ å¯†ï¼Œç§é’¥è§£å¯†</li></ul></li></ul><h3><span id="èº«ä»½è®¤è¯">èº«ä»½è®¤è¯</span></h3><p><em>èº«ä»½è®¤è¯æ˜¯å¯¹ç½‘ç»œä¸­çš„ä¸»ä½“è¿›è¡ŒéªŒè¯çš„è¿‡ç¨‹</em>ï¼Œç”¨æˆ·å¿…é¡»æä¾›ä»–æ˜¯è°çš„è¯æ˜ï¼Œä»–æ˜¯æŸä¸ªé›‡å‘˜ï¼ŒæŸä¸ªç»„ç»‡çš„ä»£ç†ã€æŸä¸ªè½¯ä»¶è¿‡ç¨‹(å¦‚äº¤æ˜“è¿‡ç¨‹) ã€‚</p><p><em>ä¸»è¦æ–¹æ³•</em></p><ul><li>å£ä»¤è®¤è¯<ul><li>å«ä¹‰ï¼šç”¨æˆ·å/å£ä»¤è®¤è¯</li><li>ä¼˜ç‚¹<ul><li>æœ€ç®€å•ã€æœ€æ™®éçš„èº«ä»½è¯†åˆ«æŠ€æœ¯</li></ul></li><li>ç¼ºç‚¹<ul><li>å¤§å¤šæ•°ç³»ç»Ÿçš„å£ä»¤æ˜¯æ˜æ–‡ä¼ é€åˆ°éªŒè¯æœåŠ¡å™¨çš„ï¼Œ å®¹æ˜“è¢«æˆªè·</li><li>å£ä»¤ç»´æŠ¤çš„æˆæœ¬è¾ƒé«˜ï¼Œéš¾äºè®°å¿†</li><li>å£ä»¤å®¹æ˜“åœ¨è¾“å…¥çš„æ—¶å€™è¢«æ”»å‡»è€…å·çª¥ï¼Œè€Œä¸”ç”¨æˆ·æ— æ³•åŠæ—¶å‘ç°</li></ul></li><li>å®‰å…¨æ€§è¦æ±‚<ul><li>ä½æ•°&gt;6ä½</li><li>å¤§å°å†™å­—æ¯æ··åˆ</li><li>å­—æ¯ä¸æ•°å­—æ··åˆ</li><li>å£ä»¤æœ‰å­—æ¯ã€æ•°å­—ä»¥å¤–çš„ç¬¦å·</li><li>ç¦æ­¢ä½¿ç”¨ç¼ºçœå£ä»¤</li><li>å®šæœŸæ›´æ¢å£ä»¤</li><li>ä¿æŒå£ä»¤å†å²è®°å½•ï¼Œä½¿ç”¨æˆ·ä¸èƒ½å¾ªç¯ä½¿ç”¨æ—§å£ä»¤</li><li>ç”¨å£ä»¤ç ´è§£ç¨‹åºæµ‹è¯•å£ä»¤</li></ul></li><li>æ”»å‡»ç§ç±»<ul><li>å­—å…¸æ”»å‡»</li><li>ç©·ä¸¾å°è¯•</li><li>çª¥æ¢</li><li>ç¤¾äº¤å·¥ç¨‹</li><li>åƒåœ¾æœç´¢</li><li>é‡æ”¾æ”»å‡»</li></ul></li></ul></li><li>æ™ºèƒ½å¡è®¤è¯<ul><li>å«ä¹‰ï¼š<em>ç½‘ç»œé€šè¿‡ç”¨æˆ·æ‹¥æœ‰ä»€ä¹ˆä¸œè¥¿æ¥è¯†åˆ«çš„æ–¹æ³•ï¼Œä¸€èˆ¬æ˜¯ç”¨æ™ºèƒ½å¡æˆ–å…¶å®ƒç‰¹æ®Šå½¢å¼çš„æ ‡å¿—</em>ï¼Œè¿™ç±»æ ‡å¿—å¯ä»¥ä»è¿æ¥åˆ°è®¡ç®—æœºä¸Šçš„è¯»å‡ºå™¨è¯»å‡ºæ¥ã€‚è®¿é—®ä¸ä½†éœ€è¦å£ä»¤ï¼Œä¹Ÿéœ€è¦ä½¿ç”¨ç‰©ç†æ™ºèƒ½å¡ï¼ˆ<em>è¯¢é—®ï¼åº”ç­”æ¨¡å¼</em>ï¼‰</li><li>ä¼˜ç‚¹<ul><li>å­˜å‚¨å®¹é‡å¤§ ã€ä½“ç§¯å°è€Œè½»ã€ä¿å¯†æ€§å¼ºã€ç½‘ç»œè¦æ±‚ä½ã€ æ•°æ®å¯é æ€§é«˜ ã€é˜²ç£ã€é˜²é™ç”µã€é˜²æ½®ã€è€æ¸©ã€æŠ—å¹²æ‰°èƒ½åŠ›å¼ºï¼Œä¸€å¼ ICå¡ç‰‡å¯é‡å¤è¯»å†™åä¸‡æ¬¡ï¼Œå¡ä¸­æ•°æ®å¯ ä¿å­˜å‡ åå¹´ï¼Œå¯¹è®¡ç®—æœºçš„å®æ—¶æ€§ã€æ•æ„Ÿæ€§è¦æ±‚é™ä½ã€‚å†…éƒ¨æ•°æ®ä¿å¯†æ€§ã€å¯é æ€§å¥½ï¼Œè¯»å†™ç¨³å®šå¯è„±æœºå·¥ä½œï¼Œæ˜“äºå®‰è£…ç»´æŠ¤</li></ul></li><li>ç¼ºç‚¹<ul><li><em>ä¸¢å¤±åçŸ­æ—¶é—´å†…ä¸å¥½è¡¥å›</em></li></ul></li><li>å®‰å…¨æ€§è¦æ±‚</li><li>æ”»å‡»ç§ç±»</li></ul></li><li>åŸºäºç”Ÿç‰©ç‰¹å¾çš„è®¤è¯<ul><li>å«ä¹‰ï¼šç›®å‰å·²æœ‰çš„è®¾å¤‡åŒ…æ‹¬:è§†ç½‘è†œæ‰«æä»ªã€å£°éŸ³éªŒè¯è®¾å¤‡ã€æ‰‹å‹è¯†åˆ«å™¨ç­‰</li><li>ä¼˜ç‚¹<ul><li>å®‰å…¨æ€§é«˜</li></ul></li><li>ç¼ºç‚¹<ul><li>ä¸€æ—¦æ³„éœ²ï¼Œ<em>ç”Ÿç‰©ä¿¡æ¯ä¸å¯æ›´æ”¹ï¼</em></li></ul></li><li>å®‰å…¨æ€§è¦æ±‚</li><li>æ”»å‡»ç§ç±»</li></ul></li><li>åŒå› ç´ è®¤è¯<ul><li>å«ä¹‰ï¼šæ‰€çŸ¥é“çš„å†…å®¹+æ‰€æ‹¥æœ‰çš„ç‰©å“</li><li>ä¼˜ç‚¹</li><li>ç¼ºç‚¹</li><li>å®‰å…¨æ€§è¦æ±‚</li><li>æ”»å‡»ç§ç±»</li></ul></li></ul><p><em>èº«ä»½è®¤è¯åè®®</em></p><ul><li>NSSKï¼šé€šä¿¡åŒæ–¹Aå’ŒBé€šè¿‡å¯ä¿¡ç¬¬ä¸‰æ–¹åå•†ä¼šè¯å¯†é’¥<ul><li>åŸºäºå¯¹ç§°å¯†ç çš„åŒå‘è®¤è¯åè®® <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-40.png"></li></ul><ol type="1"><li>Aå‘å¯ä¿¡ç¬¬ä¸‰æ–¹Tå‘é€è¦å’ŒBå‹¾æ­çš„è¯·æ±‚ï¼ŒåŠ ä¸Šéšæœºæ•°Na</li><li>Tç»™Aå›å¤ç›¸åº”çš„Naï¼ŒBçš„ä¿¡æ¯ï¼ŒABä¹‹é—´çš„å¯†é’¥ï¼Œå’Œç”¨Kbtçš„å¯†é’¥åŠ å¯†çš„Kabä¸Açš„ä¿¡æ¯</li><li>Aè§£å¯†ä¹‹åï¼ŒéªŒè¯Naï¼Œç„¶åæŠŠç”¨Kbtçš„å¯†é’¥åŠ å¯†çš„Kabä¸Açš„ä¿¡æ¯å‘ç»™B</li><li>Bç”¨Kbtè§£å¯†ï¼Œè·å–Kabï¼Œå¹¶ç”Ÿæˆéšæœºæ•°ï¼Œç”¨KabåŠ å¯†å‘ç»™A</li><li>Aè§£å¯†åï¼ŒæŠŠéšæœºæ•°+1ï¼Œåœ¨ç”¨KabåŠ å¯†å‘å›B <strong>ä¿¡ä»»å»ºç«‹</strong></li></ol><ul><li><em>Aè®¤è¯B</em>ï¼šç¬¬å››æ­¥ï¼Œå› ä¸ºåªæœ‰çœŸæ­£çš„Bæ‰èƒ½è§£å‡ºBTé€šè®¯çš„å¯¹ç§°å¯†é’¥</li><li><em>Bè®¤è¯A</em>ï¼šç¬¬äº”æ­¥ï¼Œå› ä¸ºåªæœ‰çœŸæ­£çš„Aæ‰èƒ½è§£å‡ºABé€šè®¯çš„å¯¹ç§°å¯†é’¥</li></ul></li><li>NSPKï¼šé€šä¿¡åŒæ–¹Aå’ŒBé€šè¿‡å¯ä¿¡ç¬¬ä¸‰æ–¹åå•†ä¼šè¯å¯†é’¥<ul><li>åŸºäºéå¯¹ç§°å¯†ç çš„åŒå‘è®¤è¯åè®® <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-41.png"></li></ul><ol type="1"><li>Aå‘å¯ä¿¡ç¬¬ä¸‰æ–¹Tå‘é€è¦å’ŒBå‹¾æ­çš„è¯·æ±‚</li><li>Tè‡­ä¸è¦è„¸çš„åŒæ„äº†ï¼Œç»™äº†Bçš„è”ç³»æ–¹å¼ï¼ˆBçš„å…¬é’¥ï¼‰ï¼Œæ€•Aä¸ç›¸ä¿¡ï¼Œè¿˜åœ¨ä¸Šé¢æ”¹äº†ä¸€ä¸ªæˆ³ï¼ˆç”¨è‡ªå·±çš„ç§é’¥ç­¾åï¼‰</li><li>Aæ‹¿åˆ°Bçš„å…¬é’¥ï¼Œéšä¾¿é€‰äº†ä¸ªæ•°ï¼Œä½œä¸ºå®šæƒ…ä¿¡æ•°ï¼Œç„¶åé™„ä¸Šè‡ªå·±çš„åç‰‡ï¼Œç”¨Bçš„å…¬é’¥åŠ å¯†ï¼Œå‘é€ç»™B</li><li>Bæ”¶åˆ°è¿™å°ä¿¡ï¼Œç”¨è‡ªå·±çš„ç§é’¥è§£å¯†ï¼ŒçŸ¥é“æ˜¯Aè¿™ä¸ªå°å½ªå­è¦å‹¾æ­è‡ªå·±ï¼Œç²¾è™«ä¸Šè„‘ï¼Œç„¶åä¹Ÿå‘Tå»ç”³è¯·</li><li>åŒæ ·çš„Tä¹Ÿç»™äº†Bä¸€ä¸ªè‡ªå·±ç›–è¿‡ç« çš„Açš„å…¬é’¥</li><li>Bæ‹¿åˆ°Açš„å…¬é’¥ï¼Œåˆé€‰äº†ä¸€ä¸ªå®šæƒ…ä¿¡æ•°Nbï¼Œä¿©æ•°ä¸€å—ç”¨Açš„å…¬é’¥åŠ å¯†å‘ç»™A</li><li>Aè§£å¯†å‡ºNbçš„å€¼ï¼Œå†ç”¨KbåŠ å¯†å‘å›ç»™B <strong>ä¿¡ä»»å»ºç«‹</strong>ï¼š</li></ol><ul><li><em>Bè®¤è¯A</em>ï¼š(6)é‡Œé¢Bå‘ç»™Açš„æ˜¯ç”¨Açš„å…¬é’¥åŠ å¯†çš„ï¼Œåªæœ‰Aèƒ½è§£å¼€ï¼Œæ‰€ä»¥ï¼Œ(7)é‡Œé¢AæŠŠæ­£ç¡®çš„Nbå‘å›ç»™Bï¼Œè¯æ˜ä»–çœŸçš„æ˜¯A</li><li><em>Aè®¤è¯B</em>ï¼š(6)é‡Œé¢Bèƒ½æŠŠAéšä¾¿é€‰çš„å®šæƒ…ä¿¡æ•°è§£å¯†å‡ºæ¥ï¼ˆä¹‹å‰æ˜¯ç”¨KbåŠ å¯†çš„ï¼‰ï¼Œå†å‘å›ç»™Aï¼Œå°±è¯æ˜è‡ªå·±æ˜¯çœŸçš„B</li></ul></li><li>åŸºäºéå¯¹ç§°å¯†ç çš„å•å‘è®¤è¯åè®® <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-42.png"></li></ul><h2><span id="pki">PKI</span></h2><p>æ¦‚å¿µï¼šPKI-Public Key Infrastructureå…¬é’¥åŸºç¡€è®¾æ–½ã€‚<em>æ˜¯ä¸€ä¸ªç”¨å…¬é’¥æŠ€æœ¯æ¥å®æ–½å’Œæä¾›å®‰å…¨æœåŠ¡çš„å…·æœ‰æ™®é€‚æ€§çš„å®‰å…¨åŸºç¡€è®¾æ–½</em>ã€‚</p><p>åŠŸèƒ½</p><ul><li>ç­¾å‘è¯ä¹¦</li><li>ç­¾å‘è¯ä¹¦æ’¤é”€åˆ—ï¦œè¡¨</li><li>å¯†é’¥å¤‡ä»½ä¸æ¢å¤åŠŸèƒ½</li><li>è¯ä¹¦ã€å¯†é’¥å¯¹çš„â¾ƒè‡ªåŠ¨æ›´ï¤æ–°</li><li>åŠ å¯†ã€ç­¾åå¯†é’¥çš„åˆ†å‰² å¯†é’¥å†å²çš„ç®¡ç†ï§¤</li><li>äº¤å‰è®¤è¯</li></ul><p><em>æœ¬è´¨ä»»åŠ¡</em>ï¼š<strong>ç»‘å®šç”¨æˆ·å’Œå…¬é’¥</strong> <em>ä¸ºä»€ä¹ˆéœ€è¦PKI</em>ï¼šå…¬é’¥å’Œç”¨æˆ·æ²¡æœ‰å¤©ç„¶çš„ç»‘å®šå…³ç³»ï¼Œæ‰€ä»¥éœ€è¦KPIæ¥å®Œæˆè¿™ç§ç»‘å®šã€‚ <em>å¯†é’¥å¤‡ä»½åŠæ¢å¤ç³»ç»Ÿ</em>ï¼šå¯†é’¥çš„å¤‡ä»½ä¸æ¢å¤<em>åªèƒ½é’ˆå¯¹è§£å¯†å¯†é’¥</em>ï¼Œ<strong>ç­¾åç§é’¥ä¸èƒ½å¤‡ä»½</strong></p><ul><li>ä¸ºä»€ä¹ˆï¼Ÿ<em>é˜²â½Œå‘ç”Ÿå‘é€æ–¹æŠµèµ–ï¼Œè¯´ç­¾åï¥§æ˜¯â¾ƒå·±ç­¾çš„ï¼Œå› ä¸ºPKIä¹Ÿæœ‰è‡ªâ¼°çš„ç§é’¥</em></li></ul><p><em>æ’¤é”€æ–¹æ³•</em>ï¼šæŠŠè¯ä¹¦åˆ—å…¥è¯ä¹¦æ’¤é”€åˆ—è¡¨ä¸­ï¼ˆCRLï¼‰æ¥å®ç°</p><ul><li>åˆ°æœŸ</li><li>ä¸´æ—¶<ul><li>ç”¨æˆ·èº«ä»½æ”¹å˜</li><li>å¯¹å¯†é’¥çš„æ€€ç–‘ï¼ˆä¸¢å¤±æˆ–æ³„éœ²ï¼‰</li><li>ç”¨æˆ·å·¥ä½œçš„å˜åŠ¨</li><li>è®¤ä¸ºCAè¯ä¹¦å·²æ³„éœ²</li></ul></li></ul><p><em>äº¤å‰è®¤è¯</em></p><ul><li>ä¸ºä»€ä¹ˆï¼šåœ¨ä»¥å‰æ²¡æœ‰è”ç³»çš„PKIä¹‹é—´å»ºç«‹ä¿¡ä»»å…³ç³»ï¼Œå°±éœ€è¦äº¤å‰è®¤è¯ã€‚å®ƒèƒ½å¤Ÿè®©ä¸€ä¸ªPKIå›¢ä½“çš„ç”¨æˆ·éªŒè¯å¦ä¸€ä¸ªPKIå›¢ä½“çš„ç”¨æˆ·è¯ä¹¦ï¼Œä»è€Œå®ç°é€šä¿¡ã€‚</li><li>åˆ†ç±»<ul><li>åŸŸå†…ï¼é—´äº¤å‰è®¤è¯</li><li>å•å‘ï¼åŒå‘</li><li>æ­£ï¼åå‘äº¤å‰éªŒè¯</li></ul></li><li>éªŒè¯æ­¥éª¤<ol type="1"><li>éªŒè¯çœŸå®æ€§ï¼ˆåŸºäºè¯ä¹¦é“¾æœºåˆ¶ï¼‰ã€‚è¯ä¹¦æ˜¯å¦ä¸ºå¯ä¿¡ä»»çš„CAè®¤è¯ä¸­å¿ƒé¢å‘ï¼Ÿ</li><li>éªŒè¯æœ‰æ•ˆæ€§ã€‚è¯ä¹¦æ˜¯å¦åœ¨æœ‰æ•ˆæœŸä¹‹å†…ï¼Ÿ</li><li>éªŒè¯å¯ç”¨æ€§ï¼ˆåŸºäºè¯ä¹¦æ’¤é”€æœºåˆ¶ï¼‰ã€‚è¯ä¹¦æ˜¯å¦å·²åºŸé™¤ï¼Ÿ</li></ol></li></ul><h2><span id="åŸºäºèº«ä»½åŠ å¯†ä½“åˆ¶">åŸºäºèº«ä»½åŠ å¯†ä½“åˆ¶</span></h2><p>ä¸ºä»€ä¹ˆä¼šå‡ºç°ï¼Ÿ</p><ul><li><strong>CAæˆä¸ºäº†PKIçš„æ€§èƒ½ç“¶é¢ˆ</strong></li><li>å…¬é’¥å’Œç”¨æˆ·æ²¡æœ‰å¤©ç„¶çš„ç»‘å®šå…³ç³»ï¼Œæ‰€ä»¥éœ€è¦KPIæ¥å®Œæˆè¿™ç§ç»‘å®š</li><li>å¦‚æœä¸ç”¨KPIï¼Œé‚£ä¹ˆå…¬é’¥å’Œç”¨æˆ·è¦æœ‰å¤©ç„¶çš„ç»‘å®šå…³ç³»</li></ul><p><em>æ¦‚å¿µ</em>ï¼šä¸€ç§èƒ½å¤Ÿè®©ç”¨æˆ·åŠå…¶å…¬é’¥æœ‰å¤©ç„¶çš„ç»‘å®šå…³ç³»çš„åŠ å¯†ä½“åˆ¶ å¤©ç„¶çš„ç»‘å®šå…³ç³»ï¼Ÿ</p><ul><li>å±æ€§</li><li>èº«ä»½</li><li>éœ€è¦ä»ä¸åŒçš„è§’åº¦è€ƒè™‘</li></ul><p>ç®—æ³•å«ä¹‰</p><ul><li><em>Setup</em><ul><li>ç³»ç»Ÿåˆå§‹åŒ–ç®—æ³•ç”¨äºç”Ÿæˆç³»ç»Ÿå…¬å¼€å‚æ•°å’Œç³»ç»Ÿç§˜å¯†å‚æ•°</li></ul></li><li><em>Extract</em><ul><li>æ ¹æ®ç³»ç»Ÿç§˜å¯†å‚æ•°å’Œç”¨æˆ·çš„èº«ä»½ä¿¡æ¯ï¼ˆå…¬é’¥ï¼‰ï¼Œæ ¹æ®ç³»ç»Ÿç§˜å¯†å‚æ•°å’Œç”¨æˆ·çš„èº«ä»½ä¿¡æ¯ï¼ˆå…¬é’¥ï¼‰ ç”Ÿæˆç”¨æˆ·çš„ç§é’¥</li></ul></li><li><em>Enc</em><ul><li>å‘é€æ–¹æ ¹æ®ç³»ç»Ÿå…¬å¼€å‚æ•°ã€æ¥æ”¶æ–¹èº«ä»½ä¿¡æ¯ ï¼ˆå…¬é’¥ï¼‰ï¼ŒåŠ å¯†æ˜æ–‡ï¼Œå¹¶ç”Ÿæˆå¯†æ–‡</li></ul></li><li><em>Dec</em><ul><li>æ¥æ”¶æ–¹ç”¨è‡ªå·±çš„ç§é’¥è§£å¯†æ”¶åˆ°çš„å¯†æ–‡</li></ul></li></ul><h2><span id="ç‰©è”ç½‘å®‰å…¨">ç‰©è”ç½‘å®‰å…¨</span></h2><p><em>RFIDå¨èƒ</em></p><ul><li><em>ç‰©ç†æ”»å‡»</em><ul><li>é’ˆå¯¹èŠ‚ç‚¹æœ¬èº«è¿›è¡Œ<em>ç‰©ç†ä¸Šçš„ç ´åè¡Œä¸º</em>ï¼Œå¯¼è‡´ä¿¡æ¯æ³„éœ²ã€æ¶æ„è¿½è¸ªç­‰ã€‚</li></ul></li><li><em>ä¿¡é“å µå¡</em><ul><li>æ”»å‡»è€…é•¿æœŸå æ®ä¿¡é“å¯¼è‡´é€šä¿¡<em>æ— æ³•ä¼ è¾“</em>ã€‚</li></ul></li><li><em>ä¼ªé€ æ”»å‡»</em><ul><li><em>ä¼ªé€ ç”µå­æ ‡ç­¾</em>ç”Ÿæˆç³»ç»Ÿè®¤å¯çš„â€œåˆæ³•ç”¨æˆ·æ ‡ç­¾â€ï¼ˆå®ç°ä»£ä»·è¾ƒé«˜ï¼‰ã€‚ ÂŒ</li></ul></li><li><em>å‡å†’æ”»å‡»</em><ul><li>æˆªè·åˆæ³•ç”¨æˆ·èº«ä»½ä¿¡æ¯åï¼Œæˆªè·åˆæ³•ç”¨æˆ·èº«ä»½ä¿¡æ¯åä½¿ç”¨è¯¥ä¿¡æ¯<em>å‡å†’åˆæ³•ç”¨æˆ·</em>å…¥ç½‘ã€‚ä½¿ç”¨è¯¥ä¿¡æ¯å‡å†’åˆæ³•ç”¨æˆ·å…¥ç½‘ ÂŒ</li></ul></li><li><em>é‡æ”¾æ”»å‡»</em><ul><li>åˆ©ç”¨æŸæ¬¡åˆæ³•ç”¨æˆ·çš„èº«ä»½ç™»é™†ä¿¡æ¯æˆ–è€…çªƒå¬åˆ°çš„æœ‰æ•ˆä¿¡æ¯è¿‡ä¸€æ®µæ—¶é—´å<em>é‡å‘é€ç»™æ¥æ”¶è€…</em>ï¼Œéª—å–ä¿¡ä»»ï¼Œè¾¾åˆ°æ”»å‡»çš„ç›®çš„ã€‚ ÂŒ</li></ul></li><li><em>ä¸­é—´äººæ”»å‡»</em><ul><li>æ”»å‡»è€…å°†çªƒå¬åˆ°çš„ä¿¡æ¯è¿›è¡Œ<em>ä¿®æ”¹ä¹‹åå†å°†ä¿¡æ¯ä¼ ç»™</em>æ¥æ”¶è€…ã€‚</li></ul></li></ul><p><em>æ— çº¿ä¼ æ„Ÿç½‘ç»œçš„å¨èƒ</em></p><ul><li><em>ç½‘å…³èŠ‚ç‚¹ä¿˜è·</em><ul><li>æ§åˆ¶<em>èŠ‚ç‚¹è¢«ä¿˜è·</em>ä¹‹åï¼Œå¯èƒ½å¯¼è‡´é€šä¿¡å¯†é’¥ã€å¹¿æ’­å¯†é’¥ã€é…å¯¹å¯†é’¥ç­‰å…¨éƒ¨ æ³„éœ²ï¼Œæ³„éœ² è¿›è€Œå¨èƒåˆ°æ•´ä¸ªç½‘ç»œçš„é€šä¿¡å®‰å…¨ã€‚è¿›è€Œå¨èƒåˆ°<em>æ•´ä¸ªç½‘ç»œçš„é€šä¿¡å®‰å…¨</em></li></ul></li><li><em>æ™®é€šèŠ‚ç‚¹ä¿˜è·</em><ul><li>å¯¼è‡´<em>éƒ¨åˆ†é€šä¿¡å¯†é’¥æ³„éœ²</em>ï¼Œå¯¹å±€éƒ¨ç½‘ç»œé€šä¿¡å®‰å…¨é€ æˆå¨èƒã€‚ ÂŒ</li></ul></li><li><em>ä¼ æ„Ÿä¿¡æ¯çªƒå¬</em><ul><li>æ”»å‡»è€…å¯¹é€šä¿¡é“¾è·¯é—´ä¼ è¾“çš„ä¿¡æ¯è¿›è¡Œçªƒå¬ï¼Œä»è€Œåˆ†æå¹¶å¾—å‡ºå…¶ä¸­çš„æ•æ„Ÿä¿¡æ¯ã€‚</li></ul></li><li><em>DoSæ”»å‡»ï¼ˆæ‹’ç»æœåŠ¡æ”»å‡»ï¼‰</em><ul><li>ç½‘å…³èŠ‚ç‚¹å®¹æ˜“å—åˆ°DoSæ”»å‡»ï¼Œè€—å°½èŠ‚ç‚¹èµ„æºï¼Œä½¿å¾—èŠ‚ç‚¹ä¸§å¤±è¿è¡Œèƒ½åŠ›ã€‚</li></ul></li><li><em>è™šå‡è·¯ç”±ä¿¡æ¯</em><ul><li>é€šè¿‡æ¬ºéª—ï¼Œçº‚æ”¹æˆ–é‡å‘è·¯ç”±ä¿¡æ¯ï¼Œæ”»å‡»è€…å¯ä»¥åˆ›å»ºå¾ªç¯è·¯ç”±ï¼Œå»¶é•¿æˆ–è€… å±è”½è·¯å¾„ï¼Œå±è”½è·¯å¾„ï¼Œå¢åŠ ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œå¢åŠ ç«¯åˆ°ç«¯å»¶è¿Ÿä»è€Œ<em>æ¶ˆè€—èŠ‚ç‚¹èƒ½æº</em>ã€‚</li></ul></li></ul><p><em>ä¼ è¾“å±‚å®‰å…¨å¨èƒ</em></p><ul><li>å¼‚æ„ç½‘ç»œè·¨ç½‘è®¤è¯</li><li>å¼‚æ­¥æ”»å‡»ï¼ˆä¼ è¾“å±‚çš„é‡æ”¾æ”»å‡»ç­‰ç­‰ï¼‰</li><li>åˆè°‹æ”»å‡»</li></ul><p><em>ä¼ è¾“å±‚ç›¸å…³æªæ–½</em></p><ul><li><strong>ç‚¹åˆ°ç‚¹åŠ å¯†æœºåˆ¶</strong>ï¼šåœ¨è·¯ç”±èŠ‚ç‚¹è§£å¯†åå†åŠ å¯†ä¼ è¾“ï¼šå¥½å¤šå¯†é’¥</li><li><strong>ç«¯åˆ°ç«¯åŠ å¯†æœºåˆ¶</strong>ï¼šä¼ è¾“è¿‡ç¨‹å§‹ç»ˆä¿æŒå¯†æ–‡ä¼ è¾“ï¼šå•ä¸€å¯†é’¥</li></ul><p><em>åº”ç”¨å±‚å®‰å…¨å¨èƒ</em></p><ul><li>åœ¨æ»¡è¶³æ•°æ®æ™ºèƒ½åŒ–å¤„ç†åŸºç¡€ä¹‹ä¸Šï¼Œ<em>åŠ å¼ºæ•°æ®åº“è®¿é—®æ§åˆ¶ç­–ç•¥</em>ã€‚ ÂŒ</li><li>åŠ å¼ºä¸åŒåº”ç”¨åœºæ™¯çš„<em>è®¤è¯æœºåˆ¶å’ŒåŠ å¯†æœºåˆ¶</em>ã€‚ ÂŒ</li><li>åŠ å¼º<em>æ•°æ®æº¯æºèƒ½åŠ›å’Œç½‘ç»œå–è¯èƒ½åŠ›</em>ï¼Œå®Œå–„ç½‘ç»œçŠ¯ç½ªå–è¯æœºåˆ¶ã€‚</li></ul><h3><span id="å¯†ç å­¦åœ¨åˆ†å¸ƒå¼ä¼ æ„Ÿå™¨ç½‘ç»œdsnä¸­çš„åº”ç”¨">å¯†ç å­¦åœ¨åˆ†å¸ƒå¼ä¼ æ„Ÿå™¨ç½‘ç»œï¼ˆDSNï¼‰ä¸­çš„åº”ç”¨</span></h3><p><strong>å¯†é’¥åˆ†å‘é—®é¢˜</strong></p><ol type="1"><li><em>å•ä¸€å¯†é’¥</em><ul><li>ä¼˜ç‚¹<ul><li>å­˜å‚¨å°‘</li><li>æ•ˆç‡é«˜</li><li>å¢åŠ ï¼åˆ é™¤æ–°èŠ‚ç‚¹å®¹æ˜“ï¼Œä¸ä¼šå¯¹ç°æœ‰èŠ‚ç‚¹äº§ç”Ÿé—®é¢˜</li></ul></li><li>ç¼ºç‚¹<ul><li>å•ä¸€èŠ‚ç‚¹è¢«ä¿˜è·ï¼Œå±å®³æ•´ä¸ªç³»ç»Ÿçš„å®‰å…¨</li></ul></li></ul></li><li><em>æ¯ä¸¤ä¸ªä¼ æ„Ÿå™¨é‡‡ç”¨ä¸åŒå¯†é’¥</em><ul><li>ä¼˜ç‚¹<ul><li>å®‰å…¨æ€§é«˜</li></ul></li><li>ç¼ºç‚¹<ul><li>æ¯ä¸ªä¼ æ„Ÿå™¨éœ€è¦å­˜å‚¨N-1ä¸ªå¯†é’¥</li><li>å¢åŠ ï¼åˆ é™¤ä¼ æ„Ÿå™¨ä¼šå¯¹ç°æœ‰ä¼ æ„Ÿå™¨äº§ç”Ÿå½±å“</li></ul></li></ul></li><li><em>æŠ˜ä¸­</em>æ–¹æ³•<ul><li>åˆ†ç»„</li></ul></li></ol><p>å®‰å…¨æ€§ VS æ•ˆç‡</p><ol type="1"><li>è¿½æ±‚æè‡´çš„æ•ˆç‡è€Œä¸è€ƒè™‘å®‰å…¨æ€§<ul><li>çœ‹æ­¤é—®é¢˜æœ‰æ²¡æœ‰æœ‰æ•ˆçš„è§£å†³æ–¹æ³•-&gt;å¦‚æœæ²¡æœ‰ï¼Œåˆ™ä¸å¿…å‘ä¸‹æ¢ç©¶</li></ul></li><li>è¿½æ±‚æè‡´çš„å®‰å…¨æ€§è€Œä¸è€ƒè™‘æ•ˆç‡çš„å¼€é”€<ul><li>æœ€å¤§èƒ½è¾¾åˆ°çš„å®‰å…¨æ€§</li></ul></li><li>å¹³è¡¡å®‰å…¨æ€§å’Œæ•ˆç‡<ul><li>å¼±åŒ–ç¬¬äºŒç§æ–¹æ¡ˆçš„å®‰å…¨æ€§-&gt;å‡å°‘æ­¥éª¤</li></ul></li></ol><h3><span id="åŸºäºå¯†ç å­¦çš„rfidè®¤è¯">åŸºäºå¯†ç å­¦çš„RFIDè®¤è¯</span></h3><p>å®‰å…¨æ€§éœ€æ±‚</p><ul><li><em>ä¿å¯†æ€§</em>ï¼šå³ä¿¡æ¯åœ¨Tagä¸Readerä¹‹é—´ä¼ è¾“æ—¶éœ€è¦è¿›è¡Œä¿æŠ¤ï¼Œä¾‹å¦‚åŠ å¯†</li><li><em>ä¸å¯ä¼ªé€ æ€§</em>ï¼šæ”»å‡»è€…ä¸èƒ½å¤Ÿä¼ªè£…æˆä¸€ä¸ªåˆæ³•çš„æ”»å‡»è€…ä¸èƒ½å¤Ÿä¼ªè£…æˆä¸ªåˆæ³•çš„Tagæˆ–è€…Reader</li><li><em>ä½ç½®éšç§</em>ï¼šæ”»å‡»è€…ä¸èƒ½å¤Ÿè·çŸ¥Tagçš„ä½ç½®ä¿¡æ¯ï¼Œ å³ä¸å¯è¿½è¸ª</li></ul><p><em>Hash-Lockåè®®ï¼ˆæœ€ç®€å•ï¼‰</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-43.png"></p><ul><li>å®ç°Tagä¸Readerçš„<em>äº’è®¤è¯</em><ul><li>ç¬¬äº”æ­¥ï¼ŒTagè®¤è¯è¯»å†™å™¨</li><li>ç¬¬å…­æ­¥ï¼Œè¯»å†™å™¨è®¤è¯Tag</li></ul></li><li>ä¼˜ç‚¹<ul><li>ç®€å•</li></ul></li><li>é—®é¢˜ï¼šæ”»å‡»è€…å¯ä»¥<em>åŠ«æŒä¼ è¾“çš„metaIDå’ŒID</em><ul><li><strong>ä¼ªé€ RFIDæ ‡ç­¾</strong></li><li><strong>é‡æ”¾æ”»å‡»</strong>ï¼ˆéœ€è¦æˆªè·å¹¶è®°å½•ä»¥å‰çš„é€šè®¯ï¼‰</li></ul></li></ul><p><em>éšæœºåŒ–Hash-Lockåè®®</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-44.png"></p><ul><li>è®¤è¯<ul><li>ç¬¬äº”æ­¥ï¼ŒTagéªŒè¯è¯»å†™å™¨</li><li>ç¬¬å››æ­¥ï¼Œè¯»å†™å™¨éªŒè¯Tagï¼Œå› ä¸ºè§£å‡ºä¸€ä¸ªæ­£ç¡®çš„æ ‡ç­¾ID</li></ul></li><li>ä½†Tagæ ‡è¯†ä»ä»¥æ˜æ–‡å½¢å¼ä¼  è¾“ï¼Œå¾ˆå®¹æ˜“å¯¹Tagè¿›è¡Œè·Ÿè¸ªï¼Œä¸”<strong>æ˜“å—ä¼ªé€ æ”»å‡»å’Œé‡ä¼ æ”»å‡»Â </strong><ul><li>æˆªè·åˆæ³•çš„IDkï¼Œæ”¾åˆ°ä¼ªé€ çš„æ ‡ç­¾é‡Œ</li><li>ç¬¬å››æ­¥ä¼ å›æ‰€æœ‰çš„IDï¼Œé€šä¿¡å¼€é”€å¾ˆå¤§ï¼Œè¯»å–å™¨å­˜å‚¨å¼€é”€å¤§</li></ul></li></ul><p><em>Hashé“¾åè®®</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-45.png"> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-46.png"></p><ul><li><em>å•å‘è®¤è¯</em><ul><li>è¯»å†™å™¨è®¤è¯Tagï¼šç¬¬å››æ­¥ï¼Œå› ä¸ºè§£å‡ºä¸€ä¸ªæ­£ç¡®çš„æ ‡ç­¾ID</li></ul></li><li>åˆæ³•RFIDæ ‡ç­¾çš„IDå€¼æ˜¯åŠ¨æ€å˜åŒ–çš„</li><li>ä¼˜ç‚¹<ul><li>å¯é˜²è¿½é€</li><li>å¯é˜²ä¼ªé€ </li><li>å¯é‡ä¼ æ”»å‡»</li></ul></li><li>Gã€Hä¸èƒ½ç›¸åŒ<ul><li>è‹¥ç›¸åŒåˆ™aå˜æˆä¸‹ä¸€æ¬¡çš„çŠ¶æ€ä¿¡æ¯</li></ul></li></ul><h3><span id="åŸºäºpkeçš„rfidè®¤è¯">åŸºäºPKEçš„RFIDè®¤è¯</span></h3><p><img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-47.png"></p><p><em>æ–¹æ¡ˆ1</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-48.png"></p><ul><li>å®‰å…¨æ€§ï¼šå¼•å…¥äº†éšæœºæ•°ï¼Œå› æ­¤å¯ä»¥æŠµæŠ—æ¶ˆæ¯é‡æ”¾æ”»å‡»</li><li><em>è¯»å†™å™¨å¯¹Tagçš„å•å‘è®¤è¯</em><ul><li>å› ä¸ºåªæœ‰çœŸæ­£çš„Tagæ‰ä¼šæœ‰æ­£ç¡®çš„ï¼ˆID, Kï¼‰å’Œåˆšå‘çš„éšæœºæ•° <em>æ–¹æ¡ˆ2</em> <img src="/images/ç‰©è”ç½‘å®‰å…¨æ¦‚è®º/DraggedImage-49.png"></li></ul></li><li>å®‰å…¨æ€§</li><li><em>è¯»å†™å»å’ŒTagçš„åŒå‘è®¤è¯</em><ul><li>ç¬¬ä¸‰æ­¥ï¼Œè¯»å†™å™¨éªŒè¯Tag</li><li>ç¬¬å››æ­¥ï¼ŒTagéªŒè¯è¯»å†™å™¨</li></ul></li></ul><p>å®é™…åº”â½¤ç”¨ä¸­ç¼ºç‚¹ï¼šå¤æ‚ã€æ•ˆç‡ä½ã€æˆæœ¬â¾¼é«˜</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœ¬ç§‘è¯¾ç¨‹ </tag>
            
            <tag> ç‰©è”ç½‘ </tag>
            
            <tag> ä¿¡æ¯å®‰å…¨ </tag>
            
            <tag> RSA </tag>
            
            <tag> DES </tag>
            
            <tag> AES </tag>
            
            <tag> PKI </tag>
            
            <tag> HASH </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>è®¡ç®—æœºç½‘ç»œ</title>
      <link href="/2017/06/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
      <url>/2017/06/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#è®¡ç®—æœºç½‘ç»œæ¦‚è®º">è®¡ç®—æœºç½‘ç»œæ¦‚è®º</a><ul><li><a href="#è®¡ç®—æœºç½‘ç»œçš„å®šä¹‰">è®¡ç®—æœºç½‘ç»œçš„å®šä¹‰</a></li><li><a href="#å› ç‰¹ç½‘çš„ç»“æ„">å› ç‰¹ç½‘çš„ç»“æ„</a></li><li><a href="#åè®®åˆ†å±‚ä¸æœåŠ¡æ¨¡å‹">åè®®åˆ†å±‚ä¸æœåŠ¡æ¨¡å‹</a></li><li><a href="#åˆ†ç»„äº¤æ¢ç½‘çš„æ€§èƒ½æŒ‡æ ‡">åˆ†ç»„äº¤æ¢ç½‘çš„æ€§èƒ½æŒ‡æ ‡</a></li></ul></li><li><a href="#æ•°æ®é€šä¿¡åŸºç¡€">æ•°æ®é€šä¿¡åŸºç¡€</a><ul><li><a href="#äº¤æ¢æŠ€æœ¯">äº¤æ¢æŠ€æœ¯</a></li><li><a href="#æ¥å…¥ç½‘">æ¥å…¥ç½‘</a></li><li><a href="#ç‰©ç†å±‚æ¦‚è¿°">ç‰©ç†å±‚æ¦‚è¿°</a></li></ul></li><li><a href="#ç›´æ¥è¿æ¥çš„ç½‘ç»œ">ç›´æ¥è¿æ¥çš„ç½‘ç»œ</a><ul><li><a href="#é“¾è·¯å±‚æ¦‚è¿°">é“¾è·¯å±‚æ¦‚è¿°</a></li><li><a href="#æˆæ¡¢">æˆæ¡¢</a></li><li><a href="#å·®é”™æ£€æµ‹å’Œçº é”™æŠ€æœ¯">å·®é”™æ£€æµ‹å’Œçº é”™æŠ€æœ¯</a></li><li><a href="#å¯é ä¼ è¾“åŸç†">å¯é ä¼ è¾“åŸç†</a></li><li><a href="#å¤šè·¯è®¿é—®åè®®">å¤šè·¯è®¿é—®åè®®</a></li><li><a href="#ä»¥å¤ªç½‘">ä»¥å¤ªç½‘</a></li><li><a href="#é“¾è·¯å±‚äº¤æ¢æœº">é“¾è·¯å±‚äº¤æ¢æœº</a></li></ul></li><li><a href="#ç½‘ç»œäº’è”">ç½‘ç»œäº’è”</a><ul><li><a href="#ç½‘ç»œå±‚æ¦‚è¿°">ç½‘ç»œå±‚æ¦‚è¿°</a></li><li><a href="#ç½‘ç»œæœåŠ¡æ¨¡å‹">ç½‘ç»œæœåŠ¡æ¨¡å‹</a></li><li><a href="#ç½‘é™…åè®®ip">ç½‘é™…åè®®ï¼ˆIPï¼‰</a></li><li><a href="#è·¯ç”±é€‰æ‹©åè®®åŠå…¶ç®—æ³•">è·¯ç”±é€‰æ‹©åè®®åŠå…¶ç®—æ³•</a></li><li><a href="#è·¯ç”±å™¨çš„å·¥ä½œåŸç†">è·¯ç”±å™¨çš„å·¥ä½œåŸç†</a></li></ul></li><li><a href="#ç«¯åˆ°ç«¯åè®®">ç«¯åˆ°ç«¯åè®®</a><ul><li><a href="#è¿è¾“å±‚åè®®æ¦‚è¿°">è¿è¾“å±‚åè®®æ¦‚è¿°</a></li><li><a href="#å¤šè·¯å¤ç”¨ä¸å¤šè·¯åˆ†è§£">å¤šè·¯å¤ç”¨ä¸å¤šè·¯åˆ†è§£</a></li><li><a href="#udp">UDP</a></li><li><a href="#tcp">TCP</a></li><li><a href="#tcpæ‹¥å¡æ§åˆ¶">TCPæ‹¥å¡æ§åˆ¶</a></li></ul></li><li><a href="#ç½‘ç»œåº”ç”¨åè®®">ç½‘ç»œåº”ç”¨åè®®</a><ul><li><a href="#åŸŸåç³»ç»Ÿdns">åŸŸåç³»ç»ŸDNS</a></li><li><a href="#http">HTTP</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="è®¡ç®—æœºç½‘ç»œæ¦‚è®º">è®¡ç®—æœºç½‘ç»œæ¦‚è®º</span></h2><h3><span id="è®¡ç®—æœºç½‘ç»œçš„å®šä¹‰">è®¡ç®—æœºç½‘ç»œçš„å®šä¹‰</span></h3><p>ç½‘ç»œå®ä½“å¯æŠ½è±¡ä¸ºä¸¤ç§åŸºæœ¬æ„ä»¶:</p><ul><li><em>ç»“ç‚¹(node)</em>(äº¦ç§°èŠ‚ç‚¹):è®¡ç®—è®¾å¤‡</li><li><em>é“¾è·¯(link)</em>:ç‰©ç†åª’ä½“</li></ul><p>æ„æˆç½‘ç»œçš„æ–¹å¼</p><ol type="1"><li>ç›´æ¥ç›¸è¿<ul><li>ç”±æŸç§ç‰©ç†åª’ä½“ç›´æ¥ç›¸è¿æ‰€æœ‰ä¸»æœºç»„æˆ</li><li>åˆ†ç±»<ul><li>ç‰©ç†é“¾è·¯ä¸ä¸€å¯¹ç»“ç‚¹ç›¸è¿: <em>ç‚¹åˆ°ç‚¹é“¾è·¯(point-to-point link)Â </em></li><li>å¤šç»“ç‚¹å…±äº«åŒä¸€ç‰©ç†é“¾è·¯: <em>å¤šè·¯è®¿é—®é“¾è·¯(multiple access)Â </em></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage.png"></li></ul></li></ul></li><li>ç½‘ç»œäº‘<ul><li>ç½‘ç»œäº‘è¡¨ç¤ºä»»ä½•ç±»å‹çš„</li><li>ç½‘ç»œé€šå¸¸é‡‡ç”¨<em>åˆ†ç»„äº¤æ¢</em>æŠ€æœ¯</li><li>ä¸»æœºé—´æ¥è¿é€šçš„ç¬¬ä¸€ç§æ–¹æ³•</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-1.png"></li></ul></li><li>ç½‘ç»œäº‘äº’è”<ul><li><em>é€’å½’åœ°è¿æ¥ç½‘ç»œäº‘</em>å½¢æˆæ›´å¤§è§„æ¨¡çš„ç½‘ç»œï¼Œæœ‰å¾ˆå¥½çš„æ‰©å±•æ€§ç”±ç½‘ç»œäº‘æ„å»ºæˆç½‘ç»œç§°ä¸ºäº’è”ç½‘</li><li>è¿æ¥ä¸¤ä¸ªæˆ–å¤šä¸ªç½‘ç»œäº‘çš„ç»“ç‚¹ç§°<strong>è·¯ç”±å™¨</strong></li><li>ä¸»æœºé—´æ¥è¿é€šçš„ç¬¬äºŒç§æ–¹æ³•</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-2.png"></li></ul></li></ol><p>ä¸¤ç§æ•°æ®ä¼ é€’æ–¹æ³•</p><ul><li>ç”µè·¯äº¤æ¢(circuit switching)<ul><li>ä¸»è¦ç”¨äºç”µè¯ç½‘ï¼Œåœ¨å‘é€æ–¹å’Œæ¥æ”¶æ–¹ä¹‹é—´é€šè¿‡å¤šå°äº¤æ¢æœºå»ºç«‹ä¸€æ¡è¿æ¥(ç”µè·¯circuit)</li></ul></li><li>åˆ†ç»„äº¤æ¢(packet switching)<ul><li>ä¸»è¦ç”¨äºè®¡ç®—æœºç½‘ç»œåˆ†ç»„(packets) é•¿æŠ¥æ–‡(message)åˆ’åˆ†ä¸ºç­‰é•¿çš„çŸ­æ®µï¼Œå¹¶ä¸ºæ¯ä¸ªæ®µåŠ ä¸Šé¦–éƒ¨</li></ul></li></ul><p>ç½‘ç»œæœåŠ¡</p><ul><li>ç½‘ç»œæœåŠ¡æ˜¯å‘ç”¨æˆ·æ‰€æä¾›çš„æœ‰ç”¨ç½‘ç»œåŠŸèƒ½ï¼Œç”±è¿è¡Œåœ¨ç½‘ç»œä¸­ä¸åŒä¸»æœºä¸Šçš„ç½‘ç»œåº”ç”¨ç¨‹åºåä½œæä¾›ã€‚</li><li><strong>åº”ç”¨ç¨‹åºè¿è¡Œåœ¨ç«¯ç³»ç»Ÿä¸Š</strong>ï¼Œè€Œä¸è¿è¡Œåœ¨äº¤æ¢æœºå’Œè·¯ç”±å™¨ä¸Š</li></ul><h3><span id="å› ç‰¹ç½‘çš„ç»“æ„">å› ç‰¹ç½‘çš„ç»“æ„</span></h3><ul><li>ç½‘ç»œè¾¹ç¼˜(edge):<ul><li>åº”ç”¨ä¸ä¸»æœº</li></ul></li><li>ç½‘ç»œæ ¸å¿ƒ(core):<ul><li>è·¯ç”±å™¨(ç½‘ç»œçš„ç½‘ç»œ)</li></ul></li><li>æ¥å…¥ç½‘(access network):<ul><li>è¿æ¥ä¸¤è€…çš„é€šä¿¡é“¾è·¯</li><li>å°†ç«¯ç³»ç»Ÿè¿æ¥åˆ°å…¶<em>è¾¹ç¼˜è·¯ç”±å™¨(edge router)</em>çš„ç‰©ç†é“¾è·¯åŠè®¾å¤‡çš„é›†åˆ</li></ul></li><li><strong>ç«¯åˆ°ç«¯åŸåˆ™</strong><ul><li><strong>è¾¹ç¼˜æ™ºèƒ½ï¼Œæ ¸å¿ƒç®€å•</strong></li><li>å°†å¤æ‚çš„ç½‘ç»œåŠŸèƒ½ç½®äºè¾¹ç¼˜ï¼ˆå¦‚å·®é”™æ§åˆ¶ã€æµé‡æ§åˆ¶å’Œåº”ç”¨ç­‰ï¼‰</li><li>ç›¸å¯¹ç®€å•çš„åˆ†ç»„äº¤ä»˜åŠŸèƒ½ç½®äºæ ¸å¿ƒï¼ˆå¦‚åˆ†ç»„çš„é€‰è·¯å’Œè½¬å‘åŠŸèƒ½ï¼‰</li></ul></li></ul><p><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-3.png"></p><ul><li>å› ç‰¹ç½‘çš„æ ¸å¿ƒ<ul><li>åœ¨ä¸­å¿ƒ: â€œç¬¬ä¸€å±‚â€ISP (å¦‚UUNet, BBN/Genuity, Sprint, AT&amp;T), è¦†ç›–å›½å®¶/å›½é™…</li><li>ç¬¬äºŒå±‚â€ ISP: è¾ƒå°çš„(å¸¸ä¸ºåŒºåŸŸçš„) ISP(å¦‚ä¸­å›½ç”µä¿¡ã€ä¸­å›½ ç½‘é€šã€ä¸­å›½ç§»åŠ¨)</li><li>ç¬¬ä¸‰å±‚â€ ISPå’Œæœ¬åœ°ISP</li></ul></li></ul><p><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-4.png"></p><h3><span id="åè®®åˆ†å±‚ä¸æœåŠ¡æ¨¡å‹">åè®®åˆ†å±‚ä¸æœåŠ¡æ¨¡å‹</span></h3><p>ç½‘ç»œåè®®</p><ul><li>ä¸ºè¿›è¡Œç½‘ç»œä¸­çš„æ•°æ®äº¤æ¢è€Œå»ºç«‹çš„è§„åˆ™ã€æ ‡å‡†æˆ–çº¦å®šå³ç§°ä¸º<em>ç½‘ç»œåè®®(network protocol)Â </em></li><li>ç½‘ç»œåè®®3è¦ç´ :<ul><li>è¯­æ³• :æ•°æ®ä¸æ§åˆ¶ä¿¡æ¯çš„ç»“æ„æˆ–æ ¼å¼</li><li>è¯­ä¹‰:å‘å‡ºä½•ç§æ§åˆ¶ä¿¡æ¯ï¼Œå®Œæˆä½•ç§åŠ¨ä½œä»¥åŠåšå‡ºä½•ç§å“åº”</li><li>å®šæ—¶:äº‹ä»¶å®ç°é¡ºåºçš„è¯¦ç»†è¯´æ˜</li></ul></li></ul><p>ä½œä¸š</p><ol type="1"><li>ç½‘ç»œæœ‰å“ªäº›æ„ä»¶?ä¸»æœºä¹‹é—´äº’è”æœ‰å“ªå‡ ç§æ–¹å¼? ç«¯ç³»ç»Ÿä¸Šçš„ç°ä»£æ“ä½œç³»ç»Ÿé€šå¸¸å®šä¹‰äº†å“ªäº›ç¼–ç¨‹å¼€å‘æ¥å£?</li><li>å‚è§å›¾1-11ï¼Œå› ç‰¹ç½‘å…·æœ‰å¤§è‡´åˆ†å±‚çš„ISPç­‰çº§ç»“æ„ã€‚ç”±æ­¤å›ç­”:ä¸ºä½•è¯´å› ç‰¹ç½‘æ˜¯ç½‘ç»œçš„ç½‘ç»œ?æ¯å±‚ISPæ˜¯å¦å¤§è‡´ä¸åœ°ç†èŒƒå›´å¯¹åº”?å†…å®¹æä¾›å•†æ­£åœ¨ä»¥ä½•ç§æ–¹å¼æ”¹å˜å› ç‰¹ç½‘ çš„ç»“æ„?</li><li>ä»€ä¹ˆå«åšç½‘ç»œåè®®?æ„æˆåè®®çš„å‡ ä¸ªè¦ç´ æ˜¯ä»€ä¹ˆ?æ˜¯å¦å¯ä»¥ç¼ºå¤±å…¶ä¸­çš„æŸä¸ªè¦ç´ ?è¯·ä¸¾ä¾‹è¯´æ˜åŸå› ã€‚</li></ol><p><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-5.png" title="ç½‘ç»œç»“æ„"></p><p>ç½‘ç»œåˆ†å±‚</p><ul><li><strong>åˆ†è€Œæ²»ä¹‹</strong></li><li><strong>åè®®æ˜¯</strong>â€œ<em>æ°´å¹³çš„</em>â€ï¼Œ<strong>æœåŠ¡æ˜¯</strong>â€œ<em>å‚ç›´çš„</em>â€</li><li>ä½“ç³»ç»“æ„ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-6.png"></li></ul><p><strong>ç«¯åˆ°ç«¯åŸåˆ™</strong></p><ul><li>å¦‚æœåœ¨è¾ƒé«˜å±‚èƒ½å¤Ÿå®Œå–„åœ°å®ç°æŸç§åŠŸèƒ½ï¼Œå°±æ— éœ€å†ç”±è¾ƒä½å±‚æä¾›è¿™ç§åŠŸèƒ½</li></ul><h3><span id="åˆ†ç»„äº¤æ¢ç½‘çš„æ€§èƒ½æŒ‡æ ‡">åˆ†ç»„äº¤æ¢ç½‘çš„æ€§èƒ½æŒ‡æ ‡</span></h3><p>æ—¶å»¶å’Œä¸¢åŒ…çš„äº§ç”Ÿ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-7.png"></p><p><em>æµé‡å¼ºåº¦</em></p><ul><li>R = é“¾è·¯å¸¦å®½ (bps)</li><li>L = åˆ†ç»„é•¿åº¦ (æ¯”ç‰¹)</li><li>a = å¹³å‡åˆ†ç»„åˆ°è¾¾é€Ÿç‡</li><li>æµé‡å¼ºåº¦ = <span class="math inline">\(La / R\)</span><ul><li>La/R -&gt; 0: å¹³å‡æ’é˜Ÿæ—¶å»¶å°</li><li>La/R -&gt; 1: æ—¶å»¶æ€¥å‰§å˜å¤§</li><li>La/R &gt; 1: æ›´å¤šâ€œå·¥ä½œâ€åˆ°è¾¾ï¼Œè¶…å‡ºäº†æœåŠ¡èƒ½ åŠ›ï¼Œå¹³å‡æ—¶å»¶æ— ç©·å¤§!</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-8.png"></li></ul></li></ul><p><em>èŠ‚ç‚¹æ—¶å»¶</em></p><ul><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-9.png"></li><li>dproc = å¤„ç†æ—¶å»¶<ul><li>é€šå¸¸å‡ ä¸ªå¾®ç§’æˆ–æ›´å°‘</li></ul></li><li>dqueue = æ’é˜Ÿæ—¶å»¶<ul><li>å–å†³äºæ‹¥å¡</li></ul></li><li>dtrans = ä¼ è¾“æ—¶å»¶(å‘é€æ—¶å»¶)= <em>L/R</em><ul><li>å¯¹ä½é€Ÿé“¾è·¯å¾ˆå¤§</li></ul></li><li>dprop = ä¼ æ’­æ—¶å»¶<ul><li>å‡ å¾®ç§’åˆ°å‡ ç™¾æ¯«ç§’</li></ul></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-10.png"></li></ul><p>ä¸¢åŒ…ç‡</p><ul><li>åœ¨ä¸€å®šçš„æ—¶æ®µå†…åœ¨ä¸¤ç»“ç‚¹é—´ä¼ è¾“è¿‡ç¨‹<em>ä¸¢å¤±åˆ†ç»„æ•°é‡</em>ä¸<em>æ€»çš„åˆ†ç»„å‘é€æ•°é‡</em>çš„æ¯”ç‡</li><li>IPç½‘ä¸¢åŒ…ä¸»è¦åŸå› <ul><li>è·¯ç”±å™¨æ— æ³•å®¹çº³åˆ°è¾¾çš„åˆ†ç»„ï¼Œåªèƒ½ä¸¢å¼ƒ(drop) åˆ°è¾¾çš„åˆ†ç»„</li></ul></li></ul><p>å¸¦å®½å’Œååé‡</p><ul><li>ç½‘ç»œå¸¦å®½<ul><li>é“¾è·¯åœ¨<em>ä¸€æ®µç‰¹å®šçš„æ—¶é—´</em>å†…æ‰€èƒ½<em>ä¼ é€çš„æ¯”ç‰¹æ•°</em>çš„é¢å®šå€¼</li></ul></li><li>ååé‡<ul><li>ç½‘ç»œåœ¨å•ä½æ—¶é—´å†…æ— å·®é”™åœ°ä¼ è¾“æ•°æ®çš„èƒ½åŠ›</li></ul></li><li>ç“¶é¢ˆé“¾è·¯<ul><li>è·¯å¾„ä¸­å¯ç”¨å¸¦å®½æœ€å°çš„é“¾è·¯</li></ul></li><li>å¯ç”¨å¸¦å®½<ul><li>å¸¦å®½ä¸å¹²æ‰°æµé‡ä¹‹å·®</li></ul></li></ul><p>è·³ä¸è·¯å¾„</p><ul><li>è·¯å¾„å¯ä»¥å®šä¹‰ä¸ºå½¢å¼ä¸º <span class="math inline">\([h_0, l_1, h_1, ..., l_nï¼Œh_n]\)</span> çš„åºåˆ—ï¼Œæ˜¯å•å‘çš„</li><li>å¯¹äºç«¯åˆ°ç«¯è·¯å¾„è€Œè¨€ï¼Œh0å’Œhnæ˜¯ç«¯ç³»ç»Ÿï¼Œè€Œ h1...hn-1 æ˜¯è·¯ç”±å™¨ã€‚æ¯ä¸ª&lt;liï¼Œhi&gt;äºŒå…ƒç»„è¢«ç§°ä¸ºä¸€â€œè·³â€</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-11.png"></li></ul><p>æ—¶å»¶ä¸å¸¦å®½ä¹˜ç§¯</p><ul><li>ç‰©ç†æ„ä¹‰<ul><li><strong>ç®¡é“èƒ½å¤Ÿå®¹çº³çš„æ¯”ç‰¹æ•°</strong></li></ul></li></ul><p>ä½œä¸š</p><ol type="1"><li>æ•°æ®åœ¨å„å±‚ä¹‹é—´çš„ä¼ é€’è¿‡ç¨‹ä¸­ï¼Œå„å±‚åè®®çš„é¦–éƒ¨èµ·ç€ä»€ä¹ˆä½œ ç”¨?â€œæ°´å¹³çš„â€åè®®å’Œâ€œå‚ç›´çš„â€æœåŠ¡ä¹‹é—´æœ‰ä»€ä¹ˆå…³ç³»?</li><li>TCP/IPä½“ç³»ç»“æ„å…·æœ‰å“ªäº›å±‚æ¬¡?è¯¥ä½“ç³»ç»“æ„çš„ä¸»è¦ç‰¹ç‚¹æ˜¯ä»€ ä¹ˆ?</li><li>è€ƒè™‘ä¸€ä¸ªé•¿åº¦ä¸ºLçš„åˆ†ç»„ä»ç«¯ç³»ç»ŸAå¼€å§‹ï¼Œç»ä¸€æ®µé“¾è·¯ä¼ é€åˆ°ä¸€ å°åˆ†ç»„äº¤æ¢æœºï¼Œå¹¶ä»è¯¥åˆ†ç»„äº¤æ¢æœºç»ç¬¬äºŒæ®µé“¾è·¯ä¼ é€åˆ°ç›®çš„ç«¯ ç³»ç»Ÿã€‚ä»¤diã€siå’ŒRiè¡¨ç¤ºé“¾è·¯içš„é•¿åº¦ã€ä¼ æ’­é€Ÿåº¦å’Œä¼ è¾“é€Ÿç‡ (i=1,2)ã€‚è¯¥åˆ†ç»„äº¤æ¢æœºå¯¹æ¯ä¸ªåˆ†ç»„çš„æ—¶å»¶ä¸ºdprocã€‚å‡å®šæ²¡æœ‰ æ’é˜Ÿæ—¶å»¶ï¼Œæ ¹æ®diã€siã€Ri (i=1,2)å’ŒLï¼Œè¯¥åˆ†ç»„æ€»çš„ç«¯åˆ°ç«¯æ—¶å»¶ æ˜¯ä»€ä¹ˆ?ç°åœ¨å‡å®šè¯¥åˆ†ç»„æ˜¯1,000å­—èŠ‚ï¼Œåˆ†ç»„äº¤æ¢æœºçš„å¤„ç†æ—¶å»¶ æ˜¯1 msï¼Œç¬¬ä¸€æ®µé“¾è·¯çš„é•¿åº¦æ˜¯4,000kmï¼Œå¹¶ä¸”æœ€åä¸€æ®µé“¾è·¯çš„ é•¿åº¦æ˜¯1,000kmã€‚å¯¹äºè¿™äº›å€¼ï¼Œè¯¥ç«¯åˆ°ç«¯æ—¶å»¶ä¸ºå¤šå°‘?</li></ol><h2><span id="æ•°æ®é€šä¿¡åŸºç¡€">æ•°æ®é€šä¿¡åŸºç¡€</span></h2><h3><span id="äº¤æ¢æŠ€æœ¯">äº¤æ¢æŠ€æœ¯</span></h3><p>ç”µè·¯äº¤æ¢</p><ul><li>å…·æœ‰â€œ<em>è¿æ¥å»ºç«‹-æ•°æ®ä¼ è¾“-è¿æ¥é‡Šæ”¾</em>â€ä¸‰ä¸ªæ­¥éª¤ï¼Œä»¥<em>åˆ†æ—¶</em>çš„æ–¹å¼å…±äº«é€šä¿¡èµ„æº</li><li>ä¼˜ç‚¹<ul><li>ç‹¬å èµ„æºï¼Œé€šä¿¡è´¨é‡æœ‰ä¿è¯</li><li>ä¼ è¾“æ—¶å»¶å°ï¼Œé€šä¿¡ä¸­æ— æ‹¥å¡</li></ul></li><li>ç¼ºç‚¹:<ul><li>å»ºè¿æ—¶é—´è¾ƒé•¿ï¼Œå·¥ä½œè¿‡ç¨‹å¤æ‚</li><li>æœ‰æ—¶å·¥ä½œæ•ˆç‡è¾ƒä½:è®¡ç®—æœºé€šä¿¡</li></ul></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-12.png"></li></ul><p>æŠ¥æ–‡äº¤æ¢</p><ul><li>ä¼˜ç‚¹:<ul><li><em>æ— è¿æ¥</em>ï¼ŒæŠ¥æ–‡å‘ç»™ç›¸é‚»ç»“ç‚¹ï¼ŒæŠ¥æ–‡å­˜å‚¨åå†é€‰æ‹©åˆé€‚å‡ºå£å‘åè½¬å‘ï¼Œç›´è‡³ç›®çš„ç»“ç‚¹</li><li>ä»¥â€œ<em>å­˜å‚¨è½¬å‘</em>â€ä¸ºç‰¹å¾</li></ul></li><li>ç¼ºç‚¹<ul><li>å¯¹æŠ¥æ–‡é•¿åº¦ä¸åŠ é™åˆ¶ï¼Œä¸­é—´ç»“ç‚¹<em>å­˜å‚¨ç©ºé—´å¾ˆå¤§</em></li><li>é•¿æ—¶é—´å ç”¨æŸæ®µçº¿è·¯ï¼Œå¯¼è‡´æŠ¥æ–‡åœ¨ä¸­é—´ç»“ç‚¹<em>æ—¶å»¶éå¸¸å¤§</em></li></ul></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-13.png"></li></ul><p>åˆ†ç»„äº¤æ¢</p><ul><li>â€œå­˜å‚¨è½¬å‘â€èƒ½é€æ®µå¹¶è¡Œåˆ©ç”¨çº¿è·¯ï¼Œè€Œé•¿æŠ¥æ–‡é™ä½äº†ç³»ç»Ÿæ•ˆç‡</li><li>æ”¹è¿›æªæ–½:<ul><li>é•¿æŠ¥æ–‡åˆ†ä¸ºè¾ƒçŸ­æ•°æ®å—(åˆ†ç»„)</li><li>ä»…å¼•å…¥è¾ƒå°æ—¶å»¶</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-14.png"></li></ul></li><li>ç»Ÿè®¡å¤ç”¨<ul><li>æŒ‰éœ€ä½¿ç”¨é“¾è·¯å¸¦å®½èµ„æº</li><li>é“¾è·¯ä¼ è¾“èƒ½åŠ›é€åˆ†ç»„åœ°è¢«å…±äº«ï¼Œä»¥é“¾è·¯çš„æœ€å¤§ä¼ è¾“é€Ÿç‡ä¼ è¾“</li><li>æ¯æ®µé“¾è·¯ä¼ è¾“é€Ÿç‡ä¸ä¸€å®šç›¸åŒ</li></ul></li></ul><h3><span id="æ¥å…¥ç½‘">æ¥å…¥ç½‘</span></h3><p>ç‚¹å¯¹ç‚¹æ¥å…¥</p><ul><li>ç»è°ƒåˆ¶è§£è°ƒå™¨æ‹¨å·<ul><li>æœ€é«˜è¾¾56Kbpsç›´æ¥æ¥å…¥åˆ°è·¯ç”±å™¨(ç»å¸¸è¾ƒå°‘)</li><li><em>ä¸èƒ½åŒæ—¶ä¸Šç½‘å’Œæ‰“ç”µè¯</em></li></ul></li><li><em>ADSL: ä¸å¯¹ç§°æ•°å­—ç”¨æˆ·çº¿</em><ul><li>æœ€é«˜è¾¾1Mbpsä¸Šè¡Œ(å…¸å‹&lt;256kbps)</li><li>æœ€é«˜è¾¾8Mbpsä¸‹è¡Œ(å…¸å‹&lt;1Mbps)</li></ul></li></ul><p>ç”µç¼†è°ƒåˆ¶è§£è°ƒå™¨</p><ul><li><em>HFC: æ··åˆå…‰çº¤åŒè½´</em><ul><li><em>ä¸å¯¹ç§°</em>:æœ€é«˜è¾¾30Mbpsä¸‹è¡Œ, 2 Mbpsä¸Šè¡Œ</li></ul></li><li>ç”µç¼†å’Œå…‰ç¼†çš„ç½‘ç»œå°†å®¶åº­è¿åˆ°ISPçš„è·¯ç”±å™¨<ul><li>å®¶åº­å…±äº«åˆ°è·¯ç”±å™¨çš„æ¥å…¥</li></ul></li></ul><p>å…¬å¸/å¤§å­¦å±€åŸŸç½‘ (LAN)</p><ul><li>å°†ç«¯ç³»ç»Ÿè¿æ¥åˆ°è¾¹ç¼˜è·¯ç”±å™¨</li></ul><p>ä»¥å¤ªç½‘</p><ul><li>å…±äº«æˆ–ä¸“ç”¨é“¾è·¯è¿æ¥ç«¯ç³»ç»Ÿå’Œè·¯ç”±å™¨</li><li>10 Mbs, 100Mbps, åƒå…†ä»¥ å¤ªç½‘</li></ul><h3><span id="ç‰©ç†å±‚æ¦‚è¿°">ç‰©ç†å±‚æ¦‚è¿°</span></h3><p>ç‰©ç†å±‚ä½œç”¨</p><ul><li>å®šä¹‰åœ¨è¿æ¥å„ç§è®¡ç®—æœºçš„ä¼ è¾“åª’ä½“ä¸ŠåŸå§‹æ¯”ç‰¹çš„äº¤äº’æ–¹å¼åŠå…¶æ¥å£ï¼Œ<em>ä¸å…³å¿ƒå…·ä½“çš„ç‰©ç†è®¾å¤‡æˆ–å…·ä½“çš„ä¼ è¾“åª’ä½“</em></li><li><em>å±è”½</em>æ‰ç§ç±»ç¹å¤šçš„ç‰©ç†è®¾å¤‡å’Œä¼ è¾“åª’ä½“çš„<em>å·®å¼‚</em>ï¼Œä½¿è¿™äº›å·®å¼‚å¯¹ä¸Šé¢çš„æ•°æ®é“¾è·¯å±‚é€æ˜</li></ul><p>ç‰©ç†å±‚åè®®</p><ul><li>æœºæ¢°ç‰¹æ€§</li><li>ç”µæ°”ç‰¹æ€§</li><li>åŠŸèƒ½ç‰¹æ€§</li><li>è§„ç¨‹ç‰¹æ€§</li><li>ä½¿ç”¨ç›¸åŒçš„ç‰©ç†å±‚æ ‡å‡†ï¼Œäº’è”è®¾å¤‡ä¹‹é—´èƒ½å¤Ÿäº¤äº’æ¯”ç‰¹</li></ul><p>ä½œä¸š</p><ol type="1"><li>å‡å®šç”¨æˆ·å…±äº«ä¸€æ¡2 Mbpsé“¾è·¯ã€‚åŒæ—¶å‡å®šå½“æ¯ä¸ªç”¨æˆ·ä¼ è¾“ æ—¶è¿ç»­ä»¥1 Mbpsä¼ è¾“ï¼Œä½†æ¯ä¸ªç”¨æˆ·ä»…ä¼ è¾“20%çš„æ—¶é—´ã€‚<ol type="a"><li>å½“ä½¿ç”¨ç”µè·¯äº¤æ¢æ—¶ï¼Œèƒ½å¤Ÿæ”¯æŒå¤šå°‘ç”¨æˆ·?</li><li>å¯¹äºè¯¥é—®é¢˜çš„é—ç•™é—®é¢˜ï¼Œå‡å®šä½¿ç”¨åˆ†ç»„äº¤æ¢ã€‚ä¸ºä»€ä¹ˆå¦‚æœä¸¤ä¸ªæˆ–æ›´å°‘çš„ç”¨æˆ·åŒæ—¶ä¼ è¾“çš„è¯ï¼Œåœ¨é“¾è·¯å‰é¢åŸºæœ¬ä¸Šæ²¡æœ‰æ’é˜Ÿæ—¶å»¶?ä¸ºä»€ä¹ˆå¦‚æœ3ä¸ªç”¨æˆ·åŒæ—¶ä¼ è¾“çš„è¯ï¼Œå°†æœ‰æ’é˜Ÿæ—¶å»¶? c.æ±‚å‡ºæŸæŒ‡å®šç”¨æˆ·æ­£åœ¨ä¼ è¾“çš„æ¦‚ç‡ã€‚d. å‡å®šç°åœ¨æœ‰3ä¸ªç”¨æˆ·ã€‚æ±‚å‡ºåœ¨ä»»ä½•ç»™å®šçš„æ—¶é—´ï¼Œæ‰€æœ‰3ä¸ªç”¨æˆ·åœ¨åŒæ—¶ä¼ è¾“çš„æ¦‚ç‡ã€‚æ±‚å‡ºæ’é˜Ÿå¢é•¿çš„æ—¶é—´æ¯”ç‡ã€‚ <em>ç­”</em>ï¼š</li><li>å½“ä½¿ç”¨ç”µè·¯äº¤æ¢æ—¶ï¼Œä¿¡é“å¸¦å®½éœ€è¦ç”¨æˆ·ç‹¬å ï¼Œæœ€å¤šæ™ºèƒ½æ”¯æŒ2ä¸ªç”¨æˆ·;</li><li>å› ä¸º2Mbpsé“¾è·¯ä»…èƒ½å®¹çº³ä¸¤ä¸ªæˆ–æ›´å°‘çš„ç”¨æˆ·åŒæ—¶ä»¥1Mbpsè¿ç»­ä¼ è¾“æ—¶ï¼Œ è¿™æ—¶ç»Ÿè®¡ä¸Šä¼šæœ‰èµ„æºå¯Œä½™ï¼Œè€Œå½“ 3 ä¸ªç”¨æˆ·åŒæ—¶ä¼ è¾“æ—¶ï¼Œç»Ÿè®¡ä¸Šä¾¿ä¼šå‡ºç°ä¾›ä¸åº”æ±‚ çš„ç°è±¡ï¼Œå¯¼è‡´æ’é˜Ÿæ—¶å»¶ã€‚</li></ol></li><li>ADSLçš„ä¸Šä¸‹è¡Œå¸¦å®½ä¸ºä½•è®¾è®¡ä¸ºä¸å¯¹ç§°?</li><li>å½“å‰æ— çº¿æ¥å…¥æ‰€ä½¿ç”¨çš„WiFiæŠ€æœ¯åŸºäºä½•ç§æ ‡å‡†?ä¸ºä½•3GæŠ€æœ¯ç»å¸¸è¦ä¸WiFiæŠ€æœ¯é…åˆä½¿ç”¨?</li></ol><h2><span id="ç›´æ¥è¿æ¥çš„ç½‘ç»œ">ç›´æ¥è¿æ¥çš„ç½‘ç»œ</span></h2><p>æœºåˆ¶</p><ul><li>æˆæ¡¢</li><li>æŸ¥é”™æ£€æµ‹å’Œçº é”™</li><li>å¯é æ•°æ®ä¼ è¾“</li><li>å¤šè·¯è®¿é—®</li></ul><p>è®¾å¤‡</p><ul><li>ä»¥å¤ªç½‘</li><li>å±€åŸŸç½‘äº¤æ¢æœº</li></ul><h3><span id="é“¾è·¯å±‚æ¦‚è¿°">é“¾è·¯å±‚æ¦‚è¿°</span></h3><p>é“¾è·¯å±‚åè®®</p><ul><li>é€šè¿‡<em>å•æ®µé“¾è·¯</em>ï¼Œ<em>ç‚¹åˆ°ç‚¹</em>ä¼ é€ä¸Šå±‚æ•°æ®æŠ¥</li><li>é“¾è·¯ä¸¤ç«¯ç»“ç‚¹é—´äº¤äº’çš„å¸§æ ¼å¼ï¼Œå‘é€å’Œæ¥æ”¶å¸§æ—¶çš„æ“ä½œ</li></ul><p>ä¸¤ç§ç½‘ç»œé“¾è·¯ç±»å‹</p><ul><li>ç‚¹å¯¹ç‚¹é“¾è·¯å’Œå¹¿æ’­é“¾è·¯ é“¾è·¯å±‚ç¯å¢ƒé‡è¦ç‰¹ç‚¹</li><li>ä¸€æ¡è·¯å¾„ä¸Šçš„ä¸åŒé“¾è·¯å¯è¿è¡Œä¸åŒçš„é“¾è·¯å±‚åè®®</li><li>é“¾è·¯å±‚åè®®æä¾›çš„æœåŠ¡å¯ä»¥ä¸åŒ</li><li>é€šä¿¡ç¯å¢ƒè¾ƒä¸ºç®€å•</li></ul><p>é“¾è·¯å±‚æœåŠ¡çš„è®¾è®¡é—®é¢˜</p><ol type="1"><li><em>å¸§è®¿é—®é“¾è·¯</em><ul><li>ç”¨<strong>åª’ä½“è®¿é—®æ§åˆ¶(MAC)</strong>åœ°å€æ ‡è¯†æºã€ç›®çš„åœ°</li></ul></li><li>ç›¸è¿èŠ‚ç‚¹é—´çš„<em>å¯é äº¤ä»˜</em></li><li>æµé‡æ§åˆ¶</li><li>æŸ¥é”™æ£€æµ‹</li><li>çº é”™</li></ol><h3><span id="æˆæ¡¢">æˆæ¡¢</span></h3><p><em>é¢å‘æ¯”ç‰¹çš„åè®®</em></p><ul><li>é¢å‘æ¯”ç‰¹çš„åè®®æŠŠå¸§çœ‹æˆæ¯”ç‰¹çš„é›†åˆ</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-15.png"></li><li>å¸§çš„å¼€å§‹å’Œç»“æŸï¼š<code>01111110</code></li><li><em>æ¯”ç‰¹å¡«å…… (bit stuffing)æ³•</em>(ç”¨äºå‘é€å‰/æ¥æ”¶å)<ul><li>å‘é€æ–¹ï¼šè‹¥æŠ¥æ–‡ä¸­5ä¸ªè¿ç»­1ï¼Œåˆ™æ’å…¥ä¸€ä¸ª0</li><li>æ¥æ”¶æ–¹ï¼šæ”¶åˆ°5ä¸ªè¿ç»­1ï¼š<ul><li>å¦‚æœåé¢ä¸º0 ï¼Œå»æ‰ï¼›</li><li>å¦‚æœåé¢ä¸º1ï¼Œå†åä¸º0ï¼Œåˆ™å¸§ç»“æŸ;å¦åˆ™å‡ºé”™</li></ul></li></ul></li></ul><p><em>PPPåè®®</em></p><ul><li>ç‚¹å¯¹ç‚¹åè®®</li><li>å®¶åº­ä¸»æœºç‚¹å¯¹ç‚¹é“¾è·¯çš„é“¾è·¯å±‚åè®®</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-16.png"></li></ul><p><em>é¢å‘å­—èŠ‚çš„åè®®</em></p><ul><li>æ¯å¸§éƒ½çœ‹æˆæ˜¯å­—èŠ‚çš„é›†åˆ</li><li>ä¿ç•™ä¸€ç»„å­—ç¬¦ä¸ºæ§åˆ¶å­—ç¬¦</li><li><em>æ•ˆç‡è¾ƒä½ï¼Œç›®å‰å·²å¾ˆå°‘ä½¿ç”¨</em></li><li>DLEå­—ç¬¦çš„â€œè½¬ä¹‰â€ä½œç”¨</li></ul><h3><span id="å·®é”™æ£€æµ‹å’Œçº é”™æŠ€æœ¯">å·®é”™æ£€æµ‹å’Œçº é”™æŠ€æœ¯</span></h3><p>å¤„ç†å¸§å·®é”™çš„ä¸¤ç§æ–¹æ³•</p><ol type="1"><li>æ£€é”™é‡å‘<ul><li>å·®é”™ç‡ä½æ•ˆæœå¥½</li><li>é€‚åˆ<em>é“¾è·¯å·®é”™ç‡</em>å¾ˆ<em>ä½</em>çš„åœºåˆï¼Œå¦‚æœ‰çº¿é€šä¿¡</li></ul></li><li>å‰å‘çº é”™ï¼ˆForward Error Correction, FEC ï¼‰<ul><li>çº é”™é€šè¿‡é¢å¤–ä¿¡æ¯â€œé¢„å…ˆâ€è¿›è¡Œ</li><li>æ—¶æ•ˆæ€§å¥½</li><li>é€‚åˆ<em>å¯¹æ—¶é—´è¦æ±‚</em>å¾ˆ<em>é«˜</em>çš„åœºåˆï¼Œå¦‚èˆªå¤©å’Œå®æ—¶æ§åˆ¶</li></ul></li></ol><p><strong>å·®é”™æ£€æµ‹</strong></p><ul><li>EDC= å·®é”™æ£€æµ‹å’Œçº é”™æ¯”ç‰¹ (å†—ä½™)</li><li>D = æ•°æ®ç”±å·®é”™æ ¡éªŒä¿æŠ¤ï¼Œå¯èƒ½åŒ…æ‹¬é¦–éƒ¨å­—æ®µ</li><li>å¥‡å¶æ ¡éªŒ<ul><li>å•æ¯”ç‰¹å¥‡å¶æ ¡éªŒ<ul><li>æ£€æµ‹å•ä¸ªæ¯”ç‰¹å·®é”™</li></ul></li><li>äºŒç»´æ¯”ç‰¹å¥‡å¶æ ¡éªŒ<ul><li>æ£€æµ‹å’Œ<em>çº æ­£</em>å•ä¸ªæ¯”ç‰¹å·®é”™</li></ul></li></ul></li><li><strong>äº’è”ç½‘æ ¡éªŒå’Œ</strong><ul><li>ç›®æ ‡:æ£€æµ‹ä¼ è¾“æ®µä¸­çš„â€œå·®é”™â€(å¦‚æ¯”ç‰¹ç¿»è½¬) (æ³¨æ„: ä»…ç”¨äºè¿è¾“å±‚)</li><li>å‘é€æ–¹ï¼š<ul><li>å°†æ®µå†…å®¹ä½œä¸º16æ¯”ç‰¹æ•´æ•°åºåˆ—æ¥å¤„ç†</li><li>æ£€éªŒå’Œ: <em>æ®µå†…å®¹ç›¸åŠ (è¡¥ç å’Œ)Â </em></li><li>å‘é€æ–¹å°†æ£€éªŒå’Œçš„å€¼å–åæ”¾å…¥ UDP æ£€éªŒå’Œå­—æ®µ</li></ul></li><li>æ¥æ”¶æ–¹ï¼š<ul><li>è®¡ç®—æ¥æ”¶åˆ°æ®µçš„æ£€éªŒå’Œ</li><li>æ£€æŸ¥æ˜¯å¦è®¡ç®—çš„æ£€éªŒå’Œç­‰äºæ£€éªŒå’Œå­—æ®µçš„å€¼:<ul><li>NO â€“ æ£€æµ‹åˆ°å·®é”™</li><li>YES â€“ æ²¡æœ‰æ£€æµ‹åˆ°å·®é”™ï¼Œä»å¯èƒ½æœ‰é”™</li></ul></li></ul></li><li>æ³¨æ„:å½“ä½œåŠ æ³•æ—¶ï¼Œæœ€é«˜ä½è¿›æ¯”ç‰¹ä½çš„è¿›ä½éœ€è¦åŠ åˆ°ç»“æœä¸­</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-17.png"></li></ul></li><li><strong>CRC</strong><ul><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-18.png"></li><li>å°†æ•°æ®æ¯”ç‰¹Dçœ‹ä½œä¸€ä¸ªäºŒè¿›åˆ¶æ•°</li><li>é€‰æ‹©r+1æ¯”ç‰¹æ¨¡å¼(ç”Ÿæˆå¼)G<ul><li>ç›®æ ‡:é€‰æ‹©rä¸ªCRC æ¯”ç‰¹R, ä½¿å¾— &lt;D,R&gt; è¢«Gæ•´é™¤ (ä»¥2ä¸ºæ¨¡)</li><li>æ¥æ”¶æ–¹çŸ¥é“G, ç”¨Gé™¤ä»¥&lt;D,R&gt;ã€‚å¦‚æœæœ‰éé›¶ä½™æ•°:æ£€æµ‹åˆ°å·®é”™!</li><li>èƒ½å¤Ÿæ£€æµ‹æ‰€æœ‰å°äºr+1æ¯”ç‰¹çš„çªå‘å·®é”™</li></ul></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-19.png"></li></ul></li></ul><h3><span id="å¯é ä¼ è¾“åŸç†">å¯é ä¼ è¾“åŸç†</span></h3><p><em>SW0åè®®</em></p><ul><li><strong>ä¿¡é“ä¸ä¸¢åŒ…</strong></li><li>åœæ­¢ç­‰å¾…(stop-and-wait, SW)åè®®</li><li>æ–¹æ¡ˆ<ul><li>æ¥åˆ°æ­£ç¡®PKTï¼Œå‘é€ä¸€ä¸ªè‚¯å®šç¡®è®¤(ACK)</li><li>æ”¶åˆ°é”™è¯¯PKTï¼Œå‘é€ä¸€ä¸ª å¦å®šç¡®è®¤(NAK)ï¼Œé‡ä¼ åŸ PKT</li></ul></li><li>é—®é¢˜ï¼šè‹¥ä¿¡é“ä¸¢åŒ…ï¼Œåˆ™å‘é€æ–¹ä¼šä¸€è‡´ç­‰å¾…æ¥æ”¶æ–¹çš„ç¡®è®¤åˆ°æ¥ï¼Œä»è€Œäº§ç”Ÿ<em>åè®®æ­»é”</em></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-20.png"></li></ul><p><em>SW1åè®®</em></p><ul><li><strong>ä¿¡é“ä¸¢åŒ…</strong></li><li>è§£å†³æ–¹æ¡ˆ: <em>å¢åŠ è¶…æ—¶å®šæ—¶å™¨</em></li><li>æ¯å‘PKTï¼Œå¯åŠ¨è¶…æ—¶å®šæ—¶å™¨ï¼Œç§°ä¸º<em>è¶…æ—¶é‡ä¼ æœºåˆ¶</em></li><li>é‡ä¼ æ—¶é—´ç•¥å¤§äºRTT</li><li>é—®é¢˜ï¼šå½“ç¡®è®¤åˆ†ç»„ä¸¢å¤±æ—¶ï¼Œæ¥æ”¶æ–¹ä¼šæ”¶åˆ°ä¸¤ä¸ªåŒæ ·çš„PKT</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-21.png"></li></ul><p><em>SW2åè®®</em></p><ul><li>è§£å†³æ–¹æ¡ˆ: å¢åŠ ä¸€ç§æ–°æœºåˆ¶ï¼š<strong>å‘é€åºå·</strong></li><li>åºå·åªéœ€1æ¯”ç‰¹ï¼Œå› ä¸ºå®ƒå¯ä»¥è®©æ¥æ”¶æ–¹çŸ¥é“å‘é€æ–¹æ˜¯å¦åœ¨é‡ä¼ å‰ä¸€ä¸ªåˆ†ç»„</li><li>é—®é¢˜ï¼šè‹¥ACKè¿Ÿåˆ°ï¼Œåˆ™å‘é€æ–¹åˆ¤æ–­åŒ…è¶…æ—¶é‡å‘ï¼Œç»“æœåˆšå‘å®Œå°±æ”¶åˆ°äº†ACKï¼ŒSW2æ— æ³•çŸ¥é“è¿™ä¸ªACKç¡®è®¤çš„æ˜¯å“ªä¸ªåŒ…</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-22.png"></li></ul><p><em>SW3åè®®</em>(rdt2.2)</p><ul><li>è§£å†³æ–¹æ¡ˆ: å¢åŠ <strong>ç¡®è®¤åºå·æœºåˆ¶</strong>ï¼Œåˆ†è¾¨å‡ºç¡®è®¤å¯¹åº”å“ªä¸ªåˆ†ç»„</li><li>ç»¼åˆä»¥ä¸Šæœºåˆ¶ä¸ºSWåè®®ï¼Œæˆ–è‡ªåŠ¨é‡ä¼ è¯·æ±‚ (ARQ, Automatic Repeat Request)<ul><li>å·®é”™æ£€æµ‹</li><li>æ¥æ”¶æ–¹ç¡®è®¤</li><li>é‡ä¼ </li><li>å®šæ—¶å™¨</li><li>åºå·</li></ul></li><li>å‘é€æ–¹FSM <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-23.png"></li></ul><p>ä½œä¸š</p><ol type="1"><li>é“¾è·¯å±‚åè®®èƒ½å¤Ÿå‘ç½‘ç»œå±‚æä¾›å“ªäº›å¯èƒ½çš„æœåŠ¡? ä¸¾ä¾‹è¯´æ˜é“¾è·¯å±‚åè®®ç›¸åº”çš„æœåŠ¡ ç­”ï¼šé“¾è·¯å±‚åè®®èƒ½å¤Ÿå‘ç½‘ç»œå±‚æä¾›çš„æœåŠ¡åŒ…æ‹¬:<em>æˆå¸§ã€å·®é”™æ£€æµ‹ã€å¯é äº¤ä»˜ã€ åª’ä½“è®¿é—®ã€æµé‡æ§åˆ¶</em>ã€‚ ä¾‹å¦‚ï¼ŒHDLC åè®®æä¾›äº†æ•°æ®é“¾è·¯å±‚çš„æˆå¸§å’Œ CRC æ£€æµ‹åŠŸèƒ½ç­‰ã€‚</li><li>è€ƒè™‘4 bitçš„ç”Ÿæˆå¤šé¡¹å¼G(x)=x3+1ï¼Œå‡è®¾æ•°æ®M(x) çš„å€¼ä¸º10101010ã€‚é™„åŠ æ¯”ç‰¹R(x)çš„å€¼æ˜¯ä»€ä¹ˆ?</li></ol><p><em>æµæ°´çº¿å¯é æ•°æ®ä¼ è¾“åè®®</em></p><ul><li>æµæ°´çº¿: å‘é€æ–¹å…è®¸å‘é€å¤šä¸ªä¼ è¾“ä¸­ã€æœªåº”ç­”çš„åˆ†ç»„<ul><li>å¿…é¡»å¢åŠ åºå·èŒƒå›´</li><li>å‘é€æ–¹å’Œ/æˆ–æ¥æ”¶æ–¹è®¾æœ‰ç¼“å†²</li></ul></li><li>ä¾‹å­ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-24.png"></li></ul><p><strong>å›é€€Næ­¥ (Go-Back-N, GBN)</strong></p><ul><li>å‘é€æ–¹<ul><li>åœ¨åˆ†ç»„é¦–éƒ¨éœ€è¦Kæ¯”ç‰¹åºå·ï¼Œ2çš„kæ¬¡æ–¹=N</li><li>â€œçª—å£â€æœ€å¤§ä¸ºN, å…è®¸Nä¸ªè¿ç»­çš„æ²¡æœ‰åº”ç­”åˆ†ç»„</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-25.png"></li><li>ACK(n)ï¼šç¡®è®¤æ‰€æœ‰ï¼ˆåŒ…æ‹¬åºå·nï¼‰çš„åˆ†ç»„-&gt;<strong>ç´¯è®¡ACK</strong><ul><li>å¯èƒ½æ”¶åˆ°é‡å¤çš„åˆ†ç»„</li></ul></li><li>å¯¹æ¯ä¸ªä¼ è¾“åˆ†ç»„ç”¨<em>åŒä¸€ä¸ªè®¡æ—¶å™¨</em></li><li>timeout(n)ï¼šé‡ä¼ çª—å£ä¸­çš„<em>åˆ†ç»„nåŠæ‰€æœ‰æ›´é«˜åºå·çš„åˆ†ç»„</em></li><li>å‘é€çª—å£ä¸º3ï¼Œåºå·ä¸º0, 1, 2, 3 <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-26.png"></li></ul></li><li>æ¥æ”¶æ–¹<ul><li>æ¥æ”¶æ–¹æ ¹æ®æ»‘åŠ¨çª—å£çš„åºå·æŒ‰åºæ¥æ”¶åˆ†ç»„ï¼Œ<em>çª—å£å†…è¿ç»­</em></li><li>çª—å£ä¸­<em>å¤±åºåˆ†ç»„åŠåé¢å°†è¢«ä¸¢å¼ƒ</em></li><li>æ¥æ”¶æ–¹é‡‡ç”¨<strong>ç´¯ç§¯ç¡®è®¤</strong>çš„æ–¹å¼ï¼Œå¯ä»¥ä¸ä¸€ä¸€ç¡®è®¤</li><li>GBNåè®®çš„æ¥æ”¶çª—å£çš„é•¿åº¦ä¸º1<ul><li>å¦‚æœå…è®¸æ¥æ”¶çª—å£çš„é•¿åº¦å¤§äº1ï¼Œå°±ä¸å¿…é‡å‘å·²å‘é€è¿‡çš„Nä¸ªåˆ†ç»„ï¼Œäºæ˜¯å¾—åˆ°é€‰æ‹©é‡ä¼ åè®®</li></ul></li></ul></li></ul><p><strong>é€‰æ‹©é‡ä¼  (Selective Repeat, SR)</strong></p><ul><li>æ¥æ”¶æ–¹åˆ†åˆ«ç¡®è®¤æ‰€æœ‰æ­£ç¡®æ¥æ”¶çš„æŠ¥æ–‡æ®µ<ul><li><em>ç¼“å­˜åˆ†ç»„</em>, ä»¥ä¾¿æœ€åæŒ‰åºäº¤ä»˜ç»™ä¸Šå±‚</li></ul></li><li>å‘é€æ–¹åªéœ€è¦<em>é‡ä¼ æ²¡æœ‰æ”¶åˆ°ACKçš„åˆ†ç»„</em><ul><li>å‘é€æ–¹å®šæ—¶å™¨<em>å¯¹æ¯ä¸ªæ²¡æœ‰ç¡®è®¤çš„åˆ†ç»„è®¡æ—¶</em></li></ul></li><li>å‘é€çª—å£<ul><li>Nä¸ªè¿ç»­çš„åºå·</li><li>ä¹Ÿéœ€è¦é™åˆ¶å·²å‘é€ä½†å°šæœªåº”ç­”åˆ†ç»„çš„åºå·</li><li><strong>çª—å£é•¿åº¦å°äºç­‰äºåºå·ç©ºé—´çš„ä¸€åŠ</strong></li></ul></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-27.png"></li><li>å‘é€æ–¹<ul><li>ä¸Šå±‚ä¼ æ¥æ•°æ®ï¼š<ul><li>å¦‚æœçª—å£ä¸­ä¸‹ä¸€ä¸ªåºå·å¯ç”¨, å‘é€æŠ¥æ–‡æ®µ</li></ul></li><li>timeout(n)ï¼šé‡ä¼ åˆ†ç»„nï¼Œé‡å¯è®¡æ—¶å™¨</li><li>ACK(n)ï¼šåœ¨[å‘é€åŸºï¼Œå‘é€åŸº+N\]<ul><li>æ ‡è®°åˆ†ç»„ n å·²ç»æ”¶åˆ°</li><li>å¦‚æœn æ˜¯æœ€å°æœªæ”¶åˆ°åº”ç­”çš„åˆ†ç»„ï¼Œå‘å‰æ»‘åŠ¨çª—å£åŸºæŒ‡é’ˆåˆ°ä¸‹ä¸€ä¸ªæœªç¡®è®¤åºå·</li></ul></li></ul></li><li>æ¥æ”¶æ–¹<ul><li>åˆ†ç»„nåœ¨[æ¥æ”¶åŸºï¼Œæ¥æ”¶åŸº+N-1\]<ul><li>å‘é€ACK(n)</li><li>å¤±åºï¼šç¼“å­˜</li><li>æŒ‰åºï¼šäº¤ä»˜(ä¹Ÿäº¤ä»˜æ‰€æœ‰ç¼“å­˜çš„æŒ‰åºåˆ†ç»„),å‘å‰æ»‘åŠ¨çª—å£åˆ°ä¸‹ä¸€ä¸ªæœªæ”¶åˆ°æŠ¥æ–‡æ®µçš„åºå·</li></ul></li><li>åˆ†ç»„nåœ¨[æ¥æ”¶åŸº-Nï¼Œæ¥æ”¶åŸº-1\]<ul><li>å‘é€ACK(n)</li></ul></li><li>å…¶ä»–ï¼šå¿½ç•¥</li></ul></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-28.png"></li></ul><p>ä½œä¸š</p><ol type="1"><li>åœ¨è¯¾ä»¶ä¸­ç»™å‡ºäº†SW3çš„å‘é€æ–¹FSMï¼Œè¯·ç”»å‡ºåè®®SW3çš„æ¥æ”¶æ–¹çš„FSMã€‚ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-29.png"></li><li>è€ƒè™‘è®¨è®ºæµæ°´çº¿æ—¶çš„ä¾‹å­ï¼Œç½‘ç»œè·¨è¶Šå›½å®¶çš„ä¾‹å­ã€‚çª—å£é•¿åº¦è®¾ç½®æˆå¤šå°‘æ—¶ï¼Œæ‰èƒ½ä½¿è¯¥ä¿¡é“çš„åˆ©ç”¨ç‡è¶…è¿‡90%?</li><li>è€ƒè™‘ä¸€ç§GBNåè®®ï¼Œå…¶å‘é€æ–¹çª—å£ä¸º3ï¼Œåºå·èŒƒå›´ä¸º1,024ã€‚å‡è®¾åœ¨æ—¶åˆ»tï¼Œ æ¥æ”¶æ–¹æœŸå¾…çš„ä¸‹ä¸€ä¸ªæœ‰åºåˆ†ç»„çš„åºå·æ˜¯kã€‚å‡è®¾ä»‹è´¨ä¸ä¼šå¯¹æŠ¥æ–‡é‡æ–°æ’åºã€‚ å›ç­”ä»¥ä¸‹é—®é¢˜:<ol type="a"><li>åœ¨tæ—¶åˆ»ï¼Œå‘é€æ–¹çª—å£å†…çš„æŠ¥æ–‡åºå·å¯èƒ½æ˜¯å¤šå°‘?ä¸ºä»€ä¹ˆ? b.åœ¨tæ—¶åˆ»ï¼Œåœ¨å½“å‰ä¼ æ’­å›åˆ°å‘é€æ–¹çš„æ‰€æœ‰å¯èƒ½æŠ¥æ–‡ä¸­ï¼ŒACKå­—æ®µä¸­æ‰€æœ‰å¯èƒ½å€¼æ˜¯å¤šå°‘?ä¸ºä»€ä¹ˆ?</li></ol></li></ol><h3><span id="å¤šè·¯è®¿é—®åè®®">å¤šè·¯è®¿é—®åè®®</span></h3><p>å¤šä¸ªå‘é€/æ¥æ”¶ç»“ç‚¹<em>åŒæ—¶ä½¿ç”¨å¹¿æ’­ä¿¡é“</em>ï¼Œå¦‚ä½•åè°ƒå®ƒä»¬<em>å…±äº«</em>ä¸€ä¸ªä¿¡é“ ï¼Ÿ</p><p>ä¿¡é“åªæœ‰ä¸€ä¸ªï¼Œè®¿é—®ç»“ç‚¹å¤šä¸ªï¼Œå¦‚ä½•è®¾è®¡å…±äº«ç®—æ³•ï¼Ÿ</p><ul><li>å½“å¤šä¸ªç»“ç‚¹é¢‘ç¹è®¿é—®ä¿¡é“<ul><li>ååŒç»“ç‚¹æ— ç¢°æ’ï¼Œç»Ÿä¸€æ§åˆ¶æ•ˆç‡é«˜</li></ul></li><li>å½“å¤§é‡ç»“ç‚¹å¶å°”è®¿é—®ä¿¡é“<ul><li>ç»“ç‚¹éšæœºå èµ„æºï¼Œç®€å•ç®—æ³•è§£ç¢°æ’</li></ul></li></ul><p>å¤šè·¯è®¿é—®åè®®</p><ul><li>ä¿¡é“åˆ’åˆ†<ul><li>å°†ä¿¡é“åˆ’åˆ†ä¸ºè¾ƒå°çš„â€œæ®µâ€ (<em>æ—¶éš™ï¼Œé¢‘ç‡ï¼Œç¼–ç </em>) ä¸ºæ¯ä¸ªç»“ç‚¹åˆ†é…ä¸€éƒ¨åˆ†ä¸“ç”¨</li></ul></li><li>è½®æµ<ul><li>ç»“ç‚¹è½®æµï¼Œä¿¡æ¯è¾ƒå¤šçš„è½®æµå‘é€çš„æ—¶é—´è¾ƒé•¿</li></ul></li><li>éšæœºè®¿é—®<ul><li>ä¸åˆ’åˆ†ä¿¡é“ï¼Œå…è®¸ç¢°æ’</li><li>è®¾æ³•ä»â€œç¢°æ’â€æ¢å¤</li><li>å¤§é‡ç»“ç‚¹ä»¥å°æ¦‚ç‡å‘é€åˆ†ç»„<ul><li>ä»¥ä¿¡é“å…¨éƒ¨é€Ÿç‡Rä¼ è¾“</li><li>ç»“ç‚¹é—´æ— ä¼˜å…ˆæƒåè°ƒ</li></ul></li><li>éšæœºè®¿é—®MACåè®®å®šä¹‰äº†:<ul><li>å¦‚ä½•æ£€æµ‹ç¢°æ’</li><li>å¦‚ä½•ä»ç¢°æ’ä¸­æ¢å¤ (ä¾‹å¦‚ï¼Œç»å»¶è¿Ÿåé‡æ–°ä¼ è¾“)</li></ul></li><li>éšæœºè®¿é—®MACåè®®çš„å®ä¾‹:<ul><li>ALOHA</li><li>æ—¶éš™ALOHA</li><li>CSMA, CSMA/CD, CSMA/CA</li></ul></li></ul></li></ul><p><em>ä¿¡é“åˆ’åˆ†MACåè®®: TDMA</em></p><ul><li>â€œå¾ªç¯â€è®¿é—®ä¿¡é“</li><li>æ¯ä¸ªç«™ç‚¹åœ¨æ¯ä¸ªå¾ªç¯ä¸­è·å¾—å›ºå®šé•¿åº¦æ—¶éš™(é•¿åº¦=åˆ†ç»„ä¼ è¾“æ—¶é—´)</li><li>ä¸ä½¿ç”¨çš„æ—¶éš™åˆ™ç©ºé—²</li></ul><p><em>ä¿¡é“åˆ’åˆ†MACåè®®: FDMA</em></p><ul><li>ä¿¡é“é¢‘è°±åˆ’åˆ†ä¸ºé¢‘å¸¦</li><li>æ¯ä¸ªç«™ç‚¹åˆ†é…å›ºå®šçš„é¢‘å¸¦</li><li>é¢‘å¸¦ä¸­æœªä½¿ç”¨çš„ä¼ è¾“æ—¶é—´ç©ºé—²</li></ul><p><em>TDMAå’ŒFDMAç‰¹ç‚¹</em></p><ul><li>æ¶ˆé™¤äº†ç¢°æ’ä¸”å…¬å¹³<ul><li>ç»“ç‚¹åœ¨æ¯ä¸ªå¸§æ—¶é—´å†…å¾—åˆ°äº†ä¸“ç”¨çš„ä¼ è¾“é€Ÿç‡R/N bps</li></ul></li><li>è‹¥ç³»ç»Ÿä»…æœ‰å°‘æ•°å‡ ä¸ªæœ‰å¤§é‡åˆ†ç»„è¦å‘é€çš„ç»“ç‚¹<ul><li>åˆ†é…çš„é¢‘ç‡æˆ–æ—¶éš™è¢«æµªè´¹</li></ul></li><li>é€‚åˆåœºåˆ<ul><li>æ‰€æœ‰ç»“ç‚¹éƒ½æŒç»­æœ‰å¤§é‡æ•°æ®å‘é€</li></ul></li></ul><p>è½®æµåè®®</p><ul><li>ä»¤ç‰Œä¼ é€’ï¼ˆæ— ä¸­å¿ƒï¼‰<ul><li>æ§åˆ¶ä»¤ç‰Œä»ä¸€ä¸ªç»“ç‚¹é¡ºåºåœ°ä¼ é€’åˆ°ä¸‹ä¸€ä¸ª</li></ul></li><li>è½®è¯¢ï¼ˆæœ‰ä¸­å¿ƒï¼‰<ul><li>ä¸»ç»“ç‚¹â€œé‚€è¯·â€ä»ç»“ç‚¹ä¾æ¬¡ä¼ è¾“</li></ul></li><li>é€‚ç”¨äºå¸Œæœ›å…±äº«ä¿¡é“ä½†å´æ— æ³•é¢„æµ‹è®¿é—®ç»“ç‚¹çš„æ•°é‡çš„åœºæ™¯</li></ul><p><strong>ALOHA</strong></p><ul><li>éæ—¶éš™ALOHA: æ— åŒæ­¥è¦æ±‚<ul><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-30.png"></li></ul></li><li>æ—¶éš™ALOHA<ul><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-31.png"></li><li>æ•ˆç‡ï¼šæœ€å¤§1/e=0.37</li><li>ä¼˜ç‚¹<ul><li>æ•ˆç‡é«˜</li></ul></li><li>ç¼ºç‚¹<ul><li>æœ‰ç¢°æ’/ç©ºé—²æ—¶éš™ï¼Œæµªè´¹æ—¶éš™</li><li>æ—¶é’ŸåŒæ­¥å›°éš¾</li></ul></li></ul></li></ul><p><strong>CSMA(è½½æ³¢ä¾¦å¬å¤šè·¯è®¿é—®)</strong></p><ul><li><em>å‘å‰å…ˆå¬</em><ul><li>å¦‚æœä¾¦å¬åˆ°ä¿¡é“å¿™, æ¨è¿Ÿä¼ è¾“</li><li>å¦‚æœä¾¦å¬åˆ°ä¿¡é“ç©ºé—²: ä¼ è¾“æ•´ä¸ªå¸§</li><li><em>ä»å¯å‡ºç°ç¢°æ’</em>: ä¼ æ’­æ—¶å»¶æ„å‘³ç€ä¸¤ä¸ªç»“ç‚¹ä¹Ÿè®¸ä¸èƒ½å¬åˆ°å…¶ä»–ç»“ç‚¹ä¼ è¾“</li></ul></li><li><em>è¾¹å‘è¾¹å¬</em><ul><li>å‘é€æ—¶ä¾¦å¬åˆ°ä¿¡é“å¿™, ç«‹å³åœæ­¢;</li><li>è½¬å‘å¼ºåŒ–å†²çªä¿¡å·</li></ul></li></ul><p><strong>CSMA/CD (ç¢°æ’æ£€æµ‹)</strong></p><ul><li>åœ¨çŸ­æ—¶é—´å†…æ£€æµ‹åˆ°ç¢°æ’</li><li>ç¢°æ’çš„ä¼ è¾“å°½å¿«ç»“æŸï¼Œä»¥å‡å°‘ä¿¡é“æµªè´¹</li><li>ç¢°æ’æ£€æµ‹<ul><li>åœ¨æœ‰çº¿çš„LANä¸­å®¹æ˜“: æµ‹é‡ä¿¡å·å¼ºåº¦ï¼Œæ¯”è¾ƒä¼ è¾“çš„å’Œæ¥æ”¶çš„ä¿¡å·</li><li>åœ¨æ— çº¿LANä¸­å›°éš¾:ç¢°æ’å¯èƒ½å¬ä¸åˆ°</li></ul></li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-32.png"></li></ul><p>åè®®æ¯”è¾ƒ</p><ul><li>ä¿¡é“åˆ’åˆ†MACåè®®<ul><li>åœ¨é«˜è´Ÿè½½æ—¶é«˜æ•ˆã€å…¬å¹³åœ°å…±äº«ä¿¡é“</li><li>ä½è´Ÿè½½æ—¶ä½æ•ˆ:ä¿¡é“è®¿é—®ä¸­å»¶æ—¶ï¼Œå½“1ä¸ªæ´»è·ƒç»“ç‚¹æ—¶ï¼Œç”šè‡³ä»…æœ‰åˆ†é…äº† 1/N å¸¦å®½!</li></ul></li><li>éšæœºè®¿é—®MACåè®®<ul><li>ä½è´Ÿè½½æ˜¯æœ‰æ•ˆ:å•ä¸ªç»“ç‚¹èƒ½å¤Ÿå…¨é¢åˆ©ç”¨ä¿¡é“</li><li>é«˜è´Ÿè½½:ç¢°æ’å¼€é”€å¤§</li></ul></li><li>è½®æµåè®®<ul><li>å…¼æœ‰ä¸¤æ–¹é¢çš„ä¼˜ç‚¹!</li></ul></li></ul><p>ä½œä¸š</p><ol type="1"><li>åœ¨åˆ†æå¤šè·¯è®¿é—®åè®®æ—¶è¿›è¡Œäº†å“ªäº›å‡è®¾?ç°æœ‰çš„å‡ åç§å¤šè·¯è®¿é—®åè®®æ˜¯å¦‚ä½•åˆ†ç±»çš„?è¿™ç§åˆ†ç±»çš„æ–¹æ³•ä¸ç»“ç‚¹æ•° é‡å’Œç»“ç‚¹è®¿é—®ä¿¡é“çš„é¢‘ç‡æ˜¯å¦æœ‰å…³?</li><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-33.png"></li></ol><h3><span id="ä»¥å¤ªç½‘">ä»¥å¤ªç½‘</span></h3><p><em>ä»¥å¤ªç½‘(Ethernet)å¸§ç»“æ„</em></p><ul><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-34.png"></li><li>å‰å¯¼ç <ul><li>æ¨¡å¼ä¸º10101010 çš„7ä¸ªå­—èŠ‚ï¼Œåè·Ÿæ¨¡å¼ä¸º 10101011 çš„ä¸€ä¸ªå­—èŠ‚</li><li>ç”¨äºåŒæ­¥æ¥æ”¶æ–¹ï¼Œå‘é€æ–¹æ—¶é’Ÿé€Ÿç‡</li></ul></li><li>åœ°å€: 6å­—èŠ‚<ul><li>å¦‚æœé€‚é…å™¨æ¥æ”¶å…·æœ‰åŒ¹é…çš„<em>ç›®çš„åœ°å€</em>æˆ–<em>å¹¿æ’­åœ°å€</em>(å¦‚ARPåˆ†ç»„)çš„å¸§, å®ƒå°†å¸§ä¸­çš„æ•°æ®æäº¤ç»™ç½‘ç»œå±‚åè®®</li><li>å¦åˆ™, é€‚é…å™¨ä¸¢å¼ƒå¸§</li></ul></li><li>ç±»å‹: æŒ‡ç¤ºè¾ƒé«˜å±‚åè®® (å¤§å¤šæ•°ä¸ºIPä½†ä¹Ÿå¯ä»¥æ”¯æŒå…¶ä»–ç±»å‹å¦‚ Novell IPXå’ŒAppleTalk)</li><li>CRC: åœ¨æ¥æ”¶æ–¹æ ¸å¯¹;å¦‚æœæ£€æµ‹åˆ°å·®é”™ï¼Œè¯¥å¸§è¢«ä¸¢å¼ƒ</li></ul><p><em>MACåœ°å€</em></p><ul><li>LANåœ°å€=ç‰©ç†åœ°å€=MACåœ°å€ï¼Œé€šå¸¸ç”¨6å­—èŠ‚16è¿›åˆ¶è¡¨ç¤º<ul><li>å¦‚1a-03-65-3F-2e-46</li></ul></li><li>å…±æœ‰2çš„48æ¬¡æ–¹ä¸ªLANåœ°å€</li><li>IEEEåœ°å€åˆ†é…æ–¹å¼ï¼šå›ºå®šå‰24 bitï¼Œå…¬å¸ç”Ÿæˆå24 bitï¼Œæ¯ä¸ªé€‚é…å™¨å…·æœ‰å”¯ä¸€MACåœ°å€</li><li>é€‚é…å™¨çš„MACåœ°å€å…·æœ‰æ‰å¹³(æ²¡æœ‰å±‚æ¬¡)ç»“æ„ï¼Œä¸”ä¿æŒä¸å˜</li></ul><p><em>ä»¥å¤ªç½‘åè®®(CSMA/CD)</em></p><ul><li><strong>æ— è¿æ¥</strong>: åœ¨å‘é€å’Œæ¥æ”¶é€‚é…å™¨ä¹‹é—´æ²¡æœ‰æ¡æ‰‹</li><li><strong>ä¸å¯é </strong>: æ¥æ”¶é€‚é…å™¨ä¸å‘å‘é€é€‚é…å™¨å‘é€åº”ç­”æˆ–å¦å®šåº”ç­”</li><li><strong>å‘å‰å…ˆå¬ï¼›è¾¹å‘è¾¹å¬ï¼›å¼ºåŒ–ç¢°æ’ï¼›æŒ‡æ•°åé€€</strong></li><li>CSMA/CD<ol type="1"><li>é€‚é…å™¨ä»ç½‘ç»œå±‚æ¥æ”¶æ•°æ®æŠ¥å¹¶ç”Ÿæˆå¸§</li><li>å¦‚æœé€‚é…å™¨æ„ŸçŸ¥ä¿¡é“ç©ºé—²ï¼Œå®ƒå¼€å§‹ä¼ è¾“å¸§ï¼›å¦‚æœå®ƒæ„ŸçŸ¥ä¿¡é“å¿™ï¼Œç­‰å¾…ä¿¡é“ç©ºé—²å†ä¼ è¾“</li><li>å½“é€‚é…å™¨ä¼ è¾“æ•´ä¸ªå¸§æ—¶ï¼Œä¸€ç›´åœ¨æ£€æµ‹</li><li>å¦‚æœæ£€æµ‹ä¼ è¾“è¿‡ç¨‹ä¸­çš„å…¶ä»–ä¼ è¾“, ä¸­æ­¢å¹¶å‘é€å¼ºåŒ–å†²çªä¿¡å·</li><li>ä¸­æ­¢å, é€‚é…å™¨è¿›å…¥æŒ‡æ•°å›é€€: åœ¨ç¬¬mæ¬¡ç¢°æ’å, é€‚é…å™¨éšæœºåœ°ä»[0,1,2,â€¦, 2^m-1]é€‰æ‹©ä¸€ä¸ªKå€¼ã€‚é€‚é…å™¨ç­‰å¾…KÎ‡512 æ¯”ç‰¹æ—¶é—´å¹¶è¿”å›åˆ°ç¬¬2æ­¥</li></ol></li></ul><p>ç‰¹ç‚¹</p><ul><li>å¼ºåŒ–å†²çªä¿¡å·<ul><li>ç¡®ä¿æ‰€æœ‰çš„å…¶ä»–ä¼ è¾“æ–¹éƒ½çŸ¥é“ç¢°æ’</li><li>48 bité•¿</li></ul></li><li>æ¯”ç‰¹æ—¶é—´<ul><li>å¯¹10 Mbps ä»¥å¤ªç½‘ä¼ æ¯æ¯”ç‰¹éœ€ 0.1 Î¼s</li><li>å¯¹K=1023, ç­‰å¾…æ—¶é—´çº¦ä¸º50 msec</li></ul></li><li>æŒ‡æ•°å›é€€ç®—æ³•<ul><li>ç›®æ ‡ï¼šä¼°è®¡å½“å‰è´Ÿè½½ï¼Œé€‚åº”é‡ä¼ å°è¯•<ul><li>é‡è´Ÿè½½æ—¶ï¼Œéšæœºç­‰å¾…æ—¶é—´æ›´é•¿</li></ul></li><li>é¦–æ¬¡ç¢°æ’å: ä»[0,1] ä¸­ é€‰æ‹©Kï¼›æ—¶å»¶æ˜¯K*512 bit ä¼ è¾“æ—¶é—´</li><li>ç¬¬äºŒæ¬¡ç¢°æ’å: ä»[0,1,2,3]é€‰æ‹© K â€¦â€¦</li><li>10æ¬¡ç¢°æ’å, ä»[0,1,2,3,4,â€¦, 1023] é€‰æ‹©K</li></ul></li><li>æ•ˆç‡ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-35.png"></li></ul><h3><span id="é“¾è·¯å±‚äº¤æ¢æœº">é“¾è·¯å±‚äº¤æ¢æœº</span></h3><p>é›†çº¿å™¨</p><ul><li>å°†æ¥è‡ªæŸé“¾è·¯çš„æ¯”ç‰¹æ”¾å¤§åä»å…¶ä»–æ‰€æœ‰é“¾è·¯ä¼ å‡º</li><li>å¯èƒ½ä¸æ¥è‡ªå…¶ä»–ç»“ç‚¹çš„æ¯”ç‰¹ç¢°æ’</li><li>æ— å¸§ç¼“å­˜</li><li>é›†çº¿å™¨ç›¸å½“äºä¸€æ ¹å¯¼çº¿ï¼Œç¢°æ’æ£€æµ‹ç”±é€‚é…å™¨å®Œæˆ</li></ul><p><strong>äº¤æ¢æœº</strong></p><ul><li>å­˜å‚¨å¹¶è½¬å‘ä»¥å¤ªç½‘å¸§</li><li>å½“å¸§åœ¨ç½‘æ®µä¸Šè½¬å‘æ—¶ï¼Œæ£€æŸ¥å¸§é¦–éƒ¨å¹¶åŸºäºMACç›®çš„åœ°å€ï¼Œé€‰æ‹©æ€§åœ°å‘ä¸€ä¸ªæˆ–å¤šä¸ªå‡ºé“¾è·¯è½¬å‘å¸§</li><li>å½“å¸§åœ¨ç½‘æ®µä¸Šè½¬å‘æ—¶ï¼Œä½¿ç”¨CSMA/CD è®¿é—®ç½‘æ®µ</li><li>å…¨åŒå·¥ã€æ— ç¢°æ’</li><li>é€æ˜æ€§<ul><li>ä¸»æœºä¸çŸ¥é“äº¤æ¢æœºå­˜åœ¨</li></ul></li><li>å³æ’å³ç”¨, è‡ªå­¦ä¹ <ul><li>äº¤æ¢æœºä¸å¿…é…ç½®</li></ul></li><li>æµé‡éš”ç¦»<ul><li>äº¤æ¢æœºå°†å­ç½‘åˆ†å‰²æˆLANæ®µ</li><li>äº¤æ¢æœºè¿‡æ»¤åˆ†ç»„:<ul><li>ç›¸åŒLANæ®µçš„å¸§é€šå¸¸ä¸åœ¨å…¶ä»–LANæ®µä¸Šè½¬å‘</li><li>æ®µæˆä¸ºåˆ†ç¦»çš„ç¢°æ’åŸŸ</li></ul></li></ul></li></ul><p><strong>äº¤æ¢æœºè¡¨</strong></p><ul><li>å½“æ”¶åˆ°å¸§æ—¶ï¼Œäº¤æ¢æœºâ€œå­¦ä¹ â€åˆ°å‘é€æ–¹ä½ç½®ï¼šå…¥é“¾è·¯</li><li>åœ¨äº¤æ¢æœºè¡¨ä¸­è®°å½•ä¸‹å‘é€æ–¹/ä½ç½®å¯¹</li><li>è¡¨ç»“æ„ï¼š(MACåœ°å€ï¼Œæ¥å£ï¼ŒTTL)</li></ul><p>å¸§è¿‡æ»¤/è½¬å‘ç®—æ³•</p><ol type="1"><li>è®°å½•ä¸å‘é€ä¸»æœºå…³è”çš„é“¾è·¯</li><li>ä½¿ç”¨MACç›®çš„åœ°å€ç´¢å¼•äº¤æ¢æœºè¡¨ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if æ‰¾åˆ°ç›®çš„åœ°é¡¹</span><br><span class="line">then&#123;</span><br><span class="line"> if ç›®çš„åœ°ä½äºå¸§åˆ°è¾¾çš„æ®µ</span><br><span class="line">then ä¸¢å¼ƒå¸§</span><br><span class="line">else åœ¨æŒ‡ç¤ºçš„æ¥å£è½¬å‘è¯¥å¸§</span><br><span class="line">&#125;</span><br><span class="line">else æ´ªæ³›</span><br></pre></td></tr></table></figure></li></ol><p>ä½œä¸š</p><ol type="1"><li>è€ƒè™‘æŸè®©æ‰€æœ‰ç»“ç‚¹ç›´æ¥ä¸ä¸€ä¸ªé›†çº¿å™¨ç›¸è¿çš„100 Mbpsçš„100BASE-Tä»¥å¤ªç½‘ã€‚ä¸ºäº†è·å¾—0.5çš„æ•ˆç‡ï¼Œç»“ç‚¹å’Œé›†çº¿å™¨ä¹‹é—´çš„æœ€å¤§è·ç¦»æ˜¯å¤šå°‘ï¼Ÿå‡è®¾å¸§é•¿ä¸º64 byteå¹¶ä¸”ä¸­é—´æ²¡æœ‰è½¬å‘å™¨ã€‚è¿™ä¸ªæœ€å¤§è·ç¦»ä¹Ÿç¡®ä¿æ­£åœ¨ä¼ è¾“çš„ç»“ç‚¹Aèƒ½å¤Ÿæ£€æµ‹å‡ºå½“Aåœ¨ä¼ è¾“æ—¶æ˜¯å¦æœ‰å…¶ä»–ä»»ä½•ç»“ç‚¹åœ¨ä¼ è¾“å—ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿä½ å¾—åˆ°çš„æœ€å¤§è·ç¦»å’Œå®é™…çš„100 Mbpsæ ‡å‡†æ¯”è¾ƒå°†æœ‰ä»€ä¹ˆç»“è®ºï¼Ÿ <em>åªè¦T0&gt;2t(tao)å°±èƒ½æ£€æµ‹å‡ºæœ‰å…¶ä»–èŠ‚ç‚¹ä¼ è¾“</em>ï¼Ÿ</li><li>è€ƒè™‘åœ¨å›¾3-26ç¯å¢ƒä¸­çš„äº¤æ¢æœºçš„æƒ…å†µã€‚å‡å®š(i)Aå‘Då‘é€ä¸€ä¸ªå¸§ï¼Œ(ii)Då‘Aå›ç­”ä¸€ä¸ªå¸§ï¼Œ(iii)Cå‘Då‘é€ä¸€ä¸ªå¸§ï¼Œ(iv)Då‘Cå›ç­”ä¸€ä¸ªå¸§ã€‚è¯¥äº¤æ¢æœºè¡¨åˆå§‹ä¸ºç©ºã€‚æ˜¾ç¤ºåœ¨è¿™äº›æ—¶é—´çš„å‰åè¯¥äº¤æ¢æœºè¡¨çš„çŠ¶æ€ã€‚å¯¹äºè¿™äº›äº‹ä»¶çš„æ¯ä¸ªï¼Œç¡®å®šä¼ è¾“çš„å¸§åœ¨ä¸Šé¢çš„è½¬å‘çš„é“¾è·¯ï¼Œå¹¶ç®€è¦åœ°è®ºè¯ä½ çš„ç­”æ¡ˆã€‚ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-36.png"></li></ol><h2><span id="ç½‘ç»œäº’è”">ç½‘ç»œäº’è”</span></h2><h3><span id="ç½‘ç»œå±‚æ¦‚è¿°">ç½‘ç»œå±‚æ¦‚è¿°</span></h3><p>å¼‚æ„ç½‘ç»œ</p><ul><li>åœ¨ä½“ç³»ç»“æ„å’Œé€šä¿¡åè®®æ–¹é¢å…·æœ‰å·®å¼‚çš„è®¡ç®—æœºç½‘ç»œ</li><li>åœ¨å¯»å€æ–¹æ³•ã€åˆ†ç»„é•¿åº¦ã€è·¯ç”±é€‰æ‹©ã€å·®é”™æ¢å¤ç­‰æ–¹é¢ä¸åŒï¼Œæ— æ³•ç›´æ¥é€šä¿¡</li></ul><p>äº’è”äº’é€šéœ€é‡‡ç”¨<em>ç½‘ç»œå±‚ä¸­ç»§ç³»ç»Ÿ</em>å¯¹ä¸åŒåè®®çš„è¯­æ³•ã€è¯­ä¹‰å’Œæ—¶åºè¿›è¡Œè½¬æ¢</p><ul><li>IPå…·æœ‰ç»Ÿä¸€çš„åè®®å’Œåœ°å€ï¼Œä¸ºå…¨å±€æ€§å¯»å€å’Œè·¯ç”±é€‰æ‹©è¿›è€Œå®ç°ç½‘ç»œäº’è”äº’é€šæä¾›äº†å¯èƒ½</li><li>IPç½‘ç»œæ˜¯è™šæ‹Ÿç½‘ç»œï¼Œæä¾›å…¨å±€æ€§è·¯ç”±é€‰æ‹©å’Œè½¬å‘åŠŸèƒ½ï¼Œä¸‹å±‚ç½‘ç»œæä¾›äº†åˆ†ç»„ä¼ é€äº¤ä»˜åŠŸèƒ½</li><li>è·¯ç”±å™¨æ˜¯è¿æ¥å¼‚æ„ç½‘ç»œçš„å…³é”®è®¾å¤‡ï¼Œè‡³å°‘æœ‰ä¸¤ä¸ªæ¥å£ï¼Œæœ€é«˜å±‚æ˜¯ç½‘ç»œå±‚</li><li>ç«¯ç³»ç»Ÿæœ‰åè®®æ ˆæ‰€æœ‰å±‚æ¬¡ï¼Œæ²¿é€”ç½‘ç»œå±‚åè®®çš„å…±åŒä½œç”¨ä¸‹ï¼Œå½¢æˆäº†ä¸»æœºåˆ°ä¸»æœºçš„ç«¯åˆ°ç«¯è·¯å¾„</li></ul><p>ç½‘ç»œå±‚æœåŠ¡</p><ul><li>åº•å±‚ç›´æ¥è¿æ¥çš„ç½‘ç»œå¯ä¸º<em>å¼‚æ„</em>ï¼Œç½‘ç»œå±‚æä¾›äº’è”äº’é€š</li><li>å¤šæ¡ä¼ é€åˆ†ç»„ï¼Œéœ€è¦ç½‘é—´è·¯ç”±å™¨è¿›è¡Œ<em>åˆ†ç»„è½¬å‘</em>å’Œ<em>è·¯ç”±é€‰æ‹©</em></li><li>å…³é”®åŠŸèƒ½<ul><li>è½¬å‘</li><li>è·¯ç”±é€‰æ‹©</li><li><em>è·¯ç”±</em>ï¼šåˆ†ç»„ä»æºåˆ°ç›®çš„åœ°æ‰€ç»è¿‡çš„ç«¯åˆ°ç«¯è·¯å¾„</li></ul></li></ul><p>åˆ†ç»„äº¤ä»˜</p><ul><li>ç›´æ¥äº¤ä»˜<ul><li>åœ¨ä¸€ä¸ª<em>ç›´æ¥è¿æ¥çš„ç½‘ç»œ</em>ä¸Šæ—¶ï¼Œåˆ†ç»„ä»ä¸€å°ä¸»æœºä¸Šç›´æ¥ä¼ é€åˆ°å¦ä¸€å°ä¸»æœºçš„è¿‡ç¨‹</li></ul></li><li><em>é—´æ¥äº¤ä»˜</em><ul><li><em>ä¸</em>åœ¨ä¸€ä¸ªç›´æ¥è¿æ¥çš„ç½‘ç»œä¸Šæ—¶ï¼Œæºä¸»æœºå¿…é¡»å…ˆæŠŠåˆ†ç»„å‘ç»™ä¸€ä¸ªè·¯ç”±å™¨</li><li>å¯èƒ½ä½¿ç”¨ä¸åŒçš„ç½‘ç»œåœ°å€</li></ul></li></ul><h3><span id="ç½‘ç»œæœåŠ¡æ¨¡å‹">ç½‘ç»œæœåŠ¡æ¨¡å‹</span></h3><p>ç½‘ç»œæœåŠ¡æ¨¡å‹ä¸é‡‡å–çš„é“¾æ¥æ–¹å¼æœ‰å…³</p><ul><li>é¢å‘è¿æ¥æœåŠ¡<ul><li>è™šç”µè·¯ (Virtual-Circuit, VC) ç½‘ç»œ<ul><li>è¿æ¥</li></ul></li></ul></li><li>æ— è¿æ¥æœåŠ¡<ul><li>æ•°æ®æŠ¥ (Datagram) ç½‘ç»œ<ul><li>åœ¨ç½‘ç»œå±‚æ— å‘¼å«å»ºç«‹</li><li>è·¯ç”±å™¨:æ²¡æœ‰ç«¯åˆ°ç«¯è¿æ¥çš„çŠ¶æ€<ul><li>æ— ç½‘ç»œçº§â€œè¿æ¥â€çš„æ¦‚å¿µ</li></ul></li><li>åˆ†ç»„ä½¿ç”¨ç›®çš„ä¸»æœºåœ°å€è½¬å‘<ul><li>åœ¨ç›¸åŒæºå’Œç›®çš„å¯¹å¯èƒ½é‡‡ç”¨ä¸åŒçš„è·¯å¾„ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-37.png"></li></ul></li></ul></li></ul></li></ul><p>å› ç‰¹ç½‘IPæœåŠ¡æ¨¡å‹ï¼ˆæ•°æ®æŠ¥ç½‘ç»œï¼‰çš„ä¼˜åŠ¿</p><ul><li>ç®€åŒ–äº†ä¸­ç»§è®¾å¤‡è·¯ç”±å™¨çš„è®¾è®¡</li><li>å®¹æ˜“äº’è”ä½¿ç”¨ä¸åŒçš„é“¾è·¯å±‚æŠ€æœ¯</li><li>ç½‘ç»œæ•…éšœå®¹æ˜“ä¿®å¤</li><li>å°½åŠ›è€Œä¸º<ul><li>ä¸å¯é </li><li>æ— è¿æ¥</li><li>æœåŠ¡æ˜¯å°½åŠ›è€Œä¸ºçš„<ul><li>ç¼–å€æ–¹æ¡ˆ</li><li>æä¾›æ ‡è¯†å› ç‰¹ç½‘ä¸­æ‰€æœ‰ä¸»æœºçš„æ–¹æ³•</li></ul></li></ul></li><li><em>ä¸å¯é çš„ã€å°½åŠ›è€Œä¸ºå’Œæ— è¿æ¥åˆ†ç»„äº¤ä»˜ç³»ç»Ÿ</em> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-38.png"></li></ul><p>ä½œä¸š</p><ol type="1"><li>æ ¹æ®å›¾4-1ï¼Œä¸ºä»€ä¹ˆè¯´IPç½‘ç»œæ˜¯ä¸€ä¸ªè™šæ‹Ÿç½‘ç»œ? å¦‚æœIPç½‘ç»œä¸å®é™…ä¼ è¾“åˆ†ç»„ï¼Œé‚£ä¹ˆå®ƒçš„ä½œç”¨æ˜¯ä»€ä¹ˆ? ç­”ï¼š<em>ç›´æ¥è¿æ¥çš„ç½‘ç»œæ˜¯èƒ½å¤Ÿå®é™…ä¼ é€åˆ†ç»„çš„é€šä¿¡ç½‘</em>ï¼Œ<em>ä½†</em>å®ƒä»¬é€šå¸¸è¦†ç›–åŒºåŸŸè¾ƒå°ã€<em>åè®®å¼‚æ„</em>ä¸”æ²¡æœ‰ç»Ÿä¸€çš„åœ°å€ï¼Œæ— æ³•äº’è”äº’é€šã€‚è®¾è®¡äº†å…·æœ‰ç»Ÿä¸€ IP åœ°å€å’Œè§„æ ¼çš„ IP åè®®ï¼Œå…¶ä»–<em>å¼‚æ„ç½‘ç»œé€šè¿‡ IP ç½‘ç»œè½¬æ¢äº†æ ¼å¼è¿›è¡Œä¸­ç»§</em>ï¼Œä½¿å¾—å®ƒä»¬èƒ½å¤Ÿç½‘ç»œäº’è”äº’é€šã€‚å› æ­¤ï¼Œ<em>IP ç½‘ç»œ</em>ç›¸å½“äºåœ¨å¼‚æ„çš„ç›´æ¥è¿æ¥çš„ç½‘ç»œä¹‹ä¸Šæ„å»ºçš„ä¸€ä¸ªè™šæ‹Ÿç½‘ç»œï¼Œå®ƒ<em>ä»…ä»…æä¾›åœ¨å„ä¸ªå¼‚æ„å­ç½‘ä¹‹é—´</em> <strong>å…¨å±€æ€§è·¯ç”±é€‰æ‹©å’Œè½¬å‘åŠŸèƒ½</strong>ï¼Œè€Œä¸‹é¢ç½‘ç»œåˆ™æä¾›äº†åˆ†ç»„å®é™…çš„é€šä¿¡åŠŸèƒ½ã€‚</li><li>æ ¹æ®å›¾4-2ï¼Œè¯•å¡«å†™å‡ºè·¯ç”±å™¨R3çš„è½¬å‘è¡¨å†…å®¹</li><li>åˆ†ç»„çš„ç›´æ¥äº¤ä»˜å’Œé—´æ¥äº¤ä»˜æœ‰ä»€ä¹ˆåŒºåˆ«ä¸è”ç³»?åœ¨<br>äº¤ä»˜è¿‡ç¨‹ä¸­ï¼Œå®ƒä»¬åˆ†åˆ«è¦ç”¨åˆ°å“ªäº›å±‚æ¬¡çš„åœ°å€?</li></ol><h3><span id="ç½‘é™…åè®®ip">ç½‘é™…åè®®ï¼ˆIPï¼‰</span></h3><p><em>IPæ•°æ®æŠ¥</em></p><ul><li><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-39.png"></li><li>åˆ†ç‰‡å’Œé‡æ–°ç»„è£…<ul><li>MTU-æœ€å¤§ä¼ è¾“é•¿åº¦</li><li>å¤§IP æ•°æ®æŠ¥è¢«åˆ† å‰²(â€œåˆ†æ®µâ€)<ul><li>ä¸€ä¸ªé•¿æ•°æ®æŠ¥åˆ†æˆå‡ ä¸ªçŸ­æ•°æ®æŠ¥</li><li>ä»…åœ¨æœ€åç›®çš„åœ°â€œé‡æ–°è£…é…â€</li><li>IPé¦–éƒ¨æ¯”ç‰¹ç”¨äºæ ‡è¯†ã€æ’åºç›¸å…³æ®µ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-40.png"></li></ul></li></ul></li></ul><p><em>IPç¼–å€</em></p><ul><li>ç‚¹åˆ†åè¿›åˆ¶è®°æ³•</li><li>IPåœ°å€: å¯¹ä¸»æœºã€è·¯ç”±å™¨ æ¥å£çš„32 bit æ ‡è¯†ç¬¦</li><li>æ¥å£: åœ¨ä¸»æœº/è·¯ç”±å™¨å’Œç‰©ç†é“¾è·¯ä¹‹é—´çš„è¿æ¥<ul><li>è·¯ç”±å™¨é€šå¸¸å…·æœ‰å¤šä¸ªæ¥å£</li><li>ä¸»æœºå¯èƒ½å…·æœ‰å¤šä¸ªæ¥å£</li><li>IPç¼–å€ä¸æ¯ä¸ªæ¥å£ç›¸è”ç³»</li></ul></li><li><em>å­ç½‘æ©ç </em><ul><li>æ—©æœŸè¡¨ç¤ºçš„IPåœ°å€ = {&lt;ç½‘ç»œå·&gt;, &lt;å­ç½‘å·&gt;, &lt;ä¸»æœºå·&gt;\}</li><li>ä¾‹ï¼š192.168.143.3/27ï¼Œ å³å­ç½‘æ©ç å…±æœ‰27ä¸ªè¿ç»­çš„1</li></ul></li><li>æ— ç±»åˆ«åŸŸé—´è·¯ç”±é€‰æ‹©ï¼ˆCIDRï¼‰<ul><li>å¯¹äºè§£å†³å› ç‰¹ç½‘è·¯ç”±å™¨è½¬å‘è¡¨ç©ºé—´æ€¥å‰§è†¨èƒ€çš„é—®é¢˜è‡³å…³é‡è¦</li><li>IPåœ°å€ = {&lt;ç½‘ç»œåœ°å€&gt;/&lt;å‰ç¼€&gt;\} <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-41.png"></li><li><strong>æœ€é•¿å‰ç¼€åŒ¹é…åŸåˆ™</strong> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-42.png"><ul><li>200.19.25.170å‰20 bitä¸è¡¨ä¸­çš„ç¬¬ä¸€é¡¹ åŒ¹é…ï¼Œè€Œè¯¥åœ°å€çš„å‰<em>23 bit</em>ä¸è¡¨ä¸­çš„ç¬¬äºŒé¡¹åŒ¹é…:åº”é€‰æ‹©ä¸è¡¨ä¸­çš„ç¬¬äºŒé¡¹ç›¸åŒ¹é…</li></ul></li></ul></li><li>ç‰¹æ®Šçš„IPåœ°å€ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-43.png"></li><li>ç½‘ç»œæ€æ ·å¾—åˆ°IPåœ°å€çš„å­ç½‘éƒ¨åˆ†?<ul><li>ä»å®ƒçš„ISPçš„åœ°å€ç©ºé—´å¾—åˆ°åˆ†é…çš„éƒ¨åˆ†</li></ul></li><li>ISPæ€æ ·å¾—åˆ°åœ°å€å—?<ul><li>ä»<em>å› ç‰¹ç½‘åå­—ä¸å·ç åˆ†é…å›¢ä½“( Internet Corporation for Assigned Names and Numbers,ICANN )Â </em></li></ul></li></ul><p><strong>DHCP: Dynamic Host Configuration Protocal</strong></p><ul><li>ç›®çš„ï¼šä½¿ä¸»æœºåœ¨å®ƒè¿›å…¥ç½‘ç»œæ—¶ä»ç½‘ç»œæœåŠ¡å™¨åŠ¨æ€è·å–å…¶IPåœ°å€<ul><li>èƒ½å¤Ÿæ›´æ–°IPå’Œç§Ÿç”¨æœŸ</li><li>å…è®¸åœ°å€é‡å¤</li><li>æ”¯æŒç§»åŠ¨ç”¨æˆ·</li></ul></li><li>æ¦‚è¿°<ul><li>ä¸»æœºå¹¿æ’­ <em>DHCP discover</em> æŠ¥æ–‡</li><li>DHCPæœåŠ¡å™¨ç”¨ <em>DHCP offer</em> æŠ¥æ–‡å“åº”</li><li>ä¸»æœºè¯·æ±‚IPåœ°å€ <em>DHCP request</em> æŠ¥æ–‡</li><li>DHCPæœåŠ¡å™¨å‘é€åœ°å€ <em>DHCP ack</em> æŠ¥æ–‡ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-44.png"></li></ul></li><li>ä¸ä»…ä»…æä¾›IPåœ°å€<ul><li>IPåœ°å€</li><li>å®¢æˆ·ç¬¬ä¸€è·³è·¯ç”±å™¨åœ°å€</li><li>DNSæœåŠ¡å™¨çš„åå­—å’ŒIPåœ°å€</li><li>ç½‘ç»œæ©ç </li></ul></li><li>è¯¦ç»†è¿‡ç¨‹<ul><li>DHCPè¯·æ±‚ä¾æ¬¡å°è£…åœ¨UDP ä¸­ã€IPä¸­ã€802.3 Ethernetä¸­</li><li>ä»¥å¤ªç½‘å¸§åœ¨LANä¸­å¹¿æ’­ (dest: FFFFFFFFFFFF), è¢«è¿è¡ŒDHCPæœåŠ¡å™¨çš„ä¸»æœºåè·¯ç”±å™¨æ”¶åˆ°</li><li>Ethernetä¾æ¬¡è§£å°è£…åˆ°IPã€ UDPã€DHCP</li></ul></li></ul><p><em>NAT ç½‘ç»œåœ°å€è½¬æ¢</em></p><ul><li>å¤–éƒ¨ä»…çœ‹åˆ°æœ¬åœ°ç½‘ç»œä½¿ç”¨çš„ä¸€ä¸ªIPåœ°å€<ul><li>å¯¹ISPæ— éœ€åˆ†é…åœ°å€èŒƒå›´:å¯¹æ‰€æœ‰è®¾å¤‡åªç”¨ä¸€ä¸ªIPåœ°å€</li><li>èƒ½å¤Ÿæ”¹å˜æœ¬åœ°ç½‘ç»œä¸­çš„è®¾å¤‡åœ°å€ï¼Œè€Œä¸å¿…é€šçŸ¥å¤–éƒ¨</li><li>æœ¬åœ°ç½‘ç»œä¸­çš„è®¾å¤‡ä¸æ˜¾å¼åœ°å¯å¯»å€ã€ç”±å¤–éƒ¨æ‰€è§(å¢å¼ºå®‰å…¨æ€§) <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-45.png"></li></ul></li><li>äº‰è®®<ul><li>è·¯ç”±å™¨çš„å¤„ç†ä¸Šå‡ä¸ºç¬¬ä¸‰å±‚</li><li>è¿åäº†ç«¯åˆ°ç«¯åŸåˆ™<ul><li>åº”ç”¨è®¾è®¡è€…å¿…é¡»è¦è€ƒè™‘ NATå¯èƒ½æ€§ï¼Œå¦‚ P2Påº”ç”¨ç¨‹åº</li></ul></li><li>åœ°å€çŸ­ç¼ºåº”å½“ç”±IPv6æ¥è§£å†³</li></ul></li></ul><p><strong>ARP: Address Resolution Protocol</strong></p><ul><li>é—®é¢˜ï¼šè™šæ‹Ÿç½‘ç»œIPåœ°å€ä¸ç›´æ¥ç›¸è¿çš„ç½‘ç»œMACåœ° å€å¦‚ä½•æ‰“äº¤é“?</li><li><em>é“¾è·¯å±‚åè®®</em></li><li>LANä¸Šæ¯ä¸ªIPç»“ç‚¹(ä¸»æœºã€ è·¯ç”±å™¨)éƒ½æœ‰ARPè¡¨</li><li>ARPè¡¨: ç»“ç‚¹çš„IP/MAC åœ°å€æ˜ å°„<ul><li><em>&lt;IPåœ°å€; MACåœ°å€; TTL&gt;</em></li><li>TTL (å¯¿å‘½): åœ°å€æ˜ å°„è¢« B å¿˜è®°çš„æ—¶é—´(å¸¸ä¸º20åˆ†é’Ÿ)</li></ul></li><li>èŠ‚ç‚¹åœ¨ç›¸åŒLAN<ul><li>Aå‘Bå‘æ•°æ®æŠ¥, ä¸”Bçš„MACåœ°å€ä¸åœ¨Açš„ARPè¡¨ä¸­</li><li>Aå¹¿æ’­ARP è¯·æ±‚åˆ†ç»„, åŒ…å«Bçš„IPåœ°å€</li><li>ç›®çš„åœ°MACåœ°å€ = FF-FF-FF-FF-FF-FF</li><li>LANä¸Šæ‰€æœ‰æœºå™¨æ¥æ”¶ ARPè¯·æ±‚</li><li>Bæ¥æ”¶ARPåˆ†ç»„ï¼Œç”¨è‡ªå·±MACåœ°å€å›ç­”A</li><li>Aåœ¨å…¶ARPè¡¨ä¸­ç¼“å­˜(ä¿å­˜) IPä¸MACçš„åœ°å€å¯¹ï¼Œç›´åˆ°ä¿¡æ¯è¶…æ—¶<ul><li>è½¯çŠ¶æ€:é™¤éä¸æ–­æ›´æ–°ä¿¡æ¯ï¼Œå¦åˆ™è¶…æ—¶</li><li>ARPæ˜¯â€œ<em>å³æ’å³ç”¨</em>â€çš„ ç»“ç‚¹è‡ªè¡Œåˆ›å»ºå…¶ARPè¡¨ï¼Œæ— éœ€ç½‘ç»œç®¡ç†å‘˜å¹²é¢„ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-46.png"></li></ul></li></ul></li><li>èŠ‚ç‚¹åœ¨ä¸åŒLAN<ul><li>Aæ¯”è¾ƒEçš„ç½‘ç»œåœ°å€ï¼Œå‘ç°ä¸åœ¨ç›¸åŒç½‘ç»œï¼Œé€è·¯ç”±å™¨R(é—´æ¥)</li><li>Aä½¿ç”¨ARPä»10.10.10.4å¾—åˆ°Rçš„MACåœ°å€</li><li>Aç”Ÿæˆä»¥<em>Rçš„MACåœ°å€ä½œ</em>ä¸ºç›®çš„åœ°çš„<em>é“¾è·¯å±‚å¸§</em>,å¸§åŒ…å«<em>Aåˆ°E</em> <strong>IP æ•°æ®æŠ¥</strong></li><li>Açš„é€‚é…å™¨å‘é€å¸§ï¼ŒRçš„é€‚é…å™¨æ¥æ”¶å¸§</li><li>Rä»å¸§ä¸­çœ‹åˆ°å®ƒç›®çš„åœ°æ˜¯Eï¼Œä½¿ç”¨é€‰è·¯åè®®ç¡®å®šè·¯ç”±å™¨ç«¯å£</li><li>Rå‡ºç«¯å£å‘ç°Eåœ¨å³ä¾§ç½‘ç»œï¼Œç”¨ARPå¾—åˆ°Eçš„MAC(ç›´æ¥)</li><li>Rç”ŸæˆåŒ…å«Aåˆ°E IPæ•°æ®æŠ¥çš„å¸§å‘Eå‘é€</li><li>Eæ”¶åˆ°æ¥è‡ªAçš„IPåˆ†ç»„ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-47.png"></li></ul></li></ul><p><em>ICMP: Internet Control Message Protocol</em></p><ul><li>è®¾è®¡ç”¨äºç½‘ ç»œç»´æŠ¤å’Œç®¡ç†</li><li>å…è®¸ç«¯ç³»ç»Ÿæˆ–è·¯ç”±å™¨æŠ¥å‘Šå·®é”™æƒ…å†µï¼Œä¸ºç½‘ç®¡äººå‘˜æä¾›é€‚å½“çš„å·¥å…·ä»¥æŸ¥è¯¢ç½‘ç»œç»“ç‚¹çš„ä¿¡æ¯</li><li><em>IP æ•°æ®æŠ¥æºå¸¦ICMP æŠ¥æ–‡</em></li><li>TracerouteåŸç†<ul><li>æºå‘ç›®çš„åœ°å‘é€ä¸€ç³»åˆ—UDPæ®µ<ul><li>ç¬¬ä¸€ä¸ª TTL = 1</li><li>ç¬¬äºŒä¸ª TTL= 2,</li><li>......</li><li>æœ€åä¸€è·³ä¸ºä¸å¯èƒ½çš„ç«¯å£å·</li></ul></li><li>å½“ç¬¬nä¸ªæ•°æ®æŠ¥åˆ°è¾¾ç¬¬nä¸ªè·¯ç”±å™¨:<ul><li>è·¯ç”±å™¨ä¸¢å¼ƒæ•°æ®æŠ¥</li><li>å‘æºå‘é€ä¸€ä¸ªICMPæŠ¥æ–‡(ç±»å‹11, ä»£ç 0) æŠ¥æ–‡åŒ…æ‹¬è·¯ç”±å™¨åå­—å’ŒIPåœ°å€</li></ul></li><li>å½“ICMPæŠ¥æ–‡åˆ°è¾¾ï¼Œæºè®¡ç®— RTT</li><li>åœæ­¢è§„åˆ™<ul><li>UDPæ®µæœ€ç»ˆåˆ°è¾¾ç›®çš„åœ°ä¸»æœº</li><li>ç›®çš„åœ°è¿”å›ICMP â€œä¸»æœºä¸å¯è¾¾â€åˆ†ç»„ (ç±»å‹3, ä»£ç 3)</li><li>å½“æºå¾—åˆ°è¯¥ICMP, åœæ­¢</li></ul></li></ul></li></ul><p>ä½œä¸š</p><ol type="1"><li>ä»IPåè®®æ”¯æŒç½‘ç»œå±‚ç¼–å€å’Œè½¬å‘ä¸¤å¤§åŠŸèƒ½çš„è§’åº¦çœ‹ï¼ŒIPåè®®æ•°æ®æŠ¥é¦–éƒ¨ è‡³å°‘è¦åŒ…æ‹¬å“ªäº›å­—æ®µ?è¿™äº›å­—æ®µåº”å½“åŒ…æ‹¬ä»€ä¹ˆå†…å®¹?</li><li>è€ƒè™‘ä½¿ç”¨8 bitä¸»æœºåœ°å€çš„æ•°æ®æŠ¥ç½‘ç»œã€‚å‡å®šä¸€å°è·¯ç”±å™¨ä½¿ç”¨æœ€é•¿å‰ç¼€åŒ¹ é…å¹¶å…·æœ‰ä¸‹åˆ—è½¬å‘è¡¨: <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-48.png"> å¯¹è¿™4ä¸ªæ¥å£ï¼Œç»™å‡ºç›¸å…³çš„ç›®çš„ä¸»æœºåœ°å€çš„èŒƒå›´å’Œåœ¨è¯¥èŒƒå›´ä¸­çš„åœ°å€æ•°é‡ã€‚</li><li>åœ¨4-14ç½‘ç»œç¯å¢ƒä¸­ï¼Œè‹¥å†…ç½‘æœ‰30å°ä¸»æœºä»172.16.0.0/24åœ°å€å— ä¸­åˆ†é…åœ°å€ï¼Œå…¬ç½‘åœ°å€ä¸º150.20.20.1ã€‚å½“å†…ç½‘ä¸»æœºæµè§ˆå…¬ç½‘ Webç½‘ç«™(ç”¨80ç«¯å£)å’Œç”¨FTPä¸‹è½½æ–‡ä»¶(ç”¨20ç«¯å£)æ—¶ï¼ŒNATçš„ ç«¯å£éšæœºç”³è¯·ã€‚è¯•å¡«å…¥NATè½¬æ¢è¡¨çš„å€¼ã€‚</li><li>åœ¨å›¾4-17æ‰€ç¤ºçš„ç½‘ç»œä¸­ï¼Œç«¯ç³»ç»ŸAè¦ä¸ç«¯ç³»ç»ŸEé€šä¿¡ã€‚è¯•ç®€è¿° å®ƒä»¬ä¹‹é—´å…·ä½“çš„é€šä¿¡è¿‡ç¨‹ã€‚</li><li>è®¾è®¡ICMPç”¨äºå¤„ç†ç½‘ç»œç®¡ç†é—®é¢˜çš„åŸºæœ¬æ€è·¯æ˜¯ä»€ä¹ˆ? Tracerouteç¨‹åºçš„å·¥ä½œåŸç†ç¬¦åˆè¿™ä¸ªåŸºæœ¬æ€è·¯å—?</li></ol><h3><span id="è·¯ç”±é€‰æ‹©åè®®åŠå…¶ç®—æ³•">è·¯ç”±é€‰æ‹©åè®®åŠå…¶ç®—æ³•</span></h3><p><strong>è·¯ç”±é€‰æ‹©</strong></p><ul><li>èŠ‚ç‚¹æ˜¯è·¯ç”±å™¨</li><li>è¾¹æ˜¯ç‰©ç†é“¾è·¯</li><li>é“¾è·¯ä»£ä»·ï¼šæ—¶å»¶ã€è´¹ç”¨æˆ–æ‹¥å¡ç­‰çº§</li><li>åˆ†ç±»<ul><li>åˆ†æ•£<ul><li>è·¯ç”±å™¨çŸ¥é“ç‰©ç†ç›¸è¿çš„é‚»å±…ã€åˆ°é‚»å±…çš„é“¾è·¯è´¹ç”¨</li><li>è®¡ç®—çš„è¿­ä»£è¿‡ç¨‹ï¼Œä¸é‚»å±…äº¤æ¢ä¿¡æ¯</li><li><em>è·ç¦»çŸ¢é‡ï¼ˆDistance-Vector, DVï¼‰ç®—æ³•</em></li></ul></li><li>å…¨å±€<ul><li>æ‰€æœ‰è·¯ç”±å™¨å…·æœ‰å®Œå…¨çš„æ‹“æ‰‘ã€é“¾è·¯è´¹ç”¨ä¿¡æ¯</li><li><em>é“¾è·¯çŠ¶æ€ï¼ˆLink State algorithm, LSï¼‰ç®—æ³•</em></li></ul></li><li>é™æ€</li><li>åŠ¨æ€</li></ul></li></ul><p><strong>RIPï¼šè·¯ç”±é€‰æ‹©ä¿¡æ¯åè®®</strong></p><ul><li>è·ç¦»çŸ¢é‡ç®—æ³•</li><li>è·ç¦»æµ‹åº¦: è·³çš„æ•°é‡(æœ€å¤§ = 15è·³)</li><li>ç‰¹ç‚¹<ul><li>ä»…ä¸ç›¸é‚»è·¯ç”±å™¨äº¤æ¢ä¿¡æ¯</li><li>äº¤æ¢æœ¬è·¯ç”±å™¨é€‰è·¯è¡¨ä¸­çš„æ›´æ–°ä¿¡æ¯</li><li>æŒ‰å›ºå®šæ—¶é—´é—´éš”äº¤æ¢ä¿¡æ¯ï¼Œçº¦30ç§’</li><li>æ ¹æ®æ›´æ–°ä¿¡æ¯ï¼Œå¯¹æœ¬åœ°RIPè¡¨è¿›è¡Œå¤„ç†</li></ul></li><li>æ€æƒ³<ul><li>å¦‚æœé‚»å±…çŸ¥é“åˆ°è¾¾ç›®çš„åœ°çš„è·ç¦»ï¼Œä¸”è‡ªå·±çŸ¥é“åˆ°è¾¾é‚»å±…çš„è·ç¦»ï¼Œåˆ™èƒ½ç®—å‡ºè‡ªå·±åˆ°è¾¾ç›®çš„åœ°çš„è·ç¦»<ul><li>æ¯ä¸ªç»“ç‚¹å‘¨æœŸæ€§åœ°å‘å…¶é‚»å±…å‘é€è‡ªå·±è·ç¦»çŸ¢é‡</li><li>å½“ç»“ç‚¹xæ¥æ”¶åˆ°æ¥è‡ªé‚»å±…çš„æ–°DVä¼°è®¡ï¼Œå®ƒä½¿ç”¨Bellman-Fordæ–¹ç¨‹æ›´æ–°å…¶è‡ªå·±çš„DV <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-49.png"></li></ul></li></ul></li><li>æ¯ä¸ªç»“ç‚¹ï¼š <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-50.png"></li><li>ç®—æ³• <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-51.png"></li><li>é—®é¢˜<ul><li>é“¾è·¯è´¹ç”¨å˜åŒ–<ul><li>å¥½æ¶ˆæ¯ä¼ æ’­å¾—å¿«</li><li>åæ¶ˆæ¯ä¼ æ’­å¾—æ…¢â€”â€œ<em>è®¡æ•°åˆ°æ— </em>â€é—®é¢˜!P171</li><li>åœ¨ç®—æ³•ç¨³å®šå‰ï¼Œåå¤è¿­ä»£</li></ul></li></ul></li><li>ä¾‹å­ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-52.png"></li></ul><p><strong>OSPFï¼šå¼€æ”¾æœ€çŸ­è·¯ä¼˜å…ˆ</strong></p><ul><li>ä½¿ç”¨<em>é“¾è·¯çŠ¶æ€(link state)</em>ç®—æ³•:<ul><li>ç½‘ç»œæ‹“æ‰‘å’Œæ‰€æœ‰é“¾è·¯çš„è´¹ç”¨éƒ½å·²çŸ¥ï¼Œå¯ä½œä¸ºLSç®—æ³•çš„è¾“å…¥</li></ul></li><li>LSç®—æ³•ä¾é ä¸¤ç§æœºåˆ¶è¿›è¡Œè·¯ç”±è®¡ç®—<ul><li>LSä¿¡æ¯çš„å¯é ä¼ è¾“</li><li>ç§¯ç´¯çš„é“¾è·¯çŠ¶æ€çŸ¥è¯†</li></ul></li><li>OSPFä¸¤ä¸ªæŠ€æœ¯è¦ç‚¹<ul><li>ä½¿ç”¨æ´ªæ³›é“¾è·¯çŠ¶æ€ä¿¡æ¯çš„é“¾è·¯çŠ¶æ€åè®®</li><li>Dijkstraæœ€ä½è´¹ç”¨è·¯å¾„ç®—æ³•</li></ul></li><li>ç‰¹è‰²<ul><li>å®‰å…¨æ€§ï¼šæ‰€æœ‰OSPFæŠ¥æ–‡ç»é‰´åˆ«ï¼ˆä»¥é˜²æ”»å‡»ï¼‰</li><li>å…è®¸å¤šæ¡è´¹ç”¨ç›¸åŒçš„è·¯å¾„</li><li>åœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­ï¼Œç”¨å±‚æ¬¡çš„OSPF</li></ul></li><li>Dijkstraç®—æ³•<ul><li>çŸ¥é“ç½‘ç»œæ‰€æœ‰ç»“ç‚¹çš„æ‹“æ‰‘ã€é“¾è·¯è´¹ç”¨</li><li>ä»ä¸€ä¸ªç»“ç‚¹(æº)åˆ°æ‰€æœ‰å…¶ä»– ç»“ç‚¹è®¡ç®—æœ€ä½è´¹ç”¨è·¯å¾„</li><li>è¿­ä»£: kæ¬¡è¿­ä»£åï¼Œå¾—çŸ¥åˆ°k ä¸ªç›®çš„åœ°çš„æœ€ä½è´¹ç”¨è·¯å¾„</li><li><code>c(x,y)</code>: ä»ç»“ç‚¹xåˆ°yçš„é“¾è·¯ è´¹ç”¨; = âˆ å¦‚æœéç›´æ¥é‚»å±…</li><li><code>D(v)</code>:ä»æºåˆ°ç›®çš„åœ°vè·¯å¾„è´¹ç”¨çš„å½“å‰å€¼</li><li><code>p(v)</code>: ä»æºåˆ°væ²¿è·¯å¾„çš„å‰ä»»ç»“ç‚¹</li><li><code>Nâ€˜</code>: å·²çŸ¥åœ¨æœ€å°è´¹ç”¨è·¯å¾„ä¸­çš„ç»“ç‚¹é›†åˆ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-53.png"></li></ul></li></ul><p>BGPå’Œå±‚æ¬¡è·¯ç”±é€‰æ‹©</p><ul><li>å…ˆå°†æŸåŒºåŸŸçš„è·¯ç”±å™¨èšåˆæˆä¸º â€œè‡ªæ²»ç³»ç»Ÿâ€ ï¼ˆASï¼‰</li><li>åœ¨ç›¸åŒASä¸­çš„è·¯ç”±å™¨è¿è¡Œç›¸åŒçš„è·¯ç”±é€‰æ‹©åè®®</li><li>ä¸åŒçš„ASä¸­çš„è·¯ç”±å™¨é€šè¿‡ASé—´çš„è·¯ç”±é€‰æ‹©åè®®é€‰è·¯</li><li>BGPï¼šè¾¹ç•Œç½‘å…³åè®®</li></ul><h3><span id="è·¯ç”±å™¨çš„å·¥ä½œåŸç†">è·¯ç”±å™¨çš„å·¥ä½œåŸç†</span></h3><p>åŠŸèƒ½</p><ul><li><strong>è½¬å‘</strong>ï¼šä¸¤ä¸ªå¼‚æ„é€šä¿¡å­ç½‘ä¸­çš„åˆ†ç»„ç»è¿‡è·¯ç”±å™¨çš„å¸§æ ¼å¼è½¬æ¢ï¼Œå®ç°äº†å¼‚æ„ç½‘ç»œçš„äº’è”</li><li><strong>è·¯ç”±é€‰æ‹©</strong>ï¼šè·¯ç”±å™¨é€šè¿‡æ‰§è¡Œè·¯ç”±é€‰æ‹©åè®®ï¼Œæ›´æ–°äº†è½¬å‘è¡¨ï¼Œå¹¶ä½¿åˆ†ç»„åˆ°è¾¾æ­£ç¡®çš„è¾“å‡ºç«¯å£</li></ul><p>ä½“ç³»ç»“æ„ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-54.png"></p><ul><li>è¾“å…¥æ¥å£å¡ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-55.png"></li><li>è¾“å‡ºæ¥å£å¡ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-56.png"></li><li>æ§åˆ¶å™¨å¡<ul><li>ç»´æŠ¤æœ¬åœ°è·¯ç”±è½¬å‘è¡¨</li><li>ç¡®å®šåˆ†ç»„çš„è¾“å‡ºæ¥å£</li><li>æ‰§è¡Œè·¯ç”±å™¨ä¸­çš„ç½‘ç»œç®¡ç†åŠŸèƒ½</li></ul></li><li>äº¤æ¢ç»“æ„<ul><li>å†…å­˜äº¤æ¢</li><li>ç»æ€»çº¿äº¤æ¢</li><li>ç»äº’è”ç½‘ç»œäº¤æ¢</li></ul></li></ul><p>ä½œä¸š</p><ol type="1"><li>è€ƒè™‘å›¾4-27ä¸Šçš„ç½‘ç»œã€‚è¯•ç”¨è·ç¦»çŸ¢é‡ç®—æ³•ç»™å‡ºç»“ç‚¹bçš„è·ç¦»è¡¨è¡¨é¡¹ç”Ÿæˆè¿‡ç¨‹</li><li>è€ƒè™‘å›¾4-27çš„ç½‘ç»œã€‚ç”¨Dijkstraçš„æœ€çŸ­è·¯ç®—æ³•è®¡ç®—å‡ºä»båˆ°æ‰€æœ‰ç½‘ç»œç»“ç‚¹çš„æœ€çŸ­è·¯å¾„ã€‚é€šè¿‡è®¡ç®—ä¸€ä¸ªç±»ä¼¼äºè¡¨4-10çš„è¡¨ï¼Œ ç»™å‡ºè¯¥ç®—æ³•çš„å·¥ä½œè¿‡ç¨‹</li><li>BGPæœ‰å“ªäº›ä¸»è¦åŠŸèƒ½ã€‚æè¿°åœ¨BGPä¸­æ˜¯å¦‚ä½•æ£€æµ‹è·¯å¾„ä¸­çš„ç¯è·¯ ç­”ï¼šBGP æ˜¯ AS ä¹‹é—´ä¾›å¯è¾¾è·¯å¾„çš„åˆ†å±‚è·¯ç”±é€‰æ‹©åè®®ã€‚BGP å…·æœ‰ä»¥ä¸‹åŠŸèƒ½:<ol type="1"><li>ä»ç›¸é‚» AS å¤„è·å¾—å­ç½‘å¯è¾¾æ€§ä¿¡æ¯;</li><li>å‘æœ¬ AS å†…éƒ¨çš„æ‰€æœ‰è·¯ç”±å™¨ä¼ æ’­è¿™äº›å¯è¾¾æ€§ä¿¡æ¯;</li><li>åŸºäºå¯è¾¾æ€§ä¿¡æ¯å’Œ AS ç­–ç•¥ï¼Œå†³å®šåˆ°è¾¾å­ç½‘çš„â€œå¥½â€è·¯ç”±ã€‚BGP ä»ç›¸é‚» AS è·å¾—å­ç½‘å¯è¾¾æ€§ä¿¡æ¯ï¼ŒåŸºäºè‡ªå·±çš„ç­–ç•¥ï¼Œå†³å®šæ˜¯å¦å‘å…¶ä»– AS é€šå‘Šï¼Œ ä¸€æ—¦é€šå‘Šå°±æ‰¿è¯ºå‘è¯¥å­ç½‘è½¬å‘æ•°æ®æŠ¥;</li><li>BGP è¿˜å‘æœ¬ AS å†…éƒ¨çš„æ‰€æœ‰è·¯ç”±å™¨ä¼ æ’­ç›¸å…³å¯è¾¾æ€§ä¿¡æ¯ã€‚ åœ¨ AS-PATH å±æ€§åŒ…å«äº†ä¼ é€’å‰ç¼€çš„é€šå‘Šæ‰€ç»è¿‡çš„ ASï¼Œç”±æ­¤å¯ä»¥åˆ¤æ–­æ˜¯å¦å­˜ åœ¨ç¯è·¯ã€‚</li></ol></li><li>è§‚å¯Ÿå›¾4-30æ‰€ç¤ºçš„è·¯ç”±å™¨ä½“ç³»ç»“æ„ã€‚å¦‚ä½•ä½“ç°å‡ºè·¯ç”±å™¨å…·æœ‰äº’è”å¼‚æ„ç½‘ç»œã€è½¬å‘å’Œé€‰æ‹©è·¯ç”±ç­‰å‡ é¡¹å…³é”®åŠŸèƒ½ã€‚ ç­”ï¼š<ul><li>äº’è”å¼‚æ„ç½‘ç»œ:ä¸åŒå¼‚æ„é€šä¿¡å­ç½‘ä¸­çš„åˆ†ç»„ç»è¿‡è·¯ç”±å™¨çš„ç‰©ç†å±‚ã€é“¾è·¯å±‚å’Œç½‘ç»œå±‚åŠŸèƒ½è½¬æ¢ï¼Œåœ¨ IP å±‚å®ç°åœ°å€å’ŒæŠ¥æ–‡ç»“æ„çš„ç»Ÿä¸€ï¼Œèƒ½å¤Ÿè¿›è¡Œç»Ÿä¸€å¯»å€ã€‚</li><li>è½¬å‘:åˆ†ç»„è¿›å…¥è·¯ç”±å™¨ä¸åŒè¾“å…¥æ¥å£å¡åï¼Œé€šè¿‡å°†åˆ†ç»„ç›®çš„åœ°å€ä¸è½¬å‘è¡¨è¿›è¡Œæ¯”è¾ƒï¼Œç»è¿‡äº¤æ¢ç»“æ„åï¼Œç”±è¾“å‡ºæ¥å£å¡è¾“å‡ºåˆ°ä¸åŒè·¯ç”±å™¨ä¸åŒæ¥å£ã€‚</li><li>è·¯ç”±é€‰æ‹©:è·¯ç”±å™¨æ¥æ”¶æ¥è‡ªä¸åŒè·¯ç”±å™¨çš„è·¯ç”±é€‰æ‹©æŠ¥æ–‡ï¼Œé€šè¿‡æ‰§è¡Œè·¯ç”±é€‰æ‹©åè®®ï¼Œæ›´æ–°äº†è½¬å‘è¡¨å†…å®¹ï¼Œä½¿åˆ†ç»„èƒ½å¤Ÿåˆ°è¾¾æ­£ç¡®çš„è¾“å‡ºç«¯å£ ã€‚è¿™äº›åŠŸèƒ½ç”±è·¯ç”±å™¨çš„æ§åˆ¶å™¨å¡ä¾›ï¼ŒåŒ…æ‹¬è·¯ç”±è®¡ç®—ä¸æ›´æ–°ã€æ‹“æ‰‘å’Œåœ°å€ä¿¡æ¯äº¤æ¢ã€‚</li></ul></li></ol><h2><span id="ç«¯åˆ°ç«¯åè®®">ç«¯åˆ°ç«¯åè®®</span></h2><h3><span id="è¿è¾“å±‚åè®®æ¦‚è¿°">è¿è¾“å±‚åè®®æ¦‚è¿°</span></h3><p>è¿è¾“æœåŠ¡å’Œåè®®</p><ul><li>ä¸ºå½¢å½¢è‰²è‰²çš„åº”ç”¨å±‚è¿›ç¨‹åˆ©ç”¨å…±åŒçš„ç½‘ç»œå±‚å°½åŠ›è€Œä¸ºæœåŠ¡ï¼Œæä¾›äº†<em>å¤šè·¯å¤ç”¨ï¼åˆ†è§£</em>çš„åŠŸèƒ½ï¼Œä»¥åŠ<strong>å¯é ä¼ è¾“ã€æµé‡æ§åˆ¶å’Œç½‘ç»œæ‹¥å¡æ§åˆ¶</strong>åŠŸèƒ½</li><li>å¯é ã€æŒ‰åºçš„äº¤ä»˜ï¼šTCP<ul><li>é¢å‘è¿æ¥æœåŠ¡</li><li>å¯é æ•°æ®ä¼ é€æœåŠ¡</li><li>æ‹¥å¡æ§åˆ¶æœåŠ¡</li><li>ä¼ é€çš„æ•°æ®å•ä½æ˜¯TCPæŠ¥æ–‡æ®µ</li></ul></li><li>ä¸å¯é ã€ä¸æŒ‰åºäº¤ä»˜: UDP<ul><li>æ‰©å±•äº†å°½åŠ›è€Œä¸ºIPåŸºæœ¬æœåŠ¡</li><li>ä¼ é€çš„æ•°æ®å•ä½æ˜¯ UDP æŠ¥æ–‡æˆ–ç”¨æˆ·æ•°æ®æŠ¥</li></ul></li></ul><h3><span id="å¤šè·¯å¤ç”¨ä¸å¤šè·¯åˆ†è§£">å¤šè·¯å¤ç”¨ä¸å¤šè·¯åˆ†è§£</span></h3><p><em>ç«¯å£</em></p><ul><li>å®šä½å™¨ç«¯å£è¿åŒIPåœ°å€ï¼Œå”¯ä¸€æ ‡è¯†è¿›ç¨‹</li><li>ç«¯å£æ‰©å±•äº†ç½‘ç»œåœ°å€</li><li>è¿›ç¨‹æ ‡è¯†ç¬¦æ ‡è¯†æœ¬åœ°è¿›ç¨‹</li><li>ç«¯å£å·ä¸º16 bitçš„æ•°ï¼Œå…¶å¤§å°åœ¨0åˆ°65535ä¹‹é—´</li><li>0åˆ°1023èŒƒå›´çš„ç«¯å£å·ç§°ä¸ºå‘¨çŸ¥ç«¯å£å·</li></ul><p>è¿›ç¨‹é€šè¿‡<em>å¥—æ¥å­—(socket)</em>æ¥æè¿°ç½‘ç»œä¸¤ç«¯è¿›ç¨‹é—´çš„é€šä¿¡é“¾ã€‚</p><p>UDPçš„å¤šè·¯å¤ç”¨ï¼åˆ†è§£</p><ul><li>UDPå¥—æ¥å­—ç”±äºŒå…ƒç»„æ ‡è¯† ï¼š<em>(ç›®çš„åœ°IPåœ°å€, ç›®çš„åœ°ç«¯å£å·)Â </em></li><li>å…·æœ‰<em>ä¸åŒ</em>æºIPåœ°å€å’Œ/æˆ–æºç«¯å£å·çš„IPæ•°æ®æŠ¥å¯å®šå‘åˆ°<em>ç›¸åŒ</em>çš„å¥—æ¥å­—</li><li>ä¸»æœºä¸Šè¿›ç¨‹ç›®çš„ç«¯å£å·ç›¸åŒï¼ŒUDPå¥—æ¥å­—ç›¸åŒ</li><li>ä¸€ä¸ªUDPå¥—æ¥å­—å¯¹åº”ç€ä¸€æ¡UDPé€šä¿¡é“¾</li></ul><p><em>TCPçš„å¤šè·¯å¤ç”¨ï¼åˆ†è§£</em></p><ul><li>TCPå¥—æ¥å­—ç”±å››å…ƒç»„æ ‡è¯†: <em>(æºIPåœ°å€, æºç«¯å£å·; ç›®çš„åœ°IPåœ°å€, ç›®çš„ç«¯å£å·)Â </em></li><li>æœåŠ¡å™¨ä¸»æœºå¯èƒ½æ”¯æŒè®¸å¤šå¹¶è¡Œçš„TCPå¥—æ¥å­—<ul><li>æ¯ä¸ªå¥—æ¥å­—ç”±å…¶è‡ªå·±çš„å››å…ƒç»„æ ‡è¯†</li></ul></li><li>WebæœåŠ¡å™¨å¯¹æ¯ä¸ªè¿æ¥çš„å®¢æˆ·å…·æœ‰ä¸åŒçš„å¥—æ¥å­—<ul><li>å¦‚éæŒç»­HTTPå°†ä¸ºæ¯ä¸ªè¯·æ±‚å…·æœ‰ä¸åŒçš„å¥—æ¥å­—</li></ul></li></ul><h3><span id="udp">UDP</span></h3><p>UDPä¼˜ç‚¹</p><ul><li>æ— è¿æ¥</li><li>ç®€å•</li><li>æ•ˆç‡é«˜</li><li>é¢å‘æŠ¥æ–‡</li><li>æ²¡æœ‰æ‹¥å¡æ§åˆ¶</li></ul><p>UDPåªåšäº†è¿è¾“åè®®çš„æœ€å°‘å·¥ä½œåœ¨IPä¹‹ä¸ŠåŠ å…¥<em>å¤šè·¯å¤ç”¨/å¤šè·¯åˆ†è§£</em>å’Œ<em>é”™è¯¯æ£€æµ‹</em></p><p>é‡è¦åº”ç”¨</p><ul><li>DNS</li><li>RIPé€‰è·¯è¡¨æ›´æ–°æŠ¥æ–‡</li><li>ç½‘ç»œç®¡ç†æ•°æ®</li></ul><p><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-57.png"></p><p>UDPæ ¡éªŒå’Œ=äº’è”ç½‘æ ¡éªŒå’Œ</p><p>ä½œä¸š</p><ol type="1"><li>æ ¹æ®ç½‘ç»œåº”ç”¨çš„æ—¶å»¶å’Œå¯é æ€§å¯ä»¥å°†å®ƒä»¬åˆ†ä¸ºå‡ ç±»?è¿è¾“å±‚æ˜¯å¦åº”å½“ç”±æ­¤è®¾è®¡å‡ ç§ä¸åŒçš„åè®®?å› ç‰¹ç½‘çš„è¿è¾“å±‚åè®®èƒ½å¤Ÿä¸ºç½‘ç»œåº”ç”¨æä¾›å“ªäº›æœåŠ¡?ä¸èƒ½å¤Ÿæä¾›å“ªäº›æœåŠ¡? ç­”ï¼š<strong>ä¸èƒ½å¤Ÿæä¾›</strong>å¸¦å®½å’Œæ—¶å»¶ä¿è¯ã€å®‰å…¨æ€§æœåŠ¡ç­‰</li><li>å¯ä»¥è®¤ä¸ºç«¯å£å·æ˜¯ä¸€ç§åœ°å€å—?å¦‚æœæ˜¯ï¼Œå®ƒæ˜¯æ ‡è¯†ä»€ä¹ˆçš„åœ°å€?å°†ç«¯å£å·åˆ†ä¸ºå‘¨çŸ¥ç«¯å£å·å’Œä¸€èˆ¬ç«¯å£å·æœ‰ä»€ä¹ˆå¥½å¤„ï¼Œ è¿™ä¸ç½‘ç»œåº”ç”¨çš„æ¨¡å¼æœ‰å…³ç³»å—? ç­”ï¼šå¥½å¤„ï¼š<em>å¤§å¤§åœ°é™ä½äº†å‡ºå¤„å·®é”™çš„å¯èƒ½æ€§</em>ã€‚ä¸€èˆ¬åœ¨ C/S æ¨¡å¼ä¸­ï¼ŒæœåŠ¡å™¨ç«¯å£é€šå¸¸ä½¿ç”¨å‘¨çŸ¥ç«¯å£å¥½ï¼Œè€Œä¸”å¿…é¡»è¦é•¿æœŸå¤„äº æ‰“å¼€çŠ¶æ€ï¼Œå› æ­¤ç«¯å£å·åˆ’åˆ†ä¸ç½‘ç»œè®¾è®¡æ¨¡å¼æœ‰å…³ã€‚</li><li>ç»™å‡ºæ ‡è¯†å›¾5-5ä¸­TCPå¥—æ¥å­—çš„æ‰€æœ‰å››å…ƒç»„ã€‚ä¸UDPå¥—æ¥å­—å¿½ç•¥äº†æºç«¯çš„æ ‡è¯†ä¿¡æ¯ç›¸æ¯”ï¼ŒTCPçš„å¥—æ¥å­—æ ‡è¯†èƒ½åŠ›æ˜¯å¢å¼ºäº†è¿˜æ˜¯å‰Šå¼±äº†?</li></ol><h3><span id="tcp">TCP</span></h3><p>ç‰¹ç‚¹</p><ul><li>é¢å‘è¿æ¥</li><li>ç‚¹å¯¹ç‚¹</li><li>å…¨åŒå·¥<ul><li>MSSï¼šæœ€å¤§æŠ¥æ–‡æ®µé•¿åº¦</li><li>MTUï¼šæœ€å¤§ä¼ è¾“å•å…ƒ</li></ul></li><li>å¯é çš„äº¤ä»˜æœåŠ¡</li><li>å®¢æˆ·ï¼æœåŠ¡å™¨æ¨¡å¼</li><li>é¢å‘å­—èŠ‚æµ</li><li>æµé‡æ§åˆ¶</li><li>æ‹¥å¡æ§åˆ¶</li></ul><p><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-58.png"></p><p>TCP çš„é¦–éƒ¨åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š</p><ol type="1"><li>æºç«¯å£ source port</li><li>ç›®çš„ç«¯å£ destination port</li><li>åºå· sequence number</li><li>ç¡®è®¤å· acknowledgment number</li><li>æ•°æ®åç§» offset</li><li>ä¿ç•™ reserved</li><li>æ ‡å¿—ä½ tcp flags</li><li>çª—å£å¤§å° window size</li><li>æ£€éªŒå’Œ checksum</li><li>ç´§æ€¥æŒ‡é’ˆ urgent pointer</li><li>é€‰é¡¹ tcp options</li></ol><p><em>TCPå¯é æ•°æ®ä¼ è¾“æœºåˆ¶</em></p><ul><li>ä½¿ç”¨<em>åºå·ã€ç¡®è®¤ã€è¶…æ—¶é‡ä¼ ã€æ»‘åŠ¨çª—å£</em>ç­‰æœºåˆ¶</li><li>æ•°æ®æ˜¯æ— ç»“æ„ã€æœ‰åºçš„å­—èŠ‚æµ<ul><li>æŠ¥æ–‡æ®µçš„<em>åºå·</em>æ˜¯è¯¥æŠ¥æ–‡æ®µå­—èŠ‚æµçš„<em>é¦–å­—èŠ‚ç¼–å·</em></li></ul></li><li>TCPçš„é«˜æ•ˆè½½ç­”æœºåˆ¶<ul><li>ç¡®è®¤æœºåˆ¶æ˜¯<em>æå¸¦(piggybacked)</em>çš„</li><li>ç¡®è®¤å·æ˜¯<em>æœŸæœ›æ”¶åˆ°çš„ä¸‹ä¸€å­—èŠ‚çš„ç¼–å·</em></li></ul></li><li>ç´¯ç§¯ç¡®<ul><li>ç¡®è®¤å·éšå«è¡¨æ˜äº†å‰é¢æ‰€æœ‰å­—èŠ‚å·²æ­£ç¡®æ”¶åˆ°</li></ul></li><li>å¯¹å¤±åºæŠ¥æ–‡æ®µçš„å¤„ç†æ–¹å¼<ul><li>æœªè§„å®šï¼Œå¯ç”¨â€œå›é€€Næ­¥åè®®â€å’Œâ€œé€‰æ‹©é‡ä¼ åè®®â€</li></ul></li><li>åˆå§‹åºå·çš„é€‰æ‹©<ul><li>åŒæ–¹å‡å¯<em>éšæœºåœ°é€‰æ‹©</em></li></ul></li><li>è¶…æ—¶æ—¶é™ &gt; RTT</li><li>RTTä¼°è®¡å€¼ = (1 - a) x RTTä¼°è®¡å€¼ + a x RTTæ ·æœ¬<ul><li>æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡</li><li>å…¸å‹å€¼ a = 0.125</li></ul></li><li>RTTåå·®</li></ul><p>ä½œä¸š</p><ol type="1"><li>ä¸»æœºAå’ŒBç»ä¸€æ¡TCPè¿æ¥é€šä¿¡ï¼Œå¹¶ä¸”ä¸»æœºBå·²ç»æ”¶åˆ°äº†æ¥è‡ªAçš„ åˆ°å­—èŠ‚248çš„æ‰€æœ‰å­—èŠ‚ã€‚å‡å®šä¸»æœºAéšåå‘ä¸»æœºBå‘é€ä¸¤ä¸ªç´§æ¥ ç€çš„æŠ¥æ–‡æ®µã€‚ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªæŠ¥æ–‡æ®µåˆ†åˆ«åŒ…å«äº†40å’Œ60 byteçš„æ•°æ®ã€‚åœ¨ç¬¬ä¸€ä¸ªæŠ¥æ–‡æ®µä¸­ï¼Œåºå·æ˜¯249ï¼Œæºç«¯å£å·æ˜¯503, ç›®çš„åœ°ç«¯å£å·æ˜¯80ã€‚æ— è®ºä½•æ—¶ä¸»æœºBæ¥æ”¶åˆ°æ¥è‡ªä¸»æœºAçš„æŠ¥æ–‡æ®µï¼Œå®ƒéƒ½ä¼šå‘é€ç¡®è®¤ã€‚<ol type="a"><li>åœ¨ä»ä¸»æœºAå‘å¾€Bçš„ç¬¬äºŒä¸ªæŠ¥æ–‡æ®µä¸­ï¼Œåºå·ã€æºç«¯å£å·å’Œç›®çš„ç«¯å£å·å„æ˜¯ä»€ä¹ˆ?</li><li>å¦‚æœç¬¬ä¸€ä¸ªæŠ¥æ–‡æ®µåœ¨ç¬¬äºŒä¸ªæŠ¥æ–‡æ®µä¹‹å‰åˆ°è¾¾ï¼Œåœ¨ç¬¬ä¸€ä¸ªåˆ°è¾¾æŠ¥æ–‡æ®µçš„ç¡®è®¤ä¸­ï¼Œç¡®è®¤å·ã€æºç«¯å£å·å’Œç›®çš„ç«¯å£å·å„æ˜¯ä»€ä¹ˆ?</li><li>å¦‚æœç¬¬äºŒä¸ªæŠ¥æ–‡æ®µåœ¨ç¬¬ä¸€ä¸ªæŠ¥æ–‡æ®µä¹‹å‰åˆ°è¾¾ï¼Œåœ¨ç¬¬ä¸€ä¸ªåˆ°è¾¾æŠ¥æ–‡æ®µçš„ ç¡®è®¤ä¸­ï¼Œç¡®è®¤å·æ˜¯ä»€ä¹ˆ?</li><li>å‡å®šç”±Aå‘é€çš„ä¸¤ä¸ªæŠ¥æ–‡æ®µæŒ‰åºåˆ°è¾¾Bã€‚ç¬¬ä¸€ä¸ªç¡®è®¤ä¸¢å¤±äº†è€Œç¬¬äºŒä¸ªç¡®è®¤åœ¨ç¬¬ä¸€ä¸ªè¶…æ—¶é—´éš”ä¹‹ååˆ°è¾¾ï¼Œå¦‚åœ¨ä¸‹ä¸€é¡µä¸Šçš„å›¾ä¸­æ‰€æ˜¾ç¤ºçš„é‚£æ ·ã€‚ ç”»å‡ºæ—¶åºå›¾ï¼Œæ˜¾ç¤ºè¿™äº›æŠ¥æ–‡æ®µå’Œå‘é€çš„æ‰€æœ‰å…¶ä»–æŠ¥æ–‡æ®µå’Œç¡®è®¤ã€‚(å‡è®¾æ²¡ æœ‰å…¶ä»–åˆ†ç»„ä¸¢å¤±ã€‚)å¯¹äºä½ å›¾ä¸Šæ¯ä¸ªæŠ¥æ–‡æ®µï¼Œæ ‡å‡ºåºå·å’Œæ•°æ®çš„å­—èŠ‚ç¼–å·; å¯¹äºä½ å¢åŠ çš„æ¯ä¸ªåº”ç­”ï¼Œæ ‡å‡ºç¡®è®¤å·ã€‚</li></ol></li></ol><p><em>TCPæµé‡æ§åˆ¶</em></p><ul><li>è®©<em>æ¥æ”¶æ–¹æ§åˆ¶</em>å‘é€æ–¹</li><li>æ§åˆ¶æ–¹æ³•ï¼š<em>å‘é€æ–¹</em>ç»´æŠ¤ä¸€ä¸ª<strong>æ¥æ”¶çª—å£</strong></li><li>å·¥ä½œåŸç†<ul><li>è®¾ç½®æ¥æ”¶çª—å£Rwin<ul><li>Rwinç”¨äºå‘å‘é€æ–¹æç¤º<em>æ¥æ”¶æ–¹çš„ç¼“å­˜è¿˜æœ‰å¤šå¤§</em></li><li><code>Rwin = RcvBuffer - [LastByteRcvd - LastByteRead]</code></li></ul></li><li>å‘é€æ–¹ä¸ä½¿æ¥æ”¶ç¼“å­˜æº¢å‡º<ul><li><code>LastbyteSent - LastByteAcked â‰¤ Rwin</code></li></ul></li><li>ä½¿TCPç¼“å­˜ä¸æº¢å‡º<ul><li><code>LastbyteRcvd - LastByteRead â‰¤ RcvBuffer</code></li></ul></li><li>å½“æ¥æ”¶çª—å£ä¸º<strong>0</strong>æ—¶ï¼Œ<em>Aåº”å½“å‘¨æœŸæ€§åœ°å‘é€åªæœ‰ä¸€ä¸ªå­—èŠ‚æ•°æ®çš„æŠ¥æ–‡æ®µ</em> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-59.png"></li></ul></li><li><em>æµé‡æ§åˆ¶ä¸æ‹¥å¡æ§åˆ¶çš„åŒºåˆ«</em><ul><li>æµé‡æ§åˆ¶æ˜¯<strong>æŸTCPæ¥æ”¶æ–¹</strong>é’ˆå¯¹<em>å…¶å‘é€æ–¹</em>æ‰€é‡‡å–çš„æªæ–½</li><li>æ‹¥å¡æ§åˆ¶æ˜¯TCPå‘é€æ–¹<em>é’ˆå¯¹ç½‘ç»œæ‹¥å µ</em>æƒ…å†µæ‰€é‡‡å–çš„æªæ–½</li></ul></li></ul><p><em>TCPè¿æ¥ç®¡ç†</em></p><ul><li>ä¸‰æ¬¡æ¡æ‰‹<ol type="1"><li>å®¢æˆ·å‘æœåŠ¡å™¨å‘é€TCP <em>SYNæŠ¥æ–‡æ®µ</em><ul><li>æŒ‡å®šåˆå§‹åºå·</li><li>æ²¡æœ‰æ•°æ®</li></ul></li><li>æœåŠ¡å™¨æ”¶åˆ°SYN æŠ¥æ–‡æ®µ, ç”¨<em>SYN ACKæŠ¥æ–‡æ®µ</em>å›å¤<ul><li>æœåŠ¡å™¨ä¸ºè¯¥è¿æ¥åˆ†é…ç¼“å†²åŒºå’Œå˜é‡</li><li>æŒ‡å®šæœåŠ¡å™¨åˆå§‹åºå·</li></ul></li><li>å®¢æˆ·æ”¶åˆ°SYN ACKï¼Œç”¨<em>ACKæŠ¥æ–‡æ®µ</em>å›å¤ï¼Œå¯èƒ½åŒ…å«æ•°æ® <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-60.png"></li></ol></li><li>å››æ¬¡æŒ¥æ‰‹<ol type="1"><li>å®¢æˆ·æœºå‘æœåŠ¡å™¨å‘é€<em>FINæŠ¥æ–‡æ®µ</em><ul><li>å®¢æˆ·ä¸å†å‘é€æ•°æ®</li></ul></li><li>æœåŠ¡å™¨æ”¶åˆ°FINåï¼Œè¿”å›<em>ACKæŠ¥æ–‡æ®µ</em><ul><li>é€šçŸ¥åº”ç”¨è¿›ç¨‹å¯¹æ–¹å…³é—­è¿æ¥</li><li>æœåŠ¡å™¨ä»ç„¶å¯ä»¥å‘é€æ•°æ®</li></ul></li><li>æœåŠ¡å™¨å‘é€å®Œæ•°æ®ï¼Œå‘é€<em>FIN ACKæŠ¥æ–‡æ®µ</em><ul><li>æœåŠ¡å™¨é‡Šæ”¾è¿æ¥ï¼Œä¸å†å‘é€æ•°æ®</li></ul></li><li>å®¢æˆ·æ”¶åˆ°FIN ACKåï¼Œå›å¤<em>ACKæŠ¥æ–‡æ®µ</em><ul><li>ç­‰å¾…è¶…æ—¶ï¼Œè¿æ¥å…³é—­</li></ul></li><li>æœåŠ¡å™¨æ”¶åˆ°ACKåï¼Œè¿æ¥å…³é—­ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-61.png"></li></ol></li><li><em>ä¸ºä»€ä¹ˆç­‰å¾…è¶…æ—¶å†å…³é—­ï¼Ÿ</em><ul><li>ç¡®ä¿å…¨éƒ¨æ¥æ”¶æœåŠ¡å™¨(B)å‘æ¥çš„æ•°æ®</li><li>æœ‰å¯ä»¥æœ€åä¸€ä¸ªACKä¸¢å¤±ã€‚æ‰€ä»¥<em>TIME_WAITçŠ¶æ€å°±æ˜¯ç”¨æ¥é‡å‘å¯èƒ½ä¸¢å¤±çš„ACKæŠ¥æ–‡</em></li></ul></li></ul><p><img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-62.png"></p><p><em>æ‹¥å¡æ§åˆ¶åŸç†</em> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-63.png"></p><ul><li>æˆå› <ul><li>å½“å¯¹ç½‘ç»œä¸­<em>æŸç§èµ„æºçš„éœ€æ±‚è¶…è¿‡äº†å…¶å¯ç”¨éƒ¨åˆ†</em>ã€‚æ‰€å‡ºç°çš„ç½‘ç»œæ€§èƒ½å˜å·®ç›´è‡³ç³»ç»Ÿå´©æºƒç°è±¡</li><li><em>Î£å¯¹èµ„æºçš„éœ€æ±‚ &gt; å¯ç”¨èµ„æº</em></li></ul></li><li>æ€è·¯<ul><li>å¢åŠ ç“¶é¢ˆèµ„æº</li><li><strong>æŠ‘åˆ¶æµé‡æ³¨å…¥</strong></li><li>é—­ç¯æ§åˆ¶</li></ul></li><li>æ–¹æ³•<ul><li>ç«¯åˆ°ç«¯çš„æ‹¥å¡æ§åˆ¶<ul><li>ä¸èƒ½ä»ç½‘ç»œå¾—åˆ°æ˜ç¡®çš„åé¦ˆ</li><li>ä»ç«¯ç³»ç»Ÿæ ¹æ®è§‚å¯Ÿåˆ°çš„æ—¶å»¶/ä¸¢å¤±æ¨æ–­å‡ºæ‹¥å¡</li><li>TCPâœ…</li></ul></li><li>ç½‘ç»œè¾…åŠ©çš„æ‹¥å¡æ§åˆ¶<ul><li>è·¯ç”±å™¨ä¸ºç«¯ç³»ç»Ÿæä¾›åé¦ˆ</li></ul></li></ul></li></ul><p>ä½œä¸š</p><ol type="1"><li>è§‚å¯Ÿå›¾5-9æ‰€ç¤ºçš„TCPæŠ¥æ–‡æ®µç»“æ„ï¼Œå…¶ä¸­å“ªäº›å­—æ®µåˆ†åˆ«ä¸å¤šè·¯å¤ç”¨/åˆ†è§£åŠŸèƒ½æœ‰å…³?å“ªäº›å­—æ®µåˆ†åˆ«ä¸å¯é æ•°æ®ä¼ è¾“åŠŸèƒ½æœ‰å…³?å“ªäº›å­—æ®µåˆ†åˆ«ä¸æµé‡æ§åˆ¶åŠŸèƒ½æœ‰å…³?å“ªäº›å­—æ®µåˆ†åˆ«ä¸æ‹¥å¡æ§åˆ¶ä¼ è¾“åŠŸèƒ½æœ‰å…³? ç­”ï¼šæºç«¯å£å’Œç›®çš„ç«¯å£ï¼›åºå·ã€ç¡®è®¤å·å’Œæ£€éªŒå’Œï¼›çª—å£å¤§å°ï¼›åºå·å’Œç¡®è®¤å·</li><li>TCPåˆ›å»ºè¿æ¥é‡‡ç”¨äº†ä¸‰æ¬¡æ¡æ‰‹è¿‡ç¨‹ã€‚åˆ†æç¬¬ä¸‰æ¬¡æ¡æ‰‹æœ‰ä½•ä½œç”¨?å½“TCPä¸€ç«¯é‡Šæ”¾è¿æ¥åï¼Œè¿™ç«¯æ˜¯å¦è¿˜èƒ½å¤Ÿå‘é€æŠ¥æ–‡æ®µ?æ­¤æ—¶ï¼Œå¦ä¸€ç«¯æ˜¯å¦è¿˜èƒ½å¤Ÿç»§ç»­å‘é€æŠ¥æ–‡æ®µ? ç­”ï¼š<em>åœ¨ TCP åˆ›å»ºè¿æ¥çš„ä¸‰æ¬¡æ¡æ‰‹è¿‡ç¨‹ä¸­ï¼Œç¬¬ä¸‰æ¬¡æ¡æ‰‹è¡¨æ˜ç¬¬ä¸€æ¬¡æ¡æ‰‹çš„ç¡® æ˜¯è‡ªå·±å‘é€çš„ï¼Œä»¥é˜²æ­¢ç¬¬ä¸€æ¬¡æ¡æ‰‹æ˜¯ä»¥å‰é—ç•™çš„è¿æ¥</em>ã€‚ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-64.png"></li><li>ç½‘ç»œæ‹¥å¡çš„ä¸»è¦æˆå› æœ‰å“ªäº›?å®ƒä»¬å¸¦æ¥çš„å±å®³åˆ†åˆ«æœ‰å“ªäº›?æœ‰å“ªå‡ ç§ç½‘ç»œæ‹¥å¡æ§åˆ¶æ–¹æ³•? ç­”ï¼šç«¯åˆ°ç«¯ï¼›ç½‘ç»œè¾…åŠ©</li><li>åˆ†æäº§ç”Ÿç½‘ç»œæ‹¥å¡æ¡ä»¶çš„å¼(5-6)ï¼Œå…¶ä¸­çš„èµ„æºé€šå¸¸åŒ…æ‹¬å“ªäº›å†…å®¹?è¯¥å…¬å¼èƒ½å¤Ÿä¸ºè®¾è®¡å’Œè§£å†³ç½‘ç»œç®¡ç†å’Œç½‘ç»œå®‰å…¨æ–¹æ¡ˆåŠé—®é¢˜æä¾›å“ªäº›æ€è·¯?</li></ol><h3><span id="tcpæ‹¥å¡æ§åˆ¶">TCPæ‹¥å¡æ§åˆ¶</span></h3><p>TCPæ„ŸçŸ¥æ‹¥å¡æ–¹æ³•</p><ul><li>TCPæ‹¥å¡æ§åˆ¶ï¼š<strong>ç«¯ç³»ç»Ÿ</strong>é‡‡å–æªæ–½ä½¿ç½‘ç»œä¸è‡´æ‹¥å¡</li><li><em>è¶…æ—¶</em>ï¼šç¡®è®¤æŠ¥æ–‡æ²¡æœ‰åŠæ—¶è¿”å›ï¼Œåˆ¤æ–­æŠ¥æ–‡æ®µâ€œä¸¢å¤±â€ï¼Œå³å‡ºç°äº†<em>ç½‘ç»œæ‹¥å¡</em></li><li><em>å†—ä½™ACK</em>ï¼šå¤šæ¬¡æ”¶åˆ°å¯¹æŸä¸ªæŠ¥æ–‡æ®µçš„ACK<ul><li>æŠ¥æ–‡<em>æœªæŒ‰åº</em>è¾¾åˆ°ï¼Œåªèƒ½å¯¹æŒ‰åºæ¥æ”¶åˆ°çš„æœ€åä¸€å­—èŠ‚æ•°æ®é‡å¤ç¡®è®¤</li></ul></li><li>ä¸¢åŒ…äº‹ä»¶<ul><li>æŸTCPæŠ¥æ–‡æ®µ<em>ç¡®è®¤è¶…æ—¶</em></li><li>æ”¶åˆ°å¯¹ç›¸åŒæŠ¥æ–‡æ®µçš„<em>3ä¸ªå†—ä½™ACK</em></li></ul></li><li>æ§åˆ¶å‘é€é€Ÿç‡æ–¹æ³•<ul><li>ç»´æŠ¤ä¸€ä¸ª<strong>æ‹¥å¡çª—å£</strong><code>CWin</code></li><li><code>å‘é€çª—å£ä¸Šé™å€¼ â‰¤ min{CWin, RWin}</code></li></ul></li></ul><p><strong>TCPæ‹¥å¡æ§åˆ¶æœºåˆ¶</strong></p><ul><li>åŸºæœ¬æ€æƒ³<ul><li>å½“<em>å‡ºç°ä¸¢åŒ…äº‹ä»¶</em>æ—¶ï¼Œ<strong>è¿…é€Ÿ</strong><em>å‡å°æ‹¥å¡çª—å£CWin</em> çš„é•¿åº¦ï¼Œä½¿å‘é€æ–¹é™ä½å…¶å‘é€é€Ÿç‡ï¼Œè€Œ<em>ä¸€èˆ¬æƒ…å†µä¸‹</em>åˆ™é¡»<strong>è°¨æ…</strong>åœ°<em>å¢åŠ  CWin</em> çš„é•¿åº¦ã€‚</li></ul></li><li><strong>æ…¢å¯åŠ¨ï¼ˆSSï¼‰</strong><ul><li>åŸºæœ¬æ€æƒ³<ul><li>å…ˆ<em>ä»è¾ƒå°</em>çš„æ‹¥å¡çª—å£(å¦‚1ä¸ª MSS)<em>å¼€å§‹</em>ï¼Œ<em>é€æ­¥è¯•æ¢å‡º</em>ç½‘ç»œçŠ¶æ€ï¼Œè€Œè¯•æ¢çš„å¢é•¿é€Ÿç‡è¦è¿…é€Ÿï¼Œç›´è‡³æ¥è¿‘æŸä¸ªé˜ˆå€¼</li></ul></li><li>è¿æ¥å¼€å§‹æ—¶ï¼Œæ‹¥å¡çª—å£<code>CWin = 1 MSS</code></li><li>ä»¥<em>æŒ‡æ•°ç‡</em>å¿«é€Ÿå¢åŠ é€Ÿç‡ï¼Œç›´åˆ°è¿›å…¥<strong>æ‹¥å¡é¿å…åŒºåŸŸ</strong>æˆ–<strong>å‘ç”Ÿä¸¢åŒ…</strong><ul><li><strong>Â æ¯æ”¶åˆ°ACK</strong>ï¼Œæ‹¥å¡çª—å£<code>CWin = CWin + 1</code>ï¼Œå‘ˆç°å€å¢æ•ˆæœ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-65.png"></li></ul></li><li>æ€»ç»“ï¼šåˆå§‹é€Ÿç‡å¾ˆä½ï¼Œä½†ä»¥æŒ‡æ•°ç‡å¿«é€Ÿå¢åŠ </li></ul></li><li><strong>åŠ æ€§å¢å’Œä¹˜æ€§å‡ï¼ˆAIMDï¼‰</strong><ul><li>åŠ æ€§å¢<ul><li>åŸºæœ¬æ€æƒ³<ul><li>å½“ç½‘ç»œå¯èƒ½è¿›å…¥æ‹¥å¡çŠ¶æ€æ—¶ï¼Œå°†<em>æŒ‡æ•°å¢é•¿</em>çš„å‘é€é€Ÿç‡é™ä½ä¸º<em>çº¿æ€§å¢é•¿</em>çš„å‘é€é€Ÿç‡</li></ul></li><li>å¦‚<strong>æ²¡æœ‰</strong>æ£€æµ‹åˆ°ä¸¢åŒ…äº‹ä»¶ï¼Œ <strong>æ¯ä¸ªRTT</strong>æ—¶é—´æ‹¥å¡çª—å£å€¼<code>CWin = CWin + 1</code></li><li><strong>çŠ¶æ€å˜é‡ssthresh</strong>ï¼šä»æ…¢å¯åŠ¨é˜¶æ®µè¿›å…¥æ‹¥å¡é¿å…é˜¶æ®µçš„<em>é˜ˆå€¼</em></li></ul></li><li>ä¹˜æ€§å‡<ul><li>åŸºæœ¬æ€æƒ³<ul><li>æ€¥å‰§å‡å°æ‹¥å¡çª—å£</li></ul></li><li><strong>è¶…æ—¶äº‹ä»¶</strong>åï¼š<ul><li><code>ssthresh = CWin / 2</code></li><li><code>CWin = 1</code></li><li>é‡æ–°è¿›å…¥<em>æ…¢å¯åŠ¨</em></li></ul></li><li>æ”¶åˆ°<strong>3ä¸ªå†—ä½™ACK</strong>åï¼ˆRenoï¼‰ï¼š<ul><li><code>ssthresh = CWin / 2</code></li><li><code>CWin = CWin / 2</code></li><li>ç»§ç»­<em>åŠ æ€§å¢</em> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-66.png"></li></ul></li></ul></li></ul></li><li>å°ç»“<ul><li>å½“<code>CWin &lt; ssthresh</code>æ—¶ï¼Œå‘é€æ–¹å¤„äº<strong>æ…¢å¯åŠ¨</strong>é˜¶æ®µ, CWin<strong>æŒ‡æ•°å¢é•¿</strong></li><li>å½“<code>CWin &gt; ssthresh</code>æ—¶ï¼Œå‘é€æ–¹å¤„äº<strong>æ‹¥å¡é¿å…</strong>é˜¶ æ®µ, CWin<strong>çº¿æ€§å¢é•¿</strong></li><li>å½“å‡ºç°<strong>3ä¸ªå†—ä½™ç¡®è®¤</strong>æ—¶, é˜ˆå€¼<code>ssthresh = CWin/2</code>ï¼Œä¸”<code>CWin = ssthresh</code>å<strong>çº¿æ€§å¢é•¿</strong></li><li>å½“<strong>è¶…æ—¶</strong>å‘ç”Ÿæ—¶ï¼Œé˜ˆå€¼<code>ssthresh = CWin/2</code>ï¼Œå¹¶ ä¸”<code>CWin = 1 MSS</code>å<strong>æ…¢å¯åŠ¨</strong> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-67.png"></li></ul></li><li>å¿«é€Ÿé‡ä¼ ï¼ˆFast Retransmitï¼‰<ul><li>ä¸€æ—¦å¯¹æŸæŠ¥æ–‡æ®µæ”¶åˆ°äº†3ä¸ªå†—ä½™ACKï¼Œå¯ä»¥åœ¨è¯¥æŠ¥æ–‡æ®µçš„<strong>å®šæ—¶å™¨è¿‡æœŸä¹‹å‰</strong>å°±é‡ä¼ ä¸¢å¤±çš„æŠ¥æ–‡æ®µ</li></ul></li><li>å¿«é€Ÿæ¢å¤ï¼ˆFast Recoveryï¼‰<ul><li>å¯¹<em>TCP Tahoe</em>ï¼Œå½“å‘ç”Ÿä¸¢åŒ…äº‹ä»¶ï¼Œç«‹å³å°†æ‹¥å¡çª—å£å‡ é€Ÿè‡³1 MSSï¼Œç„¶åè½¬å…¥æ…¢å¯åŠ¨é˜¶æ®µ</li><li>å¯¹æ–°ç‰ˆ<em>TCP Reno</em>ï¼Œä¸€æ—¦æ”¶åˆ°3ä¸ªå†—ä½™ACKåï¼Œ å–æ¶ˆæ…¢å¯åŠ¨å¹¶è½¬å…¥æ‹¥å¡é¿å…é˜¶æ®µ</li></ul></li></ul><p>TCPçš„å…¬å¹³æ€§ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-68.png"> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-69.png"></p><ul><li>å¤šåª’ä½“åº”ç”¨ä¸å¸Œæœ›ç”¨TCP</li><li>TCPå¯¹ç”¨æˆ·å…¬å¹³ä¸”ç¨³å®šç½‘ç»œï¼ŒTCPå‹å¥½(TCP friendly)</li><li>ä¸èƒ½é˜²æ­¢2å°ä¸»æœºä¹‹é—´æ‰“å¼€å¤šä¸ªå¹¶è¡Œè¿æ¥</li></ul><p>ä½œä¸š</p><ol type="1"><li>TCPæ‹¥å¡æ§åˆ¶çš„åŸºæœ¬æ€æƒ³æ˜¯ä»€ä¹ˆ?æœ‰å“ªäº›åŸºæœ¬æ‹¥å¡æ§åˆ¶æœº åˆ¶?è¯•ç®€è¦é˜è¿°å®ƒä»¬çš„åŸºæœ¬æ€æƒ³</li><li>è€ƒè™‘ä¸‹å›¾ä¸­TCPçª—å£é•¿åº¦ä½œä¸ºæ—¶é—´çš„å‡½æ•°ã€‚ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-70.png"> å‡è®¾<em>TCP Reno</em>æ˜¯ä¸€ä¸ªç»å†å¦‚ä¸Šæ‰€ç¤ºè¡Œä¸ºçš„åè®®ï¼Œå›ç­”ä¸‹åˆ—é—®é¢˜ã€‚åœ¨å„ç§æƒ…å†µä¸­ï¼Œè¯·ç®€è¦åœ°è®ºè¯ä½ çš„å›ç­”<ol type="1"><li>æŒ‡å‡ºå½“TCPæ…¢å¯åŠ¨è¿è¡Œæ—¶çš„æ—¶é—´é—´éš”</li><li>æŒ‡å‡ºå½“TCPæ‹¥å¡é¿å…è¿è¡Œæ—¶çš„æ—¶é—´é—´éš”</li><li>åœ¨ç¬¬16ä¸ªä¼ è¾“è½®å›ä¹‹åï¼ŒæŠ¥æ–‡æ®µçš„ä¸¢å¤±æ˜¯æ ¹æ®3ä¸ªé‡å¤ç¡®è®¤è¿˜æ˜¯æ ¹æ®è¶…æ—¶ æ£€æµ‹å‡ºæ¥çš„?</li><li>åœ¨ç¬¬22ä¸ªä¼ è¾“è½®å›ä¹‹åï¼ŒæŠ¥æ–‡æ®µçš„ä¸¢å¤±æ˜¯æ ¹æ®3ä¸ªé‡å¤ç¡®è®¤è¿˜æ˜¯æ ¹æ®è¶…æ—¶ æ£€æµ‹å‡ºæ¥çš„?</li><li>åœ¨ç¬¬ä¸€ä¸ªä¼ è¾“è½®å›é‡Œï¼Œssthreshçš„åˆå§‹å€¼è®¾ç½®ä¸ºå¤šå°‘?</li><li>åœ¨ç¬¬18ä¸ªä¼ è¾“è½®å›é‡Œï¼Œssthreshçš„å€¼è®¾ç½®ä¸ºå¤šå°‘?</li><li>åœ¨ç¬¬24ä¸ªä¼ è¾“è½®å›é‡Œï¼Œssthreshçš„å€¼è®¾ç½®ä¸ºå¤šå°‘?</li><li>ç¬¬70ä¸ªæŠ¥æ–‡æ®µåœ¨å“ªä¸€ä¸ªä¼ è¾“è½®å›å†…å‘é€?</li><li>å‡å®šåœ¨ç¬¬26ä¸ªå‘é€è½®å›åï¼Œé€šè¿‡æ”¶åˆ°3ä¸ªå†—ä½™ACKæ£€æµ‹å‡ºæœ‰åˆ†ç»„ä¸¢å¤±ï¼Œæ‹¥å¡çš„çª—å£é•¿åº¦å’Œssthreshçš„å€¼å°†åº”å½“æ˜¯å¤šå°‘?</li></ol></li><li>è‹¥é€šä¿¡ä¿¡é“å¸¦å®½ä¸º1Gbps,ä¸¤ä¸ªç«¯ç³»ç»Ÿä¹‹é—´çš„æ—¶å»¶ä¸º 15msï¼Œè€ŒTCPçš„å‘é€çª—å£æœ€å¤§ä¸º65535å­—èŠ‚ã€‚è¯•è®¡ç®—:èƒ½è¾¾åˆ°çš„æœ€å¤§ååé‡æ˜¯å¤šå°‘?ä¿¡é“çš„åˆ©ç”¨ç‡æ˜¯å¤šå°‘?</li></ol><h2><span id="ç½‘ç»œåº”ç”¨åè®®">ç½‘ç»œåº”ç”¨åè®®</span></h2><h3><span id="åŸŸåç³»ç»Ÿdns">åŸŸåç³»ç»ŸDNS</span></h3><p>åŸŸåç³»ç»Ÿ</p><ul><li><em>åˆ†å¸ƒå¼æ•°æ®åº“</em>:ç”±å±‚æ¬¡åŒ–çš„è®¸å¤šåå­—æœåŠ¡å™¨å®ç°</li><li><em>åº”ç”¨å±‚åè®®</em>ï¼šä¸»æœºã€è·¯ç”±å™¨ã€ åå­—æœåŠ¡å™¨é—´é€šä¿¡ï¼Œä»¥è§£æåå­— (è¿›è¡Œåœ°å€/åå­—è½¬æ¢)<ul><li>ä¾›åº”ç”¨ç¨‹åºè€Œä¸æ˜¯äººç›´æ¥ä½¿ç”¨</li><li>å› ç‰¹ç½‘æ ¸å¿ƒåŠŸèƒ½ï¼Œä½œä¸ºåº”ç”¨å±‚åè®®å®ç°</li><li>å¤æ‚æ€§ä½äºç½‘ç»œâ€œè¾¹ç¼˜â€</li></ul></li><li>åŸŸåç³»ç»Ÿç»´æŠ¤äº†ä¸€ç»„åå­—åˆ°å€¼çš„æ˜ å°„å…³ç³»</li><li>ç»™å®šä¸€ä¸ªä¸»æœºåï¼ŒåŸŸåç³»ç»Ÿè§£æè¿”å›ä¸€ä¸ªå€¼ï¼Œ å¦‚IPåœ°å€</li><li>DNSåè®®è¿è¡Œåœ¨<strong>UDP</strong>ä¹‹ä¸Šï¼Œä½¿ç”¨53å·ç«¯å£ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-71.png"> <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-72.png"></li><li>ç±»å‹<ul><li>æ ¹åŸŸåæœåŠ¡å™¨(root name server)<ul><li>è´Ÿè´£com, org, net, eduç­‰ï¼Œä»¥åŠæ‰€æœ‰é¡¶çº§å›½å®¶åŸŸcnã€ukç­‰</li></ul></li><li>é¡¶çº§åŸŸåæœåŠ¡å™¨(top-level domainï¼ŒTLD)<ul><li>è´Ÿè´£ç®¡ç†åœ¨è¯¥é¡¶çº§åŸŸåæœåŠ¡å™¨æ³¨å†Œçš„æ‰€æœ‰äºŒçº§åŸŸå</li></ul></li><li>æƒå¨åŸŸåæœåŠ¡å™¨(authoritative name server)<ul><li>ä¸ºæœ¬ç»„ç»‡çš„æœåŠ¡å™¨(å¦‚Webå’Œç”µå­é‚®ä»¶)æä¾›æ˜ å°„ï¼Œé€šå¸¸æœ‰åŸºæœ¬ã€è¾…åŠ©(å¤‡ä»½)æœåŠ¡å™¨</li></ul></li><li>æœ¬åœ°åŸŸåæœåŠ¡å™¨(local name server)<ul><li>é»˜è®¤åŸŸåæœåŠ¡å™¨</li></ul></li></ul></li><li>äº¤äº’<ul><li>é€’å½’æŸ¥è¯¢(recursive query)</li><li>è¿­ä»£æŸ¥è¯¢(iterative query)<ul><li>å3ä¸ªæŸ¥è¯¢</li></ul></li></ul></li></ul><p>ä½œä¸š</p><ol type="1"><li>å¦‚æœåœ¨æœ¬åœ°åŸŸåæœåŠ¡å™¨ã€æ ¹æœåŠ¡å™¨å’Œé¡¶çº§åŸŸåæœåŠ¡å™¨çš„æ— æ³•æ‰¾åˆ°æŸå…¬å¸çš„åŸŸåï¼Œè¯·é˜è¿°è§£æè¯¥å…¬å¸åŸŸåçš„è¿‡ç¨‹ ç­”ï¼šä¸»æœºè¦ç»è¿‡å¦‚ä¸‹è¿‡ç¨‹: (1)DNS æŸ¥è¯¢æŠ¥æ–‡å‘å‘æœ¬åœ° DNS æœåŠ¡å™¨ï¼Œå®ƒå°†æŸ¥è¯¢è½¬å‘åˆ°æƒå¨ DNS æœåŠ¡å™¨; (2)DNS æƒå¨æœåŠ¡å™¨å°†æŸ¥è¯¢è½¬å‘åˆ°é¡¶çº§åŸŸåæœåŠ¡å™¨; (3)é¡¶çº§åŸŸåæœåŠ¡å™¨å°†æŸ¥è¯¢è½¬å‘åˆ°æ ¹åŸŸåæœåŠ¡å™¨; (4)è·ŸåŸŸåæœåŠ¡å™¨åœ¨ com é¡¶çº§åŸŸåæœåŠ¡å™¨è§£æè¯¥å…¬å¸çš„æƒå¨æœåŠ¡å™¨; (5)ç”±æƒå¨æœåŠ¡å™¨å°±å¯ä»¥è§£æåˆ°è¯¥å…¬å¸çš„æœ¬åœ°åŸŸåæœåŠ¡å™¨ã€‚</li><li>å¯¹åŒä¸€ä¸ªåŸŸåå‘DNSæœåŠ¡å™¨å‘å‡ºå¥½å‡ æ¬¡çš„DNSè¯·æ±‚æŠ¥æ–‡åï¼Œ æ¯ä¸€æ¬¡å¾—åˆ°IPåœ°å€éƒ½ä¸ä¸€æ ·ã€‚è¿™å¯èƒ½å—? ç­”ï¼šå¦‚æœä¸€ä¸ªåŸŸåä¸å¤šä¸ª IP åœ°å€å¯¹åº”ï¼Œè¿™æ˜¯å¯èƒ½çš„ã€‚è¿™ç§æŠ€æœ¯å¯ç”¨äºè´Ÿè½½ å‡è¡¡åœºåˆã€‚</li><li>ç”µå­é‚®ä»¶ç³»ç»Ÿåœ¨è¿è¾“å±‚ä½¿ç”¨äº†TCPæ¥ä¼ é€é‚®ä»¶ã€‚ä¸ºä»€ä¹ˆè¿˜ä¼šæœ‰å‘é€çš„ç”µå­é‚®ä»¶å¯¹æ–¹æ²¡æœ‰æ”¶åˆ°çš„æƒ…å†µå‡ºç°?è¯·è§£é‡ŠåŸå› ã€‚ ç­”ï¼šä¸€ä»½ç”µå­é‚®ä»¶å¿…è¦ç»è¿‡: (1)ä»å‘é€æ–¹ç”¨æˆ·ä»£ç†é€šè¿‡ SMTP å‘å‘é€æ–¹ é‚®ä»¶æœåŠ¡å™¨ (2)å‘é€æ–¹é‚®ä»¶æœåŠ¡å™¨é€šè¿‡ SMTP å‘æ¥æ”¶æ–¹é‚®ä»¶æœåŠ¡å™¨å‘é€é‚®ä»¶ (3)æ¥æ”¶æ–¹ç”¨æˆ·ä»£ç†ç”¨ POP3 æˆ– IMAP ä»æ¥æ”¶æ–¹é‚®ä»¶æœåŠ¡å™¨è¯»å–é‚®ä»¶ ç­‰ 3 ä¸ªç¯èŠ‚ã€‚ å°½ç®¡æ¯ä¸ªåº”ç”¨åè®®éƒ½æ˜¯åŸºäº TCP çš„ï¼Œå¯ä»¥ä¿è¯é‚®ä»¶æ¯æ¬¡ç«¯åˆ°ç«¯ä¼ è¾“çš„å¯é  æ€§ï¼Œä½†å¹¶ä¸èƒ½ä¿è¯:<ol type="1"><li>åœ¨å‘é€é‚®ä»¶æœåŠ¡å™¨æˆ–æ¥æ”¶é‚®ä»¶æœåŠ¡å™¨å› æœåŠ¡å™¨æ•…éšœæˆ–ç¼“å­˜æº¢ç­‰åŸå› å¯¼è‡´çš„é‚®ä»¶ä¸¢å¤±;</li><li>é‚®ä»¶æœåŠ¡å™¨æœªå·¥ä½œï¼Œé‚®ä»¶å‘é€ä¸å‡ºå»ã€‚ç”µå­é‚®ä»¶æœ¬èº«å¹¶æ²¡æœ‰ç«¯åˆ°ç«¯çš„å¯é æ€§ä¿éšœæœºåˆ¶ã€‚</li></ol></li></ol><h3><span id="http">HTTP</span></h3><p>HTTPå·¥ä½œè¿‡ç¨‹</p><ul><li>å®¢æˆ·å‘æœåŠ¡å™¨å‘èµ·TCPè¿æ¥ï¼Œ80ç«¯å£</li><li>æœåŠ¡å™¨æ¥å—æ¥è‡ªå®¢æˆ·TCPè¿æ¥</li><li>åœ¨æµè§ˆå™¨(HTTPå®¢æˆ·)å’Œ WebæœåŠ¡å™¨(HTTPæœåŠ¡å™¨) ä¹‹é—´äº¤æ¢HTTPæŠ¥æ–‡(åº”ç”¨å±‚åè®®æŠ¥æ–‡)</li><li>å…³é—­TCP è¿æ¥</li><li>HTTPæ˜¯<strong>æ— çŠ¶æ€çš„</strong></li><li><em>RTT</em><ul><li>ä»å®¢æˆ·åˆ°æœåŠ¡å™¨å‘é€ä¸€ä¸ªåˆ†ç»„å¹¶è¿”å›æ‰€å†ç»çš„æ—¶é—´</li></ul></li><li><strong>å“åº”æ—¶é—´</strong>ï¼š2RTT + ä¼ è¾“æ—¶é—´<ul><li>ä¸€ä¸ªRTTå‘èµ·TCPè¿æ¥</li><li>æ–‡ä»¶ä¼ è¾“æ—¶é—´ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-73.png"> *Â è¿æ¥æ–¹å¼</li></ul></li><li>éæŒç»­HTTP<ul><li>è‡³å¤šä¸€ä¸ªå¯¹è±¡ç»è¿‡ä¸€ä¸ªTCPè¿æ¥å‘é€</li><li>HTTP/1.0</li><li>é—®é¢˜<ul><li>æ¯ä¸ªå¯¹è±¡è¦æ±‚2RTT</li><li>æ“ä½œç³»ç»Ÿå¿…é¡»ä¸ºæ¯ä¸ªTCPè¿ æ¥å·¥ä½œå¹¶é€ä¸ªåˆ†é…èµ„æº</li><li>ä½†æµè§ˆå™¨ç»å¸¸æ‰“å¼€å¹¶è¡ŒTCP è¿æ¥ä»¥è·å–å¼•ç”¨çš„å¯¹è±¡</li></ul></li></ul></li><li><strong>æŒç»­HTTP</strong><ul><li>å¤šä¸ªå¯¹è±¡èƒ½å¤Ÿç»è¿‡å®¢æˆ·å’ŒæœåŠ¡å™¨ä¹‹é—´çš„å•ä¸ªTCPè¿æ¥å‘é€</li><li>æ— æµæ°´çº¿çš„æŒç»­<ul><li>ä»…å½“å‰é¢çš„å“åº”å·²ç»æ”¶åˆ°ï¼Œå®¢æˆ·æ‰å‘å‡ºæ–°çš„è¯·æ±‚</li><li>å¯¹æ¯ä¸ªå¼•ç”¨å¯¹è±¡ç”¨1RTT</li></ul></li><li>æœ‰æµæ°´çº¿çš„æŒç»­<ul><li>HTTP/1.1</li><li>åªè¦å®¢æˆ·é‡åˆ°ä¸€ä¸ªå¼•ç”¨å¯¹è±¡ï¼Œ å®ƒå‘é€è¯·æ±‚</li></ul></li><li>ä¾‹å­ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-74.png"><ul><li>åŸºæœ¬HTMLæ–‡ä»¶ã€8ä¸ªå›¾ç‰‡å’Œ5ä¸ªè§†é¢‘</li><li>æµæ°´çº¿æŒç»­è¿æ¥çš„å“åº”æ—¶é—´<ul><li><code>2 * RTT + 8 * t1 + 5 * t2</code></li></ul></li><li>æ— æµæ°´æŒç»­è¿æ¥çš„å“åº”æ—¶é—´<ul><li><code>RTT + 8 * (RTT + t1) + 5 * (RTT + t2) = 14 * RTT + 8 * t1 + 5 * t2</code></li></ul></li><li>å¹¶è¡ŒéæŒç»­è¿æ¥çš„å“åº”æ—¶é—´<ul><li><code>2 * RTT + t2</code></li><li>æœåŠ¡å™¨è´Ÿæ‹…å¤§</li><li>å¯¹è±¡å°æ—¶å¼€é”€å¤§</li></ul></li></ul></li></ul></li></ul><p>è¯·æ±‚æŠ¥æ–‡æ ¼å¼ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-75.png"></p><p>å“åº”æŠ¥æ–‡æ ¼å¼ <img src="/images/è®¡ç®—æœºç½‘ç»œ/DraggedImage-76.png"></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> è®¡ç®—æœºç½‘ç»œ </tag>
            
            <tag> TCP/IP </tag>
            
            <tag> æœ¬ç§‘è¯¾ç¨‹ </tag>
            
            <tag> UDP </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯</title>
      <link href="/2017/06/29/%E7%89%A9%E8%81%94%E7%BD%91%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"/>
      <url>/2017/06/29/%E7%89%A9%E8%81%94%E7%BD%91%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#æ— çº¿é€šä¿¡åŸºç¡€">æ— çº¿é€šä¿¡åŸºç¡€</a><ul><li><a href="#ä¿¡å·ä¼ è¾“">ä¿¡å·ä¼ è¾“</a></li><li><a href="#ç¼–ç å’Œè°ƒåˆ¶">ç¼–ç å’Œè°ƒåˆ¶</a></li></ul></li><li><a href="#æ— çº¿ç½‘ç»œåŸºç¡€">æ— çº¿ç½‘ç»œåŸºç¡€</a><ul><li><a href="#å¤šå€æ¥å…¥mac">å¤šå€æ¥å…¥ï¼ˆMACï¼‰</a></li></ul></li><li><a href="#802154zigbee">802.15.4/Zigbee</a><ul><li><a href="#æ¦‚è¿°">æ¦‚è¿°</a></li><li><a href="#ç‰©ç†å±‚">ç‰©ç†å±‚</a></li><li><a href="#macå±‚">MACå±‚</a></li><li><a href="#ç½‘ç»œå±‚">ç½‘ç»œå±‚</a></li><li><a href="#tinyos">TinyOS</a></li></ul></li><li><a href="#æ— çº¿å±€åŸŸç½‘">æ— çº¿å±€åŸŸç½‘</a><ul><li><a href="#macå±‚-1">MACå±‚</a></li><li><a href="#åŠŸè€—ç®¡ç†">åŠŸè€—ç®¡ç†</a></li></ul></li><li><a href="#æ— çº¿å¹¿åŸŸç½‘">æ— çº¿å¹¿åŸŸç½‘</a><ul><li><a href="#å¤§å®¹é‡çš„å°åŒºåˆ¶åˆ©ç”¨æœ‰é™é¢‘æ®µè¦†ç›–æ— é™å¤§é¢ç§¯">å¤§å®¹é‡çš„å°åŒºåˆ¶ï¼šåˆ©ç”¨æœ‰é™é¢‘æ®µè¦†ç›–æ— é™å¤§é¢ç§¯</a></li><li><a href="#gsmgprs">GSM/GPRS</a></li><li><a href="#cdma">CDMA</a></li><li><a href="#3g">3G</a></li></ul></li><li><a href="#ç‰©è”ç½‘é€šä¿¡æ¶æ„">ç‰©è”ç½‘é€šä¿¡æ¶æ„</a><ul><li><a href="#åŸºäºipçš„ç‰©è”ç½‘é€šä¿¡æ¶æ„">åŸºäºIPçš„ç‰©è”ç½‘é€šä¿¡æ¶æ„</a></li><li><a href="#6lowpan">6LowPAN</a></li></ul></li><li><a href="#å„ç§æŠ€æœ¯å¯¹æ¯”">å„ç§æŠ€æœ¯å¯¹æ¯”ï¼</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="æ— çº¿é€šä¿¡åŸºç¡€">æ— çº¿é€šä¿¡åŸºç¡€</span></h2><h3><span id="ä¿¡å·ä¼ è¾“">ä¿¡å·ä¼ è¾“</span></h3><p><em>ä¿¡å·</em></p><ul><li>æ—¶åŸŸæ¦‚å¿µ<ul><li>æ¨¡æ‹Ÿä¿¡å·</li><li>æ•°å­—ä¿¡å·</li><li>å‘¨æœŸä¿¡å·</li><li>éå‘¨æœŸä¿¡å·</li></ul></li><li>é¢‘åŸŸæ¦‚å¿µ<ul><li>ä¸€ä¸ªç”µç£ä¿¡å·ç”±å¤šç§é¢‘ç‡æˆåˆ†ç»„æˆ</li><li>åŸºé¢‘ï¼šå½“ä¸€ä¸ªä¿¡å·çš„æ‰€æœ‰é¢‘ç‡æˆåˆ†éƒ½æ˜¯æŸä¸ªé¢‘ç‡çš„æ•´æ•°å€æ—¶ï¼Œåè€…ç§°ä¸ºåŸºé¢‘</li><li>é¢‘è°±ï¼šä¸€ä¸ªä¿¡å·åŒ…æ¶µçš„é¢‘ç‡èŒƒå›´</li><li>ç»å¯¹å¸¦å®½ï¼šä¸€ä¸ªä¿¡å·çš„é¢‘è°±å®½åº¦</li><li>æœ‰æ•ˆå¸¦å®½ï¼šä¸€ä¸ªä¿¡å·çš„ç»å¤§éƒ¨åˆ†èƒ½é‡é›†ä¸­åœ¨ç›¸å½“çª„çš„é¢‘å¸¦å†…</li></ul></li><li>æ•°æ®ä¸ä¿¡å·<ul><li>æ•°æ®ï¼šä¼ è¾¾æŸç§æ„ä¹‰æˆ–ä¿¡æ¯çš„å®ä½“</li><li>ä¿¡å·ï¼šæ•°æ®çš„ç”µæ°”æˆ–ç”µç£è¡¨ç¤º</li><li>ä¼ è¾“ï¼šé€šè¿‡ä¿¡å·çš„ä¼ æ’­å’Œå¤„ç†è¿›è¡Œæ•°æ®é€šä¿¡çš„è¿‡ç¨‹</li></ul></li><li>æ•°æ®ç‡ä¸å¸¦å®½ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-1.png"><ul><li>æ•°æ®ç‡ï¼šæ•°æ®èƒ½å¤Ÿè¿›è¡Œé€šä¿¡çš„é€Ÿç‡ï¼Œå•ä½b/s<ul><li>æ•°æ®ç‡ = 2*åŸºé¢‘</li></ul></li><li>å¸¦å®½ï¼šä¼ è¾“ä¿¡å·çš„å¸¦å®½ï¼Œå—å‘é€å™¨å’Œä¼ è¾“åª’ä½“é™åˆ¶<ul><li>ä¿¡é“æ— å™ªå£°ï¼šå°¼å¥æ–¯ç‰¹å¸¦å®½ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-2.png"><ul><li>Bï¼šå¸¦å®½</li></ul></li><li>ä¿¡é“æœ‰å™ªå£°<ul><li>ä¿¡å™ªæ¯”ï¼ŒSNR, S/Nï¼šä¿¡å·åŠŸç‡ï¼å™ªå£°åŠŸç‡ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-3.png"></li><li>åˆ†è´ï¼šç”¨æ¥è¡¨ç¤ºä¿¡å·å¼ºåº¦çš„å¢ç›Šã€æŸè€—ä»¥åŠ<em>ç›¸å¯¹å€¼</em></li><li><strong>dB &amp; dBm</strong> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-4.png"></li></ul></li></ul></li></ul></li><li>ä¿¡é“å®¹é‡ï¼šç»™å®šæ¡ä»¶ä¸‹ï¼Œåœ¨æŸä¸€é€šä¿¡çº¿è·¯ï¼ˆä¿¡é“ï¼‰ä¸Šï¼Œæ•°æ®å¯ä»¥è¢«ä¼ è¾“çš„æœ€å¤§é€Ÿç‡<ul><li>é¦™å†œå®¹é‡å…¬å¼ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-5.png"></li><li>ä¸¾ä¾‹ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-6.png"></li></ul></li><li>ä¼ è¾“åª’ä½“ï¼šæ•°æ®ä¼ è¾“ç³»ç»Ÿä¸­å‘é€å™¨å’Œæ¥æ”¶å™¨ä¹‹é—´çš„ç‰©ç†è·¯å¾„<ul><li>å¯¼å‘ï¼šåŒç»çº¿ã€å…‰çº¤</li><li>éå¯¼å‘ï¼šå¤§æ°”</li></ul></li><li>å¤ç”¨<ul><li>FDM</li><li>TDM</li><li>OFDMï¼šæ­£äº¤é¢‘åˆ†å¤ç”¨</li></ul></li></ul><p><em>å¤©çº¿</em></p><ul><li>å„å‘åŒæ€§å¤©çº¿</li><li>å¶æå¤©çº¿</li><li>æŠ›ç‰©åå°„å¤©çº¿</li></ul><p><strong>å¤©çº¿å¢ç›Š</strong></p><ul><li>å¤©çº¿å®šå‘æ€§åº¦é‡</li><li>å¤©çº¿å¢ç›Šå®šä¹‰ä¸º<em>åœ¨ä¸€ç‰¹å®šæ–¹å‘çš„åŠŸç‡è¾“å‡º</em>ï¼š <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-7.png"></li></ul><p>ä¼ æ’­</p><ul><li>ç›´çº¿ä¼ æ’­<ul><li><strong>è‡ªç”±ç©ºé—´æŸè€—å…¬å¼</strong><ul><li>æœªè€ƒè™‘å¤©çº¿å¢ç›Š <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-8.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-9.png"></li><li>è€ƒè™‘å¤©çº¿å¢ç›Š <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-10.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-11.png"></li></ul></li><li>å®è´¨å°±æ˜¯ç©ºé—´çš„æŸè€—å‡å»å‘é€ç«¯å’Œæ¥æ”¶ç«¯çš„å¢ç›Š</li></ul></li><li>ä¿¡å™ªæ¯”SNR <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-12.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-13.png"></li><li>è¡°å‡åŸå› <ul><li>å¤§æ°”å¸æ”¶</li><li>å¤šæ™®å‹’æ•ˆåº”</li><li>å¤šå¾„<ul><li>åå°„</li><li>è¡å°„</li><li>æ•£å°„</li></ul></li></ul></li></ul><p>è¡°è½</p><ul><li>ç”±äºä¿¡é“çš„å˜åŒ–å¯¼è‡´æ¥æ”¶ä¿¡å·çš„åŠŸç‡éšæ—¶é—´ã€åœ°ç†ä½ç½®ã€é¢‘ç‡ç­‰å˜åŒ–</li><li>æ…¢è¡°è½</li><li>å¿«è¡°è½<ul><li>æè¿°ä¿¡å·<em>å¹…å€¼</em>çš„<em>ç¬æ—¶å˜åŒ–</em>ï¼Œä¸<strong>å¤šå¾„ä¼ æ’­</strong>æœ‰å…³</li></ul></li></ul><p>æ¥æ”¶</p><ul><li>æ¥æ”¶åŸºå™ªå£°åŸºåº•<ul><li>RNF = kTW + NF</li><li>kTWï¼šç†è®ºçƒ­å™ªå£°åŸºåº•</li><li>NFï¼šå™ªå£°ç³»æ•°</li></ul></li><li><strong>æ¥æ”¶æœºçµæ•åº¦</strong> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-14.png"></li></ul><h3><span id="ç¼–ç å’Œè°ƒåˆ¶">ç¼–ç å’Œè°ƒåˆ¶</span></h3><p>æ•°å­—ä¿¡å·-æ¨¡æ‹Ÿä¿¡å·</p><ul><li>å¹…ç§»é”®æ§ï¼ˆASKï¼‰<ul><li>ç”¨æŒ¯å¹…æ’å®šçš„è½½æ³¢è¡¨ç¤ºä¸€ä¸ªäºŒè¿›åˆ¶æ•°</li><li><em>åœ¨å…‰çº¤ä¸­ä¼ æ’­æ•°å­—æ•°æ®æ—¶ä½¿ç”¨</em></li><li><strong>ä¼˜ç‚¹</strong><ul><li>ç®€å•</li></ul></li><li><strong>ç¼ºç‚¹</strong><ul><li>æœ€æ˜“å—å™ªå£°å½±å“</li><li>æ•ˆç‡ä½</li></ul></li></ul></li><li>é¢‘ç§»é”®æ§ï¼ˆFSKï¼‰<ul><li>ç”¨ä¸åŒé¢‘ç‡è¡¨ç¤ºä¸åŒçš„äºŒè¿›åˆ¶å€¼</li><li><em>ç”¨äºé«˜é¢‘ç‡æ— çº¿ï¼ˆæˆ–åŒè½´ç”µç¼†ï¼‰çš„ä¼ è¾“</em></li><li>å¤šè¿›åˆ¶ï¼šå¸¦å®½æ•ˆç‡é«˜ï¼Œä½†æ˜“å‡ºé”™</li><li><strong>ä¼˜ç‚¹</strong><ul><li>æ¯”ASKæŠ—å¹²æ‰°å¼º</li><li>ç”µå‹å™ªå£°å¯ä»¥å¿½ç•¥</li></ul></li><li><strong>ç¼ºç‚¹</strong><ul><li>éœ€è¦é¢‘è°±æœ€å¤§</li></ul></li></ul></li><li>ç›¸ç§»é”®æ§ï¼ˆPSKï¼‰<ul><li>äºŒç›¸ç›¸ç§»é”®æ§ï¼ˆBPSKï¼‰</li><li>å·®åˆ†ç›¸ç§»é”®æ§ï¼ˆDPSKï¼‰<ul><li>é€šè¿‡ä¸å‰é¢çš„ä¿¡å·æ¯”è¾ƒå†³å®šç›¸ç§»</li></ul></li><li>å››ç›¸ç›¸ç§»é”®æ§ï¼ˆQPSKï¼‰</li><li>å¤šç›¸ä½ç›¸ç§»é”®æ§</li><li><em>ç”¨é€”ï¼šå¹¿æ³›ä½¿ç”¨</em></li><li><strong>ä¼˜ç‚¹</strong><ul><li>æ¯”ASKæŠ—å¹²æ‰°å¼ºï¼Œå’ŒASKç”¨ç›¸åŒå¸¦å®½</li><li>æ¯”FSKå¸¦å®½åˆ©ç”¨ç‡é«˜</li></ul></li><li><strong>ç¼ºç‚¹</strong><ul><li>æ£€æµ‹ã€æ¢å¤ä¿¡å·æ¯”ASKã€FSKæ›´å¤æ‚</li></ul></li></ul></li><li>è®¡ç®—å¸¦å®½ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-15.png"></li></ul><h2><span id="æ— çº¿ç½‘ç»œåŸºç¡€">æ— çº¿ç½‘ç»œåŸºç¡€</span></h2><h3><span id="å¤šå€æ¥å…¥mac">å¤šå€æ¥å…¥ï¼ˆMACï¼‰</span></h3><p>MACå±‚å®šä¹‰ç”¨æˆ·éœ€è¦æ—¶å¦‚ä½•è®¿é—®æ— çº¿ä¿¡é“</p><ul><li>éšæœºè®¿é—®<ul><li>ALOHA, CSMA</li></ul></li><li>æœ‰åºè®¿é—®<ul><li>ä»¤ç‰Œæ€»çº¿ï¼ˆç¯ï¼‰</li></ul></li><li>ç¡®å®šæ€§è®¿é—®<ul><li>FDMA, TDMA, CDMA</li></ul></li><li>ç»„åˆ</li></ul><p><em>CSMAï¼šè½½æ³¢ç›‘å¬</em></p><ul><li>å‘å‰å…ˆå¬</li><li>1-æŒç»­CSMA<ul><li>ä¸€æœ‰ç©ºå°±å‘</li></ul></li><li>p-æŒç»­CSMA<ul><li>æœ‰ç©ºé—²éšæœºæ¦‚ç‡på‘é€</li></ul></li></ul><p>CSMA/CD</p><ul><li>å‘å‰å…ˆå¬ï¼Œè¾¹å‘è¾¹å¬</li><li>æ— çº¿ä¸­éš¾äºæ£€æµ‹å†²çª</li></ul><p>éšè—èŠ‚ç‚¹é—®é¢˜</p><ul><li>åœ¨æ— çº¿ç¯å¢ƒä¸­ï¼Œå½“ä¸¤ä¸ªèŠ‚ç‚¹ç›¸è·è¾ƒè¿œæ—¶ï¼Œæ— å‘è¿›è¡Œè½½æ³¢ç›‘å¬ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-16.png"></li></ul><p><strong>CSMA/CA</strong></p><ul><li>å†²çªé¿å…CA = Collision Avoidance</li><li>ç›‘å¬åˆ°ä¿¡é“ç©ºé—²ï¼Œç»´æŒä¸€æ®µæ—¶é—´åï¼Œå†éšæœºç­‰å¾…ä¸€æ®µæ—¶é—´ä»ç„¶ç©ºé—²ï¼Œæ‰æäº¤æ•°æ®</li><li>RTS-CTSæ¡æ‰‹<ul><li>è®¾å¤‡å‘é€æ•°æ®ä¹‹å‰ï¼Œå…ˆå‘é€RTSå¸§ç»™ç›®æ ‡ç«¯ï¼Œç­‰å¾…ç›®æ ‡ç«¯å›åº”CTSå¸§åæ‰å¼€å§‹å‘é€ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-17.png"></li></ul></li><li>æš´éœ²èŠ‚ç‚¹é—®é¢˜ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-18.png"></li></ul><p><em>æ€»ç»“å¯¹æ¯”</em></p><ul><li>éšæœºè®¿é—®ï¼šCSMA<ul><li><em>è½»è½½ï¼šå¿«é€Ÿå“åº”</em></li><li>é‡è½½ï¼šååé‡ä¸‹é™</li><li>å®ç°ç®€å•</li></ul></li><li>ç¡®å®šæ€§åè®®ï¼šTDMAï¼ŒFDMA<ul><li>å¸¦å®½ä¿è¯</li><li>å¹³å‡å»¶è¿Ÿè¾ƒé«˜</li><li>å»¶è¿Ÿå˜åŒ–å°</li><li>åŒæ­¥ã€åè°ƒç­‰æœºåˆ¶</li></ul></li><li>æ··åˆï¼šCSMA/TDMA<ul><li>è‡ªé€‚åº”ã€å¼€é”€å¤§</li></ul></li></ul><h2><span id="802154zigbee">802.15.4/Zigbee</span></h2><h3><span id="æ¦‚è¿°">æ¦‚è¿°</span></h3><p>ZigBeeæŠ€æœ¯ä¼˜ç‚¹</p><ol type="1"><li>ä½åŠŸè€—</li><li>ä½æˆæœ¬</li><li>ä½é€Ÿç‡</li><li>è¿‘è·ç¦»</li><li>çŸ­æ—¶å»¶</li><li>é«˜å®¹é‡</li><li>é«˜å®‰å…¨</li><li>å…æ‰§ç…§é¢‘æ®µ</li></ol><h3><span id="ç‰©ç†å±‚">ç‰©ç†å±‚</span></h3><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-19.png"></p><p>Symbol</p><ul><li>Symbolçš„å…·ä½“å†…å®¹å’Œé‡‡ç”¨çš„è°ƒåˆ¶æ–¹å¼æœ‰å…³<ul><li>2.4GHz, 4bitæ•°æ®ç”¨ä¸€ä¸ªSymbolè¡¨ç¤ºï¼Œ16ç§</li><li>å…¶ä»–ï¼Œ1bitæ•°æ®ç”¨ä¸€ä¸ªSymbolè¡¨ç¤ºï¼Œ2ç§</li></ul></li></ul><p>åŠŸèƒ½</p><ul><li>æ‰“å¼€å’Œå…³é—­æ”¶å‘å™¨</li><li>ä¿¡é“èƒ½é‡æ£€æµ‹</li><li>é“¾è·¯è´¨é‡æŒ‡ç¤º</li><li>ç©ºé—²ä¿¡é“è¯„ä¼°</li><li>ä¿¡é“é¢‘ç‡é€‰æ‹©</li><li>åœ¨ç‰©ç†ä»‹è´¨ä¸Šå‘é€å’Œæ¥æ”¶æ•°æ®åŒ…</li></ul><h3><span id="macå±‚">MACå±‚</span></h3><p>æ•°æ®ä¼ è¾“</p><ul><li>æ•°æ®ç”±è£…ç½®å‘é€ç»™åè°ƒè€…</li><li>æ•°æ®ç”±åè°ƒè€…å‘é€ç»™è£…ç½®</li><li>æ•°æ®ç”±ç½‘è·¯è£…ç½®ä¸­å¯¹ç­‰ä¼ è¾“ï¼ˆæ˜ŸçŠ¶æ‹“æ‰‘ä¸æ”¯æŒï¼‰</li></ul><p><em>ä¿¡æ ‡ä½¿èƒ½ç½‘ç»œï¼ˆBeacon modeï¼‰</em></p><ul><li>è¶…å¸§ï¼šå®ç°åè°ƒå™¨å’Œè®¾å¤‡çš„æ—¶é—´åŒæ­¥ã€è¯†åˆ«PANåŠè®¾å¤‡ä¹‹é—´çš„é€šä¿¡ï¼ˆ<em>ä¸æ”¯æŒç½‘çŠ¶æ‹“æ‰‘ç»“æ„</em>ï¼‰<ul><li>CAPï¼ˆContention Access Periodï¼‰é‡‡ç”¨æ—¶éš™CSMA/CA</li><li>CFPï¼ˆContention Free Periodï¼‰é‡‡ç”¨æ—¶éš™GTSæœºåˆ¶é€šä¿¡</li></ul></li><li>é€šä¿¡æ—¶é—´åˆ’åˆ†<ul><li>æ´»è·ƒæœŸï¼ˆåˆ’åˆ†ä¸º16ä¸ªç­‰é•¿çš„slotï¼‰<ul><li>ä¿¡æ ‡å¸§å‘é€é˜¶æ®µ</li><li>CAP</li><li>CFP <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-20.png"></li></ul></li><li>ç¡çœ æœŸ</li></ul></li><li><em>BO</em>ï¼š<em>ä¿¡æ ‡çº§æ•°</em>ï¼Œå–å€¼èŒƒå›´0åˆ°14ï¼Œç­‰äº15æ—¶è¡¨ç¤ºä¸ä½¿ç”¨è¶…å¸§ç»“æ„</li><li><em>SO</em>ï¼š<em>è¶…å¸§çº§æ•°</em>ï¼Œå–å€¼èŒƒå›´0åˆ°14ï¼Œä½†å¿…é¡»ä¿è¯<strong>SOä¸å¤§äºBO</strong>ï¼Œå½“äºŒè€…ç›¸ç­‰æ—¶ï¼Œè¡¨ç¤ºè¯¥è¶…å¸§ä¸­ä¸åŒ…å«éæ´»è·ƒæœŸ</li><li><em>Duty Cycle</em><ul><li>æ´»è·ƒæ—¶é—´2^(-(BO-SO))</li><li>ç¡çœ æ—¶é—´1-2^(-(BO-SO))</li><li>ï¼ˆNæ€»-Néæ´»è·ƒï¼‰/Næ€» <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-21.png"></li></ul></li><li><strong>CAP</strong><ul><li>CAPå¼€å§‹äºbeaconå¸§ä¹‹åï¼Œç»“æŸäºCFPå¼€å§‹ä¹‹å‰çš„æ—¶éš™è¾¹ç•Œä¸Šã€‚å¦‚æœCFPé•¿åº¦ä¸º0ï¼ŒCAPç»“æŸäºè¶…å¸§æ´»åŠ¨åŒºæœ«ç«¯</li><li>é•¿åº¦è‡³å°‘ä¸ºMinCAPLengthä¸ªç¬¦å·é•¿åº¦ï¼Œå¯ä»¥é€šè¿‡è°ƒèŠ‚CFPé•¿åº¦åŠ¨æ€çš„å¢å‡</li><li><em>é™¤äº†ç¡®è®¤å¸§å’Œç´§è·Ÿå› æ•°æ®è¯·æ±‚è€Œå‘é€çš„ç¡®è®¤å¸§ä¹‹åçš„æ•°æ®å¸§ä»¥å¤–</em>ï¼Œæ‰€æœ‰CAPå†…çš„å¸§éƒ½æ˜¯ç”¨CSMA/CA</li><li>å¿…é¡»ä¿è¯è¯¥ä¼ è¾“äº‹åŠ¡ç»“æŸæ—¶è·CAPç»“æŸè‡³å°‘è¿˜æœ‰ä¸€ä¸ªå¸§é—´é—´éš”ï¼ˆIFSï¼‰ï¼Œä»¥ä¿è¯æ¥æ”¶æ–¹æœ‰æ—¶é—´å¤„ç†è¯¥å¸§ï¼›å¦åˆ™å»¶è¿Ÿåˆ°ä¸‹ä¸€ä¸ªCAPå‘é€</li><li>å¸§é—´éš”æ—¶é—´IFS<ul><li>ACKå»¶æ—¶t_ACKå‘é€</li><li>SIFSï¼šå½“å‰ä¸€ä¸ªDATAå¸§é•¿åº¦å°äºç­‰äºMaxSIFSFrameSize(18)æ—¶ï¼Œåä¸€ä¸ªå¸§è‡³å°‘å»¶æ—¶SIFSå‘é€<ul><li>SIFSçš„å…¸å‹å€¼æ˜¯12 Symbols</li></ul></li><li>LIFSï¼šå‰ä¸€ä¸ªå¸§é•¿å¤§äº18ï¼Œåä¸€å¸§å»¶è¿ŸLIFSå‘é€<ul><li>LIFSçš„å…¸å‹å€¼æ˜¯40 Symbols <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-22.png"></li></ul></li></ul></li></ul></li><li><strong>CFP</strong><ul><li>CFPæ˜¯ä¸ºäº†ä¿è¯æŸä¸ªè®¾å¤‡çš„QoSè€Œè®¾ç½®çš„ã€‚å®ƒå¼€å§‹äºCAPç»“æŸåçš„æ—¶éš™è¾¹ç•Œä¸Šï¼Œç»“æŸäºè¶…å¸§æ´»åŠ¨åŒºåŸŸå°¾éƒ¨</li><li>CFPæ‰©å¤§æˆ–å‡å°å–å†³äºæ‰€æœ‰GTSçš„æ€»é•¿åº¦</li><li>åœ¨GTSå†…ä¼ è¾“ä¸ç”¨CSMA/CA</li><li>ä¿è¯ä¼ è¾“ç»“æŸæ—¶è·å®ƒçš„GTSç»“æŸè‡³å°‘æœ‰ä¸€ä¸ªå¸§é—´é—´éš”</li><li><em>GTS: Guaranteed Time Slot</em><ul><li>ç”¨äºä½å»¶è¿Ÿæˆ–å¯¹æ•°æ®ä¼ è¾“å¸¦å®½æœ‰ç‰¹æ®Šè¦æ±‚çš„åº”ç”¨</li><li>åè°ƒè€…é€šè¿‡è¶…å¸§è´Ÿè´£åˆ†é…ï¼Œæœ€å¤šåˆ†é…7ä¸ªï¼Œæ¯ä¸ªå¯ä»¥å ç”¨1ä¸ªæˆ–å¤šä¸ªæ—¶é—´ç‰‡</li></ul></li></ul></li><li>CSMA/CAæ—¶éš™ UnitBackoffPeriodï¼š20 Symbols</li><li><em>CSMA/CAé€€é¿ç®—æ³•</em><ul><li>NBï¼šåé€€æ¬¡æ•°ï¼Œå·²æ‰§è¡Œçš„back offçš„æ¬¡æ•°</li><li>CWï¼šç¢°æ’çª—å£é•¿åº¦ï¼Œå•ä½ä¸ºbackoff period, 20 Symbolsï¼Œå«ä¹‰æ˜¯å¿…é¡»æ‰§è¡Œå‡ æ¬¡å¸§æµ‹é¢‘é“çš†ä¸ºé—²ç½®æ—¶æ‰å¯å°†æ•°æ®é€å‡ºï¼Œ<em>åˆå§‹å€¼ä¸º2</em></li><li>BEï¼šåé€€æŒ‡æ•°ï¼ŒBackoff Time = 2^BE - 1ï¼Œå–å€¼0-5 <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-23.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-24.png"></li><li><em>2CCA</em>ï¼šä¸ºäº†ä¿æŠ¤ACKï¼Œå› ä¸ºACKéœ€è¦å»¶è¿Ÿt_ACKæ—¶é—´æ‰èƒ½å‘é€ï¼Œåªæ£€æµ‹ä¸€ä¸ªCCAå¯èƒ½ä¼šå¯¼è‡´ç¢°æ’ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-25.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-26.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-27.png"></li></ul></li><li>æ•°æ®ç”±è£…ç½®å‘é€ç»™åè°ƒå™¨ï¼ˆç›´æ¥ä¼ è¾“ï¼‰ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-28.png"></li><li>æ•°æ®ç”±åè°ƒè€…å‘é€ç»™è£…ç½®ï¼ˆé—´æ¥ä¼ è¾“ï¼‰ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-29.png"></li></ul><p><em>ä¿¡æ ‡ä¸ä½¿èƒ½ç½‘ç»œï¼ˆNon-beacon modeï¼‰</em></p><ul><li>æ— è¶…å¸§ï¼Œé€šè¿‡æ— æ—¶éš™çš„CSMA/CAæœºåˆ¶å‘é€æ•°æ®</li><li>æŸä¸€èŠ‚ç‚¹çš„é€€é¿å‘¨æœŸå’ŒPANä¸­ä»»ä½•å…¶ä»–çš„èŠ‚ç‚¹çš„é€€é¿å‘¨æœŸæ— å…³</li><li>æ— æ—¶éš™CSMA/CA <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-30.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-31.png"></li><li>æ•°æ®ç”±è£…ç½®å‘é€ç»™åè°ƒå™¨ï¼ˆç›´æ¥ä¼ è¾“ï¼‰ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-32.png"></li><li>æ•°æ®ç”±åè°ƒè€…å‘é€ç»™è£…ç½®ï¼ˆé—´æ¥ä¼ è¾“ï¼‰ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-33.png"></li></ul><p><strong>æ€§èƒ½åˆ†æ</strong></p><ul><li>å®ä¾‹ï¼š2.4GHzé¢‘æ®µä¸Šä½¿ç”¨<em>éæ—¶éš™</em>CSMA/CAèƒ½å¤Ÿè¾¾åˆ°çš„æ•°æ®ä¼ è¾“ç‡250kbps? <em>æœ‰é€€é¿ã€CCAã€å¿…è¦çš„é—´éš”</em><ol type="1"><li>ä¿¡é“è®¿é—®æ—¶é—´<ul><li>{0, 2^BE-1}å‘¨æœŸï¼Œ1CCA</li><li>å‡è®¾ä¿¡é“ç©ºé—²ï¼Œé€€é¿1æ¬¡å³å¯ï¼ŒBE=macMinBE=3</li><li>æœ€é•¿è®¿é—®æ—¶é—´=InitialblockoffPeriod + CCA = (2^3 - 1) x UnitBackoffPeriod + CCA = 7 x 320 + 128 (å¾®ç§’)= 2.368 ms</li><li>å…¶ä¸­ InitialblockoffPeriod = 8 symbols UnitBackoffPeriod = 20 symbols 1 symbol = 16 (å¾®ç§’)</li></ul></li><li>æ•°æ®å¸§ä¼ è¾“æ—¶é—´ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-34.png"><ul><li>æœ€å¤§æœ‰æ•ˆè½½è·ï¼šMaxPHYPacketSize = 127 <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-35.png"></li></ul></li><li>ç¡®è®¤ä¼ è¾“æ—¶é—´ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-36.png"><ul><li>ä¸ä½¿ç”¨CSMA/CA.....................</li></ul></li></ol></li></ul><h3><span id="ç½‘ç»œå±‚">ç½‘ç»œå±‚</span></h3><p>è·¯ç”±</p><ul><li><em>æ ‘å½¢è·¯ç”±</em><ul><li>æœ‰ä¿¡æ ‡</li><li>åœ°å€åˆ†é…<ul><li>åŸºäºæ ‘çš„æ·±åº¦æ–°åŠ å…¥çš„è·¯ç”±èŠ‚ç‚¹è¢«èµ‹äºˆä¸€ä¸ªè¿ç»­çš„åœ°å€èŒƒå›´</li><li><strong>è¯¥èŒƒå›´ä¸­çš„ç¬¬ä¸€ä¸ªæ•´æ•°ä¸ºè¯¥èŠ‚ç‚¹çš„åœ°å€</strong>ï¼Œä½™ä¸‹çš„æ•°ç”¨äºåˆ†é…å­èŠ‚ç‚¹ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-37.png"></li><li><code>Cm</code>ï¼šæœ€å¤§å­©å­ä¸ªæ•°</li><li><code>Rm</code>ï¼šæœ€å¤§å­è·¯ç”±èŠ‚ç‚¹ä¸ªæ•°</li><li><code>Lm</code>ï¼šç½‘ç»œæœ€å¤§æ·±åº¦ï¼Œ<code>[0 ~ Lm]</code></li><li><strong>åˆ†é…æ–¹æ¡ˆ</strong><ul><li>å…·æœ‰æ·±åº¦<code>d &lt; Lm</code>çš„è·¯ç”±èŠ‚ç‚¹çš„<em>åœ°å€èŒƒå›´</em>ä¸º<code>A(d)</code><ul><li><code>if d = Lm - 1, then A(d) = 1 + Cm</code></li><li><code>else A(d) = 1 + Cm - Rm + Rm * A(d+1)</code></li></ul></li><li>æ·±åº¦ä¸º<code>Lm</code>çš„è·¯ç”±èŠ‚ç‚¹å’Œç»ˆç«¯è®¾å¤‡çš„åœ°å€èŒƒå›´ä¸º1</li></ul></li><li>åœ°å€åˆ†é…å®ä¾‹<ul><li>ç»™å®š<code>Rm = 2, Cm = 4, Lm = 3</code></li><li>åˆ†é…ï¼š<ul><li><code>A(3) = 1</code></li><li><code>A(2) = 1 + 4 - 2 + 2 * A(3) = 5</code></li><li><code>A(1) = 1 + 4 - 2 + 2 * A(2) = 13</code></li><li><code>A(0) = 1 + 4 - 2 + 2 * A(1) = 29</code></li><li>Range: <code>[0 ~ 28]</code></li><li>æ ¹èŠ‚ç‚¹åœ°å€ï¼š<code>0</code></li><li>ç¬¬ä¸€å±‚èŠ‚ç‚¹çš„åœ°å€èŒƒå›´ï¼š<code>[1 ~ 13], [14, 26], 27, 28</code></li><li>ç¬¬äºŒå±‚èŠ‚ç‚¹çš„åœ°å€èŒƒå›´ï¼š<code>{[2 ~ 6], [7 ~ 11], 12, 13}, {[15 ~ 19], [20 ~ 24], 25, 26}</code> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-38.png"></li></ul></li></ul></li></ul></li></ul></li><li>ç½‘çŠ¶è·¯ç”±<ul><li>æ— ä¿¡æ ‡ï¼Œå¯¹ç­‰ä¼ è¾“</li><li>æœ‰è·¯ç”±èƒ½åŠ›ï¼šAODV</li></ul></li></ul><p><strong>AODV</strong></p><ul><li>è·¯ç”±å‘ç°è¿‡ç¨‹<ul><li>è¦å‘æŸä¸€ç›®çš„èŠ‚ç‚¹å‘é€æ•°æ®çš„èŠ‚ç‚¹å¹¿æ’­ä¸€ä¸ª<em>RREQæ¶ˆæ¯</em></li><li>æ”¶åˆ°<em>RREQæ¶ˆæ¯</em>çš„èŠ‚ç‚¹ç»§ç»­å¹¿æ’­</li><li>å½“èŠ‚ç‚¹å¹¿æ’­<em>RREQ</em>æ—¶ï¼ŒåŒæ—¶è®¾ç½®ä¸€ä¸ªæŒ‡å‘æºèŠ‚ç‚¹çš„<em>åå‘è·¯å¾„</em>ï¼ˆä¸¢å¼ƒæ”¶åˆ°çš„é‡å¤è·¯ç”±è¯·æ±‚åˆ†ç»„ï¼‰</li><li>AODVå‡å®šè¿æ¥æ˜¯å¯¹ç§°çš„</li><li>å½“ç›®çš„èŠ‚ç‚¹æ”¶åˆ°<em>RREQ</em>æ—¶ï¼Œå‘é€è·¯ç”±å›å¤æ¶ˆæ¯</li><li>è·¯ç”±å›å¤<em>RREP</em>æ¶ˆæ¯æ²¿è·¯ç”±è¯·æ±‚è½¬å‘æ—¶è®¾ç½®çš„åå‘è·¯å¾„ä¼ å›æºèŠ‚ç‚¹</li><li>å¦‚æœä¸­é—´èŠ‚ç‚¹çŸ¥é“ç›®çš„èŠ‚ç‚¹çš„è·¯å¾„ï¼Œä¸”è¯¥è·¯å¾„è¾ƒæ–°ï¼Œä¹Ÿå¯ä»¥å‘é€<em>RREP</em></li><li>ä½¿ç”¨åºåˆ—å·å®šä¹‰è·¯å¾„çš„æ–°æ—§ï¼Œè¢«å‘ç°çš„æ—¶é—´çš„è¿œè¿‘ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-39.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-40.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-41.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-42.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-43.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-44.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-45.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-46.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-47.png"></li></ul></li></ul><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-48.png"></p><h3><span id="tinyos">TinyOS</span></h3><p><em>å¯åŠ¨ï¼åœæ­¢</em> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-49.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-50.png"></p><p><em>å‘é€æ•°æ®</em> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-51.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-52.png"></p><p><em>æ¥æ”¶æ•°æ®</em> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-53.png"></p><p><em>é€‰ä¿¡é“</em> åœ¨makefileé‡ŒåŠ å…¥ï¼š<code>PFLAGS += -DCC2420_DEF_CHANNEL=13</code></p><p><em>AM Type</em> ä»£ç ä¸­çš„<code>id</code> enum { AM_BLINKTORADIO = 6, };</p><p><em>åŒ…æ ¼å¼</em></p><ul><li><code>00</code>ï¼šè¡¨ç¤ºAMæ•°æ®åŒ…</li><li>ç›®æ ‡åœ°å€ï¼ˆ2Bï¼‰</li><li>æºåœ°å€ï¼ˆ2Bï¼‰</li><li>æ¶ˆæ¯é•¿åº¦ï¼ˆ1Bï¼‰</li><li>ç»„å·ï¼ˆ1Bï¼‰</li><li>AM Type (1B)</li><li>Payload (æœ€å¤§28B)<ul><li>nodeid (2B)</li><li>counter (2B)</li></ul></li></ul><h2><span id="æ— çº¿å±€åŸŸç½‘">æ— çº¿å±€åŸŸç½‘</span></h2><h3><span id="macå±‚">MACå±‚</span></h3><p>å¸§å®šä¹‰</p><ul><li>æ§åˆ¶å¸§</li><li>æ•°æ®å¸§</li><li>ç®¡ç†å¸§</li><li>MACé¦–éƒ¨ï¼š30å­—èŠ‚</li><li>å¸§ä¸»ä½“ï¼šæ•°æ®éƒ¨åˆ†ï¼Œ<strong>ä¸è¶…è¿‡2312å­—èŠ‚ï¼ˆå¦‚æœæ•°æ®é•¿åº¦å¤§äº2312åˆ™è¦åˆ†ç‰‡ï¼ï¼‰</strong>ï¼›é€šå¸¸å°äº1500å­—èŠ‚</li><li>å¸§æ£€éªŒåºåˆ—FCSï¼š4å­—èŠ‚ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-54.png"></li></ul><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-55.png"></p><p><em>åˆ†å¸ƒå¼åè°ƒåŠŸèƒ½ï¼ˆDCFï¼‰</em>å­å±‚ä½¿ç”¨<em>CSMA/CA</em>æœºåˆ¶ï¼Œå‘ä¸Šæä¾›äº‰ç”¨æœåŠ¡ã€‚ <em>ç‚¹åè°ƒåŠŸèƒ½ï¼ˆPCFï¼‰</em>å­å±‚ä½¿ç”¨é›†ä¸­æ§åˆ¶çš„æ¥å…¥ç®—æ³•ï¼ŒæŠŠæ•°æ®æƒ<em>è½®æµ</em>äº¤ç»™å„ä¸ªç«™ä»è€Œé¿å…äº†ç¢°æ’çš„äº§ç”Ÿã€‚</p><p>å¸§é—´é—´éš”IFS</p><ul><li>SIFSï¼šçŸ­<ul><li>ACKå¸§ã€CTSå¸§ã€MACå¸§åˆ†ç‰‡çš„æ•°æ®å¸§ã€å›ç­”APæ¢å¯»çš„å¸§ã€<em>PCF</em>ä¸­APå‘é€çš„ä»»ä½•å¸§ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-56.png"></li></ul></li><li>PIFSï¼š<em>ç‚¹åè°ƒPCF</em>åŠŸèƒ½å¸§é—´é—´éš”ï¼Œæ¯”SIFSé•¿ï¼›åœ¨<em>PCF</em>æ–¹å¼ä¸‹ä½¿ç”¨ï¼Œæ²¡æœ‰äº‰ç”¨ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-57.png"></li><li>DIFSï¼š<em>åˆ†å¸ƒåè°ƒDCF</em>åŠŸèƒ½å¸§é—´é—´éš”ï¼Œåœ¨<em>DCF</em>æ–¹å¼ä¸­ç”¨æ¥å‘é€æ•°æ®å¸§å’Œç®¡ç†å¸§ã€‚</li></ul><p><strong>åˆ†å¸ƒå¼åè°ƒDCF</strong></p><ul><li>CSMA/CA<ul><li>å‘å‰å…ˆå¬ï¼Œç©ºé—²ç­‰å¾…<em>DIFS</em>ï¼Œå‘é€</li><li>ä¸ºä»€ä¹ˆç©ºé—²åè¿˜è¦ç­‰å¾…ï¼Ÿ<ul><li>å¯èƒ½æœ‰å…¶ä»–çš„ç«™æœ‰é«˜ä¼˜å…ˆçº§çš„å¸§è¦å‘é€</li></ul></li><li>æºç«™å‘é€äº†æ•°æ®å¸§ï¼›ç›®çš„ç«™æ­£ç¡®æ¥æ”¶æ­¤å¸§ï¼Œéš”<em>SIFS</em>åï¼Œå‘æºç«™å‘é€ç¡®è®¤å¸§ACK</li><li>è‹¥æºç«™æ²¡æœ‰åœ¨è§„å®šæ—¶é—´å†…æ”¶åˆ°ACKï¼Œåˆ™éœ€é‡ä¼ æ­¤å¸§ï¼Œç›´åˆ°æ”¶åˆ°æˆ–æ”¾å¼ƒ</li><li><em>è™šæ‹Ÿè½½æ³¢ç›‘å¬ï¼ˆVirtual Carrier Senseï¼‰</em><ul><li>è®©æºç«™å°†å®ƒè¦å ç”¨ä¿¡é“çš„æ—¶é—´é€šçŸ¥ç»™å…¶ä»–ç«™ï¼Œä»¥ä¾¿ä½¿å…¶ä»–ç«™åœ¨æ­¤æ—¶é—´å†…åœæ­¢å‘é€æ•°æ®</li><li>è¡¨ç¤ºå…¶ä»–ç«™å¹¶æ²¡æœ‰ç›‘å¬ä¿¡é“ï¼Œè€Œæ˜¯ç”±äºæ”¶åˆ°äº†<em>æºç«™çš„é€šçŸ¥</em>ï¼Œæ‰ä¸å‘é€æ•°æ®</li></ul></li><li>ç½‘ç»œåˆ†é…å‘é‡<ul><li>å½“æ£€æµ‹åˆ°MACå¸§é¦–éƒ¨çš„æŒç»­æ—¶é—´å­—æ®µæ—¶ï¼Œå°±è°ƒæ•´è‡ªå·±çš„<em>ç½‘ç»œåˆ†é…å‘é‡NAV</em></li><li>NAVæŒ‡å‡ºäº†å¿…é¡»ç»è¿‡å¤šå°‘æ—¶é—´æ‰èƒ½å®Œæˆæ•°æ®å¸§çš„è¿™æ¬¡ä¼ è¾“ï¼Œæ‰èƒ½ä½¿ä¿¡é“è½¬å…¥ç©ºé—²çŠ¶æ€</li></ul></li><li>äº‰ç”¨çª—å£<ul><li>ä¸ä»…è¦ç­‰å¾…ä¸€ä¸ª<em>DIFS</em>ï¼Œè¿˜è¦è¿›å…¥<em>äº‰ç”¨çª—å£</em>ï¼Œå¹¶è®¡ç®—<em>éšæœºé€€é¿æ—¶é—´</em>ä»¥ä¾¿å†æ¬¡è¯•å›¾æ¥å…¥åˆ°ä¿¡é“</li></ul></li><li>äºŒè¿›åˆ¶æŒ‡æ•°é€€é¿ç®—æ³•<ul><li>ç¬¬<code>i</code>æ¬¡é€€é¿åœ¨<code>2^{2+i}</code>ä¸ªæ—¶éš™ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª<ul><li>ç¬¬<code>1</code>æ¬¡é€€é¿åœ¨<code>8</code>ä¸ªï¼ˆ0-7ï¼‰æ—¶éš™ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª</li><li>ç¬¬<code>3</code>æ¬¡é€€é¿åœ¨<code>32</code>ä¸ªæ—¶éš™ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª</li></ul></li><li>ä»…åœ¨è¦å‘é€<em>ç¬¬ä¸€ä¸ª</em>æ•°æ®å¸§æ—¶æ£€æµ‹åˆ°ä¿¡é“ç©ºé—²æ—¶æ‰<strong>ä¸</strong>ä½¿ç”¨é€€é¿ç®—æ³•ï¼</li><li>é™¤æ­¤ä¹‹å¤–æ‰€æœ‰æƒ…å†µéƒ½è¦ç”¨ï¼å³<ul><li>å‘é€ç¬¬ä¸€å¸§æ—¶æ£€æµ‹åˆ°ä¿¡é“å¿™</li><li>æ¯æ¬¡é‡ä¼ å</li><li>æ¯æ¬¡æˆåŠŸå‘é€å</li></ul></li></ul></li><li>é€€é¿è®¡æ—¶å™¨ï¼ˆbackoff timerï¼‰<ul><li>è‹¥ä¿¡é“ç©ºé—²ï¼Œåˆ™é€€é¿è®¡æ—¶å™¨å°±<em>ç»§ç»­</em>å€’è®¡æ—¶</li><li>è‹¥ä¿¡é“å¿™ï¼Œå°±<em>å†»ç»“</em>é€€é¿è®¡æ—¶å™¨çš„å‰©ä½™æ—¶é—´ï¼Œé‡æ–°ç­‰å¾…å˜ä¸ºç©ºé—²ï¼Œå†ç»è¿‡DIFSåï¼Œ<em>ä»å‰©ä½™æ—¶é—´ç»§ç»­</em></li><li>å¦‚æœè®¡æ—¶å™¨å‡å°åˆ°0ï¼Œåˆ™å¼€å§‹å‘é€æ•´ä¸ªæ•°æ®å¸§ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-58.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-59.png"></li></ul></li><li>RTS/CTS <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-60.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-61.png"></li></ul></li><li>ä¸802.15.14 MACå±‚CSMA/CAåŒºåˆ«<ul><li>ç©ºé—²ä¿¡é“æ£€æµ‹åªéœ€ä¸€ä¸ªCCAï¼Œ802.15.14éœ€è¦2ä¸ª</li><li>æ— é™åˆ¶å›é€€</li><li>å›é€€ç®—æ³•ï¼š802.15.14æ— å†»ç»“</li><li>è™šæ‹Ÿè½½æ³¢ç›‘å¬ï¼ï¼</li></ul></li></ul><p><strong>ç‚¹åè°ƒ PCF</strong></p><ul><li>æ¯ä¸ªè¶…å¸§å‘¨æœŸåˆ†ä¸º<em>CFP</em>å’Œ<em>CP</em><ul><li><em>CFP</em>é˜¶æ®µä¼ è¾“å®æ—¶ä¸šåŠ¡ï¼Œä½¿ç”¨<strong>PCF</strong></li><li><em>CP</em>ä½¿ç”¨<em>DCF</em> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-62.png"></li></ul></li><li>è½®è¯¢åˆ—è¡¨<ul><li>ä¸€ä¸ª<code>CF-Poll</code>æˆæƒå‘é€ä¸€ä¸ªå¸§</li></ul></li><li>è°ƒåº¦ç®—æ³•<ul><li>PCåˆ°Station</li><li>Round-Robin Scheme (R-Poll)ï¼šåœ°å€ä»å°åˆ°å¤§è½®è¯¢</li><li>Cyclic Shift Polling Scheme (CS-Poll)ï¼šå¾ªç¯ç§»åŠ¨åˆ—è¡¨é¡ºåº</li><li>FIFOï¼šç¼“å­˜é˜Ÿåˆ—é‡Œçš„æ•°æ®å¸§é¡ºåº <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-63.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-64.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-65.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-66.png"></li></ul></li></ul><h3><span id="åŠŸè€—ç®¡ç†">åŠŸè€—ç®¡ç†</span></h3><p>TIMï¼šTraffic Indiction Mapï¼Œæ ‡å¿—å“ªä¸ªSTAæœ‰ç¼“å­˜çš„å¸§ DTIMï¼šå‘é€TIMå¹¿æ’­åŒ…</p><p><em>Power-Save mode (PS)</em></p><ul><li>æ¯ä¸ª<code>Listen_Interval</code>å‘¨æœŸå†…æ¿€æ´»æ¥æ”¶å™¨</li><li>STAè¿›å…¥PSæ¨¡å¼åº”é€šçŸ¥APï¼Œæ‰€æœ‰åˆ°å®ƒé‚£çš„å¸§éƒ½ä¼šè¢«ç¼“å­˜ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-67.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-68.png"></li><li>é€šä¿¡<ul><li>å…³é—­å°„é¢‘ï¼Œå®šæœŸç¡çœ </li><li>APç¼“å­˜å‘å¾€è¯¥ç»ˆç«¯çš„æ•°æ®åŒ…</li><li>ç¼“å­˜ä¿¡æ¯åœ¨TIMé‡Œè¯´æ˜</li><li>é†’æ¥çš„ç»ˆç«¯éœ€è¦ç”¨<code>PS-Poll</code>å¸§æ¥æ¥æ”¶æ•°æ®åŒ…</li></ul></li><li>APå“åº”<code>PS-Poll</code><ul><li>ç«‹å³å“åº” <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-69.png"></li><li>æœ‰åˆ†ç‰‡çš„ç«‹å³å“åº” <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-70.png"></li><li>æ¨è¿Ÿå“åº” <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-71.png"></li></ul></li></ul><h2><span id="æ— çº¿å¹¿åŸŸç½‘">æ— çº¿å¹¿åŸŸç½‘</span></h2><h3><span id="å¤§å®¹é‡çš„å°åŒºåˆ¶åˆ©ç”¨æœ‰é™é¢‘æ®µè¦†ç›–æ— é™å¤§é¢ç§¯">å¤§å®¹é‡çš„å°åŒºåˆ¶ï¼šåˆ©ç”¨æœ‰é™é¢‘æ®µè¦†ç›–æ— é™å¤§é¢ç§¯</span></h3><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-72.png"></p><p>æ€æƒ³æ˜¯ç”¨è®¸å¤šå°åŠŸç‡çš„å‘å°„æœºä»£æ›¿å•ä¸ªçš„å¤§åŠŸç‡å‘å°„æœºï¼Œæ¯ä¸€ä¸ªå°çš„åŠŸç‡è¦†ç›–åŒºåªæä¾›æœåŠ¡èŒƒå›´å†…çš„ä¸€å°éƒ¨åˆ†è¦†ç›–ã€‚ ç›¸é‚»å°åŒºä½¿ç”¨<em>ä¸åŒä¿¡é“ç»„</em>ï¼Œä»è€Œé˜²æ­¢ç›¸äº’å¹²æ‰°ã€‚ é€šè¿‡é™åˆ¶å°åŒºçš„è¦†ç›–é¢ç§¯ï¼Œä½¿å¾—åŒä¿¡é“ç»„å¯ä»¥åœ¨ä¸åŒåœ°æ–¹é‡å¤ä½¿ç”¨ã€‚</p><p>ä¸ºæ•´ä¸ªç³»ç»Ÿä¸­çš„æ‰€æœ‰åŸºç«™é€‰æ‹©å’Œåˆ†é…ä¿¡é“ç»„çš„è®¾è®¡è¿‡ç¨‹å«åš<em>é¢‘ç‡å¤ç”¨</em>ã€‚ * å¤šä¸ªä¸åŒé¢‘ç‡çš„å°åŒºcellæ„æˆç°‡clusterï¼›ä¸åŒç°‡ä½¿ç”¨å¯¹åº”çš„ç›¸åŒé¢‘ç‡</p><p><strong>è¶ŠåŒºåˆ‡æ¢ Handoff</strong> åœ¨<em>ä¸ä¸­æ–­é€šè®¯</em>çš„æƒ…å†µä¸‹ä»ä¸€ä¸ªå°åŒºç©¿è¶Šåˆ°å¦ä¸€ä¸ªå°åŒºæ—¶ï¼š</p><ul><li>è¯†åˆ«ä¸€ä¸ªæ–°çš„BS</li><li>æŠŠè¯­éŸ³ä¿¡é“å’Œæ§åˆ¶ä¿¡é“åŒæ—¶åˆ‡æ¢åˆ°æ–°çš„BS</li><li>åˆ‡æ¢è¯·æ±‚çš„ä¼˜å…ˆçº§é«˜äºå‘¼å«è¯·æ±‚</li><li>åˆ‡æ¢æ­¥éª¤<ul><li>æµ‹é‡æ§åˆ¶</li><li>æµ‹é‡æŠ¥å‘Š</li><li>åˆ‡æ¢åˆ¤å†³</li><li>åˆ‡æ¢æ‰§è¡Œ åˆ†ç±»</li></ul></li><li>ç¡¬åˆ‡æ¢<ul><li>åœ¨é¢‘ç‡<em>ä¸åŒ</em>çš„å°åŒºåˆ‡æ¢ï¼Œå…ˆæ–­æ—§è¿æ¥ï¼Œå†å»ºç«‹æ–°è¿æ¥ï¼ˆGSMï¼‰</li></ul></li><li>è½¯åˆ‡æ¢<ul><li>åœ¨é¢‘ç‡<em>ç›¸åŒ</em>çš„å°åŒºåˆ‡æ¢ï¼Œæ–°å»ºè¿æ¥æˆåŠŸåï¼Œå†æ‹†æ—§è¿æ¥ï¼ˆCDMAï¼‰ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-73.png"></li></ul></li></ul><p>åˆ‡æ¢è§„åˆ™ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-74.png"></p><ul><li>ç›¸å¯¹ä¿¡å·å¼ºåº¦å‡†åˆ™<ul><li><em>åˆ‡æ¢ç‚¹A</em>ï¼ŒåŸåŸºç«™ä¿¡å·å¼ºåº¦æ»¡è¶³é€šè¯è¦æ±‚æ—¶ï¼Œä»å¯èƒ½åˆ‡æ¢</li></ul></li><li>å…·æœ‰é—¨é™è§„å®šçš„ç›¸å¯¹ä¿¡å·å¼ºåº¦å‡†åˆ™<ul><li>é—¨é™<code>Th2</code>æ—¶ï¼Œ<em>åˆ‡æ¢ç‚¹B</em>ï¼Œå½“å‰åŸºç«™ä¿¡å·ä½äºé—¨é™ï¼Œæ–°åŸºç«™ä¿¡å·æ›´å¼º</li><li>é—¨é™é«˜æ—¶ï¼Œæ¥è¿‘äº<em>Â ç›¸å¯¹ä¿¡å·å¼ºåº¦å‡†åˆ™</em>ï¼›</li><li>é—¨é™å¤ªä½ï¼Œå¢å¤§è¶ŠåŒºæ—¶å»¶</li></ul></li><li>å…·æœ‰æ»åä½™é‡çš„ç›¸å¯¹ä¿¡å·å¼ºåº¦å‡†åˆ™<ul><li>æ–°åŸºç«™ä¿¡å·å¼ºï¼ˆæ»åä½™é‡<code>h</code>ï¼‰å¾ˆå¤šæ—¶ï¼Œ<em>åˆ‡æ¢ç‚¹C</em>ï¼Œé¿å…ä¹’ä¹“æ•ˆåº”</li></ul></li><li>å…·æœ‰æ»åä½™é‡å’Œé—¨é™è§„å®šçš„ç›¸å¯¹ä¿¡å·å¼ºåº¦å‡†åˆ™<ul><li><em>åˆ‡æ¢ç‚¹D</em></li></ul></li></ul><p>å®é™…åº”ç”¨</p><ul><li>1Gèœ‚çª<ul><li>MSCï¼ˆç§»åŠ¨äº¤æ¢ä¸­å¿ƒï¼‰å†³å®šæ˜¯å¦åˆ‡æ¢</li><li>æ—¶å»¶10s</li></ul></li><li>2Gèœ‚çª<ul><li>MSè¾…åŠ©å†³å®šåˆ‡æ¢</li><li>æ—¶å»¶1ï½2s</li></ul></li></ul><p><strong>ä½ç½®ç®¡ç†</strong> æ•°æ®åº“ï¼ˆæ¯ä¸ªMSCå»ºç«‹ï¼‰</p><ul><li><em>åŸç±ä½ç½®å¯„å­˜å™¨HLR</em><ul><li>æ³¨å†Œç”¨æˆ·ä¿¡æ¯</li><li>ç”¨æˆ·é¢„è®¢ä¸šåŠ¡</li><li>è®°è´¦ä¿¡æ¯</li><li><em>ä½ç½®è®¿é—®å¯„å­˜å™¨VLR</em></li></ul></li></ul><p>ä¸»è¦ä»»åŠ¡</p><ul><li>ä½ç½®ç™»è®°ï¼šæ›´æ–°HLR/VLR</li><li>å‘¼å«ä¼ é€’ï¼šæ ¹æ®HLR/VLRå®šä½ç§»åŠ¨å°ï¼Œç¡®å®šå¤„äºå“ªä¸ªå°åŒº <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-75.png"></li></ul><p>å‘¼å«ä¼ é€’</p><ol type="1"><li>MSé€šè¿‡åŸºç«™å‘MSCå‘å‘¼å«åˆå§‹åŒ–</li><li>MSCé€šè¿‡åœ°å€ç¿»è¯‘è¿‡ç¨‹ç¡®å®š<strong>è¢«å‘¼</strong><em>HLR</em>ï¼Œå¹¶å‘<em>HLR</em>å‘é€ä½ç½®è¯·æ±‚ä¿¡æ¯</li><li><em>HLR</em>ç¡®å®šè¢«å«æ‰€åœ¨<em>VLR</em>ï¼Œå‘<em>VLR</em>å‘é€è·¯ç”±è¯·æ±‚ï¼Œ<em>VLR</em>å°†è¯¥æ¶ˆæ¯è½¬å‘ç»™<strong>è¢«å«</strong>æœåŠ¡çš„MSC</li><li><em>MSC</em>ä¸º<strong>è¢«å«</strong>æœåŠ¡åˆ†é…ä¸´æ—¶æœ¬åœ°å·ç <em>TLDN</em>ï¼Œå¹¶å‘<em>HLR</em>å‘é€å«æœ‰è¯¥å·ç çš„åº”ç­”</li><li><em>HLR</em>å°†ä¸Šè¿°æ¶ˆæ¯è½¬å‘ç»™<strong>ä¸»å‘¼</strong>MSæœåŠ¡çš„MSC</li><li><strong>ä¸»å«</strong>MSCæ ¹æ®ä¸Šè¿°ä¿¡æ¯é€šè¿‡SS7å‘è¢«å«MSCè¯·æ±‚å‘¼å«å»ºç«‹ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-76.png"></li></ol><p><strong>æ”¯æŒçš„ç”¨æˆ·æ•°</strong></p><ul><li>è¯åŠ¡é‡<ul><li>æ¯ä¸ªç”¨æˆ·äº§ç”Ÿçš„è´Ÿè½½å¯†åº¦ä¸º <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-77.png"></li><li>è‹¥æœ‰Cä¸ªä¿¡é“ï¼Œåˆ™æ¯ä¸ªä¿¡é“çš„è´Ÿè½½å¯†åº¦ä¸º <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-78.png"></li></ul></li><li>ç³»ç»Ÿå®¹é‡ä¸é˜»å¡æ¦‚ç‡ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-79.png"><ul><li><code>Pr</code>ä»£è¡¨<em>å‘¼å«è¢«æ‹’ç»</em>çš„æ¦‚ç‡ï¼Œ<code>A</code>æ˜¯è¯åŠ¡é‡ï¼Œ<code>C</code>ä¸ºä¸­ç»§ä¿¡é“æ•°</li></ul></li><li>çˆ±å°”å…°å‘¼æŸè¡¨ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-80.png"></li><li>ä¸¾ä¾‹è®¡ç®—æ”¯æŒç”¨æˆ·æ•° <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-81.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-82.png"></li></ul><p>Tradeoffs <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-83.png"></p><h3><span id="gsmgprs">GSM/GPRS</span></h3><p><em>FDMA</em> + <em>TDMA</em> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-84.png"></p><p>GSM</p><ul><li>ç”µè·¯äº¤æ¢ç½‘ç»œ</li><li>è¯­éŸ³æœåŠ¡</li></ul><p>æ•°æ®æœåŠ¡æ”¯æŒ</p><ul><li>GPRSï¼ˆGeneral Packet Radio Serviceï¼‰</li><li>EDGEï¼ˆEnhanced Data GSM Environmentï¼‰ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-85.png"></li></ul><h3><span id="cdma">CDMA</span></h3><p>æ‰©é¢‘å¤ç”¨ <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-86.png"></p><p>æ­£äº¤ç¼–ç  <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-87.png"></p><p>ç‰¹ç‚¹</p><ul><li>é¢‘ç‡åˆ†é›†</li><li>å¤šè·¯é˜»æŠ—</li><li>ä¿å¯†</li><li>æ•…éšœå¼±åŒ–</li><li>è‡ªæˆ‘å¹²æ‰°</li><li>è½¯åˆ‡æ¢</li><li><strong>å‘å°„åŠŸç‡å°</strong></li><li>æ•°æ®ä¼ è¾“ç‡ï¼š9.6kb/s</li><li>é¢‘é“å¸¦å®½ï¼š1.25MHz</li></ul><p>CMDA vs. GSM</p><ul><li>é€šä¿¡è´¨é‡å¥½</li><li>èµ›è½¦ã€æ–­è®¯é—®é¢˜å°‘</li><li>å…¶ä»–åŠŸèƒ½å·®ä¸å¤š</li><li>å‘å°„åŠŸç‡å°</li></ul><h3><span id="3g">3G</span></h3><p>WCDMA, CDMA2000, TD-SCDMA, WiMax</p><p><strong>æå“å¯¹æ¯”å›¾</strong> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-88.png"></p><h2><span id="ç‰©è”ç½‘é€šä¿¡æ¶æ„">ç‰©è”ç½‘é€šä¿¡æ¶æ„</span></h2><h3><span id="åŸºäºipçš„ç‰©è”ç½‘é€šä¿¡æ¶æ„">åŸºäºIPçš„ç‰©è”ç½‘é€šä¿¡æ¶æ„</span></h3><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-89.png"></p><p>ä¼˜åŠ¿</p><ul><li>äº’é€šæ€§</li><li>æ¶æ„çš„ç¨³å®šæ€§å’Œæ™®éæ€§</li><li>å¯æ‰©å±•æ€§</li><li>æ˜“äºé…ç½®å’Œç®¡ç†</li><li>å¼€æ”¾æ€§</li><li>å®‰å…¨æ€§</li><li>å·²ç»å»ºç«‹å¥½çš„å„ç§æœåŠ¡.... <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-90.png"></li></ul><p>æŒ‘æˆ˜</p><ul><li>åœ¨èµ„æºå—é™çš„ç‰©ä½“ä¸Šå®ç°å®Œæ•´çš„IPåè®®æ ˆ</li><li>ä½åŠŸè€—æœ‰æŸç½‘ç»œä¸‹çš„IPæ•°æ®åŒ…ä¼ è¾“</li><li>ä½åŠŸè€—æœ‰æŸç½‘ç»œä¸‹çš„è·¯ç”±</li></ul><h3><span id="6lowpan">6LowPAN</span></h3><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-91.png"></p><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-92.png"></p><h2><span id="å„ç§æŠ€æœ¯å¯¹æ¯”">å„ç§æŠ€æœ¯å¯¹æ¯”ï¼</span></h2><p><img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-93.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-94.png"> <img src="/images/ç‰©è”ç½‘é€šä¿¡æŠ€æœ¯/DraggedImage-95.png"></p><p>ZigBee</p><ul><li>ä½åŠŸè€—</li><li>ä½æˆæœ¬</li><li>ä½é€Ÿç‡<ul><li>20-250kbps</li></ul></li><li>è¿‘è·ç¦»<ul><li>10-100m</li></ul></li><li>çŸ­å»¶æ—¶<ul><li>ç¡çœ è½¬å·¥ä½œ15ms</li><li>æ¥å…¥ç½‘ç»œ30ms</li><li>è“ç‰™ 3-10s</li><li>WiFiéœ€è¦3s</li></ul></li><li>é«˜å®¹å®¹<ul><li>æ¯ä¸ªä¸»èŠ‚ç‚¹ç®¡ 254ä¸ª</li><li>æœ€å¤š65000ä¸ª</li></ul></li><li>å®‰å…¨</li><li>å…æ‰§ç…§é¢‘æ®µ<ul><li>2.4GHz</li></ul></li></ul><p>CDMA</p><ul><li>å¤šè·¯é˜»æŠ—</li><li>ä¿å¯†</li><li>æ•…éšœå¼±åŒ–</li><li>è‡ªæˆ‘å¹²æ‰°</li><li><strong>å‘å°„åŠŸç‡å°-&gt;çœç”µï¼ˆç›¸æ¯”äºGSMç›¸æ¯”ï¼‰</strong><ul><li>æ­£å¸¸é€šè¯æ—¶<code>0.1mW</code></li></ul></li><li>æ•°æ®ä¼ è¾“ç‡ï¼š9.6kb/s</li><li>é¢‘é“å¸¦å®½ï¼š1.25MHz</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> è®¡ç®—æœºç½‘ç»œ </tag>
            
            <tag> æœ¬ç§‘è¯¾ç¨‹ </tag>
            
            <tag> TinyOS </tag>
            
            <tag> ç‰©è”ç½‘ </tag>
            
            <tag> ZigBee </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯</title>
      <link href="/2017/06/25/%E7%89%A9%E8%81%94%E7%BD%91%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%8A%80%E6%9C%AF/"/>
      <url>/2017/06/25/%E7%89%A9%E8%81%94%E7%BD%91%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#ç»ªè®º">ç»ªè®º</a></li><li><a href="#ä¸­é—´ä»¶çš„å·¥ä½œåŸç†">ä¸­é—´ä»¶çš„å·¥ä½œåŸç†</a></li><li><a href="#j2eeç®€ä»‹">J2EEç®€ä»‹</a></li><li><a href="#j2ee-ejbæ„ä»¶åŸºç¡€">J2EE-EJBæ„ä»¶åŸºç¡€</a></li><li><a href="#ejbæ„ä»¶å¼€å‘">EJBæ„ä»¶å¼€å‘</a></li><li><a href="#rfidä¸­é—´ä»¶">RFIDä¸­é—´ä»¶</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="ç»ªè®º">ç»ªè®º</span></h2><p><strong>ä¸­é—´ä»¶</strong>å®šä¹‰</p><ul><li>ä¸€ç§ç‹¬ç«‹çš„è½¯ä»¶æˆ–è€…æœåŠ¡ï¼Œç‰©è”ç½‘æœåŠ¡å¯ä»¥å€ŸåŠ©ä¸­é—´ä»¶åœ¨ä¸åŒçš„ç³»ç»Ÿä¹‹é—´å…±äº«èµ„æºã€‚å®ƒèƒ½æä¾›é€æ˜çš„æ•°æ®ä¼ è¾“èƒ½åŠ›ï¼Œæ‰¿æ‹…ç‰©ç†ç©ºé—´åˆ°ä¿¡æ¯ç©ºé—´çš„æ˜ å°„ï¼Œå®ç°å¯¹ç‰©ç†å¯¹è±¡çš„æ„ŸçŸ¥å’Œä¿¡æ¯è·å–ã€æ¸…æ´—ã€èåˆç­‰ã€‚</li><li>Software that connects two otherwise separate applications.</li><li>æ˜¯ä¸€ç§ç‹¬ç«‹çš„ç³»ç»Ÿè½¯ä»¶æˆ–æœåŠ¡ç¨‹åºï¼Œåˆ†å¸ƒå¼åº”ç”¨è½¯ä»¶å€ŸåŠ©è¿™ç§è½¯ä»¶åœ¨ä¸åŒçš„æŠ€æœ¯ä¹‹é—´å…±äº«èµ„æºï¼›ä¸­é—´ä»¶ä½äºå®¢æˆ·æœº/æœåŠ¡å™¨çš„æ“ä½œç³»ç»Ÿä¹‹ä¸Šï¼Œ<em>ç®¡ç†è®¡ç®—èµ„æºå’Œç½‘ç»œé€šä¿¡</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage.png"></li><li>å·¦ä¸­å³çš„ä¸­ï¼šä½äºåº”ç”¨ç³»ç»Ÿé—´, <em>æä¾›é€šä¿¡æœåŠ¡</em></li><li>ä¸Šä¸­ä¸‹çš„ä¸­ï¼šä½äºåº”ç”¨ç³»ç»Ÿå’Œæ“ä½œç³»ç»Ÿé—´ï¼Œæä¾›<em>åº”ç”¨ç¼–ç¨‹æ¥å£(æŠ½è±¡)</em>å¹¶ç®¡ç†è®¡ç®—èµ„æº</li></ul><p><em>åˆ†å¸ƒå¼è½¯ä»¶ç»“æ„</em></p><ul><li>ä¸¤å±‚ç»“æ„ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-1.png"><ul><li>å®¢æˆ·ç¨‹åºç›´æ¥è®¿é—®æ•°æ®åº“ï¼Œç”¨æˆ·ç•Œé¢ä»£ç å’Œä¸šåŠ¡é€»è¾‘ä»£ç äº¤ç»‡åœ¨ä¸€èµ·</li><li><em>é—®é¢˜</em><ul><li>å®¢æˆ·ç«¯è´Ÿæ‹…é‡</li><li>å®¢æˆ·ç«¯å¯ç§»æ¤æ€§ä¸å¥½</li><li>ç³»ç»Ÿå¯ç»´æŠ¤æ€§ä¸å¥½</li><li>æ•°æ®å®‰å…¨æ€§ä¸å¥½</li></ul></li></ul></li><li><strong>ä¸‰å±‚ç»“æ„</strong> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-2.png"><ul><li>å°†ä¸šåŠ¡é€»è¾‘ä»£ç ç§»åˆ°ä¸­é—´å±‚</li><li>å®¢æˆ·ç¨‹åº<em>åªèƒ½é€šè¿‡ä¸­é—´å±‚é—´æ¥åœ°è®¿é—®æ•°æ®åº“</em>ï¼Œå³<ul><li>é™ä½äº†å®¢æˆ·ç«¯çš„è´Ÿæ‹…</li><li>æ”¹å–„äº†å…¶å¯ç§»æ¤æ€§</li><li>æé«˜äº†ç³»ç»Ÿçš„æ•°æ®å®‰å…¨æ€§</li></ul></li><li>ä¸šåŠ¡é€»è¾‘ä»£ç ä¸ç”¨æˆ·ç•Œé¢ä»£ç <em>ç›¸å¯¹ç‹¬ç«‹</em>ï¼Œä¹Ÿåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Š<em>æé«˜äº†ç³»ç»Ÿçš„å¯ç»´æŠ¤æ€§</em></li></ul></li></ul><p><em>åˆ†ç±»</em></p><ul><li>æ¶ˆæ¯ä¸­é—´ä»¶(MOM:Message-oriented Middleware)</li><li>æ•°æ®åº“ä¸­é—´ä»¶(Database Middleware)</li><li>è¿œç¨‹è¿‡ç¨‹è°ƒç”¨ä¸­é—´ä»¶(RPC: Remote process Call)</li><li>å¯¹è±¡è¯·æ±‚ä»£ç†ä¸­é—´ä»¶(ORB: Object Request Broker)</li><li>äº‹åŠ¡è¯·æ±‚ä»£ç†ä¸­é—´ä»¶(TP Monitor: Transaction Process Monitor)</li></ul><p><em>ç‰©è”ç½‘ä¸­é—´ä»¶</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-3.png"></p><ul><li><em>åŠŸèƒ½</em><ul><li><strong>å±è”½å¼‚æ„æ€§</strong><ul><li>è®¡ç®—æœºç¡¬ä»¶ä¹‹é—´çš„å¼‚æ„æ€§</li><li>ç‰©è”ç½‘å¼‚æ„æ€§</li></ul></li><li>å®ç°äº’æ“ä½œ<ul><li>å®ç°å„åº”ç”¨ç³»ç»Ÿå’Œåº”ç”¨å¹³å°ä¹‹é—´äº’æ“ä½œ</li></ul></li><li>ä¿¡æ¯é¢„å¤„ç†<ul><li>è¿‡æ»¤æµ·é‡ä¿¡æ¯ï¼Œç»Ÿè®¡åˆ†æèåˆæˆæœ‰æ„ä¹‰äº‹ä»¶å†ä¼ è¾“ç»™åº”ç”¨ç³»ç»Ÿ</li></ul></li><li>å¯æ‰©å±•æ€§</li></ul></li><li><em>OPC</em><ul><li>OPCæ˜¯<em>è¿æ¥</em>æ•°æ®æº(<em>OPCæœåŠ¡å™¨</em>)å’Œæ•°æ®ä½¿ç”¨è€…(<em>OPCåº”ç”¨ç¨‹åº</em>)ä¹‹é—´çš„<em>è½¯ä»¶æ¥å£æ ‡å‡†</em>ã€‚</li></ul></li><li><em>CEP</em><ul><li><em>å¤æ‚äº‹ä»¶å¤„ç†(Complex Event Progressing)</em>æŠ€æœ¯æ˜¯ä¸€ç§æ–°å…´çš„åŸºäº<strong>äº‹ä»¶æµ</strong>çš„æŠ€æœ¯<ul><li>é€šè¿‡åˆ†æäº‹ä»¶é—´çš„<em>å…³ç³»</em>ï¼Œåˆ©ç”¨<em>è¿‡æ»¤ã€å…³è”ã€èšåˆ</em>ç­‰æŠ€æœ¯æœ€ç»ˆç”±ç®€å•äº‹ä»¶<em>äº§ç”Ÿé«˜çº§äº‹ä»¶</em>æˆ–å•†ä¸šæµç¨‹ã€‚</li></ul></li></ul></li></ul><h2><span id="ä¸­é—´ä»¶çš„å·¥ä½œåŸç†">ä¸­é—´ä»¶çš„å·¥ä½œåŸç†</span></h2><p><em>æ„ä»¶</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-4.png"></p><ul><li><em>æ¥å£</em>ï¼šå®šä¹‰åˆ†å¸ƒå¼å¯¹è±¡èƒ½åŠ›çš„çº¦å®šã€‚æ„ä»¶ä¹‹é—´å¯è§çš„åªæœ‰æ¥å£ï¼Œé€šå¸¸æ˜¯è·¨è¯­è¨€çš„</li><li><em>æ•°æ®ç±»å‹</em>ï¼šåˆ†å¸ƒå¼å¯¹è±¡äº¤äº’éœ€å®šä¹‰åœ¨åˆ†å¸ƒå¼å¯¹è±¡ä¹‹é—´ä¼ è¾“çš„æ•°æ®ç±»å‹ã€‚éœ€è¦ä¸€ç§ç‹¬ç«‹äºè¯­è¨€å’Œå¹³å°çš„æ•°æ®ç±»å‹ç³»ç»Ÿ</li><li><em>ç¼–ç»„ä¸è§£ç»„</em>ï¼šä¸²è¡ŒåŒ–æµæ•°æ®ä¸ç¨‹åºå‘˜å¤„ç†çš„æœ‰ç±»å‹æ•°æ®ä¹‹é—´éœ€ ç¼–ç»„ä¸è§£ç»„</li><li><em>å¯¹è±¡å¥æŸ„</em>ï¼šå¯¹è±¡å¥æŸ„æ˜¯å¯¹<em>è¿œç«¯åˆ†å¸ƒå¼å¯¹è±¡çš„å¼•ç”¨</em></li><li><em>å¯¹è±¡åˆ›å»º</em>ï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„åˆ†å¸ƒå¼å¯¹è±¡å®ä¾‹çš„æœºåˆ¶</li><li><em>å¯¹è±¡è°ƒç”¨</em>ï¼šåˆ†å¸ƒå¼å¯¹è±¡çš„è°ƒç”¨çš„æœºåˆ¶</li></ul><p><em>ä¸­é—´ä»¶</em></p><ul><li>æŠ½å–è½¯ä»¶çš„<em>å…±æ€§æˆåˆ†</em>ç”±<strong>ç³»ç»Ÿçº§è½¯ä»¶</strong>å®Œæˆï¼Œ å‘å¼€å‘äººå‘˜å±è”½ç³»ç»Ÿä½å±‚çš„å¤æ‚åº¦ï¼Œä»è€Œåœ¨é«˜å±‚ä¿æŒæ•´ä½“å¤æ‚åº¦çš„ç›¸å¯¹ç¨³å®š</li><li>ä¾æ®æ‰€æŠ½å–å‡ºçš„åº”ç”¨è½¯ä»¶ä¸­çš„<strong>ä¸åŒå…±æ€§</strong>è®¾è®¡ä¸å®ç°ä¸åŒç±»å‹çš„<em>ä¸­é—´ä»¶</em><ul><li>æ•°æ®è®¿é—®ä¸­é—´ä»¶ï¼šæ”¯æ’‘åº”ç”¨ç¨‹åºè®¿é—®æ•°æ®åº“ï¼Œå¯¹å¼‚æ„ç¯å¢ƒä¸‹çš„æ•°æ®åº“å®ç°è”æ¥</li><li>æ¶ˆæ¯ä¸­é—´ä»¶ï¼šä¸ºåº”ç”¨ç¨‹åºæä¾›å‘é€å’Œæ¥æ”¶å¼‚æ­¥æ¶ˆæ¯æ”¯æŒ</li></ul></li></ul><p><em>é›†æˆä¸­é—´ä»¶</em></p><ul><li><strong>åŠŸèƒ½</strong><ul><li><em>æä¾›æ„ä»¶è¿è¡Œç¯å¢ƒ</em><ul><li>ç®¡ç†æ„ä»¶çš„<em>å®ä¾‹åŠå…¶ç”Ÿå‘½å‘¨æœŸã€ç®¡ç†æ„ä»¶çš„å…ƒä¿¡æ¯</em>ç­‰</li></ul></li><li><em>æä¾›äº’æ“ä½œæœºåˆ¶</em><ul><li>å¼€å‘äººå‘˜åœ¨å¼€å‘ä¸è°ƒç”¨åˆ†å¸ƒå¼å¯¹è±¡æ—¶ï¼Œæ— éœ€è‡ªå·±ç¼–å†™<em>å¤„ç†åº•å±‚é€šä¿¡</em>çš„ä»£ç </li></ul></li><li><em>æä¾›å…¬å…±æœåŠ¡</em><ul><li><em>å…¬å…±æœåŠ¡</em>åˆç§°ä¸ºç³»ç»Ÿçº§æœåŠ¡ï¼ŒæŒ‡ç”±ä¸­é—´ä»¶(åº”ç”¨æœåŠ¡å™¨ )å®ç°çš„ã€åº”ç”¨ç¨‹åºä½¿ç”¨çš„è½¯ä»¶ç³»ç»Ÿä¸­<em>å…±æ€§ç¨‹åº¦é«˜</em>çš„åŠŸèƒ½æˆåˆ†<ul><li>äº‹åŠ¡æœåŠ¡</li><li>å®‰å…¨æœåŠ¡</li><li>å‘½åæœåŠ¡</li><li>æŒä¹…æ€§æœåŠ¡</li><li>æ¶ˆæ¯æœåŠ¡</li><li>åˆ†å¸ƒå¼åƒåœ¾å›æ”¶æœåŠ¡</li><li>èµ„æºç®¡ç†æœåŠ¡</li></ul></li></ul></li></ul></li></ul><p><em>Stub/Skeleton</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-5.png"></p><ol type="1"><li><em>å®¢æˆ·ç¨‹åº</em>å°†è°ƒç”¨è¯·æ±‚å‘é€ç»™<em>å®¢æˆ·ç«¯æ¡©</em>ï¼Œå¯¹äºå®¢æˆ·ç¨‹åºæ¥è¯´ï¼Œ<strong>æ¡©</strong>å°±æ˜¯æœåŠ¡ç¨‹åºåœ¨å®¢æˆ·ç«¯çš„ä»£ç†</li><li><em>å®¢æˆ·ç«¯æ¡©</em>è´Ÿè´£å°†è¿œç¨‹è°ƒç”¨è¯·æ±‚è¿›è¡Œç¼–ç»„å¹¶é€šè¿‡é€šä¿¡æ€»çº¿å‘é€ç»™<em>æœåŠ¡ç«¯</em></li><li>è°ƒç”¨è¯·æ±‚ç»é€šä¿¡æ€»çº¿ä¼ é€åˆ°<em>æœåŠ¡ç«¯æ¡†æ¶</em></li><li><em>æœåŠ¡ç«¯æ¡†æ¶</em>å°†è°ƒç”¨è¯·æ±‚è§£ç»„å¹¶åˆ†æ´¾ç»™<em>çœŸæ­£çš„è¿œç¨‹å¯¹è±¡å®ç°(æœåŠ¡ç¨‹åº)</em></li><li><em>æœåŠ¡ç¨‹åº</em>å®Œæˆå®¢æˆ·ç«¯çš„è°ƒç”¨è¯·æ±‚ï¼Œå°†ç»“æœè¿”å›ç»™<em>æœåŠ¡ç«¯æ¡†æ¶</em></li><li><em>æœåŠ¡ç«¯æ¡†æ¶</em>å°†è°ƒç”¨ç»“æœç¼–ç»„å¹¶é€šè¿‡é€šä¿¡æ€»çº¿å‘é€ç»™<em>å®¢æˆ·ç«¯æ¡©</em></li><li><em>å®¢æˆ·ç«¯æ¡©</em>å°†è°ƒç”¨ç»“æœè§£ç»„å¹¶è¿”å›ç»™<em>å®¢æˆ·ç¨‹åº</em></li><li><em>å®¢æˆ·ç¨‹åº</em>å¾—åˆ°è°ƒç”¨ç»“æœ</li></ol><h2><span id="j2eeç®€ä»‹">J2EEç®€ä»‹</span></h2><p><img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-6.png"></p><p>æ„ä»¶ï¼å®¹å™¨ç»“æ„</p><ul><li>æ„æˆJ2EE åº”ç”¨ç³»ç»Ÿçš„<em>æ„ä»¶</em>éƒ½<em>è¿è¡Œåœ¨</em>æŸç§J2EE <em>å®¹å™¨</em>ä¸­</li><li>å®¹å™¨<ul><li>ä¸ºæ„ä»¶æä¾›å…¬å…±æœåŠ¡</li><li>ä¸ºæ„ä»¶ä¹‹é—´çš„äº¤äº’æˆ–è€…æ˜¯æ„ä»¶è®¿é—®åå°æ•°æ®æä¾›æ”¯æŒ</li><li>æä¾›è¿è¡Œç¯å¢ƒ</li></ul></li></ul><p><em>J2EEåº”ç”¨æ„ä»¶</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-7.png"></p><ul><li>å®¢æˆ·ç«¯æ„ä»¶<ul><li>Applets<ul><li>Applet æ˜¯å…·æœ‰å›¾å½¢ç”¨æˆ·ç•Œé¢çš„ç‰¹æ®Šçš„Java ç±»</li><li>è¿è¡Œåœ¨Webæµè§ˆå™¨ä¸­</li><li>è¿è¡Œåœ¨æ”¯æŒAppletç¼–ç¨‹æ¨¡å‹çš„å®¹å™¨ä¸­</li><li>åœ¨J2EE åº”ç”¨ä¸­Applets ä¸€èˆ¬ç”¨æ¥æä¾›ç”¨æˆ·ç•Œé¢</li><li>Appletç±»è‡ªèº«ä¸åŒ…å«main å…¥å£å‡½æ•°ï¼Œå®ƒè¢«å®¹å™¨è°ƒåº¦æ‰§è¡Œ</li><li>æ— éœ€å®‰è£…ï¼Œä»Webä¸Šä¸‹è½½è¿è¡Œåœ¨æµè§ˆå™¨ä¸Š</li></ul></li><li>Application Clients<ul><li>Application Client æŒ‡æœ‰å›¾å½¢ç”¨æˆ·ç•Œé¢çš„ç‹¬ç«‹ Java ç¨‹åº</li><li>ä¸applet ä¸åŒï¼ŒApplication Client é€šå¸¸åŒ…å«main å…¥å£å‡½æ•°ä¸”éœ€è¦åœ¨ æ¯ä¸ªä½¿ç”¨çš„å®¢æˆ·ç«¯ æœºå™¨ä¸Šå®‰è£…</li></ul></li><li>å¾ˆå¤š J2EE åº”ç”¨ä¸­å‡<em>ä¸ä½¿ç”¨</em>Application Client æˆ– Applet ä½œä¸ºå®¢æˆ·ç«¯ç¨‹åºï¼Œå®¢æˆ·ç«¯çš„ç”¨æˆ·ç•Œé¢ä¸€èˆ¬ç”±<em>Web é¡µé¢</em>æ¥æä¾›</li></ul></li><li>æœåŠ¡å™¨ç«¯æ„ä»¶<ul><li>Webæ„ä»¶<ul><li>Servlets</li><li>JSP<ul><li>ä¸€ç±»ç‰¹æ®Šçš„<em>HTMLæ–‡æ¡£</em></li><li>é€šè¿‡åœ¨HTML æ–‡æ¡£ä¸­åµŒå…¥JSP ç‰¹å®šçš„æ ‡ç­¾æ¥å…è®¸ç¨‹åºå‘˜åœ¨é¡µé¢ä¸­åŠ å…¥<em>Java ä»£ç </em>æ¥<em>åŠ¨æ€</em>ç”Ÿæˆé¡µé¢å†…å®¹</li></ul></li></ul></li><li>EJBæ„ä»¶<ul><li>å®ä½“æ„ä»¶</li><li>ä¼šè¯æ„ä»¶</li><li>æ¶ˆæ¯é©±åŠ¨æ„ä»¶</li></ul></li></ul></li></ul><p><em>J2EEåº”ç”¨å¼€å‘</em></p><ul><li>åº”ç”¨ç¨‹åºåŸºæœ¬ç»“æ„ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-8.png"><ul><li>Javaç›®æ ‡æ–‡ä»¶ï¼š<code>.jar</code>æ–‡ä»¶ï¼Œç”¨æ¥æ‰“åŒ…EJBæ„ä»¶ã€Application Clientä»¥åŠå®ƒä»¬éœ€è¦çš„è¾…åŠ©Javaç›®æ ‡æ–‡ä»¶</li><li>Webç›®æ ‡æ–‡ä»¶ï¼š<code>.war</code>æ–‡ä»¶ï¼Œç”¨æ¥ æ‰“åŒ…Web æ„ä»¶(Servletã€JSP)ä»¥åŠé™æ€é¡µé¢ç›¸å…³çš„æ–‡ä»¶(å¦‚HTML æ–‡æ¡£ã€å›¾ç‰‡ç­‰)</li><li>ä¼ä¸šç›®æ ‡æ–‡ä»¶ï¼š<code>.ear</code>çš„æ–‡ä»¶ï¼Œ ç”¨æ¥æ‰“åŒ…å®Œæ•´çš„J2EE åº”ç”¨</li></ul></li><li>ä¸€ä¸ªå®Œæ•´çš„J2EEåº”ç”¨ä¸­å¯ä»¥åŒ…å«è‹¥å¹²ä¸ªJavaç›®æ ‡æ–‡ä»¶å’Œè‹¥å¹²ä¸ªWebç›®æ ‡æ–‡ä»¶</li><li>åœ¨æ‰“åŒ… Java ç›®æ ‡æ–‡ä»¶ã€Web ç›®æ ‡æ–‡ä»¶ä¸ä¼ä¸šç›®æ ‡æ–‡ä»¶æ—¶éƒ½éœ€è¦æä¾›ç›¸åº”çš„<em>éƒ¨ç½²æè¿°ç¬¦</em></li><li><strong>éƒ¨ç½²æè¿°ç¬¦</strong><ul><li>Deployment Descriptorï¼Œç®€ç§°DD</li><li>ä¸€ä¸ªå¸ƒç½²æè¿°ç¬¦æ˜¯ä¸€ä¸ªXMLæ ¼å¼çš„æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶ä¸­æè¿°äº†å½“å‰æ¨¡å—ä¸­æ‰€<em>åŒ…å«çš„å†…å®¹(æ„ä»¶æˆ–æ¨¡å—)</em>æ‰€<strong>éœ€è¦çš„ç¯å¢ƒ</strong></li><li>EJB æ¨¡å—çš„å¸ƒç½²æè¿°ç¬¦â€”â€”<code>ejb-jar.xml</code><ul><li><em>åŒä¸€EJB æ¨¡å—</em>ä¸­çš„æ‰€æœ‰EJB æ„ä»¶<em>å…±äº«</em>è¯¥æ¨¡å—çš„å¸ƒç½²æè¿°ç¬¦</li><li>æè¿°æ¯ä¸€ä¸ªEJB æ„ä»¶çš„<em>Homeæ¥å£ã€ Remote æ¥å£ä»¥åŠçœŸæ­£æä¾›æœåŠ¡çš„ç±»</em>çš„<strong>åå­—</strong></li><li>æè¿°<strong>æ„ä»¶ç±»å‹åŠéœ€è¦å®¹å™¨æä¾›çš„æœåŠ¡</strong>ï¼šå¦‚æœæ˜¯Session Beansï¼Œè¯´æ˜æ˜¯<em>å“ªç§ç±»å‹</em>çš„Session Bean;å¦‚æœæ˜¯Entity Beanï¼Œè¯´æ˜æ˜¯å¦éœ€è¦å®¹å™¨æä¾›çš„ <em>æŒä¹…æ€§ç®¡ç†æœåŠ¡åŠç›¸å…³çš„ä¿¡æ¯</em>;è¯´æ˜è¯¥EJB æ˜¯å¦éœ€è¦ç”±å®¹å™¨æ¥<em>æ§åˆ¶äº‹åŠ¡</em>ï¼Œå¦‚æœéœ€è¦ï¼Œæ€æ ·æ§åˆ¶;è¯´æ˜è¯¥EJB çš„<em>å®‰å…¨æ§åˆ¶ç­–ç•¥</em>ç­‰ç­‰ã€‚</li><li>å½“è¿™äº›ç›¸å…³çš„ç‰¹æ€§å‘ç”Ÿå˜åŒ–æ—¶ï¼Œå¯ä»¥<strong>ä¸</strong>ä¿®æ”¹EJB çš„æºç¨‹åºï¼Œè€Œä»…é€šè¿‡<em>ä¿®æ”¹éƒ¨ç½²æè¿°ç¬¦</em>å°±å¯ä»¥ä½¿å¾—EJB å»é€‚åº”æ–°çš„ç¯å¢ƒã€‚</li></ul></li><li>Web æ¨¡å—çš„å¸ƒç½²æè¿°ç¬¦â€”â€”<code>web.xml</code><ul><li><em>åŒä¸€Web æ¨¡å—</em>ä¸­çš„æ‰€æœ‰æ„ä»¶<em>å…±äº«</em>è¯¥æ¨¡å—çš„å¸ƒç½²æè¿°ç¬¦</li><li>é¦–å…ˆæè¿°<em>å½“å‰æ¨¡å—åŒ…å«çš„æ„ä»¶</em>(åŒ…æ‹¬Servletã€JSPã€è¡¨æ€é¡µé¢ç­‰);</li><li>ä¸ºå½“å‰æ¨¡å—ä¸­çš„æ„ä»¶è¯´æ˜<em>å®‰å…¨æ§åˆ¶è§„åˆ™</em>;</li><li>ç”±äºJ2EE åº”ç”¨çš„Web æ¨¡å—ä¸­ç»å¸¸éœ€è¦é…ç½®åº”ç”¨ä½¿ç”¨çš„<em>ç”¨æˆ·è®¤è¯æ–¹å¼</em>ï¼Œå› ä¸ºåœ¨å…¸å‹çš„J2EE åº”ç”¨ä¸­ï¼Œå®¢æˆ·ç«¯é€šå¸¸é€šè¿‡æµè§ˆå™¨ç›´æ¥è®¿é—®Web æ¨¡å—ä¸­çš„æ„ä»¶ï¼ŒWeb æ¨¡å—ä¸­çš„æ„ä»¶é¦–å…ˆä¸è®¿é—®è€…æ¥è§¦ï¼Œå› æ­¤é€šå¸¸åœ¨Webæ¨¡å—ä¸­å®Œæˆå¯¹ç”¨æˆ·èº«ä»½çš„è®¤è¯ã€‚</li></ul></li><li>J2EE åº”ç”¨çš„å¸ƒç½²æè¿°ç¬¦â€”â€”<code>application.xml</code><ul><li>æè¿°å½“å‰åº”ç”¨ä¸­åŒ…å«çš„<em>æ‰€æœ‰æ¨¡å—</em></li><li>è¿˜å¯èƒ½å®šä¹‰åº”ç”¨ä½¿ç”¨çš„<em>å®‰å…¨æ€§è§’è‰²</em></li></ul></li></ul></li><li>MVC <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-9.png"></li></ul><p><em>æ€è€ƒé¢˜</em></p><ul><li>J2EE åº”ç”¨ä¸­æ„ä»¶/å®¹å™¨èƒ½å¤Ÿä¸ºåº”ç”¨æ„ä»¶æä¾›å“ªäº›å¥½å¤„?<ul><li>ä¸ºåº”ç”¨æ„ä»¶æä¾›å…¬å…±æœåŠ¡</li><li>ä¸ºåº”ç”¨æ„ä»¶ä¹‹é—´çš„äº¤äº’æˆ–è€…æ˜¯åº”ç”¨æ„ä»¶è®¿é—®åå°æ•°æ®æä¾›æ”¯æŒ</li><li>æä¾›åº”ç”¨æ„ä»¶è¿è¡Œç¯å¢ƒ</li></ul></li><li>ç»„æˆ J2EE åº”ç”¨çš„åº”ç”¨æ„ä»¶ä¸»è¦æœ‰å“ªå‡ ç§ï¼Ÿæ¯ç§åº”ç”¨æ„ä»¶åœ¨J2EE åº”ç”¨ä¸­çš„åŸºæœ¬ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ<ul><li>ä¸¤ç§ï¼šå®¢æˆ·ç«¯æ„ä»¶å’ŒæœåŠ¡ç«¯æ„ä»¶</li><li>åŸºæœ¬ä½œç”¨ï¼š<ul><li>å®¢æˆ·ç«¯æ„ä»¶ï¼šæä¾›å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼Œè°ƒç”¨åå°æ¥å£</li><li>æœåŠ¡ç«¯æ„ä»¶ï¼šæä¾›æ•°æ®æœåŠ¡ã€ä¸šåŠ¡é€»è¾‘ç­‰</li></ul></li></ul></li><li>è¯·ç®€å•æè¿° J2EE åº”ç”¨ç¨‹åºçš„åŸºæœ¬ç»“æ„ï¼Œè¯´æ˜å¸ƒç½²æè¿°ç¬¦çš„ä¸»è¦ä½œç”¨<ul><li>åŸºæœ¬ç»“æ„ï¼šJavaç›®æ ‡æ–‡ä»¶ã€Webç›®æ ‡æ–‡ä»¶ã€ä¼ä¸šç›®æ ‡æ–‡ä»¶å’Œéƒ¨ç½²æè¿°ç¬¦</li><li>éƒ¨ç½²æè¿°ç¬¦ä½œç”¨<ul><li>æè¿°å½“å‰æ¨¡å—ä¸­æ‰€<em>åŒ…å«çš„å†…å®¹(æ„ä»¶æˆ–æ¨¡å—)</em>æ‰€<strong>éœ€è¦çš„ç¯å¢ƒ</strong></li><li>æè¿°<strong>æ„ä»¶ç±»å‹åŠéœ€è¦å®¹å™¨æä¾›çš„æœåŠ¡</strong></li></ul></li></ul></li></ul><h2><span id="j2ee-ejbæ„ä»¶åŸºç¡€">J2EE-EJBæ„ä»¶åŸºç¡€</span></h2><p><em>EJBæ„ä»¶æ¦‚è¿°</em></p><ul><li>EJB æ„ä»¶æ˜¯ç”±å…¬å…±æœåŠ¡æ¡†æ¶è‡ªåŠ¨ç®¡ç†çš„åˆ†å¸ƒå¼çš„æœåŠ¡ç«¯å•†ä¸šæ„ä»¶<ul><li>åˆ†å¸ƒå¼å¯¹è±¡æŠ€æœ¯-æä¾›åˆ†å¸ƒå¼å¯¹è±¡çš„æ”¯æŒ</li><li>æœåŠ¡ç«¯æ„ä»¶æŠ€æœ¯-æä¾›æœåŠ¡ç«¯æ„ä»¶ç®¡ç†çš„æ”¯æŒ</li><li>CTM(ComponentTransactionMonitor)æŠ€æœ¯-æä¾›å…¬å…±æœåŠ¡æ¡†æ¶çš„æ”¯æŒ</li></ul></li><li>ç‰¹ç‚¹<ul><li><em>å…¬å…±æœåŠ¡æ¡†æ¶</em><ul><li>æä¾›å¤§é‡ç³»ç»Ÿçº§æœåŠ¡</li><li>å¼€å‘è€…å…³æ³¨å•†ä¸šé€»è¾‘å®ç°ï¼Œæé«˜å¼€å‘æ•ˆç‡</li></ul></li><li><em>å¹³å°ç‹¬ç«‹æ€§</em><ul><li>æ²¿è¢­äº†JAVAçš„å¹³å°æ— å…³æ€§</li></ul></li><li><em>å°è£…ç‰¹æ€§</em><ul><li>å®šä¹‰æ ‡å‡†æœåŠ¡API æ¥å°è£…ç°æœ‰çš„åŸºç¡€æ€§æœåŠ¡</li></ul></li><li><em>å¯å®šåˆ¶æ€§</em><ul><li>ä¿®æ”¹EJB æ„ä»¶çš„è¿è¡Œæ—¶é…ç½®ä»¥æ»¡è¶³ç‰¹å®šç”¨æˆ·çš„éœ€æ±‚</li></ul></li><li><em>åè®®æ— å…³æ€§</em><ul><li>æ”¯æŒå®¢æˆ·ç«¯é€šè¿‡å¤šç§EJB è®¿é—®EJB æ„ä»¶</li></ul></li><li><em>é€šç”¨æ€§</em><ul><li>æ–¹ä¾¿æ”¯æŒä¸åŒè§„æ¨¡çš„åº”ç”¨ç³»ç»Ÿï¼Œå³å¯ä»¥åœ¨ä»»ä½•æ—¶é—´å¢åŠ å®¢æˆ·ç³»ç»Ÿï¼Œè€Œä¸éœ€ä¿®æ”¹æ ¸å¿ƒçš„åº”ç”¨ç³»ç»Ÿ</li><li>ç³»ç»Ÿèµ„æºå¯ä¼¸ç¼©æ€§</li></ul></li></ul></li></ul><p><em>EJBä¸Java Beançš„æ¯”è¾ƒ</em></p><ul><li><em>ç”¨é€”åŠåŠŸèƒ½</em><ul><li>EJB æ„ä»¶é€šå¸¸ç”¨äº<em>æœåŠ¡ç«¯åº”ç”¨å¼€å‘</em></li><li>Java Bean æ„ä»¶é€šå¸¸ç”¨äº<em>å®¢æˆ·ç«¯åº”ç”¨å¼€å‘</em>æˆ–ä½œä¸ºæœåŠ¡ç«¯<em>EJB æ„ä»¶çš„è¡¥å……</em></li><li>Java Bean <em>ä¸èƒ½</em>ä½¿ç”¨Java ä¼ä¸šç‰ˆå¹³å°æä¾›çš„å…¬å…±æœåŠ¡æ¡†æ¶çš„æ”¯æŒ</li></ul></li><li><em>éƒ¨ç½²&amp;å®šåˆ¶</em><ul><li>EJB æ„ä»¶æ˜¯<em>å¯å¸ƒç½²çš„</em>ï¼Œå³EJB æ„ä»¶å¯ä»¥ä½œä¸ºç‹¬ç«‹çš„è½¯ä»¶å•å…ƒ è¢«å¸ƒç½²åˆ°EJB åº”ç”¨æœåŠ¡å™¨ä¸Šï¼Œæ˜¯åº”ç”¨æ„ä»¶</li><li>Java Bean æ˜¯å¼€å‘æ„ä»¶ï¼Œ<em>ä¸èƒ½è¢«éƒ¨ç½²ä¸ºç‹¬ç«‹çš„å•å…ƒ</em></li><li>EJB æ„ä»¶æ˜¯éƒ¨ç½²æ—¶<em>å¯å®šåˆ¶çš„</em></li><li>Java Bean æ„ä»¶çš„å®šåˆ¶é€šå¸¸ä»…å‘ç”Ÿåœ¨<em>å¼€å‘é˜¶æ®µ</em>ï¼Œéƒ¨ç½²æ—¶ä¸èƒ½å¯¹å…¶è¿›è¡Œå®šåˆ¶</li></ul></li><li><em>è¿œç¨‹è®¿é—®èƒ½åŠ›</em><ul><li>EJB æ„ä»¶æ˜¯åˆ†å¸ƒå¼å¯¹è±¡ï¼Œå¯ä»¥è¢«å®¢æˆ·åº”ç”¨æˆ–è€…å…¶å®ƒEJBæ„ä»¶<em>è¿›è¡Œè¿œç¨‹è®¿é—®</em></li><li>æ™®é€šçš„Java Bean æ„ä»¶åªèƒ½<em>åœ¨å…¶æ„æˆçš„åº”ç”¨ä¸­ä½¿ç”¨</em>ï¼Œä¸èƒ½æä¾›è¿œç¨‹è®¿é—®çš„èƒ½åŠ›</li></ul></li><li><em>ç»ˆç«¯å¯è§æ€§</em><ul><li>EJB æ„ä»¶æ˜¯æœåŠ¡ç«¯æ„ä»¶ï¼Œè¿è¡Œåœ¨æœåŠ¡ç«¯ï¼Œæ²¡æœ‰äººæœºäº¤äº’ç•Œé¢ï¼Œ<em>å¯¹ç»ˆç«¯ç”¨æˆ·ä¸å¯è§</em></li><li><em>éƒ¨åˆ†JavaBeans æ„ä»¶å¯¹ç»ˆç«¯ç”¨æˆ·å¯è§</em>ï¼Œå¦‚GUI åº”ç”¨ä¸­ ä½¿ç”¨çš„æŒ‰é’®æ„ä»¶ç­‰</li></ul></li></ul><p><em>EJBä½“ç³»ç»“æ„</em></p><ul><li>EJBå®¹å™¨<ul><li>EJB å®¹å™¨ä¸ºEJB æ„ä»¶<em>æä¾›è¿è¡Œç¯å¢ƒ</em>å¹¶<em>ç®¡ç†è¿è¡Œäºå…¶ä¸­çš„EJB</em></li><li>EJB å®¹å™¨ä¸ºEJB çš„æ‰§è¡Œ<em>æä¾›ç³»ç»Ÿçº§çš„æœåŠ¡</em></li></ul></li><li>EJBæœåŠ¡å™¨<ul><li>EJB æœåŠ¡å™¨æ˜¯éµå¾ªEJB å®šä¹‰çš„æ„ä»¶æ¨¡å‹çš„CTM å®ç°ï¼Œ<em>ä¸€ä¸ªEJB æœåŠ¡å™¨å¯ä»¥åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªEJB å®¹å™¨</em>ï¼ŒEJB æœåŠ¡å™¨<em>ä¸ºEJB å®¹å™¨çš„è¿è¡Œæä¾›å…¬å…±æœåŠ¡æ¡†æ¶</em>ã€‚</li></ul></li><li>EJBå®¢æˆ·ç«¯<ul><li>EJB å®¢æˆ·ç«¯æ³›æŒ‡<em>è°ƒç”¨EJB æ„ä»¶æä¾›ä¸šåŠ¡æ“ä½œçš„è½¯ä»¶å®ä½“</em>ï¼ŒEJB æ„ä»¶çš„å®¢æˆ·ç«¯å¯ä»¥æœ‰å¤šç§å½¢å¼<ul><li>å¯ä»¥æ˜¯ç‹¬ç«‹çš„Javaç¨‹åºä¹Ÿå¯ä»¥æ˜¯å…¶ä»–EJB</li></ul></li></ul></li><li><strong>Enterprise Java Bean</strong><ul><li>å¼€å‘è€…å®ç°çš„æ ¸å¿ƒæ„ä»¶EJB</li><li>æ˜¯EJB å®¢æˆ·ç«¯æ‰€è°ƒç”¨çš„æ“ä½œçš„<em>çœŸæ­£å®ç°è€…</em></li><li>å¯ä»¥è¢«éƒ¨ç½²åˆ°EJB åº”ç”¨æœåŠ¡å™¨ä¸Šï¼Œç”¨æ¥ç»„è£…å¤§å‹çš„EJB åº”ç”¨</li></ul></li><li><em>Homeæ¥å£</em><ul><li>Home æ¥å£(Home Interface)åŒ…å«<em>EJB ç”Ÿå‘½å‘¨æœŸç®¡ç†</em>ç›¸å…³çš„æ–¹æ³•ï¼Œå®¢æˆ·ç¨‹åºä½¿ç”¨Homeæ¥å£<em>åˆ›å»ºæˆ–åˆ é™¤EJB çš„å®ä¾‹</em></li><li><em>æ¯ä¸ªHome æ¥å£éƒ½ä¾èµ–äºä¸€ä¸ªç±»(bean)æ¥æä¾› Home æ¥å£ä¸­çº¦å®šçš„åŠŸèƒ½</em>ï¼Œè¯¥ç±»ç”±å®¹å™¨è‡ªåŠ¨ç”Ÿæˆï¼Œç¨‹åºå‘˜åªéœ€å®šä¹‰æ¥å£</li></ul></li><li><em>Remoteæ¥å£</em><ul><li>Remote æ¥å£åŒ…å«EJB å®ç°çš„å•†ä¸šæ–¹æ³•çš„å£°æ˜ï¼Œ å®ƒå®é™…ä¸Š<em>çº¦å®šäº†EJB æ‰€æä¾›çš„æœåŠ¡</em></li><li>å®ç°æ¥å£çš„ç±»ç”±å®¹å™¨è‡ªåŠ¨ç”Ÿæˆï¼Œä½†<em>çœŸæ­£çš„æ“ä½œæ˜¯ç”±EJBæ„ä»¶å®ç°çš„</em></li><li>å®¢æˆ·ç¨‹åºåªèƒ½é€šè¿‡Remote æ¥å£æ¥<em>é—´æ¥åœ°è®¿é—®EJB å®ç° çš„å•†ä¸šæ–¹æ³•</em>ï¼Œä¸èƒ½ç›´æ¥è¿›è¡Œè°ƒç”¨</li></ul></li><li>LocalHome/Localæ¥å£<ul><li><code>LocalHome = Home, Local = Remote</code></li><li>ä¸Homeæ¥å£å’ŒRemoteç›¸æ¯”ï¼Œæœ¬åœ°æ¥å£çš„ä¸åŒä¹‹å¤„åœ¨äº å®¢æˆ·åº”ç”¨é€šè¿‡<em>æœ¬åœ°æ¥å£</em>å‘èµ·çš„è°ƒç”¨æ˜¯<strong>è¿›ç¨‹å†…çš„æœ¬åœ°è°ƒç”¨</strong>ï¼Œ å› æ­¤æ¯”è¿œç¨‹æ¥å£è°ƒç”¨æœ‰<em>æ›´é«˜çš„æ•ˆç‡</em></li></ul></li><li>ï¿¼æ¯ä¸ªEJB æ„ä»¶<em>éƒ½</em>æœ‰ä¸€å¯¹<em>å¯¹åº”çš„Home æ¥å£ä¸ Remote æ¥å£</em>å’Œ/æˆ–ä¸€å¯¹å¯¹åº”çš„LocalHomeæ¥å£ä¸ Local æ¥å£ï¼Œä»è¿™ç§æ„ä¹‰ä¸Šè®²ï¼Œæˆ‘ä»¬é€šå¸¸è®¤ä¸ºä¸€ä¸ª<em>å®Œæ•´çš„EJB æ„ä»¶</em>åŒ…å«ï¼š<ul><li><strong>Enterprise Beanç±»</strong><ul><li><em>å®ç°ä¸šåŠ¡é€»è¾‘</em></li></ul></li><li><strong>Homeæ¥å£</strong><ul><li><em>å®šä¹‰åˆ›å»ºã€æŸ¥æ‰¾EJBçš„æ–¹æ³•</em></li></ul></li><li><strong>Remoteæ¥å£</strong><ul><li><em>å®šä¹‰åœ¨beanä¸­å®ç°ä¸šåŠ¡é€»è¾‘çš„æ–¹æ³•</em></li></ul></li></ul></li></ul><p><em>EJBæ„ä»¶å¼€å‘</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-10.png"></p><ul><li>ä¼šè¯æ„ä»¶(Session Bean)<ul><li>Session bean å­˜åœ¨äºå®¢æˆ·åº”ç”¨ä¸åº”ç”¨æœåŠ¡å™¨<strong>äº¤äº’</strong>çš„æ—¶é—´æ®µå†…ï¼Œæ˜¯ç”¨æ¥å’Œå®¢æˆ·ç«¯åšäº¤äº’çš„</li><li>å’Œå®ä½“Bean ç›¸æ¯”ï¼ŒSession bean ä¸­çš„<strong>æ•°æ®ä¸ä¿å­˜åœ¨æ•°æ®åº“ä¸­</strong></li><li>Session bean åˆå¯åˆ†ä¸ºä¸¤ç±»<ul><li><em>æœ‰çŠ¶æ€çš„Session Bean</em> è¦è·¨æ–¹æ³•è°ƒç”¨<em>ä¿å­˜ä¼šè¯çŠ¶æ€</em>ï¼Œä¸€ä¸ªæœ‰çŠ¶æ€çš„ Session Bean å®ä¾‹<em>åŒæ—¶åªå¤„ç†ä¸€ä¸ªå®¢æˆ·åº”ç”¨çš„è¯·æ±‚</em>ï¼Œå…¸å‹åœ°å¦‚ç½‘ä¸Šè´­ç‰©ç³»ç»Ÿä¸­æä¾›è´­ç‰©è½¦åŠŸèƒ½çš„Session Bean</li><li><em>æ— çŠ¶æ€çš„Session Bean</em>åœ¨æ–¹æ³•è°ƒç”¨ä¸­é—´<em>ä¸ç»´æŠ¤ä»»ä½•çŠ¶æ€</em>ï¼Œä¸€ä¸ªæ— çŠ¶æ€çš„Session bean å®ä¾‹å¯ä»¥<em>åŒæ—¶å¤„ç†å¤šä¸ªå®¢æˆ·åº”ç”¨çš„è¯·æ±‚</em>ï¼Œå…¸å‹åœ°å¦‚ç½‘ä¸Šè¯åˆ¸ç³»ç»Ÿä¸­æä¾›è‚¡ç¥¨ä¿¡æ¯æŸ¥è¯¢åŠŸèƒ½çš„Session Bean</li></ul></li></ul></li><li>å®ä½“æ„ä»¶(Entity Bean)<ul><li><em>Entity Bean ä»£è¡¨æ•°æ®åº“ä¸­çš„è®°å½•</em>ï¼Œåœ¨EJB ä¸­æ˜¯ç”¨æ¥å°è£…æ•°æ®åº“æ“ä½œçš„ï¼Œä¸Session Beanç›¸æ¯”ï¼Œé€»è¾‘ä¸Šå¯ä»¥è®¤ä¸ºEntity Bean åœ¨æ•°æ®åº“ä¸­çš„æ•°æ®å­˜åœ¨æœŸé—´éƒ½ä¼šå­˜åœ¨</li><li>åŒæ ·ä¸æ•°æ®åº“ä¸­çš„æ•°æ®ç±»ä¼¼ï¼ŒEntity Bean <em>å¯ä»¥è¢«å¤šä¸ªå®¢æˆ·åº”ç”¨å…±äº«è®¿é—®</em></li></ul></li><li>æ¶ˆæ¯é©±åŠ¨æ„ä»¶(Message Driven Bean)<ul><li>Message Driven Bean ä¸»è¦ç”¨æ¥å¤„ç†å¼‚æ­¥æ¶ˆæ¯ï¼Œå› æ­¤é€šå¸¸åœ¨å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼ä¸‹ä½¿ç”¨</li></ul></li><li><em>ä¼šè¯æ„ä»¶ä¸å®ä½“æ„ä»¶</em><ul><li>å®¢æˆ·ç«¯<em>é€šè¿‡ä¼šè¯beanè¿æ¥æœåŠ¡å™¨</em>ï¼Œ<em>ä¼šè¯beané€šè¿‡å®ä½“beanè®¿é—®æ•°æ®åº“</em>ï¼Œè¿™ä½¿å¾—æ—¢å¯ä»¥ä¿å­˜å®¢æˆ·ç«¯çš„ä¿¡æ¯åˆå¯ä»¥ä¿å­˜æ•°æ®åº“è®°å½•çš„ä¿¡æ¯</li><li>ä¼šè¯beanç»å¸¸ç”¨äºæ¶‰åŠ<em>å¤šä¸ªå®ä½“bean</em>çš„ä¸šåŠ¡å¤„ç†å’Œæ§åˆ¶é€»è¾‘</li></ul></li><li>Hello World Session Beanä¾‹å­ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-11.png"></li><li><strong>EJBæ„ä»¶è®¿é—®æµç¨‹</strong> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-12.png"></li><li>EJBæ„ä»¶çš„å®ç°æ­¥éª¤<ol type="1"><li>åˆ›å»ºRemoteæ¥å£</li><li>åˆ›å»ºHomeæ¥å£</li><li>åˆ›å»ºBeançš„å®ç°ç±»</li><li>ç¼–è¯‘Remoteæ¥å£ã€Homeæ¥å£ã€beanå®ç°ç±»</li><li>åˆ›å»ºéƒ¨ç½²æè¿°ç¬¦</li><li>å°†ä»¥ä¸Šä¸‰ä¸ªæ–‡ä»¶ä¸éƒ¨ç½²æè¿°ç¬¦æ–‡ä»¶æ‰“åŒ…ä¸ºä¸€ä¸ª ejb-jaræ–‡ä»¶</li><li>éƒ¨ç½²EJBæ„ä»¶</li></ol></li></ul><p><strong>æ¥å£è®¾è®¡åŸåˆ™</strong></p><ul><li>Remoteæ¥å£è®¾è®¡åŸåˆ™<ul><li>ç»§æ‰¿æ€§çº¦æŸ<ul><li>æ¯ä¸ªRemote æ¥å£å¿…é¡»ç»§æ‰¿<em>EJBObject</em> æ¥å£</li><li>åŒ…å«ç”¨äº<em>ç®¡ç†å®ç°remote æ¥å£çš„EJB å¯¹è±¡çš„æ–¹æ³•</em></li></ul></li><li>æ–¹æ³•å¯¹åº”è§„åˆ™<ul><li>Remote æ¥å£ä¸­å‡ºç°çš„<em>æ¯ä¸€ä¸ªæ–¹æ³•çš„å£°æ˜</em>éƒ½å¿…é¡»åœ¨ç›¸åº”çš„<em>Enterprise Beanç±»ä¸­æœ‰ä¸€ä¸ªå¯¹åº”æ–¹æ³•çš„å®ç°</em></li><li>å…¶ä¸­æ¯ä¸ªæ–¹æ³•çš„<strong>å‚æ•°å’Œè¿”å›å€¼å¿…é¡»å®Œå…¨ç›¸åŒ</strong>ï¼ŒæŠ›å‡ºçš„<strong>å¼‚å¸¸å¿…é¡»åŒ¹é…</strong><ul><li>åŒ¹é…çš„å«ä¹‰æ˜¯æŒ‡<em>æ¥å£</em>ä¸­æ–¹æ³•æŠ›å‡º<em>å¼‚å¸¸çš„é›†åˆ</em>å¿…é¡»<strong>åŒ…å«</strong> <em>Bean ç±»ä¸­</em>å¯¹åº”æ–¹æ³•æŠ›å‡º<em>å¼‚å¸¸çš„é›†åˆ</em></li><li>å³æ¥å£æ–¹æ³•ä¸­å‡ºç°çš„å¼‚å¸¸ï¼ŒBeanç±»ä¸­å¯ä»¥å‡ºç°ï¼Œä¹Ÿå¯ä»¥ä¸å‡ºç°ï¼Œä½†æ˜¯<em>ä¸å…è®¸Bean ç±»ä¸­æ–¹æ³•æŠ›å‡ºæ¥å£å¯¹åº”æ–¹æ³•ä¸­æ²¡æœ‰å£°æ˜çš„å¼‚å¸¸</em></li></ul></li></ul></li><li>RMI çº¦æŸ<ul><li>Remote æ¥å£ä¸­çš„æ–¹æ³•<strong>å¿…é¡»æŠ›å‡ºRemoteException å¼‚å¸¸</strong>ï¼Œè¯¥å¼‚å¸¸æŠ¥å‘Šç½‘ç»œé€šä¿¡é”™è¯¯</li><li>æ–¹æ³•å®šä¹‰ä¸­çš„<em>å‚æ•°ä¸è¿”å›å€¼å¿…é¡»æ˜¯åˆæ³•</em>çš„Java RMI ç±»å‹çš„å‚æ•°/è¿”å›å€¼</li></ul></li></ul></li><li>Homeæ¥å£è®¾è®¡åŸåˆ™<ul><li>ç»§æ‰¿æ€§çº¦æŸ<ul><li>æ¯ä¸ªHome æ¥å£å¿…é¡»ç»§æ‰¿<em>EJBHome</em> æ¥å£</li><li>å…¶ä¸­åŒ…å«äº†<em>Enterprise Bean ç”Ÿå‘½å‘¨æœŸç®¡ç†çš„æ–¹æ³•</em></li></ul></li><li>æ–¹æ³•å¯¹åº”è§„åˆ™<ul><li>Home æ¥å£ä¸­çš„æ¯ä¸ª<em>create</em> æ–¹æ³•éƒ½å¿…é¡»åœ¨ç›¸åº”çš„<br>Enterprise Bean ç±»ä¸­æœ‰ä¸€ä¸ªå¯¹åº”çš„<em>ejbCreate</em> æ–¹æ³•</li><li>åŒ¹é…åŒä¸Š</li></ul></li><li>RMIçº¦æŸ<ul><li><em>RemoteException</em>åŒä¸Š</li><li>Home æ¥å£ä¸­çš„æ¯ä¸ª<em>create æ–¹æ³•</em>å¿…é¡»æŠ›å‡º <em>CreateException</em>å¼‚å¸¸ï¼Œè¯¥å¼‚å¸¸ç”¨äºæŠ¥å‘ŠEJB å®ä¾‹çš„åˆå§‹åŒ–é”™è¯¯</li></ul></li></ul></li></ul><p><em>Enterprise Bean ç±»è®¾è®¡åŸåˆ™</em></p><ul><li>æ¥å£çº¦æŸ<ul><li>Enterprise bean ç±»å¿…é¡»å®ç°<em>EnterpriseBeanæ¥å£</em></li><li><code>EnterpriseBean</code>æ¥å£ä¸­å®šä¹‰äº†Enterprise Bean <em>ç”Ÿå‘½å‘¨æœŸç®¡ç†çš„æ–¹æ³•</em>ï¼Œå®ç°è¯¥æ¥å£æ˜¯Enterprise Bean ä¸æ™®é€šjava bean çš„é‡è¦åŒºåˆ«</li></ul></li><li>å¯è§æ€§çº¦æŸ<ul><li>Enterprise bean ç±»å¿…é¡»å®šä¹‰ä¸º<em>public ç±»</em></li></ul></li><li>å•†ç”¨æ–¹æ³•çº¦æŸ<ul><li>Enterprise bean ç±»<strong>å¿…é¡»å®ç°Remote æ¥å£ä¸­å®šä¹‰çš„ä¸šåŠ¡é€»è¾‘</strong>æ“ä½œ</li></ul></li><li>ç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹æ³•çº¦æŸ<ul><li>Enterprise Bean ç±»<strong>å¿…é¡»å®ç°</strong>Home æ¥å£ä¸­å®šä¹‰çš„create æ–¹æ³•å¯¹åº”çš„ <strong>ejbCreate æ–¹æ³•</strong></li></ul></li></ul><p><em>æ€è€ƒä¸ç»ƒä¹ ï¼</em></p><ul><li>EJB æ„ä»¶ä¸æ™®é€šçš„Java Bean æœ‰å“ªäº›ä¸»è¦åŒºåˆ«? ä»–ä»¬åˆ†åˆ«é€‚åˆäºä»€ä¹ˆåœºåˆçš„å¼€å‘? è§å‰é¢</li><li>EJB ä½“ç³»ç»“æ„ä¸­åŸºäºStub/Skeleton ç»“æ„ä¸å®¢æˆ·ç«¯äº¤äº’çš„ç›´æ¥æ„ä»¶ä¸æ˜¯EJBï¼Œè€Œæ˜¯å®¹å™¨è‡ªåŠ¨ç”Ÿæˆçš„å¯¹è±¡ï¼Œé‡‡ç”¨è¿™æ ·çš„ç»“æ„æœ‰ä»€ä¹ˆå¥½å¤„? ä¸ä¼š</li><li>åœ¨ EJB ä½“ç³»ç»“æ„ä¸­ï¼ŒHome æ¥å£ä¸Remote æ¥å£çš„ä¸»è¦ä½œç”¨æ˜¯ä»€ä¹ˆ?ä¸ºä»€ä¹ˆè¿˜è¦å¼•å…¥LocalHome ä¸Local æ¥å£ï¼Œè¿™å¯¹æ¥å£ä½¿ç”¨æ—¶æœ‰å“ªäº›é™åˆ¶? è§å‰é¢</li><li><em>EJBæ„ä»¶çš„è®¿é—®æµç¨‹?Â </em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-13.png"><ol type="1"><li>æŸ¥æ‰¾Homeå¯¹è±¡çš„å¼•ç”¨</li><li>JNDIè¿”å›Homeå¯¹è±¡çš„å¼•ç”¨</li><li>å‘Homeæ¥å£è¯·æ±‚ä¸€ä¸ªEJBå¯¹è±¡</li><li>Homeå¯¹è±¡åˆ›å»ºä¸€ä¸ªEJBå¯¹è±¡</li><li>Homeå¯¹è±¡è¿”å›ç»™å®¢æˆ·çš„EJBå¯¹è±¡çš„å¼•ç”¨</li><li>å®¢æˆ·ç«¯é€šè¿‡Remoteæ¥å£è°ƒç”¨beanæ–¹æ³•</li><li>EJBå¯¹è±¡è¯·æ±‚Enterprise Beanè°ƒç”¨beanå®ä¾‹çš„ç›¸åº”æ–¹æ³•</li><li>Enterprise Beanè¿”å›è°ƒç”¨ç»“æœç»™EJBå¯¹è±¡</li><li>EJBå¯¹è±¡æŠŠè¿”å›å€¼è¿”å›ç»™å®¢æˆ·ç«¯</li></ol></li></ul><h2><span id="ejbæ„ä»¶å¼€å‘">EJBæ„ä»¶å¼€å‘</span></h2><p><em>æ— çŠ¶æ€ä¼šè¯Bean</em></p><ul><li>æ— çŠ¶æ€ä¼šè¯Beanæ¯æ¬¡è°ƒç”¨åªå¯¹å®¢æˆ·æä¾›ä¸šåŠ¡é€»è¾‘ï¼Œ ä½†<em>ä¸ä¿å­˜å®¢æˆ·ç«¯çš„ä»»ä½•æ•°æ®çŠ¶æ€</em></li><li>æ— çŠ¶æ€ä¼šè¯Beançš„çŠ¶æ€ï¼Œè¢«ä¿æŒåœ¨å®¢æˆ·ç«¯ï¼Œå®¹å™¨ä¸è´Ÿè´£ç®¡ç†</li><li>ç”¨é€”<ul><li>å¦‚æœ<em>æ•°æ®</em>å®é™…ä¸Šæ˜¯<em>ç¬æ—¶æ˜ åƒ</em>ï¼Œåˆ™å»ºè®®ä½¿ç”¨æ— çŠ¶æ€ä¼šè¯ Bean</li><li>å¦‚æœ<em>æ•°æ®çŠ¶æ€</em>éå¸¸<em>æ•æ„Ÿ</em>ï¼Œåˆ™<em>ä¸</em>è¦ä½¿ç”¨æ— çŠ¶æ€ä¼šè¯ Beanï¼Œè¿™äº›æƒ…å†µå¯ä»¥ä½¿ç”¨æœ‰çŠ¶æ€ä¼šè¯Beanï¼Œå°†ç”¨æˆ·çŠ¶æ€ä¿å­˜åˆ°æœåŠ¡å™¨ä¸­</li></ul></li><li>æ— çŠ¶æ€ä¼šè¯Beanï¼šç”Ÿå‘½å‘¨æœŸç”±<em>å®¹å™¨</em>æ§åˆ¶</li><li>å½“éƒ¨ç½²ä¸€ä¸ªEJBæ—¶ï¼Œå®¹å™¨ä¼šä¸ºè¿™ä¸ªBeanåˆ†é…å‡ ä¸ªå®ä¾‹åˆ°<em>ç»„ä»¶æ± </em>ä¸­</li><li>å½“å®¢æˆ·è¯·æ±‚ä¸€ä¸ªBeanæ—¶ï¼ŒJ2EEæœåŠ¡å™¨å°†ä¸€ä¸ª<em>é¢„å…ˆè¢«å®ä¾‹åŒ–</em>çš„Beanåˆ†é…å‡ºå»</li><li>ç©ºé—²çš„Bean<ul><li>ä¸åœ¨æ–¹æ³•æˆ–äº‹åŠ¡ä¸­</li><li>å®¢æˆ·é•¿æ—¶é—´ä¸ç”¨</li></ul></li><li>å¦‚æœå…¨éƒ¨å®ä¾‹éƒ½å·²ç”¨å®Œï¼Œåˆ™ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªæ–°çš„å®ä¾‹æ”¾åˆ°æ± ä¸­ï¼Œå¹¶åˆ†é…ç»™è¯·æ±‚è€…</li><li>ä¸¾ä¾‹ï¼š<em>è¿”å›æœåŠ¡ç«¯å½“å‰ç³»ç»Ÿæ—¶é—´</em><ul><li>Remoteæ¥å£ï¼ˆå›å¿†è®¾è®¡åŸåˆ™ï¼‰ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-14.png"></li><li>Homeæ¥å£<ul><li>Home æ¥å£ä¸­åŒ…å«EJB æ„ä»¶<em>ç”Ÿå‘½å‘¨æœŸç®¡ç†</em>çš„ç›¸å…³æ–¹æ³•ï¼Œå®¢æˆ·ç¨‹åºä½¿ç”¨Home Interface <em>åˆ›å»ºã€æŸ¥æ‰¾æˆ–åˆ é™¤</em>EJB çš„å®ä¾‹ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-15.png"></li><li>ç”±äº<em>æ— çŠ¶æ€ä¼šè¯æ„ä»¶</em>çš„å¯¹è±¡å¯èƒ½<em>è¢«å¤šä¸ªå®¢æˆ·ç«¯å…±äº«</em>åœ°è®¿é—® ï¼Œå› æ­¤ EJB è§„èŒƒ<strong>ä¸å…è®¸æŸä¸ªå®¢æˆ·ç«¯ä½¿ç”¨ç‰¹å®šçš„å‚æ•°åˆå§‹åŒ–</strong>æ— çŠ¶æ€ä¼šè¯æ„ä»¶çš„å¯¹è±¡ï¼Œè¿›è€Œä½¿å¾—æ— çŠ¶æ€ä¼šè¯æ„ä»¶Home æ¥å£ä¸­<strong>åªèƒ½åŒ…å«æ²¡æœ‰å‚æ•°çš„create æ–¹æ³•</strong></li></ul></li><li>Enterprise Bean ç±»<ul><li>Enterprise Bean ç±»é¦–å…ˆè¦æŒ‰ç…§Remote æ¥å£çš„çº¦å®š<em>å®ç°å•†ä¸šæ–¹æ³•getCurTime</em>ï¼Œå…¶æ¬¡è¦å®ç° Home æ¥å£ä¸­<code>create</code> æ–¹æ³•å¯¹åº”çš„<em><code>ejbCreate</code> æ–¹æ³•ä¸ä¼šè¯æ„ä»¶ç”Ÿå‘½å‘¨æœŸç›¸å…³çš„æ–¹æ³•</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-16.png"></li></ul></li></ul></li></ul><p><em>EJBç”Ÿå‘½å‘¨æœŸç®¡ç†</em></p><ul><li>ä¸æ™®é€šçš„ Java ç±»ç›¸æ¯”ï¼ŒEnterprise Bean ç±»ä¸­å¤š å‡ºäº†<code>ejbCreate</code>ã€<code>ejbRemove</code>ã€<code>ejbPassivate</code>ã€ <code>ejbActivate</code>ã€<code>setSessionContext</code> ç­‰EJB ç”Ÿå‘½å‘¨ æœŸç®¡ç†ç›¸å…³çš„æ–¹æ³•</li><li>æ— çŠ¶æ€ä¼šè¯æ„ä»¶çš„ç”Ÿå‘½å‘¨æœŸ<ul><li><em>æ–¹æ³•å°±ç»ªçŠ¶æ€</em><ul><li>æ–¹æ³•å°±ç»ªçŠ¶æ€è¡¨æ˜å¯¹åº”æ— çŠ¶æ€ä¼šè¯æ„ä»¶å¯¹è±¡å·²è¢«åˆ›å»ºï¼Œå¯ä»¥ä¸ºå®¢æˆ·ç«¯æä¾›æœåŠ¡</li></ul></li><li><em>ä¸å­˜åœ¨çŠ¶æ€</em><ul><li>ä¸å­˜åœ¨çŠ¶æ€è¡¨æ˜EJB å®¹å™¨ä¸­ä¸å­˜åœ¨å¯¹åº”æ— çŠ¶æ€ä¼šè¯æ„ä»¶çš„å®ä¾‹ ï¼Œå¤„äºä¸å­˜åœ¨çŠ¶æ€çš„<em>å®ä¾‹è¿˜æœªè¢«åˆ›å»º</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-17.png"></li></ul></li><li>æ— çŠ¶æ€çš„ä¼šè¯æ„ä»¶<strong>å®ä¾‹çš„åˆ›å»ºå’Œåˆ é™¤éƒ½æ˜¯ç”±å®¹å™¨è‡ªåŠ¨æ§åˆ¶Â </strong>ï¼Œå®¹å™¨ä¹Ÿ<em>ä¸</em>å…è®¸å®¢æˆ·ç«¯è°ƒç”¨Home æ¥å£ä¸­çš„<code>remove</code> æ–¹æ³•æ¥åˆ é™¤å®ä¾‹</li></ul></li></ul><p><em>æ€è€ƒ</em></p><ul><li>EJBæ„ä»¶çš„å®ç°æ­¥éª¤ï¼Ÿ</li><li>å¦‚æœæ²¡æœ‰Homeæ¥å£å’ŒRemoteæ¥å£ï¼Œå¼€å‘äººå‘˜éœ€è¦åšå“ªäº›å·¥ä½œ?</li></ul><p><em>æœ‰çŠ¶æ€ä¼šè¯Bean</em></p><ul><li>è¯¥EJB æ„ä»¶å®ç°ç½‘ä¸Šè´­ç‰©ç³»ç»Ÿä¸­è´­ç‰©è½¦çš„åŸºæœ¬åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ·»åŠ å•†å“ã€å»é™¤å•†å“ã€æŸ¥æ‰¾å•†å“ã€æ¸…ç©º è´­ç‰©è½¦ã€æäº¤å•†å“ç­‰</li><li>ç”±äºè¯¥æ„ä»¶çš„å®ä¾‹(å¯¹è±¡)<em>éœ€è¦ä¿å­˜ä¸ç‰¹å®šå®¢æˆ·ç«¯ç›¸å…³çš„ä¼šè¯çŠ¶æ€</em>ï¼Œå³ç‰¹å®šå®¢æˆ·æ‰€é€‰æ‹©çš„å•†å“ç­‰ç›¸å…³ä¿¡æ¯ï¼Œå› æ­¤è®¾è®¡ä¸º<em>æœ‰çŠ¶æ€çš„ä¼šè¯æ„ä»¶</em>ã€‚</li><li>Remoteæ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-18.png"></li><li>Homeæ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-19.png"></li><li>Enterprise Bean ç±» <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-20.png"> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-21.png"> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-22.png"></li><li><em>ç”Ÿå‘½å‘¨æœŸ</em><ul><li>æ–¹æ³•å°±ç»ªçŠ¶æ€</li><li>ä¸å­˜åœ¨çŠ¶æ€<ul><li>å®ä¾‹æœªè¢«åˆ›å»º</li></ul></li><li>é’åŒ–çŠ¶æ€<ul><li>å¯¹åº”æœ‰çŠ¶æ€ä¼šè¯æ„ä»¶å¯¹è±¡å·²è¢«è½¬ç§»è‡³<em>æŒä¹…å­˜å‚¨ä»‹è´¨</em>ï¼Œæš‚æ—¶ä¸èƒ½ä½¿ç”¨ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-23.png"></li></ul></li><li>å› ä¸º<em>æœ‰çŠ¶æ€ä¼šè¯æ„ä»¶</em>éœ€<em>ä¿å­˜ä¸ç‰¹å®šå®¢æˆ·ç«¯ç›¸å…³çš„ä¸­é—´çŠ¶æ€</em>ï¼Œ å› æ­¤æ¯ä¸ªå®ä¾‹/å¯¹è±¡éƒ½æ˜¯è¢«ä¸€ä¸ªå®¢æˆ·ç«¯æ‰€ä¸“ç”¨çš„ã€‚è¿™å°±ä½¿å¾—æ¯ä¸ªå®¢æˆ·ç«¯éƒ½éœ€è¦ä¸€ä¸ªä¸“é—¨çš„æœ‰çŠ¶æ€ä¼šè¯bean æ¥ä¸ºå®ƒæœåŠ¡ï¼Œåˆ™å¾ˆæœ‰å¯èƒ½åœ¨æœåŠ¡ç«¯<em>åŒæ—¶å­˜åœ¨å¤§é‡çš„EJB å®ä¾‹</em>ï¼Œä»è€Œå¯¼è‡´æœåŠ¡ç«¯<em>å†…å­˜å¼€é”€å¤ªå¤§</em>ã€‚</li><li>ä¸ºäº†<em>é™åˆ¶æœåŠ¡ç«¯å†…å­˜ä½¿ç”¨æ€»é‡</em>ï¼Œå½“EJB å®ä¾‹çš„æ•°é‡è¿‡å¤šæ—¶ï¼Œ å®¹å™¨ä»…ä»…ä¼šåœ¨å†…å­˜ä¸­ä¿ç•™é‚£äº›æ­£åœ¨ä½¿ç”¨æˆ–è€…åˆšè¢«ä½¿ç”¨çš„å®ä¾‹ ï¼Œä¼š<em>æŠŠå…¶å®ƒçš„å®ä¾‹è½¬ç§»åˆ°æŒä¹…å­˜å‚¨ä»‹è´¨</em>ä¸Š(ä¸æ˜¯åˆ é™¤)ï¼Œæ­¤æ—¶è¢«è½¬ç§»åˆ°æŒä¹…å­˜å‚¨ä»‹è´¨ä¸Šçš„å®ä¾‹ä¼šä»<em>æ–¹æ³•å°±ç»ªçŠ¶æ€</em>è¿›å…¥<em>é’åŒ–çŠ¶æ€</em>ã€‚</li><li>å½“å®¢æˆ·ç«¯å‡ºç°<em>è¶…æ—¶</em>æ—¶ï¼Œå®¹å™¨ä¼šæŠŠæŒä¹…å­˜å‚¨ä»‹è´¨ä¸­çš„å®ä¾‹<em>åˆ é™¤</em>æ‰ï¼Œè¯¥å®ä¾‹è¿›å…¥<em>ä¸å­˜åœ¨çŠ¶æ€</em></li><li>åªè¦æœ‰æ–°çš„å®¢æˆ·ç«¯è¯·æ±‚ï¼Œå®¹å™¨å°±ä¼šåˆ›å»ºæ–°çš„å®ä¾‹</li></ul></li></ul><p><em>å®ä½“æ„ä»¶ä¸æŒä¹…åŒ–æŠ€æœ¯</em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-24.png"> åŸºäº<em>å®ä½“æ„ä»¶</em>çš„æ”¯æŒï¼Œä¸šåŠ¡é€»è¾‘æ„ä»¶<em>ä»¥å¯¹è±¡çš„æ–¹å¼</em>çœ‹å¾…ä¸å¤„ç†æ•°æ®åº“ä¸­çš„æ•°æ®ï¼Œä»è€Œå¤§è‡´ç®€åŒ–æ•°æ®åº“å¼€å‘çš„ç›®çš„ã€‚</p><p>å¸¸ç”¨çš„JavaæŒä¹…åŒ–æ–¹æ¡ˆ</p><ul><li>åŸºäºDAOå’ŒJDBC<ul><li>è¿™ç§æ–¹æ¡ˆé€šè¿‡DAOæ¥å®ç°æ•°æ®çš„æŒä¹…åŒ–æ“ä½œï¼Œå…·ä½“å®ç°æ—¶ï¼Œ<em>DAOé€šè¿‡JDBCæ¥å®Œæˆå¯¹æ•°æ®åº“çš„è®¿é—®</em>ã€‚è¿™ç§æ–¹æ¡ˆ <em>è¦æ±‚å¼€å‘äººå‘˜å¯¹JDBC çš„åº•å±‚ä¿¡æ¯è¦æ¯”è¾ƒç†Ÿæ‚‰</em>ã€‚</li></ul></li><li><strong>åŸºäºORM</strong><ul><li>ORMçš„å…¨ç§°ä¸ºObject Relational Mappingï¼Œå…¶åŸºæœ¬æ€æƒ³å°†å…³ç³»å‹æ•°æ®åº“ä¸­çš„æ•°æ®åˆ©ç”¨æŸç§æœºåˆ¶<em>æ˜ å°„ä¸ºJava å¯¹è±¡</em>ï¼Œåœ¨ä¸šåŠ¡é€»è¾‘æ„ä»¶çœ‹æ¥ï¼Œæ•°æ®åº“ä¸­çš„æ•°æ®ä»¥Java å¯¹è±¡çš„å½¢å¼å‡ºç°ï¼Œé€šå¸¸<em>æ¯ä¸ªå¯¹è±¡å¯¹åº”æ•°æ®åº“ä¸­çš„ä¸€æ¡è®°å½•</em>ï¼Œå› æ­¤æ•°æ®åº“æ“ä½œä¹Ÿå°±è½¬æ¢æˆäº†å¯¹Java å¯¹è±¡çš„æ“ä½œã€‚è€Œè¿™ç§æ•°æ®ä¸ Java å¯¹è±¡ä¹‹é—´çš„æ˜ å°„é€šå¸¸å¯ä»¥è·å¾—è‡ªåŠ¨åŒ–æœºåˆ¶çš„æ”¯æŒï¼Œä»è€Œå°†å¼€å‘äººå‘˜ä»åŸºäºJDBC çš„å¤æ‚å¼€å‘ä¸­è§£è„±å‡ºæ¥</li></ul></li></ul><p><em>å®ä½“æ„ä»¶</em></p><ul><li>æœ€å…¸å‹çš„æƒ…å†µæ˜¯ä¸€ä¸ª<code>EntityBean</code>å’Œæ•°æ®åº“ä¸­æœ‰ä¸€ä¸ª<em>è¡¨</em>ç›¸å¯¹åº”ï¼Œè€Œ<code>EntityBean</code>çš„æ¯ä¸€ä¸ª<em>å®ä¾‹</em>å¯¹åº”è¡¨ä¸­çš„<em>ä¸€è¡Œ</em>æ•°æ®</li><li><em>EntityBeanå’ŒSessionBeançš„ä¸åŒä¹‹å¤„</em><ul><li>EntityBeanæ˜¯æŒä¹…æ€§çš„<ul><li>åº”ç”¨ç¨‹åºç»“æŸæˆ–è€…æœåŠ¡å™¨ç»ˆæ­¢EntityBeançš„çŠ¶æ€ä»ç„¶ä¿ç•™</li></ul></li><li>å…è®¸å…±äº«è®¿é—®<ul><li>EntityBeanå¯ä»¥è¢«å¤šå®¢æˆ·ç«¯æ‰€å…±äº«</li></ul></li><li>æ‹¥æœ‰ä¸»é”®å¹¶ä¸”ä¼šå‚ä¸å’Œå…¶ä»–EntityBeançš„å…³è”</li></ul></li><li>ç”¨é€”<ul><li>Beanä»£è¡¨ä¸€ä¸ªå•†åŠ¡<em>å®ä½“</em>è€Œä¸æ˜¯ä¸€ä¸ªè¿‡ç¨‹<ul><li>ä¾‹å¦‚è¡¨ç¤º<em>ä¿¡ç”¨å¡</em>çš„<code>CreditCardEJB</code>è¦åšæˆ<code>EntityBean</code>ï¼Œ è€Œ<em>ä¿¡ç”¨å¡æ ¸å®</em>çš„<code>VerifierEJB</code>å°±åªèƒ½åšæˆ<code>Session Bean</code></li></ul></li><li>Beançš„çŠ¶æ€æ˜¯éœ€è¦<em>æŒä¹…å­˜å‚¨</em>çš„</li><li>æŒä¹…æ€§ç®¡ç†æœºåˆ¶<ul><li>BMPï¼šBeanç®¡ç†çš„æŒä¹…æ€§<ul><li>ç›¸å…³æ•°æ®åº“æ“ä½œ<em>ç”±å¼€å‘äººå‘˜åœ¨æ„ä»¶å®ç°ä»£ç ä¸­é€šè¿‡JDBC ç¼–ç¨‹å®ç°</em></li><li>é¡»åœ¨EntityBeanä¸­æ‰‹å·¥ç¼–å†™è®¿é—®æ•°æ®åº“çš„ä»£ç </li></ul></li><li><em>CMPï¼šå®¹å™¨ç®¡ç†çš„æŒä¹…æ€§</em><ul><li>ç›¸å…³æ•°æ®åº“æ“ä½œç”±å®¹å™¨è‡ªåŠ¨å®Œæˆï¼Œ<em>å®¹å™¨ä¼šè‡ªåŠ¨ç”Ÿæˆè®¿é—®æ•°æ®åº“çš„ä»£ç </em></li><li>å¼€å‘è€…æ— éœ€ä¸ºæ•°æ®åº“è®¿é—®ç¼–ç </li></ul></li></ul></li></ul></li><li>ç”Ÿå‘½å‘¨æœŸ<ul><li>å°±ç»ªçŠ¶æ€<ul><li>å®ä½“æ„ä»¶å®ä¾‹å»ºç«‹äº†ä¸EJBå¯¹è±¡çš„å…³è”ï¼Œå·²ç»å’Œæ•°æ®åº“è®°å½•å¯¹åº”èµ·æ¥ï¼Œå¯ä»¥å¤„ç†å®¢æˆ·åº”ç”¨çš„è¯·æ±‚</li></ul></li><li>ä¸å­˜åœ¨çŠ¶æ€</li><li>æ± çŠ¶æ€<ul><li>å®ä½“æ„ä»¶çš„å®ä¾‹å­˜åœ¨äºå®ä¾‹æ± ä¸­ï¼Œå®¹å™¨<em>æ–°åˆ›å»ºçš„å®ä¾‹</em>ä¼šè¿›å…¥è¿™ä¸ªçŠ¶æ€ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-25.png"></li></ul></li><li>å®¢æˆ·ç«¯ç¨‹åºè°ƒç”¨Homeæ¥å£ä¸­çš„æ–¹æ³•<em>åˆ›å»ºæˆ–æŸ¥æ‰¾</em>åˆ°æŸä¸ªå®ä½“æ„ä»¶å®ä¾‹æ—¶ï¼Œè¯¥å®ä¾‹ä¼šä»<em>æ± çŠ¶æ€</em>è¿›å…¥<em>å°±ç»ªçŠ¶æ€</em></li></ul></li><li><em>EBJ 1.1å®ä½“æ„ä»¶</em><ul><li>å°è£…æ•°æ®åº“ç¨ç‡è¡¨ä¸­çš„æ•°æ®æ“ä½œ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-26.png"></li><li>Remoteæ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-27.png"></li><li>Homeæ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-28.png"> Home æ¥å£ä¸­çš„æ“ä½œå®é™…ç”¨äºæ•°æ®åº“è¡¨ä¸­<em>è®°å½•</em>çš„åˆ›å»º (æ’å…¥)ã€æŸ¥æ‰¾ä¸åˆ é™¤</li><li>Enterprise Bean ç±» <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-29.png"></li></ul></li><li><em>EJB 2.0å®ä½“æ„ä»¶</em><ul><li><strong>åŒºåˆ«</strong><ul><li>Enterprise Bean ç±»çš„åŒºåˆ«<ul><li>åœ¨ EJB1.1 ä¸­ï¼ŒEnterprise Bean ç±»ç”±å¼€å‘äººå‘˜å®šä¹‰</li><li>åœ¨EJB2.0 ä¸­ï¼ŒEnterprise Bean ç±»ç”±å®¹å™¨ç”Ÿæˆï¼Œå¼€å‘äººå‘˜ä»…å®šä¹‰ä¸€ä¸ªæŠ½è±¡åŸºç±»</li></ul></li><li>Enterprise Bean æ•°æ®æˆå‘˜çš„åŒºåˆ«<ul><li>åœ¨EJB2.0 ä¸­ä¸<em>æ•°æ®åº“å­—æ®µå¯¹åº”çš„Beanå±æ€§ä¸ç”±ç”¨æˆ·å®šä¹‰</em>ï¼Œ ç”¨æˆ·ä»…å®šä¹‰å¯¹åº”çš„<code>set</code>å’Œ<code>get</code>æ–¹æ³•ï¼Œå…·ä½“å±æ€§çš„å®šä¹‰ç”±å®¹å™¨ç”Ÿæˆï¼Œè¿™æ ·å®¹å™¨å¯ä»¥å¯¹å±æ€§è¿›è¡Œä¼˜åŒ–</li><li>åœ¨EJB2.0 çš„CMPæ„ä»¶ä¸­ï¼Œè¿˜æœ‰ä¸€ç§ç‰¹æ®Šçš„å­—æ®µï¼Œ<em>cmr ( Container Managed Relationship)å­—æ®µ</em>ï¼Œç”¨äºå…³è”å…¶å®ƒçš„è¡¨(å®ä½“æ„ä»¶)ã€‚åœ¨ç»„è£…/ éƒ¨ç½²æ—¶ï¼Œ<em>å¯ä»¥è®¾ç½®ç”±å®¹å™¨è‡ªåŠ¨ç»´æŠ¤è¡¨ä¹‹é—´çš„å…³è”å…³ç³»</em></li></ul></li><li>æ¥å£åŒºåˆ«<ul><li>EJB2.0 å¼•å…¥äº†<em>æœ¬åœ°æ¥å£</em>ï¼Œå®ä½“æ„ä»¶çš„è¿›ç¨‹å†…å®¢æˆ·ç«¯å¯ä»¥é€šè¿‡æœ¬åœ°æ¥å£è·å¾—æ›´å¥½çš„è°ƒç”¨æ•ˆç‡</li></ul></li></ul></li><li>è®¢å•è¡¨ä¸é€è´§åœ°å€è¡¨ç»“æ„ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-30.png"> å¯ä»¥ä¸ºåœ°å€EJBæä¾›æœ¬åœ°æ¥å£ï¼Œè®¢å•EJBå¯é€šè¿‡åœ°å€ EJB çš„<em>æœ¬åœ°æ¥å£è·å¾—è¾ƒé«˜çš„è®¿é—®æ•ˆç‡</em></li><li>åœ°å€EJB: Localæ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-31.png"></li><li>åœ°å€EJB: LocalHomeæ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-32.png"></li><li>åœ°å€EJB: Enterprise Beanç±»çš„æŠ½è±¡åŸºç±» <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-33.png"> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-34.png"></li><li>è®¢å•EJB:Remote æ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-35.png"></li><li>è®¢å•EJB: Home æ¥å£ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-36.png"></li><li>è®¢å•EJB: Enterprise Beanç±»çš„æŠ½è±¡åŸºç±» <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-37.png"> â€¦. å®šä¹‰ä¸€ä¸ª <em>CMR(Container Managed Relationship)å­—æ®µ</em>å¯¹åº”çš„ä¸€å¯¹<code>set</code>ä¸<code>get</code>æ–¹æ³•ï¼ŒCMRå­—æ®µçš„ç±»å‹ä¸ºæ‰€å…³è”çš„å®ä½“æ„ä»¶çš„<em>Remoteæˆ– Localæ¥å£</em></li></ul></li></ul><p><em>æ€è€ƒé¢˜</em></p><ol type="1"><li>æœ‰çŠ¶æ€ä¼šè¯æ„ä»¶ä¸æ— çŠ¶æ€ä¼šè¯æ„ä»¶æœ‰ä»€ä¹ˆåŒºåˆ«? è¯·åˆ†åˆ«ä»å®šä¹‰ã€ç”Ÿå‘½å‘¨æœŸã€å¼€å‘ä¸éƒ¨ç½²çš„è§’åº¦è¿›è¡Œæè¿°ã€‚</li><li>ä»€ä¹ˆæ˜¯æœ‰çŠ¶æ€ä¼šè¯æ„ä»¶çš„ç”Ÿå‘½å‘¨æœŸçš„â€é’åŒ–â€œçŠ¶æ€?ä½œç”¨æ˜¯ä»€ä¹ˆ?</li><li>å®ä½“æ„ä»¶åŒ…æ‹¬å“ªä¸¤ç§æŒä¹…æ€§ç®¡ç†æœºåˆ¶?</li><li>EJB2.x çš„å®ä½“æ„ä»¶ä¸EJB1.x çš„å®ä½“æ„ä»¶æœ‰å“ªäº›ä¸»è¦åŒºåˆ«?</li><li><p>ä»¥ä¸‹ä¸ºå®ç°å¯ä¾›å®¢æˆ·ç«¯è¿œç¨‹è®¿é—®çš„ç½‘ä¸Šè´­ç‰©ç³»ç»Ÿä¸­è´­ç‰©è½¦åŠŸèƒ½çš„EJBæ„ä»¶çš„Home æ¥å£ä¸Remote æ¥å£ä»£ç ï¼Œè¯·åˆ†åˆ«æŒ‡å‡ºä»£ç ä¸­è¿èƒŒè®¾è®¡åŸåˆ™ä¹‹å¤„ ã€‚(16åˆ†) Remoteæ¥å£: <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> shopping;</span><br><span class="line"><span class="keyword">import</span> javax.ejb.*;</span><br><span class="line"><span class="keyword">import</span> java.rmi.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ShoppingBag</span> <span class="keyword">extends</span> <span class="title">EJBLocalObject</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addCom</span> <span class="params">(Commodity comm)</span>  <span class="keyword">throws</span> RemoteException</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeComm</span> <span class="params">(Commodity comm)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> NoSuchCommodityException</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">()</span> <span class="keyword">throws</span> BagEmptyException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Homeæ¥å£: <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> shopping;</span><br><span class="line"><span class="keyword">import</span> javax.ejb.*;</span><br><span class="line"><span class="keyword">import</span> java.rmi.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ShoppingBagHome</span> <span class="keyword">extends</span> <span class="title">EJBLocalHome</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> ShoppingBag <span class="title">create</span><span class="params">(String customerName)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> RemoteException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>ç­”ï¼š<ol type="1"><li><code>public interface ShoppingBag extends EJBLocalObject</code>è¿åç»§æ‰¿æ€§çº¦æŸï¼Œåº”ç»§æ‰¿<code>EJBObject</code></li><li>å‡½æ•°<code>removeComm</code>å’Œ<code>commitÂ </code>è¿åRMIçº¦æŸï¼Œåº”æŠ›å‡º<code>RemoteExceptionÂ </code>å¼‚å¸¸</li><li><code>public interface ShoppingBagHome extends EJBLocalHome</code>è¿åç»§æ‰¿æ€§çº¦æŸï¼Œåº”ç»§æ‰¿<code>EJBHome</code>4. å‡½æ•°<code>create</code>è¿åRMIçº¦æŸï¼Œè¿˜åº”æŠ›å‡º<code>CreateException</code>å¼‚å¸¸</li></ol></li></ol><h2><span id="rfidä¸­é—´ä»¶">RFIDä¸­é—´ä»¶</span></h2><p><em>RFIDç³»ç»Ÿæ„æˆ</em></p><ul><li>ç”µå­æ ‡ç­¾</li><li>è¯»å†™å™¨</li><li>ç³»ç»Ÿé«˜å±‚<ul><li>è®¡ç®—æœºç½‘ç»œ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-38.png"></li></ul></li></ul><p><em>RFIDä¸­é—´ä»¶çš„å¿…è¦æ€§</em></p><ul><li>æ•°æ®é‡‡é›†ç‚¹åˆ†æ•£ï¼Œè¯»å†™å™¨çŸ©é˜µã€æ ‡ç­¾æ‰“å°æˆ–è´´æ ‡ç­‰è®¾å¤‡å¤šæ ·ï¼Œ<em>ä¼—å¤šåº•å±‚ç¡¬ä»¶è®¾å¤‡éœ€ç»Ÿä¸€ç®¡ç†</em></li><li>ä¸€ä¸ªRFIDç³»ç»Ÿå¯èƒ½æœåŠ¡äºå¤šä¸ªåå°ç³»ç»Ÿï¼Œéœ€å¯¹<em>RFIDç«¯å£ä¸åå°ç³»ç»Ÿçš„å¯¹åº”å…³ç³»è¿›è¡Œç»Ÿä¸€ç®¡ç†</em></li><li>RFIDç³»ç»Ÿçš„åŸå§‹æ•°æ®é‡‡é›†æ˜¯åˆ†æ•£çš„ï¼Œéœ€<em>åˆ†å¸ƒå¼å¤„ç†çš„ç³»ç»Ÿç»“æ„</em></li><li>åå°åº”ç”¨ç³»ç»Ÿçš„ç°æœ‰ç»Ÿä¸€æ¥å£ä¸èƒ½æ»¡è¶³<em>è¯»å†™å™¨è®¾å¤‡</em>åŠå…¶<em>æ•°æ®é‡‡é›†åœºæ™¯</em>çš„<em>å¤šæ ·æ€§éœ€æ±‚</em></li><li>ä¸æ–­å¢åŠ çš„RFIDæ•°æ®é‡‡é›†ç«¯å£çš„<em>æµ·é‡æ•°æ®</em> ï¼Œå¹¶ä¸æ˜¯åå°åº”ç”¨ç³»ç»Ÿæ‰€ç›´æ¥éœ€è¦çš„ï¼Œå¿…é¡»ç»<em>è¿‡æ»¤åˆ†ç±»ã€ç»Ÿè®¡åˆ†æå¤„ç†</em>ä¹‹åï¼Œæ‰èƒ½æäº¤ä½¿ç”¨</li><li>éšç€åº”ç”¨çš„<em>æ‰©å¼ </em>éœ€æ±‚ï¼Œè¯»å†™å™¨æ•°é‡å’Œç§ç±» ä¼šæ›´æ–°æˆ–å¢åŠ ï¼Œåç«¯åº”ç”¨ç¨‹åºä¹Ÿä¼šå¢åŠ æˆ–æ”¹å˜ï¼Œå…¶æ•°æ®ç»“æ„æˆ–æ ¼å¼ä¹Ÿä¼šå‘ç”Ÿå˜åŒ–</li></ul><p><em>RFIDä¸­é—´ä»¶æ¦‚å¿µ</em> åœ¨RFIDåº”ç”¨ä¸­ï¼Œä¸ºRFIDç¡¬ä»¶å’Œåº”ç”¨ç¨‹åºäº¤äº’<strong>æä¾›é€šç”¨æœåŠ¡</strong>(å…·æœ‰æ ‡å‡†çš„ç¨‹åºæ¥å£å’Œåè®®)ï¼Œ<em>å®ç°åå°ç½‘ç»œä¸RFIDè¯»å†™å™¨æ— ç¼è¿æ¥çš„ä¸€é¡¹é‡è¦æŠ€æœ¯</em>ã€‚</p><p><em>RFIDä¸­é—´ä»¶åŠŸèƒ½</em></p><ul><li><em>ç¡¬ä»¶ç®¡ç†</em><ul><li>RFIDåŸºç¡€è®¾æ–½ç®¡ç†</li><li>è¿æ¥RFIDè¯»å†™å™¨ï¼Œè¯»å–RFIDæ ‡ç­¾æ•°æ®</li><li>æ§åˆ¶RFIDè¯»å†™è®¾å¤‡æŒ‰ç…§é¢„å®šçš„æ–¹å¼å·¥ä½œï¼Œä¿è¯ä¸åŒè¯»å†™è®¾å¤‡ä¹‹é—´èƒ½å¾ˆå¥½çš„é…åˆåè°ƒ</li></ul></li><li><em>æ•°æ®é‡‡é›†</em></li><li><em>æ•°æ®å¤„ç†</em><ul><li>åŠ å·¥å¤„ç†æ¥è‡ªè¯»å†™å™¨çš„æ‰€æœ‰ä¿¡æ¯å’Œäº‹ä»¶æµ</li><li>å¯¹æ ‡ç­¾æ•°æ®è¿›è¡Œè¿‡æ»¤ã€åˆ†ç»„å’Œè®¡æ•°ï¼Œä»¥å‡å°‘å‘å¾€ä¿¡æ¯ç½‘ç»œç³»ç»Ÿçš„æ•°æ®é‡</li><li>å¹¶é˜²æ­¢é”™è¯¯è¯†è¯»ã€å¤šè¯»ä¿¡æ¯ã€‚æŒ‰ç…§ä¸€å®šçš„è§„åˆ™ç­›é€‰è¿‡æ»¤æ•°æ® ï¼Œå»é™¤é˜…è¯»å™¨äº§ç”Ÿçš„å†—ä½™ã€é”™è¯¯çš„æ ‡ç­¾æ•°æ®ã€‚å°†çœŸæ­£æœ‰æ•ˆçš„æ•°æ®ä¼ é€ç»™åå°çš„ä¿¡æ¯ç³»ç»Ÿ</li><li>ç”ŸæˆæŠ¥å‘Šæ—¶åªä¸Šä¼ å…³å¿ƒçš„æ•°æ®(åˆ†ç»„ç»Ÿè®¡)</li></ul></li><li>æ•°æ®ä¼ è¾“<ul><li>ä¸ºåˆ†å¸ƒå¼å¼‚æ„ç¯å¢ƒä¸‹çš„åº”ç”¨ç¨‹åºæä¾›å¯é æ•°æ®é€šä¿¡æœåŠ¡ï¼Œä¿è¯è¯»å†™å™¨å’Œä¼ä¸šçº§åˆ†å¸ƒå¼åº”ç”¨ç³»ç»Ÿå¹³å°ä¹‹é—´çš„<em>å¯é é€šä¿¡</em></li></ul></li></ul><p><em>EPC GLOBAL</em></p><ul><li>ç»„æˆ<ul><li>ç”µå­äº§å“ç¼–ç EPC <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-39.png"><ul><li>Header (8bit) - Tag version number</li><li>EPC Manager (28bit) - Manufacturer ID</li><li>Object class (24bit) - Manufacturerâ€™s product ID</li><li>Serial Number (36bit) - Unit ID</li></ul></li><li>è¯†åˆ«ç³»ç»Ÿï¼ˆè¯»å†™å™¨å’Œç”µå­æ ‡ç­¾ï¼‰</li><li>ä¸­é—´ä»¶</li><li><em>ç‰©è”ç½‘åç§°è§£ææœåŠ¡ IOT-NS</em><ul><li>å°†ç”µå­æ ‡ç­¾è¯†åˆ«IDå·è½¬æ¢æˆå¯¹åº”çš„<em>ç»Ÿä¸€èµ„æºæ ‡è¯†ç¬¦ (URI)</em></li></ul></li><li><em>ç‰©è”ç½‘ä¿¡æ¯å‘å¸ƒæœåŠ¡ IOT-IS</em><ul><li>å¯¹ç‰©è”ç½‘ä¸­çš„ä¿¡æ¯è¿›è¡Œå¤„ç†å’Œå‘å¸ƒ</li><li>ç½‘ä¸Šå­˜æ”¾ç‰©å“ä¿¡æ¯çš„è®¡ç®—æœºç§°ä¸º<em>ç‰©è”ç½‘ä¿¡æ¯æœåŠ¡å™¨</em></li></ul></li></ul></li><li>æ„æˆ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-40.png"></li><li>æŠ€æœ¯è§„èŒƒ<ul><li>æ ‡ç­¾ç¼–ç è§„èŒƒ</li><li>å°„é¢‘æ ‡ç­¾é€»è¾‘é€šä¿¡æ¥å£è§„èŒƒ</li><li>Savantä¸­é—´ä»¶è§„èŒƒ</li><li>ONSå¯¹è±¡åç§°è§£ææœåŠ¡è§„èŒƒ</li><li>PMLè¯­è¨€</li></ul></li></ul><p><em>Savant</em></p><ul><li>SAVANTæ˜¯Auto-ID Centeræå‡ºçš„<em>åˆ†å±‚ã€æ¨¡å—åŒ–çš„ä¸­é—´ä»¶ç»„ä»¶</em>ï¼Œæ˜¯å…·æœ‰<em>æ•°æ®æ•è·ã€ç›‘æ§ã€ä¼ é€</em>åŠŸèƒ½çš„æ•°æ®æŒ–æ˜å·¥å…·</li><li>å¤„ç†æ¨¡å—ä¸å¤–éƒ¨ä¸–ç•Œçš„è”ç³»å°±é€šè¿‡2ä¸ªè§„èŒƒä¸­å®šä¹‰çš„æ¥å£å®ç°<ul><li><em>Readeræ¥å£</em>ï¼šæä¾›ä¸æ ‡ç­¾é˜…è¯»å™¨çš„è”ç³»</li><li><em>åº”ç”¨æ¥å£</em>ï¼šæä¾›ä¸å¤–éƒ¨åº”ç”¨è½¯ä»¶çš„è”ç³» <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-41.png"></li></ul></li><li>RFIDä¸­é—´ä»¶å’ŒEPCISæ•è·åº”ç”¨ä¹‹é—´ï¼Œå®šä¹‰äº†<em>RFIDäº‹ä»¶è¿‡æ»¤å’Œé‡‡é›†æ¥å£(ALE)Â </em> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-42.png"><ul><li>åŸºæœ¬æ“ä½œ<ul><li>åº”ç”¨å‘ä¸€ä¸ªè¯·æ±‚åˆ°ALEçš„æ¥å£è¦æ±‚è¯»æˆ–å†™æ ‡ç­¾ï¼ŒALE Engineå¤„ç†ä»è¯»å†™å™¨ä¼ å›æ¥çš„æ•°æ®äº§ç”ŸæŠ¥å‘Šè¿”å›ç»™åº”ç”¨</li></ul></li><li>è¯·æ±‚æ¨¡å¼ <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-43.png"> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-44.png"> <img src="/images/ç‰©è”ç½‘ä¸­é—´ä»¶æŠ€æœ¯/DraggedImage-45.png"></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœ¬ç§‘è¯¾ç¨‹ </tag>
            
            <tag> ç‰©è”ç½‘ </tag>
            
            <tag> ä¸­é—´ä»¶ </tag>
            
            <tag> Java </tag>
            
            <tag> EJB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Combined Multi-dimension Bloom Filter</title>
      <link href="/2017/04/19/Combined%20Multi-dimension%20Bloom%20Filter/"/>
      <url>/2017/04/19/Combined%20Multi-dimension%20Bloom%20Filter/</url>
      
        <content type="html"><![CDATA[<p>â€‹ A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not â€“ in other words, a query returns either &quot;possibly in set&quot; or &quot;definitely not in set&quot;. Elements can be added to the set, but not removed (though this can be addressed with a &quot;counting&quot; filter); the more elements that are added to the set, the larger the probability of false positives.</p><a id="more"></a><h2><span id="standard-bloom-filter">Standard Bloom Filter</span></h2><p>â€‹ Letâ€™s briefly review the standard bloom filter. A bloom filter is used to represent a set <span class="math inline">\(S = \{s_1, s_2, ...,s_n\}\)</span> with a m-bit array and each bit of which is denoted by <span class="math inline">\(BF[0], BF[1], â€¦, BF[m-1]\)</span>. Initially, the m-bit array is initiated with 0 and we define hash functions. Each of them can reflect each element <span class="math inline">\(x \in S\)</span> to a number <span class="math inline">\(h_i(x) \in \{0, 1, ..., m-1\}\)</span> randomly, where <span class="math inline">\(i \in \{0, 1, .., k-1\}\)</span>. Whenever inserting an element, hashing it with the <span class="math inline">\(k\)</span> hash functions, so we get <span class="math inline">\(k\)</span> indexes. Then letting <span class="math inline">\(BF[h_i(x)] = 1\)</span> for each <span class="math inline">\(i \in \{0, 1, .., k-1\}\)</span>. Given an element <span class="math inline">\(y\)</span>, we check each <span class="math inline">\(BF[h_i(y)]\)</span> , if all of them equal to <span class="math inline">\(1\)</span> , then we assume is in the set <span class="math inline">\(S\)</span> even though it may actually not. Hence a Bloom Filter may yield false positives. However, if there is one of them equals to <span class="math inline">\(0\)</span>, then the element <span class="math inline">\(y\)</span> is definitely not in the set <span class="math inline">\(S\)</span> .</p><p>â€‹ For example, after inserting <span class="math inline">\(x,y,z\)</span> , if we want to figure out whether <span class="math inline">\(w\)</span> is in the set, since <span class="math inline">\(BF[h_2(w)] = 0\)</span> , the Bloom Filter will tell us is not in the set, as illustrated in the figure Figure 1.</p><p><img src="/images/figure1.png"></p><p>â€‹ <strong>Figure 1 An example of Bloom Filter</strong></p><p>â€‹ In order to analyze the possibility that a Bloom Filter gives a false positive, we denote a Bloom Filter with a three-element tuple <span class="math inline">\((n,m,k)\)</span> and further assume that each <span class="math inline">\(\{0, 1, ..., m-1\}\)</span> hash function is uniform distributed, which means the number in has equal possibility to be chosen by a hash function. Therefore, given a hash function, the possibility of one specific position in BF equals to 0 is: <span class="math display">\[1 - \frac{1}{m}\]</span> Then, with respect to all hash functions, the possibility becomes to: <span class="math display">\[(1-\frac{1}{m})^k\]</span> After inserted elements, the possibility is: <span class="math display">\[(1-\frac{1}{m})^{nk}\]</span> If a specific item leads the Bloom Filter to yield a false positive, all of the results of must equal to 1, whose possibility is: <span class="math display">\[[1-(1-\frac{1}{m})^{nk}]^k\]</span> According to the definition of , we can approximately represent the possibility as: <span class="math display">\[f_{BBF} = [1-(1+\frac{1}{(-m)})^{(-m)\frac{nk}{(-m)}}]^k \approx (1-e^{-\frac{kn}{m}})^k\]</span> The standard Bloom Filter is basic for extension of Bloom Filters. From now on, it is termed basic Bloom Filter (BBF).</p><h2><span id="multi-dimension-bloom-filter">Multi-dimension Bloom Filter</span></h2><p>â€‹ In order to store multi-dimension data, for example <span class="math inline">\(l\)</span> dimensions, we can simply use <span class="math inline">\(l\)</span> basic Bloom Filters to store each dimension, which called a Multi-dimension Bloom Filter (MDBF). When we want to identify whether element <span class="math inline">\(x\)</span> is in the set, just compute <span class="math inline">\(BBF_1[x_0], ..., BBF_l[x_{l-1}]\)</span>, if all of them equal to <span class="math inline">\(1\)</span>, then we consider <span class="math inline">\(x\)</span> is one of the elements of the set. Similarly as the basic Bloom Filter, such multi-dimension Bloom Filter may also yield a false positive. However, if one of them equals to <span class="math inline">\(0\)</span>, the element <span class="math inline">\(x\)</span> certainly not belong to this set. Figure 2 illustrates that how a MDBF works.</p><p><img src="/images/figure2.png"></p><p>â€‹ <strong>Figure 2 Multi-dimension Bloom Filter illustration</strong></p><p>â€‹ Nonetheless, the false positive rate of such MDBF is not as ideal as expected, because it may give a false positive even if none of the basic Bloom Filters makes a false decision. For example, we have a set <span class="math inline">\(S = \{(red, blue), (blue, black)\}\)</span> and we want to figure out whether <span class="math inline">\((red, black)\)</span> is in <span class="math inline">\(S\)</span>. So the first BBF would say that is an attribute of the set and the second BBF says <span class="math inline">\(black\)</span> is also an attribute of <span class="math inline">\(S\)</span>, so the MDBF thinks <span class="math inline">\((red, black)\)</span> is a member of <span class="math inline">\(S\)</span>, which is obviously a false positive. Therefore, we need another Bloom Filter or couple of Bloom Filters to represent the combined information of each dimensional attribute to reduce the error rate.</p><h2><span id="combined-multi-dimension-bloom-filter">Combined Multi-dimension Bloom Filter</span></h2><p>â€‹ The ideal MDBF produces a false positive only when all of the basic Bloom Filters yield false positives, so the error rate of an ideal -dimension MDBF is: <span class="math display">\[f_{iMDBF} = (f_{BBF})^l = (1-e^{-\frac{kn}{m}})^{kl}\]</span> â€‹ To achieve such false positive rate, we need not only store the attribute of each dimension, but also have to store the relationship among all dimensions. One way to do this is adding a combined Bloom Filter to represent the combination of each attribute, which is called combined multi-dimension Bloom Filter (CMDBF). The question is how to represent such combined information. A simple solution is using the result of XOR different dimensional attributesâ€™ hashing indexes as the hash index of the combined Bloom Filter, which is <span class="math inline">\(CBF[h_{1,i}[x_0]\oplus h_{2,i}[x_1] ... \oplus h_{l,i}[x_{l-1}]]=1\)</span> for <span class="math inline">\(i \in \{0, 1, ..,k-1\}\)</span>, where <span class="math inline">\(CBF\)</span> refers to the combined Bloom Filter, as illustrated in Figure 3.</p><p><img src="/images/figure3.png"></p><p>â€‹ <strong>Figure 3 Combined Multi-dimension Bloom Filter illustration</strong></p><p>â€‹ Obviously, the error rate of CMDBF is lower than MDBF since CMDBF has a combined Bloom Filter to represent the relationship among all the dimensions. CMDBF will make a false positive when some of the basic Bloom Filters make mistakes as well as the combined Bloom Filter yields a false decision.</p><p>â€‹ Letâ€™s mathematically compute the error rate of CMDBF, we represent a CMDBF by a 4-tuple <span class="math inline">\((n,m,k,l)\)</span>, where <span class="math inline">\(n\)</span> represents the number of elements in the set, <span class="math inline">\(m\)</span> represents the size of a basic Bloom Filter, <span class="math inline">\(k\)</span> represents the number of hash functions each basic Bloom Filter has, and <span class="math inline">\(l\)</span> represents the dimensions of the elements. Since <span class="math display">\[h_{1,i}[x_0], h_{2,i}[x_1] ... , h_{l,i}[x_{l-1}] \sim U(0, m-1)\]</span> where , therefore, <span class="math display">\[h_{1,i}[x_0]\oplus h_{2,i}[x_1] ... \oplus h_{l,i}[x_{l-1}]\sim U(0,m-1)\]</span> So, the false positive rate of CBF equals to that of BBF, <span class="math display">\[f_{CBF} = f_{BBF} =  (1-e^{-\frac{kn}{m}})^k\]</span> Then, the error rate of CMDBF is <span class="math display">\[f_{CMDBF} = f_{MDBF}f_{CBF} = f_{MDBF}(1-e^{-\frac{kn}{m}})^k\]</span> Since <span class="math inline">\(0&lt;(1-e^{-\frac{kn}{m}})^k&lt;1\)</span>, the false positive rate of CMDBF is lower than that of MDBF.</p><h2><span id="conclusion">Conclusion</span></h2><p>â€‹ Even though the combined multi-dimension Bloom Filter consumes more space of a m-bit array, it can represent the multi-dimension elements as a whole entity rather than represents it as many independent attributes, which contributes to a lower false positive rate significantly.</p><h2><span id="references">References</span></h2><p>[1] DEKE G, HONGHUI C, JIE W, et al. Theory and network application of dynamic bloom filters[A]. Proc of IEEE Infocom Barcelona[C]. Spain, 2006. 1-12.</p><p>[2] XIE Kun, QIN Zheng, et al. Combine multi-dimension Bloom filter for membership queries. Journal on Communications.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Bloom Filter </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å°„é¢‘è¯†åˆ«æŠ€æœ¯ï¼ˆRFIDï¼‰</title>
      <link href="/2017/01/08/RFID/"/>
      <url>/2017/01/08/RFID/</url>
      
        <content type="html"><![CDATA[<p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#ç¬¬ä¸€ç« -ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯">ç¬¬ä¸€ç«  ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯</a><ul><li><a href="#ç‰©è”ç½‘åŸºæœ¬æ¦‚å¿µ">ç‰©è”ç½‘åŸºæœ¬æ¦‚å¿µ</a></li><li><a href="#ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯">ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯</a></li><li><a href="#ä¼ ç»Ÿè‡ªåŠ¨è¯†åˆ«æŠ€æœ¯">ä¼ ç»Ÿè‡ªåŠ¨è¯†åˆ«æŠ€æœ¯</a></li></ul></li><li><a href="#ç¬¬äºŒç« -æ¡å½¢ç åŸºæœ¬æ¦‚å¿µ">ç¬¬äºŒç«  æ¡å½¢ç åŸºæœ¬æ¦‚å¿µ</a><ul><li><a href="#æ¡å½¢ç barcodeåŸºæœ¬çŸ¥è¯†">æ¡å½¢ç (Barcode)åŸºæœ¬çŸ¥è¯†</a></li><li><a href="#å•†å“æ¡ç ">å•†å“æ¡ç </a><ul><li><a href="#ean-13ç ">EAN-13ç </a></li><li><a href="#ean-8ç ">EAN-8ç </a></li><li><a href="#upc-a">UPC-A</a></li><li><a href="#upc-eç ">UPC-Eç </a></li><li><a href="#åº“å¾·å·´æ¡ç ">åº“å¾·å·´æ¡ç </a></li><li><a href="#128æ¡ç ">128æ¡ç </a></li></ul></li><li><a href="#isbnç å’Œissnç ">ISBNç å’ŒISSNç </a><ul><li><a href="#isbn">ISBN</a></li><li><a href="#issn">ISSN</a></li></ul></li><li><a href="#å¿«é€Ÿå“åº”çŸ©é˜µç ">å¿«é€Ÿå“åº”çŸ©é˜µç </a></li></ul></li><li><a href="#ç¬¬ä¸‰ç« -æ¡ç è¯†åˆ«æŠ€æœ¯åŠåº”ç”¨">ç¬¬ä¸‰ç«  æ¡ç è¯†åˆ«æŠ€æœ¯åŠåº”ç”¨</a></li><li><a href="#ç¬¬å››ç« -å°„é¢‘è¯†åˆ«æŠ€æœ¯">ç¬¬å››ç«  å°„é¢‘è¯†åˆ«æŠ€æœ¯</a><ul><li><a href="#rfidç³»ç»Ÿç»„æˆåŠç‰¹ç‚¹">RFIDç³»ç»Ÿç»„æˆåŠç‰¹ç‚¹</a></li><li><a href="#rfidæŠ€æœ¯çš„ç†è®ºåŸºç¡€">RFIDæŠ€æœ¯çš„ç†è®ºåŸºç¡€</a><ul><li><a href="#æ•°æ®ä¼ è¾“åŸç†">æ•°æ®ä¼ è¾“åŸç†</a></li><li><a href="#èƒ½é‡ä¼ è¾“åŸç†">èƒ½é‡ä¼ è¾“åŸç†</a></li><li><a href="#æ•°æ®ä¼ è¾“ç¼–ç ">æ•°æ®ä¼ è¾“ç¼–ç </a></li><li><a href="#æ•°æ®æ ¡éªŒæ–¹æ³•">æ•°æ®æ ¡éªŒæ–¹æ³•</a></li></ul></li><li><a href="#rfidç³»ç»Ÿå·¥ç¨‹">RFIDç³»ç»Ÿå·¥ç¨‹</a><ul><li><a href="#rfidç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡">RFIDç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡</a></li></ul></li><li><a href="#rfidæŠ€æœ¯çš„åº”ç”¨å‘å±•é¢ä¸´çš„é—®é¢˜">RFIDæŠ€æœ¯çš„åº”ç”¨å‘å±•é¢ä¸´çš„é—®é¢˜</a></li></ul></li><li><a href="#ç¬¬äº”ç« -ç”µå­æ ‡ç­¾">ç¬¬äº”ç«  ç”µå­æ ‡ç­¾</a><ul><li><a href="#ç”µå­æ ‡ç­¾çš„ç»„æˆåŠå·¥ä½œåŸç†">ç”µå­æ ‡ç­¾çš„ç»„æˆåŠå·¥ä½œåŸç†</a><ul><li><a href="#mifare-1å°„é¢‘å¡çš„ç»“æ„">Mifare 1å°„é¢‘å¡çš„ç»“æ„</a></li><li><a href="#mifare-1å°„é¢‘å¡çš„ç‰¹ç‚¹">Mifare 1å°„é¢‘å¡çš„ç‰¹ç‚¹</a></li><li><a href="#mifare-1å°„é¢‘å¡çš„å­˜å‚¨ç»“æ„">Mifare 1å°„é¢‘å¡çš„å­˜å‚¨ç»“æ„</a></li></ul></li><li><a href="#ç”µå­æ ‡ç­¾ç§ç±»">ç”µå­æ ‡ç­¾ç§ç±»</a><ul><li><a href="#æŒ‰èƒ½é‡æ¥æºåˆ†ç±»">æŒ‰èƒ½é‡æ¥æºåˆ†ç±»</a></li><li><a href="#æŒ‰å·¥ä½œé¢‘ç‡åˆ†ç±»">æŒ‰å·¥ä½œé¢‘ç‡åˆ†ç±»</a></li><li><a href="#æŒ‰æ ‡ç­¾è¯»å†™æ–¹å¼åˆ†ç±»">æŒ‰æ ‡ç­¾è¯»å†™æ–¹å¼åˆ†ç±»</a></li><li><a href="#æŒ‰æ ‡ç­¾ç”¨é€”åˆ†ç±»">æŒ‰æ ‡ç­¾ç”¨é€”åˆ†ç±»</a></li><li><a href="#æŒ‰æ ‡ç­¾åŠŸèƒ½åˆ†ç±»">æŒ‰æ ‡ç­¾åŠŸèƒ½åˆ†ç±»</a></li></ul></li><li><a href="#åŒé¢‘rfidç³»ç»Ÿ">åŒé¢‘RFIDç³»ç»Ÿ</a><ul><li><a href="#æœ‰æºç³»ç»Ÿ">æœ‰æºç³»ç»Ÿ</a></li><li><a href="#æ— æºç³»ç»Ÿ">æ— æºç³»ç»Ÿ</a></li><li><a href="#åŒé¢‘rfidç³»ç»Ÿçš„åº”ç”¨">åŒé¢‘RFIDç³»ç»Ÿçš„åº”ç”¨</a></li></ul></li><li><a href="#ç”µå­æ ‡ç­¾åè®®">ç”µå­æ ‡ç­¾åè®®</a></li><li><a href="#ç”µå­æ ‡ç­¾çš„å¤©çº¿">ç”µå­æ ‡ç­¾çš„å¤©çº¿</a></li><li><a href="#ç”µå­æ ‡ç­¾ä¿¡æ¯çš„å†™å…¥æ–¹å¼">ç”µå­æ ‡ç­¾ä¿¡æ¯çš„å†™å…¥æ–¹å¼</a></li><li><a href="#ç”µå­æ ‡ç­¾æ€§èƒ½å› ç´ ">ç”µå­æ ‡ç­¾æ€§èƒ½å› ç´ </a></li></ul></li><li><a href="#ç¬¬å…­ç« -è¯»å†™å™¨">ç¬¬å…­ç«  è¯»å†™å™¨</a><ul><li><a href="#è¯»å†™å™¨çš„å·¥ä½œåŸç†">è¯»å†™å™¨çš„å·¥ä½œåŸç†</a><ul><li><a href="#è¯»å†™å™¨å·¥ä½œæµç¨‹">è¯»å†™å™¨å·¥ä½œæµç¨‹</a></li></ul></li><li><a href="#è¯»å†™å™¨å¤©çº¿">è¯»å†™å™¨å¤©çº¿</a><ul><li><a href="#è¯»å†™å™¨çš„å¤©çº¿ç§ç±»">è¯»å†™å™¨çš„å¤©çº¿ç§ç±»</a></li></ul></li><li><a href="#è¯»å†™å™¨çš„å‘å±•è¶‹åŠ¿">è¯»å†™å™¨çš„å‘å±•è¶‹åŠ¿</a></li><li><a href="#ä½œä¸š">ä½œä¸š</a></li></ul></li><li><a href="#ç¬¬ä¸ƒç« -rfidæŠ€æœ¯æ ‡å‡†ä½“ç³»">ç¬¬ä¸ƒç«  RFIDæŠ€æœ¯æ ‡å‡†ä½“ç³»</a><ul><li><a href="#rfidæ ‡å‡†ä½“ç³»">RFIDæ ‡å‡†ä½“ç³»</a></li></ul></li><li><a href="#ç¬¬å…«ç« -rfidç³»ç»Ÿå…³é”®æŠ€æœ¯">ç¬¬å…«ç«  RFIDç³»ç»Ÿå…³é”®æŠ€æœ¯</a><ul><li><a href="#rfidç³»ç»Ÿçš„å®‰å…¨æŠ€æœ¯">RFIDç³»ç»Ÿçš„å®‰å…¨æŠ€æœ¯</a><ul><li><a href="#rfidç³»ç»Ÿçš„å®‰å…¨éœ€æ±‚">RFIDç³»ç»Ÿçš„å®‰å…¨éœ€æ±‚</a></li><li><a href="#rfidå®‰å…¨æŠ€æœ¯">RFIDå®‰å…¨æŠ€æœ¯</a></li></ul></li><li><a href="#å¤šæ ‡ç­¾è¯†åˆ«æŠ€æœ¯">å¤šæ ‡ç­¾è¯†åˆ«æŠ€æœ¯</a></li><li><a href="#å¤šè¯»å†™å™¨é˜²ç¢°æ’æŠ€æœ¯">å¤šè¯»å†™å™¨é˜²ç¢°æ’æŠ€æœ¯</a></li></ul></li><li><a href="#ç¬¬ä¹ç« -rfidåº”ç”¨ç³»ç»Ÿçš„æ„å»º">ç¬¬ä¹ç«  RFIDåº”ç”¨ç³»ç»Ÿçš„æ„å»º</a><ul><li><a href="#ç”µå­æ ‡ç­¾é€‰æ‹©">ç”µå­æ ‡ç­¾é€‰æ‹©</a></li><li><a href="#è¯»å†™å™¨é€‰æ‹©">è¯»å†™å™¨é€‰æ‹©</a></li></ul></li><li><a href="#ç¬¬åç« -rfidæŠ€æœ¯åº”ç”¨">ç¬¬åç«  RFIDæŠ€æœ¯åº”ç”¨</a><ul><li><a href="#åŸºäºrfidçš„å…¸å‹ç‰©è”ç½‘ç³»ç»Ÿepc">åŸºäºRFIDçš„å…¸å‹ç‰©è”ç½‘ç³»ç»ŸEPC</a></li></ul></li><li><a href="#ç”µå­é’±åŒ…">ç”µå­é’±åŒ…</a></li><li><a href="#rfidæœ¯è¯­">RFIDæœ¯è¯­</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="ç¬¬ä¸€ç« -ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯">ç¬¬ä¸€ç«  ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯</span></h2><h3><span id="ç‰©è”ç½‘åŸºæœ¬æ¦‚å¿µ">ç‰©è”ç½‘åŸºæœ¬æ¦‚å¿µ</span></h3><ul><li>ç‰©è”ç½‘å°±æ˜¯â€œç‰©ç‰©ç›¸è¿çš„äº’è”ç½‘â€ï¼Œå…¶ç›®æ ‡æ˜¯å°†æ‰€æœ‰ç‰©ä½“è”ç³»èµ·æ¥å½¢æˆä¸€ä¸ªåºå¤§çš„<strong>ç‰©ç‰©ç›¸è¿</strong>çš„äº’è”ç½‘ç»œã€‚<ul><li>ç¬¬ä¸€ï¼Œç‰©è”ç½‘çš„<strong>æ ¸å¿ƒå’ŒåŸºç¡€ä»ç„¶æ˜¯äº’è”ç½‘</strong>ï¼Œæ˜¯åœ¨äº’è”ç½‘åŸºç¡€ä¸Šçš„å»¶ä¼¸å’Œæ‰©å±•çš„ç½‘ç»œ;</li><li>ç¬¬äºŒï¼Œå…¶ç”¨æˆ·ç«¯å»¶ä¼¸å’Œæ‰©å±•åˆ°äº†<strong>ä»»ä½•ç‰©ä½“ä¸ç‰©ä½“ä¹‹é—´</strong>ï¼Œè¿›è¡Œä¿¡æ¯äº¤æ¢å’Œé€šä¿¡ã€‚</li></ul></li><li>ç‰©è”ç½‘çš„å®æ–½éœ€è¦ä¸‰ä¸ªæ­¥éª¤<ul><li>ç‰©ä½“æ ‡è¯†</li><li>æ„ŸçŸ¥ä¸è·å–</li><li>é€šä¿¡ä¸è®¡ç®—</li></ul></li><li>å±‚æ¬¡-P3<ul><li>æ„ŸçŸ¥å±‚</li><li>ç½‘ç»œå±‚</li><li>åº”ç”¨å±‚</li></ul></li></ul><h3><span id="ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯">ç‰©è”ç½‘è¯†åˆ«æŠ€æœ¯</span></h3><p>ç‰©èƒ½å¤Ÿå¼€å£è¯´è¯çš„æ¡ä»¶</p><ol type="1"><li>è¦æœ‰ç›¸åº”çš„æ¥æ”¶å™¨</li><li>è¦æœ‰æ•°æ®ä¼ è¾“é€šè·¯</li><li>è¦æœ‰ä¸€å®šçš„å­˜å‚¨åŠŸèƒ½</li><li>è¦æœ‰ä¸­å¤®å¤„ç†å™¨</li><li>è¦æœ‰æ“ä½œç³»ç»Ÿ</li><li>è¦æœ‰ä¸“é—¨çš„åº”ç”¨ç¨‹åº</li><li>è¦æœ‰æ•°æ®å‘é€å™¨</li><li>éµå¾ªç‰©è”ç½‘çš„å„ç§åè®®</li><li>åœ¨ä¸–ç•Œç½‘ç»œä¸­æœ‰å¯è¢«è¯†åˆ«çš„å”¯ä¸€ç¼–å·</li></ol><h3><span id="ä¼ ç»Ÿè‡ªåŠ¨è¯†åˆ«æŠ€æœ¯">ä¼ ç»Ÿè‡ªåŠ¨è¯†åˆ«æŠ€æœ¯</span></h3><ul><li>ç£æ¡æŠ€æœ¯ ä»¥å‰é“¶è¡Œå¡</li><li>ç”Ÿç‰©ç‰¹å¾è¯†åˆ«æŠ€æœ¯ æŒ‡çº¹è¯†åˆ«ï¼Œè™¹è†œè¯†åˆ«</li><li>è¯­éŸ³è¯†åˆ«æŠ€æœ¯<br></li><li>å›¾åƒè¯†åˆ«æŠ€æœ¯ è½¦ç‰Œè¯†åˆ«ã€é¥æ„ŸæŠ€æœ¯ã€åŒ»ç”¨å›¾åƒå¤„ç†</li><li>å…‰å­¦å­—ç¬¦è¯†åˆ«æŠ€æœ¯ ä¼ çœŸã€æ‰«æå’Œå¤å°</li><li>æ¡ç è¯†åˆ«æŠ€æœ¯ è¶…å¸‚å•†å“</li><li>ICå¡è¯†åˆ«æŠ€æœ¯ æ‰‹æœºå¡ã€å…¬äº¤å¡</li></ul><h2><span id="ç¬¬äºŒç« -æ¡å½¢ç åŸºæœ¬æ¦‚å¿µ">ç¬¬äºŒç«  æ¡å½¢ç åŸºæœ¬æ¦‚å¿µ</span></h2><h3><span id="æ¡å½¢ç barcodeåŸºæœ¬çŸ¥è¯†">æ¡å½¢ç (Barcode)åŸºæœ¬çŸ¥è¯†</span></h3><p>æ¡ç æŠ€æœ¯åŒ…æ‹¬ï¼š</p><ul><li>ç¼–ç æŠ€æœ¯</li><li>ç¬¦å·æŠ€æœ¯</li><li>è¯†è¯»æŠ€æœ¯</li><li>å°åˆ·æŠ€æœ¯</li><li>æ£€æµ‹æŠ€æœ¯</li></ul><p>æ¡ç çš„åˆ†ç±»</p><ul><li>æŒ‰æ¡ç çš„é•¿åº¦å¯åˆ†ä¸ºï¼š<ul><li>å®šé•¿æ¡ç <ul><li>å¦‚EAN-13</li></ul></li><li>éå®šé•¿æ¡ç <ul><li>å¦‚EAN-128</li></ul></li></ul></li><li>æŒ‰æ’åˆ—æ–¹å¼å¯åˆ†ä¸ºï¼š<ul><li>è¿ç»­å‹æ¡ç ï¼šæ¯ä¸ªæ¡ç å­—ç¬¦ä¹‹é—´ä¸å­˜åœ¨é—´éš”</li><li>éè¿ç»­å‹æ¡ç ï¼šæ¯ä¸ªæ¡ç å­—ç¬¦ä¹‹é—´å­˜åœ¨é—´éš”</li></ul></li><li>ä»æ ¡éªŒæ–¹å¼å¯åˆ†ä¸ºï¼š<ul><li>è‡ªæ ¡éªŒå‹æ¡ç </li><li>éè‡ªæ ¡éªŒå‹æ¡ç </li></ul></li><li>æŒ‰ç»´æ•°å¯åˆ†ä¸ºï¼š<ul><li>ä¸€ç»´ç </li><li>äºŒç»´ç </li><li>ä¸‰ç»´ç </li></ul></li></ul><h3><span id="å•†å“æ¡ç ">å•†å“æ¡ç </span></h3><ul><li>EAN-13</li><li>EAN-8</li><li>UPC-A</li><li>UPC-E</li></ul><h4><span id="ean-13ç ">EAN-13ç </span></h4><p>European Article Number æ¬§æ´²ç‰©å“ç¼–ç </p><ul><li>å…±13ä½ä»£ç </li><li>æ¯”è¾ƒé€šç”¨</li><li>ä¸»è¦åº”ç”¨äºè¶…å¸‚å’Œå…¶ä»–é›¶å”®ä¸š</li></ul><p>ç¼–ç </p><ul><li>å‰ç¼€ç </li><li>å‚å•†è¯†åˆ«ä»£ç </li><li>å•†å“é¡¹ç›®ä»£ç </li><li>æ ¡éªŒç </li></ul><p>ç»“æ„</p><ul><li>å·¦ä¾§ç©ºç™½åŒº</li><li>èµ·å§‹ç¬¦</li><li>å·¦ä¾§æ•°æ®ç¬¦</li><li>ä¸­é—´åˆ†éš”ç¬¦</li><li>å³ä¾§æ•°æ®ç¬¦</li><li>æ ¡éªŒç¬¦</li><li>ç»ˆæ­¢ç¬¦</li><li>å³ä¾§ç©ºç™½åŒº</li></ul><h4><span id="ean-8ç ">EAN-8ç </span></h4><ul><li>å…±8ä½æ•°ï¼ŒåŒ…æ‹¬å›½åˆ«ç 2ä½ï¼Œäº§å“ä»£ç 5ä½åŠæ£€æŸ¥ç 1ä½</li><li>å·¦å³èµ„æ–™ç¼–ç è§„åˆ™åŒEAN-13</li><li>æ¡ç é¢ç§¯å°</li></ul><h4><span id="upc-a">UPC-A</span></h4><p>UPC-Aå•†å“æ¡ç æ˜¯ç”¨æ¥è¡¨ç¤ºUCC-12å•†å“æ ‡è¯†ä»£ç çš„æ¡ç ç¬¦å·ï¼Œç”±ç¾å›½ç»Ÿä¸€ä»£ç å§”å‘˜ä¼š(UCC)åˆ¶å®šçš„ä¸€ç§æ¡ç ç åˆ¶ã€‚</p><ul><li>ç»“æ„åŸºæœ¬ä¸EAN-13ç›¸åŒï¼Œ12ä½</li><li>UPC-Aæ¡ç æ˜¯EAN-13ç çš„ä¸€ç§ç‰¹æ®Šå½¢å¼ï¼ŒUPC-Aæ¡ç ä¸EAN-13ç ä¸­N1=0å…¼å®¹</li></ul><h4><span id="upc-eç ">UPC-Eç </span></h4><p>åœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼Œ12ä½çš„UPC-Aæ¡ç å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸€ç§<strong>ç¼©çŸ­å½¢å¼</strong>çš„æ¡ç ç¬¦å·å³UPC-Eæ¡ç </p><ul><li>ä¸å«ä¸­é—´åˆ†éš”ç¬¦å’Œæ ¡éªŒç¬¦</li></ul><h4><span id="åº“å¾·å·´æ¡ç ">åº“å¾·å·´æ¡ç </span></h4><ul><li>åº“å¾·å·´æ¡ç æ˜¯ä¸€ç§æ¡ã€ç©ºå‡è¡¨ç¤ºä¿¡æ¯çš„éè¿ç»­å‹ã€éå®šé•¿ã€å…·æœ‰è‡ªæ ¡éªŒåŠŸèƒ½çš„åŒå‘æ¡ç ã€‚å®ƒç”±æ¡ç å­—ç¬¦åŠå¯¹åº”çš„ä¾›äººè¯†åˆ«å­—ç¬¦ç»„æˆã€‚</li><li>å®ƒçš„å­—ç¬¦é›†å…±åŒ…æ‹¬16ä¸ªå­—ç¬¦: å³æ•°å­—å­—ç¬¦0<sub>9(10ä¸ªæ•°å­—)ã€è‹±æ–‡å­—æ¯A</sub>D(4ä¸ªå­—æ¯)å’Œç‰¹æ®Šå­—ç¬¦â€œ+â€(åŠ å·) ã€â€œ-â€ (å‡å·)ã€â€œ$â€(ç¾å…ƒç¬¦å·)ã€â€œ:â€(å†’å·)ã€â€œ/â€(æ–œæ )ã€â€œÂ·â€(åœ†ç‚¹)ã€‚</li><li>åº“å¾·å·´æ¡ç ç”±å·¦ä¾§ç©ºç™½åŒºã€èµ·å§‹ç¬¦ã€æ•°æ®ç¬¦ã€ç»ˆæ­¢ç¬¦åŠå³ä¾§ç©ºç™½åŒºæ„æˆ</li></ul><h4><span id="128æ¡ç ">128æ¡ç </span></h4><p>EAN-128ç å¼€å§‹äº1981å¹´æ¨å‡ºï¼Œæ˜¯ä¸€ç§é•¿åº¦å¯å˜ã€è¿ç»­æ€§çš„å­—æ¯æ•°å­—æ¡ç ï¼Œè¾ƒä¸ºå¤æ‚ï¼Œä½†å…¶æ‰€èƒ½æ”¯æŒçš„å­—ç¬¦æ¯”å…¶ä»–ä¸€ç»´æ¡ç å¤šï¼Œæœ‰ä¸åŒçš„ç¼–ç æ–¹å¼å¯ä¾›äº¤äº’è¿ç”¨ï¼Œå› æ­¤å…¶åº”ç”¨å¼¹æ€§è¾ƒå¤§ã€‚</p><ul><li>å¯åº”ç”¨æ–¼è´§è¿æ ˆç‰ˆæ ‡ç­¾ã€æºå¸¦å¼èµ„æ–™åº“ã€è¿ç»­æ€§èµ„æ–™æ®µã€æµé€šé…é€æ ‡ç­¾ç­‰</li><li>UCC/EAN-128æ¡ç æ˜¯å”¯ä¸€èƒ½å¤Ÿè¡¨ç¤ºåº”ç”¨æ ‡è¯†çš„æ¡ç ç¬¦å·ã€‚UCC/EAN-128 å¯ç¼–ç çš„ä¿¡æ¯åŒ…æ‹¬é¡¹ç›®æ ‡è¯†ã€è®¡é‡ã€æ•°é‡ã€æ—¥æœŸã€äº¤æ˜“å‚è€ƒä¿¡æ¯ã€ä½ç½®ç­‰</li></ul><h3><span id="isbnç å’Œissnç ">ISBNç å’ŒISSNç </span></h3><ul><li>ISBN (International Standard Book Number)<ul><li><strong>å›½é™…æ ‡å‡†ä¹¦å·</strong></li></ul></li><li>ISSN(International Standard Serial Number)<ul><li><strong>å›½é™…æ ‡å‡†æœŸåˆŠå·</strong></li></ul></li></ul><h4><span id="isbn">ISBN</span></h4><ul><li>2007.1.1å‰ï¼ŒISBNç”±10ä½æ•°å­—ç»„æˆï¼Œåˆ†å››ä¸ªéƒ¨åˆ†:ç»„å·(å›½å®¶ã€åœ°åŒºã€è¯­è¨€çš„ä»£å·)ï¼Œå‡ºç‰ˆç¤¾å·ï¼Œä¹¦åºå·å’Œæ£€éªŒç ã€‚</li><li>2007.1.1èµ·ï¼Œå®è¡Œæ–°ç‰ˆISBNï¼Œç”±13ä½æ•°å­—ç»„æˆï¼Œåˆ†ä¸º5æ®µï¼Œå³åœ¨åŸæ¥çš„10ä½æ•°å­—å‰åŠ ä¸Š3ä½EANå›¾ä¹¦äº§å“ä»£ç â€œ978â€</li><li>ç›®çš„å’Œä½œç”¨<ul><li>æœ‰åŠ©äºç®€åŒ–å›¾ä¹¦å‘è¡ŒåŠç®¡ç†æ‰‹ç»­ï¼Œä¾¿äºå‡ºç‰ˆå“ç»Ÿè®¡åŠå›½é™…äº¤æµã€‚</li><li>ä¸–ç•Œå„åœ°çš„å‡ºç‰ˆæœºæ„ã€ä¹¦å•†ã€åŠå›¾ä¹¦é¦†éƒ½å¯ä»¥åˆ©ç”¨å›½é™…æ ‡å‡†ä¹¦å·è¿…é€Ÿè€Œæœ‰æ•ˆçš„è¯†åˆ«æŸä¸€æœ¬ä¹¦åŠå…¶ç‰ˆæœ¬ã€è£…è®¢å½¢å¼ã€‚</li><li>ä¸è®ºåŸä¹¦æ˜¯ä»¥ä½•ç§æ–‡å­—ä¹¦å†™ï¼Œéƒ½å¯ç”¨ç”µæŠ¥æˆ–ç”µè¯ä¼ çœŸè®¢è´­ï¼Œå¹¶ä»¥ç”µè„‘ä½œä¸šå¤„ç†ã€‚</li></ul></li></ul><h4><span id="issn">ISSN</span></h4><ul><li>å¸¸è§çš„æœŸåˆŠã€æ‚å¿—ã€ä¸›åˆŠã€å¹´åˆŠç­‰å¤§éƒ½å±äºå›½é™…æ ‡å‡†æœŸåˆŠå·çš„ç¼–å·ä¸ç¼–ç èŒƒå›´ã€‚æ¯ä¸€ç§æœŸåˆŠåœ¨æ³¨å†Œç™»è®°æ—¶ï¼Œå°±å¾—åˆ°ä¸€ä¸ªæ°¸ä¹…ä¸“å±çš„ ISSN ï¼Œ<strong>ä¸€ä¸ª ISSN åªå¯¹åº”ä¸€ä¸ªåˆŠå;è€Œä¸€ä¸ªåˆŠåä¹Ÿåªæœ‰ä¸€ä¸ªISSN</strong>ã€‚</li><li>å½“è¯¥åˆŠåå˜æ›´æ—¶ï¼Œå°±å¾—å¦ç”³è¯·ä¸€ä¸ª ISSN ã€‚å¦‚æœæœŸåˆŠåœåˆŠï¼Œé‚£ä¹ˆè¢«åˆ é™¤çš„ ISSN ä¹Ÿä¸ä¼šè¢«å…¶ä»–æœŸåˆŠå†ä½¿ç”¨ã€‚</li></ul><h3><span id="å¿«é€Ÿå“åº”çŸ©é˜µç ">å¿«é€Ÿå“åº”çŸ©é˜µç </span></h3><p>QR Code - Quick Response</p><ul><li>è¶…é«˜é€Ÿè¯†è¯»</li><li>å¯é æ€§é«˜ã€æˆæœ¬ä½</li><li>æ•°æ®å®¹é‡å¤§</li><li>å…¨æ–¹ä½è¯†è¯»</li><li>èƒ½å¤Ÿæœ‰æ•ˆåœ°è¡¨ç¤ºä¸­å›½æ±‰å­—ã€æ—¥æœ¬æ±‰å­—ã€å›¾åƒ<em>???</em></li><li>ä¿å¯†é˜²ä¼ªæ€§å¼ºã€ä½¿ç”¨æ–¹ä¾¿</li></ul><h2><span id="ç¬¬ä¸‰ç« -æ¡ç è¯†åˆ«æŠ€æœ¯åŠåº”ç”¨">ç¬¬ä¸‰ç«  æ¡ç è¯†åˆ«æŠ€æœ¯åŠåº”ç”¨</span></h2><p>ç›¸å…³æœ¯è¯­</p><ul><li>æ¡ç è¯†è¯»å™¨(Barcode Reader)</li><li>æ‰«æå™¨(Scanner)</li><li>è¯‘ç (Decode)</li><li>è¯‘ç å™¨(Decoder)</li><li>é¦–è¯»ç‡(FirstReadRate)</li><li>è¯¯ç ç‡(Misread Rate)</li><li>æ‹’è¯†ç‡(Non-read Rate)</li></ul><h2><span id="ç¬¬å››ç« -å°„é¢‘è¯†åˆ«æŠ€æœ¯">ç¬¬å››ç«  å°„é¢‘è¯†åˆ«æŠ€æœ¯</span></h2><h3><span id="rfidç³»ç»Ÿç»„æˆåŠç‰¹ç‚¹">RFIDç³»ç»Ÿç»„æˆåŠç‰¹ç‚¹</span></h3><p>ç»„æˆ</p><ul><li>ç”µå­æ ‡ç­¾</li><li>è¯»å†™å™¨</li><li>æ•°æ®ç®¡ç†ç³»ç»Ÿ</li></ul><p>ä¸æ¡ç è¯†åˆ«æŠ€æœ¯çš„æ ¹æœ¬å·®åˆ«</p><ul><li>æ¡ç æŠ€æœ¯æ˜¯ä¸€ç§<strong>å…‰å­¦æŠ€æœ¯</strong></li><li>RFIDæ˜¯ä¸€ç§<strong>æ— çº¿ç”µæŠ€æœ¯</strong></li></ul><p>ç‰¹ç‚¹</p><ol type="1"><li>è¯†åˆ«é€Ÿåº¦å¿«ã€è¯†åˆ«è·ç¦»è¿œ</li><li>ä½“ç§¯å°å‹åŒ–ï¼Œå½¢çŠ¶å¤šæ ·åŒ–ï¼Œæ˜“å°è£…</li><li>æŠ—æ±¡æŸ“èƒ½åŠ›å’Œè€ä¹…æ€§</li><li>å¯é‡å¤ä½¿ç”¨</li><li>ç©¿é€æ€§å’Œæ— å±éšœé˜…è¯»</li><li>æ•°æ®çš„è®°å¿†å®¹é‡å¤§</li><li>å®‰å…¨æ€§è¾ƒé«˜</li></ol><h3><span id="rfidæŠ€æœ¯çš„ç†è®ºåŸºç¡€">RFIDæŠ€æœ¯çš„ç†è®ºåŸºç¡€</span></h3><p>RFIDæŠ€æœ¯ä½œä¸ºä¸€ç§éæ¥è§¦å¼çš„è‡ªåŠ¨è¯†åˆ«æŠ€æœ¯ï¼Œå…¶æ•°æ®é€šä¿¡åŸºç¡€å°±æ˜¯è¯»å†™å™¨ä¸ç”µå­æ ‡ç­¾ä¹‹é—´çš„<strong>æ— çº¿è½½æ³¢é€šä¿¡æŠ€æœ¯</strong>ã€‚</p><h4><span id="æ•°æ®ä¼ è¾“åŸç†">æ•°æ®ä¼ è¾“åŸç†</span></h4><p>åœ¨RFIDç³»ç»Ÿä¸­ï¼Œè¯»å†™å™¨å’Œç”µå­æ ‡ç­¾ä¹‹é—´çš„é€šä¿¡é€šè¿‡ç”µç£æ³¢æ¥å®ç°ã€‚</p><ul><li>æŒ‰ç…§é€šä¿¡è·ç¦»ï¼Œå¯ä»¥åˆ’åˆ†ä¸º<strong>è¿‘åœºå’Œè¿œåœº</strong>ã€‚ç›¸åº”çš„ï¼Œè¯»å†™å™¨å’Œç”µå­æ ‡ç­¾ä¹‹é—´çš„æ•°æ®äº¤æ¢æ–¹å¼è¢«åˆ’åˆ†:<ol type="1"><li>è´Ÿè½½è°ƒåˆ¶<ol type="1"><li>è´Ÿè½½è°ƒåˆ¶å°±æ˜¯åˆ©ç”¨è´Ÿè½½çš„æŸäº›å·®å¼‚æˆ–è´Ÿè½½çš„å˜åŠ¨è€Œä½¿æºçš„æŸç§æˆ–æŸäº›å‚æ•°å‘ç”Ÿç›¸åº”æ”¹å˜çš„è¿‡ç¨‹æˆ–æ•ˆåº”</li></ol></li><li>åå‘æ•£å°„è°ƒåˆ¶<ol type="1"><li>é›·è¾¾åŸç†æ¨¡å‹ï¼Œå‘å°„å‡ºå»çš„ç”µç£æ³¢ï¼Œç¢°åˆ°ç›®æ ‡ååå°„ï¼ŒåŒæ—¶æºå¸¦å›ç›®æ ‡ä¿¡æ¯ï¼Œä¾æ®çš„æ˜¯<strong>ç”µç£æ³¢çš„ç©ºé—´ä¼ æ’­è§„å¾‹</strong></li></ol></li></ol></li></ul><h4><span id="èƒ½é‡ä¼ è¾“åŸç†">èƒ½é‡ä¼ è¾“åŸç†</span></h4><ul><li>æ— æºRFIDç³»ç»Ÿçš„ç”µå­æ ‡ç­¾é€šè¿‡ç”µç£åœºä¾›ç”µï¼Œç”µå­æ ‡ç­¾çš„åŠŸè€—è¶Šå¤§ï¼Œè¯»å†™è·ç¦»è¶Šè¿‘ï¼Œæ€§èƒ½è¶Šå·®</li></ul><h4><span id="æ•°æ®ä¼ è¾“ç¼–ç ">æ•°æ®ä¼ è¾“ç¼–ç </span></h4><p>æ•°æ®ç¼–ç æ˜¯å°†æ•°æ®è¡¨ç¤ºæˆé€‚å½“çš„ä¿¡å·å½¢å¼ï¼Œä»¥ä¾¿æ•°æ®çš„ä¼ è¾“å’Œå¤„ç†ã€‚åœ¨æ•°æ®ä¼ è¾“ç³»ç»Ÿä¸­ï¼Œæœ‰ä¸‰ç§æ•°æ®ç¼–ç æŠ€æœ¯:</p><ul><li>æ•°å­—æ•°æ®çš„æ¨¡æ‹Ÿä¿¡å·ç¼–ç <ul><li>å¹…ç§»é”®æ§(ASK)æ³•</li><li>é¢‘ç§»é”®æ§(FSK)æ³• (Frequency Shift Keying)</li><li>ç›¸ç§»é”®æ§(PSK)æ³• (Phase Shift Keying)</li></ul></li><li>æ•°å­—æ•°æ®çš„æ•°å­—ä¿¡å·ç¼–ç <ul><li>è„‰å†²ç¼–ç è°ƒåˆ¶PCM(Pulse Code Modulation)æŠ€æœ¯</li></ul></li><li>æ¨¡æ‹Ÿæ•°æ®çš„æ•°å­—ä¿¡å·ç¼–ç <ul><li>ä¸ºäº†é«˜ä¿¡å·æŠ—å¹²æ‰°èƒ½åŠ›ï¼Œå¹¶ä¸”ä¾¿äºä¿¡å·æ¥æ”¶åŒæ­¥ï¼Œé€šå¸¸é‡‡ç”¨æ›´ä¸ºæœ‰æ•ˆçš„ä¿¡å·ç¼–ç æ–¹æ³• (ä¸å½’é›¶ç ã€å·®åˆ†ä¸å½’é›¶ç ã€æ›¼å½»æ–¯ç‰¹ç åŠå·®åˆ†æ›¼å½»æ–¯ç‰¹ç ç­‰)</li></ul></li></ul><p><img src="/images/code.png"></p><p>ä¼˜ç¼ºç‚¹</p><p>é€‰æ‹©ç¼–ç æ–¹å¼çš„è€ƒè™‘å› ç´ </p><ul><li>ç¼–ç æ–¹å¼çš„é€‰æ‹©è¦è€ƒè™‘ç”µå­æ ‡ç­¾èƒ½é‡çš„æ¥æº</li><li>ç¼–ç æ–¹å¼çš„é€‰æ‹©è¦è€ƒè™‘æ•°æ®çš„æ ¡éªŒå’Œä¿æŠ¤</li><li>ç¼–ç æ–¹å¼çš„é€‰æ‹©è¦è€ƒè™‘æ•°æ®çš„æ£€æµ‹é”™è¯¯èƒ½åŠ›</li></ul><h4><span id="æ•°æ®æ ¡éªŒæ–¹æ³•">æ•°æ®æ ¡éªŒæ–¹æ³•</span></h4><ul><li>å¥‡å¶æ ¡éªŒï¼ˆParity Checkï¼‰</li><li>çºµå‘å†—ä½™æ ¡éªŒï¼ˆLongitudinal Redundancy Check, LRCï¼‰</li><li>å¾ªç¯å†—ä½™ç æ ¡éªŒï¼ˆCyclic Redundancy Check, CRCï¼‰</li></ul><h3><span id="rfidç³»ç»Ÿå·¥ç¨‹">RFIDç³»ç»Ÿå·¥ç¨‹</span></h3><p>RFIDç³»ç»Ÿå€ŸåŠ©ç©ºé—´ä¼ è¾“é€šé“å·¥ä½œçš„è¿‡ç¨‹å¯å½’ç»“ä¸ºä¸‰ç§äº‹ä»¶æ¨¡å‹:èƒ½é‡ã€æ—¶åºå’Œæ•°æ®ã€‚èƒ½é‡æ˜¯æ—¶åºå¾—ä»¥å®ç°çš„åŸºç¡€ï¼Œæ—¶åºæ˜¯æ•°æ®äº¤æ¢çš„å®ç°æ–¹å¼ï¼Œæ•°æ®äº¤æ¢æ˜¯ç›®çš„ã€‚</p><h4><span id="rfidç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡">RFIDç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡</span></h4><ol type="1"><li>æ•°æ®ä¼ è¾“é€Ÿç‡<ol type="1"><li>åªè¯»é€Ÿç‡</li><li>æ— é™è¯»å†™é€Ÿç‡</li><li>æœ‰é™è¯»å†™é€Ÿç‡</li></ol></li><li>è¯»å†™è·ç¦»</li><li>ç”µå­æ ‡ç­¾ä¸å¤©çº¿é—´çš„å°„é¢‘è½½æ³¢é¢‘ç‡</li><li>å¤šæ ‡ç­¾è¯»å†™ç‰¹æ€§</li><li>ç”µå­æ ‡ç­¾å­˜å‚¨å®¹é‡</li><li>å·¥ä½œæ–¹å¼<ol type="1"><li>å…¨åŒå·¥(Full Duplexï¼ŒFDX)</li><li>åŠåŒå·¥(Half Duplexï¼ŒHDX)</li><li>æ—¶åº(Sequenceï¼ŒSEQ)</li></ol></li><li>RFIDç³»ç»Ÿçš„æ¥å£å½¢å¼<ul><li>RS232, RS482, RJ45, éŸ¦æ ¹, æ— çº¿ç½‘ç»œ</li></ul></li><li>æ•°æ®è½½ä½“<ol type="1"><li>EEPROM:ç”µå¯æ“¦å¯ç¼–ç¨‹åªè¯»å­˜å‚¨å™¨ï¼ˆä¸»è¦ä½¿ç”¨ï¼‰</li><li>FRAM: Ferroelectric Random Access Memoryé“ç”µéšæœºå­˜å–å­˜å‚¨å™¨</li><li>SRAM: é™æ€éšæœºå­˜å–å­˜å‚¨å™¨</li></ol></li><li>çŠ¶æ€æ¨¡å¼</li><li>èƒ½é‡ä¾›åº”æ–¹å¼</li></ol><h3><span id="rfidæŠ€æœ¯çš„åº”ç”¨å‘å±•é¢ä¸´çš„é—®é¢˜">RFIDæŠ€æœ¯çš„åº”ç”¨å‘å±•é¢ä¸´çš„é—®é¢˜</span></h3><ol type="1"><li>æ ‡å‡†åˆ¶å®šé—®é¢˜</li><li>æ ‡ç­¾æˆæœ¬é—®é¢˜</li><li>å…³é”®æŠ€æœ¯é—®é¢˜<ul><li>å¦‚å¤šæ ‡ç­¾è¯†åˆ«é—®é¢˜ã€é˜²ç¢°æ’æŠ€æœ¯é—®é¢˜ã€é«˜é€Ÿè¿åŠ¨ä¸­çš„å¯¹è±¡è¯†åˆ«é—®é¢˜ç­‰ç­‰</li></ul></li><li>å®‰å…¨ä¸éšç§é—®é¢˜</li></ol><h2><span id="ç¬¬äº”ç« -ç”µå­æ ‡ç­¾">ç¬¬äº”ç«  ç”µå­æ ‡ç­¾</span></h2><h3><span id="ç”µå­æ ‡ç­¾çš„ç»„æˆåŠå·¥ä½œåŸç†">ç”µå­æ ‡ç­¾çš„ç»„æˆåŠå·¥ä½œåŸç†</span></h3><p><strong>ç”µå­æ ‡ç­¾=å¤©çº¿(æˆ–çº¿åœˆ)+æ ‡ç­¾èŠ¯ç‰‡</strong></p><ul><li>æ ‡ç­¾èŠ¯ç‰‡ç›¸å½“äºä¸€ä¸ªå•ç‰‡ç³»ç»Ÿ(SoC):æ”¶å‘åŠŸèƒ½+å­˜è´®åŠŸèƒ½</li></ul><p>ä»çº¯æŠ€æœ¯çš„è§’åº¦æ¥è¯´ï¼Œå°„é¢‘è¯†åˆ«æŠ€æœ¯çš„æ ¸å¿ƒåœ¨ç”µå­æ ‡ç­¾ï¼Œé˜…è¯»å™¨æ˜¯æ ¹æ®ç”µå­æ ‡ç­¾çš„è®¾è®¡è€Œè®¾è®¡çš„ã€‚</p><p>æ ‡ç­¾èŠ¯ç‰‡ä¸€èˆ¬<strong>ç”±ç¼–ç /è§£ç å™¨ã€ç”µæºã€è§£è°ƒå™¨ã€å­˜å‚¨å™¨ã€æ§åˆ¶å™¨å’Œè´Ÿè½½è°ƒåˆ¶</strong>ç»„æˆã€‚</p><h4><span id="mifare-1å°„é¢‘å¡çš„ç»“æ„">Mifare 1å°„é¢‘å¡çš„ç»“æ„</span></h4><p>ï® Mifare 1 ICå°„é¢‘å¡é‡‡ç”¨å…ˆè¿›çš„èŠ¯ç‰‡å·¥è‰ºåˆ¶ä½œï¼Œå†…å»ºæœ‰é«˜é€Ÿçš„CMOSã€EEPROMå’ŒMCUç­‰ï¼Œå¡ç‰‡çš„ç”µæ°”éƒ¨åˆ†:</p><ul><li>å¤©çº¿:å¡ç‰‡çš„å¤©çº¿æ˜¯åªæœ‰å‡ ç»„ç»•çº¿çš„çº¿åœˆã€‚</li><li>ASIC:å¡ç‰‡çš„ASICç”±ä¸€ä¸ªé«˜é€Ÿ(106KBæ³¢ç‰¹ç‡)çš„RFæ¥å£ï¼Œä¸€ä¸ªæ§åˆ¶å•å…ƒå’Œä¸€ä¸ª8Kä½EEPROMç»„æˆã€‚</li></ul><h4><span id="mifare-1å°„é¢‘å¡çš„ç‰¹ç‚¹">Mifare 1å°„é¢‘å¡çš„ç‰¹ç‚¹</span></h4><ul><li><p>M1å¡æ‰€å…·æœ‰çš„ç‹¬ç‰¹çš„Mifareå°„é¢‘æ¥å£æ ‡å‡†å·²è¢«åˆ¶å®šä¸ºå›½é™…æ ‡å‡†ISO/IEC 14443 TYPE A æ ‡å‡†ã€‚</p></li><li><p>M1å¡ä¸Šå…·æœ‰å…ˆè¿›çš„æ•°æ®é€šä¿¡åŠ å¯†å’ŒåŒå‘éªŒè¯å¯†ç ç³»ç»Ÿï¼Œè€Œä¸”å…·æœ‰é˜²å†²çªåŠŸèƒ½ï¼Œèƒ½åœ¨åŒä¸€æ—¶é—´å¤„ç†è¯»å†™å™¨å¤©çº¿çš„æœ‰æ•ˆå·¥ä½œè·ç¦»å†…å†²çªçš„å¤šå¼ å¡ç‰‡ã€‚</p></li><li><p>M1å¡ä¸è¯»å†™å™¨é€šä¿¡ä½¿ç”¨æ¡æ‰‹å¼åŠåŒå·¥é€šä¿¡åè®®ï¼Œå¡ç‰‡ä¸Šæœ‰é«˜é€Ÿçš„CRCåå¤„ç†å™¨ï¼Œç¬¦åˆCCITTæ ‡å‡†ã€‚</p></li><li><p>å¡ç‰‡åˆ¶é€ æ—¶å…·æœ‰å”¯ä¸€çš„å¡ç‰‡ç³»åˆ—å·ï¼Œæ²¡æœ‰é‡å¤çš„ç›¸åŒçš„ä¸¤å¼ Mifareå¡ç‰‡ã€‚</p></li><li><p>å¡ç‰‡ä¸Šå†…å»º8 K ä½ EEPROM å­˜å‚¨å®¹é‡ï¼Œå¹¶åˆ’åˆ†ä¸º16ä¸ªæ‰‡åŒºï¼Œæ¯ä¸ªæ‰‡åŒºåˆ’åˆ†ä¸º4ä¸ªæ•°æ®å­˜å‚¨å—ï¼Œæ¯ä¸ªæ‰‡åŒºå¯ç”±å¤šç§æ–¹å¼çš„å¯†ç ç®¡ç†ã€‚</p></li><li><p>å¡ç‰‡ä¸Šè¿˜å†…å»ºæœ‰å¢å€¼/å‡å€¼çš„ä¸“é¡¹çš„æ•°å­¦è¿ç®—ç”µè·¯ï¼Œéå¸¸é€‚åˆå…¬äº¤ã€åœ°é“ç­‰è¡Œä¸šçš„æ£€ç¥¨ã€æ”¶è´¹ç³»ç»Ÿç­‰å…¸å‹çš„å¿«æ·äº¤æ˜“ï¼Œæ—¶é—´æœ€é•¿ä¸è¶…è¿‡100 msã€‚</p></li></ul><h4><span id="mifare-1å°„é¢‘å¡çš„å­˜å‚¨ç»“æ„">Mifare 1å°„é¢‘å¡çš„å­˜å‚¨ç»“æ„</span></h4><p>M1å¡çš„å­˜å‚¨å®¹é‡ä¸º8192ä½Ã—1ä½å­—é•¿ï¼Œå³1KÃ—8ä½å­—é•¿ã€‚é‡‡ç”¨EEPROMä½œä¸ºå­˜å‚¨ä»‹è´¨ã€‚</p><p>æ•´ä¸ªç»“æ„åˆ’åˆ†ä¸º16ä¸ªæ‰‡åŒºï¼Œç¼–å·ä¸º0~15;</p><ul><li>æ¯ä¸ªæ‰‡åŒºç”±4å—(Block)ï¼Œåˆ†åˆ«ä¸ºå—0ã€å—1ã€å—2ã€å—3ï¼Œæ¯å—æœ‰16ä¸ªå­—èŠ‚ï¼Œä¸€ä¸ªæ‰‡åŒºå…±æœ‰64ä¸ªå­—èŠ‚</li><li>å®é™…ä¸­ï¼Œä¹Ÿå¯å°†16ä¸ªæ‰‡åŒºçš„64ä¸ªå—æŒ‰ç»å¯¹åœ°å€ç¼–å·ä¸º0~63ã€‚</li><li>ç¬¬0æ‰‡åŒºçš„å—0(å³ç»å¯¹åœ°å€0å—)ï¼Œå®ƒç”¨äºå­˜æ”¾å‚å•†ä»£ç ï¼Œå·²ç»å›ºåŒ–ï¼Œä¸å¯æ›´æ”¹ã€‚å…¶ä¸­å­—èŠ‚0~3ä¸ºå¡çš„åºåˆ—å·;å­—èŠ‚4ä¸ºåºåˆ—å·çš„æ ¡éªŒç ;å­—èŠ‚5ä¸ºå¡ç‰‡å¤§å°çš„æ•°å€¼;å­—èŠ‚6å’Œå­—èŠ‚7ä¸ºå¡çš„ç±»å‹å·ï¼Œå³Tag typeå­—èŠ‚;å…¶ä»–å­—èŠ‚ç”±å‚å•†å¦åŠ å®šä¹‰ã€‚</li></ul><h3><span id="ç”µå­æ ‡ç­¾ç§ç±»">ç”µå­æ ‡ç­¾ç§ç±»</span></h3><h4><span id="æŒ‰èƒ½é‡æ¥æºåˆ†ç±»">æŒ‰èƒ½é‡æ¥æºåˆ†ç±»</span></h4><ul><li>è·å–ç”µèƒ½æ–¹å¼<ul><li>æ— æºæ ‡ç­¾ï¼ˆä¸»æµï¼‰</li><li>åŠæœ‰æºæ ‡ç­¾</li><li>æœ‰æºæ ‡ç­¾</li></ul></li><li>ä½¿ç”¨ç”µèƒ½æ–¹å¼<ul><li>è¢«åŠ¨å¼æ ‡ç­¾<ul><li>å¿…é¡»åˆ©ç”¨è¯»å†™å™¨çš„è½½æ³¢æ¥è°ƒåˆ¶è‡ªèº«çš„ä¿¡å·ï¼Œæ ‡ç­¾äº§ç”Ÿç”µèƒ½çš„è£…ç½®æ˜¯å¤©çº¿å’Œçº¿åœˆ</li></ul></li><li>åŠè¢«åŠ¨å¼æ ‡ç­¾<ul><li>ç”µå­æ ‡ç­¾æœ¬èº«å¸¦æœ‰ç”µæ± ï¼Œä½†æ˜¯æ ‡ç­¾å¹¶ä¸é€šè¿‡è‡ªèº«èƒ½é‡ä¸»åŠ¨å‘é€æ•°æ®ç»™è¯»å†™å™¨ï¼Œç”µæ± åªè´Ÿè´£å¯¹æ ‡ç­¾å†…éƒ¨ç”µè·¯ä¾›ç”µ</li></ul></li><li>ä¸»åŠ¨å¼æ ‡ç­¾<ul><li>æœ‰æºç³»ç»Ÿï¼Œç”¨è‡ªèº«èƒ½é‡ä¸»åŠ¨åœ°å‘é€æ•°æ®ç»™è¯»å†™å™¨</li></ul></li></ul></li></ul><h4><span id="æŒ‰å·¥ä½œé¢‘ç‡åˆ†ç±»">æŒ‰å·¥ä½œé¢‘ç‡åˆ†ç±»</span></h4><ul><li>ä½é¢‘ç”µå­æ ‡ç­¾ï¼ˆ30ï½300kHzï¼‰<ul><li>ä½é¢‘æ ‡ç­¾ä¸€èˆ¬ä¸ºæ— æºå¼ç”µå­æ ‡ç­¾ï¼Œå…¶å·¥ä½œèƒ½é‡é€šè¿‡ç”µæ„Ÿè€¦åˆæ–¹å¼ä»è¯»å†™å™¨è€¦åˆçº¿åœˆçš„è¾å°„è¿‘åœºä¸­è·å¾—</li><li>ä¼˜åŠ¿<ul><li>æ ‡ç­¾èŠ¯ç‰‡ä¸€èˆ¬é‡‡ç”¨æ™®é€šçš„CMOSå·¥è‰ºï¼Œå…·æœ‰çœç”µã€å»‰ä»·çš„ç‰¹ç‚¹;</li><li>å·¥ä½œé¢‘ç‡ä¸å—æ— çº¿ç”µé¢‘ç‡ç®¡åˆ¶çº¦æŸ;</li><li>å¯ä»¥ç©¿é€æ°´ã€æœ‰æœºç»„ç»‡ã€æœ¨æç­‰ï¼Œç²˜é™„åœ¨è£…æœ‰æ°´ã€åŠ¨ç‰©ç»„ç»‡ã€é‡‘å±ã€æœ¨æå’Œæ¶²ä½“çš„å®¹å™¨ä¸Š</li><li>éå¸¸é€‚åˆè¿‘è·ç¦»ã€ä½é€Ÿåº¦ã€æ•°æ®é‡è¦æ±‚è¾ƒå°‘çš„è¯†åˆ«åº”ç”¨ç­‰</li></ul></li><li>åŠ£åŠ¿<ul><li>æ•°æ®ä¼ è¾“é€Ÿç‡æœ€ä½ï¼Œæ ‡ç­¾å­˜è´®æ•°æ®é‡ä¹Ÿè¾ƒå°‘ï¼Œåªèƒ½é€‚åˆä½é€Ÿã€è¿‘è·ç¦»è¯†åˆ«åº”ç”¨</li><li>ä½é¢‘ç”µå­æ ‡ç­¾çµæ´»æ€§å·®ï¼Œä¸æ˜“è¢«è¯†åˆ«;</li><li>ä¸è¶…é«˜é¢‘æ ‡ç­¾ç›¸æ¯”:æ ‡ç­¾å¤©çº¿åŒæ•°æ›´å¤šï¼Œæˆæœ¬æ›´é«˜ä¸€äº›;</li><li>ä½é¢‘æ ‡ç­¾æ²¡æœ‰é˜²ç¢°æ’èƒ½åŠ›ï¼Œè¯»å–ç”µå­æ ‡ç­¾æ•°æ®æ—¶åªèƒ½ä¸€å¯¹ä¸€è¿›è¡Œè¯»å–ï¼Œä¸å¯èƒ½åŒæ—¶è¯»å–å¤šä¸ªæ ‡ç­¾</li></ul></li><li>ä¸»è¦åº”ç”¨<ul><li>ç‰§ä¸šçš„ç®¡ç†ç³»ç»Ÿ</li><li>æ±½è½¦é˜²ç›—å’Œæ— é’¥åŒ™å¼€é—¨ç³»ç»Ÿçš„åº”ç”¨</li><li>é©¬æ‹‰æ¾èµ›è·‘ç³»ç»Ÿçš„åº”ç”¨</li><li>åŠ¨åœè½¦åœºæ”¶è´¹å’Œè½¦è¾†ç®¡ç†ç³»ç»Ÿ</li><li>åŠ¨åŠ æ²¹ç³»ç»Ÿçš„åº”ç”¨</li><li>é…’åº—é—¨é”ç³»ç»Ÿçš„åº”ç”¨</li><li>é—¨ç¦å’Œå®‰å…¨ç®¡ç†ç³»ç»Ÿ</li></ul></li></ul></li><li>ä¸­é«˜é¢‘ç”µå­æ ‡ç­¾ï¼ˆ3ï½30MHzï¼Œå…¸å‹13.56MHzï¼‰<ul><li>æ— æºï¼Œä¸ä½é¢‘åŸç†ä¸€æ ·</li></ul></li><li>è¶…é«˜é¢‘æ ‡ç­¾ï¼ˆ300ï½1000MHzï¼‰<ul><li>433MHzé¢‘ç‡ç”¨äºä¸»åŠ¨å¼æ ‡ç­¾ï¼Œè€Œ860~960MHzé¢‘æ®µå¤§éƒ¨åˆ†ç”¨äºè¢«åŠ¨å¼æ ‡ç­¾å’Œä¸€äº›åŠè¢«åŠ¨å¼æ ‡ç­¾</li><li>860~960MHzè¿™ä¸€é¢‘æ®µå¸¸å¸¸å¯è®¤ä¸ºæ˜¯ä¸€ä¸ªå•ç‹¬çš„é¢‘ç‡900MHzæˆ–è€…915MHzã€‚å·¥ä½œåœ¨è¿™ä¸€é¢‘æ®µçš„æ ‡ç­¾å’Œè¯»å†™å™¨ç§°ä¸ºè¶…é«˜é¢‘æ ‡ç­¾å’Œè¶…é«˜é¢‘è¯»å†™å™¨</li></ul></li><li>å¾®æ³¢æ ‡ç­¾<ul><li>å¾®æ³¢é¢‘æ®µä»1~10GHzï¼Œä½†RFIDåº”ç”¨å…¬ä½¿ç”¨å…¶ä¸­çš„ä¸¤ä¸ªé¢‘æ®µ:2.45GHzå’Œ5.8GHz</li></ul></li></ul><h4><span id="æŒ‰æ ‡ç­¾è¯»å†™æ–¹å¼åˆ†ç±»">æŒ‰æ ‡ç­¾è¯»å†™æ–¹å¼åˆ†ç±»</span></h4><ul><li>åªè¯»æ ‡ç­¾<ul><li>å†…éƒ¨åªæœ‰åªè¯»å­˜å‚¨å™¨(Read Only Memory, ROM)</li></ul></li><li>å¯è¯»å¯å†™æ ‡ç­¾<ul><li>éšæœºå­˜å–å™¨(Random Access Memory, RAM)</li></ul></li><li>ä¸€æ¬¡å†™å…¥å¤šæ¬¡è¯»å‡ºæ ‡ç­¾<ul><li>ä¸€æ¬¡å†™å…¥å¤šæ¬¡è¯»å‡º(Write Once Read Many, WORM)</li></ul></li></ul><h4><span id="æŒ‰æ ‡ç­¾ç”¨é€”åˆ†ç±»">æŒ‰æ ‡ç­¾ç”¨é€”åˆ†ç±»</span></h4><p>å¾ˆå¤šï¼Œå¦‚æ¸©åº¦ã€æŒ¯åŠ¨ã€åŒé¢‘é˜²ç›—ç­‰</p><h4><span id="æŒ‰æ ‡ç­¾åŠŸèƒ½åˆ†ç±»">æŒ‰æ ‡ç­¾åŠŸèƒ½åˆ†ç±»</span></h4><ul><li>1ä½ç”µå­æ ‡ç­¾ğŸ·ï¸<ul><li>åªèƒ½è¡¨ç¤ºä¸¤ä¸ªçŠ¶æ€1å’Œ0</li><li>å®ƒæ˜¯æœ€æ—©çš„å•†ç”¨ç”µå­æ ‡ç­¾ï¼Œä¸»è¦åº”ç”¨åœ¨20ä¸–çºª60å¹´ä»£çš„å•†å“ç”µå­ç›‘è§†å™¨(EAS)ä¸­ã€‚å®ƒ<strong>ä¸éœ€è¦èŠ¯ç‰‡</strong>ï¼Œå¯ä»¥é‡‡ç”¨<strong>å°„é¢‘æ³•</strong>ã€å¾®æ³¢æ³•ã€åˆ†é¢‘æ³•ã€ç”µç£æ³•å’Œå£°ç£æ³•ç­‰æ–¹æ³•è¿›è¡Œå·¥ä½œã€‚</li></ul></li><li>å£°è¡¨é¢æ³¢æ ‡ç­¾<ul><li>å£°è¡¨é¢æ³¢(Surface Acoustic Wave, SAW)</li></ul></li><li>æ— èŠ¯ç‰‡æ ‡ç­¾<ul><li>ä¸å«æœ‰ICèŠ¯ç‰‡çš„ç”µå­æ ‡ç­¾ï¼Œå¦‚å‰ä¸¤ä¸ª</li></ul></li><li>èŠ¯ç‰‡æ ‡ç­¾<ul><li>å¤©çº¿ã€å°„é¢‘ç”µè·¯å’Œæ§åˆ¶ç”µè·¯ç»„æˆï¼Œå…·æœ‰å­˜å‚¨åŠŸèƒ½</li></ul></li><li>å¾®å¤„ç†å™¨æ ‡ç­¾<ul><li>æ‹¥æœ‰ç‹¬ç«‹çš„CPUå’Œæ“ä½œç³»ç»Ÿ</li><li>é›†æˆå„ç±»ä¼ æ„Ÿå™¨æ£€æµ‹åŠŸèƒ½ï¼Œæ— çº¿é€šä¿¡åŠŸèƒ½</li></ul></li></ul><h3><span id="åŒé¢‘rfidç³»ç»Ÿ">åŒé¢‘RFIDç³»ç»Ÿ</span></h3><h4><span id="æœ‰æºç³»ç»Ÿ">æœ‰æºç³»ç»Ÿ</span></h4><p>åŒé¢‘ç”µå­æ ‡ç­¾ç”±<strong>åµŒå…¥å¼å¤„ç†å™¨</strong>å’Œ<strong>è½¯ä»¶ã€å¡å†…å‘å°„å’Œæ¥æ”¶å¤©çº¿</strong>ã€<strong>æ”¶å‘ç”µè·¯ä»¥åŠé«˜èƒ½ç”µæ± </strong>ç»„æˆã€‚</p><p>åŒé¢‘ç”µå­æ ‡ç­¾å·¥ä½œåœ¨ä¸¤ä¸ªé¢‘ç‚¹ä¸Šï¼Œå¹³æ—¶å¤„äº<strong>ç¡çœ çŠ¶æ€</strong>ï¼Œå½“è¿›å…¥ç³»ç»Ÿå·¥ä½œåŒºåï¼Œè¢«å‘å°„å¤©çº¿(è·¯æ ‡)å‘å‡ºçš„ä½é¢‘æ— çº¿ç”µä¿¡å·æ¿€æ´»ï¼Œå‘å°„å‡ºæƒŸä¸€çš„åŠ å¯†è¯†åˆ«ç æ— çº¿ç”µä¿¡å·ã€‚</p><p>å¯ä»¥è§£å†³ä¼ ç»Ÿæœ‰æºç”µå­æ ‡ç­¾<strong>è€—ç”µå¤§å’Œæ§åˆ¶è·ç¦»</strong>ä¸¤å¤§éš¾é¢˜ ã€‚</p><h4><span id="æ— æºç³»ç»Ÿ">æ— æºç³»ç»Ÿ</span></h4><ul><li>ä¸æœ‰æºåŒé¢‘ç³»ç»Ÿç›¸æ¯”ï¼Œæ— æºåŒé¢‘ç³»ç»Ÿå…·æœ‰ä½“ç§¯å°ã€ç³»ç»Ÿç´§å‡‘å’Œæˆæœ¬ä½å»‰ç­‰ç‰¹ç‚¹ã€‚</li><li>é‡‡ç”¨åŒé¢‘æŠ€æœ¯çš„RFIDç³»ç»ŸåŒæ—¶å…·æœ‰ä½é¢‘å’Œé«˜é¢‘ç³»ç»Ÿå„è‡ªçš„ä¼˜ç‚¹ï¼Œå³å…·æœ‰è¾ƒå¼ºçš„ç©¿é€èƒ½åŠ›ã€è¾ƒè¿œçš„è¯†åˆ«è·ç¦»å’Œé«˜é€Ÿçš„è¯†åˆ«èƒ½åŠ›ã€‚</li></ul><h4><span id="åŒé¢‘rfidç³»ç»Ÿçš„åº”ç”¨">åŒé¢‘RFIDç³»ç»Ÿçš„åº”ç”¨</span></h4><p>åŒé¢‘(Dual Frequencyï¼ŒDF)</p><ol type="1"><li><p>ä¾›åº”é“¾ç®¡ç†åŒ…æ‹¬æœ¨è´¨æ‰˜ç›˜ã€é›†è£…ç®±ã€æ°´æœç®±ã€çº¸å·è·Ÿ</p><p>è¸ªç­‰æ–¹é¢</p></li><li><p>äººå‘˜è‡ªç”±æµè·Ÿè¸ªä¸ä¸ªæ€§åŒ–èº«ä»½è®¤è¯</p></li><li><p>åŠ¨ç‰©è·Ÿè¸ªä¸è¯†åˆ«åŒ…æ‹¬ç¾Šç¾¤ã€ç‰›ç¾¤ã€çŒªã€é©¬ä»¥åŠé‡ç”ŸåŠ¨ç‰©çš„è·Ÿè¸ªä¸è¯†åˆ«</p></li><li><p>é‡‡çŸ¿ä½œä¸šä¸åœ°ä¸‹è·¯ç½‘ç®¡ç†</p></li><li><p>è¿åŠ¨è®¡æ—¶</p></li></ol><h3><span id="ç”µå­æ ‡ç­¾åè®®">ç”µå­æ ‡ç­¾åè®®</span></h3><ul><li>ISO/IEC 14443(A/B)</li><li>ISO/IEC 15693</li><li>ISO/IEC 18000-6(A/B)</li><li>EPCglobal Generation2(Gen2)</li></ul><h3><span id="ç”µå­æ ‡ç­¾çš„å¤©çº¿">ç”µå­æ ‡ç­¾çš„å¤©çº¿</span></h3><p>å¤©çº¿æ˜¯å‘å°„å’Œæ¥æ”¶ç”µç£æ³¢çš„ä¸€ä¸ªé‡è¦çš„æ— çº¿ç”µè®¾å¤‡ï¼Œä¸»è¦æ˜¯å°†æ¥æ”¶åˆ°çš„ç”µç£æ³¢è½¬æ¢æˆç”µæµä¿¡å·ï¼Œæˆ–è€…å°†ç”µæµä¿¡å·è½¬æ¢æˆç”µç£æ³¢ã€‚</p><h3><span id="ç”µå­æ ‡ç­¾ä¿¡æ¯çš„å†™å…¥æ–¹å¼">ç”µå­æ ‡ç­¾ä¿¡æ¯çš„å†™å…¥æ–¹å¼</span></h3><p>ç”µå­æ ‡ç­¾ä½œä¸ºæ ‡è¯†å¯¹è±¡çš„æ ¸å¿ƒéƒ¨ä»¶ï¼Œå…¶å†…éƒ¨ä¿¡æ¯è¦åœ¨ä½¿ç”¨å‰æˆ–ä½¿ç”¨è¿‡ç¨‹ä¸­é€šè¿‡ä¸€å®šçš„æ–¹å¼å†™å…¥åˆ°æ ‡ç­¾å­˜å‚¨èŠ¯ç‰‡ä¸­ã€‚å…¶ä¿¡æ¯çš„å†™å…¥æ–¹å¼å¤§è‡´å¯ä»¥åˆ†ä¸ºä»¥ä¸‹ä¸‰ç§ç±»å‹:</p><ul><li>ï‚¨ Â (1)ç”µå­æ ‡ç­¾åœ¨å‡ºå‚æ—¶ï¼Œå³å·²å°†å®Œæ•´çš„æ ‡ç­¾ä¿¡æ¯å†™å…¥æ ‡ç­¾ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œåº”ç”¨è¿‡ç¨‹ä¸­ï¼Œç”µå­æ ‡ç­¾ä¸€èˆ¬å…·æœ‰åªè¯»åŠŸèƒ½ã€‚</li><li>ï‚¨ Â (2)ç”µå­æ ‡ç­¾ä¿¡æ¯çš„å†™å…¥é‡‡ç”¨æœ‰çº¿æ¥è§¦æ–¹å¼å®ç°ï¼Œä¸€èˆ¬ç§°è¿™ç§æ ‡ç­¾ä¿¡æ¯å†™å…¥è£…ç½®ä¸ºç¼–ç¨‹å™¨ã€‚è¿™ç§æ¥è§¦å¼çš„ç”µå­æ ‡ç­¾ä¿¡æ¯å†™å…¥æ–¹å¼é€šå¸¸å…·æœ‰å¤šæ¬¡æ”¹å†™çš„èƒ½åŠ›ã€‚</li><li>ï‚¨ Â (3)ç”µå­æ ‡ç­¾åœ¨å‡ºå‚åï¼Œå…è®¸ç”¨æˆ·é€šè¿‡ä¸“ç”¨è®¾å¤‡ä»¥æ— æ¥è§¦çš„æ–¹å¼å‘ç”µå­æ ‡ç­¾ä¸­å†™å…¥æ•°æ®ä¿¡æ¯ã€‚è¿™ç§ä¸“ç”¨å†™å…¥åŠŸèƒ½é€šå¸¸ä¸ç”µå­æ ‡ç­¾è¯»å–åŠŸèƒ½ç»“åˆåœ¨ä¸€èµ·å½¢æˆç”µå­æ ‡ç­¾è¯»å†™å™¨ã€‚</li></ul><h3><span id="ç”µå­æ ‡ç­¾æ€§èƒ½å› ç´ ">ç”µå­æ ‡ç­¾æ€§èƒ½å› ç´ </span></h3><ol type="1"><li>èƒ½é‡æ¥æº</li><li>ç”µå­æ ‡ç­¾çš„æ–¹å‘å’Œä½ç½®</li><li>ç”µå­æ ‡ç­¾çš„æ”¾ç½®</li><li>æ ‡ç­¾å †å›(Tag Stacking)</li><li>æ ‡ç­¾çš„æåŒ–æ–¹å‘</li><li>æ ‡ç­¾çš„ç§»åŠ¨é€Ÿåº¦</li><li>ç¯å¢ƒå› ç´ </li><li>è¯»å–å’Œå†™å…¥</li></ol><h2><span id="ç¬¬å…­ç« -è¯»å†™å™¨">ç¬¬å…­ç«  è¯»å†™å™¨</span></h2><h3><span id="è¯»å†™å™¨çš„å·¥ä½œåŸç†">è¯»å†™å™¨çš„å·¥ä½œåŸç†</span></h3><p>ç¡¬ä»¶</p><ul><li>æ‰€æœ‰çš„è¯»å†™å™¨ç¡¬ä»¶å‡å¯ç®€åŒ–ä¸º<strong>å¤©çº¿</strong>ã€<strong>é«˜é¢‘æ¥å£</strong>ã€<strong>æ§åˆ¶å•å…ƒ</strong>å’Œ<strong>å¤–å›´æ¥å£</strong>å››ä¸ªåŸºæœ¬æ¨¡å—ã€‚<ul><li>å¤–å›´æ¥å£ï¼šRS232, RS485, RJ45, æ— çº¿ç½‘ç»œæ¥å£</li></ul></li></ul><p>è½¯ä»¶</p><ul><li>æ§åˆ¶è½¯ä»¶</li><li>å¯¼å…¥è½¯ä»¶</li><li>è§£ç å™¨</li></ul><h4><span id="è¯»å†™å™¨å·¥ä½œæµç¨‹">è¯»å†™å™¨å·¥ä½œæµç¨‹</span></h4><p>RFIDç³»ç»Ÿæ•°æ®é‡‡é›†ä¸€èˆ¬æœ‰ä¸¤ç§å·¥ä½œæ¨¡å¼:</p><ul><li>ä¸€æ˜¯ä»¥è¯»å†™å™¨ä¸ºä¸»çš„å·¥ä½œæ¨¡å¼ï¼Œå¤šç”¨äºæ— æºæ ‡ç­¾</li><li>äºŒæ˜¯ä»¥æ ‡ç­¾ä¸ºä¸»çš„å·¥ä½œæ¨¡å¼ï¼Œå¿…é¡»æ˜¯æœ‰æºæ ‡ç­¾</li></ul><h3><span id="è¯»å†™å™¨å¤©çº¿">è¯»å†™å™¨å¤©çº¿</span></h3><p>å¤©çº¿çš„ä¸»è¦å‚æ•°åŒ…æ‹¬:å·¥ä½œé¢‘ç‡ã€é¢‘å¸¦å®½åº¦ã€æ–¹å‘æ€§å¢ç›Šã€æåŒ–æ–¹å¼ã€æ³¢ç“£å®½åº¦ã€‚</p><ol type="1"><li><p>å¤©çº¿çš„å·¥ä½œé¢‘ç‡å’Œé¢‘å¸¦å®½åº¦</p><p>å¤©çº¿çš„å·¥ä½œé¢‘ç‡å’Œé¢‘å¸¦å®½åº¦åº”å½“ç¬¦åˆRFIDç³»ç»Ÿçš„é¢‘ç‡èŒƒå›´è¦æ±‚ï¼Œå¦‚å¤©çº¿å¯ä»¥å·¥ä½œåœ¨860-960MHzé¢‘ç‡èŒƒå›´ä¹‹é—´ã€‚</p></li><li><p>å¤©çº¿çš„å¢ç›Š</p><p>å¤©çº¿çš„å¢ç›Šæ˜¯æŒ‡åœ¨è¾“å…¥åŠŸç‡ç›¸ç­‰çš„æ¡ä»¶ä¸‹ï¼Œå®é™…å¤©çº¿ä¸ç†æƒ³çš„è¾å°„å•å…ƒåœ¨ç©ºé—´åŒä¸€ç‚¹å¤„æ‰€äº§ç”Ÿçš„ä¿¡å·çš„åŠŸç‡å¯†åº¦ä¹‹æ¯”ï¼Œå®ƒå®šé‡åœ°æè¿°äº†å¤©çº¿é›†ä¸­è¾å°„è¾“å…¥åŠŸç‡çš„ç¨‹åº¦ã€‚</p></li><li><p>å¤©çº¿çš„æåŒ–æ–¹å‘</p><p>å¤©çº¿å‘å‘¨å›´ç©ºé—´è¾å°„ç”µç£æ³¢ï¼Œç”µç£æ³¢ç”±ç”µåœºå’Œç£åœºæ„æˆã€‚ç”µåœºçš„æ–¹å‘å°±æ˜¯å¤©çº¿æåŒ–æ–¹å‘ï¼Œå¤©çº¿çš„æåŒ–æ–¹å¼åˆ†ä¸º<strong>çº¿æåŒ–(æ°´å¹³æåŒ–å’Œå‚ç›´æåŒ–)å’Œåœ†æåŒ–(å·¦æ—‹æåŒ–å’Œå³æ—‹æåŒ–)</strong>ä¸¤ç§ã€‚</p></li><li><p>å¤©çº¿çš„æ³¢ç“£å®½åº¦</p></li></ol><h4><span id="è¯»å†™å™¨çš„å¤©çº¿ç§ç±»">è¯»å†™å™¨çš„å¤©çº¿ç§ç±»</span></h4><ol type="1"><li>çº¿åœˆå¤©çº¿</li><li>å¾®å¸¦è´´ç‰‡å¤©çº¿</li><li>å¶æå­å¤©çº¿</li><li>éš§é“å¤©çº¿</li><li>å¤©çº¿é˜µåˆ—</li></ol><h3><span id="è¯»å†™å™¨çš„å‘å±•è¶‹åŠ¿">è¯»å†™å™¨çš„å‘å±•è¶‹åŠ¿</span></h3><ol type="1"><li>å¤šåŠŸèƒ½</li><li>æ™ºèƒ½å¤šå¤©çº¿ç«¯å£</li><li>å¤šç§æ•°æ®æ¥å£</li><li>å¤šåˆ¶å¼å…¼å®¹</li><li>å°å‹åŒ–</li><li>å¤šé¢‘æ®µå…¼å®¹</li><li>ä½æˆæœ¬</li><li>æ–°æŠ€æœ¯</li></ol><h3><span id="ä½œä¸š">ä½œä¸š</span></h3><p>6-3 åœ¨ä¸€RFIDåº”ç”¨ç³»ç»Ÿä¸­ï¼Œè¯»å†™å™¨ä¸»è¦å®ç°å“ªäº›åŠŸèƒ½ï¼Ÿ</p><ol type="1"><li>ä¸ç”µå­æ ‡ç­¾çš„é€šä¿¡åŠŸèƒ½</li><li>ä¸è®¡ç®—æœºä¹‹é—´çš„é€šä¿¡åŠŸèƒ½</li><li>å¤šæ ‡ç­¾åŒæ—¶è¯»å–ï¼Œé˜²ç¢°æ’</li><li>æ ¡éªŒè¯»å†™è¿‡ç¨‹ä¸­çš„é”™è¯¯ä¿¡æ¯</li><li>å¯¹äºæœ‰æºç”µå­æ ‡ç­¾ï¼Œèƒ½å¤Ÿè¯»å…¶ç”µé‡ğŸ”‹</li></ol><p>6-7 å¦‚ä½•è¡¡é‡è¯»å†™å™¨å¤©çº¿çš„æ€§èƒ½å¥½åï¼Ÿ</p><p>æ ¹æ®å·¥ä½œé¢‘ç‡ã€é¢‘å¸¦å®½åº¦ã€æ–¹å‘æ€§å¢ç›Šã€æåŒ–æ–¹å¼å’Œæ³¢ç“£å®½åº¦æ¥è¡¡é‡ã€‚</p><p>6-8 å¯¹äºåˆ†ä½“å¼è¯»å†™å™¨ï¼Œåœ¨è¯»å†™å™¨å’Œå¤©çº¿ä¹‹é—´çš„è¿æ¥æ—¶åº”è¯¥æ³¨æ„å“ªäº›é—®é¢˜ï¼Ÿ</p><p>é¿å…ä½¿ç”¨éå±è”½ç”µç¼†ï¼Œå¦åˆ™ä¼šäº§ç”Ÿä¸è‰¯æ•ˆåº”ã€‚</p><h2><span id="ç¬¬ä¸ƒç« -rfidæŠ€æœ¯æ ‡å‡†ä½“ç³»">ç¬¬ä¸ƒç«  RFIDæŠ€æœ¯æ ‡å‡†ä½“ç³»</span></h2><p>å›½é™…éç”µç¦»è¾å°„ä¿æŠ¤å§”å‘˜ä¼š(International Commission on Non-ionizing Radiation Protectionï¼ŒICNIRP)</p><p>RFIDæ ‡å‡†ä½“ç³»ç»“æ„</p><ul><li>RFIDæŠ€æœ¯æ ‡å‡†</li><li>RFIDåº”ç”¨æ ‡å‡†</li><li>RFIDæ•°æ®å†…å®¹æ ‡å‡†</li><li>RFIDæ€§èƒ½æ ‡å‡†</li></ul><h3><span id="rfidæ ‡å‡†ä½“ç³»">RFIDæ ‡å‡†ä½“ç³»</span></h3><p><strong>ISO/IEC 10536</strong></p><ul><li>å¯†è€¦åˆé›†æˆç”µè·¯å¡(Contactless Integrated Circuit Cardï¼ŒCICC)</li></ul><p><strong>ISO/IEC 14443</strong></p><ul><li>è¿‘è€¦åˆé›†æˆç”µè·¯å¡ (Proximity Integrated Circuit Cardï¼ŒPICC )</li><li>Type Aå¡<ul><li>Mifare Lightã€MIFARE1ã€Mifare2 (å³:Mifare Pro)ç­‰ã€‚åœ¨äºšæ´²ç­‰åœ°åŒºï¼ŒType AæŠ€æœ¯å’Œäº§å“å æ®äº†å¾ˆå¤§çš„å¸‚åœºä»½é¢</li><li>NFCé€æ¸æˆä¸ºæ™ºèƒ½æ‰‹æœºæ ‡é…åŠŸèƒ½ã€‚å›½å†…NFCåº”ç”¨æœ€ä¸ºå¹¿æ³›çš„å°†æ˜¯Type Aï¼Œå¦‚Mifareã€NFC Tagã€ç§»åŠ¨æ”¯ä»˜ç­‰</li></ul></li><li>Type Bå¡<ul><li>äºŒä»£å±…æ°‘èº«ä»½è¯</li><li>TYPE Bä¸TYPE Aç›¸æ¯”ï¼Œç”±äºè°ƒåˆ¶æ·±åº¦å’Œç¼–ç æ–¹å¼çš„ä¸åŒï¼Œå…·æœ‰ä¼ è¾“èƒ½é‡ä¸ä¸­æ–­ã€é€Ÿç‡æ›´é«˜ã€æŠ—å¹²æ‰°èƒ½åŠ›æ›´å¼ºçš„ä¼˜ç‚¹</li></ul></li><li>ç‰©ç†ç‰¹æ€§</li><li>ç©ºä¸­æ¥å£å’Œåˆå§‹åŒ–</li><li>é˜²å†²çªå’Œä¼ è¾“åè®®</li><li>æ‰©å±•å‘½ä»¤é›†å’Œå®‰å…¨ç‰¹æ€§</li><li>è¶…çŸ­è·ç¦»æ™ºæ…§å¡æ ‡å‡†</li></ul><p><strong>ISO/IEC 15693</strong></p><ul><li>ç–è€¦åˆé›†æˆç”µè·¯å¡(Vicinity Integrated Circuit Cardï¼ŒVICC)</li><li>ISO/IEC 15693é‡‡ç”¨çš„è½½æ³¢é¢‘ç‡ä»ä¸º13.56MHzï¼Œä¸»è¦åŒ…æ‹¬ç‰©ç†ç‰¹æ€§ã€ç©ºä¸­æ¥å£å’Œåˆå§‹åŒ–ã€é˜²å†²çªå’Œä¼ è¾“åè®®ã€æ‰©å±•å‘½ä»¤é›†å’Œå®‰å…¨ç‰¹æ€§å››ä¸ªéƒ¨åˆ†</li><li>çŸ­è·ç¦»æ™ºæ…§å¡æ ‡å‡†</li></ul><p><strong>ISO/IEC 18000</strong></p><ul><li>å•å“ç®¡ç†</li><li>ä¾›åº”é“¾å’Œç‰©æµ</li></ul><p>å…¨çƒè´¸æ˜“é¡¹ç›®ä»£ç (Global Trade Item Number)</p><p><strong>EPC ç”µå­æ ‡ç­¾çš„å­˜å‚¨ç»“æ„</strong></p><p>ç¬¦åˆEPC Class1 Gen2(ç®€ç§°C1G2)åè®®V109ç‰ˆçš„EPCç”µå­æ ‡ç­¾çš„å­˜å‚¨ç»“æ„æ˜¯ç›¸åŒçš„ã€‚åªæ˜¯ä¸åŒå‚å®¶çš„Tagå­˜å‚¨å™¨å®¹é‡å¤§å°ä¸åŒï‚¨ EPC æ ‡ç­¾åˆ†ä¸ºå››ä¸ªç‹¬ç«‹çš„å­˜å‚¨åŒºå—(Bank)ã€‚</p><p><img src="/images/EPC.png"></p><p>æ ‡ç­¾èŠ¯ç‰‡å†…éƒ¨å¸¦æœ‰ä¸€å®šå®¹é‡çš„éæ˜“å¤±æ€§å­˜å‚¨å™¨ï¼ŒæŒ‰ç…§EPCGlobal C1G2åè®®ï¼Œå››ä¸ªç‹¬ç«‹çš„å­˜å‚¨åŒºå—(Bank):</p><ul><li>ReservedåŒº(Bank00)ï¼šå­˜å‚¨Kill Password(ç­æ´»å£ä»¤)å’ŒAccessPassword(è®¿é—®å£ä»¤)ã€‚(4 words)</li><li>EPCåŒº(Bank01)ï¼šå­˜å‚¨EPCç¼–ç ï¼ŒEPCGlobalæ ¹æ®ä¸åŒçš„åº”ç”¨é¢†åŸŸåˆ¶å®šäº†ä¸åŒè§„åˆ™çš„å›½é™…é€šç”¨ç¼–ç ï¼Œé•¿åº¦åœ¨96ä½ä»¥ä¸Šã€‚(16bytes)</li><li>TIDåŒº(Bank10)ï¼šå­˜å‚¨æ ‡ç­¾è¯†åˆ«å·ç ï¼Œæ¯ä¸ªTIDå·ç éƒ½åœ¨æ ‡ç­¾å‡ºå‚æ—¶è®¾å®šï¼Œæ˜¯ä¸–ç•Œå”¯ä¸€çš„ã€‚(12wordsã€24bytes)</li><li>UseråŒº(Bank11)ï¼šå­˜å‚¨ç”¨æˆ·è‡ªå®šä¹‰çš„æ•°æ®ã€‚(32words)</li></ul><p>â€¢ æ­¤å¤–è¿˜æœ‰å„åŒºå—çš„Lock(é”å®š)çŠ¶æ€ä½ç­‰ç”¨åˆ°çš„ä¹Ÿæ˜¯å­˜å‚¨æ€§è´¨çš„å•å…ƒ</p><p><strong>TID(Tag identifier)æ•°æ®ä¿¡æ¯æ¶µä¹‰</strong></p><p><img src="/images/TID.png"></p><ul><li>TIDçš„æ•°æ®æ ¼å¼ç»Ÿä¸€ä¸ºE2xxxxxxx(æ­¤å¤„xå¹¶ä¸ä¸å®é™…æ•°æ®å­˜åœ¨ä¸€ä¸€å¯¹åº”çš„å…³ç³»)</li><li>003(åå…­è¿›åˆ¶)è¡¨ç¤ºèŠ¯ç‰‡å•†ä»£å·ï¼Œå„æ”¯æŒGen2åè®®çš„èŠ¯ç‰‡å•†å‘EPCglobalç”³è¯·è·å¾—å”¯ä¸€çš„ä»£å·ï¼Œå¸¸è§å‚å•†ç è§ä¸‹è¡¨</li><li>412(åå…­è¿›åˆ¶)è¡¨ç¤ºæ ‡ç­¾å‹å·(å…·ä½“ä»£è¡¨æŸå¤§ç±»ç‰©å“)</li><li>ä¹‹åä¸ºæ ‡ç­¾åºåˆ—å·<ul><li>ä¸åŒæ ‡ç­¾çš„TIDå‡ä¸ç›¸åŒï¼Œåˆ©ç”¨TIDå¯ä»¥ä¿è¯æ¯ä¸€æ ‡ç­¾çš„å”¯ä¸€æ€§å¹¶æ ‡è¯†å‡ºè¯¥æ ‡ç­¾çš„åˆ¶é€ å•†ã€åˆ¶é€ æ‰¹æ¬¡ç­‰ä¿¡æ¯</li></ul></li></ul><h2><span id="ç¬¬å…«ç« -rfidç³»ç»Ÿå…³é”®æŠ€æœ¯">ç¬¬å…«ç«  RFIDç³»ç»Ÿå…³é”®æŠ€æœ¯</span></h2><h3><span id="rfidç³»ç»Ÿçš„å®‰å…¨æŠ€æœ¯">RFIDç³»ç»Ÿçš„å®‰å…¨æŠ€æœ¯</span></h3><p>é’ˆå¯¹RFIDç³»ç»Ÿçš„å®‰å…¨æ”»å‡»æ‰‹æ®µå’Œæ–¹å¼ä¸»è¦åˆ†ä¸ºä»¥ä¸‹ä¸¤ç§:</p><ol type="1"><li>å¯¹RFIDç³»ç»Ÿè¿›è¡Œç ´åã€æ‰°ä¹±çš„æ”»å‡»<ul><li>é€šè¿‡å¹²æ‰°ã€é˜»å¡æ— çº¿ä¿¡é“æˆ–å…¶å®ƒæ‰‹æ®µï¼Œäº§ç”Ÿå¼‚å¸¸ç¯å¢ƒï¼Œä½¿RFIDå‘ç”Ÿæ•…éšœï¼Œæˆ–è¿›è¡Œæ‹’ç»æœåŠ¡çš„æ”»å‡»ç­‰</li><li>é€šè¿‡å¯¹æ ‡ç­¾çš„å±è”½å’Œå¤±è°ƒæ¥ä½¿å¾—æ ‡ç­¾æ— æ•ˆï¼Œä¾‹å¦‚åœ¨å¤©çº¿å‘¨å›´è¦†ç›–ä¸€å±‚é‡‘å±ç®”ï¼Œä½¿å¾—å¤©çº¿æ— æ³•å·¥ä½œ</li><li>è¿˜æœ‰çš„æ˜¯è¿›è¡Œæ°¸ä¹…æ€§çš„ç ´åï¼Œä¾‹å¦‚å¯¹æ ‡ç­¾çš„å¾®èŠ¯ç‰‡è¿›è¡Œæœºæ¢°çš„æ‹†é™¤ï¼Œæˆ–è€…æ˜¯å°†æ ‡ç­¾æ”¾åœ¨å¾®æ³¢ç‚‰ç­‰çš„å¼ºç£åœºç¯å¢ƒä¸‹ï¼Œè¿™äº›éƒ½ä¼šå¯¹æ ‡ç­¾è¿›è¡Œæ°¸ä¹…æ€§çš„ç ´åï¼Œå½“ç„¶æ ‡ç­¾å†…çš„æ•°æ®ä¹Ÿä¼šæ°¸è¿œçš„ä¸¢å¤±</li><li>åœ¨æ ‡ç­¾é™„è¿‘æ”¾ä¸€ä¸ªé˜»å¡æ ‡ç­¾ï¼Œä¸æ–­åœ°å‘å°„å¹²æ‰°ä¿¡å·ï¼Œä½¿RFIDç³»ç»Ÿä¸èƒ½æ­£å¸¸é€šä¿¡ï¼Œæ­¤æ—¶æœåŠ¡å°±ä¼šç»ˆæ­¢ï¼Œå¦¨ç¢è¯»å†™å™¨å¯¹åˆæ³•æ ‡ç­¾çš„è¯»å†™</li><li>å¯¹äºè¿™ä¸€ç±»çš„æ”»å‡»ï¼Œç›®å‰è¿˜æ²¡æœ‰æœ‰æ•ˆçš„å¯¹ç­–æ¥è§£å†³</li></ul></li><li>å¯¹é€šä¿¡æ•°æ®çš„é‡‡é›†ã€å¤åˆ¶å’Œä¿®æ”¹<ul><li>å¯¹äºè¿™ä¸€ç±»æ”»å‡»ï¼ŒåŠ å¯†ç¨‹åºå°±æ˜¯å¾ˆå¥½çš„è§£å†³æ–¹æ³•ï¼Œä¾‹å¦‚å¯¹äºè¯»å†™å™¨å’Œæ ‡ç­¾ä¹‹é—´çš„ç›¸äº’è®¤è¯ï¼Œè¯»å†™å™¨å’Œæ ‡ç­¾ä¹‹é—´çš„æ•°æ®ä¼ è¾“çš„åŠ å¯†ï¼Œä»¥åŠå‘¨æœŸæ€§çš„å¯†é’¥æ›´æ–°</li><li>å­˜åœ¨çš„é—®é¢˜å°±æ˜¯è¿ç”¨äº†åŠ å¯†åè®®åä¼šå¤§å¤§å¢åŠ èƒ½é‡çš„æ¶ˆè€—ï¼Œå› æ­¤è¢«åŠ¨ç”µå­æ ‡ç­¾æŠ€æœ¯ç›®å‰è¿˜æ²¡æœ‰è¿ç”¨åŠ å¯†åè®®</li></ul></li></ol><h4><span id="rfidç³»ç»Ÿçš„å®‰å…¨éœ€æ±‚">RFIDç³»ç»Ÿçš„å®‰å…¨éœ€æ±‚</span></h4><ol type="1"><li>æœºå¯†æ€§</li><li>å®Œæ•´æ€§</li><li>å¯ç”¨æ€§</li><li>çœŸå®æ€§</li><li>éšç§æ€§</li></ol><h4><span id="rfidå®‰å…¨æŠ€æœ¯">RFIDå®‰å…¨æŠ€æœ¯</span></h4><ol type="1"><li>ç‰©ç†å®‰å…¨æœºåˆ¶<ul><li>Killå‘½ä»¤</li><li>æ³•æ‹‰ç¬¬ç¬¼</li><li>ä¸»åŠ¨å¹²æ‰°æ³•</li><li>é˜»å¡æ ‡ç­¾</li><li>åªè¯»æ ‡ç­¾</li><li>åŠ¨æ€é¢‘ç‡æ³•</li><li>å¤©çº¿èƒ½é‡åˆ†ææ³•</li><li>æŒ‡ä»¤è¯†åˆ«æ³•</li></ul></li><li>é€»è¾‘å®‰å…¨æœºåˆ¶<ul><li>è®¿é—®æ§åˆ¶</li><li>è®¤è¯</li><li>åŠ å¯†ç®—æ³•</li></ul></li></ol><h3><span id="å¤šæ ‡ç­¾è¯†åˆ«æŠ€æœ¯">å¤šæ ‡ç­¾è¯†åˆ«æŠ€æœ¯</span></h3><p>æ— çº¿ç”µé€šä¿¡ç³»ç»Ÿä¸­ï¼Œå¤šè·¯å­˜å–æ–¹æ³•çš„è§£å†³æ–¹å¼ä¸€èˆ¬å…·æœ‰ä»¥ä¸‹å‡ ç§æ–¹å¼:</p><ul><li>ç©ºåˆ†å¤šè·¯æ³•(Space Division Multiple Accessï¼ŒSDMA)</li><li>é¢‘åˆ†å¤šè·¯æ³•(Frequency Division Multiple Accessï¼ŒFDMA)</li><li>ç åˆ†å¤šè·¯æ³•(Code Division Multiple Accessï¼ŒCDMA)</li><li>æ—¶åˆ†å¤šè·¯æ³•(Time Division Multiple Accessï¼ŒTDMA)</li></ul><p><strong>å¤šæ ‡ç­¾ç¢°æ’</strong></p><p>åœ¨<strong>ä¿¡é“å…±ç”¨</strong>ã€<strong>ä¿¡å·é¢‘ç‡</strong>ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œå¤šä¸ªç”µå­æ ‡ç­¾<strong>åŒæ—¶</strong>å‘è¯»å†™å™¨å‘é€ä¿¡å·ï¼Œè¿™äº›ä¿¡å·å°±ä¼šç›¸äº’å¹²æ‰°è€Œäº§ç”Ÿä¿¡é“äº‰å¤ºçš„æƒ…å†µï¼Œäº§ç”Ÿæ•°æ®ç¢°æ’ã€‚</p><ol type="1"><li>ç©ºåˆ†å¤šè·¯SDMA</li><li>é¢‘åˆ†å¤šè·¯FDMA<ul><li>é¢‘åˆ†å¤šè·¯æ³•æ˜¯æŠŠè‹¥å¹²ä¸ªä½¿ç”¨ä¸åŒè½½æ³¢é¢‘ç‡çš„ä¼ è¾“é€šè·¯åŒæ—¶ä¾›ç»™é€šä¿¡ç”¨æˆ·ä½¿ç”¨çš„æŠ€æœ¯</li></ul></li><li>ç åˆ†å¤šè·¯CDMA<ul><li>ç åˆ†å¤šè·¯æ³•æ˜¯ä¸€ç§å…±äº«ä¿¡é“çš„æ–¹æ³•ï¼Œæ¯ä¸ªç”¨æˆ·å¯åœ¨åŒä¸€æ—¶é—´ä½¿ç”¨åŒæ ·çš„é¢‘å¸¦è¿›è¡Œé€šä¿¡ã€‚ä½†ä½¿ç”¨çš„æ˜¯åŸºäºç å‹çš„åˆ†å‰²ä¿¡é“çš„æ–¹æ³•ï¼Œå³æ¯ä¸ªç”¨æˆ·åˆ†é…ä¸€ä¸ªåœ°å€ç ï¼Œå„ä¸ªç å‹äº’ä¸é‡å ï¼Œé€šä¿¡å„æ–¹ä¹‹é—´ä¸ä¼šç›¸äº’å¹²æ‰°ï¼Œä¸”æŠ—å¹²æ‹¢èƒ½åŠ›å¼º</li></ul></li><li>æ—¶åˆ†å¤šè·¯TDMA<ul><li>æ—¶åˆ†å¤ç”¨(Time division Multiplexing-TDM)æ˜¯åˆ©ç”¨å„ä¿¡å·çš„æŠ½æ ·å€¼åœ¨æ—¶é—´ä¸Šä¸ç›¸äº’é‡å æ¥è¾¾åˆ°åœ¨åŒä¸€ä¿¡é“ä¸­ä¼ è¾“å¤šè·¯ä¿¡å·çš„ä¸€ç§æ–¹æ³•ã€‚</li></ul></li></ol><p>ç»¼åˆåˆ†ææ¥çœ‹</p><ul><li>SDMA æ³•ç”±äºå…¶å¤æ‚çš„å¤©çº¿ç³»ç»Ÿäº§ç”Ÿçš„é«˜è´¹ç”¨ï¼Œä½¿å¾—å…¶åº”ç”¨ä¸æ˜¯å¾ˆå¹¿æ³›</li><li>FDMAæ³•å› å…¶è¯»å†™å™¨çš„è´¹ç”¨æ¯”è¾ƒé«˜ï¼Œç”µå­æ ‡ç­¾çš„å·®å¼‚ä¹Ÿè¦æ±‚è¾ƒé«˜ï¼Œåº”ç”¨ä¹Ÿå—åˆ°äº†é™åˆ¶</li><li>CDMAæ³•çš„é¢‘å¸¦åˆ©ç”¨ç‡ä½ã€ä¿¡é“å®¹é‡è¾ƒå°ã€åœ°å€ç é€‰æ‹©è¾ƒéš¾ã€æ¥æ”¶æ—¶åœ°å€ç æ•è·æ—¶é—´è¾ƒé•¿ï¼Œå…¶é€šä¿¡é¢‘å¸¦åŠæŠ€æœ¯å¤æ‚æ€§ç­‰ä½¿å¾—å®ƒå¾ˆéš¾åœ¨RFIDç³»ç»Ÿä¸­æ¨å¹¿åº”ç”¨</li></ul><p>å› æ­¤ï¼Œåœ¨RFIDç³»ç»Ÿä¸­ï¼Œ<strong>TDMAåº”ç”¨æ¯”è¾ƒå¹¿æ³›</strong>ã€‚</p><h3><span id="å¤šè¯»å†™å™¨é˜²ç¢°æ’æŠ€æœ¯">å¤šè¯»å†™å™¨é˜²ç¢°æ’æŠ€æœ¯</span></h3><p>éšç€RFIDç³»ç»Ÿçš„å¤§è§„æ¨¡åº”ç”¨ï¼Œè¶Šæ¥è¶Šå¤šçš„åº”ç”¨åœºåˆ(å¦‚ç‰©æµä¾›åº”é“¾ç®¡ç†ï¼Œä½ç½®è·Ÿè¸ªç­‰)éœ€è¦RFIDè¯»å†™å™¨ç½‘ç»œæ¥ç›‘è§†æ•´ä¸ªè¦†ç›–çš„åŒºåŸŸï¼Œå¯èƒ½ä¼šå‡ºç°åœ¨ä¸€å®šèŒƒå›´å†…å¤šä¸ªè¯»å†™å™¨é˜…è¯»åŒä¸€ä¸ªæ ‡ç­¾çš„æƒ…å†µã€‚</p><p>é˜…è¯»å™¨çš„ä¿¡å·åŒºæœ‰å¯èƒ½å‡ºç°ç›¸äº’é‡å ï¼Œåˆ™è¯»å†™å™¨ä¹‹é—´ä¼šäº’ç›¸å¹²æ‰°ï¼Œå…¶ä¸­ä»»ä¸€ä¸ªé˜…è¯»å™¨ä¸æ ‡ç­¾çš„é€šä¿¡ï¼Œå¯èƒ½ä¼šä¸¥é‡å¹²æ‰°å…¶ä»–é˜…è¯»å™¨å¯¹è¯¥æ ‡ç­¾çš„æ­£å¸¸è¯»å–ï¼Œè¿™ç§å¤šé˜…è¯»å™¨é—´çš„è¯»å†™å†²çªé—®é¢˜ç§°ä¸º<strong>é˜…è¯»å™¨é˜²ç¢°æ’é—®é¢˜</strong>ã€‚</p><p>è¯»å†™å™¨çš„ç¢°æ’é—®é¢˜åˆ†ä¸ºä¸¤ç±»:</p><ul><li>è¯»å†™å™¨ä¸è¯»å†™å™¨ä¹‹é—´çš„å¹²æ‰°é—®é¢˜<ul><li>å½“ä¸€ä¸ªè¯»å†™å™¨å‘é€ä¸€ä¸ªä¿¡å·è€Œä¸å¦ä¸€ä¸ªè¯»å†™å™¨çš„å·¥ä½œç›¸å¹²æ‰°æ—¶ï¼Œè¯»å†™å™¨ä¹‹é—´çš„é¢‘ç‡å¹²æ‰°å°±äº§ç”Ÿäº†</li><li>å½“ä¸€ä¸ªè¯»å†™å™¨å‘é€çš„ä¿¡å·æœ‰è¶³å¤Ÿçš„å¼ºåº¦ï¼Œå¹¶ä¸”è¢«ç¬¬äºŒä¸ªè¯»å†™å™¨æ”¶åˆ°æ—¶ï¼Œå°±æ©ç›–äº†æˆ–é˜»å¡äº†å®ƒä¸æ ‡ç­¾çš„é€šä¿¡</li></ul></li><li>å¤šè¯»å†™å™¨åˆ°æ ‡ç­¾ä¹‹é—´çš„å¹²æ‰°é—®é¢˜<ul><li>å½“ä¸€ä¸ªæ ‡ç­¾å¤„åœ¨å¤šä¸ªè¯»å†™å™¨çš„æŸ¥è¯¢åŒºåŸŸä¸­ï¼Œç”±äºå„è¯»å†™å™¨çš„ç›¸äº’å¹²æ‰°ï¼Œæœ‰å¯èƒ½ä½¿å¾—æ²¡æœ‰ä¸€ä¸ªè¯»å†™å™¨å¯ä»¥è¯»åˆ°è¯¥åŒºåŸŸçš„æ ‡ç­¾</li></ul></li></ul><h2><span id="ç¬¬ä¹ç« -rfidåº”ç”¨ç³»ç»Ÿçš„æ„å»º">ç¬¬ä¹ç«  RFIDåº”ç”¨ç³»ç»Ÿçš„æ„å»º</span></h2><p><strong>å®æ–½RFIDåº”ç”¨ç³»ç»Ÿçš„æµç¨‹</strong></p><ul><li>é˜¶æ®µ0 - å¯åŠ¨</li><li>é˜¶æ®µ1<ul><li>ç°åœºè°ƒç ”</li><li>ä¸šåŠ¡åˆ†æã€æ€»ä½“æ–¹æ¡ˆè§„åˆ’</li><li>å®è·µæ£€éªŒ</li></ul></li><li>é˜¶æ®µ2 é¡¹ç›®è¯•ç‚¹</li><li>é˜¶æ®µ3 æ­£å¼é¡¹ç›®</li></ul><h3><span id="ç”µå­æ ‡ç­¾é€‰æ‹©">ç”µå­æ ‡ç­¾é€‰æ‹©</span></h3><p>åœ¨è¿›è¡Œæ ‡ç­¾é€‰æ‹©æ—¶ï¼Œéœ€è¦è€ƒè™‘çš„æ ‡ç­¾æŠ€æœ¯å‚æ•°æœ‰: èƒ½é‡è¦æ±‚ã€å®¹é‡è¦æ±‚ã€å·¥ä½œé¢‘ç‡ã€æ•°æ®ä¼ è¾“é€Ÿç‡ã€è¯»/å†™é€Ÿåº¦ã€è¯»/å†™æ–¹å¼ã€è¯†è¯»è·ç¦»ã€æ ‡ç­¾å¤–å½¢ã€æ•°æ®å®‰å…¨æ€§è¦æ±‚ç­‰ã€‚</p><ol type="1"><li>æ ‡ç­¾çš„ç±»å‹</li><li>æ ‡ç­¾çš„å½¢çŠ¶å’Œå°ºå¯¸</li><li>å…³äºæ ‡ç­¾çš„åŠ å·¥</li><li>å¦‚ä½•åœ¨å›½å¤–é€‚ç”¨</li></ol><h3><span id="è¯»å†™å™¨é€‰æ‹©">è¯»å†™å™¨é€‰æ‹©</span></h3><p>è¯»å†™å™¨çš„æŠ€æœ¯å‚æ•°åŒ…æ‹¬: å·¥ä½œé¢‘ç‡ã€è¾“å‡ºåŠŸç‡ã€æ•°æ®ä¼ è¾“é€Ÿç‡ã€I/Oç«¯å£å½¢å¼ã€è¯»å†™å™¨æ˜¯å¦å¯è°ƒç­‰</p><ol type="1"><li>é€‚ç”¨å½¢æ€<ul><li>å›ºå®šè¯»å†™å™¨</li><li>æ‰‹æŒå¼è¯»å†™å™¨</li></ul></li><li>è¾“å…¥ï¼è¾“å‡ºçš„ç±»å‹</li><li>å¤©çº¿çš„é€‰æ‹©</li><li>è¯»å–çš„æ€§èƒ½</li></ol><h2><span id="ç¬¬åç« -rfidæŠ€æœ¯åº”ç”¨">ç¬¬åç«  RFIDæŠ€æœ¯åº”ç”¨</span></h2><h3><span id="åŸºäºrfidçš„å…¸å‹ç‰©è”ç½‘ç³»ç»Ÿepc">åŸºäºRFIDçš„å…¸å‹ç‰©è”ç½‘ç³»ç»ŸEPC</span></h3><p>EPCç³»ç»Ÿæ˜¯åœ¨è®¡ç®—æœºäº’è”ç½‘çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨RFIDã€æ— çº¿æ•°æ®é€šä¿¡ç­‰æŠ€æœ¯ï¼Œé€šè¿‡å…¨çƒç»Ÿä¸€æ ‡è¯†ç³»ç»Ÿç¼–ç æŠ€æœ¯ç»™æ¯ä¸€ä¸ªå®ä½“å¯¹è±¡ä¸€ä¸ªå”¯ä¸€ä»£ç ï¼Œæ„é€ äº†ä¸€ä¸ªå®ç°å…¨çƒç‰©å“ä¿¡æ¯å®æ—¶å…±äº«çš„ç‰©è”ç½‘ã€‚</p><p><img src="/images/EPC1.png"></p><p><img src="/images/EPC2.png"></p><h2><span id="ç”µå­é’±åŒ…">ç”µå­é’±åŒ…</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2B 00 00 00 D4 FF FF FF 2B 00 00 00 09 F6 09 F6</span><br><span class="line">å……å€¼é‡‘é¢      å……å€¼é‡‘é¢å–å  ä½™é¢        å—å·      å—å·å–å</span><br></pre></td></tr></table></figure><p>å‰å››ä¸ªå­—èŠ‚ä¸ºå®é™…å……å€¼æ•°æ®ï¼Œå¦‚è¿™é‡Œçš„ 2B 00 00 00ï¼Œæ¥ä¸‹æ¥å››ä¸ªå­—èŠ‚ä¸ºå®ƒçš„å–åï¼Œå³ D4 FF FF FFï¼Œæ¥ä¸‹æ¥å››ä¸ªå­—èŠ‚æ˜¯å¡å†…å®é™…é‡‘é¢ï¼Œå³ 2B 00 00 00ï¼Œåé¢çš„å››ä¸ªå­—èŠ‚åˆ†ä¸ºä¸¤ä¸ªå­—èŠ‚ä¸€ç»„ï¼Œè¿™ä¸¤ç»„å®Œå…¨ä¸€æ ·ï¼Œä¸º 09 F6 09 F6ï¼Œå…¶ä¸­09æ˜¯ç»å¯¹å—å·ï¼Œå³æ‰‡åŒºå·*4+å—å·ï¼Œæ‰€ä»¥å®é™…æ˜¯ç¬¬äºŒæ‰‡åŒºç¬¬ä¸€å—ï¼Œæœ€å F6 = FF - 09ã€‚</p><h2><span id="rfidæœ¯è¯­">RFIDæœ¯è¯­</span></h2><ul><li>ISBN (International Standard Book Number) - å›½é™…æ ‡å‡†ä¹¦å·</li><li>ISSN (International Standard Serial Number) - å›½é™…æ ‡å‡†æœŸåˆŠå·</li><li>FSK (Frequency Shift Keying) - é¢‘ç§»é”®æ§æ³•</li><li>PSK (Phase Shift Keying) - ç›¸ç§»é”®æ§æ³•</li><li>PCM (Pulse Code Modulation) - è„‰å†²ç¼–ç è°ƒåˆ¶æŠ€æœ¯</li><li>PC (Parity Check) - å¥‡å¶æ ¡éªŒ</li><li>LRC (Longitudinal Redundancy Check) - çºµå‘å†—ä½™æ ¡éªŒ</li><li>CRC (Cyclic Redundancy Check) - å¾ªç¯å†—ä½™ç æ ¡éªŒ</li><li>FDX (Full Duplex) - å…¨åŒå·¥</li><li>HDX (Half Duplex) - åŠåŒå·¥</li><li>SEQ (Sequence) - æ—¶åº</li><li>FRAM (Ferroelectric Random Access Memory) - é“ç”µéšæœºå­˜å–å­˜å‚¨å™¨</li><li>ROM (Read Only Memory) - åªè¯»å­˜å‚¨å™¨</li><li>RAM (Random Access Memory) - éšæœºå­˜å–å™¨</li><li>WORM (Write Once Read Many) - ä¸€æ¬¡å†™å…¥å¤šæ¬¡è¯»å‡º</li><li>DF (Dual Frequency) - åŒé¢‘</li><li>TS (Tag Stacking) - æ ‡ç­¾å †å›</li><li>ICNIRP (International Commission on Non-ionizing Radiation Protection) - å›½é™…éç”µç¦»è¾å°„ä¿æŠ¤å§”å‘˜ä¼š</li><li>SAW (Surface Acoustic Wave) - å£°è¡¨é¢æ³¢</li><li>CICC (Contactless Integrated Circuit Card) - è€¦åˆé›†æˆç”µè·¯å¡</li><li>PICC (Proximity Integrated Circuit Card) - è¿‘è€¦åˆé›†æˆç”µè·¯å¡</li><li>VICC (Vicinity Integrated Circuit Card) - ç–è€¦åˆé›†æˆç”µè·¯å¡</li><li>SDMA (Space Division Multiple Access) - ç©ºåˆ†å¤šè·¯æ³•</li><li>FDMA (Frequency Division Multiple Access) - é¢‘åˆ†å¤šè·¯æ³•</li><li>CDMA (Code Division Multiple Access) - ç åˆ†å¤šè·¯æ³•</li><li>TDMA (Time Division Multiple Access) - æ—¶åˆ†å¤šè·¯æ³•</li><li>TDM (Time division Multiplexing) - æ—¶åˆ†å¤ç”¨</li><li>MOM (Message-Oriented Middleware) - é¢å‘æ¶ˆæ¯çš„ä¸­é—´ä»¶</li><li>EMS (Event Management System) - äº‹ä»¶ç®¡ç†ç³»ç»Ÿ</li><li>RIED (Real-time In-Memory Event Database) - å®æ—¶å†…å­˜äº‹ä»¶æ•°æ®åº“</li><li>TMS (Task Management System) - ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ</li><li>ERP (Enterprise Resource Planning) - ä¼ä¸šèµ„æºè§„åˆ’</li><li>MES (Management Execution System) - ç®¡ç†æ‰§è¡Œç³»ç»Ÿ</li><li>SOAP (Simple Object Access Protocol) - ç®€å•å¯¹è±¡è®¿é—®åè®®</li><li>RFU (Reserved for Future ISO/IEC Use) - ä¿ç•™ä¾›å°†æ¥ä½¿ç”¨</li><li>SOF (Start Of Frame, Type B) - å¸§çš„å¼€å§‹ï¼Œç±»å‹ B</li><li>EOF (end of frame) - å¸§ç»“æŸ</li><li>AFI (application family identifier) - åº”ç”¨æ—è¯†åˆ«ç¬¦ï¼Œåº”ç”¨çš„å¡é¢„é€‰å‡†åˆ™</li><li>VCD (vicinity coupling device) - é™„è¿‘å¼è€¦åˆè®¾å¤‡</li><li>ONS (Object Name Server) - å¯¹è±¡åç§°è§£ææœåŠ¡</li><li>PML (Physical Markup Language) - ç‰©ç†æ ‡è¯†è¯­è¨€</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœ¬ç§‘è¯¾ç¨‹ </tag>
            
            <tag> ç‰©è”ç½‘ </tag>
            
            <tag> RFID </tag>
            
            <tag> QR-Code </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>åµŒå…¥å¼æ“ä½œç³»ç»Ÿ</title>
      <link href="/2017/01/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
      <url>/2017/01/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#ç¬¬ä¸€ç« ">ç¬¬ä¸€ç« </a></li><li><a href="#ç¬¬äºŒç« ">ç¬¬äºŒç« </a></li><li><a href="#ç¬¬ä¸‰ç« ">ç¬¬ä¸‰ç« </a></li><li><a href="#ç¬¬å››ç« ">ç¬¬å››ç« </a></li><li><a href="#ç¬¬äº”ç« ">ç¬¬äº”ç« </a></li><li><a href="#ç¬¬å…­ç« ">ç¬¬å…­ç« </a></li><li><a href="#ç¬¬ä¸ƒç« ">ç¬¬ä¸ƒç« </a></li><li><a href="#ç¬¬å…«ç« ">ç¬¬å…«ç« </a></li><li><a href="#tinyos">TinyOS</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="ç¬¬ä¸€ç« ">ç¬¬ä¸€ç« </span></h2><ul><li>å¤šé“<ul><li>å¤šé“ç¨‹åºè®¾è®¡æŠ€æœ¯æ˜¯åœ¨è®¡ç®—æœºä¸»å­˜ä¸­åŒæ—¶å­˜æ”¾å‡ é“ç›¸äº’ç‹¬ç«‹çš„ç¨‹åºï¼Œä½¿å®ƒä»¬åœ¨ç®¡ç†ç¨‹åºæ§åˆ¶ä¹‹ä¸‹ï¼Œç›¸äº’ç©¿æ’åœ°è¿è¡Œã€‚<strong>å½“ä¸€ä¸ªç¨‹åºæ— æ³•ä½¿ç”¨å¤„ç†å™¨èµ„æºçš„æ—¶å€™ï¼ˆåšI/Oçš„æ—¶å€™ï¼‰ï¼Œç³»ç»Ÿå¯ä»¥è°ƒç”¨å¦ä¸€ä¸ªç¨‹åºåœ¨å¤„ç†å™¨ä¸Šè¿è¡Œã€‚</strong></li><li>ç‰¹å¾ï¼šå¤šé“ã€å®è§‚ä¸Šå¹¶è¡Œã€å¾®è§‚ä¸Šä¸²è¡Œ</li></ul></li><li>åˆ†æ—¶<ul><li>åˆ†æ—¶æŠ€æœ¯æ˜¯å°†å¤„ç†å™¨çš„æ—¶é—´<strong>åˆ†æˆå¾ˆçŸ­çš„æ—¶é—´ç‰‡</strong>ï¼Œå°†è¿™äº›æ—¶é—´ç‰‡<strong>è½®æµåˆ†é…ç»™åœ¨å†…å­˜ä¸­çš„ç”¨æˆ·ç¨‹åºä½¿ç”¨</strong>ã€‚</li><li>åˆ†æ—¶ç³»ç»Ÿå…·æœ‰çš„ç‰¹ç‚¹<ol type="1"><li>ç‹¬ç«‹æ€§ï¼ˆå„ç”¨æˆ·æ„Ÿè§‰ç‹¬å èµ„æºï¼‰</li><li>åŠæ—¶æ€§</li><li>äº¤äº’æ€§</li></ol></li></ul></li><li>å¹¶å‘<ul><li>åœ¨ç³»ç»Ÿé‡Œæœ‰å¤šä¸ªåŒæ—¶è¿›è¡Œçš„æ´»åŠ¨</li></ul></li><li>å…±äº«<ul><li>è¿›ç¨‹ä¹‹é—´å…±äº«ç³»ç»Ÿèµ„æº</li></ul></li><li>ä¸ç¡®å®šæ€§<ul><li>ç³»ç»Ÿä¸­å«æœ‰å¤§é‡ä¸ç¡®å®šçš„äº‹ä»¶</li></ul></li></ul><h2><span id="ç¬¬äºŒç« ">ç¬¬äºŒç« </span></h2><ul><li>ç¡¬ä»¶æ”¯æŒï¼š<ol type="1"><li>å¤„ç†æœºçš„çŠ¶æ€ï¼šç›®æ€ã€ç®¡æ€<ol type="1"><li>ç®¡æ€æŒ‡CPUä¸Šè¿è¡Œç®¡ç†ç¨‹åºæ‰€å¤„çš„çŠ¶æ€ï¼Œç›®æ€æ˜¯æŒ‡CPUä¸Šè¿è¡Œç”¨æˆ·ç¨‹åºæ‰€å¤„çš„æ€ï¼›</li><li>äºŒè€…çš„åŒºåˆ«ï¼šç‰¹æƒçº§ä¸åŒï¼ŒCPUåœ¨ç®¡æ€ä¸‹å¯ä»¥ä½¿ç”¨å…¨éƒ¨æœºå™¨æŒ‡ä»¤ï¼ŒåŒ…æ‹¬ä¸€ç»„ç‰¹æƒæŒ‡ä»¤ï¼Œå¯ä»¥ä½¿ç”¨æ‰€æœ‰çš„èµ„æºï¼Œè®¿é—®æ•´ä¸ªå­˜å‚¨åŒºã€‚CPUåœ¨ç”¨æˆ·æ€ä¸‹åªèƒ½ä½¿ç”¨ç”¨æˆ·æ€éç‰¹æƒæŒ‡ä»¤ï¼Œè®¿é—®è§„å®šçš„å­˜å‚¨åŒºï¼Œä½¿ç”¨ä¸€éƒ¨åˆ†èµ„æºã€‚</li><li>ä»ç”¨æˆ·æ€åˆ°ç®¡æ€åˆ‡æ¢çš„å”¯ä¸€é€”å¾„æ˜¯ä¸­æ–­</li></ol></li><li>ç‰¹æƒæŒ‡ä»¤<ol type="1"><li>æ”¹å˜æœºå™¨çŠ¶æ€çš„æŒ‡ä»¤</li><li>ä¿®æ”¹ç‰¹æ®Šå¯„å­˜å™¨çš„æŒ‡ä»¤</li><li>æ¶‰åŠå¤–éƒ¨è®¾å¤‡çš„è¾“å…¥/è¾“å‡ºæŒ‡ä»¤</li></ol></li></ol></li><li>ä¸­æ–­<ul><li>ä¸­æ–­å®è´¨æ˜¯ä¸€ä¸ªå—ä¿æŠ¤çš„æ§åˆ¶è½¬ç§»(protected control transfer)</li><li>ä¸­æ–­åˆ†ç±»ï¼šI/Oã€å¤–ä¸­æ–­ã€æœºå™¨æ•…éšœä¸­æ–­ã€ç¨‹åºæ€§ä¸­æ–­ã€è®¿ç®¡ä¸­æ–­</li><li>æ“ä½œç³»ç»Ÿå…·å¤‡å¤„ç†åŒæ—¶æ€§æ´»åŠ¨çš„èƒ½åŠ›ï¼Œé‡è¦çš„ç¡¬ä»¶æ”¯æŒæ˜¯ï¼šä¸­æ–­ç³»ç»Ÿ</li></ul></li></ul><h2><span id="ç¬¬ä¸‰ç« ">ç¬¬ä¸‰ç« </span></h2><ul><li>ç³»ç»ŸåŠŸèƒ½è°ƒç”¨<ul><li>å‘½ä»¤è¡Œ</li><li>å›¾å½¢ç”¨æˆ·ç•Œé¢</li></ul></li><li>ç¨‹åºæ¥å£</li></ul><h2><span id="ç¬¬å››ç« ">ç¬¬å››ç« </span></h2><ul><li><p>å¹¶å‘ï¼šè‹¥å¹²ä¸ªç¨‹åºæ®µåŒæ—¶åœ¨ç³»ç»Ÿä¸­è¿è¡Œï¼Œè‹¥è¿™äº›ç¨‹åºçš„æ‰§è¡Œåœ¨æ—¶é—´ä¸Šå­˜åœ¨é‡å ï¼Œåˆ™ç§°ä¸ºç¨‹åºå¹¶å‘æ‰§è¡Œã€‚</p><ul><li>ç‰¹ç‚¹ï¼šå¤±å»äº†å°é—­æ€§ï¼›ç¨‹åºä¸è®¡ç®—ä¸å†ä¸€ä¸€å¯¹åº”</li></ul></li><li><p>è¿›ç¨‹</p><ul><li>è¿›ç¨‹æ˜¯ä¸€ä¸ªç¨‹åºåœ¨ç»™å®šçš„åˆå§‹ç¯å¢ƒå’Œæ´»åŠ¨ç©ºé—´ä¸‹ï¼Œåœ¨å¤„ç†æœºä¸Šçš„ä¸€æ¬¡æ‰§è¡Œè¿‡ç¨‹</li><li>ç»„æˆ<ul><li>è¿›ç¨‹æ§åˆ¶å—</li><li>è¿›ç¨‹çš„æ‰§è¡Œç¨‹åº</li><li>è¿›ç¨‹æ€»æ˜¯å¤„äºæŸä¸ªé˜Ÿåˆ—</li><li>å¤„äºæŸç§çŠ¶æ€</li><li>å ç”¨ç³»ç»ŸæŸäº›èµ„æº</li></ul></li></ul></li><li><p>çº¿ç¨‹</p><ul><li>è½»é‡çº§è¿›ç¨‹</li></ul></li><li>çŠ¶æ€å˜è¿<ul><li>æ—  ç­‰å¾…-ã€‹è¿è¡Œ âŒ</li><li>æ—  å°±ç»ª-ã€‹ç­‰å¾… âŒ</li><li><img src="/images/OS/process_state_trans.png"></li><li>å¦‚æœç³»ç»Ÿä¸­æœ‰Nä¸ªè¿›ç¨‹ï¼Œè¿è¡Œçš„è¿›ç¨‹æœ€å¤šå‡ ä¸ªï¼Œæœ€å°‘å‡ ä¸ªï¼›å°±ç»ªã€ç­‰å¾…å‘¢ï¼Ÿ<ul><li>è¿è¡Œçš„è¿›ç¨‹æœ€å¤šä¸€ä¸ªï¼Œæœ€å°‘0ä¸ª</li><li>å°±ç»ªæœ€å¤šN - 1ä¸ªï¼Œæœ€å°‘0ä¸ª</li><li>ç­‰å¾…æœ€å¤šNä¸ªï¼Œæœ€å°‘0ä¸ª</li></ul></li><li>ä¸€ä¸ªçŠ¶æ€çš„å‘ç”Ÿï¼Œæ˜¯å¦ä¸€å®šå¯¼è‡´å¦ä¸€ä¸ªçŠ¶æ€çš„å‘ç”Ÿï¼Ÿåˆ—å‡ºæ‰€æœ‰å¯èƒ½<ul><li>è¿è¡Œ -&gt; å°±ç»ª ä¸€å®šæœ‰ å°±ç»ª -&gt; è¿è¡Œ</li><li>å°±ç»ª -&gt; è¿è¡Œ ä¸ä¸€å®šæœ‰ è¿è¡Œ -&gt; å°±ç»ª</li></ul></li></ul></li><li><p>åˆä½œå…³ç³»</p><ul><li><p>è¿›ç¨‹çš„ç›¸äº’åˆ¶çº¦å…³ç³»äº§ç”ŸåŸå› ï¼šèµ„æºå…±äº«ã€è¿›ç¨‹åˆä½œ</p></li><li><p>äº’æ–¥</p><ul><li>å½“æŸä¸€è¿›ç¨‹æ­£åœ¨è®¿é—®æŸä¸´ç•Œèµ„æºæ—¶ï¼Œå°±ä¸å…è®¸å…¶ä»–è¿›ç¨‹è¿›å…¥ï¼Œå¦åˆ™å°±ä¼šäº§ç”Ÿæ— æ³•ä¼°è®¡çš„é”™è¯¯ã€‚</li><li>æºäºå¯¹ç‹¬å è®¾å¤‡çš„ç«äº‰</li></ul></li><li><p>åŒæ­¥</p><ul><li><p>æºäºè¿›ç¨‹çš„åˆä½œ</p></li><li><p>å…±äº«ç¼“å†²åŒºçš„åˆä½œè¿›ç¨‹åŒæ­¥</p><ul><li><p>ç”Ÿäº§è€…-æ¶ˆè´¹è€…é—®é¢˜</p><ul><li><p>Fullï¼šç¼“å†²åŒºäº§å“æ•°ç›®ï¼Œåˆå€¼ä¸º0</p></li><li><p>Emptyï¼šç¼“å†²åŒºå¯å­˜æ”¾äº§å“çš„ç©ºä½ï¼Œåˆå€¼ä¸ºn</p></li><li><p>Mutex:ç¼“å†²åŒºäº’æ–¥ä¿¡å·ç¯ï¼Œåˆå€¼ä¸º1</p></li><li><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(ç”Ÿäº§æœªå®Œæˆ) &#123;</span><br><span class="line">    ç”Ÿäº§ä¸€ä¸ªäº§å“;</span><br><span class="line">    p(empty);</span><br><span class="line">    p(mutex);</span><br><span class="line">    å°†äº§å“æ”¾å…¥ç¼“å†²åŒº;</span><br><span class="line">    v(mutex);</span><br><span class="line">    v(full);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (è¿˜è¦ç»§ç»­æ¶ˆè´¹) &#123;</span><br><span class="line">    p(full);</span><br><span class="line">    p(mutex);</span><br><span class="line">    ä»ç¼“å†²åŒºå–å‡ºä¸€ä¸ªäº§å“;</span><br><span class="line">    v(mutex);</span><br><span class="line">    v(empty);</span><br><span class="line">    æ¶ˆè´¹äº§å“;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>è¯»è€…å†™è€…é—®é¢˜ï¼Ÿ</p></li><li><p>èªŠæŠ„é—®é¢˜</p></li></ul></li></ul></li><li><p>åœ¨åœ°çƒä¸Šï¼Œç«äº‰å’Œåˆä½œæ˜¯æ°¸æ’çš„ï¼</p></li><li><p>ä¸´ç•Œèµ„æº</p><ul><li>ä¸€æ¬¡ä»…å…è®¸ä¸€ä¸ªè¿›ç¨‹è®¿é—®çš„èµ„æº</li></ul></li><li><p>ä¸´ç•ŒåŒº</p><ul><li>æ¯ä¸ªè¿›ç¨‹ä¸­è®¿é—®ä¸´ç•Œèµ„æºçš„<strong>ç¨‹åºæ®µ</strong>ç§°ä¸ºä¸´ç•ŒåŒº</li></ul></li><li><p>åŸå­ã€åŸè¯­ï¼šä¸å¯åˆ†å‰²ã€ä¸å¯ä¸­æ–­çš„ç¨‹åº</p></li><li><p>ä¿¡å·ç¯Pã€Væ“ä½œ</p><ul><li><p>P</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  s--;</span><br><span class="line">  <span class="keyword">if</span> (s &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    æŒ‚èµ·è¯¥è¿›ç¨‹;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>V</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  s++;</span><br><span class="line">  <span class="keyword">if</span> (s &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    å”¤é†’ç­‰å¾…Sçš„è¿›ç¨‹;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>ä¿¡å·ç¯ï¼ˆs, qï¼‰</p><ul><li>sä»£è¡¨å¯ç”¨èµ„æºçš„æ•°ç›®ï¼Œåˆå€¼åº”è¯¥å¤§äºç­‰äº0</li></ul></li><li><p><img src="/images/OS/process_corporate.png"></p></li><li><p>s13 = 0 è¡¨ç¤ºè¿›ç¨‹P1å°šæœªæ‰§è¡Œå®Œæˆ</p></li><li><p>s23 = 0 è¡¨ç¤ºè¿›ç¨‹P2å°šæœªæ‰§è¡Œå®Œæˆ</p></li><li><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">P1</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">....;</span><br><span class="line">  v(s13);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">P2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ....;</span><br><span class="line">  v(s23);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">P3</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  p(s13);</span><br><span class="line">  p(s23);</span><br><span class="line">  .....;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>æ€è·¯ï¼šä¸ºæ¯ä¸ªåªèƒ½åœ¨è¿›ç¨‹iç»“æŸåæ‰èƒ½æ‰§è¡Œçš„è¿›ç¨‹jè®¾ç½®æ˜¯å¦å¯å¼€å§‹çš„ä¿¡å·ç¯<span class="math inline">\(S_{ij}\)</span>ï¼Œå…¶åˆå€¼ä¸º0ï¼Œè¿™äº›è¿›ç¨‹æ‰§è¡Œå‰å…ˆå¯¹<span class="math inline">\(S_{ij}\)</span>è¿›è¡Œpæ“ä½œã€‚</p></li></ul></li></ul></li><li>IPC<ul><li><p>fork</p><ul><li><p>å­è¿›ç¨‹å€¼ä¸º0ï¼Œçˆ¶è¿›ç¨‹ä¸­ä¸ºä¸€å¤§äº0æ•´æ•°</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pid_t</span> p1, p2, p3;</span><br><span class="line"><span class="keyword">if</span> ((p1 = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// child process</span></span><br><span class="line">    execv(<span class="string">"./get"</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> ((p2 = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// child process</span></span><br><span class="line">    execv(<span class="string">"./copy"</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> ((p3 = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// child process</span></span><br><span class="line">    execv(<span class="string">"./put"</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    wait(<span class="literal">NULL</span>);</span><br><span class="line">    wait(<span class="literal">NULL</span>);</span><br><span class="line">    wait(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>å¹¶å‘å®è·µï¼ŒP80å·¦å³ï¼Œæ³¨æ„æœ‰æ— else</p></li></ul></li><li><p>çº¿ç¨‹</p><ul><li>çº¿ç¨‹(Thread)æ˜¯ä¸€ä¸ªåŠ¨æ€çš„å¯¹è±¡ï¼Œæ˜¯å¤„ç†æœºè°ƒåº¦çš„åŸºæœ¬å•ä½ï¼Œè¡¨ç¤ºä¸€ä¸ªè¿›ç¨‹ä¸­çš„ä¸€ä¸ªæ§åˆ¶ç‚¹ï¼Œæ‰§è¡Œä¸€ç³»åˆ—çš„æŒ‡ä»¤ã€‚</li><li>è¿›ç¨‹æ˜¯ç³»ç»Ÿèµ„æºçš„åˆ†é…å•ä½ï¼›çº¿ç¨‹æ˜¯å¤„ç†æœºè°ƒåº¦çš„å¯¹è±¡</li><li>ä¸è¿›ç¨‹ç›¸åŒçš„åœ°æ–¹<ul><li>çº¿ç¨‹å…±äº«çˆ¶è¿›ç¨‹çš„ä»£ç æ®µå’Œæ•°æ®æ®µï¼Œæ‹¥æœ‰ç›¸åŒçš„ä¼˜å…ˆçº§</li></ul></li><li>ä¸åŒçš„åœ°æ–¹<ul><li>æ¯ä¸ªçº¿ç¨‹æ‹¥æœ‰è‡ªå·±çš„PCï¼Œå¯„å­˜å™¨å’Œæ ˆæŒ‡é’ˆ</li></ul></li><li>ä¸Šä¸‹æ–‡åˆ‡æ¢<ul><li>åŒä¸€ä¸ªè¿›ç¨‹ä¸­çº¿ç¨‹åˆ‡æ¢ç®€å•ï¼Œå› ä¸ºè¿›ç¨‹ä¸­æ‰€æœ‰çº¿ç¨‹æ˜¯å…±äº«ä¸€ä¸ªä¸Šä¸‹æ–‡çš„</li></ul></li><li>å®éªŒ<ul><li>é£æœºå”®ç¥¨</li></ul></li></ul></li><li>è°ƒåº¦<ul><li><p>å¾ªç¯è½®è½¬</p><p><img src="/images/OS/rotate.png"></p><ul><li>å›ºå®šæ—¶é—´ç‰‡<ul><li>ä¼˜ç‚¹ï¼šå®ç°ç®€å•ã€ç³»ç»Ÿå¼€é”€å°</li><li>ç¼ºç‚¹ï¼šä¸çµæ´»ï¼Œå½“ç³»ç»Ÿä¸­è¿›ç¨‹è¾ƒå°‘æ—¶ï¼Œç³»ç»Ÿå¼€é”€å¤§</li></ul></li></ul></li><li><p>ä¼˜å…ˆçº§</p><ul><li>å¤šçº§åé¦ˆé˜Ÿåˆ—è°ƒåº¦ç®—æ³•</li></ul><p><img src="/images/OS/priority&amp;timeslice.png"></p><p><img src="/images/OS/ä¼˜å…ˆçº§.png"></p><ul><li>I/Oé‡å¤§-&gt;é«˜ä¼˜å…ˆå°±ç»ªé˜Ÿåˆ—ï¼Œ<strong>ä¼˜å…ˆç…§é¡¾</strong></li><li>è®¡ç®—é‡å¤§-&gt;ä½ä¼˜å…ˆå°±ç»ªé˜Ÿåˆ—ï¼Œä½†ä¸€æ¬¡å¯æ‰§è¡Œ500msï¼Œ<strong>é€‚å½“ç…§é¡¾</strong></li><li>I/Oå¤š-&gt;ä¼˜å…ˆæ‰§è¡Œï¼Œç³»ç»Ÿçš„å¤–éƒ¨è®¾å¤‡ç»å¸¸å¿™</li><li>I/Oå°‘-&gt;æ—¶é—´ç‰‡é•¿ï¼Œä¸Šä¸‹æ–‡åˆ‡æ¢å°‘ç³»ç»Ÿå¼€é”€å°</li></ul></li></ul></li></ul><h2><span id="ç¬¬äº”ç« ">ç¬¬äº”ç« </span></h2><ul><li>æ­»é”<ul><li>æ­»é”å°±æ˜¯ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„è¿›ç¨‹ç­‰å€™ç€ä¸€ä¸ªæ°¸è¿œä¸ä¼šå‘ç”Ÿçš„äº‹ä»¶æ—¶æ‰€å¤„çš„ä¸€ç§ç³»ç»ŸçŠ¶æ€ã€‚</li><li>å››ä¸ªå¿…è¦æ¡ä»¶<ul><li>äº’æ–¥-Mutual Exclusion</li><li>ä¸å¯å‰¥å¤º-No preemption</li><li>éƒ¨åˆ†åˆ†é…-Hold and wait</li><li>å¾ªç¯ç­‰å¾…-Circular wait</li></ul></li></ul></li><li>é¢„é˜²<ul><li>é¢„å…ˆåˆ†é…ä¸€ä¸ªè¿›ç¨‹è¦ç”¨çš„æ‰€æœ‰èµ„æºï¼ˆé™æ€åˆ†é…ï¼‰æ˜¯é˜²æ­¢æ­»é”çš„ä¸€ç§å®‰å…¨è€Œç®€å•çš„æ–¹æ³•<ul><li>ç ´åéƒ¨åˆ†åˆ†é…æ¡ä»¶</li><li>ç¼ºç‚¹ï¼šè®¾å¤‡ï¼ˆèµ„æºï¼‰çš„æµªè´¹å¤ªå¤§</li></ul></li></ul></li><li>é¿å…<ul><li>æœ‰åºèµ„æºåˆ†é…<ul><li>ç³»ç»Ÿä¸­çš„æ‰€æœ‰èµ„æºç»Ÿä¸€ç¼–å·ï¼ˆå¦‚æ‰“å°æœºä¸º1ï¼Œç£å¸¦æœºä¸º2...ï¼‰</li><li>ç”³è¯·æ—¶å¿…é¡»ä»¥ä¸Šå‡çš„æ¬¡åº</li><li>ç³»ç»Ÿè¦æ±‚<ul><li>å¯¹å¿…é¡»ä½¿ç”¨çš„è€Œä¸”å±äºåŒä¸€ç±»çš„èµ„æºï¼Œå¿…é¡»ä¸€æ¬¡ç”³è¯·å®Œ</li><li>åœ¨ç”³è¯·ä¸åŒç±»èµ„æºæ—¶ï¼Œå¿…é¡»æŒ‰è®¾å¤‡ç¼–å·ä¾æ¬¡ç”³è¯·</li></ul></li></ul></li><li>æœ€ç®€å•çš„é“¶è¡Œå®¶ç®—æ³•ï¼ˆä¹¦ä¸Šçš„ä¾‹å­ï¼‰<ul><li>é“¶è¡Œå®¶ç®—æ³•è¦æ±‚è¿›å…¥ç³»ç»Ÿçš„è¿›ç¨‹å¿…é¡»è¯´æ˜å®ƒå¯¹å„ç±»èµ„æºç±»å‹çš„å®ä¾‹çš„æœ€å¤§éœ€æ±‚é‡ã€‚è¿™ä¸€æ•°é‡ä¸èƒ½è¶…è¿‡ç³»ç»Ÿå„ç±»èµ„æºçš„æ€»æ•°ã€‚å½“è¿›ç¨‹ç”³è¯·ä¸€ç»„èµ„æºæ—¶ï¼Œè¯¥ç®—æ³•éœ€è¦æ£€æŸ¥ç”³è¯·è€…å¯¹å„ç±»èµ„æºçš„æœ€å¤§éœ€æ±‚é‡ï¼Œ<strong>å¦‚æœç³»ç»Ÿç°å­˜çš„å„ç±»èµ„æºçš„æ•°é‡å¯ä»¥æ»¡è¶³å½“å‰å®ƒå¯¹å„ç±»èµ„æºçš„æœ€å¤§éœ€æ±‚é‡ï¼Œå°±æ»¡è¶³å½“å‰çš„ç”³è¯·</strong>ï¼›å¦åˆ™è¿›ç¨‹å¿…é¡»ç­‰å¾…ï¼Œç›´åˆ°å…¶ä»–è¿›ç¨‹é‡Šæ”¾è¶³å¤Ÿçš„èµ„æºä¸ºæ­¢ã€‚</li><li>é—®é¢˜<ul><li>è€ƒå¯Ÿæ¯ä¸ªè¿›ç¨‹å¯¹å„ä¸ªèµ„æºçš„ç”³è¯·éœ€èŠ±è´¹è¾ƒå¤šçš„æ—¶é—´</li><li>è¿‡äºè°¨æ…</li></ul></li></ul></li></ul></li></ul><h2><span id="ç¬¬å…­ç« ">ç¬¬å…­ç« </span></h2><ul><li>æ˜ å°„<ul><li>é€»è¾‘ã€ç‰©ç†è½¬æ¢</li><li>é™æ€åœ°å€æ˜ å°„<ul><li>åœ¨ä½œä¸šè£…å…¥è¿‡ç¨‹ä¸­è¿›è¡Œåœ°å€æ˜ å°„</li><li>éœ€è½¯ä»¶é‡å®šä½è£…å…¥ç¨‹åº</li><li>éœ€è¦èŠ±è´¹è¾ƒå¤šCPUæ—¶é—´</li><li>ä¸çµæ´»</li></ul></li><li>åŠ¨æ€åœ°å€æ˜ å°„<ul><li>åœ¨ç¨‹åºæ‰§è¡ŒæœŸé—´è¿›è¡Œåœ°å€æ˜ å°„</li><li>éœ€è¦ç¡¬ä»¶åœ°å€å˜æ¢æœºæ„-é‡å®šä½å¯„å­˜å™¨</li><li>åœ°å€å˜æ¢å¿«</li><li>çµæ´»</li></ul></li></ul></li><li><p>åˆ†é…</p><ul><li>æ”¾ç½®ç­–ç•¥</li><li>è°ƒå…¥ç­–ç•¥<ul><li>è¯·è°ƒ</li><li>é¢„è°ƒ</li></ul></li><li>æ·˜æ±°ç­–ç•¥</li></ul></li><li>æ‰©å……<ul><li>è™šæ‹Ÿå­˜å‚¨-ä¸ºç”¨æˆ·æä¾›ä¸€ç§ä¸å—ç‰©ç†å­˜å‚¨å™¨ç»“æ„å’Œå®¹é‡é™åˆ¶çš„å­˜å‚¨å™¨</li><li>æ ¸å¿ƒ<ul><li>ç¨‹åºæ‰§è¡Œçš„å±€éƒ¨æ€§åŸç†</li><li>é€»è¾‘åœ°å€å’Œç‰©ç†åœ°å€çš„åˆ†ç¦»</li></ul></li></ul></li><li>ä¿æŠ¤<ul><li>ä¸Šä¸‹ç•Œ -&gt; ç‰©ç†<ul><li>ä¸‹ç•Œå¯„å­˜å™¨ï¼šå­˜æ”¾ç¨‹åºè£…å…¥å†…å­˜åçš„å¼€å§‹åœ°å€</li><li>ä¸Šç•Œå¯„å­˜å™¨ï¼šå­˜æ”¾ç¨‹åºè£…å…¥å†…å­˜åçš„æœ«åœ°å€</li><li>ï¼ˆä¸‹ç•Œå¯„å­˜å™¨ï¼‰<span class="math inline">\(\le\)</span> ç‰©ç†åœ°å€ &lt; ï¼ˆä¸Šç•Œå¯„å­˜å™¨ï¼‰</li></ul></li><li>åŸºå€é™é•¿ -&gt; é€»è¾‘<ul><li>0 <span class="math inline">\(\le\)</span> é€»è¾‘åœ°å€ &lt; é™é•¿</li></ul></li><li>ä»…é€‚ç”¨äºè¿ç»­åˆ†é…</li></ul></li><li>åŠ¨æ€åˆ†åŒº<ul><li><p>è‡ªç”±ä¸»å­˜é˜Ÿåˆ—</p><p><img src="/images/OS/M_RIB.png"><img src="/images/OS/PD.png"></p><p><img src="/images/OS/free.png"></p></li><li><p>é¦–æ¬¡é€‚åº”ç®—æ³•</p><ul><li><p>æŒ‰ç©ºé—²åŒºé¦–å€å‡åºçš„æ–¹æ³•ç»„ç»‡</p></li><li><p>å°½å¯èƒ½åœ°åˆ©ç”¨ä½åœ°å€çš„ç©ºé—²åŒºï¼Œè€Œå°½é‡åœ°ä¿è¯é«˜åœ°å€çš„å¤§ç©ºé—²åŒº</p><p><img src="/images/OS/first.png"></p></li></ul></li><li><p>æœ€ä½³é€‚åº”ç®—æ³•</p><ul><li><p>æŒ‰ç©ºé—²åŒºå¤§å°å‡åºæ–¹æ³•ç»„ç»‡</p></li><li><p>å°†ç”³è¯·è€…æ”¾å…¥ä¸å…¶å¤§å°æœ€æ¥è¿‘çš„ç©ºé—²åŒºä¸­</p></li><li><p>è‹¥ç³»ç»Ÿä¸­å­˜åœ¨ä¸ç”³è¯·åŒºå¤§å°ç›¸ç­‰çš„ç©ºé—²åŒºï¼Œè¿™ç§ç®—æ³•è‚¯å®šèƒ½å°†è¿™ç§ç©ºé—²åŒºåˆ†é…ç»™ç”³è¯·è€…ï¼ˆé¦–æ¬¡é€‚åº”åˆ™ä¸ä¸€å®šï¼‰</p><p><img src="/images/OS/best.png"></p></li></ul></li><li><p>æœ€åé€‚åº”ç®—æ³•</p><ul><li><p>æŒ‰ç©ºé—²åŒºå¤§å°é™åºçš„æ–¹æ³•ç»„ç»‡</p></li><li><p>å°†æœ€å¤§çš„ç©ºé—²åŒºåˆ‡å»ä¸€éƒ¨åˆ†ç»™è¯·æ±‚è€…</p></li><li><p>å…‹æœæœ€ä½³é€‚åº”ç®—æ³•æŠŠç©ºé—²åŒºåˆ†å‰²å¾—å¤ªå°çš„ç¼ºç‚¹</p><p><img src="/images/OS/worst.png"></p></li></ul></li><li><p>é«˜ã€ä½åœ°å€ä¼˜å…ˆ</p></li></ul></li><li>é¡µå¼ç³»ç»Ÿ<ul><li><p>é¡µè¡¨</p><table><thead><tr class="header"><th>é¡µå·</th><th>å—å·</th></tr></thead><tbody></tbody></table></li><li><p>å¿«è¡¨</p><ul><li>Translation Look-aside Buffers, TLB</li></ul></li><li><p>åœ°å€å˜æ¢è¿‡ç¨‹</p><p><img src="/images/OS/trans.png"></p><p>å†…å­˜åœ°å€ = å—å· * é¡µå¤§å° + ä½ç§»é‡</p><ul><li>æŒ‰å­—èŠ‚ç¼–å€</li><li>1KB = 10ä½</li><li>2KB = 11ä½</li><li>1MB = 20ä½</li><li>1GB = 30ä½</li></ul><p>ç¨‹åºåœ°å€ä»¥åè¿›åˆ¶ç»™å‡º</p><ul><li>é¡µå· = è™šåœ°å€ % é¡µå¤§å°</li><li>ä½ç§»é‡ = è™šåœ°å€ mod é¡µå¤§å°</li></ul></li><li><p>TLB</p><p><img src="/images/OS/TLB.png"></p><ul><li>æŸ¥TLB = <span class="math inline">\(\epsilon\)</span> æ—¶é—´</li><li>æŸ¥å†…å­˜ = 1 æ¯«ç§’</li><li>å‘½ä¸­ç‡ = <span class="math inline">\(\alpha\)</span></li><li>Effective Access Time(EAT) = <span class="math inline">\((1+\epsilon)\alpha+(2+\epsilon)(1-\alpha)\)</span></li></ul></li><li><p>è¯·æ±‚åˆ†é¡µï¼Œæ‰©å……é¡µè¡¨ä½</p><ul><li><p>æ‰©å±•é¡µè¡¨</p><table><thead><tr class="header"><th>é¡µå·</th><th>å—å·</th><th>ä¸­æ–­</th><th>è¾…å­˜åœ°å€</th><th>å¼•ç”¨</th><th>ä¿®æ”¹</th><th>è®¿é—®æ–¹æ³•</th></tr></thead><tbody></tbody></table></li><li><p>ä¸­æ–­ä½ï¼š0 -&gt; åœ¨å†…å­˜ï¼Œ1 -&gt; ä¸åœ¨å†…å­˜</p></li><li><p>å¼•ç”¨ä½ï¼š0 -&gt; æ²¡æœ‰è¿›ç¨‹è®¿é—®ï¼Œ1 -&gt; æœ‰è¿›ç¨‹è®¿é—®</p></li><li><p>ä¿®æ”¹ä½ï¼š0 -&gt; è°ƒå…¥åæ²¡ä¿®æ”¹ï¼Œ2 -&gt; è°ƒå…¥åä¿®æ”¹è¿‡</p></li></ul></li><li><p>é¡µé¢ç½®æ¢ç®—æ³•</p><ul><li><p>å…ˆè¿›å…ˆå‡º</p><ul><li>å»ºç«‹ä¸€ä¸ªé¡µé¢è¿›å…¥ä¸»å­˜çš„å…ˆåæ¬¡åºè¡¨</li><li>å»ºç«‹ä¸€ä¸ªæ›¿æ¢æŒ‡é’ˆï¼ŒæŒ‡å‘æœ€æ—©è¿›å…¥ä¸»å­˜çš„é¡µé¢</li><li>å½“éœ€è¦ç½®æ¢ä¸€é¡µæ—¶ï¼Œé€‰æ‹©æ›¿æ¢æŒ‡å‘çš„ä¸€é¡µï¼Œç„¶åè°ƒæ•´æ›¿æ¢æŒ‡é’ˆçš„å†…å®¹</li><li>æ¯æ¬¡æœ‰æ–°é¡µé¢è¿›å…¥å†…å­˜æ›´æ–°æ¬¡åºè¡¨</li></ul></li><li><p>LRU-Least Recently Used</p><ul><li><p>éœ€è¦æ·˜æ±°é¡µæ—¶ï¼Œé€‰æ‹©æœ€é•¿æ—¶é—´æœªä½¿ç”¨çš„é¡µ</p><p><img src="/images/OS/LRU.png"></p></li></ul></li><li><p>è¿‘ä¼¼LRUï¼ˆå®ç°ï¼‰</p><p><img src="/images/OS/LRUæµç¨‹.png"></p><p><img src="/images/OS/LRUeg.png"></p></li></ul></li></ul></li><li><p>é¡µå¼ç³»ç»Ÿæœ€ç»ˆé¢è²Œ</p><p><img src="/images/OS/page.png"></p><p>ä¼˜ç‚¹ï¼š</p><ul><li>ä¸è¦æ±‚ä½œä¸šçš„ç¨‹åºå’Œæ•°æ®æ®µåœ¨å†…å­˜ä¸­è¿ç»­å­˜æ”¾ï¼Œè§£å†³äº†ç¢ç‰‡é—®é¢˜</li><li>å¯ä»¥åˆ©ç”¨çš„å­˜è´®ç©ºé—´å¤§å¤§å¢åŠ ï¼Œæé«˜äº†ä¸»å­˜åˆ©ç”¨ç‡</li><li>è¯·æ±‚å¼ç³»ç»Ÿæä¾›äº†ç»Ÿä¸€ç®¡ç†çš„è™šæ‹Ÿå­˜å‚¨å®ç°æ–¹æ¡ˆ</li></ul><p>ç¼ºç‚¹ï¼š</p><ul><li>ç¡¬ä»¶æ”¯æŒï¼Œæˆæœ¬</li><li>ç³»ç»Ÿå¼€é”€å¤§ï¼Œé¡µè¡¨ç»´æŠ¤ä¸ç®¡ç†ï¼Œç¼ºé¡µä¸­æ–­</li><li>æŠ–åŠ¨</li></ul></li><li><p>æ®µé¡µå¼ç³»ç»Ÿ</p><ul><li>åŒºåˆ«ã€å˜æ¢<ul><li>é¡µæ˜¯ç‰©ç†å•ä½ï¼Œæ®µæ˜¯é€»è¾‘å•ä½</li><li>é¡µå¤§å°æ˜¯å›ºå®šçš„ï¼Œæ®µå¤§å°ä¸å›ºå®š</li></ul></li><li>æ®µé¡µå¼ç³»ç»Ÿï¼šæ®µå†…åˆ†é¡µ</li><li>éš¾åº¦å°äºè¯¾ä»¶ä¸Šä¾‹å­</li></ul></li></ul><h2><span id="ç¬¬ä¸ƒç« ">ç¬¬ä¸ƒç« </span></h2><ul><li>ç‹¬ç«‹æ€§ï¼šç”¨æˆ·åœ¨ç¼–ç¨‹å¼æ‰€ä½¿ç”¨çš„è®¾å¤‡ä¸å®é™…è®¾å¤‡æ— å…³<ul><li>é€»è¾‘è®¾å¤‡åï¼šç”¨æˆ·æŒ‡å®šçš„è®¾å¤‡åï¼ˆå¯æ›´æ”¹çš„ï¼‰</li><li>ç‰©ç†åï¼šç³»ç»Ÿæä¾›çš„è®¾å¤‡çš„æ ‡å‡†åç§°ï¼ˆä¸å¯æ›´æ”¹ï¼‰</li><li>ä¼˜ç‚¹<ul><li>æ–¹ä¾¿ç”¨æˆ·</li><li>æ”¹å–„è®¾å¤‡åˆ©ç”¨ç‡</li><li>æé«˜ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œå¯é€‚åº”æ€§</li></ul></li></ul></li><li><p>ç‹¬å è®¾å¤‡ï¼šé‡‡ç”¨åŠ¨æ€åˆ†é…æœ‰å¯èƒ½é€ æˆæ­»é”</p><ul><li>è®©ä¸€ä¸ªè®¾å¤‡åœ¨æ•´ä¸ªè¿è¡ŒåŒºé—´ç‹¬å ä½¿ç”¨</li></ul></li><li><p>å…±äº«è®¾å¤‡ï¼šä¸ä¼šæ­»é”</p><ul><li>ç”±å¤šä¸ªä½œä¸šã€è¿›ç¨‹å…±åŒä½¿ç”¨çš„è®¾å¤‡</li></ul></li><li><p>è®¾å¤‡åˆ†é…</p><ul><li>å…ˆæ¥å…ˆæœåŠ¡</li><li>ä¼˜å…ˆçº§é«˜è€…ä¼˜å…ˆ</li><li>ç‹¬å åˆ†é…ï¼šåœ¨ä¸€ä½œä¸šæ‰§è¡Œå‰ï¼Œå°†å®ƒæ‰€è¦ä½¿ç”¨çš„è®¾å¤‡åˆ†é…ç»™å®ƒï¼›å½“å®ƒç»“æŸæ’¤ç¦»æ—¶ï¼Œå°†åˆ†é…ç»™å®ƒçš„è¿™ç±»è®¾å¤‡æ”¶å›</li><li>å…±äº«åˆ†é…ï¼šåŠ¨æ€åˆ†é…ï¼Œè¿›ç¨‹æå‡ºèµ„æºç”³è¯·ï¼Œç”±è®¾å¤‡ç®¡ç†æ¨¡å—è¿›è¡Œåˆ†é…ï¼Œè¿›ç¨‹ä½¿ç”¨å®Œæ¯•åç«‹å³å½’è¿˜</li><li>è™šæ‹Ÿåˆ†é…<ul><li>å°†ç‹¬å è®¾å¤‡è½¬æ¢ä¸ºå…±äº«è®¾å¤‡çš„ä¸€ç§æŠ€æœ¯</li><li>é€šå¸¸æŠŠç”¨æ¥ä»£æ›¿ç‹¬å ç±»å‹è®¾å¤‡çš„é‚£éƒ¨åˆ†å¤–å­˜ç©ºé—´ç§°ä¸º<strong>è™šæ‹Ÿè®¾å¤‡</strong></li><li>å½“è¿›ç¨‹éœ€è¦ä¸ç‹¬å è®¾å¤‡äº¤æ¢ä¿¡æ¯æ—¶ï¼Œç³»ç»Ÿå°†åˆ†é…ç£ç›˜ç©ºé—´ï¼Œå¹¶å»ºç«‹ç›¸åº”çš„æ•°æ®ç»“æ„ï¼Œè¿™ç§åˆ†é…æ–¹æ³•ç§°ä¸ºè™šæ‹Ÿåˆ†é…</li></ul></li></ul><p>â€‹</p></li><li>ç¼“å†²ç®¡ç†<ul><li><p>é¢„å­˜ç¼“å†™</p></li><li><p>ä¸è®©è¿›ç¨‹é•¿æ—¶é—´ç­‰å¾…å¤–è®¾å®Œæˆæ“ä½œ</p></li><li><p>ç¼“å†™</p><p><img src="/images/OS/ç¼“å†².png"></p></li></ul></li></ul><h2><span id="ç¬¬å…«ç« ">ç¬¬å…«ç« </span></h2><ul><li>æ–‡ä»¶<ul><li>é€»è¾‘ç»“æ„<ul><li>æµå¼ Byte Sequence<ul><li>æ— ç»“æ„ï¼Œæµå¼æ–‡ä»¶æ˜¯ç›¸å…³çš„å­—ç¬¦çš„é›†åˆï¼Œæ–‡ä»¶çš„é•¿åº¦ä¸ºæ‰€å«å­—ç¬¦æ•°</li></ul></li><li>è®°å½•å¼ Record Structure<ul><li>è®°å½•å¼æ–‡ä»¶æ˜¯è®°å½•çš„é›†åˆï¼Œæ¯ä¸ªè®°å½•ç”±ç›¸å…³çš„åŸŸæ„æˆ</li></ul></li></ul></li><li>ç‰©ç†ç»“æ„<ul><li><p>è¿ç»­æ–‡ä»¶</p><ul><li>æ–‡ä»¶å†…å®¹å­˜æ”¾åœ¨è¿ç»­ç¼–å·çš„ç£ç›˜å—ä¸­</li><li>ä¼˜ç‚¹<ul><li>ç»“æ„ç®€å•ï¼Œå®¹æ˜“å®ç°</li><li>ä¸éœ€è¦é¢å¤–å¼€é”€</li></ul></li><li>ç¼ºç‚¹<ul><li>ç©ºé—´åˆ©ç”¨ç‡ä½</li><li>ä¸åˆ©äºæ–‡ä»¶çš„åŠ¨æ€å¢åŠ å’Œä¿®æ”¹</li></ul></li></ul></li><li><p>ä¸²è”æ–‡ä»¶</p><ul><li>æ–‡ä»¶çš„å†…å®¹æ”¾åœ¨è‹¥å¹²ä¸è¦æ±‚è¿ç»­ç¼–å·çš„ç£ç›˜å—ä¸­</li><li>ä¸€ä¸ªæ–‡ä»¶å ç”¨çš„ç£ç›˜å—é“¾æ¥æˆä¸€ä¸ªç£ç›˜å—é“¾ï¼Œé“¾æ¥æŒ‡é’ˆå­˜æ”¾åœ¨æ¯ç£ç›˜å—çš„æœ€æœ«ä¸€ä¸ªå­—ï¼ˆæˆ–ç¬¬ä¸€ä¸ªå­—ï¼‰</li><li>ä¼˜ç‚¹<ul><li>å­˜å‚¨ç©ºé—´åˆ©ç”¨ç‡é«˜</li><li>æ–‡ä»¶åŠ¨æ€æ‰©å……å’Œä¿®æ”¹å®¹æ˜“</li></ul></li><li>ç¼ºç‚¹<ul><li>éšæœºå­˜å–æ•ˆç‡å¤ªä½</li></ul></li></ul></li><li><p>FAT</p><ul><li>æ–‡ä»¶æ˜ ç…§</li><li>æŠŠä¸²è”æ–‡ä»¶ä¸­çš„é“¾æ¥é›†ä¸­åœ¨ä¸€ä¸ªç»“æ„ä¸­ï¼Œè¿™æ ·æ—¢ä¿æŒäº†ä¸²è”æ–‡ä»¶çš„ä¼˜ç‚¹ï¼Œä¹Ÿå…‹æœäº†å…¶ç¼ºç‚¹</li></ul><p><img src="/images/OS/FAT.png"></p></li><li><p>ç´¢å¼•æ–‡ä»¶</p><ul><li>æ¯ä¸ªæ–‡ä»¶æœ‰ä¸€ä¸ªç´¢å¼•è¡¨ï¼Œç™»è®°æ–‡ä»¶çš„é€»è¾‘å—ä¸ç‰©ç†å—é—´çš„å¯¹åº”å…³ç³»</li></ul><p><img src="/images/OS/index.png"></p><ul><li>i_addr[0]~i_addr[9] ä¸ºç›´æ¥ç´¢å¼•</li><li>i_addr[10]ä¸ºä¸€çº§é—´æ¥ç´¢å¼•å—</li><li>i_addr[11]ä¸ºäºŒçº§é—´æ¥ç´¢å¼•å—</li><li>i_addr[12]ä¸ºä¸‰çº§é—´æ¥ç´¢å¼•å—</li></ul></li></ul></li></ul></li><li>ç©ºé—²ç©ºé—´<ul><li><p>ä½ç¤ºå›¾</p><ul><li><p>ç”¨ä¸€ä¸ªä½å‘é‡è¡¨ç¤ºå“ªä¸€å—ç©ºé—²</p><p><img src="/images/OS/bitmap.png"></p></li></ul></li><li><p>æˆç»„è¿æ¥-Grouping</p><p><img src="/images/OS/group.png"></p><ul><li><p>ç©ºé—²inode</p><ul><li>s_nfree ç©ºé—²å—æ•°ï¼Œåˆå€¼ä¸º1</li><li>s_free[100] ç©ºé—²å—å—å·ï¼Œs_free[0]åˆå€¼ä¸º0</li></ul></li><li><p>ç¬¬ä¸€ç»„æ˜¯99å—ï¼Œä¸­é—´éƒ½æ˜¯100å—ï¼Œæœ€åä¸€ç»„&lt;=100å—</p></li><li><p>å›æ”¶ç®—æ³•free</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">free</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (s_nfree &lt; <span class="number">100</span>) &#123;</span><br><span class="line">    s_free[s_nfree++] = é‡Šæ”¾ç£ç›˜å—å·;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    å°†s_free[]å†™åˆ°é‡Šæ”¾ç£ç›˜å—ä¸­;</span><br><span class="line">    s_nfree = <span class="number">1</span>;</span><br><span class="line">    s_free[<span class="number">0</span>] = é‡Šæ”¾ç£ç›˜å·;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>åˆ†é…ç®—æ³•alloc</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ç£ç›˜å— alloc()</span><br><span class="line">&#123;</span><br><span class="line">  s_nfree--;</span><br><span class="line">  <span class="keyword">if</span> (s_nfree == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (s_free[<span class="number">0</span>] == <span class="number">0</span>) &#123;</span><br><span class="line">      sleep();</span><br><span class="line">    &#125;</span><br><span class="line">    a = s_free[<span class="number">0</span>];</span><br><span class="line">    å°†s_free[<span class="number">0</span>]å—è¯»åˆ°filsys;</span><br><span class="line">    s_nfree = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> s_free[s_nfree];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li>æ–‡ä»¶å›¾ç¤º<ul><li><p>æ ‘å½¢</p><p><img src="/images/OS/filetree.png"></p><ul><li><p>ç›®å½•æ–‡ä»¶æ˜¯æœ‰æ–‡ä»¶ç›®å½•é¡¹ç»„æˆçš„æ–‡ä»¶</p></li><li><p>æ–‡ä»¶ç›®å½•é¡¹ç”±æ–‡ä»¶åå’Œinodeç»„æˆ</p><table><thead><tr class="header"><th>æ–‡ä»¶å</th><th>inode</th></tr></thead><tbody></tbody></table></li></ul><p><strong>inode</strong></p><p><img src="/images/OS/inode.png"></p></li><li><p>ç»å¯¹ï¼ç›¸å¯¹è·¯å¾„</p></li><li><p>é“¾æ¥</p><ul><li>ç¡¬é“¾æ¥ï¼šç›®å½•é¡¹ä¸­æŒ‡å‘åŒä¸€ä¸ªinode</li><li>è½¯é“¾æ¥ï¼šç›®å½•é¡¹ä¸­æŒ‡å‘ä¸åŒçš„inodeï¼Œé“¾æ¥æ–‡ä»¶çš„ç£ç›˜å—é‡Œå­˜å‚¨é“¾æ¥å¯¹è±¡çš„inode</li></ul></li><li><p>æ–‡ä»¶å…±äº«</p><ul><li>è¢«å¤šä¸ªç”¨æˆ·ä½¿ç”¨ï¼Œç”±å­˜å–æƒé™æ§åˆ¶</li><li>è¢«å¤šä¸ªè¿›ç¨‹ä½¿ç”¨ï¼Œä½†å„ç”¨è‡ªå·±çš„è¯»å†™æŒ‡é’ˆ</li><li>è¢«å¤šä¸ªè¿›ç¨‹ä½¿ç”¨ï¼Œä½†å…±äº«è¯»å†™æŒ‡é’ˆ</li></ul></li><li><p>æ–‡ä»¶æ“ä½œï¼ˆFCBï¼‰</p><p><img src="/images/OS/FCB.png"></p><ul><li>æ‰“å¼€</li><li>é‡å‘½å</li><li>ç§»åŠ¨</li></ul></li></ul></li></ul><h2><span id="tinyos">TinyOS</span></h2><ul><li>ç»„ä»¶åŒ–ç¼–ç¨‹ï¼Œè¿æ¥é…ç½®æ–‡ä»¶<ul><li>Application = Graph of Components</li></ul></li><li>æ‰§è¡Œæœºåˆ¶<ul><li>åˆ†é˜¶æ®µä½œä¸šï¼Œæ— é˜»å¡</li><li>ä¸»åŠ¨æ¶ˆæ¯é€šä¿¡</li></ul></li><li>ä¸­æ–­</li><li>äº‹ä»¶<ul><li>äº‹ä»¶é©±åŠ¨</li><li>ä¼˜å…ˆçº§é«˜äºä»»åŠ¡</li></ul></li><li>ä»»åŠ¡<ul><li>è½»é‡çº§çº¿ç¨‹ã€‚ä»»åŠ¡ä¹‹é—´å¹³ç­‰ï¼Œä¸èƒ½ç›¸äº’æŠ¢å ï¼Œå…ˆå…¥å…ˆå‡ºè¿›è¡Œè°ƒåº¦</li><li>ä»»åŠ¡ä¸€èˆ¬ç”¨äºå¯¹æ—¶é—´è¦æ±‚ä¸æ˜¯å¾ˆé«˜çš„åº”ç”¨ä¸­ï¼Œè¦æ±‚æ¯ä¸ªä»»åŠ¡éƒ½å¾ˆçŸ­å°ï¼Œèƒ½å¤Ÿä½¿ç³»ç»Ÿçš„è´Ÿæ‹…è¾ƒè½»</li><li>ä¸èƒ½æœ‰è¿”å›å€¼å’Œå‚æ•°</li></ul></li></ul><p><strong>ä¹ é¢˜</strong></p><ol type="1"><li>è¾“å…¥è¾“å‡ºæ§åˆ¶çš„ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ<ul><li>è§£é‡Šç”¨æˆ·çš„I/Oç³»ç»Ÿè°ƒç”¨å‘½ä»¤</li><li>è®¾å¤‡é©±åŠ¨</li><li>ä¸­æ–­å¤„ç†</li></ul></li><li>å®æ—¶ç³»ç»Ÿçš„åŸºæœ¬ç‰¹å¾ï¼š<ul><li>å®‰å…¨æ€§</li><li>å®æ—¶æ€§</li><li>é«˜å¯é </li><li><strong>æ²¡æœ‰</strong>å…¬å¹³å“åº”ï¼</li></ul></li><li>æ–‡ä»¶çš„ç‰©ç†ç»“æ„ï¼š<ul><li>è¿ç»­</li><li>ä¸²è”</li><li>ç´¢å¼•</li></ul></li><li>è®¾å¤‡ç‹¬ç«‹æ€§æ˜¯æŒ‡<strong>ç”¨æˆ·ç¨‹åºä¸­ä½¿ç”¨çš„è®¾å¤‡ç‹¬ç«‹äºå…·ä½“çš„ç‰©ç†è®¾å¤‡</strong></li><li>æ‰€è°“æ“ä½œç³»ç»Ÿè™šæ‹Ÿæœºçš„æ¦‚å¿µï¼Œæ˜¯æŒ‡<strong>åœ¨è£¸æœºä¸Šé…ç½®æ“ä½œç³»ç»Ÿ</strong></li><li>å¸¸ç”¨çš„èµ„æºåˆ†é…ç­–ç•¥æœ‰ä¼˜å…ˆè°ƒåº¦å’Œ<strong>å…ˆæ¥å…ˆæœåŠ¡</strong>ä¸¤ç§</li><li>æ–‡ä»¶ç›®å½•é‡‡ç”¨æ ‘å‹ç»“æ„è€Œä¸é‡‡ç”¨ç®€å•è¡¨ç»“æ„çš„æœ€ä¸»è¦åŸå› æ˜¯<strong>è§£å†³é‡åé—®é¢˜</strong></li><li>åœ¨è¯·æ±‚åˆ†é¡µç³»ç»Ÿä¸­ï¼Œä¸ºå®ç°æ·˜æ±°é¡µé¢çš„åŠŸèƒ½ï¼Œåœ¨é¡µè¡¨ä¸­å¢åŠ <strong>å¼•ç”¨ä½</strong>å’Œ<strong>æ”¹å˜ä½</strong>ä¸¤ä¸ªæ•°æ®é¡¹</li><li>å¸¸ç”¨çš„è®¾å¤‡åˆ†é…æŠ€æœ¯æœ‰ç‹¬å åˆ†é…ã€å…±äº«åˆ†é…å’Œ<strong>è™šæ‹Ÿåˆ†é…</strong>3ç§</li><li>æ–‡ä»¶ç³»ç»Ÿä¸­çš„é“¾æ¥æŠ€æœ¯ï¼ŒæŒ‡çš„æ˜¯åœ¨<strong>ç›®å½•è¡¨ç›®</strong>ä¹‹é—´è¿›è¡Œé“¾æ¥</li><li>æ“ä½œç³»ç»Ÿæ˜¯ç”±ä¸€ç»„èµ„æºç®¡ç†ç¨‹åºç»„æˆçš„ï¼Œå…¶ä¸­<strong>æ–‡ä»¶ç³»ç»Ÿ</strong>æ˜¯å¯¹è½¯ä»¶èµ„æºçš„ç®¡ç†ã€‚</li><li>UNIXç¼“å†²ç®¡ç†ä¸­ï¼Œä½¿ç”¨çš„é˜Ÿåˆ—ç»“æ„æœ‰<strong>ç©ºé—²ç¼“å†²åŒºé˜Ÿåˆ—</strong>å’Œ<strong>è®¾å¤‡ç¼“å†²åŒºé˜Ÿåˆ—</strong>ä¸¤ç§</li><li>åœ¨æ•´ä¸ªä¸­æ–­å‘é‡å¤„ç†è¿‡ç¨‹ä¸­ï¼Œç¡¬ä»¶è´Ÿè´£<strong>ä¸­æ–­å“åº”</strong>è¿‡ç¨‹</li><li>è¿›ç¨‹ä»ç»“æ„ä¸Šè®²ï¼ŒåŒ…æ‹¬<strong>ç¨‹åºã€æ•°æ®å’ŒPCB</strong>å‡ ä¸ªéƒ¨åˆ†</li><li><strong>ä¸€ç»„è¿›ç¨‹é—´å‘ç”Ÿäº†æ­»é”</strong>ï¼Œè¿™æ—¶è¿™äº›è¿›ç¨‹éƒ½å æœ‰èµ„æº</li><li><strong>ç”¨æˆ·å­˜å–ä¿¡æ¯</strong>æ˜¯ç”¨æ¥è¿›è¡ŒI/Oæ“ä½œçš„åŸºæœ¬å•ä½</li></ol>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æœ¬ç§‘è¯¾ç¨‹ </tag>
            
            <tag> æ“ä½œç³»ç»Ÿ </tag>
            
            <tag> OS </tag>
            
            <tag> TinyOS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç‰©è”ç½‘å­˜å‚¨æŠ€æœ¯</title>
      <link href="/2017/01/05/%E7%89%A9%E8%81%94%E7%BD%91%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF/"/>
      <url>/2017/01/05/%E7%89%A9%E8%81%94%E7%BD%91%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><strong>ç›®å½•</strong></p><!-- toc --><ul><li><a href="#å…ƒæ•°æ®ç®¡ç†">å…ƒæ•°æ®ç®¡ç†</a></li><li><a href="#é‡å¤æ•°æ®åˆ é™¤">é‡å¤æ•°æ®åˆ é™¤</a></li><li><a href="#å›ºæ€å­˜å‚¨æŠ€æœ¯">å›ºæ€å­˜å‚¨æŠ€æœ¯</a></li><li><a href="#æº¯æºæ•°æ®çš„é«˜æ•ˆå­˜å‚¨ç®¡ç†åŠåº”ç”¨">æº¯æºæ•°æ®çš„é«˜æ•ˆå­˜å‚¨ç®¡ç†åŠåº”ç”¨</a></li><li><a href="#åè¯è§£é‡Š">åè¯è§£é‡Š</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="å…ƒæ•°æ®ç®¡ç†">å…ƒæ•°æ®ç®¡ç†</span></h2><p>å…ƒæ•°æ®æè¿°ä»¶ç³»ç»Ÿç»„ç»‡ç»“æ„çš„æ•°æ®(æè¿°æ•°æ®çš„æ•°æ®)ï¼Œå³è®¿é—®æ•°æ®ä¹‹å‰å¿…é¡»è®¿é—®çš„æ•°æ®çš„æè¿°ä¿¡æ¯å’Œç©ºé—´ç»„ç»‡ä¿¡æ¯ã€‚</p><ul><li>OBS(Object-based Storageï¼Œå¯¹è±¡å­˜å‚¨)ï¼ŒOSD(Obeject-based Storage Deviceï¼Œå¯¹è±¡å­˜å‚¨è®¾å¤‡)</li><li>åœ¨OBSç³»ç»Ÿä¸­ï¼Œå…ƒæ•°æ®åˆ†ä¸ºç‰©ç†è§†å›¾ï¼ˆçº¦å å…ƒæ•°æ®æ€»é‡90%ï¼‰å’Œé€»è¾‘è§†å›¾ï¼ˆçº¦å å…ƒæ•°æ®æ€»é‡10%ï¼‰ã€‚<ul><li><strong>ç‰©ç†è§†å›¾</strong>è´Ÿè´£å°†<strong>å¯¹è±¡çš„é€»è¾‘å—æ˜ å°„åˆ°å­˜å‚¨ç‰©ç†ä»‹è´¨</strong>ï¼Œä»¥æ”¯æŒå¯¹è±¡åœ¨å—å­˜å‚¨è®¾å¤‡ä¸Šçš„å·¥ä½œï¼Œå­˜æ”¾åœ¨<strong>OSD</strong>ä¸Š</li><li><strong>é€»è¾‘è§†å›¾</strong>ç”¨äº<strong>æè¿°æ•´ä¸ªç³»ç»Ÿçš„å‘½åç©ºé—´ã€ç›®å½•å±‚æ¬¡ç»“æ„å’Œè®¿é—®æ§åˆ¶ç­–ç•¥ï¼Œå°†æ–‡ä»¶æ˜ å°„ä¸ºå­˜å‚¨å¯¹è±¡</strong>ï¼Œå­˜æ”¾åœ¨<strong>MDS</strong>ä¸Šã€‚</li><li>å­˜å‚¨åœ¨<strong>OSD</strong>ä¸­çš„å…ƒæ•°æ®è´Ÿè´£OSDä¸Š<strong>å±€éƒ¨</strong>çš„æ•°æ®ç®¡ç†</li><li>è€Œ<strong>MDS</strong>ä¸Šç»´æŠ¤ç®¡ç†çš„å…ƒæ•°æ®åˆ™è´Ÿè´£æ•´ä¸ªå­˜å‚¨ç³»ç»Ÿä¸­<strong>å…¨å±€çš„æ•°æ®å¸ƒå±€ã€è´Ÿè½½è°ƒåº¦ä¸è®¿é—®æ§åˆ¶</strong>æ˜¯OBSå…ƒæ•°æ®ç®¡ç†çš„<strong>é‡ç‚¹</strong></li></ul></li></ul><p>å…ƒæ•°æ®è¡¨</p><ul><li>ç”¨æ¥æè¿°æ–‡ä»¶ä¸å¯¹è±¡ä¹‹é—´çš„å¯¹åº”å…³ç³»</li><li>flagä¸º0è¡¨ç¤ºä¸€ä¸ªæ–‡ä»¶å¯¹åº”å¤šä¸ªå¯¹è±¡ï¼Œç´¢å¼•å·å­—æ®µè¡¨ç¤ºå„å¯¹è±¡åœ¨æ–‡ä»¶ä¸­çš„ç‰©ç†é€»è¾‘é¡ºåºï¼Œåç§»å€¼å­—æ®µè¡¨ç¤ºè¯¥å¯¹è±¡åœ¨å¯¹åº”æ–‡ä»¶ä¸­çš„åç§»é¦–åœ°å€</li><li>flagä¸º1åˆ™è¡¨ç¤ºå¤šä¸ªæ–‡ä»¶å­˜åœ¨ä¸€ä¸ªå¯¹è±¡ä¸­ï¼Œç´¢å¼•å·å­—æ®µè¡¨ç¤ºå„æ–‡ä»¶åœ¨å¯¹è±¡ä¸­çš„ç‰©ç†é€»è¾‘é¡ºåºï¼Œåç§»å€¼å­—æ®µè¡¨ç¤ºå„æ–‡ä»¶åœ¨ä¸­è¯¥å¯¹è±¡çš„åç§»é¦–åœ°å€</li><li>OSDå·æ˜¯å„å­˜å‚¨è®¾å¤‡ï¼ˆOSDï¼‰åœ¨OBSå­˜å‚¨ç³»ç»Ÿä¸­çš„å…¨å±€å”¯ä¸€æ ‡è¯†</li><li>å¯¹è±¡å·åˆ™æ˜¯æ ¹æ®ä¸€å®šçš„å‘½åè§„åˆ™å½¢æˆçš„å¯¹è±¡æ ‡è¯†ç¬¦ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªå…¨å±€å”¯ä¸€çš„128ä½æ— ç¬¦å·æ•°</li></ul><p>MDSçš„åŸºæœ¬åŠŸèƒ½</p><ul><li>ç»´æŠ¤å…¨å±€æ ‘å½¢ç›®å½•ç»“æ„</li><li>æä¾›ç»™å®¢æˆ·ç»Ÿä¸€çš„ç›®å½•è§†å›¾</li><li>å®Œæˆå®¢æˆ·ç«¯æäº¤çš„æ–‡ä»¶è¯·æ±‚åˆ°å¯¹è±¡çš„æ˜ å°„</li><li>å¹¶ç»™å‡ºæ‰€å±å¯¹è±¡çš„å­˜å‚¨ä½ç½®</li><li>å…ƒæ•°æ®çš„æœ¬åœ°å­˜å‚¨ç®¡ç†</li><li>å®‰å…¨ç­–ç•¥</li><li>å¯¹è±¡åˆ†å¸ƒç®¡ç†ï¼šè´Ÿè½½å‡è¡¡</li><li>Cacheçš„ä¸€è‡´æ€§ç»´æŠ¤</li></ul><p>å…ƒæ•°æ®ç®¡ç†æ–¹å¼</p><ul><li>æ ¸å¿ƒé—®é¢˜ï¼š<strong>å…ƒæ•°æ®åœ¨é›†ç¾¤ä¸Šçš„åˆ†é…ç­–ç•¥</strong></li><li>åˆç†çš„åˆ†é…ç­–ç•¥å¯ä»¥ä½¿å…ƒæ•°æ®åœ¨å„MDSä¸Šå‡åŒ€åˆ†å¸ƒï¼Œæ¥è‡ªå®¢æˆ·ç«¯çš„è®¿é—®è´Ÿè½½ä¹Ÿå¯ä»¥å‡è¡¡çš„åˆ†å¸ƒåœ¨å„ä¸ªMDSä¸Šï¼Œåœ¨æ•´ä¸ªMDSé›†ç¾¤ä¸­å°½é‡åˆ†æ•£çƒ­ç‚¹å…ƒæ•°æ®</li><li>é™æ€ç›®å½•å­æ ‘åˆ†å‰²<ul><li>æŒ‰ç…§ä¼ ç»Ÿçš„æ–‡ä»¶ç»„ç»‡æ–¹å¼ï¼Œå°†å…¨å±€ç›®å½•æ ‘åˆ’åˆ†ä¸ºè‹¥å¹²å­æ ‘ï¼Œæ¯ä¸ªMDSèŠ‚ç‚¹ä¸Šé¢ç»´æŠ¤ä¸€ä¸ªæˆ–å¤šä¸ªå­æ ‘ï¼Œå„èŠ‚ç‚¹å…±åŒç»„æˆå…¨å±€çš„é€»è¾‘è§†å›¾</li><li>ä¼˜ç‚¹<ul><li>ç®€å•</li><li>æœ€å¤§ç¨‹åº¦çš„ä¿ç•™äº†ç›®å½•çš„å±‚æ¬¡é€»è¾‘ç»“æ„</li><li>ä¾¿äºåˆ©ç”¨æ–‡ä»¶è®¿é—®çš„ç©ºé—´å±€éƒ¨æ€§</li><li>ç”¨æˆ·çš„æ–‡ä»¶è®¿é—®è¯·æ±‚åªéœ€æ¶‰åŠä¸€å°MDSï¼Œå„ä¸ªMDSå½¼æ­¤ç‹¬ç«‹</li></ul></li><li>ç¼ºç‚¹<ul><li>è‹¥æŸä¸ªç›®å½•å­æ ‘ä¸‹é¢çš„è‡ªç›®å½•æˆ–æ–‡ä»¶æˆä¸ºè®¿é—®<strong>çƒ­ç‚¹</strong>ï¼Œåˆ™å­˜æ”¾è¯¥ç›®å½•å­æ ‘çš„MDSèŠ‚ç‚¹å°†è´Ÿè½½è¿‡é‡ï¼Œæˆä¸ºMDSé›†ç¾¤ä¸­çš„ç“¶é¢ˆ</li><li>å½“åŠ å…¥æˆ–åˆ é™¤MDSèŠ‚ç‚¹æ—¶ï¼Œéœ€è¦äººå·¥çš„è°ƒæ•´ç›®å½•å­æ ‘çš„åˆ†é…ï¼Œå¤§å¤§<strong>é™åˆ¶äº†MDSé›†ç¾¤çš„å¯æ‰©å±•æ€§</strong></li></ul></li></ul></li><li>é™æ€å“ˆå¸Œ<ul><li>é™æ€å“ˆå¸Œæ–¹æ³•é€šè¿‡å°†æ–‡ä»¶æ ‡è¯†ç¬¦ã€ç›®å½•/æ–‡ä»¶åæˆ–å…¶ä»–æ–‡ä»¶ç‰¹å¾å€¼è¿›è¡Œå“ˆå¸Œè¿ç®—ï¼Œæ˜ å°„åˆ†é…åˆ°ä¸åŒçš„MDSèŠ‚ç‚¹ä¸Š</li><li>ä¼˜ç‚¹<ul><li>å°†å…¨å±€å…ƒæ•°æ®å‡åŒ€çš„åˆ†é…åˆ°MDSé›†ç¾¤å„èŠ‚ç‚¹ä¸Šï¼Œä¸ä¼šå› ä¸ºå­˜åœ¨çƒ­ç‚¹ç›®å½•å¯¼è‡´MDSè´Ÿè½½ä¸å‡è¡¡</li><li>å®¢æˆ·çš„æ–‡ä»¶è®¿é—®è¯·æ±‚ï¼Œåªè¦ç»è¿‡ç®€å•çš„å“ˆå¸Œè¿ç®—ä¾¿å¯ä»¥å®šä½åˆ°ç›®æ ‡MDS</li></ul></li><li>ç¼ºç‚¹<ul><li>ç”±äºæ”¾å¼ƒäº†ç³»ç»Ÿç›®å½•ç»“æ„çš„ç©ºé—´å±€éƒ¨æ€§ï¼Œåœ¨å¯¹å­ç›®å½•è¿›è¡Œéå†æ“ä½œï¼Œè¦æ¶‰åŠMDSä¸­å¤§é‡èŠ‚ç‚¹çš„å·¥ä½œ</li><li>å¯¹å­ç›®å½•è¿›è¡Œé‡å‘½åæ“ä½œå°†å¯¼è‡´å¤§é‡å…ƒæ•°æ®è¿ç§»ï¼›</li><li>å®¢æˆ·ç«¯ä¸Šçš„Cacheä¹Ÿå› ä¸ºä¸æ–­åˆ·æ–°è€Œé™ä½äº†å‘½ä¸­ç‡</li><li>é›†ç¾¤ä¸­åŠ å…¥æˆ–åˆ é™¤MDSèŠ‚ç‚¹æ—¶ï¼Œå¿…ç„¶éœ€è¦æ›´æ”¹å“ˆå¸Œå‡½æ•°ï¼Œå°†å¯¼è‡´MDSé›†ç¾¤ä¸­å…ƒæ•°æ®çš„é‡æ–°åˆ†é…ï¼Œå¤§é‡å…ƒæ•°æ®è¿ç§»ï¼Œå› æ­¤å…¶å¯æ‰©å±•æ€§èƒ½å¾ˆæœ‰é™</li></ul></li></ul></li><li>Lazy Hybrid<ul><li>é‡‡ç”¨æ–‡ä»¶çš„å…¨è·¯å¾„åè¿›è¡Œå“ˆå¸Œè¿ç®—ï¼Œè¿™æ ·<strong>ç›¸åŒè·¯å¾„ä¸‹çš„æ‰€æœ‰æ–‡ä»¶è¢«æ˜ å°„å­˜æ”¾åˆ°åŒä¸€MDSä¸Š</strong>ï¼Œè¿™äº›æ–‡ä»¶çš„<strong>å…ƒæ•°æ®è¿›ä¸€æ­¥é€šè¿‡å“ˆå¸Œåˆ†æ•£å¼€æ¥</strong>ï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªå…ƒæ•°æ®æŸ¥æ‰¾è¡¨ï¼ˆMetadata Look-up Tableï¼ŒMLTï¼‰æ¥è®°å½•åˆ†å¸ƒä¿¡æ¯</li><li>ä¼˜ç‚¹<ul><li>æ—¢ä¿ç•™äº†ä¸€å®šçš„ç›®å½•ç»“æ„ï¼Œåˆå……åˆ†åˆ†æ•£äº†çƒ­ç‚¹ç›®å½•ä¸‹çš„å…ƒæ•°æ®</li><li>é‡‡ç”¨äº†ä¸€ç§<strong>è®¿é—®æ§åˆ¶é“¾è¡¨</strong>æè¿°æ–‡ä»¶çš„å®‰å…¨æƒé™ï¼Œå°†ç›®å½•æƒé™çš„æ£€æŸ¥åˆç»“åˆæ–‡ä»¶çš„å…ƒæ•°æ®ä¸­ï¼Œä¸å¿…éå†æ–‡ä»¶è·¯å¾„çš„æ‰€æœ‰ç›®å½•å±‚æ¬¡æ‰èƒ½ç¡®å®šè¯¥æ–‡ä»¶çš„è®¿é—®æƒé™</li><li>å°†å…ƒæ•°æ®çš„æ›´æ–°æ“ä½œæš‚å­˜å»¶è¿Ÿåˆ°è¯¥å…ƒæ•°æ®å†æ¬¡è®¿é—®çš„æ—¶å€™è¿›è¡Œï¼Œåˆ†æ•£MDSçš„æ›´æ–°è´Ÿæ‹…</li></ul></li><li>ç¼ºç‚¹<ul><li>ä¸é™æ€å“ˆå¸Œç±»ä¼¼</li></ul></li></ul></li><li>åŠ¨æ€ç›®å½•å­æ ‘åˆ†å‰²<ul><li>å°†å…¨å±€ç›®å½•åˆ’åˆ†ä¸ºè‹¥å¹²ç›®å½•å­æ ‘ï¼Œåˆ†å¸ƒå­˜å‚¨åœ¨MDSé›†ç¾¤å„èŠ‚ç‚¹ä¸Šï¼Œå½“ç³»ç»Ÿä¸­å‡ºç°çƒ­ç‚¹å­ç›®å½•æˆ–ç›®å½•å­æ ‘è¿‡äºåºå¤§æ—¶ï¼Œåˆ™é‡‡ç”¨å“ˆå¸Œçš„æ–¹æ³•å°†è¯¥å­ç›®å½•ä¸‹çš„æ‰€æœ‰<strong>å…ƒæ•°æ®åˆ†é…åˆ°é›†ç¾¤å…¶ä»–MDSèŠ‚ç‚¹ä¸Š</strong>ã€‚</li><li>ä¼˜ç‚¹<ul><li>æœ€å¤§ç¨‹åº¦ä¿ç•™ç›®å½•ç»“æ„ï¼Œä»¥ä¾¿å……åˆ†åˆ©ç”¨æ–‡ä»¶çš„ç©ºé—´å±€éƒ¨æ€§</li><li>åŠ¨æ€çš„è¿›è¡Œå…ƒæ•°æ®è¿ç§»ï¼Œè°ƒæ•´é›†ç¾¤è´Ÿè½½</li></ul></li><li>ç¼ºç‚¹<ul><li>åœ¨æ–‡ä»¶è®¿é—®è´Ÿè½½ä¸æ–­å˜åŒ–çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•èƒ½ä½¿ç³»ç»Ÿæ ¹æ®è´Ÿè½½æƒ…å†µè‡ªé€‚åº”è°ƒæ•´å…ƒæ•°æ®åˆ†å¸ƒï¼Œæ˜¯ä¸€ä¸ªå®ç°éš¾é¢˜</li></ul></li></ul></li><li>åŠ¨æ€å“ˆå¸Œ<ul><li>æä¾›äº†ç›¸å¯¹è´Ÿè½½å‡è¡¡ã€å¼¹æ€§æ›´æ–°ç­–ç•¥å’Œå…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ä¸‰ç§ç­–ç•¥ï¼Œé€šè¿‡MDSä¹‹é—´çš„æ£€æµ‹ï¼Œå°†é«˜è´Ÿè½½MDSä¸­çš„éƒ¨åˆ†å…ƒæ•°æ®å‘ä½è´Ÿè½½MDSè¿ç§»</li><li>å½“éœ€æ·»åŠ æˆ–ç§»å‡ºMDSæ—¶<ul><li>é‡‡ç”¨å¼¹æ€§æ›´æ–°ç­–ç•¥è¿›è¡Œè´Ÿè½½è°ƒåº¦</li><li>å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†åˆ©ç”¨ç¼“å­˜å‘ç°çƒ­ç‚¹å¹¶åˆ¶ä½œå‰¯æœ¬</li><li>åˆ†æ‹…å…ƒæ•°æ®è®¿é—®è´Ÿè½½</li></ul></li></ul></li><li>HBA<ul><li>è®¾è®¡æ€æƒ³æ˜¯åœ¨æ¯ä¸ªMDSä¸Šå»ºç«‹ä¸¤çº§å¸ƒéš†è¿‡æ»¤å™¨é˜µåˆ—ï¼ˆBloom-filter arraysï¼‰ï¼Œç¬¬ä¸€çº§æ˜¯<strong>LRU Bloom-filter</strong>ï¼Œç”¨æ¥è®°å½•æœ¬åœ°MDSè®¿é—®æœ€é¢‘ç¹çš„æ–‡ä»¶ï¼Œä½“ç§¯å°ä½†æŸ¥æ‰¾å¿«ï¼›ç¬¬äºŒçº§Bloom-filterç”¨æ¥<strong>è®°å½•æœ¬åœ°MDSå­˜å‚¨çš„æ‰€æœ‰æ–‡ä»¶</strong>ï¼Œä½“ç§¯å¤§ä½†æŸ¥æ‰¾æ…¢ã€‚</li><li>åŒæ—¶ï¼Œæ¯å°MDSè¿˜ä¿å­˜äº†é›†ç¾¤ä¸­<strong>å…¶ä»–MDSèŠ‚ç‚¹çš„ä¸¤çº§Bloom-filter</strong>ï¼Œæ„æˆäº†ä¸¤çº§è®°å½•å…¨å±€æ–‡ä»¶åˆ†å¸ƒä¿¡æ¯çš„Bloom-filteré˜µåˆ—</li><li>å½“LRUè¡¨å‘ç”Ÿæº¢å‡ºæ—¶ï¼ŒLRUæ›¿æ¢ç­–ç•¥å°†ä¼šåœ¨ç›¸åº”LRU BFä¸­è§¦å‘ä¸€ä¸ªå¢åˆ æ“ä½œã€‚</li><li>å½“LRU BFçš„æ”¹å˜è¶…è¿‡ä¸€ä¸ªé˜ˆå€¼æ—¶ï¼Œè¯¥å…ƒæ•°æ®æœåŠ¡å™¨å°†ä¼šå‘å…¶ä»–æ‰€æœ‰å…ƒæ•°æ®æœåŠ¡å™¨å¹¿æ’­æ–°çš„LRU BFæ¥æ›´æ–°å®ƒåœ¨å…¶ä»–æœåŠ¡å™¨çš„å‰¯æœ¬</li><li>ä¼˜ç‚¹<ul><li>HBAç­–ç•¥ä¸å…³å¿ƒå…ƒæ•°æ®çš„å…·ä½“åˆ†é…æ–¹å¼ï¼Œè€Œæ˜¯é€šè¿‡å°†å®¢æˆ·è¯·æ±‚è¿›è¡Œä¸¤çº§Bloom-filteré˜µåˆ—æŸ¥æ‰¾å¿«é€Ÿå®šå‘åˆ°å­˜å‚¨è¯¥è¯·æ±‚æ–‡ä»¶å…ƒæ•°æ®çš„MDSä¸Šï¼Œæé«˜äº†è®¿é—®é€Ÿåº¦</li></ul></li><li>ç¼ºç‚¹<ul><li>ä¸å‘½ä¸­å¸¦åœ¨çš„è¯·æ±‚å¹¿æ’­ä¼šå¢åŠ ç³»ç»Ÿé¢å¤–è´Ÿæ‹…</li></ul></li></ul></li><li>G-HBA<ul><li>å¼•å…¥äº†åˆ†ç»„çš„æ¦‚å¿µï¼Œå°†MDSé›†ç¾¤æ ¹æ®ç‰©ç†ä½ç½®ç­‰å› ç´ åˆ†æˆè‹¥å¹²å°ç»„ï¼Œæ¯ä¸ªå°ç»„ç»´æŒç€ä¸€ä¸ªå…¨å±€çš„ä¸¤çº§Bloom-filteré˜µåˆ—ï¼Œåˆ†å¸ƒçš„å­˜å‚¨åœ¨å„MDSèŠ‚ç‚¹ä¸Š</li><li>ä¼˜ç‚¹<ul><li>å®¢æˆ·è¯·æ±‚åˆ°æ¥æ—¶ï¼ŒMDSé¦–å…ˆæŸ¥è¯¢æœ¬åœ°çš„éƒ¨åˆ†Bloom-filteré˜µåˆ—ï¼Œå‘½ä¸­åˆ™ç›´æ¥å°†è¯·æ±‚é‡å®šå‘ï¼Œå¦åˆ™é¦–å…ˆåœ¨ç»„å†…ç»„æ’­æŸ¥è¯¢ï¼Œè‹¥å†ä¸å‘½ä¸­åˆ™åœ¨ç»„å¤–å¹¿æ’­ã€‚è¿™æ ·çš„è®¾è®¡<strong>æ˜¾è‘—å‡å°‘äº†HBAç³»ç»Ÿä¸­å®¢æˆ·è¯·æ±‚å¹¿æ’­å¸¦æ¥çš„ç½‘ç»œè´Ÿè½½</strong></li></ul></li></ul></li></ul><p>å…ƒæ•°æ®ç®¡ç†æ–¹å¼å¯¹æ¯”</p><ul><li><em>é™æ€ç›®å½•å­æ ‘åˆ†å‰²</em>ä¸<em>é™æ€å“ˆå¸Œ</em>æ˜¯æœ€<strong>åŸºæœ¬</strong>çš„å…ƒæ•°æ®åˆ†é…ç­–ç•¥ï¼Œç®¡ç†ç®€å•è€Œæ˜“äºå®æ–½ï¼Œä½†åœ¨ç›®å½•ç»“æ„æˆ–åç§°å‘ç”Ÿå˜åŒ–æ—¶ä¼šå¯¼è‡´å¤§é‡å…ƒæ•°æ®è¿ç§»ï¼ŒMDSé›†ç¾¤èŠ‚ç‚¹çš„åŠ å…¥ä¸åˆ é™¤ä¹Ÿä¼šå¯¼è‡´å…ƒæ•°æ®çš„é‡æ–°åˆ†é…ï¼Œå› æ­¤å¯æ‰©å±•æ€§è¾ƒå·®ã€‚</li><li>HBAä¸G-HBAåˆ™ä¸ºå…ƒæ•°æ®ç®¡ç†å‘å±•äº†ä¸€ç§æ–°çš„è®¾è®¡æ€è·¯ï¼Œæ—¢åœ¨åŸæœ‰å…ƒæ•°æ®åˆ†é…ç­–ç•¥çš„åŸºç¡€ä¸Šå»ºç«‹ä¸€ä¸ªé€»è¾‘å±‚ï¼Œå……åˆ†åˆ©ç”¨å®¢æˆ·è®¿é—®çš„æ—¶é—´å±€éƒ¨æ€§ï¼Œç»“åˆBloom-filterç»“æ„çš„é«˜é€ŸæŸ¥è¯¢ï¼Œä½¿å®¢æˆ·è¯·æ±‚èƒ½å¤Ÿå¿«é€Ÿå®šä½ï¼Œ<strong>æ˜¾è‘—çš„åˆ†æ‹…äº†MDSçš„å·¥ä½œè´Ÿè½½ï¼Œæé«˜äº†MDSé›†ç¾¤çš„æ•´ä½“æ€§èƒ½</strong>ã€‚</li><li>LHç­–ç•¥ã€åŠ¨æ€ç›®å½•å­æ ‘åˆ†å‰²ä¸åŠ¨æ€å“ˆå¸Œåœ¨å‰ä¸¤ç§åŸºæœ¬ç­–ç•¥åŸºç¡€ä¸Šè¿›è¡Œäº†æ”¹è¿›ï¼Œé€šè¿‡ä½¿ç”¨å»¶è¿Ÿæ›´æ–°ç­–ç•¥ã€å…ƒæ•°æ®æŸ¥æ‰¾è¡¨ã€è´Ÿè½½åŠ¨æ€è°ƒæ•´ç­‰æ–¹æ³•ï¼Œä½¿å…ƒæ•°æ®ç®¡ç†è·å¾—æ›´æœ‰æ•ˆçš„ç®¡ç†ï¼Œä½†æ˜¯ä¹Ÿä¸å¯é¿å…çš„<strong>ç»§æ‰¿äº†</strong>é™æ€ç›®å½•å­æ ‘åˆ†å‰²ä¸é™æ€å“ˆå¸Œçš„<strong>ç¼ºç‚¹</strong>ã€‚</li></ul><p>Bloom Filter</p><p>è¯¯åˆ¤ç‡ä¸ºï¼š <span class="math display">\[f = (1- (1-\frac{1}{m})^{nk})^k = (1-e^{-\frac{kn}{m}})^k = (1-p)^k\]</span> æœ€ä¼˜çš„å“ˆå¸Œå‡½æ•°ä¸ªæ•° <span class="math display">\[g = \ln f = k\ln(1-e^{-\frac{kn}{m}})\]</span></p><p><span class="math display">\[\frac{\partial g}{\partial k} = \ln(1-e^{-\frac{kn}{m}}) + \frac{kn}{m}\frac{e^{-\frac{kn}{m}}}{1-e^{-\frac{kn}{m}}} = \ln(1-p) + \frac{kn}{m}\frac{p}{1-p}\]</span></p><p>ä»¤<span class="math inline">\(\frac{\partial g}{\partial k} = 0\)</span>ï¼Œè§£å¾—ï¼š<span class="math inline">\(k = \frac{m}{n}\ln2\)</span> <span class="math display">\[f_{min} = (1-e^{-\ln2})^{\frac{m}{n}\ln2} = (\frac{1}{2})^{\frac{m}{n}\ln2} = (0.6185)^{\frac{m}{n}}\]</span> åº”ç”¨</p><ul><li>å­—å…¸å­˜å‚¨</li><li>æ•°æ®åº“</li><li>åˆ†å¸ƒå¼ç¼“å­˜</li><li>P2P/Overlayç½‘ç»œåº”ç”¨</li></ul><h2><span id="é‡å¤æ•°æ®åˆ é™¤">é‡å¤æ•°æ®åˆ é™¤</span></h2><p><strong>ä¸ºä»€ä¹ˆé‡å¤æ•°æ®åˆ é™¤ï¼Ÿ</strong></p><ul><li>é«˜æ•ˆåœ°èŠ‚çº¦å­˜å‚¨ç©ºé—´ï¼Œæ•°æ®ä¿å­˜æ—¶é—´æ›´é•¿ï¼Œæˆ–è€…å¤‡ä»½æ›´å¤š</li><li>å‡å°‘ç½‘ç»œä¸­æ•°æ®çš„ä¼ è¾“é‡ï¼Œä¹Ÿå¯ä»¥æé«˜å¤‡ä»½æ¢å¤çš„æ€§èƒ½</li><li>å¹¿åŸŸç½‘ç¯å¢ƒï¼Œå‡å°‘æ•°æ®ä¼ è¾“é‡çš„æ„ä¹‰å°±æ›´åŠ æ˜æ˜¾ï¼Œå¯ä»¥æ›´å®¹æ˜“åœ°å®ç°è¿œç¨‹å¤‡ä»½æˆ–å®¹ç¾</li><li>å¸®åŠ©ç”¨æˆ·èŠ‚çº¦æ—¶é—´å’Œæˆæœ¬<ul><li>æ•°æ®çš„æ¢å¤é€Ÿåº¦æ›´å¿«</li><li>éšç€å¤‡ä»½å­˜å‚¨è®¾å¤‡çš„å‡å°‘ï¼Œç©ºé—´ã€ç”µåŠ›ã€æ•£çƒ­çš„æˆæœ¬æ¶ˆè€—ä¹Ÿåœ¨é™ä½</li></ul></li></ul><p><strong>é‡åˆ æµç¨‹</strong></p><ul><li>æ–‡ä»¶æ•°æ®æµåˆ†å—ã€‚</li><li>æ•°æ®å—å“ˆå¸ŒæŒ‡çº¹ã€‚</li><li>æŒ‡çº¹æŸ¥æ‰¾ã€‚</li><li>æ•°æ®å­˜å‚¨</li></ul><p><img src="/images/ç‰©è”ç½‘å­˜å‚¨æŠ€æœ¯/é‡åˆ æµç¨‹å›¾.png"></p><p><strong>åº”ç”¨</strong></p><ul><li>å¤‡ä»½å’Œå½’æ¡£ç³»ç»Ÿã€‚</li><li>ä¸»å­˜å‚¨æ–‡ä»¶ç³»ç»Ÿã€‚</li><li>å†…å­˜çš„ç¼“å­˜è®¾è®¡ã€‚</li><li>è™šæ‹Ÿæœºå­˜å‚¨ä¼˜åŒ–ã€‚</li></ul><p><strong>é‡å¤æ•°æ®åˆ é™¤çš„ç²’åº¦</strong></p><ul><li>æ–‡ä»¶çº§<ul><li>é€šè¿‡æ£€æŸ¥æ–‡ä»¶çš„å±æ€§æ¥ç¡®å®šé‡å¤æ–‡ä»¶ã€‚</li><li>è¿™ç§æ–¹æ³•å»é‡çš„<strong>æ•ˆæœä¸å¦‚</strong>å…¶ä»–ç²’åº¦çº§åˆ«</li><li>ä½†æ˜¯<strong>æŠ€æœ¯æ¯”è¾ƒç®€å•ï¼Œè€Œä¸”é€Ÿåº¦å¿«</strong>ã€‚</li></ul></li><li>æ•°æ®å—çº§<ul><li>å®šé•¿åˆ†å—</li><li>å˜é•¿åˆ†å—</li><li>å°†æ•°æ®åˆ‡åˆ†æˆå¤§å°ç›¸åŒçš„å—ã€‚æ¯ä¸ªå—éƒ½è¢«èµ‹äºˆä¸€ä¸ªâ€œæŒ‡çº¹â€ï¼Œé€šè¿‡â€œæŒ‡çº¹â€ä¸æ•°æ®ç´¢å¼•ï¼ˆæŒ‡çº¹åº“ï¼‰çš„æ¯”è¾ƒåˆ¤æ–­æ˜¯å¦ä¸ºé‡å¤æ•°æ®ã€‚</li><li>å¦‚æœå—åˆ†å‰²çš„è¶Šå°ï¼Œå—æ•°é‡ç›¸åº”å°±è¶Šå¤šï¼Œç´¢å¼•ä¹Ÿå°±è¶Šå¤šã€‚ï¼ˆäº§ç”Ÿè¾ƒé«˜çš„æ•°æ®å»é‡æ¯”ç‡ï¼‰ã€‚</li><li>ä¸è¿‡ï¼Œæˆ‘ä»¬è¿˜è¦è¯„ä¼°ä¸€ä¸ªé‡è¦çš„æŒ‡æ ‡â€”å°±æ˜¯<strong>I/Oçš„å‹åŠ›</strong>ï¼Œå®ƒ<strong>ä¸æ•°æ®æ¯”è¾ƒçš„é¢‘åº¦æˆæ­£æ¯”</strong>ï¼ŒåŠ ä¹‹æ•°æ®å—è¶Šå°ç´¢å¼•å°±è¶Šå¤§ï¼Œè¿™å¯èƒ½å¯¼è‡´å¤‡ä»½æ€§èƒ½çš„ä¸‹é™ã€‚</li></ul></li><li>å­—èŠ‚çº§<ul><li>é€šè¿‡åœ¨æ–°æ—§æ–‡ä»¶ä¹‹é—´è¿›è¡Œé€ä¸ªå­—èŠ‚çš„æ¯”è¾ƒå®ç°çš„ã€‚</li><li>å¯¹æ€§èƒ½çš„å½±å“å´éå¸¸å¤§ã€‚</li></ul></li><li>ç²’åº¦è¶Šå°ï¼Œé‡å¤æ•°æ®åˆ é™¤æ‰€å¸¦æ¥çš„å…ƒæ•°æ®è¶Šå¤š</li></ul><p><strong>é‡å¤æ•°æ®åˆ é™¤æ—¶é—´</strong></p><ul><li><strong>åœ¨çº¿</strong>æœºåˆ¶æ˜¯æŒ‡åœ¨<strong>æ•°æ®åˆ°è¾¾å­˜å‚¨è®¾å¤‡ä¹‹å‰</strong>å¯¹ç›¸åŒçš„æ•°æ®è¿›è¡Œåˆ é™¤ï¼Œå­˜å‚¨è®¾å¤‡ä¸Šä»…å­˜å‚¨å”¯ä¸€çš„ä¸é‡å¤çš„æ•°æ®ã€‚</li><li><strong>ç¦»çº¿</strong>çš„å®ç°æœºåˆ¶æ˜¯äº‹å…ˆé‡‡ç”¨ä¸€ä¸ªç£ç›˜ç¼“å†²åŒºï¼Œ<strong>å…ˆ</strong>å°†æ‰€æœ‰åˆ°è¾¾çš„æ•°æ®<strong>ç¼“æš‚å­˜</strong>åˆ°ä¸€ä¸ªç£ç›˜ç¼“å†²åŒºä¸­ï¼Œç­‰æ‰€æœ‰çš„æ•°æ®å…¨éƒ¨å†™å®Œä¹‹åï¼Œ<strong>åœ¨ç³»ç»Ÿç©ºé—²çš„æ—¶åˆ»</strong>ï¼Œå°†ç£ç›˜ç¼“å†²åŒºçš„æ•°æ®é‡æ–°è¯»å–å‡ºæ¥å†<strong>æŸ¥æ‰¾å’Œåˆ é™¤å…¶é‡å¤çš„æ•°æ®</strong>ã€‚</li></ul><p><strong>é‡å¤æ•°æ®åˆ é™¤ä½ç½®</strong></p><p>æ•°æ®çš„ä¼ è¾“å’Œå­˜å‚¨åˆ†ä¸ºä¸¤ç«¯ï¼Œä¸€ä¸ªä¸ºæ•°æ®çš„å‘é€æ–¹ï¼Œå³æºç«¯ï¼›å¦ä¸€ä¸ªä¸ºæ•°æ®çš„æ¥æ”¶æ–¹å’Œå­˜å‚¨æ–¹ï¼Œå³ç›®æ ‡ç«¯ã€‚</p><ul><li>æºç«¯é‡å¤æ•°æ®åˆ é™¤ã€‚<ul><li><strong>åœ¨æ•°æ®å¼€å§‹ä¼ é€ä¹‹å‰</strong>ï¼Œåœ¨æºç«¯å°†é‡å¤çš„æ•°æ®è¿›è¡Œåˆ é™¤ï¼Œå³é‡å¤çš„æ•°æ®ä¸éœ€è¦è¿›è¡Œä¼ è¾“å’Œå­˜å‚¨ã€‚</li></ul></li><li>ç›®æ ‡ç«¯é‡å¤æ•°æ®åˆ é™¤ã€‚<ul><li><strong>åœ¨ç›®æ ‡ç«¯çš„å­˜å‚¨è®¾å¤‡</strong>ä¸Šåˆ é™¤é‡å¤çš„æ•°æ®ã€‚åœ¨è¿™ç§å®ç°æœºåˆ¶ä¸‹ï¼Œé‡å¤æ•°æ®åˆ é™¤æ‰€å¸¦æ¥çš„å®ç°å¼€é”€å…¨éƒ¨é›†ä¸­åœ¨ç›®æ ‡ç«¯ï¼Œæºç«¯ä¸éœ€è¦åšä»»ä½•çš„æœ‰å…³äºé‡å¤æ•°æ®åˆ é™¤çš„æ“ä½œã€‚</li></ul></li></ul><p><strong>å˜é•¿åˆ†å—åˆ†å—ç®—æ³•</strong></p><ul><li>åŸºäºå†…å®¹çš„åˆ†å—ç®—æ³•</li><li>Rabin æŒ‡çº¹åˆ†å—ç®—æ³•</li><li>Hashç®—æ³•<ul><li>MDè¡¨ç¤ºæ¶ˆæ¯æ‘˜è¦(Message Digestï¼Œç®€è®°ä¸ºMD)ï¼ŒMD5ä»¥512æ¯”ç‰¹ä¸€å—çš„æ–¹å¼å¤„ç†è¾“å…¥çš„æ¶ˆæ¯æ–‡æœ¬ï¼Œæ¯ä¸ªå—åˆåˆ’åˆ†ä¸º16ä¸ª32æ¯”ç‰¹çš„å­å—ã€‚ç®—æ³•çš„è¾“å‡ºæ˜¯ç”±4ä¸ª32æ¯”ç‰¹çš„å—ç»„æˆï¼Œå°†å®ƒä»¬çº§è”æˆä¸€ä¸ª128æ¯”ç‰¹çš„æ‘˜è¦å€¼ã€‚</li><li>é‡å¤åˆ é™¤æŠ€æœ¯é€šå¸¸é‡‡ç”¨MD-5 (a 128 å­—èŠ‚çš„æ•£åˆ—) æˆ– SHA-1 (a 160å­—èŠ‚çš„æ•£åˆ—) ç®—æ³•</li><li>å‘ç”Ÿæ•£åˆ—å†²çªçš„æ¦‚ç‡å°äºè¡Œæ˜Ÿç¢°æ’åœ°çƒ</li><li>hashç¢°æ’å¹¶ä¸æ„å‘³ç€æ•°æ®ä¼šå…¨éƒ¨ä¸¢å¤±ã€‚æ•°æ®è¢«é”™è¯¯è¯†åˆ«çš„è¿™ä¸ªæ–‡ä»¶ä¼šè¢«ç ´åã€‚æ‰€æœ‰å…¶å®ƒçš„æ•°æ®ä¼šè¢«æ­£ç¡®åœ°æ¢å¤ã€‚</li></ul></li></ul><p><strong>é—®é¢˜ä¸æŒ‘æˆ˜</strong></p><ul><li>å¯æ‰©å±•æ€§</li><li>ååç‡</li><li>å†…å­˜å¼€é”€</li><li>æ¢å¤æ€§èƒ½</li></ul><p><strong>æ€»ç»“</strong></p><ul><li>é‡åˆ åˆ†å—ç®—æ³•<ul><li>å®šé•¿&amp;å˜é•¿</li><li>åˆ†å—å¤§å°</li></ul></li><li>å“ˆå¸ŒæŒ‡çº¹ç®—æ³•<ul><li>SHA-1ã€MD5</li><li>å†™ååç‡</li><li>æ–‡ä»¶å¤§å°</li><li>å“ˆå¸Œç®—æ³•</li></ul></li><li>è¯»æ€§èƒ½<ul><li>æ–‡ä»¶ç¢ç‰‡</li></ul></li><li>åˆ†å—ç®—æ³•ï¼Œä»ç„¶ç»§ç»­ã€‚</li><li>å“ˆå¸Œæ‘˜è¦ï¼Œå·²ç»æˆç†Ÿã€‚</li><li>æŒ‡çº¹æŸ¥æ‰¾ï¼Œä¾æ—§æŒ‘æˆ˜ã€‚</li><li>æ•°æ®è¯»å–ï¼Œæ½œåœ¨é—®é¢˜ã€‚</li></ul><h2><span id="å›ºæ€å­˜å‚¨æŠ€æœ¯">å›ºæ€å­˜å‚¨æŠ€æœ¯</span></h2><p><strong>åŠå¯¼ä½“å­˜å‚¨è®¾å¤‡</strong></p><ul><li>é—ªå­˜ï¼ˆFlashï¼‰<ul><li>ç”µå®¹æ€§</li></ul></li><li>ç›¸å˜å­˜å‚¨å™¨ï¼ˆPCMï¼‰<ul><li>ç”µé˜»æ€§</li></ul></li></ul><p><strong>SSDä¼˜åŠ¿</strong></p><ul><li>SSDæ²¡æœ‰æœºæ¢°éƒ¨ä»¶ï¼ŒæŠ—éœ‡åŠ¨</li><li>SSDä¸éœ€è¦é©¬è¾¾ï¼Œä½èƒ½è€—</li><li>SSDé«˜æ€§èƒ½</li><li>SSDä»·æ ¼åœ¨ä¸æ–­ä¸‹é™</li></ul><p><strong>å›ºæ€å­˜å‚¨ç›¸å…³æŠ€æœ¯</strong></p><ul><li>SSDï¼šSolid State Disk å›ºæ€ç›˜<ul><li>åŸºæœ¬å­˜å‚¨ä»‹è´¨æ˜¯NAND FLASH</li><li>ç”±ä¸€ä¸ªåµŒå…¥å¼æ§åˆ¶å™¨æ§åˆ¶NAND FLASHçš„æ“ä½œ</li><li>RAMä½œä¸ºbuffer</li><li>é€šè¿‡IDE,SATA,PCI-eç­‰æ€»çº¿å¯¹å¤–æä¾›å—æ¥å£</li><li>è¯»è¯·æ±‚ï¼šå—çº§æ¥å£</li><li>å†™è¯·æ±‚ï¼šæ‰‡åŒºä¸ºå•ä½</li><li>å…ˆæ“¦åå†™</li><li>ä¸»è¦æ¨¡å—<ul><li>æ•°æ®ç¼“å­˜ç®¡ç†æ¨¡å—<ul><li>å¥½çš„bufferç­–ç•¥èƒ½å¤Ÿæé«˜SSDçš„æ•´ä½“æ€§èƒ½</li></ul></li><li>é—ªå­˜ç¿»è¯‘å±‚æ¨¡å— FTL (Flash Translation Layer)<ul><li>Address Mapping (åœ°å€æ˜ å°„)<ul><li>&lt;lsn, size&gt; -&gt; &lt;packageï¼Œdieï¼Œplaneï¼Œblockï¼Œpage&gt;</li><li>é¡µçº§æ˜ å°„ï¼ˆå¥½ï¼Œé•¿ï¼Œå¤§ï¼Œå¤§ï¼Œé«˜ï¼‰</li><li>å—çº§æ˜ å°„ï¼ˆå·®ï¼ŒçŸ­ï¼Œå°ï¼Œå°ï¼Œä½ï¼‰</li><li>æ··åˆæ˜ å°„ï¼ˆè¾ƒå·®....ï¼‰</li></ul></li><li>Wear leveling (æŸè€—å¹³è¡¡)<ul><li>åŠ¨æ€æŸè€—å¹³è¡¡<ul><li>åœ¨è¯·æ±‚åˆ°è¾¾æ—¶ï¼Œé€‰å–æ“¦é™¤æ¬¡æ•°è¾ƒå°‘çš„å—ä½œä¸ºè¯·æ±‚çš„ç‰©ç†åœ°å€ã€‚</li></ul></li><li>é™æ€æŸè€—å¹³è¡¡<ul><li>å°†å†·æ•°æ®ä»åŸå—å–å‡ºï¼Œå­˜æ”¾åœ¨æ“¦é™¤æ¬¡æ•°è¿‡å¤šçš„å—ï¼ŒåŸæ¥å­˜æ”¾å†·æ•°æ®çš„å—è¢«é‡Šæ”¾å‡ºæ¥ï¼Œæ¥å—çƒ­æ•°æ®çš„æ“¦å†™ã€‚</li></ul></li></ul></li><li>Garbage collection (åƒåœ¾å›æ”¶)<ul><li>SSDåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œä¼šäº§ç”Ÿå¤§é‡å¤±æ•ˆé¡µï¼Œåœ¨SSDçš„å®¹é‡åˆ°è¾¾ä¸€å®šé˜ˆå€¼æ—¶ï¼Œéœ€è¦è°ƒç”¨GCå‡½æ•°ï¼Œæ¸…é™¤æ‰€æœ‰å¤±æ•ˆé¡µï¼Œä»¥å¢åŠ å¯ç”¨ç©ºé—´</li></ul></li></ul></li></ul></li></ul></li><li>SCMï¼šStorage-Class Memory å­˜å‚¨çº§å†…å­˜<ul><li>éæ˜“å¤±</li><li>é›¶æˆ–ä½ç©ºé—²èƒ½è€—</li><li>ç±»ä¼¼ç£ç›˜ä¸€æ ·çš„å®¹é‡</li><li>æ¥è¿‘DRAMçš„å­˜å–å»¶è¿Ÿ</li><li>å­—èŠ‚çº§ç¼–å€</li><li>é›†æˆSCMçš„ç­–ç•¥<ul><li>ç¼“å­˜ç­–ç•¥</li><li>å­˜å‚¨æ›¿ä»£ç­–ç•¥</li><li>å†…å­˜æ›¿ä»£æ··åˆç­–ç•¥</li><li>å•çº§å­˜å‚¨ç­–ç•¥</li></ul></li></ul></li></ul><p><strong>SSDçš„æ¥å£æ ‡å‡†</strong></p><ul><li>ç›®å‰ï¼šIDEå’ŒSATA</li><li>å°†æ¥ï¼šPCI-E</li></ul><p><strong>æ€§èƒ½æ ‡å‡†</strong></p><ul><li>æµ‹è¯•å‰æ<ul><li>è¯»å†™æ¯”ä¾‹ï¼ˆR/Wï¼š75/25, 50/50ï¼‰</li><li>è¯·æ±‚å—å¤§å°ï¼ˆ2KBã€128KBï¼‰</li><li>æµ‹è¯•è¿‡ç¨‹ä¸­æ˜¯å¦è°ƒç”¨è¿‡GCæ“ä½œ</li><li>ä¿ç•™ç©ºé—´æ˜¯å¤šå°‘ï¼ˆ20%ï¼‰</li></ul></li></ul><p>èƒ½è€—</p><ul><li>äº§å“æ ‡ç§°ä¸Šçš„åŠŸç‡ä¸ä¸€å®šèƒ½å¤Ÿåæ˜ SSDçœŸå®çš„èƒ½è€—ã€‚<strong>å› ä¸ºä¸åŒçš„SSDçš„å†…éƒ¨ç»“æ„å¯èƒ½æœ‰æ‰€å·®åˆ«ï¼Œè€Œä¸”æ™ºèƒ½çš„åŠŸè€—ç®¡ç†ç³»ç»Ÿåœ¨SSDå®é™…è¿è¡Œæ—¶ä¼šå¯¹èƒ½è€—æœ‰å½±å“ã€‚</strong></li><li>å› æ­¤ï¼Œèƒ½åæ˜ èƒ½è€—çš„æŒ‡æ ‡æ˜¯ï¼š<strong>å®Œæˆç›¸åŒçš„IOè®¿é—®è¯·æ±‚ï¼Œæ‰€æ¶ˆè€—çš„æ€»èƒ½é‡</strong>ï¼Œæˆ–è€…æ˜¯<strong>å•ä½èƒ½è€—æ‰€èƒ½å®Œæˆçš„IOè®¿é—®æ•°</strong>ã€‚</li></ul><p><strong>è‡ªé€‚åº”çš„åŠ¨æ€ç¼“å­˜ç®¡ç†ç®—æ³•</strong></p><ul><li>æ ¸å¿ƒæ€æƒ³ï¼šåˆ©ç”¨ä¸¤æ¬¡çªå‘æ€§è¯·æ±‚å‘¨æœŸé—´çš„ç›¸å¯¹ç©ºé—²æ—¶é—´æ®µï¼Œä»¥åŠå›ºæ€ç›˜å†…çš„ç©ºé—²èµ„æºï¼Œæå‰å†™å›å›ºæ€ç›˜ç¼“å­˜ä¸­çš„éƒ¨åˆ†æ•°æ®ã€‚</li><li>æå‰å†™å›çš„ä¼˜åŠ¿åœ¨äºï¼šå½“åç»­å†™è¯·æ±‚æ²¡æœ‰å‘½ä¸­ç¼“å­˜æ—¶ï¼Œå¯å°†ä¹‹å‰æå‰å†™å›çš„æ•°æ®ç›´æ¥åˆ é™¤ï¼Œè…¾å‡ºç©ºé—´åï¼Œå°†è¯¥å†™è¯·æ±‚çš„æ•°æ®ç›´æ¥ä¿å­˜åœ¨ç¼“å­˜ä¸­ï¼Œé¿å…äº†å®æ—¶çš„ç¼“å­˜æ•°æ®å†™å›é—ªå­˜å¯¼è‡´è¿™ä¸ªå†™è¯·æ±‚çš„å»¶æ—¶ã€‚</li><li>ç»„æˆ<ol type="1"><li>åŠ¨æ€é˜ˆå€¼è°ƒæ•´ç®—æ³•</li><li>åŠ¨æ€å†…å­˜åˆ†åŒºè°ƒæ•´ç®—æ³•</li></ol></li></ul><h2><span id="æº¯æºæ•°æ®çš„é«˜æ•ˆå­˜å‚¨ç®¡ç†åŠåº”ç”¨">æº¯æºæ•°æ®çš„é«˜æ•ˆå­˜å‚¨ç®¡ç†åŠåº”ç”¨</span></h2><p><strong>æº¯æºçš„æ¦‚å¿µåŠç ”ç©¶çš„æ„ä¹‰</strong></p><ul><li>åœ¨ç³»ç»Ÿé¢†åŸŸï¼Œä¸€ä¸ªæ•°æ®çš„æº¯æºæ˜¯<strong>æ‰€æœ‰å½±å“è¿™ä¸ªæ•°æ®æœ€ç»ˆçŠ¶æ€çš„è¿›ç¨‹å’Œæ•°æ®</strong></li><li>æº¯æºæ­ç¤ºäº†æ•°æ®å¯¹è±¡çš„è¿‡å»æˆ–äº§ç”Ÿè¿‡ç¨‹ï¼Œä½¿å¾—äººä»¬å¯¹å¤æ‚çš„æµ·é‡æ•°æ®æœ¬èº«çš„åˆ†æå’Œç†è§£æ›´åŠ é€å½»</li></ul><p><strong>æº¯æºæ•°æ®çš„å­˜å‚¨</strong></p><p>è¯¥æº¯æºå›¾ä¿¡æ¯å¯ç”¨Key-Valueæ•°æ®åº“ï¼ˆä¾‹å¦‚BerkeleyDBæˆ–Redisï¼‰ï¼Œæˆ–é‡‡ç”¨å›¾æ•°æ®åº“ï¼ˆä¾‹å¦‚Neo4jï¼‰è¿›è¡Œå­˜å‚¨ã€‚</p><table><thead><tr class="header"><th style="text-align: center;">æ•°æ®åº“åç§°</th><th style="text-align: center;">æ•°æ®è¡¨è®°å½•</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">ProvenanceDB</td><td style="text-align: center;">&lt;pnodeå·ï¼Œå±æ€§ä¿¡æ¯&gt;</td></tr><tr class="even"><td style="text-align: center;">NameDB</td><td style="text-align: center;">&lt;Nameï¼Œpnodeå·&gt;</td></tr><tr class="odd"><td style="text-align: center;">ParentDB</td><td style="text-align: center;">&lt;å­pnodeå·ï¼Œçˆ¶pnodeå·ï¼Œtime&gt;</td></tr><tr class="even"><td style="text-align: center;">ChildDB</td><td style="text-align: center;">&lt;çˆ¶pnodeå·ï¼Œå­pnodeå·ï¼Œtime&gt;</td></tr></tbody></table><p><strong>æº¯æºçš„ä¸»è¦åº”ç”¨é¢†åŸŸ</strong></p><ul><li>ç›‘æ§åŠ å·¥ç¯èŠ‚</li><li>é‡ç°å®éªŒç»“æœ</li><li>è·Ÿè¸ªçŠ¯ç½ªè¡Œä¸º</li><li>å®¡è®¡è´¢åŠ¡è´¦ç›®</li><li>å¯ä»¥é‡‡ç”¨æº¯æºå­˜å‚¨ç³»ç»Ÿçš„æŠ€æœ¯æ‰‹æ®µæ¥ç®¡ç†ç‰©ç†ç½‘ä¸­çš„æº¯æºä¿¡æ¯ï¼Œå¯¹å®é™…ç‰©å“/æ“ä½œè¿›è¡Œç®¡æ§</li><li>åˆ©ç”¨æº¯æºæ‰‹æ®µï¼Œå¯¹ç‰©è”ç½‘ä¸­çš„ç‰©å“è¿›è¡Œè¿½è¸ªï¼Œæ˜¯è®°å½•ç‰©å“æµå‘çš„é‡è¦æ‰‹æ®µ</li></ul><p><strong>é‡å¤§æŒ‘æˆ˜ï¼šæ•°æ®é‡å¤§</strong></p><ul><li>æ•°æ®çš„æ¯æ¬¡è¯»å†™æ“ä½œéƒ½ä¼šäº§ç”Ÿæº¯æºæ•°æ®ï¼Œä»è€Œå¯¼è‡´æº¯æºæ•°æ®é‡å·¨å¤§ï¼Œé€šå¸¸æ˜¯åŸå§‹æ•°æ®é‡çš„10å€ä»¥ä¸Š</li><li>å½“æŠŠä¸€ä¸ªå¤§çš„æº¯æºå›¾å‹ç¼©çš„è¶³å¤Ÿå°åˆ°èƒ½æ”¾åœ¨å†…å­˜ä¸­æ—¶ï¼Œå¯¹äºæº¯æºçš„é«˜æ•ˆæŸ¥è¯¢æ˜¯éå¸¸é‡è¦çš„</li><li>ä¸ºä»€ä¹ˆéœ€è¦å‹ç¼©ï¼Ÿä¸ºä»€ä¹ˆç¨‹åºè¿è¡Œæ…¢ï¼Ÿï¼ˆå†…å­˜å æ¯”é«˜ï¼‰</li></ul><p><strong>ä¼ ç»Ÿæ•°æ®å‹ç¼©æ–¹æ³•</strong></p><ul><li>gzip: window size 64KB</li><li>bzip2: window size 900KB</li><li>7Z: window size 1GB</li><li>ç¼ºç‚¹ï¼šçª—å£ä¹‹å¤–çš„æ•°æ®æ— æ³•å‹ç¼©</li><li>ä½¿ç”¨ç»å…¸çš„å‹ç¼©å·¥å…·ï¼Œå¦‚bzipã€zblicç­‰ï¼Œå¯ä»¥æœ€å¤§é™åº¦åœ°å‹ç¼©æº¯æºï¼Œä½†è¿™äº›å·¥å…·å¯¼è‡´çš„æº¯æºä¿¡æ¯å¾ˆéš¾è¢«æŸ¥è¯¢ã€‚</li></ul><p>è¿ç§»å‹ç¼©</p><ul><li>å°†ç›¸ä¼¼çš„æº¯æºä¿¡æ¯é‡ç»„åˆ°ä¸€èµ·ï¼Œå†åº”ç”¨å‹ç¼©å™¨è¿›è¡Œå‹ç¼©</li></ul><p><strong>é€šè¿‡æŒ–æ˜æº¯æºçš„åŸºæœ¬ç‰¹å¾æ¥è¿›è¡Œå‹ç¼©</strong></p><ul><li>webå‹ç¼©å’Œå­—å…¸ç¼–ç ç»“åˆçš„æ–¹æ³•æ¥è¿›è¡Œå‹ç¼©<ul><li>å……åˆ†åˆ†æå’ŒæŒ–æ˜äº†æº¯æºæ•°æ®çš„åŸºæœ¬ç‰¹å¾</li><li>å……åˆ†åˆ©ç”¨äº† webå›¾å’Œæº¯æºå›¾åœ¨ç»“æ„ä¸Šçš„ç›¸ä¼¼æ€§ï¼Œå¹¶æŒ–æ˜äº†æº¯æºèŠ‚ç‚¹å±æ€§ä¸­æ‰€å­˜åœ¨çš„å¤§é‡é‡å¤æ€§çš„å­—ç¬¦ä¸²ä¿¡æ¯</li></ul></li></ul><p><strong>æº¯æºçš„åŸºæœ¬ç‰¹å¾</strong></p><ul><li>æº¯æºæ•°æ®çš„ç»„æˆ<ul><li>èº«ä»½ä¿¡æ¯ (èŠ‚ç‚¹å±æ€§)+ç¥–å…ˆä¿¡æ¯ï¼ˆè¾¹ä¸Šä¿¡æ¯ï¼‰</li></ul></li><li>æº¯æºå›¾ä¸­åŒ…å«æœ‰å¤§é‡é‡å¤æ€§ä¿¡æ¯</li><li>æº¯æºå›¾å’Œwebå›¾éƒ½å…·æœ‰ä»¥ä¸‹ä¸¤ä¸ªç‰¹å¾<ul><li><strong>å±€éƒ¨æ€§</strong><ul><li>webå›¾ï¼šä¸€ä¸ªç½‘é¡µé“¾æ¥é€šå¸¸ä¼šæŒ‡å‘åŒä¸€ä¸ªURLåŸŸä¸­çš„ç½‘é¡µã€‚</li><li>æº¯æºå›¾ï¼šä¸€ä¸ªè¿›ç¨‹(æº¯æºèŠ‚ç‚¹)ä¾èµ–äºå¾ˆå¤šåº“æ–‡ä»¶ï¼Œè¿™äº›åº“æ–‡ä»¶é€šå¸¸åœ¨åŒä¸€ç›®å½•ã€‚è¿™äº›åº“æ–‡ä»¶ä»£è¡¨çš„æº¯æºèŠ‚ç‚¹ç¼–å·åœ¨åŒä¸€åŒºæ®µã€‚</li></ul></li><li><strong>ç›¸ä¼¼æ€§</strong><ul><li>webå›¾ï¼šä¸¤ä¸ªé‚»è¿‘çš„ç½‘é¡µå¾ˆæœ‰å¯èƒ½æ‹¥æœ‰ç›¸åŒçš„é‚»å±…ã€‚</li><li>æº¯æºå›¾ï¼š ä¸¤ä¸ªè¿›ç¨‹ï¼ˆæº¯æºèŠ‚ç‚¹ï¼‰ä¾èµ–äºåŒä¸€ä¸ªåº“æ–‡ä»¶ã€‚</li></ul></li></ul></li><li>æº¯æºæ•°æ®éœ€è¦è¢«æŸ¥è¯¢</li></ul><p><strong>Webå›¾å‹ç¼©å’Œå­—å…¸ç¼–ç ï¼ˆWeb+Dictionaryï¼‰</strong></p><ul><li>åˆ©ç”¨æº¯æºå›¾å’Œwebå›¾çš„ç›¸ä¼¼æ€§ï¼Œå……åˆ†æŒ–æ˜æº¯æºå›¾ä¸­æ•°æ®å­˜åœ¨çš„å±€éƒ¨æ€§å’Œç›¸ä¼¼æ€§ï¼Œæ¥å‹ç¼©ç¥–å…ˆä¿¡æ¯</li><li>å­—å…¸ç¼–ç å¯å°†èº«ä»½ä¿¡æ¯å’Œç¥–å…ˆä¿¡æ¯è¾¹ä¸Šå­˜åœ¨çš„ä»»ä½•é‡å¤æ€§å­—ç¬¦ä¸²è¿›è¡Œç¼–ç ï¼Œå…·æœ‰æå…¶çµæ´»ä»¥åŠè¶³å¤Ÿç»†ç²’åº¦çš„ç¼–ç æ–¹å¼</li></ul><p><strong>æº¯æºtraceå’Œæº¯æºå›¾ï¼Œä»¥åŠwebå›¾ä¹‹é—´çš„æ˜ å°„</strong></p><p><img src="/images/ç‰©è”ç½‘å­˜å‚¨æŠ€æœ¯/relationship.png"></p><ul><li>æº¯æºtraceä¸­çš„æ ‡è®°â€œA INPUT[ANC] Bâ€ è¡¨ç¤º <strong>Bæ˜¯Açš„ä¸€ä¸ªç¥–å…ˆ</strong>ï¼Œè¿™æ„å‘³ç€æº¯æºå›¾ä¸­æœ‰ä¸€æ¡<strong>ä» A æŒ‡å‘ B</strong>çš„è¾¹.</li></ul><p><strong>webå›¾å‹ç¼©</strong></p><ul><li><p>æº¯æºæ•°æ®</p><ul><li>15.1 INPUT [ANC] 3.1</li><li>15.1 INPUT [ANC] 11.0</li><li>15.1 INPUT [ANC] 13.1</li><li>15.1 INPUT [ANC] 14.1</li><li>15.1 INPUT [ANC] 17.1</li><li>16.1 INPUT [ANC] 11.0</li><li>16.1 INPUT [ANC] 14.1</li><li>16.1 INPUT [ANC] 19.1</li><li>16.1 INPUT [ANC] 20.1</li><li>16.1 INPUT [ANC] 21.1</li><li>16.1 INPUT [ANC] 33.1</li></ul></li><li><p>é‚»æ¥è¡¨</p><table><thead><tr class="header"><th>Node</th><th>outd</th><th>ancestors</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>3, 11, 13, 14, 17</td></tr><tr class="even"><td>16</td><td>6</td><td>11, 14, 19, 20, 21, 33</td></tr></tbody></table></li><li><p>å¯»æ‰¾ç›¸ä¼¼ç¥–å…ˆåˆ—è¡¨</p><table><thead><tr class="header"><th>node</th><th>outd</th><th>ref.</th><th>copy list</th><th>ancestors</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>0=15-15</td><td></td><td>3, 11, 13, 14, 17</td></tr><tr class="even"><td>16</td><td>6</td><td>1=16-15</td><td>01010</td><td>19, 20, 21, 33</td></tr></tbody></table></li><li><p>ç¼–ç è¿ç»­çš„ç¥–</p><p>#intervalsè¡¨ç¤ºæœ‰å‡ ä¸ªè¿ç»­çš„ä¸²</p><p>Left extremeè¡¨ç¤ºè·ŸNodeçš„å·®è·</p></li></ul><table><thead><tr class="header"><th>node</th><th>outd</th><th>ref</th><th>copy list</th><th>inter</th><th>left</th><th>len</th><th>res</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>0</td><td></td><td>1</td><td>-2</td><td>2</td><td>3,11,17</td></tr><tr class="even"><td>16</td><td>6</td><td>1</td><td>01010</td><td>1</td><td>3</td><td>3</td><td>33</td></tr></tbody></table><ul><li>ç”¨ç¥–å…ˆèŠ‚ç‚¹ä¹‹é—´çš„é—´è·è¿›è¡Œç¼–ç </li></ul><table><thead><tr class="header"><th>node</th><th>outd</th><th>ref</th><th>copy list</th><th>inter</th><th>left</th><th>len</th><th>res</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>0</td><td></td><td>1</td><td>-2</td><td>2</td><td>-12,8,6</td></tr><tr class="even"><td>16</td><td>6</td><td>1</td><td>01010</td><td>1</td><td>3</td><td>3</td><td>17</td></tr></tbody></table><ul><li>æ¯ä¸ªèŠ‚ç‚¹çš„ç¼–ç ï¼š<span class="math inline">\(r\ [b\ B_1 â€¦ B_b] i\ E_1 L_1 â€¦E_i L_i R_1 â€¦ R_k\)</span><ul><li>r: å‚è€ƒå·</li><li>b: copy listä¸­bitçš„æ•°é‡</li><li><span class="math inline">\(B_1â€¦B_b\)</span>: copy listä¸­bitä½çš„å€¼</li><li>i: intervalçš„ä¸ªæ•°</li><li><span class="math inline">\(E_1â€¦E_i\)</span>: Left Extremes</li><li><span class="math inline">\(L_1â€¦L_i\)</span>: Length</li><li><span class="math inline">\(R_1â€¦R_k\)</span>: Residuals</li></ul></li></ul><p><strong>å­—å…¸ç¼–ç </strong></p><ul><li>ç”¨è¾ƒå°çš„æ•´æ•°å°†é‡å¤æ€§å­—ç¬¦ä¸²è¿›è¡Œç¼–ç </li><li>å¯å°†èº«ä»½ä¿¡æ¯ä¸Šçš„é‡å¤æ€§å­—ç¬¦ä¸²ï¼ˆå¦‚è¿›ç¨‹æ‰§è¡Œå‚æ•°å’Œç¯å¢ƒå˜é‡ï¼‰ã€ä»¥åŠç¥–å…ˆè¾¹ä¸Šçš„é‡å¤æ€§å­—ç¬¦ä¸²ï¼ˆå¦‚æ—¶é—´ä¿¡æ¯ï¼‰è¿›è¡Œç¼–ç </li><li>å…·æœ‰æå…¶çµæ´»ä»¥åŠè¶³å¤Ÿç»†ç²’åº¦çš„ç¼–ç æ–¹å¼ï¼ˆå¯æ‰¾å‡ºç›¸åŒå­—ç¬¦ä¸²ï¼Œæˆ–è€…å­—ç¬¦ä¸²ä¸­çš„ç›¸åŒå‰ç¼€ã€åç¼€ï¼‰</li></ul><p><img src="/images/ç‰©è”ç½‘å­˜å‚¨æŠ€æœ¯/diccode.png"></p><p><strong>å…¥ä¾µæ£€æµ‹ä¸­çš„æº¯æº</strong></p><p>ä¾‹å­ï¼šä¸€ä¸ªè¿œç¨‹çš„æ”»å‡»è€…ï¼Œé€šè¿‡æ”»å‡»ä¸»æœºä¸Šçš„<code>vsftpd-2.3.4</code>çš„backdooræ¼æ´ï¼Œè·å¾—æ ¹ç”¨æˆ·è®¿é—®æƒé™ã€‚ç„¶åå…¥ä¾µè€…ä»¥<code>root</code>æƒé™ç™»é™† <code>shell</code>ï¼Œå¹¶é€šè¿‡<code>vi</code>å‘½ä»¤ç¯¡æ”¹äº†æ–‡ä»¶<code>f1</code>å’Œ<code>f2</code>ã€‚</p><p><img src="/images/ç‰©è”ç½‘å­˜å‚¨æŠ€æœ¯/attack.png"></p><p>è¿›è¡Œè®¡ç®—æœºå–è¯</p><ul><li>æ€ä¹ˆå…¥ä¾µ</li><li>å…¥ä¾µåéƒ½å¹²äº†ä»€ä¹ˆï¼ˆä¿®æ”¹æ–‡ä»¶ï¼Œæ³„æ¼ç§˜å¯†ï¼Œå®‰è£…åé—¨ç­‰ï¼‰</li><li>ä¿®è¡¥ç³»ç»Ÿæ¼æ´ï¼Œå°è¯•æ¢å¤å…¥ä¾µè€…é€ æˆçš„ä¿®æ”¹</li></ul><p>å‘ç°å…¥ä¾µæ£€æµ‹ç‚¹</p><ul><li>æ–‡ä»¶ç³»ç»Ÿå®Œæ•´æ€§æ£€æŸ¥ï¼ˆTripwireï¼ŒAIDEï¼‰</li><li>ç½‘ç»œæ£€æµ‹</li><li>æ²™ç›’</li></ul><p>åˆ†æå…¥ä¾µè¡Œä¸º</p><ul><li>ç³»ç»Ÿ/ç½‘ç»œæ—¥å¿—ï¼ˆSnortï¼ŒEtherealï¼‰</li><li>ç£ç›˜çŠ¶æ€ï¼ˆThe Coronerâ€™s Toolkitï¼‰</li></ul><p>å½“å‰å–è¯æ–¹æ³•çš„ä¸è¶³</p><ul><li>ç³»ç»Ÿæ—¥å¿—è®°å½•ä¸å¤Ÿå…¨é¢ï¼Œç¼ºä¹å¿…è¦ä¿¡æ¯</li><li>ç½‘ç»œæ¶ˆæ¯å¯èƒ½è¢«åŠ å¯†</li><li>ç£ç›˜çŠ¶æ€ä»…æ˜¾ç¤ºäº†æ–‡ä»¶çš„æœ€ç»ˆçŠ¶æ€</li></ul><p>åŸºäºæº¯æºçš„å…¥ä¾µæ£€æµ‹æ€»ä½“è®¾è®¡</p><ul><li><p>æ”¶é›†å™¨</p><ul><li>å®æ—¶ç›‘æ§åº”ç”¨ï¼Œç”Ÿæˆæº¯æºä¿¡æ¯</li><li>æˆªè·ç³»ç»Ÿè°ƒç”¨ï¼Œè·Ÿè¸ªæ”¶é›†æ–‡ä»¶ã€è¿›ç¨‹å’Œç½‘ç»œsocketçš„æº¯æºä¿¡æ¯</li><li>ä¿®å‰ªå¤§é‡ç¹æ‚çš„æº¯æºä¿¡æ¯æ¥é¿å…è¯¯æ£€ã€‚</li><li>ä½¿ç”¨ç»“æ„åŒ–çš„key-value æ•°æ®åº“æ¥è®°å½•å’ŒæŸ¥è¯¢å…¥ä¾µä¿¡æ¯</li><li>æº¯æºæ•°æ®åº“<ul><li>PnodeèŠ‚ç‚¹å·å”¯ä¸€çš„æ ‡è¯†äº†æ¯ä¸ªå¯¹è±¡</li><li>ParentDB å’Œ ChildDB åˆ†åˆ«å­˜å‚¨äº†ä¸€ä¸ªèŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹å’Œå­èŠ‚ç‚¹</li><li>RuleDB å­˜å‚¨äº†ä»£è¡¨å¯¹è±¡ä¹‹é—´ä¾èµ–æ€§å…³ç³»çš„ç»å¸¸æ€§äº‹ä»¶</li></ul></li></ul></li><li><p>æ£€æµ‹å™¨</p><ul><li><p>ä»æº¯æºä¸­æŠ½å–ä¾èµ–æ€§ä¿¡æ¯ï¼Œå»ºç«‹è§„åˆ™åº“å’Œæ£€æµ‹å…¥ä¾µ</p></li><li><p>è§„åˆ™å»ºç«‹</p><ul><li>é€šè¿‡å­˜å‚¨ç»å¸¸æ€§äº‹ä»¶ä¾èµ–æ€§å…³ç³»ç”Ÿæˆè§„åˆ™ï¼Œå¹¶ç¼–ç è§„åˆ™</li><li><ol type="1"><li>å¤šæ¬¡è¿è¡Œä¸€ä¸ªæ­£å¸¸çš„ç¨‹åºæ¥è·å–å®ƒçš„æº¯æºä¿¡æ¯R</li></ol></li><li><ol start="2" type="1"><li>å¯¹äºæ¯ä¸ªR, åˆ’åˆ†ä¸º <span class="math inline">\(R=\{Dep_1, â€¦Dep_n\}\)</span>, å…¶ä¸­<span class="math inline">\(Dep_i = (A, B)\)</span>è¡¨ç¤º Aæ˜¯ Bçš„çˆ¶èŠ‚ç‚¹</li></ol></li><li><ol start="3" type="1"><li>å°†æ¯ä¸ª<span class="math inline">\(Dep_i\)</span>ä½¿ç”¨å­—å…¸ç¼–ç æ–¹æ³•æ¥å‡å°‘åœ¨Aå’ŒBä¸­é‡å¤çš„å­—ç¬¦ä¸²</li></ol></li><li><ol start="4" type="1"><li>å°†æ‰€æœ‰è¿™äº›<span class="math inline">\(Dep_i\)</span>æ”¾è¿›è§„åˆ™åº“<span class="math inline">\(G\)</span>, å³<span class="math inline">\(G= \{Dep_1, â€¦ Dep_k\}\)</span>.</li></ol></li></ul><p><img src="/images/ç‰©è”ç½‘å­˜å‚¨æŠ€æœ¯/rule.png"></p></li><li><p>è·¯å¾„åŒ¹é…</p><ul><li>åŸºäºæº¯æºçš„è·¯å¾„åŒ¹é…ç®—æ³•</li><li><ol type="1"><li>è·å–æ‰€æ£€æµ‹ç¨‹åºçš„æº¯æºä¿¡æ¯R, å°†å®ƒè¡¨ç¤ºä¸º<span class="math inline">\(R= \{Dep_1, â€¦ Dep_n\}\)</span></li></ol></li><li><ol start="2" type="1"><li>å¯¹äºRä¸­çš„æ¯ä¸ª<span class="math inline">\(Dep_i\)</span> , å¦‚æœ,<span class="math inline">\(Dep_i = (A, B) \in G\)</span> åˆ™è®¾ç½®å®ƒçš„å¯ç–‘åº¦<span class="math inline">\(d_i = 0\)</span>, å¦åˆ™è®¾ç½®å¯ç–‘åº¦ä¸º1</li></ol></li><li><ol start="3" type="1"><li>å¯»æ‰¾Rä¸­é•¿åº¦ä¸ºWçš„è·¯å¾„, å°†è·¯å¾„è¡¨ç¤ºä¸º <span class="math inline">\((Dep_1, â€¦ Dep_w)\)</span>, å°†è·¯å¾„å†³ç­–å€¼pè¡¨ç¤ºä¸º<span class="math inline">\(p = \frac{\sum_{i=1}^wd_i}{W}\)</span></li></ol></li><li><ol start="4" type="1"><li>è®¾ç½®é˜ˆå€¼T, å¦‚æœ P&gt; T, åˆ™è­¦æŠ¥ä¼šå“èµ·ï¼Œç›¸åº”çš„æº¯æºè·¯å¾„ä¼šè¾“å‡º, ç¨‹åºè¢«åˆ¤æ–­ä¸ºä¸æ­£å¸¸.</li></ol></li></ul></li><li><p>è­¦æŠ¥è¾“å‡º</p><ul><li>æä¾›ç›´æˆªäº†å½“çš„å…¥ä¾µè·¯å¾„ä¿¡æ¯æ¥å‡å°‘è¯¯æ£€å’Œå¸®åŠ©å–è¯åˆ†æã€‚</li></ul></li></ul></li><li><p>åˆ†æå™¨</p><ul><li>åˆ†æå…¥ä¾µçš„ç³»ç»Ÿæ¼æ´å’Œå…¥ä¾µæ¥æº</li></ul></li></ul><p><strong>ä¼˜åŒ–ã€è¿‡æ»¤æº¯æºå›¾</strong></p><ol type="1"><li><p>å¿½ç•¥ä¸€äº›ç‰¹å®šçš„å¯¹è±¡</p><p>æ¯”å¦‚loginè¿›ç¨‹ä¼šè¯»å†™æ–‡ä»¶/var/run/utmpï¼Œå¯¼è‡´æ–°çš„loginè¿›ç¨‹ä¾èµ–äºä¹‹å‰çš„loginè¿›ç¨‹ï¼›Mountã€umountä¼šå†™æ–‡ä»¶/etc/mtabï¼Œè€Œbashè¿›ç¨‹åœ¨äº§ç”Ÿæ—¶ä¼šè¯»å–è¯¥æ–‡ä»¶ï¼Œå¯¼è‡´ä¾èµ–äºmountè¿›ç¨‹ï¼›</p></li><li><p>éšè—åªè¢«è¯»çš„æ–‡ä»¶</p><p>é€šå¸¸æ˜¯åº“æ–‡ä»¶æˆ–è€…é…ç½®æ–‡ä»¶</p></li><li><p>è¿‡æ»¤â€è¾…åŠ©â€è¿›ç¨‹</p><p>Bashè¿›ç¨‹äº§ç”Ÿidè¿›ç¨‹ã€consoletypeè¿›ç¨‹å’Œdircolorsè¿›ç¨‹</p></li></ol><h2><span id="åè¯è§£é‡Š">åè¯è§£é‡Š</span></h2><table><thead><tr class="header"><th>ä¸­æ–‡</th><th>è‹±æ–‡</th><th>ç¼©å†™</th></tr></thead><tbody><tr class="odd"><td>å…ƒæ•°æ®æœåŠ¡å™¨</td><td>Metadata server</td><td>MDS</td></tr><tr class="even"><td>å¯¹è±¡å­˜å‚¨</td><td>Object-based Storage</td><td>OBS</td></tr><tr class="odd"><td>å¯¹è±¡å­˜å‚¨è®¾å¤‡</td><td>Object-based Storage Device</td><td>OSD</td></tr><tr class="even"><td>å…ƒæ•°æ®æŸ¥æ‰¾è¡¨</td><td>Metadata Look-up Table</td><td>MLT</td></tr><tr class="odd"><td>é—ªå­˜ç¿»è¯‘å±‚</td><td>Flash Translation Layer</td><td>FTL</td></tr><tr class="even"><td>æ¶ˆæ¯æ‘˜è¦</td><td>Message Digest</td><td>MD</td></tr><tr class="odd"><td>ç›¸å˜å­˜å‚¨å™¨</td><td>Phase-change Memory</td><td>PCM</td></tr><tr class="even"><td>åœ°å€æ˜ å°„</td><td>Address mapping</td><td>AM</td></tr><tr class="odd"><td>æŸè€—å¹³è¡¡</td><td>Wear leveling</td><td>WL</td></tr><tr class="even"><td>åƒåœ¾å›æ”¶</td><td>Garbage Collection</td><td>GC</td></tr><tr class="odd"><td>å­˜å‚¨çº§å†…å­˜</td><td>Storage-Class Memory</td><td>SCM</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bloom Filter </tag>
            
            <tag> æœ¬ç§‘è¯¾ç¨‹ </tag>
            
            <tag> ç‰©è”ç½‘ </tag>
            
            <tag> å¯¹è±¡å­˜å‚¨ </tag>
            
            <tag> é‡å¤æ•°æ®åˆ é™¤ </tag>
            
            <tag> å…ƒæ•°æ®ç®¡ç† </tag>
            
            <tag> SSD </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ­ç§˜äºŒç»´ç â€”åŸç†ä¸å®è·µ</title>
      <link href="/2016/11/14/%E6%8F%AD%E7%A7%98%E4%BA%8C%E7%BB%B4%E7%A0%81%E2%80%94%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
      <url>/2016/11/14/%E6%8F%AD%E7%A7%98%E4%BA%8C%E7%BB%B4%E7%A0%81%E2%80%94%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h2><span id="ä»€ä¹ˆæ˜¯äºŒç»´ç ">ä»€ä¹ˆæ˜¯äºŒç»´ç </span></h2><p>äºŒç»´ç ï¼Œè‹±æ–‡ï¼š<strong>Quick Response Code</strong>ï¼Œ ç®€ç§° <strong>QR</strong> ç ã€‚äºŒç»´ç æœ€åˆç”±æ—¥æœ¬ä¸€å®¶å…¬å¸å‘æ˜ï¼Œåç”±å›½é™…æ ‡å‡†åŒ–ç»„ç»‡ISOæ‰¹å‡†è¿›è¡Œæ ‡å‡†åŒ–ã€‚ç°åœ¨äºŒç»´ç åœ¨æˆ‘ä»¬ç”Ÿæ´»ä¸­å¹¿æ³›ä½¿ç”¨ï¼Œå®ƒå…·æœ‰æ¯”æ¡å½¢ç æ›´å¼ºçš„æ•°æ®è¡¨ç¤ºèƒ½åŠ›å’Œæ›´å¼ºçš„çº é”™èƒ½åŠ›ã€‚</p><p>æˆ‘è®¤ä¸ºï¼Œ<strong>äºŒç»´ç å°±æ˜¯ä¸€ç§ç¼–ç ï¼ŒæŠŠæˆ‘ä»¬è¦ä¼ é€’çš„æ•°æ®è¿›è¡Œç¼–ç å¹¶è½¬æ¢æˆå¦å¤–ä¸€ç§å½¢å¼å‘ˆç°å‡ºæ¥</strong>ã€‚</p><a id="more"></a><h2><span id="æŠ€æœ¯åŸç†">æŠ€æœ¯åŸç†</span></h2><p>æ³¨ï¼šæ–‡ä¸­æ‰€æŒ‡çš„QR Code Spec : <a href="http://www.codeplex.com/Download?ProjectName=qrcodenet&amp;DownloadId=284291" target="_blank" rel="noopener">ISO/IEC 18004:2000(E) - QR code specificationÂ </a>ã€‚</p><h3><span id="æ•´ä½“ç»“æ„">æ•´ä½“ç»“æ„</span></h3><p>äºŒç»´ç çš„æ•´ä½“ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/QR_Structure.png"></p><p>æ•´ä½“åˆ†ä¸ºä¸¤å¤§éƒ¨åˆ†ï¼šåŠŸèƒ½åŒºï¼ˆFunction Patternsï¼‰å’Œç¼–ç åŒºï¼ˆEncoding regionï¼‰ã€‚</p><p>åŠŸèƒ½åŒºé‡Œåˆåˆ†ä¸ºï¼š</p><ul><li>Finder Patternï¼šç”¨äºè®©è§£ç å™¨å®šä½äºŒç»´ç çš„ä½ç½®ï¼Œåˆ†åˆ«ä½äºä¸‰ä¸ªè§’</li><li>Separatorï¼šèµ·åˆ†éš”ä½œç”¨</li><li>Timing Patternsï¼šç›¸å½“äºåæ ‡è½´</li><li>Alignment Patternsï¼šå¸®åŠ©è§£ç å™¨é‡æ–°åŒæ­¥åæ ‡æ˜ å°„ï¼Œåœ¨äºŒç»´ç æœ‰ä¸€å®šæ±¡æŸçš„æƒ…å†µä¸‹</li></ul><p>ç¼–ç åŒºé‡Œåˆ†ä¸ºï¼š</p><ul><li>Format Informationï¼šç”¨æ¥å­˜å‚¨çº é”™ç­‰çº§å’Œæ©ç ï¼ˆmaskï¼‰ç±»å‹</li><li>Version Informationï¼šäºŒç»´ç ä¸€å…±æœ‰40ä¸ªå°ºå¯¸ï¼ŒVersion 1æ˜¯21 x 21çš„çŸ©é˜µï¼ŒVersion 2æ˜¯ 25 x 25çš„çŸ©é˜µï¼ŒVersion 3æ˜¯29çš„å°ºå¯¸ï¼Œæ¯å¢åŠ ä¸€ä¸ªversionï¼Œå°±ä¼šå¢åŠ 4çš„å°ºå¯¸ã€‚åœ¨ &gt;= Version 7ä»¥ä¸Šï¼Œéœ€è¦é¢„ç•™ä¸¤å—3 x 6çš„åŒºåŸŸå­˜æ”¾ä¸€äº›ç‰ˆæœ¬ä¿¡æ¯</li><li>å‰©ä¸‹çš„åŒºåŸŸç”¨æ¥å­˜æ”¾æ•°æ®å’Œçº é”™ç </li></ul><h3><span id="ç¼–ç æ–¹å¼">ç¼–ç æ–¹å¼</span></h3><p>äºŒç»´ç æœ‰å¤šç§ç¼–ç æ¨¡å¼ï¼Œè¿™é‡Œä»‹ç»å››ç§ï¼š</p><ul><li><p><strong>Numeric Mode</strong>ï¼šæ”¯æŒæ•°å­—0ï½9</p></li><li><p><strong>Alphanumeric Mode</strong>ï¼šåŒ…æ‹¬æ•°å­—0ï½9ï¼Œå¤§å†™å­—æ¯Aï½Zï¼Œå’Œä¸€äº›ç¬¦å·ç©ºæ ¼ $ % * + - . / : ã€‚è¿™äº›å­—ç¬¦ä¼šæ˜ å°„æˆä¸€ä¸ªå­—ç¬¦ç´¢å¼•è¡¨ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="/images/EncodingAM.png"></p><p>ç¼–ç çš„è¿‡ç¨‹æ˜¯æŠŠå­—ç¬¦ä¸¤ä¸¤åˆ†ç»„ï¼Œç„¶åè½¬æˆä¸Šè¡¨çš„45è¿›åˆ¶ï¼Œç„¶åè½¬æˆ11bitsçš„äºŒè¿›åˆ¶ï¼Œå¦‚æœæœ€åæœ‰ä¸€ä¸ªè½å•çš„ï¼Œé‚£å°±è½¬æˆ6bitsçš„äºŒè¿›åˆ¶ã€‚</p></li><li><p><strong>Byte Mode</strong>ï¼šè¿™ä¸ªæ¨¡å¼å¯ä»¥ç¼–ç çš„å­—ç¬¦å°±æ¯”ä¸Šä¸€ä¸ªå¤šä¸€äº›ï¼Œæ¯æŠŠä¸ªbitæ„æˆä¸€ä¸ªå­—ç¬¦ï¼Œæ€»å…±å¯ä»¥è¡¨ç¤º256ä¸ªä¸åŒå­—ç¬¦ï¼Œå…·ä½“æ˜ å°„è¡¨è§QR Code Specçš„Table 6</p></li><li><p><strong>Kanji Mode</strong>ï¼šåŒå­—èŠ‚ç¼–ç ï¼Œè¿™ä¸ªæ¨¡å¼å¯ä»¥ç¼–ç æ—¥æ–‡ï¼Œä¹Ÿå¯ä»¥ç”¨äºä¸­æ–‡ç¼–ç ï¼Œä¸‹å›¾æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š</p><p><img src="/images/Kanji-mode.png"></p></li></ul><p>æ¯ç§ç¼–ç æ¨¡å¼éƒ½æœ‰å¯¹åº”çš„æ ‡è¯†ç¬¦ï¼Œå¦‚è¡¨1æ‰€ç¤ºã€‚æ¨¡å¼è¡¨ç¤ºè¦æ”¾åœ¨æ•°æ®çš„å‰é¢ã€‚</p><table><thead><tr class="header"><th>Mode</th><th>indicator</th></tr></thead><tbody><tr class="odd"><td>Numeric</td><td>0001</td></tr><tr class="even"><td>Alphanumeric</td><td>0010</td></tr><tr class="odd"><td>Byte</td><td>0100</td></tr><tr class="even"><td>Kanji</td><td>1000</td></tr></tbody></table><p>â€‹ è¡¨1 Mode Indicator</p><p>ä¸‹é¢æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªå…·ä½“ç¤ºä¾‹ã€‚</p><p>æˆ‘ä»¬ç”¨Alphanumericæ¨¡å¼ç¼–ç  AC-42 è¿™5ä¸ªå­—ç¬¦ï¼Œå‡è®¾ä¸ºVersion1ï¼š</p><ol type="1"><li><p>ä»å­—ç¬¦ç´¢å¼•è¡¨ä¸­æ‰¾åˆ° â€œAC-42â€ è¿™äº”ä¸ªå­—ç¬¦çš„ç´¢å¼•ï¼š(10, 12, 41, 4, 2)</p></li><li><p>ä¸¤ä¸¤åˆ†ç»„ï¼š(10, 12), (41, 4), (2)</p></li><li><p>æŠŠæ¯ä¸€ç»„è½¬æˆ11bitsçš„äºŒè¿›åˆ¶ï¼Œè½å•çš„è½¬æˆ6bitsçš„äºŒè¿›åˆ¶ï¼š</p><p>(10, 12) = 10 * 45 + 12 = 462 = 00111001110</p><p>(41, 4) = 41 * 25 + 4 = 1849 = 11100111001</p><ol start="2" type="1"><li>= 000010</li></ol></li><li><p>æŠŠè¿™äº›äºŒè¿›åˆ¶è¿æ¥èµ·æ¥ï¼š00111001110 11100111001 000010</p></li><li><p>æŠŠå­—ç¬¦çš„ä¸ªæ•°è½¬æˆäºŒè¿›åˆ¶ï¼Œä¸åŒçš„Versionå¯¹åº”çš„bitä¸ªæ•°å¦‚Table3æ‰€ç¤ºã€‚Version1å¯¹åº”çš„æ˜¯9bitsï¼Œæ€»å…±5ä¸ªå­—ç¬¦ï¼Œè½¬æ¢æˆ9-bitäºŒè¿›åˆ¶æ•°å°±æ˜¯ï¼š000000101</p><p><img src="/images/Count-Indicator.png"></p></li><li><p>åœ¨æ•°æ®å‰é¢åŠ ä¸Šæ¨¡å¼æ ‡è¯†ç¬¦0010å’Œä¸Šä¸€æ­¥å¾—åˆ°çš„å­—ç¬¦æ•°ç¼–ç ï¼š0010 000000101 00111001110 11100111001 000010</p></li></ol><h3><span id="ç»“æŸå’Œè¡¥é½">ç»“æŸå’Œè¡¥é½</span></h3><p>å‡å¦‚æˆ‘ä»¬æœ‰ä¸ªHELLO WORLDçš„å­—ç¬¦ä¸²è¦ç¼–ç ï¼Œæ ¹æ®ä¸Šè¿°ç¤ºä¾‹ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸‹ç¼–ç ï¼š</p><table><colgroup><col style="width: 7%"><col style="width: 16%"><col style="width: 75%"></colgroup><thead><tr class="header"><th>æ¨¡å¼</th><th>å­—ç¬¦æ•°</th><th>Hello worldç¼–ç </th></tr></thead><tbody><tr class="odd"><td>0010</td><td>000001011</td><td>01100001011 01111000110 10001011100 10110111000 10011010100 001101</td></tr></tbody></table><p>æˆ‘ä»¬è¿˜è¦åŠ ä¸Šç»“æŸç¬¦ï¼š</p><table><colgroup><col style="width: 7%"><col style="width: 15%"><col style="width: 70%"><col style="width: 7%"></colgroup><thead><tr class="header"><th>æ¨¡å¼</th><th>å­—ç¬¦æ•°</th><th>Hello worldç¼–ç </th><th>ç»“æŸç¬¦</th></tr></thead><tbody><tr class="odd"><td>0010</td><td>000001011</td><td>01100001011 01111000110 10001011100 10110111000 10011010100 001101</td><td>0000</td></tr></tbody></table><p><strong>æŒ‰8bitsé‡æ’</strong></p><p>å¦‚æœæ‰€æœ‰çš„ç¼–ç åŠ èµ·æ¥ä¸æ˜¯8ä¸ªå€æ•°æˆ‘ä»¬è¿˜è¦åœ¨åé¢åŠ ä¸Šè¶³å¤Ÿçš„0ï¼Œæ¯”å¦‚ä¸Šé¢ä¸€å…±æœ‰78ä¸ªbitsï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬è¿˜è¦åŠ ä¸Š2ä¸ª0ï¼Œç„¶åæŒ‰8ä¸ªbitsåˆ†å¥½ç»„ï¼š</p><p>00100000 Â  01011011 Â  00001011 Â  01111000 Â  11010001 Â  01110010 Â  11011100 Â  01001101 Â  01000011 Â  010000<strong>00</strong></p><p><strong>è¡¥é½ç ï¼ˆPadding Bytesï¼‰</strong></p><p>æœ€åï¼Œå¦‚æœå¦‚æœè¿˜æ²¡æœ‰è¾¾åˆ°æˆ‘ä»¬æœ€å¤§çš„bitsæ•°çš„é™åˆ¶ï¼Œæˆ‘ä»¬è¿˜è¦åŠ ä¸€äº›è¡¥é½ç ï¼ŒPadding Byteså°±æ˜¯é‡å¤ä¸‹é¢çš„ä¸¤ä¸ªbytesï¼š<strong>11101100 00010001</strong> ã€‚å…³äºæ¯ä¸€ä¸ªVersionçš„æ¯ä¸€ç§çº é”™çº§åˆ«çš„æœ€å¤§Bitsé™åˆ¶ï¼Œå¯ä»¥å‚çœ‹QR Code Specçš„ç¬¬33é¡µçš„Table-7ä¸€è¡¨ï¼Œä¸‹é¢æ˜¯è¿™ä¸ªè¡¨çš„ä¸€éƒ¨åˆ†ï¼Œé‡Œé¢ä¹ŸåŒ…å«å¯è¡¨ç¤ºçš„æœ€å¤§å­—ç¬¦æ•°ï¼š</p><p><img src="/images/table7.png"></p><p>å‡è®¾æˆ‘ä»¬éœ€è¦ç¼–ç çš„æ˜¯Version 1çš„Qçº é”™çº§ï¼Œé‚£ä¹ˆï¼Œå…¶æœ€å¤§éœ€è¦104ä¸ªbitsï¼Œè€Œæˆ‘ä»¬ä¸Šé¢åªæœ‰80ä¸ªbitsï¼Œæ‰€ä»¥ï¼Œè¿˜éœ€è¦è¡¥24ä¸ªbitsï¼Œä¹Ÿå°±æ˜¯éœ€è¦3ä¸ªPadding Bytesï¼Œæˆ‘ä»¬å°±æ·»åŠ ä¸‰ä¸ªï¼Œäºæ˜¯å¾—åˆ°ä¸‹é¢çš„ç¼–ç ï¼š</p><p>00100000 01011011 00001011 01111000 11010001 01110010 11011100 01001101 01000011 01000000Â <strong>11101100 00010001 11101100</strong></p><p>ä¸Šé¢çš„ç¼–ç å°±æ˜¯æ•°æ®ç äº†ï¼Œå«Data Codewordsï¼Œæ¯ä¸€ä¸ª8bitså«ä¸€ä¸ªcodewordï¼Œæˆ‘ä»¬è¿˜è¦å¯¹è¿™äº›æ•°æ®ç åŠ ä¸Šçº é”™ä¿¡æ¯ã€‚</p><h3><span id="çº é”™ç ">çº é”™ç </span></h3><p>æ­£æ˜¯å› ä¸ºæœ‰äº†çº é”™ç çš„å­˜åœ¨ï¼ŒäºŒç»´ç æ‰å¯ä»¥åœ¨æœ‰ä¸€å®šæ±¡æŸçš„æƒ…å†µä¸‹è¢«æ­£ç¡®è¯†åˆ«ï¼Œè¿™ä¹Ÿæ˜¯å¥½å¤šäºŒç»´ç ä¸­é—´æœ‰å›¾æ ‡æˆ–å¤´åƒä¾ç„¶å¯ä»¥è¢«æ‰«å‡ºæ¥çš„ç†è®ºåŸºç¡€ã€‚</p><p>äºŒç»´ç æœ‰å››ä¸ªçº é”™çº§åˆ«ï¼Œåˆ†åˆ«å¦‚ä¸‹ï¼š</p><p><img src="/images/table8.png"></p><p><strong>äºŒç»´ç çš„çº é”™æ–¹å¼ä¹Ÿæ˜¯é€šè¿‡å¢åŠ å†—ä½™ä½æ¥å®ç°çº é”™</strong>ï¼Œè¿™ä¸€ç‚¹åœ¨æœ¬è´¨ä¸Šå’Œï¼ˆåˆ†ç»„ï¼‰å¥‡å¶æ ¡éªŒï¼ŒCRCå¾ªç¯æ ¡éªŒç­‰çº é”™æ–¹å¼æ˜¯ç›¸åŒçš„ï¼Œçº æ­£ <span class="math inline">\(t\)</span> ä¸ªé”™è¯¯å°±éœ€è¦ <span class="math inline">\(2t\)</span> ä¸ªçº é”™ç ã€‚</p><p>å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®ç è¿›è¡Œåˆ†ç»„ï¼Œä¹Ÿå°±æ˜¯åˆ†æˆä¸åŒçš„Blockï¼Œç„¶åå¯¹å„ä¸ªBlockè¿›è¡Œçº é”™ç¼–ç ï¼Œå¯¹äºå¦‚ä½•åˆ†ç»„ï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹QR Code Specçš„ç¬¬38é¡µçš„Table-9çš„å®šä¹‰è¡¨ï¼Œä¸‹é¢æ˜¯è¯¥è¡¨çš„ä¸€éƒ¨åˆ†ï¼š</p><p><img src="/images/table9.png"></p><p>å€’æ•°ç¬¬äºŒåˆ—è¡¨ç¤ºäº†éœ€è¦åˆ†å¤šå°‘ä¸ªçº é”™å—ï¼Œæœ€åä¸€åˆ—è¡¨ç¤ºæ¯ä¸ªçº é”™å—çš„å…·ä½“æƒ…å†µï¼Œ(c, k, r) åˆ†åˆ«ä»£è¡¨ï¼š</p><ul><li>cï¼šè¯¥å—ä¸­æ€»å…±çš„Codewordä¸ªæ•°</li><li>kï¼šæ•°æ®Codewordçš„ä¸ªæ•°</li><li>rï¼šå¯ä»¥çº æ­£çš„é”™è¯¯ä¸ªæ•°ï¼Œæ‰€ä»¥çº é”™ç çš„ä½(Codeword)æ•°ç­‰äº 2r</li></ul><p>ä¸¾ä¸ªä¾‹å­ï¼Œä¸Šè¿°çš„Version 5 + Qçº é”™çº§ï¼šéœ€è¦4ä¸ªBlocksï¼ˆ2ä¸ªBlocksä¸ºä¸€ç»„ï¼Œå…±ä¸¤ç»„ï¼‰ï¼Œå¤´ä¸€ç»„çš„ä¸¤ä¸ªBlocksä¸­å„15ä¸ªCodewordsæ•°æ® + å„ 18ä¸ªCodewordsçš„çº é”™ç ã€‚ä¸‹å›¾ç»™ä¸€ä¸ª5-Qçš„ç¤ºä¾‹ï¼ˆå› ä¸ºäºŒè¿›åˆ¶å†™èµ·æ¥ä¼šè®©è¡¨æ ¼å¤ªå¤§ï¼Œæ‰€ä»¥éƒ½ç”¨äº†åè¿›åˆ¶ï¼‰ï¼š</p><table><colgroup><col style="width: 4%"><col style="width: 4%"><col style="width: 45%"><col style="width: 45%"></colgroup><thead><tr class="header"><th>ç»„</th><th>å—</th><th>æ•°æ®</th><th>çº é”™ç </th></tr></thead><tbody><tr class="odd"><td>1</td><td>1</td><td>67 85 70 134 87 38 85 194 119 50 6 18 6 103 38</td><td>213 199 11 45 115 247 241 223 229 248 154 117 154 111 86 161 111 39</td></tr><tr class="even"><td>1</td><td>2</td><td>246 246 66 7 118 134 242 7 38 86 22 198 199 146 6</td><td>87 204 96 60 202 182 124 157 200 134 27 129 209 17 163 163 120 133</td></tr><tr class="odd"><td>2</td><td>1</td><td>182 230 247 119 50 7 118 134 87 38 82 6 134 151 50 7</td><td>148 116 177 212 76 133 75 242 238 76 195 230 189 10 108 240 192 141</td></tr><tr class="even"><td>2</td><td>2</td><td>70 247 118 86 194 6 151 50 16 236 17 236 17 236 17 236</td><td>235 159 5 173 24 147 59 33 106 40 255 172 82 2 131 32 178 236</td></tr></tbody></table><h4><span id="reed-solomon-code">Reed Solomon Code</span></h4><p>å…³äºæ¯ä¸€å—çš„çº é”™ç æ˜¯æ€ä¹ˆæ¥çš„ï¼Œå®ƒæ˜¯é€šè¿‡<a href="http://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction" target="_blank" rel="noopener">Reed-Solomon error correction</a>ï¼ˆé‡Œå¾·-æ‰€ç½—é—¨çº é”™ç®—æ³•ï¼‰å®ç°çš„ï¼Œè¿™ä¸ªåœ°æ–¹åº”è¯¥æ˜¯äºŒç»´ç æœ€éš¾çš„åœ°æ–¹äº†ã€‚RSç æ˜¯åŸºäº <a href="https://www.wikiwand.com/en/Finite_field" target="_blank" rel="noopener">æœ‰é™åŸŸ</a>çš„ç¼–ç ï¼Œè¿™ç‚¹å’Œ<a href="https://www.wikiwand.com/en/Cyclic_redundancy_check" target="_blank" rel="noopener">CRCå¾ªç¯å†—ä½™æ ¡éªŒ</a>æ˜¯ä¸€æ ·çš„ã€‚</p><p>åœ¨è¿™ä¸ªæœ‰é™åŸŸ(<strong>GF(2)</strong>)ä¸­ï¼Œå››åˆ™è¿ç®—éƒ½æ˜¯æŒ‰æ¯”ç‰¹æ¨¡2çš„å››åˆ™è¿ç®—ï¼Œå³ä¸¤ä¸ªæ•°çš„åŠ å‡æ³•å°±æ˜¯æŒ‰ä½å¼‚æˆ–ï¼ˆæ²¡æœ‰è¿›ä½å’Œå€Ÿä½ï¼‰ï¼Œä¹˜æ³•å’Œé™¤æ³•çš„ç›¸åŠ è¿‡ç¨‹ä¹Ÿæ˜¯æ¨¡2åŠ æ³•ã€‚</p><p>æ¯ä¸€ä¸ªäºŒè¿›åˆ¶æ•°ï¼Œéƒ½å¯ä»¥è¡¨ç¤ºæˆä¸€ä¸ªå¤šé¡¹å¼ï¼Œæ¯ä¸€ä½ä»£è¡¨è¯¥é¡¹çš„ç³»æ•°ï¼Œç¬¬å‡ ä½ä»£è¡¨æŒ‡æ•°ï¼Œå¦‚100011101 å¯ä»¥è¡¨ç¤ºä¸º<span class="math inline">\(x^8 + x^4 + x^3 + x^2 + 1\)</span>ã€‚</p><p><strong>çº é”™ç å°±æ˜¯ç”¨æ•°æ®å¤šé¡¹å¼é™¤ä»¥æŸä¸€ä¸ªæœ¬åŸå¤šé¡¹å¼<span class="math inline">\(g(x)\)</span>å¾—åˆ°çš„ä½™æ•°</strong>ã€‚å…¶ä¸­ï¼Œæœ¬åŸå¤šé¡¹å¼æ˜¯ä»€ä¹ˆå°±ä¸å¤šå†è§£é‡Šï¼Œæœ‰å…´è¶£çš„è‡ªè¡Œäº†è§£ï¼Œåœ¨QR Code Specä¸­çš„é™„å½•Aä¸­æœ‰åˆ—å‡ºï¼›è¿™é‡Œé¢çš„é™¤æ³•æ˜¯æ¨¡2é™¤æ³•ã€‚</p><p>å…³äºå…·ä½“çº é”™æ–¹æ³•å’Œå®ç°å°±ä¸åœ¨è¿™é‡Œå±•å¼€ï¼Œé¦–å…ˆæˆ‘çš„ç†è§£å¾—ä¹Ÿä¸æ˜¯å¾ˆæ¸…æ¥šï¼Œå…¶æ¬¡è¿™é‡Œé¢æ¶‰åŠçš„ä¸œè¥¿å¤ªå¤šï¼Œå°¤å…¶æ˜¯æ•°å­¦çŸ¥è¯†ï¼Œéƒ½è¯´æ¸…æ¥šå¯èƒ½éœ€è¦ä¸“é—¨å†™ä¸€ç¯‡æ–‡ç« ã€‚</p><h3><span id="æœ€ç»ˆç¼–ç ">æœ€ç»ˆç¼–ç </span></h3><p>åœ¨ç”»å›¾å‰ï¼Œè¿˜éœ€è¦ä¸€æ­¥ç©¿æ’æ”¾ç½®çš„è¿‡ç¨‹ã€‚</p><p>å¯¹äºæ•°æ®ç ï¼šæŠŠæ¯ä¸ªå—çš„ç¬¬ä¸€ä¸ªCodewordså…ˆæ‹¿å‡ºæ¥æŒ‰é¡ºåº¦æ’åˆ—å¥½ï¼Œç„¶åå†å–ç¬¬ä¸€å—çš„ç¬¬äºŒä¸ªï¼Œå¦‚æ­¤ç±»æ¨ã€‚å¦‚ï¼Œä¸Šè¿°ç¤ºä¾‹ä¸­çš„ä¸€éƒ¨åˆ†Data Codewordså¦‚ä¸‹ï¼š</p><table><thead><tr class="header"><th style="text-align: center;">å—1</th><th>67</th><th>85</th><th>70</th><th>134</th><th>87</th><th>38</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">å— 2</td><td>246</td><td>246</td><td>66</td><td>7</td><td>118</td><td>134</td></tr><tr class="even"><td style="text-align: center;">å— 3</td><td>182</td><td>230</td><td>247</td><td>119</td><td>50</td><td>7</td></tr><tr class="odd"><td style="text-align: center;">å—4</td><td>70</td><td>247</td><td>118</td><td>86</td><td>194</td><td>6</td></tr></tbody></table><p>æˆ‘ä»¬å…ˆå–ç¬¬ä¸€åˆ—çš„ï¼š67ï¼Œ 246ï¼Œ 182ï¼Œ 70 ç„¶åå†å–ç¬¬äºŒåˆ—çš„ï¼š67ï¼Œ 246ï¼Œ 182ï¼Œ 70ï¼Œ 85ï¼Œ246ï¼Œ230 ï¼Œ247 å¦‚æ­¤ç±»æ¨ï¼š67ï¼Œ 246ï¼Œ 182ï¼Œ 70ï¼Œ 85ï¼Œ246ï¼Œ230 ï¼Œ247 â€¦â€¦â€¦ Â â€¦â€¦â€¦ ï¼Œ38ï¼Œ6ï¼Œ50ï¼Œ17ï¼Œ7ï¼Œ236</p><p>å¯¹äºçº é”™ç ï¼Œä¹Ÿæ˜¯ä¸€æ ·çš„è¿‡ç¨‹ï¼Œç„¶åï¼Œå†æŠŠè¿™ä¸¤ç»„æ”¾åœ¨ä¸€èµ·ï¼ˆçº é”™ç æ”¾åœ¨æ•°æ®ç ä¹‹åï¼‰å¾—åˆ°ï¼š</p><p>67, 246, 182, 70, 85, 246, 230, 247, 70, 66, 247, 118, 134, 7, 119, 86, 87, 118, 50, 194, 38, 134, 7, 6, 85, 242, 118, 151, 194, 7, 134, 50, 119, 38, 87, 16, 50, 86, 38, 236, 6, 22, 82, 17, 18, 198, 6, 236, 6, 199, 134, 17, 103, 146, 151, 236, 38, 6, 50, 17, 7, 236, 213, 87, 148, 235, 199, 204, 116, 159, 11, 96, 177, 5, 45, 60, 212, 173, 115, 202, 76, 24, 247, 182, 133, 147, 241, 124, 75, 59, 223, 157, 242, 33, 229, 200, 238, 106, 248, 134, 76, 40, 154, 27, 195, 255, 117, 129, 230, 172, 154, 209, 189, 82, 111, 17, 10, 2, 86, 163, 108, 131, 161, 163, 240, 32, 111, 120, 192, 178, 39, 133, 141, 236</p><p>è¿™å°±æ˜¯æˆ‘ä»¬çš„æ•°æ®åŒºã€‚</p><p><strong>Remainder Bits</strong></p><p>å¯¹äºæŸäº›Versionçš„äºŒç»´ç ï¼Œä¸Šé¢çš„è¿˜ä¸å¤Ÿé•¿åº¦ï¼Œè¿˜è¦åŠ ä¸ŠRemainder Bitsã€‚æ¯”å¦‚ï¼šä¸Šè¿°çš„5Qç‰ˆçš„äºŒç»´ç ï¼Œè¿˜è¦åŠ ä¸Š7ä¸ªbitsï¼ŒRemainder BitsåŠ é›¶å°±å¥½äº†ã€‚å…³äºå“ªäº›Versionéœ€è¦å¤šå°‘ä¸ªRemainder bitï¼Œå¯ä»¥å‚çœ‹QR Code Specçš„Table-1çš„å®šä¹‰è¡¨ã€‚</p><hr><h2><span id="ç”»äºŒç»´ç å›¾">ç”»äºŒç»´ç å›¾</span></h2><p><strong>Finder Pattern</strong></p><p>ç»ˆäºåˆ°äº†æ¿€åŠ¨äººå¿ƒçš„ç”»å›¾ç¯èŠ‚ã€‚é¦–å…ˆï¼Œå…ˆæŠŠPosition Detectionå›¾æ¡ˆç”»åœ¨ä¸‰ä¸ªè§’ä¸Šï¼Œæ— è®ºVersionå¦‚ä½•ï¼Œè¿™ä¸ªå›¾æ¡ˆçš„å°ºå¯¸å°±æ˜¯è¿™ä¹ˆå¤§ï¼š</p><p><img src="/images/finder.png"></p><p>æ¥ç€ç”¨ HELLO WORLD çš„ä¾‹å­ï¼Œç”»å®Œä¹‹åå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/draw_finder.png"></p><p><strong>Alignment Pattern</strong></p><p>ç„¶åï¼Œå†æŠŠAlignmentå›¾æ¡ˆç”»ä¸Šï¼Œæ— è®ºVersionå¦‚ä½•ï¼Œè¿™ä¸ªå›¾æ¡ˆçš„å°ºå¯¸å°±æ˜¯è¿™ä¹ˆå¤§ï¼š</p><p><img src="/images/alignment-pattern.png"></p><p>å…³äºAlignmentçš„ä½ç½®ï¼Œå¯ä»¥æŸ¥çœ‹QR Code Specçš„ç¬¬83é¡µçš„Table-E.1çš„å®šä¹‰è¡¨ï¼Œä¸‹é¢æ˜¯è¯¥è¡¨çš„ä¸€éƒ¨åˆ†ï¼š</p><p><img src="/images/tableE.png"></p><p>ä¸¾ä¸ªä¾‹å­ï¼ŒVersion 2 çš„å€¼æ˜¯6å’Œ18ã€‚å› æ­¤ Alignment Pattern çš„ä½ç½®åº”ä»¥(è¡Œï¼Œåˆ—)çš„ (18, 18) ä¸ºä¸­å¿ƒï¼Œå› ä¸º (6, 6), (6, 18), (18, 6) å’Œ Finder Patterns çš„ä½ç½®å†²çªï¼Œæ‰€ä»¥åªå‰©ä¸€ä¸ªã€‚</p><p>ç”»å®Œå¦‚ä¸‹ï¼š</p><p><img src="/images/draw_align.png"></p><p><strong>Timing Pattern</strong></p><p>æ¥ä¸‹æ¥æ˜¯Timing Patternçš„é»‘ç™½ç›¸é—´çš„çº¿ï¼š</p><p><img src="/images/Timing-Pattern.png"></p><p>ç”»å®Œå¦‚ä¸‹ï¼š</p><p><img src="/images/draw_timing.png"></p><p><strong>Format Information</strong></p><p>å†æ¥ä¸‹æ¥æ˜¯Formation Informationï¼Œä¸‹å›¾ä¸­çš„è“è‰²éƒ¨åˆ†:</p><p><img src="/images/Format-Information.png"></p><p>Format Informationæ˜¯ä¸€ä¸ª15ä¸ªbitsçš„ä¿¡æ¯ï¼Œæ¯ä¸€ä¸ªbitçš„ä½ç½®å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/format.png"></p><p>æ³¨1ï¼šå›¾ä¸­çš„Dark Moduleï¼Œé‚£æ˜¯æ°¸è¿œå‡ºç°çš„ æ³¨2ï¼šå›¾ä¸­çš„ç¬¬14ä½æ˜¯æœ€é«˜ä½ï¼ˆThe Most Significant Bitï¼‰ï¼Œç¬¬0ä½æ˜¯æœ€ä½ä½ï¼ˆThe Least significant bitï¼‰ï¼Œå³å¦‚æœä½ å¾—åˆ°çš„ç»“æœæ˜¯100100001101000ï¼Œé‚£ä¹ˆç¬¬14ä½åº”è¯¥æ˜¯1ï¼Œç¬¬0ä½åº”è¯¥æ˜¯0.</p><p>è¿™15ä¸ªbitsä¸­åŒ…æ‹¬ï¼š</p><ul><li><p>5ä¸ªæ•°æ®bitsï¼šå…¶ä¸­ï¼Œ2ä¸ªbitsç”¨äºè¡¨ç¤ºä½¿ç”¨ä»€ä¹ˆæ ·çš„Error Correction Levelï¼Œ 3ä¸ªbitsè¡¨ç¤ºä½¿ç”¨ä»€ä¹ˆæ ·çš„Maskï¼Œæ¯ä¸ªçº é”™çº§åˆ«çš„æ ‡è¯†ç¬¦å¦‚Table25æ‰€ç¤º:</p><p><img src="/images/table25.png"></p></li><li><p>10ä¸ªçº é”™bitsï¼Œé€šè¿‡BCHç æ¥è®¡ç®—ã€‚BCHç ä¹Ÿæ˜¯ä¸€ç§æ¯”è¾ƒéº»çƒ¦çš„ç¼–ç ï¼ŒRSç æ˜¯BCHç çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œæœ‰å…´è¶£çš„è¯»è€…è‡ªå·±äº†è§£ä¸€ä¸‹ã€‚</p></li></ul><p>æœ€åè¿™15ä¸ªbitsè¿˜è¦ä¸101010000010010åšXORæ“ä½œï¼Œè¿™æ ·å°±ä¿è¯ä¸ä¼šå› ä¸ºæˆ‘ä»¬é€‰ç”¨äº†00çš„çº é”™çº§åˆ«å’Œ000çš„Maskï¼Œä»è€Œé€ æˆå…¨éƒ¨ä¸ºç™½è‰²ï¼Œè¿™ä¼šå¢åŠ æˆ‘ä»¬çš„æ‰«æå™¨çš„å›¾åƒè¯†åˆ«çš„å›°éš¾ã€‚</p><p>ä¸¾ä¸ªä¾‹å­ï¼š</p><p>å‡è®¾çº é”™çº§åˆ«æ˜¯Mï¼š 00 Maskæ ‡è¯†ç¬¦ï¼š 101 æ•°æ®ï¼š 00101 BCHç ï¼š 0011011100 æ©ç ï¼š 101010000010010 ä¸æ©ç å¼‚æˆ–ï¼š 100000011001110</p><p>ç”»å®Œå¦‚ä¸‹ï¼š</p><p><img src="/images/draw_format.png"></p><p><strong>Version Information</strong></p><p>Version7ä»¥åéœ€è¦è¿™ä¸ªç¼–ç ï¼Œä¸‹å›¾ä¸­çš„è“è‰²éƒ¨åˆ†ï¼š</p><p><img src="/images/Version-Information.png"></p><p>Version Informationä¸€å…±æ˜¯18ä¸ªbitsï¼Œå…¶ä¸­åŒ…æ‹¬6ä¸ªbitsçš„ç‰ˆæœ¬å·ä»¥åŠ12ä¸ªbitsçš„çº é”™ç ï¼Œå…·ä½“æ€ä¹ˆæ”¾çš„æœ‰éœ€è¦çš„å¯ä»¥å»çœ‹QR Code Specç¬¬54é¡µçš„8.10èŠ‚ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚</p><p><strong>æ•°æ®ç å’Œçº é”™ç </strong></p><p>é‡å¤´æˆæ¥äº†ï¼Œç»ˆäºå¯ä»¥æ­£è€Œå…«ç»åœ°å¡«å……æ•°æ®äº†ã€‚</p><p>æ•°æ®æ˜¯ä¸€å—ä¸€å—å¡«å……çš„ï¼Œæ¯ä¸€å—åº”è¯¥æ˜¯ä¸€ä¸ªçŸ©å½¢ï¼ˆæ¯”è¾ƒç†æƒ³çš„æƒ…å†µï¼‰ï¼Œä¸€å—æœ‰8ä¸ªbitæ­£å¥½å¯¹åº”ä¸€ä¸ªCodewordã€‚ä¸¾ä¸ªä¾‹å­ï¼ŒVersion2çš„æ•°æ®å¡«å……åº”è¯¥æ˜¯è¿™ä¸ªæ ·å­ï¼š</p><p><img src="/images/v2.png"></p><p>çœ‹èµ·æ¥æ˜¯ä¸æ˜¯æœ‰ç‚¹å¤æ‚ï¼Ÿ</p><p>æˆ‘ä»¬çœ‹åˆ°D1~D9éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢ï¼Œå…¶ä»–çš„å°±ä»€ä¹ˆæƒ…å†µéƒ½æœ‰äº†ï¼Œä¸‹é¢æ¥å…·ä½“çœ‹çœ‹æ¯ä¸€å°å—è¯¥æ€ä¹ˆå¡«ã€‚</p><p>æ¯ä¸€ç§æ•°æ®å—çš„å¡«å……éƒ½æœ‰ä¸¤ç§æ¨¡å¼ï¼Œåˆ†åˆ«æ˜¯ä¸Šå‡å’Œä¸‹é™ï¼Œå…ˆçœ‹æ™®é€šçš„çŸ©å½¢ï¼š</p><p><img src="/images/rect.png"></p><p>æ³¨æ„ï¼Œè¿™é‡Œé¢çš„ç¬¬0ä½æ˜¯æ¯ä¸ªCodewordçš„æœ€ä½ä½ï¼ˆthe least significant bitï¼‰ï¼Œè€Œç¬¬7ä½æ˜¯æœ€é«˜ä½ï¼ˆthe most significant bitï¼‰ï¼Œä¸è¦æé”™äº†ã€‚</p><p>ç”±äºæˆ‘ä»¬éœ€è¦æŠ˜è¿”ç€å¡«ï¼Œæ‰€ä»¥åœ¨è½¬å‘çš„æ—¶å€™å¯èƒ½å‡ºç°ä¸‹é¢çš„æƒ…å†µï¼š</p><p><img src="/images/turn.png"></p><p>è€Œä¸”æˆ‘ä»¬å¡«å……çš„æ—¶å€™è¿˜ä¸èƒ½æ›¿æ¢äº†åŠŸèƒ½åŒºçš„å€¼ï¼Œæ‰€ä»¥è¿˜è¦ç»•è¿‡å»ï¼š</p><p><img src="/images/go.png"></p><p>å°±è¿™å‡ ç§æƒ…å†µï¼Œçœ‹ä¸Šå»æœ‰ç‚¹å¤æ‚ï¼Œç¼–ç¨‹ä¸å¥½å®ç°ï¼Œä½†å®é™…ä¸Šè‡ªå·±åªè¦å®é™…å†™å†™çœ‹å°±ä¼šå‘ç°å¡«å……è§„å¾‹æ˜¯<strong>ç›¸åŒ</strong>çš„ï¼šä»å³ä¸‹è§’å¼€å§‹æ²¿ç€çº¢çº¿å¡«æˆ‘ä»¬çš„å„ä¸ªbitsï¼Œ1æ˜¯é»‘è‰²ï¼Œ0æ˜¯ç™½è‰²ã€‚å¦‚æœé‡åˆ°äº†ä¸Šé¢çš„éæ•°æ®åŒºï¼Œåˆ™ç»•å¼€æˆ–è·³è¿‡ã€‚</p><p><img src="/images/Data-Placement.png"></p><p>ç”»å®Œå¦‚ä¸‹ï¼š</p><p><img src="/images/draw_data.png"></p><p><strong>Mask</strong></p><p>è¿™æ ·ä¸‹æ¥ï¼Œæˆ‘ä»¬çš„å›¾å°±å¡«å¥½äº†ï¼Œä½†æ˜¯ï¼Œä¹Ÿè®¸é‚£äº›ç‚¹å¹¶ä¸å‡è¡¡ï¼Œå¦‚æœå‡ºç°å¤§é¢ç§¯çš„ç©ºç™½æˆ–é»‘å—ï¼Œä¼šå‘Šè¯‰æˆ‘ä»¬æ‰«æè¯†åˆ«çš„å›°éš¾ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬è¿˜è¦åšMaskingæ“ä½œã€‚QR Code Specä¸­è¯´äº†ï¼ŒQRç æœ‰8ä¸ªMaskä½ å¯ä»¥ä½¿ç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p><p><img src="/images/mask.png"></p><p>æ¯ä¸ªå›¾ä¸‹é¢çš„æ•°å­—æ ‡è¯†ç¬¦ï¼Œå…¬å¼æ˜¯å¯¹åº”çš„æ¡ä»¶ï¼Œå½“æ¡ä»¶æ»¡è¶³æ—¶ï¼Œè¯¥ç‚¹æ˜¯é»‘çš„ã€‚</p><p>ç”Ÿæˆå¥½ç›¸åº”maskä¹‹åï¼Œå°±å’ŒåŸå§‹å¡«å……å¥½çš„å›¾æ¡ˆè¿›è¡Œå¼‚æˆ–æ“ä½œï¼Œæ³¨æ„maskä¸èƒ½å’ŒåŠŸèƒ½åŒºå¼‚æˆ–ï¼Œåªèƒ½å’Œæ•°æ®åŒºè¿›è¡Œå¼‚æˆ–ã€‚</p><p>Maskè¿‡åçš„äºŒç»´ç å°±æˆæœ€ç»ˆçš„å›¾äº†ï¼š</p><p><img src="/images/draw_mask.png"></p><h2><span id="å®è·µ">å®è·µ</span></h2><p>æ ¹æ®ä¸Šé¢çš„æµç¨‹å†åŠ ä¸ŠQR Code Specï¼Œæˆ‘ä»¬å°±å¯ä»¥ç¼–ç å®ç°ç”ŸæˆäºŒç»´ç äº†ï¼</p><p>è¿™é‡Œé™„ä¸Šæˆ‘åšçš„<a href="https://github.com/NeymarL/qr-code" target="_blank" rel="noopener">demo</a>ã€‚</p><p><img src="/images/github.png"></p><h2><span id="å‚è€ƒ">å‚è€ƒ</span></h2><p><a href="http://www.codeplex.com/Download?ProjectName=qrcodenet&amp;DownloadId=284291" target="_blank" rel="noopener">ISO/IEC 18004:2000(E) - QR code specificationÂ </a></p><p><a href="http://coolshell.cn/articles/10590.html" target="_blank" rel="noopener">äºŒç»´ç çš„ç”Ÿæˆç»†èŠ‚å’ŒåŸç†</a></p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> QR Code </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Context Encoder</title>
      <link href="/2016/10/23/Context%20Encoder/"/>
      <url>/2016/10/23/Context%20Encoder/</url>
      
        <content type="html"><![CDATA[<p>å‰ä¸¤å¤©çœ‹äº†ä¸€ä¸‹Context Encoderçš„ç›¸å…³è®ºæ–‡ï¼Œè¿™ä¸ªä¸œè¥¿å¯ä»¥ç”¨äºç†è§£å›¾ç‰‡çš„è¯­ä¹‰ï¼Œæ¯”å¦‚<strong>å¡«è¡¥å›¾ç‰‡çš„ç¼ºå¤±åŒºåŸŸ</strong>ã€‚æˆ‘åªç ”ç©¶å‡ºäº†å®ƒå¤§æ¦‚æ€ä¹ˆåšçš„ï¼Œæœ‰äº›ç»†èŠ‚è¿˜æ²¡ææ‡‚ï¼Œä»¥æ­¤è®°å½•ä¸€ä¸‹ã€‚</p><a id="more"></a><h2><span id="overall">Overall</span></h2><p>æ•´ä½“ç½‘ç»œç”±ä¸¤éƒ¨åˆ†æ„æˆï¼Œåˆ†åˆ«æ˜¯ç¼–ç å™¨(Encoder)å’Œè§£ç å™¨(Decoder)ï¼Œä¸­é—´ç”±Channel-wise fully-connected layer è¿æ¥ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><p><img src="/images/CD-structure.png"></p><h2><span id="encoder">Encoder</span></h2><p>ç¼–ç å™¨ç”¨äºä»å›¾ç‰‡æå–é«˜ç»´ç‰¹å¾ï¼Œå…¶ç»“æ„æ¥è‡ª <em>AlexNet</em> çš„å‰5ä¸ªå·ç§¯å±‚å’Œç›¸åº”çš„æ± åŒ–å±‚(<em>pool5</em>)ï¼Œå¹¶éšæœºåˆå§‹åŒ–æƒé‡ã€‚</p><h2><span id="channel-wise-fully-connected-layer">Channel-wise fully-connected layer</span></h2><p>ä¸ºäº†èƒ½ç»¼åˆå„ä¸ª feature map çš„ä¿¡æ¯ï¼Œé€šå¸¸æ˜¯ç”¨å…¨è¿æ¥å±‚(fully-connected layer)æ¥åšï¼Œä½†æ˜¯è¿™ä¹ˆåšçš„è¯å‚æ•°å¤ªå¤šäº†ï¼Œè®­ç»ƒæ¯”è¾ƒå›°éš¾ï¼Œäºæ˜¯å°±é‡‡ç”¨åˆ†ç»„çš„ç­–ç•¥ã€‚</p><p>å‡è®¾æœ‰ <span class="math inline">\(m\)</span> ä¸ª feature mapï¼Œæ¯ä¸ªfeature mapçš„å¤§å°æ˜¯ <span class="math inline">\(n*n\)</span>ï¼Œè¯¥å±‚è¾“å‡ºä¹Ÿæ˜¯ <span class="math inline">\(m\)</span> ä¸ª feature mapï¼Œæ¯ä¸ªå¤§å°ä¸º <span class="math inline">\(n*n\)</span>ï¼Œ ä½†æ˜¯ä¸å…¨è¿æ¥ä¸åŒçš„æ˜¯ï¼Œæ¯ä¸ªfeature map åªå’Œè‡ªå·±å…¨è¿æ¥ï¼Œä¸å’Œå…¶ä»–feature mapè¿æ¥ï¼Œè¿™æ ·çš„è¯éœ€è¦çš„å‚æ•°æ˜¯ <span class="math inline">\(mn^4\)</span>ï¼Œç›¸è¾ƒäºå…¨è¿æ¥å±‚çš„ <span class="math inline">\(m^2n^4\)</span>ã€‚</p><h2><span id="decoder">Decoder</span></h2><p>è§£ç å™¨æ˜¯ä½¿ç”¨ç¼–ç å™¨çš„ç‰¹å¾ç”Ÿæˆç¼ºå¤±çš„å›¾åƒã€‚ç”Ÿæˆå›¾åƒä½¿ç”¨ <em>up-convolutinal/upsampling layers</em>ï¼Œæ¯å±‚åè·Ÿä¸€ä¸ªçº¿æ€§æ•´æµ(ReLU)å±‚ã€‚</p><p>up-convolutinalå¯ä»¥è¢«ç†è§£ä¸ºå…ˆåæ± åŒ–å†å·ç§¯(<em>unpooling+convolution</em>)ã€‚åæ± åŒ–å°±æ˜¯æ± åŒ–çš„é€†è¿‡ç¨‹ï¼ŒæŠŠä¸€ä¸ªå¤§å°ä¸º <span class="math inline">\(s*s\)</span> çš„feature mapåæ± åŒ–ï¼Œåªéœ€æŠŠæ¯ä¸ªåƒç´ å˜ä¸º <span class="math inline">\(s*s\)</span> çš„åƒç´ å—ï¼Œåªæœ‰æ¯ä¸ªå—å·¦ä¸Šè„šçš„åƒç´ å’ŒåŸæ¥ä¸€æ ·ï¼Œå…¶ä»–å€¼ä¸º0ï¼Œå¦‚ <span class="math inline">\(s = 2\)</span> çš„åæ± åŒ–å¦‚ä¸‹å›¾(å·¦)æ‰€ç¤ºï¼š</p><p><img src="/images/unpooling.png"></p><p>å®ƒè¿˜å¯ä»¥è¢«ç†è§£æˆæ˜¯æ­¥é•¿(stride)ä¸ºå°æ•°çš„å·ç§¯å±‚ï¼šæ­£å¸¸çš„å·ç§¯å±‚æ­¥é•¿ä¸ºä¸€ä¸ªæ•´æ•° <span class="math inline">\(f\)</span>ï¼Œé‚£ä¹ˆé€†å·ç§¯å±‚(<em>deconvolutin/up-convolutinal layers</em>) å°±ç›¸å½“äºæ˜¯æ­¥é•¿ä¸º <span class="math inline">\(\frac{1}{f}\)</span> çš„å·ç§¯å±‚ã€‚å®ç°é€†å·ç§¯å±‚çš„ä¸€ä¸ªè‡ªç„¶åŠæ³•å°±æ˜¯å®ç°ä¸€ä¸ªæ­¥é•¿ä¸º <span class="math inline">\(f\)</span> çš„å‘åå·ç§¯(<em>backwards convolution</em>)ï¼Œåªç”¨ç®€å•åœ° reverses the forward and backward passes of convolution(è®ºæ–‡é‡Œè¿™ä¹ˆå†™çš„ï¼Œä¸æ˜¯å¾ˆæ‡‚ä»€ä¹ˆæ„æ€)ã€‚</p><p>è§£ç å¯ä»¥é€šè¿‡æ·»åŠ ä¸€ç³»åˆ—è¿™æ ·çš„ <em>upsampling layers</em> å®ç°ï¼Œç›´åˆ°ç”Ÿæˆçš„å›¾åƒè¾¾åˆ°ç›®æ ‡å¤§å°ã€‚</p><h2><span id="loss-function">Loss function</span></h2><p>æ•´ä¸ªç½‘ç»œçš„æŸå¤±å‡½æ•°ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œä¸€éƒ¨åˆ†æ˜¯é‡å»ºæŸå¤±(<em>reconstruction loss</em>)ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯å¯¹æŠ—æŸå¤±(<em>adversarial loss</em>)ã€‚</p><p><strong>é‡å»ºæŸå¤±</strong>æ˜¯ä¸€ä¸ªL2æŸå¤±ï¼Œä¸ºäº†æ•è·ç¼ºå¤±åŒºåŸŸçš„æ•´ä½“ç»“æ„å¹¶ä¸”ä¿æŒä¸Šä¸‹æ–‡çš„è¿ç»­æ€§ï¼Œä½†æ˜¯L2æŸå¤±åœ¨é¢„æµ‹æ—¶è¶‹å‘äºå‡å€¼ï¼Œå¦‚æœåªç”¨L2æŸå¤±ï¼Œé¢„æµ‹å‡ºæ¥å°±éå¸¸æ¨¡ç³Šï¼Œå¦‚ä¸‹å›¾(c)æ‰€ç¤ºã€‚<strong>å¯¹æŠ—æŸå¤±</strong>å°±æ˜¯ä¸ºäº†ä½¿é¢„æµ‹ç»“æœæ›´åŠ çœŸå®ï¼Œå®ƒæœ‰ä»åˆ†å¸ƒä¸­æŒ‘é€‰å‡ºä¸€ä¸ªç‰¹å®šæ¨¡å¼çš„æ•ˆæœã€‚</p><p><img src="/images/loss.png"></p><p>å¯¹äºæ¯ä¸ªå›¾ç‰‡ <span class="math inline">\(x\)</span>ï¼Œé€ç»™æ•´ä¸ªç¼–ç å™¨ <span class="math inline">\(F\)</span> å»è®­ç»ƒï¼Œäº§ç”Ÿæœ€ç»ˆç»“æœè®°ä¸º <span class="math inline">\(F(x)\)</span>ã€‚ä»¤ <span class="math inline">\(\hat{M}\)</span> ä¸ºä¸€ä¸ªäºŒè¿›åˆ¶æ©ç çŸ©é˜µï¼Œå›¾ç‰‡çš„ç¼ºå¤±åŒºåŸŸå€¼ä¸º1ï¼Œå…¶ä»–åŒºåŸŸä¸º0 ã€‚é‚£ä¹ˆæˆ‘ä»¬å®é™…é€ç»™ç¼–ç å™¨è®­ç»ƒçš„å›¾ç‰‡å°±æ˜¯ <span class="math inline">\((1-\hat{M})\odot x\)</span> ï¼Œå…¶ä¸­ <span class="math inline">\(\odot\)</span> ä¸ºæŒ‰ä½ç›¸ä¹˜ã€‚</p><p><strong>Reconstruction Loss</strong></p><p>é‚£ä¹ˆé‡å»ºæŸå¤±çš„è¡¨è¾¾å¼å°±ä¸ºï¼š <span class="math display">\[L_{rec}(x) = ||\hat{M}\odot(x-F((1-\hat{M})\odot x))||^2_2\]</span> è®ºæ–‡ä¸­è¯´ä½¿ç”¨L1æŸå¤±å’ŒL2æŸå¤±å·®åˆ«ä¸å¤§ã€‚å°½ç®¡è¿™ä¸ªæŸå¤±å¾ˆç®€å•ï¼Œä½†å®ƒèƒ½ä¿ƒä½¿è§£ç å™¨ç”Ÿæˆé¢„æµ‹ç›®æ ‡çš„å¤§è‡´è½®å»“ï¼Œä¸€èˆ¬ä¸èƒ½ç”Ÿæˆé«˜é¢‘çš„ç»†èŠ‚ï¼Œå¦‚ä¸Šå›¾(c)æ‰€ç¤ºã€‚æˆ‘ä»¬è§‰å¾—å‡ºç°è¿™ç§æƒ…å†µæ˜¯å› ä¸ºé¢„æµ‹ä¸€ä¸ªåˆ†å¸ƒçš„å¹³å‡å€¼å¯¹L2æŸå¤±æ¥è¯´æ›´åŠ â€œå®‰å…¨â€ï¼Œå› ä¸ºè¿™æ ·èƒ½æœ€å°åŒ–æ¯ä¸ªåƒç´ çš„å¹³å‡è¯¯å·®ï¼Œä½†è¿™æ ·å°±ä¼šå¯¼è‡´æ¨¡ç³Šçš„ç»“æœã€‚</p><p><strong>Adverarial Loss</strong></p><p>ä¸ºäº†å‡è½»ä¸Šé¢çš„é—®é¢˜ï¼Œæˆ‘ä»¬åˆåŠ äº†ä¸€ä¸ªå¯¹æŠ—æŸå¤±ã€‚</p><p>å¯¹æŠ—æŸå¤±åŸºäº <em>Generative Adversarial Networks(GAN)</em>ï¼ŒåŸå§‹GANæ˜¯è¿™æ ·çš„ï¼šä¸ºäº†ä¸€ä¸ªä½¿<strong>ç”Ÿæˆæ¨¡å‹</strong> <span class="math inline">\(G\)</span> å­¦ä¹ æŸç§æ•°æ®åˆ†å¸ƒï¼ŒGANåŒæ—¶è®­ç»ƒä¸€ä¸ªä¸ä¹‹å¯¹æŠ—çš„<strong>åˆ¤åˆ«æ¨¡å‹</strong> <span class="math inline">\(D\)</span> æ¥æä¾› <span class="math inline">\(G\)</span> çš„æŸå¤±ã€‚<span class="math inline">\(G\)</span> å’Œ <span class="math inline">\(D\)</span> éƒ½æ˜¯ parametric functionï¼Œå…¶ä¸­ <span class="math inline">\(G\)</span> æ˜¯ä¸€ä¸ªä»å™ªå£°åˆ†å¸ƒ <span class="math inline">\(Z\)</span> åˆ°æ•°æ®åˆ†å¸ƒ <span class="math inline">\(\chi\)</span> çš„æ˜ å°„ã€‚å­¦ä¹ è¿‡ç¨‹å°±æ˜¯åˆ¤åˆ«æ¨¡å‹ <span class="math inline">\(D\)</span> æ¥æ”¶ <span class="math inline">\(G\)</span> çš„è¾“å‡ºå’ŒçœŸå®æ ·ä¾‹ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°è¯•åŒºåˆ†å®ƒä»¬ï¼Œè¾“å‡ºå“ªä¸ªæ˜¯çœŸå®æ ·æœ¬å“ªä¸ªæ˜¯ç”Ÿæˆå‡ºæ¥çš„ï¼Œè€Œ <span class="math inline">\(G\)</span> çš„ç›®æ ‡å°±æ˜¯é€šè¿‡è¾“å‡ºç»“æœå°½å¯èƒ½æ¥è¿‘â€œçœŸå®â€æ¥æ··æ·† <span class="math inline">\(D\)</span> çš„åˆ¤æ–­ã€‚</p><p>æ‰€ä»¥ GAN çš„ç›®æ ‡å°±ä¸ºï¼š <span class="math display">\[\min_G\max_D E_{x\in \chi}[\log(D(x))] + E_{z\in Z}[\log(1-D(G(z)))]\]</span> è¿™é‡Œè¾¹çš„ <span class="math inline">\(E\)</span> æ˜¯ä»€ä¹ˆæ„æ€æ²¡æœ‰ææ‡‚ï¼Œæ„Ÿè§‰ä¸åƒæ˜¯æ•°å­¦æœŸæœ›çš„æ„æ€ã€‚å¦‚æœæŠŠ <span class="math inline">\(G\)</span> å’Œ <span class="math inline">\(D\)</span> çš„ç›®æ ‡åˆ†å¼€æ¥å†™çš„è¯ï¼Œé‚£ <span class="math inline">\(D\)</span> çš„ç›®æ ‡å°±æ˜¯ï¼š <span class="math display">\[\max_D E_{x\in \chi}[\log(D(x))] + E_{z\in Z}[\log(1-D(G(z)))]\]</span> <span class="math inline">\(G\)</span> çš„ç›®æ ‡æ˜¯ï¼š <span class="math display">\[\max_G E_{z\in Z}[\log(D(G(z)))]\]</span> å›åˆ°æˆ‘ä»¬çš„é—®é¢˜ï¼Œæ‰€ä»¥ context encoder çš„å¯¹æŠ—æŸå¤±å°±æ˜¯ï¼š <span class="math display">\[L_{adv} = \max_D E_{x\in \chi}[\log(D(x)) + \log(1-D(F((1-\hat{M})\odot x)))]\]</span> è¿™ä¸ªç›®æ ‡ä½¿å¾—æ•´ä¸ªç¼–ç å™¨çš„è¾“å‡ºçœ‹èµ·æ¥æ›´åŠ çœŸå®ã€‚</p><p><strong>Joint Loss</strong></p><p>æ‰€ä»¥æ•´ä½“çš„æŸå¤±å‡½æ•°å°±å®šä¹‰ä¸ºï¼š <span class="math display">\[L = \lambda_{rec}L_{rec} + \lambda_{adv}L_{adv}\]</span> åœ¨å¡«è¡¥å›¾ç‰‡ç¼ºå¤±åŒºåŸŸè¿™ä¸ªé—®é¢˜ä¸­ï¼Œè¶…å‚æ•°çš„é€‰æ‹©åˆ†åˆ«ä¸º <span class="math inline">\(\lambda_{rec} = 0.99\)</span> å’Œ <span class="math inline">\(\lambda_{adv} = 0.01\)</span>ã€‚</p><p>æ•´ä¸ªæ¨¡å‹çš„å¤§æ¦‚æ€ä¹ˆåšçš„å°±æ˜¯è¿™æ ·äº†ï¼Œå…·ä½“ç»†èŠ‚è¿˜éœ€è¦åœ¨çœ‹è®ºæ–‡å’Œä»£ç ã€‚</p><p>é™„ï¼š</p><p><img src="/images/network.png"></p><p>â€‹ é’ˆå¯¹Inpaintingä»»åŠ¡çš„å…·ä½“æ¨¡å‹</p><h2><span id="reference">Reference</span></h2><p><a href="https://arxiv.org/pdf/1604.07379v1" target="_blank" rel="noopener">Context Encoders: Feature Learning by Inpainting</a></p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi5yYCF4O7PAhUJlZQKHc1wB-YQFggvMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1406.2661&amp;usg=AFQjCNErq4Snyx25yb_clgYjWGAiFMYkow&amp;sig2=4ULZmy8sVRVUdboTQI-aKw" target="_blank" rel="noopener">I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NIPS, 2014.</a></p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi79s6p4O7PAhUHspQKHfVzC2IQFggwMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1411.5928&amp;usg=AFQjCNGPEI4w9KrBWZcicHemUf7CaHwZOw&amp;sig2=M2UUrea6sVMh7z5WUoxK_g" target="_blank" rel="noopener">A. Dosovitskiy, J. T. Springenberg, and T. Brox. Learning togenerate chairs with convolutional neural networks. CVPR,2015.</a></p><p><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html" target="_blank" rel="noopener">J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015</a></p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjFnubk4O7PAhXBmpQKHcnVBWkQFggfMAA&amp;url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&amp;usg=AFQjCNFlGsSmTUkJw0gLJ0Ry4cm961B7WA&amp;sig2=_qDaDLGSlvAoxbyfkxLeGA" target="_blank" rel="noopener">A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classification with deep convolutional neural networks. In NIPS, 2012</a></p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CV </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Random sample consensus</title>
      <link href="/2016/10/15/ransac/"/>
      <url>/2016/10/15/ransac/</url>
      
        <content type="html"><![CDATA[<p>éšæœºæŠ½æ ·ä¸€è‡´ï¼ˆ<strong>Random sample consensus</strong>Â ï¼Œ<strong>RANSAC</strong>ï¼‰æ˜¯ä¸€ç§è¿­ä»£æ–¹æ³•ï¼Œç”¨æ¥æ’é™¤å¼‚å¸¸æ•°æ®ï¼ˆoutliersï¼‰å¯¹æ¨¡å‹çš„å½±å“ã€‚</p><p>è¿™ä¸ªç®—æ³•åŸºäºä¸€ä¸ªåŸºæœ¬å‡è®¾ï¼šæ•°æ®é›†ä¸­æ­£å¸¸çš„æ ·æœ¬ï¼ˆinliersï¼‰å¯ä»¥å¾ˆå¥½åœ°æ‹Ÿåˆç»™å®šæ¨¡å‹ï¼Œå¼‚å¸¸æ•°æ®åˆ™ä¸è¡Œï¼Œæ¯”å¦‚å¼‚å¸¸æ ·æœ¬ä»£å…¥æ¨¡å‹æŸå¤±ä¼šå¾ˆå¤§ã€‚</p><a id="more"></a><h2><span id="algorithm">Algorithm</span></h2><p>ç®—æ³•ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼š</p><ol type="1"><li>ä»å…¨éƒ¨æ•°æ®é›†ä¸­éšæœºæŠ½å–ä¸€å°éƒ¨åˆ†ï¼Œæˆ‘ä»¬å‡è®¾è¿™éƒ¨åˆ†æ•°æ®éƒ½æ˜¯æ­£å¸¸çš„ï¼Œç”¨è¿™éƒ¨åˆ†æ•°æ®è®­ç»ƒæ¨¡å‹ã€‚é‡‡æ ·é›†çš„å¤§å°æ˜¯èƒ½è®­ç»ƒæ¨¡å‹çš„æœ€å°æ ·æœ¬æ•°ã€‚</li><li>ç”¨è¿™ä¸ªæ¨¡å‹æµ‹è¯•å…¶ä»–å‰©ä½™æ ·æœ¬ï¼Œå¦‚æœæŸä¸ªæ ·æœ¬çš„æŸå¤±å°äºæŸä¸ªé˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºå®ƒæ˜¯å’ŒæŠ½æ ·å‡ºçš„æ ·æœ¬æ˜¯ä¸€è‡´çš„ï¼Œå³ä¹Ÿæ˜¯æ­£å¸¸æ ·æœ¬ï¼›è‹¥æŸä¸ªæ ·æœ¬çš„æŸå¤±å¤§äºé˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºå®ƒæ˜¯å¼‚å¸¸æ ·æœ¬ã€‚</li></ol><p>æ‰€æœ‰æ­£å¸¸æ ·æœ¬çš„é›†åˆå«åšä¸€è‡´é›†ï¼ˆconsensus setï¼‰ï¼Œé‡å¤ä¸Šé¢ä¸¤ä¸ªæ­¥éª¤ï¼Œç›´åˆ°æ‰¾åˆ°ä¸€è‡´é›†ä¸­åŒ…å«è¶³å¤Ÿå¤šçš„æ ·æœ¬æˆ–è€…åˆ°è¾¾æœ€å¤§å¾ªç¯æ¬¡æ•°ã€‚</p><p>å…·ä½“æè¿°ï¼š</p><ol type="1"><li>ä»åŸå§‹æ•°æ®ä¸­é‡‡æ ·å‡ºä¸€ä¸ªå­é›†ï¼Œå‡è®¾ä¸ºæ­£å¸¸æ ·æœ¬é›†ã€‚</li><li>ç”¨ä¸Šè¿°å­é›†è®­ç»ƒæ¨¡å‹</li><li>ç”¨å…¶ä»–æ ·æœ¬æµ‹è¯•è¯¥æ¨¡å‹ã€‚å¯¹äºæ‹Ÿåˆå¾ˆå¥½çš„æ ·æœ¬ç‚¹ï¼Œå¯ä»¥é€šè¿‡æŸå¤±å°äºæŸä¸€é˜ˆå€¼æ¥åˆ¤æ–­ï¼ŒæŠŠå®ƒåŠ å…¥ä¸€è‡´é›†ã€‚</li><li>å¦‚æœä¸€è‡´é›†çš„æ ·æœ¬æœ‰è¶³å¤Ÿå¤šçš„æ ·æœ¬ï¼Œåˆ™è®¤ä¸ºè¯¥æ¨¡å‹å¾ˆå¥½ï¼Œæ‹Ÿåˆäº†å¤§éƒ¨åˆ†æ­£å¸¸æ ·æœ¬ã€‚</li><li>ç„¶åï¼Œç”¨ä¸€è‡´é›†å’Œé‡‡æ ·é›†ä¸­çš„æ ·æœ¬é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œè¿™ä¹Ÿè®¸ä¼šè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ•ˆæœï¼Œå¦‚æœæ•´ä½“æŸå¤±æ¯”ä¸Šæ¬¡è¿­ä»£å°ï¼Œåˆ™æ›´æ–°æœ€ä½³æ‹Ÿåˆæ¨¡å‹ã€‚</li><li>é‡å¤æ­¥éª¤1ï½5ï¼Œç›´åˆ°ä¸€è‡´é›†æ ·æœ¬è¶³å¤Ÿå¤šæˆ–è€…è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿”å›æœ€ä½³æ‹Ÿåˆæ¨¡å‹ã€‚</li></ol><p>ä¼ªä»£ç ï¼š</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Given:</span><br><span class="line">    data â€“ a set of observed data points</span><br><span class="line">    model â€“ a model that can be fitted to data points</span><br><span class="line">    n â€“ the minimum number of data values required to fit the model</span><br><span class="line">    k â€“ the maximum number of iterations allowed in the algorithm</span><br><span class="line">    t â€“ a threshold value <span class="keyword">for</span> determining when a data point fits a model</span><br><span class="line">    d â€“ the number of close data values required to assert that a model fits well to data</span><br><span class="line"></span><br><span class="line">Return:</span><br><span class="line">    bestfit â€“ model parameters which best fit the data (or nul <span class="keyword">if</span> no good model is found)</span><br><span class="line"></span><br><span class="line">iterations = <span class="number">0</span></span><br><span class="line">bestfit = nul</span><br><span class="line">besterr = something really large</span><br><span class="line"><span class="keyword">while</span> iterations &lt; k &#123;</span><br><span class="line">    maybeinliers = n randomly selected values from data</span><br><span class="line">    maybemodel = model parameters fitted to maybeinliers</span><br><span class="line">    alsoinliers = empty set</span><br><span class="line">    <span class="keyword">for</span> every point in data not in maybeinliers &#123;</span><br><span class="line">        <span class="keyword">if</span> point fits maybemodel with an error smaller than t</span><br><span class="line">             add point to alsoinliers</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> the number of elements in alsoinliers is &gt; d &#123;</span><br><span class="line">        <span class="comment">% this implies that we may have found a good model</span></span><br><span class="line">        <span class="comment">% now test how good it is</span></span><br><span class="line">        bettermodel = model parameters fitted to all points in maybeinliers and alsoinliers</span><br><span class="line">        thiserr = a measure of how well model fits these points</span><br><span class="line">        <span class="keyword">if</span> thiserr &lt; besterr &#123;</span><br><span class="line">            bestfit = bettermodel</span><br><span class="line">            besterr = thiserr</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    increment iterations</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> bestfit</span><br></pre></td></tr></table></figure><p>Pythonä»£ç ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ransac</span><span class="params">(data, model, n, k, t, d)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    data â€“ a set of observed data points</span></span><br><span class="line"><span class="string">    model â€“ a model that can be fitted to data points</span></span><br><span class="line"><span class="string">    n â€“ the minimum number of data values required </span></span><br><span class="line"><span class="string">    to fit the model</span></span><br><span class="line"><span class="string">    k â€“ the maximum number of iterations allowed </span></span><br><span class="line"><span class="string">    in the algorithm</span></span><br><span class="line"><span class="string">    t â€“ a threshold value for determining </span></span><br><span class="line"><span class="string">    when a data point fits a model</span></span><br><span class="line"><span class="string">    d â€“ the number of close data values required to </span></span><br><span class="line"><span class="string">    assert that a model fits well to data</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        bestfit â€“ model parameters which best fit the data </span></span><br><span class="line"><span class="string">          (or nul if no good model is found)</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    train_data_x = [[data[<span class="number">0</span>][i]] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data[<span class="number">0</span>]))]</span><br><span class="line">    train_data_y = data[<span class="number">1</span>]</span><br><span class="line">    iterations = <span class="number">0</span></span><br><span class="line">    bestfit = <span class="number">0</span></span><br><span class="line">    besterr = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">while</span> iterations &lt; k:</span><br><span class="line">        indexes = [rnd.randrange(<span class="number">0</span>, len(data[<span class="number">0</span>])) </span><br><span class="line">                   <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</span><br><span class="line">        maybeinliners_x = [train_data_x[i] <span class="keyword">for</span> i <span class="keyword">in</span> indexes]</span><br><span class="line">        maybeinliners_y = [train_data_y[i] <span class="keyword">for</span> i <span class="keyword">in</span> indexes]</span><br><span class="line">        maybemodel = model.fit(maybeinliners_x,</span><br><span class="line">                               maybeinliners_y)</span><br><span class="line">        alsoinliers = set()</span><br><span class="line">        predict = maybemodel.predict(train_data_x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(train_data_x)):</span><br><span class="line">            points_x = train_data_x[i]</span><br><span class="line">            <span class="keyword">if</span> points_x <span class="keyword">not</span> <span class="keyword">in</span> maybeinliners_x:</span><br><span class="line">                data_loss = loss(train_data_y[i], predict[i])</span><br><span class="line">                <span class="keyword">if</span> data_loss &lt; t:</span><br><span class="line">                    alsoinliers.add((points_x[<span class="number">0</span>],</span><br><span class="line">                                     train_data_y[i]))</span><br><span class="line">        <span class="keyword">if</span> len(alsoinliers) &gt; d:</span><br><span class="line">            <span class="comment"># this implies that we may have found a good model</span></span><br><span class="line">            <span class="comment"># now test how good it is</span></span><br><span class="line">            inliers_x = [[point[<span class="number">0</span>]] <span class="keyword">for</span> point <span class="keyword">in</span> alsoinliers]</span><br><span class="line">            inliers_y = [point[<span class="number">1</span>] <span class="keyword">for</span> point <span class="keyword">in</span> alsoinliers]</span><br><span class="line">            inliers_x.extend(maybeinliners_x)</span><br><span class="line">            inliers_y.extend(maybeinliners_y)</span><br><span class="line">            bettermodel = model.fit(inliers_x, inliers_y)</span><br><span class="line">            predict = maybemodel.predict(inliers_x)</span><br><span class="line">            thiserr = np.sqrt(np.average(</span><br><span class="line">                (inliers_y - predict) ** <span class="number">2</span>))</span><br><span class="line">            <span class="keyword">if</span> thiserr &lt; besterr:</span><br><span class="line">                besterr = thiserr</span><br><span class="line">                bestfit = bettermodel</span><br><span class="line">        iterations = iterations + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> bestfit</span><br></pre></td></tr></table></figure><h2><span id="demo">DEMO</span></h2><p>ç”Ÿæˆäº†ä¸€éƒ¨åˆ†å¯ä»¥ç”¨ç›´çº¿æ‹Ÿåˆçš„æ•°æ®å’Œä¸€äº›éšæœºå™ªå£°ï¼Œæ¯”ä¾‹ä¸º <span class="math inline">\(1:1\)</span> ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/dataset.png"></p><p>ç”¨çº¿æ€§å›å½’ç›´æ¥æ‹Ÿåˆå’ŒRANSACç®—æ³•çš„ç»“æœï¼š</p><p><img src="/images/good.png"></p><h2><span id="parameters">Parameters</span></h2><p>RANSACç®—æ³•ä¸­æœ‰å‡ ä¸ªè¶…å‚æ•°éœ€è¦è°ƒè¯•ï¼š</p><ul><li><p>t, d : è¿™ä¸¤ä¸ªå‚æ•°éœ€è¦æ ¹æ®åº”ç”¨å’Œæ•°æ®é›†æ¥è°ƒèŠ‚</p></li><li><p>kï¼ˆæœ€å¤§è¿­ä»£æ¬¡æ•°ï¼‰ï¼šå¯ä»¥ä»ç†è®ºä¸Šç¡®å®šã€‚</p><p>å®šä¹‰ <span class="math inline">\(p\)</span> æ˜¯RANSACç®—æ³•åœ¨æŸæ¬¡è¿­ä»£é‡‡æ ·æ—¶åªé‡‡æ ·åˆ°æ­£å¸¸æ ·æœ¬çš„æ¦‚ç‡ã€‚å¦‚æœè¿™çœŸçš„å‘ç”Ÿäº†ï¼Œé‚£ä¹ˆè¿™æ¬¡è¿­ä»£å°†è®­ç»ƒå‡ºä¸€ä¸ªå¾ˆå¥½çš„æ¨¡å‹ï¼Œæ‰€ä»¥ <span class="math inline">\(p\)</span> ä¹Ÿä»£è¡¨äº†RANSACç®—æ³•å¾—å‡ºä¸€ä¸ªå¥½ç»“æœçš„æ¦‚ç‡ã€‚å†å®šä¹‰ <span class="math inline">\(w\)</span> ä¸ºæ¯æ¬¡é‡‡æ ·æ—¶ï¼Œé‡‡åˆ°ä¸€ä¸ªæ­£å¸¸ç‚¹çš„æ¦‚ç‡ï¼Œå³ <span class="math inline">\(w\)</span> = Â number of inliers in data / number of points in dataã€‚å‡è®¾ä¸€æ¬¡é‡‡æ ·é€‰å– <span class="math inline">\(n\)</span> çš„æ ·æœ¬ï¼Œé‚£ä¹ˆè¿™æ¬¡é‡‡æ ·é€‰æ‹©çš„æ ·æœ¬å…¨éƒ¨éƒ½æ˜¯æ­£å¸¸æ ·æœ¬çš„æ¦‚ç‡ä¸º <span class="math inline">\(w^n\)</span>ï¼ˆå‡è®¾ä¸ºæ”¾å›é‡‡æ ·ï¼‰ï¼Œè‡³å°‘é€‰æ‹©ä¸€ä¸ªå¼‚å¸¸æ ·æœ¬çš„æ¦‚ç‡å°±ä¸º <span class="math inline">\(1-w^n\)</span>ã€‚æ€»å…±è¿­ä»£ <span class="math inline">\(k\)</span> æ¬¡ï¼Œé‚£ä¹ˆè¿™ <span class="math inline">\(k\)</span> æ¬¡é‡‡æ ·éƒ½è‡³å°‘æœ‰ä¸€ä¸ªå¼‚å¸¸æ ·æœ¬çš„æ¦‚ç‡ä¸ºï¼š<span class="math inline">\((1-w^n)^k\)</span>ï¼Œåº”è¯¥ç­‰äº <span class="math inline">\(1-p\)</span>ï¼Œå³ <span class="math display">\[1-p=(1-w^n)^k\]</span> ä¸¤è¾¹åŒæ—¶å–å¯¹æ•°å¾—ï¼š <span class="math display">\[k = \frac{\log(1-p)}{\log(1-w^n)}\]</span> å®é™…ä¸Šæˆ‘ä»¬æ˜¯ä¸æ”¾å›é‡‡æ ·ï¼Œæ‰€ä»¥è¿˜è¦åœ¨ä¸Šé¢çš„åŸºç¡€ä¸ŠåŠ ä¸Š <span class="math inline">\(k\)</span> çš„æ ‡å‡†å·®ã€‚<span class="math inline">\(k\)</span> çš„æ ‡å‡†å·®å®šä¹‰ä¸ºï¼š <span class="math display">\[SD(k) = \frac{\sqrt{1-w^n}}{w^n}\]</span></p></li></ul><h2><span id="advantages-and-disadvantages">Advantages and disadvantages</span></h2><p>ä¼˜åŠ¿ï¼š</p><ul><li>å¯ä»¥åšæ¨¡å‹å‚æ•°çš„ <a href="https://www.wikiwand.com/en/Robust_statistics" target="_blank" rel="noopener">robust estimation</a></li></ul><p>åŠ£åŠ¿ï¼š</p><ul><li><p>æ²¡æœ‰æ—¶é—´ä¸Šç•Œï¼Œå³ä¸ä¼šè‡ªç„¶æ”¶æ•›ï¼Œåªèƒ½é æœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶ã€‚æœ‰æ—¶å¯èƒ½æœ€åä¸€æ¬¡è¿­ä»£æ‰æ‰¾åˆ°ä¸€ä¸ªå¥½çš„æ¨¡å‹ï¼Œæœ‰æ—¶å¯èƒ½ç¬¬ä¸€æ¬¡å°±æ‰¾åˆ°äº†</p></li><li><p>éœ€è¦æ ¹æ®ä¸åŒé—®é¢˜æ‰‹åŠ¨è°ƒè¯•å‚æ•°ï¼ˆä¸€äº›é˜ˆå€¼ï¼‰</p></li><li><p>åªèƒ½åŒæ—¶è¯„ä¼°ä¸€ç§æ¨¡å‹</p></li><li><p>ä¸æ˜¯æ‰€æœ‰æ—¶å€™éƒ½èƒ½æ‰¾åˆ°åˆé€‚çš„æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨å¼‚å¸¸æ ·æœ¬ä¸ªæ•°å¤§äº 50% çš„æ—¶å€™ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p></li></ul><p><img src="/images/bad.png"></p><p>â€‹</p><h2><span id="å‚è€ƒ">å‚è€ƒ</span></h2><p><a href="https://www.wikiwand.com/en/Random_sample_consensus" target="_blank" rel="noopener">Random sample consensus</a></p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Statistics </tag>
            
            <tag> RANSAC </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>éšé©¬å°”ç§‘å¤«æ¨¡å‹ï¼ˆHMMï¼‰</title>
      <link href="/2016/10/02/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88HMM%EF%BC%89/"/>
      <url>/2016/10/02/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88HMM%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>éšé©¬å°”ç§‘å¤«æ¨¡å‹(HMM, Hidden Markov Model)å¯ç”¨æ ‡æ³¨é—®é¢˜ï¼Œåœ¨è¯­éŸ³è¯†åˆ«ã€NLPã€ç”Ÿç‰©ä¿¡æ¯ã€æ¨¡å¼è¯†åˆ«ç­‰é¢†åŸŸè¢«å®è·µè¯æ˜æ˜¯æœ‰æ•ˆçš„ç®—æ³•ã€‚</p><!-- toc --><ul><li><a href="#å‰è¨€">å‰è¨€</a><ul><li><a href="#hmmå®šä¹‰">HMMå®šä¹‰</a></li><li><a href="#é©¬å°”å¯å¤«é“¾">é©¬å°”å¯å¤«é“¾</a></li></ul></li><li><a href="#hmmçš„ç¡®å®š">HMMçš„ç¡®å®š</a></li><li><a href="#hmmçš„3ä¸ªåŸºæœ¬é—®é¢˜">HMMçš„3ä¸ªåŸºæœ¬é—®é¢˜</a><ul><li><a href="#æ¦‚ç‡è®¡ç®—">æ¦‚ç‡è®¡ç®—</a><ul><li><a href="#æš´åŠ›ç®—æ³•">æš´åŠ›ç®—æ³•</a></li><li><a href="#å‰å‘-åå‘ç®—æ³•">å‰å‘ï¼åå‘ç®—æ³•</a></li></ul></li><li><a href="#å­¦ä¹ ç®—æ³•">å­¦ä¹ ç®—æ³•</a><ul><li><a href="#ç›‘ç£å­¦ä¹ ">ç›‘ç£å­¦ä¹ </a></li><li><a href="#baum-welch-ç®—æ³•">Baum-Welch ç®—æ³•</a></li></ul></li><li><a href="#é¢„æµ‹ç®—æ³•">é¢„æµ‹ç®—æ³•</a><ul><li><a href="#è¿‘ä¼¼ç®—æ³•">è¿‘ä¼¼ç®—æ³•</a></li><li><a href="#viterbiç®—æ³•">Viterbiç®—æ³•</a></li></ul></li></ul></li><li><a href="#æ€»ç»“">æ€»ç»“</a></li><li><a href="#å‚è€ƒ">å‚è€ƒ</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="å‰è¨€">å‰è¨€</span></h2><h3><span id="hmmå®šä¹‰">HMMå®šä¹‰</span></h3><p>éšé©¬å°”å¯å¤«æ¨¡å‹ï¼ˆHMMï¼‰æ˜¯å…³äºæ—¶åºçš„æ¦‚ç‡æ¨¡å‹ï¼Œæè¿°ç”±ä¸€ä¸ªéšè—çš„é©¬å°”å¯å¤«é“¾ç”Ÿæˆä¸å¯é¢„æµ‹çš„çŠ¶æ€éšæœºåºåˆ—ï¼Œå†ç”±å„ä¸ªçŠ¶æ€ç”Ÿæˆè§‚æµ‹éšæœºåºåˆ—çš„è¿‡ç¨‹ã€‚</p><p><img src="/images/1475388928648.png"></p><p>â€‹ å›¾1. éšé©¬å°”å¯å¤«æ¨¡å‹çš„å›¾ç»“æ„</p><p>å›¾1ä¸­çš„ <span class="math inline">\(z_1, z_2 â€¦ z_{n+1}\)</span> æ˜¯ <span class="math inline">\(n+1\)</span> ä¸ªä¸å¯è§‚æµ‹çŠ¶æ€ï¼Œç”±é©¬å°”å¯å¤«é“¾è¿æ¥ï¼Œç§°ä¸º<strong>çŠ¶æ€åºåˆ—</strong>ï¼›<span class="math inline">\(x_1, x_2, â€¦, x_{n+1}\)</span> æ˜¯ç”±çŠ¶æ€åºåˆ—ç”Ÿæˆçš„è§‚æµ‹éšæœºåºåˆ—ï¼Œç§°ä¸º<strong>è§‚æµ‹åºåˆ—</strong>ã€‚å…¶ä¸­ï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ª<strong>æ—¶åˆ»</strong>ã€‚</p><h3><span id="é©¬å°”å¯å¤«é“¾">é©¬å°”å¯å¤«é“¾</span></h3><p>ä¸‹é¢çš„ä»‹ç»æ‘˜è‡ªWikipediaï¼š</p><blockquote><p><strong>é©¬å°”å¯å¤«é“¾</strong>ï¼ˆè‹±è¯­ï¼šMarkov chainï¼‰ï¼Œåˆç§°<strong>ç¦»æ•£æ—¶é—´é©¬å¯å¤«é“¾</strong>ï¼ˆdiscrete-time Markov chainï¼Œç¼©å†™ä¸º<strong>DTMC</strong>ï¼‰ï¼Œå› ä¿„å›½æ•°å­¦å®¶<a href="https://www.wikiwand.com/zh-hans/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB" target="_blank" rel="noopener">å®‰å¾·çƒˆÂ·é©¬å°”å¯å¤«</a>ï¼ˆä¿„è¯­ï¼šĞĞ½Ğ´Ñ€ĞµĞ¹ ĞĞ½Ğ´Ñ€ĞµĞµĞ²Ğ¸Ñ‡ ĞœĞ°Ñ€ĞºĞ¾Ğ²ï¼‰å¾—åï¼Œä¸º<a href="https://www.wikiwand.com/zh-hans/%E7%8B%80%E6%85%8B%E7%A9%BA%E9%96%93_(%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8)" target="_blank" rel="noopener">çŠ¶æ€ç©ºé—´</a>ä¸­ç»è¿‡ä»ä¸€ä¸ªçŠ¶æ€åˆ°å¦ä¸€ä¸ªçŠ¶æ€çš„è½¬æ¢çš„<a href="https://www.wikiwand.com/zh-hans/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B" target="_blank" rel="noopener">éšæœºè¿‡ç¨‹</a>ã€‚è¯¥è¿‡ç¨‹è¦æ±‚å…·å¤‡â€œæ— è®°å¿†â€çš„æ€§è´¨ï¼šä¸‹ä¸€çŠ¶æ€çš„æ¦‚ç‡åˆ†å¸ƒåªèƒ½ç”±å½“å‰çŠ¶æ€å†³å®šï¼Œåœ¨æ—¶é—´åºåˆ—ä¸­å®ƒå‰é¢çš„äº‹ä»¶å‡ä¸ä¹‹æ— å…³ã€‚è¿™ç§ç‰¹å®šç±»å‹çš„â€œæ— è®°å¿†æ€§â€ç§°ä½œ<a href="https://www.wikiwand.com/zh-hans/%E9%A6%AC%E5%8F%AF%E5%A4%AB%E6%80%A7%E8%B3%AA" target="_blank" rel="noopener">é©¬å¯å¤«æ€§è´¨</a>ã€‚é©¬å°”ç§‘å¤«é“¾ä½œä¸ºå®é™…è¿‡ç¨‹çš„ç»Ÿè®¡æ¨¡å‹å…·æœ‰è®¸å¤šåº”ç”¨ã€‚</p><p>åœ¨é©¬å°”å¯å¤«é“¾çš„æ¯ä¸€æ­¥ï¼Œç³»ç»Ÿæ ¹æ®æ¦‚ç‡åˆ†å¸ƒï¼Œå¯ä»¥ä»ä¸€ä¸ªçŠ¶æ€å˜åˆ°å¦ä¸€ä¸ªçŠ¶æ€ï¼Œä¹Ÿå¯ä»¥ä¿æŒå½“å‰çŠ¶æ€ã€‚çŠ¶æ€çš„æ”¹å˜å«åšè½¬ç§»ï¼Œä¸ä¸åŒçš„çŠ¶æ€æ”¹å˜ç›¸å…³çš„æ¦‚ç‡å«åšè½¬ç§»æ¦‚ç‡ã€‚<a href="https://www.wikiwand.com/zh-hans/%E9%9A%8F%E6%9C%BA%E6%BC%AB%E6%AD%A5" target="_blank" rel="noopener">éšæœºæ¼«æ­¥</a>å°±æ˜¯é©¬å°”å¯å¤«é“¾çš„ä¾‹å­ã€‚éšæœºæ¼«æ­¥ä¸­æ¯ä¸€æ­¥çš„çŠ¶æ€æ˜¯åœ¨å›¾å½¢ä¸­çš„ç‚¹ï¼Œæ¯ä¸€æ­¥å¯ä»¥ç§»åŠ¨åˆ°ä»»ä½•ä¸€ä¸ªç›¸é‚»çš„ç‚¹ï¼Œåœ¨è¿™é‡Œç§»åŠ¨åˆ°æ¯ä¸€ä¸ªç‚¹çš„æ¦‚ç‡éƒ½æ˜¯ç›¸åŒçš„ï¼ˆæ— è®ºä¹‹å‰æ¼«æ­¥è·¯å¾„æ˜¯å¦‚ä½•çš„ï¼‰ã€‚</p></blockquote><p>å›åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ï¼Œç”±äº <span class="math inline">\(z_1, z_2, â€¦, z_{n+1}\)</span> æ˜¯ä¸€æ¡é©¬å°”å¯å¤«é“¾ï¼Œæ‰€ä»¥é“¾ä¸­æŸä¸€çŠ¶æ€ <span class="math inline">\(z_i\)</span> å‘ç”Ÿçš„æ¦‚ç‡åªä¸ <span class="math inline">\(z_{i-1}\)</span> æœ‰å…³ï¼Œè¡¨è¾¾æˆå…¬å¼å°±æ˜¯ï¼š</p><p><span class="math display">\[P(Z_i = z_i|Z_{i-1}=z_{i-1}, Z_{i-2}=z_{i-2}, â€¦, Z_1 = z_1) = P(Z_i = z_i|Z_{i-1} = z_{i-1})\]</span></p><p>è¿˜æœ‰ä¸€ç‚¹å°±æ˜¯ï¼Œç”±äº <span class="math inline">\(z_2\)</span> å’Œ <span class="math inline">\(x_1\)</span> éƒ½æ˜¯ç”± <span class="math inline">\(z_1\)</span> â€œç”Ÿæˆâ€å‡ºæ¥çš„ï¼Œæ‰€ä»¥åœ¨ä¸çŸ¥é“ <span class="math inline">\(z_1\)</span> çš„æƒ…å†µä¸‹ï¼Œ <span class="math inline">\(x_1\)</span> å’Œ <span class="math inline">\(z_2\)</span> æ˜¯<strong>ä¸</strong>ç‹¬ç«‹çš„ï¼›ç”±äº <span class="math inline">\(x_2\)</span> æ˜¯ç”± <span class="math inline">\(z_2\)</span> ç”Ÿæˆçš„ï¼Œè‹¥æŠŠ <span class="math inline">\(x_2\)</span> å’Œ <span class="math inline">\(z_2\)</span> çœ‹æˆä¸€ä¸ªæ•´ä½“ï¼Œé‚£ä¹ˆè¿™ä¸ªæ•´ä½“ä¸ <span class="math inline">\(x_1\)</span> ä¹Ÿæ˜¯<strong>ä¸</strong>ç‹¬ç«‹çš„ï¼›æ‰€ä»¥åœ¨ <span class="math inline">\(z_1\)</span>, <span class="math inline">\(z_2\)</span> éƒ½ä¸å¯è§‚å¯Ÿï¼ˆæœªçŸ¥ï¼‰çš„å‰æä¸‹ï¼Œ<span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> <strong>ä¸ç›¸äº’ç‹¬ç«‹</strong>ã€‚</p><p>è¿™ä¸€ç‚¹ä¸å…¶å®ƒæœºå™¨å­¦ä¹ ç®—æ³•æ¯”å¦‚ Logistic Regression, SVM, Decision Tree ç­‰éƒ½ä¸ä¸€æ ·ï¼Œé‚£äº›ç®—æ³•éƒ½æ˜¯å‡è®¾æ¯ä¸ªæ ·æœ¬ç›¸äº’ç‹¬ç«‹ï¼Œè€ŒHMMå°±æ°æ°ç›¸åï¼Œè¦æ±‚æ ·æœ¬é—´æœ‰æŸç§è”ç³»ã€‚å°±æ‹¿ä¸­æ–‡åˆ†è¯æ¥ä¸¾ä¾‹ï¼Œæ­£å¸¸äººè¯´çš„æ¯ä¸€å¥è¯é‡Œï¼Œå‰ä¸€ä¸ªå­—å’Œåä¸€ä¸ªå­—éƒ½åº”è¯¥æ˜¯<strong>æœ‰è”ç³»çš„</strong>ï¼Œæœ‰çš„è”ç³»å¾ˆç´§å¯†ï¼Œæˆ‘ä»¬æŠŠå®ƒè®¤ä¸ºæ˜¯ä¸€ä¸ªè¯è¯­ï¼Œæœ‰çš„è”ç³»ä¸é‚£ä¹ˆå¼ºï¼Œæˆ‘ä»¬è®¤ä¸ºæ˜¯è¯ä¸è¯ä¹‹é—´çš„åˆ†éš”ï¼Œæ˜¾ç„¶æ¯ä¸ªå­—ä¹‹é—´éƒ½ä¸æ˜¯ç‹¬ç«‹çš„ã€‚è¿™ä¹Ÿå°±è§£é‡Šäº†ä¸ºä»€ä¹ˆHMMå¯ä»¥ç”¨åšä¸­æ–‡åˆ†è¯è€Œé‚£äº›ç®—æ³•ä¸å¯ä»¥ã€‚</p><h2><span id="hmmçš„ç¡®å®š">HMMçš„ç¡®å®š</span></h2><p>HMMç”±åˆå§‹æ¦‚ç‡åˆ†å¸ƒ <span class="math inline">\(\pi\)</span>ï¼ŒçŠ¶æ€è½¬ç§»æ¦‚ç‡åˆ†å¸ƒ <span class="math inline">\(A\)</span> ä»¥åŠè§‚æµ‹æ¦‚ç‡åˆ†å¸ƒ <span class="math inline">\(B\)</span> ç¡®å®šï¼ŒæŠŠå®ƒä»¬ä¸‰ä¸ªåˆèµ·æ¥è¡¨ç¤ºæˆ <span class="math inline">\(\lambda\)</span>ï¼Œå³ï¼š<span class="math display">\[\lambda = (A, B, \pi)\]</span></p><p>åˆ†åˆ«æ¥è§£é‡Šä¸€ä¸‹è¿™ä¸‰ä¸ªéƒ½æ˜¯ä»€ä¹ˆä¸œè¥¿ã€‚</p><p>å®šä¹‰ <span class="math inline">\(Q\)</span> ä¸ºæ‰€æœ‰å¯èƒ½çš„çŠ¶æ€çš„é›†åˆï¼Œ<span class="math inline">\(N\)</span> æ˜¯æ‰€æœ‰å¯èƒ½çš„çŠ¶æ€æ•°ï¼Œå³ <span class="math inline">\(Q=\{q_1, q_2, â€¦, q_N\}\)</span>ã€‚</p><ul><li>å¯¹äºä¸­æ–‡åˆ†è¯çš„ä¾‹å­æ¥è¯´ï¼Œå¯èƒ½çš„çŠ¶æ€åªæœ‰ä¸¤ä¸ªï¼š<span class="math inline">\(0, 1\)</span>ï¼Œ<span class="math inline">\(0\)</span> è¡¨ç¤ºè¿™ä¸ªå­—ä¸æ˜¯è¿™ä¸ªè¯çš„æœ€åä¸€ä¸ªå­—ï¼Œ<span class="math inline">\(1\)</span> è¡¨ç¤ºè¿™ä¸ªå­—æ˜¯è¿™ä¸ªè¯çš„æœ«å°¾ï¼Œè¯¥åˆ†å‰²äº†ã€‚æ‰€ä»¥ <span class="math inline">\(Q = \{0, 1\}, N = 2\)</span>ã€‚</li></ul><p>å®šä¹‰ <span class="math inline">\(V\)</span> æ˜¯æ‰€æœ‰å¯èƒ½çš„è§‚æµ‹çš„é›†åˆï¼Œ<span class="math inline">\(M\)</span> æ˜¯å¯èƒ½çš„è§‚æµ‹æ•°ï¼Œå³ <span class="math inline">\(V = \{v_1, v_2, â€¦, v_M\}\)</span></p><ul><li>å¯¹äºä¸­æ–‡åˆ†è¯çš„ä¾‹å­æ¥è¯´ï¼Œ<span class="math inline">\(V\)</span> å°±æ˜¯è¯­æ–™åº“é‡Œçš„æ‰€æœ‰å­—ï¼Œè€Œæ±‰å­—åœ¨è®¡ç®—æœºé‡Œå®é™…æ˜¯ç”¨ç¼–ç è¡¨ç¤ºçš„ï¼Œè‹¥æ˜¯ä¸¤å­—èŠ‚ç¼–ç ï¼Œåˆ™åªæœ‰ <span class="math inline">\(2^{16} = 65536\)</span> ç§æƒ…å†µï¼Œæ‰€ä»¥ <span class="math inline">\(M = 65536\)</span>ã€‚</li></ul><p>å†å®šä¹‰ <span class="math inline">\(I\)</span> æ˜¯é•¿åº¦ä¸º <span class="math inline">\(T\)</span> çš„çŠ¶æ€åºåˆ—ï¼Œ<span class="math inline">\(O\)</span> æ˜¯å¯¹åº”çš„è§‚æµ‹åºåˆ—ï¼Œå³ï¼š<span class="math inline">\(I = \{i_1, i_2, â€¦, i_T\}\ \ O = \{o_1, o_2, â€¦, o_T\}\)</span>ã€‚</p><ul><li>çŠ¶æ€åºåˆ— <span class="math inline">\(I\)</span> å¯¹åº”å›¾1ä¸­çš„ <span class="math inline">\(z_1, z_2, â€¦, z_n\)</span>ï¼Œè§‚æµ‹åºåˆ— <span class="math inline">\(O\)</span> å¯¹åº”å›¾1çš„ <span class="math inline">\(x_1, x_2, â€¦ , x_n\)</span>ï¼Œåªä¸è¿‡æ¢äº†ä¸ªåå­—ã€‚</li></ul><p><strong>çŠ¶æ€è½¬ç§»æ¦‚ç‡åˆ†å¸ƒ<span class="math inline">\(A\)</span></strong></p><p>çŠ¶æ€è½¬ç§»æ¦‚ç‡æ˜¯ä¸ªä»€ä¹ˆä¸œè¥¿å‘¢ï¼Œå…¶å®å°±æ˜¯ä»ä¸€ä¸ªçŠ¶æ€è½¬ç§»åˆ°å¦ä¸€ä¸ªçŠ¶æ€çš„æ¦‚ç‡ï¼Œå…·ä½“æ¥è¯´å°±æ˜¯ <span class="math inline">\(t\)</span> æ—¶åˆ»çš„éšçŠ¶æ€å¤„äºçŠ¶æ€ <span class="math inline">\(q_i\)</span>ï¼Œå³ <span class="math inline">\(i_t = q_i\)</span> çš„æ¡ä»¶ä¸‹ï¼Œ<span class="math inline">\(t+1\)</span> æ—¶åˆ»éšçŠ¶æ€è½¬æ¢åˆ°çŠ¶æ€ <span class="math inline">\(q_j\)</span>ï¼Œå³ <span class="math inline">\(i_{t+1} = q_j\)</span> çš„æ¦‚ç‡ï¼Œè¿™ä¸ªå°±æ˜¯ä» <span class="math inline">\(q_i\)</span> è½¬æ¢åˆ° <span class="math inline">\(q_j\)</span> çš„è½¬ç§»æ¦‚ç‡ï¼Œå®šä¹‰ä¸º <span class="math inline">\(a_{ij}\)</span>ï¼Œé‚£ä¹ˆå®ƒçš„å…¬å¼å°±æ˜¯ï¼š<span class="math inline">\(a_{ij} = P(i_{t+1} = q_j|i_t=q_i)\)</span>ã€‚</p><p>æˆ‘ä»¬æ€»å…±æœ‰ <span class="math inline">\(N\)</span> çš„å¯èƒ½çš„çŠ¶æ€ï¼Œæ¯ä¸ªçŠ¶æ€éƒ½æœ‰ä¸€å®šçš„æ¦‚ç‡è½¬ç§»åˆ°å…¶å®ƒçš„çŠ¶æ€ï¼Œæ‰€ä»¥çŠ¶æ€è½¬ç§»æ¦‚ç‡åº”è¯¥æœ‰ <span class="math inline">\(N*N\)</span> ä¸ªï¼Œä¸ºæ–¹ä¾¿è¡¨ç¤ºï¼Œæˆ‘ä»¬æŠŠå®ƒå†™æˆä¸€ä¸ª <span class="math inline">\(N*N\)</span> çš„çŸ©é˜µï¼Œå®šä¹‰ä¸º <span class="math inline">\(A\)</span>ï¼Œä¹Ÿå°±æ˜¯<strong>çŠ¶æ€è½¬ç§»æ¦‚ç‡åˆ†å¸ƒ</strong>ï¼Œä¹Ÿå«<strong>çŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µ</strong>ã€‚</p><p><span class="math display">\[A = [a_{ij}]_{N*N}\]</span>ï¼Œå…¶ä¸­ <span class="math inline">\(a_{ij} = P(i_{t+1} = q_j|i_t = q_i)\)</span></p><p><strong>è§‚æµ‹æ¦‚ç‡åˆ†å¸ƒ <span class="math inline">\(B\)</span> </strong></p><p>è§‚æµ‹æ¦‚ç‡åˆæ˜¯ä»€ä¹ˆé¬¼å‘¢ï¼Œå…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œå°±æ˜¯ç”±éšçŠ¶æ€ <span class="math inline">\(i_t\)</span> ç”Ÿæˆè§‚æµ‹ <span class="math inline">\(o_t\)</span> çš„æ¦‚ç‡ï¼Œå…·ä½“æ¥è¯´å°±æ˜¯æ—¶åˆ» <span class="math inline">\(t\)</span> å¤„äºçŠ¶æ€ <span class="math inline">\(q_i\)</span>ï¼Œå³ <span class="math inline">\(i_t = q_i\)</span> çš„æ¡ä»¶ä¸‹ï¼Œç”Ÿæˆè§‚æµ‹ <span class="math inline">\(v_k\)</span> çš„æ¦‚ç‡ï¼Œè®°ä¸º <span class="math inline">\(b_{ik}\)</span>ï¼Œå†™æˆå…¬å¼å°±æ˜¯ <span class="math inline">\(b_{ik} = P(o_t = v_k|i_t=q_i)\)</span>ã€‚</p><p>ç”±äºæ¯ä¸ªéšçŠ¶æ€æœ‰ <span class="math inline">\(N\)</span> ç§å¯èƒ½ï¼Œè§‚æµ‹æœ‰ <span class="math inline">\(M\)</span> ç§å¯èƒ½ï¼Œæ‰€ä»¥è§‚æµ‹æ¦‚ç‡åº”æœ‰ <span class="math inline">\(M*N\)</span> ä¸ªï¼Œä¸ºæ–¹ä¾¿è¡¨ç¤ºï¼Œæˆ‘ä»¬æŠŠå®ƒå†™æˆä¸€ä¸ª <span class="math inline">\(N*M\)</span> çš„çŸ©é˜µï¼Œå®šä¹‰ä¸º <span class="math inline">\(B\)</span>ï¼Œä¹Ÿå°±æ˜¯ <strong>è§‚æµ‹æ¦‚ç‡åˆ†å¸ƒ</strong>ï¼Œä¹Ÿå«<strong>è§‚æµ‹æ¦‚ç‡çŸ©é˜µ</strong>ï¼Œåˆå«<strong>å‘å°„çŸ©é˜µ</strong>æˆ–<strong>æ··æ·†çŸ©é˜µ</strong>ã€‚</p><p><span class="math display">\[B = [b_{ij}]_{N*M}\]</span>ï¼Œå…¶ä¸­ <span class="math inline">\(b_{ik} = P(o_t = v_k|i_t=q_i)\)</span></p><p><strong>åˆå§‹æ¦‚ç‡åˆ†å¸ƒ <span class="math inline">\(\pi\)</span></strong></p><p>æ‰€è°“åˆå§‹æ¦‚ç‡å°±æ˜¯åœ¨ <span class="math inline">\(t = 1\)</span> æ—¶åˆ»é€‰æ‹©æŸä¸€çŠ¶æ€çš„æ¦‚ç‡ã€‚å¦‚ <span class="math inline">\(\pi_i\)</span> æ˜¯æ—¶åˆ» <span class="math inline">\(t=1\)</span> å¤„äºçŠ¶æ€ <span class="math inline">\(q_i\)</span> çš„æ¦‚ç‡ï¼Œå³ <span class="math inline">\(\pi_i = P(i_1 = q_i)\)</span>ã€‚</p><p>æ˜¾ç„¶åº”è¯¥æœ‰ <span class="math inline">\(N\)</span> ä¸ªåˆå§‹æ¦‚ç‡ï¼Œå®šä¹‰ <span class="math inline">\(\pi\)</span> ä¸º<strong>åˆå§‹æ¦‚ç‡å‘é‡</strong>ï¼Œå…±æœ‰ <span class="math inline">\(N\)</span> çš„å…ƒç´ ã€‚</p><p><strong>å‚æ•°æ€»ç»“</strong></p><p>HMMç”±<strong>åˆå§‹æ¦‚ç‡åˆ†å¸ƒ <span class="math inline">\(\pi\)</span></strong>ã€<strong>çŠ¶æ€è½¬ç§»æ¦‚ç‡åˆ†å¸ƒ<span class="math inline">\(A\)</span></strong> ä»¥åŠ<strong>è§‚æµ‹æ¦‚ç‡åˆ†å¸ƒ <span class="math inline">\(B\)</span> </strong>ç¡®å®šã€‚å› æ­¤ï¼ŒHMMå¯ä»¥ç”¨ä¸‰å…ƒç¬¦å·è¡¨ç¤ºï¼Œç§°ä¸ºHMMçš„ä¸‰è¦ç´ ï¼š<span class="math inline">\(\lambda = (A, B, \pi)\)</span></p><p><strong>HMMçš„ä¸¤ä¸ªåŸºæœ¬æ€§è´¨</strong></p><p>é½æ¬¡å‡è®¾ï¼š <span class="math display">\[P(i_t|i_{t-1}, o_{t-1}, i_{t-2}, o_{t-2}, â€¦, i_1, o_1) = P(i_t|i_{t-1})\]</span> è§‚æµ‹ç‹¬ç«‹æ€§å‡è®¾ï¼š <span class="math display">\[P(o_t|i_t, i_{t-1}, o_{t-1}, â€¦, i_1, o_1) = P(o_t|i_t)\]</span> è¿™ä¸¤ä¸ªæ€§è´¨æˆ–è€…è¯´å‡è®¾å‡æ¥è‡ª<a href="#é©¬å°”å¯å¤«é“¾">é©¬å°”å¯å¤«é“¾</a>ï¼Œåœ¨å‰é¢ä¹Ÿç•¥æœ‰æåˆ°ï¼Œåº”è¯¥å¯ä»¥ç†è§£å§ã€‚</p><h2><span id="hmmçš„3ä¸ªåŸºæœ¬é—®é¢˜">HMMçš„3ä¸ªåŸºæœ¬é—®é¢˜</span></h2><p>ä¸çŸ¥é“å¤§å®¶çœ‹åˆ°è¿™é‡Œæ˜¯ä»€ä¹ˆæ„Ÿè§‰ï¼Œæœ‰æ²¡æœ‰è§‰å¾—è¿™ä¸ªæ¨¡å‹å¾ˆæ€ªï¼Œå¿ƒæƒ³ï¼šè¿™ç©æ„å’‹è®­ç»ƒï¼Ÿ</p><p>åæ­£æˆ‘åˆšå­¦åˆ°è¿™çš„æ—¶å€™æ˜¯æœ‰è¿™ç§æ„Ÿè§‰çš„ï¼Œè¿™ä¹Ÿå°±å¼•å‡ºäº†HMMçš„3ä¸ªæœ€é‡è¦çš„é—®é¢˜ï¼š<strong>æ¦‚ç‡è®¡ç®—</strong>ã€<strong>å­¦ä¹ </strong>å’Œ<strong>é¢„æµ‹</strong>ã€‚</p><p>å¤§ä½“æ¥è§£é‡Šä¸€ä¸‹ï¼š</p><ul><li>æ¦‚ç‡è®¡ç®—é—®é¢˜ï¼šç»™å®šæ¨¡å‹ <span class="math inline">\(\lambda = (A, B, \pi)\)</span> å’Œè§‚æµ‹åºåˆ— O = {o_1, o_2, â€¦, o_T}ï¼Œè®¡ç®—æ¨¡å‹ <span class="math inline">\(\lambda\)</span> ä¸‹è§‚æµ‹åºåˆ— <span class="math inline">\(O\)</span> å‡ºç°çš„æ¦‚ç‡ <span class="math inline">\(P(O|\lambda)\)</span></li><li>å­¦ä¹ é—®é¢˜ï¼šå·²çŸ¥è§‚æµ‹åºåˆ— <span class="math inline">\(O=\{o_1, o_2, â€¦, o_T\}\)</span>ï¼Œä¼°è®¡æ¨¡å‹ <span class="math inline">\(\lambda=(A, B, \pi)\)</span> çš„å‚æ•°ï¼Œä½¿å¾—åœ¨è¯¥æ¨¡å‹ä¸‹è§‚æµ‹åºåˆ— <span class="math inline">\(P(O|\lambda)\)</span> æœ€å¤§ã€‚</li><li>é¢„æµ‹é—®é¢˜ï¼šå·²çŸ¥æ¨¡å‹ <span class="math inline">\(\lambda=(A,B,\pi)\)</span> å’Œè§‚æµ‹åºåˆ— <span class="math inline">\(O=\{o_1, o_2, â€¦, o_T\}\)</span>ï¼Œæ±‚ç»™å®šè§‚æµ‹åºåˆ—æ¡ä»¶æ¦‚ç‡ <span class="math inline">\(P(I|O, \lambda)\)</span> æœ€å¤§çš„çŠ¶æ€åºåˆ— <span class="math inline">\(I\)</span>ã€‚</li></ul><h3><span id="æ¦‚ç‡è®¡ç®—">æ¦‚ç‡è®¡ç®—</span></h3><p>ç›®æ ‡ï¼šç»™å®šæ¨¡å‹ <span class="math inline">\(\lambda = (A, B, \pi)\)</span> å’Œè§‚æµ‹åºåˆ— O = {o_1, o_2, â€¦, o_T}ï¼Œè®¡ç®—æ¨¡å‹ <span class="math inline">\(\lambda\)</span> ä¸‹è§‚æµ‹åºåˆ— <span class="math inline">\(O\)</span> å‡ºç°çš„æ¦‚ç‡ <span class="math inline">\(P(O|\lambda)\)</span>ã€‚</p><p>æ¦‚ç‡è®¡ç®—æœ‰ä¸‰ç§æ–¹æ³•ï¼šæš´åŠ›æ±‚è§£ï¼Œ<strong>å‰å‘ç®—æ³•</strong>å’Œ<strong>åå‘ç®—æ³•</strong>ï¼Œåä¸¤è€…å®é™…ä¸Šå¼<strong>åŠ¨æ€è§„åˆ’</strong>ç®—æ³•ã€‚</p><h4><span id="æš´åŠ›ç®—æ³•">æš´åŠ›ç®—æ³•</span></h4><p>ç®—æ³•æ€æƒ³ï¼šæŒ‰ç…§æ¦‚ç‡å…¬å¼ï¼Œåˆ—ä¸¾æ‰€æœ‰å¯èƒ½çš„é•¿åº¦ä¸º <span class="math inline">\(T\)</span> çš„çŠ¶æ€åºåˆ— <span class="math inline">\(I = \{i_1, i_2, â€¦, i_T\}\)</span>ï¼Œæ±‚å„ä¸ªçŠ¶æ€åºåˆ— <span class="math inline">\(I\)</span> ä¸è§‚æµ‹åºåˆ— <span class="math inline">\(O=\{o_1, o_2, â€¦, o_T\}\)</span> çš„è”åˆæ¦‚ç‡ <span class="math inline">\(P(O, I|\lambda)\)</span>ï¼Œç„¶åå¯¹æ‰€æœ‰å¯èƒ½çš„çŠ¶æ€åºåˆ—æ±‚å’Œï¼Œä»è€Œå¾—åˆ° <span class="math inline">\(P(O|\lambda)\)</span>ã€‚</p><p>å…ˆæ±‚ <span class="math inline">\(P(O, I|\lambda)\)</span>ï¼Œç„¶åå¯¹æ‰€æœ‰ <span class="math inline">\(I\)</span> åŠ å’Œå³å¯ã€‚</p><p>æˆ‘ä»¬å¯ä»¥æŠŠè”åˆæ¦‚ç‡åˆ†è§£ä¸ºæ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ï¼š<span class="math inline">\(P(O, I|\lambda) = P(O|I, \lambda)P(I|\lambda)\)</span></p><p>çŠ¶æ€åºåˆ— <span class="math inline">\(\{i_1, i_2, â€¦, i_T\}\)</span> çš„æ¦‚ç‡æ€ä¹ˆæ±‚å‘¢ï¼Ÿä¸€æ­¥ä¸€æ­¥æ¥ã€‚ <span class="math display">\[\begin{array}{lcl}P(I|\lambda) = P(i_1, i_2, â€¦, i_T|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = P(i_2, â€¦, i_T|\lambda)\cdot P(i_1|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = P(i_2, â€¦, i_T|\lambda)\cdot \pi_{i_1} \\\ \ \ \ \ \ \ \ \ \ \ \ = \pi_{i_1} \cdot P(i_3, ..., i_T|\lambda)P(i_2|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = \pi_{i_1} a_{i_1i_2} \cdot P(i_3, ..., i_T|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = \ .... \\\ \ \ \ \ \ \ \ \ \ \ \ = \pi_{i_1} a_{i_1i_2}a_{i_2i_3}...a_{i_{T-1}i_T}\end{array}\]</span> åŒç†å¯ä»¥æ±‚è§‚æµ‹åºåˆ—çš„æ¦‚ç‡ï¼š <span class="math display">\[P(O|I, \lambda) = b_{i_1o_1}b_{i_2o_2}...b_{i_To_T}\]</span> æ‰€ä»¥ <span class="math inline">\(O\)</span> å’Œ <span class="math inline">\(I\)</span> åŒæ—¶å‡ºç°çš„è”åˆæ¦‚ç‡æ˜¯ï¼š <span class="math display">\[P(O,I|\lambda) = P(O|I, \lambda)P(I|\lambda) = \pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}...a_{i_{T-1}i_T}b_{i_ToT}\]</span> å¯¹æ‰€æœ‰å¯èƒ½çš„çŠ¶æ€åºåˆ— <span class="math inline">\(I\)</span> æ±‚å’Œï¼Œå¾—åˆ°è§‚æµ‹åºåˆ— <span class="math inline">\(O\)</span> çš„æ¦‚ç‡ï¼š <span class="math display">\[P(O|\lambda) = \sum_I P(O, I|\lambda) = \sum_{i_1, i_2, ..., i_T}\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}...a_{i_{T-1}i_T}b_{i_ToT}\]</span> è¿™æ ·å°±æ±‚è§£å‡ºè§‚æµ‹åºåˆ— <span class="math inline">\(O\)</span> çš„æ¦‚ç‡ï¼Œä¹Ÿä¸æ˜¯å¾ˆéš¾ï¼Œä¸æ˜¯å—ï¼Ÿ</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹è¿™ä¸ªç®—æ³•çš„<strong>æ—¶é—´å¤æ‚åº¦</strong>ã€‚</p><p>ç”±äºè¦ç©·ä¸¾æ‰€æœ‰ <span class="math inline">\(I\)</span> çš„å¯èƒ½æ€§ï¼Œ <span class="math inline">\(I\)</span> çš„é•¿åº¦æ˜¯ <span class="math inline">\(T\)</span>ï¼Œæ¯ä¸ª <span class="math inline">\(i\)</span> æœ‰ <span class="math inline">\(N\)</span> ç§å¯èƒ½æ€§ï¼Œæ‰€ä»¥æ€»å…±æœ‰ <span class="math inline">\(N^T\)</span> ä¸ª <span class="math inline">\(I\)</span>ã€‚è®¡ç®—æ¯ä¸ª <span class="math inline">\(I\)</span> éœ€è¦åš <span class="math inline">\(2T\)</span> æ¬¡ä¹˜æ³•ï¼Œå› æ­¤ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º <span class="math inline">\(O(TN^T)\)</span>ï¼Œè¶…çº§é«˜ã€‚</p><h4><span id="å‰å‘-åå‘ç®—æ³•">å‰å‘ï¼åå‘ç®—æ³•</span></h4><p>æˆ‘ä»¬æ€è€ƒä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨æ±‚æœ€é•¿é€’å¢å­åºåˆ—ã€æœ€å¤§è¿ç»­å­æ•°ç»„æˆ–æ˜¯KMPä¸­nextæ•°ç»„çš„è®¡ç®—ï¼Œæ— ä¸ç”¨åˆ°åŒä¸€ä¸ªæ€æƒ³ï¼šåœ¨å‰ <span class="math inline">\(k\)</span> ä¸ªå·²çŸ¥çš„æƒ…å†µä¸‹æ±‚ç¬¬ <span class="math inline">\(k+1\)</span> ä¸ªã€‚</p><p>æˆ‘ä»¬å€Ÿé‰´è¿™ç§ä¼˜åŒ–æ€æƒ³æ¥å®šä¹‰ä¸¤ä¸ªæ¦‚å¿µï¼šå‰å‘æ¦‚ç‡å’Œåå‘æ¦‚ç‡ã€‚</p><p><img src="/images/1475388965126.png"></p><p>â€‹ å›¾2:å‰å‘æ¦‚ç‡å’Œåå‘æ¦‚ç‡ç¤ºæ„å›¾</p><p>å®šä¹‰å‰å‘æ¦‚ç‡ <span class="math inline">\(\alpha_t(i)\)</span> ä¸º <span class="math inline">\(t\)</span> æ—¶åˆ»ä¸‹éšçŠ¶æ€ä¸º <span class="math inline">\(q_i\)</span> å¹¶ä¸”è§‚æµ‹åˆ°è§‚æµ‹åºåˆ— <span class="math inline">\(o_1, o_2, â€¦, o_t\)</span> çš„æ¦‚ç‡ï¼Œå³ <span class="math display">\[\alpha_t(i) = P(o_1, o_2, ..., o_t, i_t = q_i|\lambda)\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(o\)</span> ç­‰äºå›¾2ä¸­çš„ <span class="math inline">\(y\)</span>ï¼Œ<span class="math inline">\(i\)</span> ç­‰äºå›¾2ä¸­çš„ <span class="math inline">\(q\)</span>ï¼Œå’Œæˆ‘ä»¬ä¹‹å‰çš„å®šä¹‰ç›¸åŒã€‚</p><p>åŒç†å®šä¹‰åå‘æ¦‚ç‡ <span class="math inline">\(\beta_t(i)\)</span> ä¸ºå·²çŸ¥ <span class="math inline">\(t\)</span> æ—¶åˆ»çš„çŠ¶æ€ä¸º <span class="math inline">\(q_i\)</span>ï¼Œè§‚æµ‹åˆ°è¾“å‡ºåºåˆ—ä¸º <span class="math inline">\(o_{y+1}, â€¦, o_T\)</span> çš„æ¦‚ç‡ï¼Œå³ï¼š <span class="math display">\[\beta_t(i) = P(o_{t+1}, o_{t+2}, ..., o_T|i_t = q_i, \lambda)\]</span> <strong>å‰å‘ç®—æ³•</strong></p><p>æ€æƒ³ï¼šé€’æ¨è®¡ç®—å‰å‘æ¦‚ç‡ <span class="math inline">\(\alpha_t(i)\)</span> åŠè§‚æµ‹åºåˆ—æ¦‚ç‡ <span class="math inline">\(P(O|\lambda)\)</span>ã€‚</p><p>åˆå€¼ï¼š<span class="math inline">\(\alpha_1(i) = P(o_1, i_1=q_i|\lambda) = \pi_ib_{io_1}\)</span></p><p>é€’æ¨ï¼šå¯¹äº <span class="math inline">\(t = 1, 2, â€¦, T-1\)</span>ï¼Œ <span class="math display">\[\begin{array}{lcl}\alpha_{t+1}(i) = P(o_1, ..., o_{t+1}, i_{t+1}=q_i|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = (\sum_{j=1}^N P(o_1, ..., o_t, i_t=q_j|\lambda) \cdot a_{ji})\cdot b_{io_{t+1}} \\\ \ \ \ \ \ \ \ \ \ \ \ = (\sum_{j=1}^Na_t(j)a_{ji})b_{io_{i+1}}\end{array}\]</span> æœ€ç»ˆï¼š<span class="math inline">\(P(O|\lambda) = \sum_{i=1}^N\alpha_T(i)\)</span></p><p>æˆ‘ä»¬å†åˆ†æä¸€ä¸‹è¯¥ç®—æ³•çš„å¤æ‚åº¦ï¼Œæ¯è®¡ç®—ä¸€ä¸ª <span class="math inline">\(\alpha_T(i)\)</span> éœ€è¦ <span class="math inline">\(T\)</span> æ¬¡è¿­ä»£ï¼Œæ¯æ¬¡è¿­ä»£éœ€è¦è®¡ç®—çº¦ <span class="math inline">\(N\)</span> æ¬¡ä¹˜æ³•ï¼Œå…±è®¡ç®— <span class="math inline">\(N\)</span> æ¬¡ï¼Œå› æ­¤ï¼Œå‰å‘ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º <span class="math inline">\(O(N^2T)\)</span>ã€‚</p><p>ç›¸æ¯”äºæš´åŠ›æ±‚è§£ï¼Œé€šè¿‡é€’æ¨çš„æ–¹å¼å¤§å¤§é™ä½äº†æ—¶é—´å¤æ‚åº¦ï¼ŒåŸå› åœ¨äºæš´åŠ›æ±‚è§£é‡å¤è®¡ç®—äº†å¥½å¤šä¸œè¥¿ï¼Œè€Œé€’æ¨å…¬å¼æ¯ä¸€æ­¥éƒ½å¯ä»¥åˆ©ç”¨ä¸Šä¸€æ­¥çš„ç»“æœã€‚</p><p><strong>åå‘ç®—æ³•</strong></p><p>æ€æƒ³ï¼šå’Œå‰å‘ç®—æ³•ç±»ä¼¼ï¼Œä¹Ÿæ˜¯é€’æ¨çš„æ€æƒ³ã€‚</p><p>åˆå€¼ï¼š<span class="math inline">\(\beta_T(i) = 1\)</span></p><p>é€’æ¨ï¼šå¯¹äº <span class="math inline">\(t = T-1, T-2, â€¦, 1\)</span> <span class="math display">\[\begin{array}{lcl}\beta_t(i) = P(o_{t+1}, ..., o_T|i_t = q_i, \lambda) \\\ \ \ \ \ \ \ \ = \sum_{j=1}^N(P(o_{t+2}, ..., o_T|i_{t+1}=q_j, \lambda) \cdot a_{ji}b_{jo_{t+1}}) \\\ \ \ \ \ \ \ \ = \sum_{j=1}^N(a_{ji}b_{jo_{t+1}}\beta_{t+1}(j))\end{array}\]</span> æœ€ç»ˆï¼š<span class="math inline">\(P(O|\lambda) = \sum_{i=1}^N\pi_ib_{io_1}\beta_1(i)\)</span></p><p>åŒç†åå‘ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¹Ÿæ˜¯ <span class="math inline">\(O(N^2T)\)</span>ã€‚</p><p><strong>å‰åå‘å…³ç³»</strong></p><p>æˆ‘ä»¬è®¡ç®—ä¸€ä¸‹è§‚æµ‹åˆ°è§‚æµ‹åºåˆ— <span class="math inline">\(O\)</span> å¹¶ä¸” <span class="math inline">\(t\)</span> æ—¶åˆ»çš„çŠ¶æ€ä¸º <span class="math inline">\(q_i\)</span> çš„æ¦‚ç‡ï¼š <span class="math display">\[\begin{array}{lcl}\ \ \ \ P(i_t = q_i, O|\lambda) \\= P(O|i_t = q_i, \lambda)P(i_t = q_i|\lambda)\\= P(o_1, ..., o_t, o_{t+1}, ...., o_T|i_t=q_i,\lambda)P(i_t=q_i|\lambda)\\= P(o_1, ..., o_t|i_t=q_i, \lambda)P(o_{i+1}, ..., o_T|i_t=q_i,\lambda)P(i_t=q_i|\lambda)\\= P(o_1, ..., o_t, i_t=q_i|\lambda)P(o_{i+1}, ..., o_T|i_t=q_i,\lambda)\\= \alpha_t(i)\beta_t(i)\end{array}\]</span> æ­£å¥½ç­‰äº <span class="math inline">\(\alpha\)</span> å’Œ <span class="math inline">\(\beta\)</span> çš„ä¹˜ç§¯ï¼Œæ˜¯ä¸æ˜¯å¾ˆæœ‰æ„æ€ã€‚</p><p><strong>å•ä¸ªçŠ¶æ€çš„æ¦‚ç‡</strong></p><p>æˆ‘ä»¬å®šä¹‰å•ä¸ªçŠ¶æ€çš„æ¦‚ç‡ä¸º <span class="math inline">\(\gamma_t(i)\)</span>ï¼Œå³ç»™å®šæ¨¡å‹ <span class="math inline">\(\lambda\)</span> å’Œè§‚æµ‹ <span class="math inline">\(O\)</span>ï¼Œåœ¨æ—¶åˆ» <span class="math inline">\(t\)</span> å¤„äºçŠ¶æ€ <span class="math inline">\(q_i\)</span> çš„æ¦‚ç‡ï¼Œå†™æˆå…¬å¼å°±æ˜¯ï¼š <span class="math display">\[\gamma_t(i) = P(i_t = q_i|O, \lambda)\]</span> ç”¨ä¸Šå‰é¢çš„ç»“è®ºè¿›ä¸€æ­¥æ¨å¯¼ä¸€ä¸‹ï¼š <span class="math display">\[\gamma_t(i) = P(i_t=q_i|O,\lambda)=\frac{P(i_t=q_i,O|\lambda)}{P(O|\lambda)}=\frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^N\alpha_t(i)\beta_t(i)}\]</span> æ‰€ä»¥æ±‚å®ƒä¸ºäº†å¹²å˜›ï¼Ÿï¼Ÿï¼Ÿ</p><p>å½“ç„¶æ˜¯æœ‰ç”¨çš„äº†ï¼Œæˆ‘ä»¬æƒ³æƒ³ <span class="math inline">\(\gamma_t(i)\)</span> ä»£è¡¨äº†å•¥ï¼Œæ˜¯ç»™å®šæ¨¡å‹ <span class="math inline">\(\lambda\)</span> å’Œè§‚æµ‹ <span class="math inline">\(O\)</span>ï¼Œåœ¨æ—¶åˆ» <span class="math inline">\(t\)</span> å¤„äºçŠ¶æ€ <span class="math inline">\(q_i\)</span> çš„æ¦‚ç‡ã€‚é‚£æˆ‘ä»¬å¯ä»¥æŠŠæ—¶åˆ» <span class="math inline">\(t\)</span> å¤„äºæ‰€æœ‰çŠ¶æ€çš„æ¦‚ç‡éƒ½æ±‚å‡ºæ¥ï¼Œç„¶åå–ä¸€ä¸ªæœ€å¤§çš„ä½œä¸ºé¢„æµ‹å€¼ï¼Œå¯¹æ‰€æœ‰æ—¶åˆ»éƒ½è¿™ä¹ˆåšï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªçŠ¶æ€åºåˆ— <span class="math inline">\(I^*=\{i_1^*, i_2^*, â€¦, i_T^*\}\)</span>ï¼Œå°†å®ƒä½œä¸ºé¢„æµ‹ç»“æœï¼Œè¿™ä¸å°±è§£å†³äº†é¢„æµ‹é—®é¢˜å—ï¼</p><p><strong>ä¸¤ä¸ªçŠ¶æ€çš„è”åˆæ¦‚ç‡</strong></p><p>å®šä¹‰ä¸¤ä¸ªçŠ¶æ€çš„è”åˆæ¦‚ç‡ <span class="math inline">\(\xi_t(i,j)\)</span> ä¸ºç»™å®šæ¨¡å‹ <span class="math inline">\(\lambda\)</span> å’Œè§‚æµ‹ <span class="math inline">\(O\)</span>ï¼Œåœ¨æ—¶åˆ» <span class="math inline">\(t\)</span> å¤„äºçŠ¶æ€ <span class="math inline">\(q_i\)</span> ä¸”æ—¶åˆ» <span class="math inline">\(t+1\)</span> å¤„äºçŠ¶æ€ <span class="math inline">\(q_j\)</span> çš„æ¦‚ç‡ï¼Œå³ï¼š <span class="math display">\[\xi_t(i,j) = P(i_t = q_i, i_{t+1}=q_j|O, \lambda)\]</span> è¿›ä¸€æ­¥æ¨å¯¼ï¼š <span class="math display">\[\begin{array}{lcl}\xi_t(i, j) = P(i_t = q_i, i_{t+1}=q_j|O, \lambda) \\\ \ \ \ \ \ \ \ \ \ \ = \frac{P(i_t=q_i, i_{t+1=q_j},O|\lambda)}{P(O|\lambda)}\\\ \ \ \ \ \ \ \ \ \ \ = \frac{P(i_t=q_i, i_{t+1=q_j},O|\lambda)}{\sum_{i=1}^N\sum_{j=1}^NP(i_t=q_i, i_{t+1=q_j},O|\lambda)}\end{array}\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(P(i_t=q_i, i_{t+1=q_j},O|\lambda) = \alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)\)</span>ã€‚</p><p><strong>æœŸæœ›</strong></p><p>åœ¨è§‚æµ‹ <span class="math inline">\(O\)</span> ä¸‹çŠ¶æ€ <span class="math inline">\(i\)</span> å‡ºç°çš„æœŸæœ›ï¼š <span class="math display">\[\sum_{t=1}^T\gamma_t(i)\]</span> åœ¨è§‚æµ‹ <span class="math inline">\(O\)</span> ä¸‹çŠ¶æ€ <span class="math inline">\(i\)</span> è½¬ç§»åˆ°çŠ¶æ€ <span class="math inline">\(j\)</span> çš„æœŸæœ›ï¼š <span class="math display">\[\sum_{t=1}^{T-1}\xi_t(i, j)\]</span></p><p>è¿™äº›éƒ½æ˜¯åœ¨ä¸ºåé¢åšé“ºå«ã€‚</p><h3><span id="å­¦ä¹ ç®—æ³•">å­¦ä¹ ç®—æ³•</span></h3><p>HMMçš„å­¦ä¹ æ–¹æ³•åˆ†ä¸ºç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ä¸¤ç§ã€‚</p><ul><li>è‹¥è®­ç»ƒæ•°æ®åŒ…æ‹¬è§‚æµ‹åºåˆ—å’Œå£®æ€åºåˆ—ï¼Œåˆ™HMMçš„å­¦ä¹ éå¸¸ç®€å•ï¼Œæ˜¯ç›‘ç£å­¦ä¹ ï¼›</li><li>è‹¥è®­ç»ƒæ•°æ®åªæœ‰è§‚æµ‹åºåˆ—ï¼Œåˆ™HMMçš„å­¦ä¹ éœ€è¦ä½¿ç”¨<a href="https://www.liuhe.website/index.php?/Articles/single/53" target="_blank" rel="noopener">EMç®—æ³•</a>ï¼Œæ˜¯éç›‘ç£å­¦ä¹ ã€‚</li></ul><h4><span id="ç›‘ç£å­¦ä¹ ">ç›‘ç£å­¦ä¹ </span></h4><p><strong>Bernoulliå¤§æ•°å®šç†</strong></p><p>ä¸€è¨€ä»¥æ¦‚ï¼š<strong>é¢‘ç‡çš„æé™æ˜¯æ¦‚ç‡</strong>ã€‚</p><p><strong>å­¦ä¹ æ–¹æ³•</strong></p><p>HMMçš„ç›‘ç£å­¦ä¹ æ–¹æ³•å¾ˆç®€å•ï¼Œè€Œä¸”æœ‰ç‚¹æ— è¶£ï¼Œç›´æ¥ç»Ÿè®¡å°±è¡Œï¼Œè¿™é‡Œç›´æ¥åˆ—å‡ºå…¬å¼ã€‚</p><p>åˆå§‹æ¦‚ç‡ <span class="math display">\[\hat{\pi_i} = \frac{|q_i|}{\sum_i|q_i|}\]</span> è½¬ç§»æ¦‚ç‡ <span class="math display">\[\hat{a_{ij}} = \frac{|q_{ij}|}{\sum_{j=1}^N|q_{ij}|}\]</span> è§‚æµ‹æ¦‚ç‡ <span class="math display">\[\hat{b_{ik}} = \frac{|s_{ik|}}{\sum_{k=1}^M|s_{ik}|}\]</span></p><h4><span id="baum-welch-ç®—æ³•">Baum-Welch ç®—æ³•</span></h4><p>è‹¥è®­ç»ƒæ•°æ®åªæœ‰è§‚æµ‹åºåˆ—ï¼Œåˆ™HMMçš„å­¦ä¹ éœ€è¦ä½¿ç”¨<a href="https://neymarl.github.io/2016/09/22/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3EM%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener">EMç®—æ³•</a>ï¼Œæ˜¯éç›‘ç£å­¦ä¹ ã€‚</p><p><img src="/images/1475389008451.png"></p><p>â€‹ å›¾3.EMç®—æ³•æ¡†æ¶</p><p>æ‰€æœ‰è§‚æµ‹æ•°æ®å†™æˆ <span class="math inline">\(O = (o_1, o_2, â€¦, o_T)\)</span>ï¼Œæ‰€æœ‰éšæ•°æ®å†™æˆ <span class="math inline">\(I=(i_1,i_2, â€¦, i_T)\)</span>ï¼Œå®Œå…¨æ•°æ®æ˜¯ <span class="math inline">\((O, I) = (o_1, o_2, â€¦, o_T, i_1, i_2, â€¦, i_T)\)</span>ï¼Œåˆ™å®Œå…¨æ•°æ®çš„å¯¹æ•°ä¼¼ç„¶ä¸º <span class="math inline">\(\ln P(O,I|\lambda)\)</span>ã€‚</p><p>è®¾ <span class="math inline">\(\overline{\lambda}\)</span> æ˜¯HMMå‚æ•°çš„å½“å‰ä¼°è®¡å€¼ï¼Œ<span class="math inline">\(\lambda\)</span> ä¸ºå¾…æ±‚çš„å‚æ•°ï¼Œåˆ™EMç®—æ³•ä¸­çš„ <span class="math inline">\(Q\)</span>ï¼Œå³æ¡ä»¶æ¦‚ç‡ä¸ºï¼š <span class="math display">\[\begin{array}{lcr}Q(\lambda, \overline{\lambda}) = P(I|O,\overline{\lambda})\\\ \ \ \ \ \ \ \ \ \ \ \ \ = \frac{P(O,I|\overline{\lambda})}{P(O|\overline{\lambda})}\\\ \ \ \ \ \ \ \ \ \ \ \ \ \propto P(O,I|\overline{\lambda})\end{array}\]</span> EMç®—æ³•ä¸­çš„Mæ­¥ä¸ºï¼š <span class="math display">\[\lambda = \arg\max_\lambda \sum_IP(O,I|\overline{\lambda})\cdot \ln P(O,I|\lambda)\]</span> æ ¹æ®<a href="#æš´åŠ›ç®—æ³•">æš´åŠ›ç®—æ³•</a>ä¸­çš„è®¡ç®—ç»“æœï¼š <span class="math display">\[P(O,I|\lambda) =\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}...a_{i_{T-1}i_T}b_{i_ToT}\]</span> åŒ–ç®€å¾—ï¼š <span class="math display">\[\begin{array}{lcr}\ \ \ \sum_IP(O,I|\overline{\lambda})\cdot \ln P(O,I|\lambda)\\= \sum_I\ln \pi_{i_1}P(O,I|\overline{\lambda})\\+ \sum_I(\sum_{t=1}^{T-1}\ln a_{i_ti_{t+1}})P(O,I|\overline{\lambda})\\+ \sum_I(\sum_{t=1}^T\ln b_{i_to_t})P(O,I|\overline{\lambda})\end{array}\]</span> æ¥ä¸‹æ¥å°±æ˜¯æå¤§åŒ–ä¸Šé¢çš„å¼å­ï¼Œæ±‚å¾—å‚æ•° <span class="math inline">\(A, B, \pi\)</span>ã€‚</p><p>ç”±äºè¯¥ä¸‰ä¸ªå‚æ•°åˆ†åˆ«ä½äºä¸‰ä¸ªé¡¹ä¸­ï¼Œå¯åˆ†åˆ«æå¤§åŒ–ã€‚</p><p>å…ˆæ±‚ <span class="math inline">\(\pi\)</span> çœ‹çœ‹ï¼š<span class="math inline">\(\sum_I\ln \pi_{i_1}P(O,I|\overline{\lambda}) = \sum_{i=1}^N\ln \pi_{i}P(O,i_1=i|\overline{\lambda})\)</span>ï¼Œæ³¨æ„åˆ° <span class="math inline">\(\pi_i\)</span> æ»¡è¶³åŠ å’Œä¸º <span class="math inline">\(1\)</span>ï¼Œåˆ©ç”¨Lagrangeä¹˜æ•°æ³•ï¼Œæ„é€ Lagrangeå‡½æ•°å¾—ï¼š <span class="math display">\[L(\pi_i, \gamma) = \sum_{i=1}^NP(O,i_1=i|\overline{\lambda}) + \gamma(\sum_{i=1}^N\pi_i - 1)\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\gamma\)</span> ä¸ºLagrangeä¹˜å­ï¼Œå¯¹ <span class="math inline">\(L\)</span> æ±‚åå¯¼å¹¶ä»¤å…¶ç­‰äºé›¶ï¼Œå¾—åˆ°ï¼š <span class="math display">\[P(O,i_1=1|\overline{\lambda}) + \gamma\pi_i = 0\]</span> å¯¹æ‰€æœ‰ <span class="math inline">\(i\)</span> æ±‚å’Œï¼Œå¾—åˆ°ï¼š <span class="math display">\[\gamma = -P(O|\overline{\lambda})\]</span> æŠŠ <span class="math inline">\(\gamma\)</span> ä»£å›ä¸Šå¼ï¼Œå¾—åˆ°åˆå§‹çŠ¶æ€æ¦‚ç‡ï¼š <span class="math display">\[\pi_i = \frac{P(O,i_1=1|\overline{\lambda})}{P(O|\overline{\lambda})} = \frac{P(O,i_1=i|\overline{\lambda})}{\sum_{i=1}^NP(O,i_1=i|\overline{\lambda})} ï¼ \frac{\gamma_1(i)}{\sum_{i=1}^N\gamma_1(i)}\]</span> å¯¹äºè½¬ç§»æ¦‚ç‡å’Œè§‚æµ‹æ¦‚ç‡ï¼Œç”¨åŒæ ·çš„æ–¹æ³•ï¼Œå¯ä»¥å¾—åˆ°ï¼š <span class="math display">\[a_{ij} = \frac{\sum_{t=1}^{T-1}P(O,i_t=i, i_{t+1}=j|\overline{\lambda})}{\sum_{t=1}^{T-1}P(O,i_t=i|\overline{\lambda})} = \frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}\]</span></p><p><span class="math display">\[b_{ik} = \frac{\sum_{t=1}^TP(O,i_t=i|\overline{\lambda})I(o_t=v_k)}{\sum_{t=1}^TP(O,i_t=i|\overline{\lambda})} = \frac{\sum_{t=1,o_t=v_k}^T\gamma_t(i)}{\sum_{t=1}^T\gamma_t(i)}\]</span></p><p>è‡³æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡EMç®—æ³•æ¨å‡ºäº†å‚æ•°æ›´æ–°å…¬å¼ï¼Œå‚æ•°å­¦ä¹ çš„é—®é¢˜å°±å…¨éƒ¨è§£å†³äº†ã€‚</p><h3><span id="é¢„æµ‹ç®—æ³•">é¢„æµ‹ç®—æ³•</span></h3><p>é¢„æµ‹ç®—æ³•æœ‰ä¸¤ç§ï¼Œä¸€ä¸ªæ˜¯è¿‘ä¼¼ç®—æ³•ï¼Œå¦ä¸€ä¸ªæ˜¯Viterbiç®—æ³•ã€‚</p><h4><span id="è¿‘ä¼¼ç®—æ³•">è¿‘ä¼¼ç®—æ³•</span></h4><p>å…¶å®è¿‘ä¼¼ç®—æ³•åœ¨è®²å•ä¸ªçŠ¶æ€çš„æ¦‚ç‡ <span class="math inline">\(\gamma_t(i)\)</span> çš„æ—¶å€™å°±å·²ç»æåˆ°äº†ã€‚</p><p>åœ¨æ¯ä¸ªæ—¶åˆ» <span class="math inline">\(t\)</span> é€‰æ‹©åœ¨è¯¥æ—¶åˆ»æœ€æœ‰å¯èƒ½å‡ºç°çš„çŠ¶æ€ <span class="math inline">\(i_t^*\)</span>ï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªçŠ¶æ€åºåˆ— <span class="math inline">\(I^* = \{i_1^*, i_2^*, â€¦, i_T^*\}\)</span>ï¼Œå°†å®ƒä½œä¸ºé¢„æµ‹ç»“æœã€‚</p><p>æˆ‘ä»¬å·²ç»çŸ¥é“å•ä¸ªçŠ¶æ€çš„æ¦‚ç‡ï¼š <span class="math display">\[\gamma_t(i) =\frac{P(i_t=q_i,O|\lambda)}{P(O|\lambda)}=\frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^N\alpha_t(i)\beta_t(i)}\]</span> ç›´æ¥é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ <span class="math inline">\(i\)</span> ä½œä¸ºæœ€æœ‰å¯èƒ½çš„çŠ¶æ€å³å¯ã€‚</p><p>ä½†æ˜¯è¿™ä¹ˆè®¡ç®—æœ‰ä¸ªé—®é¢˜å°±æ˜¯å¯èƒ½ä¼šå‡ºç°æ­¤çŠ¶æ€åœ¨å®é™…ä¸­å¯èƒ½ä¸ä¼šå‘ç”Ÿçš„æƒ…å†µã€‚</p><h4><span id="viterbiç®—æ³•">Viterbiç®—æ³•</span></h4><p>Viterbiç®—æ³•å®é™…æ˜¯ç”¨<strong>åŠ¨æ€è§„åˆ’</strong>è§£HMMé¢„æµ‹é—®é¢˜ï¼Œç”¨DPæ±‚æ¦‚ç‡æœ€å¤§çš„è·¯å¾„ï¼ˆæœ€ä¼˜è·¯å¾„ï¼‰ï¼Œè¿™æ—¶ä¸€æ¡è·¯å¾„å¯¹åº”ä¸€ä¸ªçŠ¶æ€åºåˆ—ã€‚</p><p>å®šä¹‰å˜é‡ <span class="math inline">\(\delta_t(i)\)</span>ï¼šåœ¨æ—¶åˆ» <span class="math inline">\(t\)</span> çŠ¶æ€ä¸º <span class="math inline">\(i\)</span> çš„æ‰€æœ‰è·¯å¾„ä¸­ï¼Œæ¦‚ç‡çš„æœ€å¤§å€¼ã€‚å³ï¼š <span class="math display">\[\delta_t(i) = \max_{i_1,i_2, ..., i_{t-1}}P(i_t=i, i_{t-1}, ..., i_1, o_t, ..., o_1|\lambda)\]</span> åˆå€¼ï¼š <span class="math display">\[\delta_1(i) = P(i_1=i,o_1|\lambda) = \pi_ib_{io_1}\]</span> é€’æ¨ï¼š <span class="math display">\[\delta_{t+1}(i) =\max_{i_1,i_2, ..., i_{t}}P(i_{t+1}=i, i_{t}, ..., i_1, o_{t+1}, ..., o_1|\lambda) = \max_{1\leqslant j \leqslant N}(\delta_t(j)a_{ji})\cdot b_{io_{t+1}}\]</span> ç»ˆæ­¢ï¼š <span class="math display">\[P^* = \max_{1\leqslant i \leqslant N}\delta_T(i)\]</span> æœ€åæ±‚å‡ºæ¥çš„ <span class="math inline">\(P^*\)</span> æ˜¯æœ€å¤§æ¦‚ç‡è·¯å¾„çš„æ¦‚ç‡ï¼Œè‹¥è¦çŸ¥é“å…·ä½“æ˜¯å“ªæ¡è·¯è¿˜éœ€åœ¨é€’æ¨æ—¶æ ‡è®°ä¸€ä¸‹ã€‚</p><p>æˆ‘ä»¬å¤šæƒ³ä¸€ç‚¹ï¼Œçœ‹åˆ°è¿™é‡Œçš„æ—¶å€™æœ‰æœ¨æœ‰è§‰å¾—Viterbiç®—æ³•å’Œ<a href="#å‰å‘ï¼åå‘ç®—æ³•">å‰å‘ç®—æ³•</a>å¾ˆåƒï¼Ÿå¦‚æœä½ ç¿»å›å»çœ‹ä¸€çœ¼çš„è¯ï¼Œå°±ä¼šå‘ç°Viterbiç®—æ³•å’Œå‰å‘ç®—æ³•å”¯ä¸€çš„åŒºåˆ«å°±æ˜¯æŠŠæ±‚å’Œå· <span class="math inline">\(\sum\)</span> æ¢æˆäº†å–æœ€å¤§å€¼ <span class="math inline">\(\max\)</span> ï¼æ˜¯ä¸æ˜¯å¾ˆæœ‰æ„æ€ï¼Œå…¶å®æ•°å­¦é‡Œæœ‰å¾ˆå¤šè¿™ç§æƒ…å†µï¼Œä»…ä»…æ˜¯æ¢ä¸ªç¬¦å·å°±å¯ä»¥å¾—åˆ°å¦ä¸€ä¸ªå¾ˆæœ‰ç”¨çš„ç»“è®ºï¼ä½ æœ‰æ²¡æœ‰æ„Ÿå—åˆ°æ•°å­¦ä¹‹ç¾å‘¢ï¼Ÿ</p><h2><span id="æ€»ç»“">æ€»ç»“</span></h2><ul><li>HMMè§£å†³æ ‡æ³¨é—®é¢˜ï¼Œåœ¨è¯­éŸ³è¯†åˆ«ã€NLPã€ç”Ÿç‰©ä¿¡æ¯ã€æ¨¡å¼è¯†åˆ«ç­‰é¢†åŸŸè¢«å¹¿æ³›ä½¿ç”¨ã€‚</li><li>å¦‚æœè§‚æµ‹çŠ¶æ€æ˜¯è¿ç»­å€¼ï¼Œå¯å°†å¤šé¡¹å¼åˆ†å¸ƒæ”¹æˆé«˜æ–¯åˆ†å¸ƒæˆ–é«˜æ–¯æ··åˆåˆ†å¸ƒã€‚</li><li>éšé©¬å°”å¯å¤«æ¨¡å‹è™½ç„¶æœ‰ç‚¹éš¾ï¼Œä½†ä¹Ÿéå¸¸å¥½ç©ã€‚</li></ul><h2><span id="å‚è€ƒ">å‚è€ƒ</span></h2><ul><li><p>æèˆª,ç»Ÿè®¡å­¦ä¹ æ–¹æ³•,æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾,2012</p></li><li><p>Christopher M. Bishop. Pattern Recognition and Machine Learning</p><p>Chapter 10. Springer-Verlag, 2006</p></li><li><p>Radiner L,Juang B. An introduction of hidden markov Models. IEEEASSP Magazine, 1986</p></li><li><p>Lawrence R. Rabiner. A tutorial on hidden Markov models andselected applications in speech recognition. Proceedings of theIEEE 77.2, pp. 257-286, 1989</p></li><li><p>Jeff A. Bilmes. A gentle tutorial of the EM algorithm and itsapplication to parameter estimation for Gaussian mixture andhidden Markov models. 1998.</p></li><li><p>https://en.wikipedia.org/wiki/Hidden_Markov_model</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> HMM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ·±å…¥ç†è§£EMç®—æ³•</title>
      <link href="/2016/09/22/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3EM%E7%AE%97%E6%B3%95/"/>
      <url>/2016/09/22/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3EM%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p>In statistics, an <a href="https://www.wikiwand.com/en/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="noopener">expectationâ€“maximization (EM) algorithm</a> is an iterative method for finding <strong>maximum likelihood</strong> or <strong>maximum a posteriori (MAP)</strong> estimates of parameters in statistical models, where the model depends on <strong>unobserved latent variables</strong>.</p></blockquote><!-- toc --><ul><li><a href="#ç›´è§‚ç†è§£é«˜æ–¯æ··åˆæ¨¡å‹gmm">ç›´è§‚ç†è§£é«˜æ–¯æ··åˆæ¨¡å‹(GMM)</a><ul><li><a href="#æœ€å¤§ä¼¼ç„¶ä¼°è®¡">æœ€å¤§ä¼¼ç„¶ä¼°è®¡</a></li><li><a href="#é—®é¢˜-éšæœºå˜é‡æ— æ³•ç›´æ¥å®Œå…¨è§‚å¯Ÿåˆ°">é—®é¢˜ : éšæœºå˜é‡æ— æ³•ç›´æ¥(å®Œå…¨)è§‚å¯Ÿåˆ°</a></li></ul></li><li><a href="#emç®—æ³•">EMç®—æ³•</a></li><li><a href="#ä»ç†è®ºå…¬å¼æ¨å¯¼gmm">ä»ç†è®ºå…¬å¼æ¨å¯¼GMM</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="ç›´è§‚ç†è§£é«˜æ–¯æ··åˆæ¨¡å‹gmm">ç›´è§‚ç†è§£é«˜æ–¯æ··åˆæ¨¡å‹(GMM)</span></h2><h3><span id="æœ€å¤§ä¼¼ç„¶ä¼°è®¡">æœ€å¤§ä¼¼ç„¶ä¼°è®¡</span></h3><p>æœ€å¤§ä¼¼ç„¶ä¼°è®¡(<strong>Maximum Likelihood Estimation, MLE</strong>)æ˜¯ä¸ºäº†æ‰¾å‡º<strong>æ‰¾å‡ºä¸æ ·æœ¬çš„åˆ†å¸ƒæœ€æ¥è¿‘çš„æ¦‚ç‡åˆ†å¸ƒæ¨¡å‹</strong>ã€‚</p><p>ps : ç†Ÿæ‚‰æœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„åŒå­¦å¯ä»¥è·³è¿‡è¿™éƒ¨åˆ† :)</p><p>ä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼š10æ¬¡æŠ›ç¡¬å¸çš„ç»“æœæ˜¯: æ­£æ­£åæ­£æ­£æ­£ååæ­£æ­£ã€‚å‡è®¾ <span class="math inline">\(p\)</span> æ˜¯æ¯æ¬¡æŠ›ç¡¬å¸ç»“æœä¸ºæ­£çš„æ¦‚ç‡ã€‚åˆ™å¾—åˆ°è¿™æ ·çš„å®éªŒç»“æœçš„æ¦‚ç‡æ˜¯: <span class="math display">\[P = pp(1-p)ppp(1-p)(1-p)pp = p^7(1-p)^3\]</span> æœ€å¤§åŒ– <span class="math inline">\(P\)</span> è§£å¾—æœ€ä¼˜è§£æ˜¯ <span class="math inline">\(p = 0.7\)</span>ï¼Œä¸ç›´è§‚æ„Ÿè§‰ <span class="math inline">\(p = \frac{æ­£é¢æ¬¡æ•°}{æŠ›çš„æ¬¡æ•°} = \frac{7}{10} = 0.7\)</span> ä¸€è‡´ã€‚</p><p><strong>äºŒé¡¹åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡</strong></p><p>å¯¹ä¸Šé¢çš„ä¾‹å­ç®€å•æ¨å¹¿ä¸€ä¸‹ï¼šæŠ•ç¡¬å¸è¯•éªŒä¸­ï¼Œè¿›è¡Œ <span class="math inline">\(N\)</span> æ¬¡ç‹¬ç«‹è¯•éªŒï¼Œ<span class="math inline">\(n\)</span> æ¬¡æœä¸Šï¼Œ <span class="math inline">\(N-n\)</span>æ¬¡æœä¸‹ã€‚å‡å®šæœä¸Šçš„æ¦‚ç‡ä¸º <span class="math inline">\(p\)</span>, ä½¿ç”¨å¯¹æ•°ä¼¼ç„¶å‡½æ•°ä½œä¸ºç›®æ ‡å‡½æ•°ï¼š <span class="math display">\[f(n\ |\ p) = \log(p^n(1-p)^{N-n})\]</span></p><p>å¯¹ <span class="math inline">\(p\)</span> æ±‚åå¯¼å¹¶ä»¤å…¶ç­‰äºé›¶ï¼Œæ±‚å¯¹æ•°ä¼¼ç„¶å‡½æ•°æœ€å¤§æ—¶ <span class="math inline">\(p\)</span> çš„å€¼ï¼š</p><p><span class="math display">\[\begin{array}{lcr}\frac{\partial f(n\ |\ p)}{\partial p} = \frac{n}{p} - \frac{N-n}{1-p} = 0 \\\Rightarrow p = \frac{n}{N}\end{array}\]</span></p><p><strong>é«˜æ–¯åˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡</strong></p><p>è¿›ä¸€æ­¥è€ƒè™‘ï¼Œè‹¥ç»™å®šä¸€ç»„æ ·æœ¬ <span class="math inline">\(x_1,x_2...x_n\)</span>, å·²çŸ¥å®ƒä»¬æ¥è‡ªäºé«˜æ–¯åˆ†å¸ƒ <span class="math inline">\(N(Î¼,Ïƒ)\)</span>, è¯•ä¼°è®¡å‚æ•° <span class="math inline">\(Î¼,Ïƒ\)</span>ã€‚</p><p>é«˜æ–¯åˆ†å¸ƒçš„<strong>æ¦‚ç‡å¯†åº¦</strong>å‡½æ•° : <span class="math display">\[f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x-\mu)^2}{2\sigma^2})\]</span></p><p>å°† <span class="math inline">\(X_i\)</span> çš„æ ·æœ¬å€¼ <span class="math inline">\(x_i\)</span> å¸¦å…¥, å¾—åˆ°ä¼¼ç„¶å‡½æ•° :</p><p><span class="math display">\[L(x) = \prod_{i=1}^n\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x_i-\mu)^2}{2\sigma^2})\]</span></p><p>å–å¯¹æ•°å¹¶åŒ–ç®€å¾—ï¼š</p><p><span class="math display">\[\begin{array}{lcr}l(x) = \log \prod_{i=1}^n\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) \\\ \ \ \ \ = \sum_{i=1}^n\log\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) \\\ \ \ \ \ = \sum_{i=1}^n \log\frac{1}{\sqrt{2\pi}\sigma} + \sum_{i=1}^n-\frac{(x_i-\mu)^2}{2\sigma^2} \\\ \ \ \ \ = -\frac{n}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\end{array}\]</span></p><p>æœ€å¤§åŒ–ä¸Šè¿°å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œå³å¯¹ <span class="math inline">\(\mu\)</span> å’Œ <span class="math inline">\(\sigma\)</span> æ±‚åå¯¼å¹¶ä»¤å…¶ç­‰äºé›¶ï¼Œè§£å¾—ï¼š</p><p><span class="math display">\[\begin{cases}\mu = \frac{1}{n}\sum_{i=1}^nx_i \\\sigma^2 = \frac{1}{n}\sum_{i=1}^n(x_i - \mu)^2\end{cases}\]</span></p><p>è¿™ä¸¤ä¸ªå€¼å°±æ˜¯æ ·æœ¬å‡å€¼å’Œæ ·æœ¬æ–¹å·®ï¼Œå’ŒçŸ©ä¼°è®¡çš„ç»“æœæ˜¯ä¸€è‡´çš„ï¼Œå¹¶ä¸”æ„ä¹‰éå¸¸ç›´è§‚ï¼š<strong>æ ·æœ¬çš„å‡å€¼å³é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼, æ ·æœ¬çš„ä¼ªæ–¹å·®å³é«˜æ–¯åˆ†å¸ƒçš„æ–¹å·®</strong>ã€‚</p><h3><span id="é—®é¢˜-éšæœºå˜é‡æ— æ³•ç›´æ¥å®Œå…¨è§‚å¯Ÿåˆ°">é—®é¢˜ : éšæœºå˜é‡æ— æ³•ç›´æ¥(å®Œå…¨)è§‚å¯Ÿåˆ°</span></h3><p>éšæœºæŒ‘é€‰10000ä½å¿—æ„¿è€…ï¼Œæµ‹é‡ä»–ä»¬çš„èº«é«˜: è‹¥æ ·æœ¬ä¸­å­˜åœ¨ç”·æ€§å’Œå¥³æ€§ï¼Œèº«é«˜åˆ†åˆ«æœä» <span class="math inline">\(N(Î¼_1,Ïƒ_1)\)</span> å’Œ <span class="math inline">\(N(Î¼_2,Ïƒ_2)\)</span> çš„åˆ†å¸ƒï¼Œè¯•ä¼°è®¡ <span class="math inline">\(Î¼_1,Ïƒ_1,Î¼_2,Ïƒ_2\)</span> ã€‚</p><p>æ›´åŠ ä¸€èˆ¬åŒ–çš„æè¿°å¦‚ä¸‹ï¼šéšæœºå˜é‡ <span class="math inline">\(X\)</span> æ˜¯æœ‰ <span class="math inline">\(K\)</span> ä¸ªé«˜æ–¯åˆ†å¸ƒæ··åˆè€Œæˆï¼Œå–å„ä¸ªé«˜æ–¯åˆ†å¸ƒçš„æ¦‚ç‡ï¼ˆæƒå€¼ï¼‰ä¸º <span class="math inline">\(Ï€_1,Ï€_2... Ï€_K\)</span>ï¼Œç¬¬ <span class="math inline">\(i\)</span> ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼ä¸º <span class="math inline">\(Î¼_i\)</span>ï¼Œæ–¹å·®ä¸º <span class="math inline">\(Î£_i\)</span>ã€‚è‹¥è§‚æµ‹åˆ°éšæœºå˜é‡ <span class="math inline">\(X\)</span> çš„ä¸€ç³»åˆ—æ ·æœ¬ <span class="math inline">\(x_1,x_2,...,x_n\)</span>ï¼Œè¯•ä¼°è®¡å‚æ•° <span class="math inline">\(Ï€\)</span>ï¼Œ<span class="math inline">\(Î¼\)</span>ï¼Œ<span class="math inline">\(Î£\)</span>ã€‚</p><p>å»ºç«‹ç›®æ ‡å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š</p><p><span class="math display">\[l_{\pi,\mu,\Sigma}(x) = \sum_{i=1}^N\log(\sum_{k=1}^K\pi_kN(x_i\ |\ \mu_k, \Sigma_k))\]</span></p><p>ç”±äºåœ¨å¯¹æ•°å‡½æ•°é‡Œé¢åˆæœ‰åŠ å’Œï¼Œæˆ‘ä»¬<strong>æ²¡æ³•</strong>ç›´æ¥ç”¨æ±‚å¯¼è§£æ–¹ç¨‹çš„åŠæ³•ç›´æ¥æ±‚å¾—æœ€å¤§å€¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åˆ†æˆä¸¤æ­¥ã€‚</p><p><strong>ç¬¬ä¸€æ­¥ : ä¼°ç®—æ•°æ®æ¥è‡ªå“ªä¸ªç»„ä»½</strong></p><p>ä¼°è®¡æ•°æ®ç”±æ¯ä¸ªç»„ä»½ç”Ÿæˆçš„æ¦‚ç‡ : å¯¹äºæ¯ä¸ªæ ·æœ¬ <span class="math inline">\(x_i\)</span>ï¼Œå®ƒç”±ç¬¬ <span class="math inline">\(k\)</span> ä¸ªç»„ä»½ç”Ÿæˆçš„æ¦‚ç‡ä¸º</p><p><span class="math display">\[\gamma(i, k) = \frac{\pi_kN(x_i\ |\ \mu_k, \Sigma_k)}{\sum_{j=1}^K\pi_jN(x_i\ |\ \mu_j, \Sigma_j)}\]</span></p><p>ä¸Šå¼ä¸­çš„ <span class="math inline">\(Î¼\)</span> å’Œ <span class="math inline">\(Î£\)</span> ä¹Ÿæ˜¯å¾…ä¼°è®¡çš„å€¼ï¼Œå› æ­¤é‡‡æ ·è¿­ä»£æ³•: åœ¨è®¡ç®— <span class="math inline">\(Î³(i,k)\)</span> æ—¶å‡å®š <span class="math inline">\(Î¼\)</span> å’Œ <span class="math inline">\(Î£\)</span> å·²çŸ¥; <span class="math inline">\(Î³(i,k)\)</span> äº¦å¯çœ‹æˆç»„ä»½ <span class="math inline">\(k\)</span> åœ¨ç”Ÿæˆæ•°æ® <span class="math inline">\(x_i\)</span> æ—¶æ‰€åšçš„è´¡çŒ®ã€‚</p><p><strong>ç¬¬äºŒæ­¥ : ä¼°è®¡æ¯ä¸ªç»„ä»½çš„å‚æ•°</strong></p><p>å¯¹äºæ‰€æœ‰çš„æ ·æœ¬ç‚¹ï¼Œå¯¹äºç»„ä»½ <span class="math inline">\(k\)</span> è€Œè¨€ï¼Œå¯çœ‹åšç”Ÿæˆäº† <span class="math inline">\(\{\gamma(i, k)x_i\ |\ i = 1,2,...N\}\)</span> è¿™äº›ç‚¹ã€‚ç»„ä»½ <span class="math inline">\(k\)</span> æ˜¯ä¸€ä¸ªæ ‡å‡†çš„é«˜æ–¯åˆ†å¸ƒï¼Œåˆ©ç”¨ä¸Šé¢çš„ç»“è®ºå¯ä»¥å¾—å‡º:</p><p><span class="math display">\[\begin{cases}N_k = \sum_{i=1}^N\gamma(i, k) \\\mu_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)x_i \\\Sigma_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)(x_i - \mu_k)(x_i-\mu_k)^T \\\pi_k = \frac{N_k}{N} = \frac{1}{N}\sum_{i=1}^N\gamma(i, k)\end{cases}\]</span></p><p>ç„¶åå°±å¯ä»¥è¿­ä»£äº†ï¼Œæˆ‘ä»¬å…ˆæ‹è„‘é—¨ç»™ä¸€ä¸ª <span class="math inline">\(\gamma(i, k)\)</span> ï¼Œç„¶ååœ¨å·²çŸ¥ <span class="math inline">\(\gamma\)</span> çš„æƒ…å†µä¸‹è®¡ç®—ç¬¬äºŒæ­¥å››ä¸ªé‡ï¼Œç„¶åå†ä»£å…¥ç¬¬ä¸€æ­¥æ›´æ–° <span class="math inline">\(\gamma\)</span>ï¼Œç„¶åå†è®¡ç®—ç¬¬äºŒæ­¥ ... å¦‚æ­¤å¾€å¤ï¼Œç›´åˆ°æ”¶æ•›ã€‚</p><h2><span id="emç®—æ³•">EMç®—æ³•</span></h2><p>å…¶å®ä¸Šè¿°çš„é«˜æ–¯æ··åˆæ¨¡å‹å°±æ˜¯EMç®—æ³•çš„ä¸€ä¸ªåº”ç”¨ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬ç”¨å…¬å¼æ­£å¼æ¨å¯¼ä¸€ä¸‹EMç®—æ³•ã€‚</p><p><strong>EMç®—æ³•çš„æå‡º</strong></p><p>å‡å®šæœ‰è®­ç»ƒé›† <span class="math inline">\(\{x^{(1)}, x^{(2)}, ... , x^{(m)}\}\)</span>ï¼ŒåŒ…å« <span class="math inline">\(m\)</span> ä¸ªç‹¬ç«‹æ ·æœ¬ï¼Œå¸Œæœ›ä»ä¸­æ‰¾åˆ°è¯¥ç»„æ•°æ®çš„æ¨¡å‹ <span class="math inline">\(p(x,z)\)</span> çš„å‚æ•°ï¼Œå…¶ä¸­ <span class="math inline">\(z\)</span> æ˜¯ä¸€ä¸ªéšå˜é‡ã€‚</p><p><strong>é€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡å»ºç«‹ç›®æ ‡å‡½æ•°</strong></p><p><span class="math display">\[l(\theta) = \sum_{i=1}^m\log p(x\ ;\theta) = \sum_{i=1}^m\log \sum_z p(x,z;\theta)\]</span></p><p>ç”±äº <span class="math inline">\(z\)</span> æ˜¯éšéšæœºå˜é‡ï¼Œä¸æ–¹ä¾¿ç›´æ¥æ‰¾åˆ°å‚æ•°ä¼°è®¡ã€‚æ‰€ä»¥æˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼šè®¡ç®— <span class="math inline">\(l(Î¸)\)</span> ä¸‹ç•Œï¼Œæ±‚è¯¥ä¸‹ç•Œçš„æœ€å¤§å€¼ï¼›é‡å¤è¯¥è¿‡ç¨‹ï¼Œç›´åˆ°æ”¶æ•›åˆ°<strong>å±€éƒ¨æœ€å¤§å€¼</strong>ã€‚</p><p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œ<span class="math inline">\(P(x\ |\ \theta)\)</span> æ˜¯æˆ‘ä»¬çš„ç›®æ ‡å‡½æ•°ï¼Œæˆ‘ä»¬æƒ³åœ¨ç»¿çº¿é‚£ä¸ªç‚¹çš„ä¸‹æ–¹æ‰¾åˆ°ä¸€ä¸ªå‡½æ•° <span class="math inline">\(r(x\ |\ \theta)\)</span>ï¼Œä½¿ <span class="math inline">\(r(x\ |\ \theta)\)</span> ä¸¥æ ¼å°äº <span class="math inline">\(P(x\ |\ \theta)\)</span>ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›åœ¨ç»¿çº¿é‚£ä¸ªç‚¹ä¸Š <span class="math inline">\(r(x\ |\ \theta) = P(x\ |\ \theta)\)</span>ã€‚æ‰¾åˆ°äº† <span class="math inline">\(r(x\ |\ \theta)\)</span> ä¹‹åæˆ‘ä»¬å¯ä»¥æ±‚ <span class="math inline">\(r(x\ |\ \theta)\)</span> çš„æœ€å¤§å€¼ï¼Œä¹Ÿå°±æ˜¯çº¢çº¿å¤„ï¼Œç„¶åé‡å¤ä»¥ä¸Šæ­¥éª¤ï¼Œç›´åˆ°æ”¶æ•›åˆ°å±€éƒ¨æœ€å¤§å€¼ã€‚</p><p><img src="/images/1474462011618.png"></p><p><strong>Jensenä¸ç­‰å¼</strong></p><p>åœ¨æ¨å¯¼å¦‚ä½•æ‰¾ä¸‹ç•Œ <span class="math inline">\(r(x\ |\ \theta)\)</span> ä¹‹å‰ï¼Œå…ˆæ¥çœ‹ä¸€ä¸‹Jensenä¸ç­‰å¼ï¼Œç­‰ä¸‹è¦ç”¨åˆ°ã€‚</p><p>è‹¥ <span class="math inline">\(f\)</span> æ˜¯å‡¸å‡½æ•°ï¼Œåˆ™ï¼š <span class="math display">\[f(\theta x + (1 - \theta) y) \leqslant \theta f(x) + (1-\theta)f(y) \]</span></p><p>æŠŠä¸Šæ¨å¹¿ä¸€ä¸‹ï¼Œè‹¥ <span class="math inline">\(\theta_1, ..., \theta_k \geqslant 0, \ \theta_1 + ... + \theta_k = 1\)</span>ï¼Œåˆ™ï¼š <span class="math display">\[f(\theta_1x_1 + ... + \theta_k\theta_k) \leqslant \theta_1f(x_1) + ... + \theta_kf(x_k)\]</span></p><p><span class="math inline">\(\theta_i\)</span> ä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ <span class="math inline">\(x_i\)</span> å‘ç”Ÿçš„æ¦‚ç‡ï¼Œè¿™æ ·çš„è¯å°±å¾—åˆ°ï¼š <span class="math display">\[f(E(x)) \leqslant E(f(x))\]</span></p><p><strong>å¯»æ‰¾ä¸‹ç•Œ</strong></p><p>æˆ‘ä»¬ç»§ç»­æ±‚ <span class="math inline">\(P(x\ |\ \theta)\)</span> çš„ä¸‹ç•Œã€‚</p><p>ä»¤ <span class="math inline">\(Q_i\)</span> æ˜¯ <span class="math inline">\(z\)</span> çš„æŸä¸€ä¸ªåˆ†å¸ƒï¼Œ<span class="math inline">\(Qiâ‰¥0\)</span>ï¼Œåº”ç”¨Jesenä¸ç­‰å¼æœ‰:</p><p><span class="math display">\[\begin{array}{lcl}l(\theta) = \sum_{i=1}^m\log \sum_z p(x,z;\theta) \\\ \ \ \ \ \ = \sum_{i=1}^m\log \sum_{z^{(i)}} p(x^{(i)},z^{(i)};\theta) \\\ \ \ \ \ \ = \sum_{i=1}^m\log \sum_{z^{(i)}} Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} \\\ \ \ \ \ \ \geqslant \sum_{i=1}^m \sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\end{array}\]</span></p><p>æœ€åé‚£ä¸ªå¼å­å³ä¸ºæˆ‘ä»¬è¦å¯»æ‰¾çš„ä¸‹ç•Œï¼Œä¸ºäº†ä½¿ç­‰å·æˆç«‹ï¼Œ<span class="math inline">\(\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\)</span> éœ€è¦æ˜¯ä¸€ä¸ªå¸¸æ•°ï¼Œå³</p><p><span class="math display">\[\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} = C\]</span></p><p>è¿›ä¸€æ­¥åˆ†æï¼Œä¸ºäº†æ»¡è¶³Jessenä¸ç­‰å¼ï¼Œè¿˜éœ€è¦ <span class="math inline">\(\sum_zQ_i(z^{(i)}) = 1\)</span>ï¼Œæ‰€ä»¥ <span class="math inline">\(Q_i(z^{(i)})\)</span> åº”è¯¥èƒ½çº¦æ‰ <span class="math inline">\(p(x^{(i)},z^{(i)}; \theta)\)</span>ï¼Œå¹¶ä¸”è¿›è¡Œå½’ä¸€åŒ–ï¼š</p><p><span class="math display">\[\begin{array}{lcl}Q_i(z^{(i)}) = \frac{p(x^{(i)},z^{(i)};\theta)}{\sum_zp(x^{(i)},z^{(i)};\theta)} \\\ \ \ \ \ \ \ \ \ \ \ = \frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)};\theta)} \\\ \ \ \ \ \ \ \ \ \ \ = p(z^{(i)}\ |\ x^{(i)}; \theta)\end{array}\]</span></p><p>è§£å‡ºæ¥å°±æ˜¯ä¸€ä¸ª<strong>æ¡ä»¶æ¦‚ç‡</strong>ï¼</p><p><strong>EMç®—æ³•æ•´ä½“æ¡†æ¶</strong></p><p><img src="/images/1474470389249.png"></p><p><strong>E step</strong>ï¼Œæ±‚æ¯ç»„æ•°æ®çš„æœŸæœ›ï¼ˆå®é™…æ˜¯æ¡ä»¶æ¦‚ç‡ï¼‰ï¼Œç„¶å<strong>M setp</strong>ï¼Œæœ€å¤§åŒ–æœŸæœ›ï¼Œä¹‹åå†ç¿»å›å»æ›´æ–°æœŸæœ›ï¼Œå¦‚æ­¤å¾€å¤ç›´è‡³æ”¶æ•›ï¼Œè¿™å°±æ˜¯æ‰€è°“<strong>æœŸæœ›æœ€å¤§åŒ–ç®—æ³•ï¼ˆEMï¼‰</strong>ã€‚</p><h2><span id="ä»ç†è®ºå…¬å¼æ¨å¯¼gmm">ä»ç†è®ºå…¬å¼æ¨å¯¼GMM</span></h2><p>éšæœºå˜é‡ <span class="math inline">\(X\)</span> æ˜¯æœ‰ <span class="math inline">\(K\)</span> ä¸ªé«˜æ–¯åˆ†å¸ƒæ··åˆè€Œæˆï¼Œå–å„ä¸ª<strong>é«˜æ–¯åˆ†å¸ƒ</strong>çš„æ¦‚ç‡ä¸º <span class="math inline">\(Ï†_1Ï†_2... Ï†_K\)</span>ï¼Œç¬¬ <span class="math inline">\(i\)</span> ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å‡å€¼ä¸º <span class="math inline">\(Î¼_i\)</span>ï¼Œæ–¹å·®ä¸º <span class="math inline">\(Î£_i\)</span>ã€‚è‹¥è§‚æµ‹åˆ°éšæœºå˜é‡ <span class="math inline">\(X\)</span> çš„ä¸€ç³»åˆ—æ ·æœ¬ <span class="math inline">\(x_1,x_2,...,x_n\)</span>ï¼Œè¯•ä¼°è®¡å‚æ•° <span class="math inline">\(Ï†\)</span>ï¼Œ<span class="math inline">\(Î¼\)</span>ï¼Œ<span class="math inline">\(Î£\)</span>ã€‚</p><p>æŒ‰ç…§EMç®—æ³•çš„æ€æƒ³ï¼Œæˆ‘ä»¬æ¥æ¨å¯¼ä¸€ä¸‹ã€‚</p><p><strong>E-step</strong></p><p><span class="math display">\[w_j^{(i)} = Q_i(z^{(i)} = j) = P(z^{(i)} = j\ |\ x^{(i)}; \phi, \mu, \Sigma)\]</span></p><p><strong>M-step</strong></p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \sum_{i=1}^m \sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\phi, \mu, \Sigma)}{Q_i(z^{(i)})} \\= \sum_{i=1}^m \sum_{j=1}^k Q_i(z^{(i)} = j)\log\frac{p(x^{(i)}|z^{(i)}=j; \mu, \Sigma)p(z^{(i)}=j; \phi)}{Q_i(z^{(i)} = j)} \\= \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \frac{\frac{1}{(2\pi)^{2/n}|\Sigma_j|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot \phi_j}{w_j^{(i)}}\end{array}\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(p(z^{(i)}=j; \phi)\)</span> ä¸ºç¬¬ <span class="math inline">\(i\)</span> ä¸ªæ ·æœ¬çš„éšå˜é‡å±äº <span class="math inline">\(j\)</span> ç±»çš„æ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯ <span class="math inline">\(\phi_j\)</span>ã€‚</p><p>æŠŠä¸Šå¼å¯¹å‡å€¼ <span class="math inline">\(\mu_l\)</span> æ±‚åå¯¼å¾—ï¼š</p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \bigtriangledown_{\mu_l} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \frac{\frac{1}{(2\pi)^{2/n}|\Sigma_j|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot \phi_j}{w_j^{(i)}} \\= \bigtriangledown_{\mu_l} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)} (-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j)) \\= \sum_{i=1}^m w_l^{(i)}(\Sigma_l^{-1}x^{(i)}-\Sigma_l^{-1}\mu_l)\end{array}\]</span></p><blockquote><p>è¡¥å……ï¼š<span class="math inline">\(\frac{\partial(x^TAx)}{\partial x} = 2Ax\)</span></p></blockquote><p>ä»¤ä¸Šå¼ç­‰äº <span class="math inline">\(0\)</span>ï¼Œè§£çš„å‡å€¼ï¼š</p><p><span class="math display">\[\mu_l = \frac{\sum_{i=1}^mw^{(i)}_lx^{(i)}}{\sum_{i=1}^mw^{(i)}_l}\]</span></p><p>å¯¹ <span class="math inline">\(\Sigma_j\)</span> æ±‚åå¯¼å¹¶ä»¤å…¶ç­‰äºé›¶å¯ä»¥å¾—å‡ºï¼š</p><p><span class="math display">\[\Sigma_j = \frac{\sum_{i=1}^mw^{(i)}_j(x^{(i)}-\mu_j)(x^{(i)}-\mu_j)^T}{\sum_{i=1}^mw^{(i)}_j}\]</span></p><p>ç»§ç»­å¯¹ <span class="math inline">\(\phi_j\)</span> æ±‚åå¯¼å¾—åˆ°ï¼š</p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \bigtriangledown_{\phi_j} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \frac{\frac{1}{(2\pi)^{2/n}|\Sigma_j|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot \phi_j}{w_j^{(i)}} \\= \bigtriangledown_{\phi_j} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \phi_j\end{array}\]</span></p><p>æˆ‘ä»¬å‘ç°ä»¤å…¶ç­‰äºé›¶å¹¶ä¸èƒ½è§£å‡º <span class="math inline">\(\phi_j\)</span>ï¼Œè€Œä¸” <span class="math inline">\(\phi_j\)</span> è¿˜æœ‰ä¸€ä¸ªç­‰å€¼çº¦æŸï¼š<span class="math inline">\(\sum_{j=1}^k\phi_j = 1\)</span>ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨<strong>Lagrangeä¹˜æ•°</strong>æ³•æ¥æ±‚è§£è¿™ä¸ªçº¦æŸé—®é¢˜ã€‚</p><p><strong>å»ºç«‹Lagrangeå‡½æ•°</strong></p><p><span class="math display">\[L(\phi, \beta) = \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \phi_j + \beta(\sum_{j=1}^k\phi_j  - 1)\]</span></p><p>å¯¹Lagrangeå‡½æ•°æ±‚åå¯¼ï¼š</p><p><span class="math display">\[\frac{\partial}{\partial \phi_j}L(\phi,\beta) = \sum_{i=1}^m\frac{w^{(i)}_j}{\phi_j} + \beta\]</span></p><p>ä»¤å…¶ç­‰äºé›¶ï¼š</p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \ \sum_{i=1}^m\frac{w^{(i)}_j}{\phi_j} + \beta = 0 \\\Rightarrow \sum_{i=1}^m w^{(i)}_j + \beta\cdot \phi_j = 0 \\\Rightarrow \sum_{j=1}^k\sum_{i=1}^m w^{(i)}_j + \sum_{i=1}^k\beta\cdot \phi_j = 0 \\\Rightarrow \sum_{i=1}^m\sum_{j=1}^k w^{(i)}_j + \beta = 0 \\\Rightarrow \sum_{i=1}^m1 + \beta = 0 \\\Rightarrow \beta = -m \\\Rightarrow \sum_{i=1}^m\frac{w^{(i)}_j}{\phi_j} -m = 0 \\\Rightarrow \phi_j = \frac{1}{m}\sum_{i=1}^mw^{(i)}_j\end{array}\]</span></p><p><strong>æ€»ç»“</strong></p><p>å¯¹äºæ‰€æœ‰çš„æ•°æ®ç‚¹ï¼Œå¯ä»¥çœ‹ä½œç»„ä»½ <span class="math inline">\(k\)</span> ç”Ÿæˆäº†è¿™äº›ç‚¹ã€‚ç»„ä»½ <span class="math inline">\(k\)</span> æ˜¯ä¸€ä¸ªæ ‡å‡†çš„é«˜æ–¯åˆ†å¸ƒï¼Œæ€»ç»“ä¸Šé¢çš„ç»“è®ºï¼š</p><p><span class="math display">\[\begin{cases}N_k = \sum_{i=1}^N\gamma(i, k) \\\mu_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)x_i \\\Sigma_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)(x_i - \mu_k)(x_i-\mu_k)^T \\\pi_k = \frac{N_k}{N} = \frac{1}{N}\sum_{i=1}^N\gamma(i, k)\end{cases}\]</span></p><p>å¾—åˆ°äº†ä¸ç›´è§‚ç†è§£GMMä¸€æ ·çš„å…¬å¼ï¼</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Statistics </tag>
            
            <tag> EM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ·±å…¥ç†è§£èšç±»ç®—æ³•</title>
      <link href="/2016/09/19/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
      <url>/2016/09/19/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://www.wikiwand.com/zh/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90" target="_blank" rel="noopener">èšç±»åˆ†æ</a>ï¼ˆè‹±è¯­ï¼šCluster analysisï¼‰æ˜¯å¯¹äºç»Ÿè®¡æ•°æ®åˆ†æçš„ä¸€é—¨æŠ€æœ¯ï¼Œåœ¨è®¸å¤šé¢†åŸŸå—åˆ°å¹¿æ³›åº”ç”¨ï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ ï¼Œæ•°æ®æŒ–æ˜ï¼Œæ¨¡å¼è¯†åˆ«ï¼Œå›¾åƒåˆ†æä»¥åŠç”Ÿç‰©ä¿¡æ¯ã€‚èšç±»æ˜¯æŠŠç›¸ä¼¼çš„å¯¹è±¡é€šè¿‡é™æ€åˆ†ç±»çš„æ–¹æ³•åˆ†æˆä¸åŒçš„ç»„åˆ«æˆ–è€…æ›´å¤šçš„å­é›†ï¼ˆsubsetï¼‰ï¼Œè¿™æ ·è®©åœ¨åŒä¸€ä¸ªå­é›†ä¸­çš„æˆå‘˜å¯¹è±¡éƒ½æœ‰ç›¸ä¼¼çš„ä¸€äº›å±æ€§ï¼Œå¸¸è§çš„åŒ…æ‹¬åœ¨åæ ‡ç³»ä¸­æ›´åŠ çŸ­çš„ç©ºé—´è·ç¦»ç­‰ã€‚</p></blockquote><!-- toc --><ul><li><a href="#è·ç¦»åº¦é‡æ–¹å¼">è·ç¦»åº¦é‡æ–¹å¼</a></li><li><a href="#k-means">K-Means</a></li><li><a href="#å¯†åº¦èšç±»">å¯†åº¦èšç±»</a><ul><li><a href="#dbscan">DBSCAN</a></li><li><a href="#å¯†åº¦æœ€å¤§å€¼èšç±»">å¯†åº¦æœ€å¤§å€¼èšç±»</a></li></ul></li><li><a href="#è°±èšç±»">è°±èšç±»</a><ul><li><a href="#åŸºç¡€çŸ¥è¯†">åŸºç¡€çŸ¥è¯†</a></li><li><a href="#è°±å’Œè°±èšç±»">è°±å’Œè°±èšç±»</a></li></ul></li><li><a href="#å‚è€ƒ">å‚è€ƒ</a></li></ul><!-- tocstop --><a id="more"></a><p><strong>å®šä¹‰</strong></p><p>èšç±»å°±æ˜¯å¯¹å¤§é‡<strong>æœªçŸ¥æ ‡æ³¨</strong>çš„æ•°æ®é›†ï¼ŒæŒ‰æ•°æ®çš„<strong>å†…åœ¨ç›¸ä¼¼æ€§</strong>å°†æ•°æ®é›†åˆ’åˆ†ä¸ºå¤šä¸ªç±»åˆ«ï¼Œä½¿ç±»åˆ«<strong>å†…</strong>çš„æ•°æ®<strong>ç›¸ä¼¼åº¦è¾ƒå¤§</strong>è€Œç±»åˆ«<strong>é—´</strong>çš„æ•°æ®<strong>ç›¸ä¼¼åº¦è¾ƒå°</strong>ã€‚æ˜¾ç„¶èšç±»ç®—æ³•å±äº<strong>æ— ç›‘ç£</strong>å­¦ä¹ ã€‚</p><h2><span id="è·ç¦»åº¦é‡æ–¹å¼">è·ç¦»åº¦é‡æ–¹å¼</span></h2><p>åº¦é‡æ•°æ®é—´çš„è·ç¦»/ç›¸ä¼¼æ€§æœ‰ä¸€ç³»åˆ—ä¸åŒçš„æ–¹å¼ï¼š</p><ul><li>é—µå¯å¤«æ–¯åŸºè·ç¦»Minkowski/æ¬§å¼è·ç¦»ï¼š <span class="math display">\[dist(X, Y) = (\sum_{i=1}^N(x_i - y_i)^p)^{\frac{1}{p}}\]</span></li><li>æ°å¡å¾·ç›¸ä¼¼ç³»æ•°(Jaccard) ï¼š <span class="math display">\[J(A, B) = \frac{|A\cap B|}{|A\cup B|}\]</span></li><li>ä½™å¼¦ç›¸ä¼¼åº¦(cosine similarity)ï¼š <span class="math display">\[\cos(\theta) = \frac{a^Tb}{|a|\cdot|b|}\]</span></li><li>Pearsonç›¸ä¼¼ç³»æ•°ï¼š <span class="math display">\[\rho_{XY} = \frac{cov(X, Y)}{\sigma_X\sigma_Y} = \frac{E[(X - \mu_x)(Y - \mu_y)]}{\sigma_X\sigma_Y} = \frac{\sum_{i=1}^n(x_i - \mu_x)(y_i - \mu_y)}{\sqrt{\sum_{i=1}^n(x_i - \mu_x)^2}\cdot\sqrt{\sum_{i=1}^n(y_i - \mu_y)^2}}\]</span></li><li>ç›¸å¯¹ç†µ(K-Lè·ç¦»)ï¼š <span class="math display">\[D(p || q) = \sum_xp(x)\log\frac{p(x)}{q(x)} = E_{p(x)}\log\frac{p(x)}{q(x)}\]</span></li><li>Hellingerè·ç¦» <span class="math display">\[D_\alpha(p||q) = \frac{1}{1-\alpha^2}(1 - \int p(x)^{\frac{1+\alpha}{2}}q(x)^{\frac{1-\alpha}{2}}dx)\]</span></li></ul><h2><span id="k-means">K-Means</span></h2><p><strong>èšç±»çš„åŸºæœ¬æ€æƒ³</strong></p><ul><li>ç»™å®šä¸€ä¸ªæœ‰ <span class="math inline">\(N\)</span> ä¸ªå¯¹è±¡çš„æ•°æ®é›†, æ„é€ æ•°æ®çš„ <span class="math inline">\(k\)</span> ä¸ªç°‡, <span class="math inline">\(kâ‰¤n\)</span>ã€‚æ»¡è¶³ä¸‹åˆ—æ¡ä»¶:<ul><li>æ¯ä¸€ä¸ªç°‡è‡³å°‘åŒ…å«ä¸€ä¸ªå¯¹è±¡</li><li>æ¯ä¸€ä¸ªå¯¹è±¡å±äºä¸”ä»…å±äºä¸€ä¸ªç°‡</li></ul></li><li>å°†æ»¡è¶³ä¸Šè¿°æ¡ä»¶çš„ <span class="math inline">\(k\)</span> ä¸ªç°‡ç§°ä½œä¸€ä¸ªåˆç†åˆ’åˆ†ï¼Œå¯¹äºç»™å®šçš„ç±»åˆ«æ•°ç›® <span class="math inline">\(k\)</span>, é¦–å…ˆç»™å‡ºåˆå§‹åˆ’åˆ†, é€šè¿‡<strong>è¿­ä»£</strong>æ”¹å˜æ ·æœ¬å’Œç°‡çš„<strong>éš¶å±</strong>å…³ç³», ä½¿å¾—æ¯ä¸€æ¬¡æ”¹è¿›ä¹‹åçš„åˆ’åˆ†æ–¹æ¡ˆéƒ½è¾ƒå‰ä¸€æ¬¡<strong>å¥½</strong>ã€‚</li></ul><p><strong>K-meansç®—æ³•</strong></p><p>K-meansç®—æ³•ï¼Œä¹Ÿè¢«ç§°ä¸ºk-å¹³å‡æˆ–k-å‡å€¼ï¼Œæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„èšç±»ç®—æ³•ã€‚</p><ul><li>å‡å®šè¾“å…¥æ ·æœ¬ä¸º <span class="math inline">\(S=x_1,x_2,...,x_m\)</span> , åˆ™ç®—æ³•æ­¥éª¤ä¸º:<ul><li>é€‰æ‹©åˆå§‹çš„ <span class="math inline">\(k\)</span> ä¸ªç±»åˆ«ä¸­å¿ƒ <span class="math inline">\(Î¼_1, Î¼_2, ..., Î¼_k\)</span></li><li>å¯¹äºæ¯ä¸ªæ ·æœ¬ <span class="math inline">\(x_i\)</span>ï¼Œå°†å…¶æ ‡è®°ä¸ºè·ç¦»ç±»åˆ«ä¸­å¿ƒæœ€è¿‘çš„ç±»åˆ«, å³: <span class="math display">\[label_i = \arg\min_{1\leqslant j \leqslant k}||x_i-\mu_j||\]</span></li><li>å°†æ¯ä¸ªç±»åˆ«ä¸­å¿ƒæ›´æ–°ä¸ºéš¶å±è¯¥ç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬çš„<strong>å‡å€¼</strong>ï¼š <span class="math display">\[\mu_j = \frac{1}{c_j}\sum_{i\in c_j}x_i\]</span></li><li>é‡å¤æœ€åä¸¤æ­¥ï¼Œç›´åˆ°ç±»åˆ«ä¸­å¿ƒçš„å˜åŒ–<strong>å°äºæŸé˜ˆå€¼</strong>ã€‚</li></ul></li><li>ä¸­æ­¢æ¡ä»¶:<ul><li>è¿­ä»£æ¬¡æ•°/ç°‡ä¸­å¿ƒå˜åŒ–ç‡/æœ€å°å¹³æ–¹è¯¯å·®MSE(MinimumSquaredError</li></ul></li></ul><p><strong>å…¬å¼åŒ–ç†è§£</strong></p><p>è®° <span class="math inline">\(K\)</span>ä¸ªç°‡ä¸­å¿ƒä¸º <span class="math inline">\(\mu_1,\mu_2,...,\mu_k\)</span> , æ¯ä¸ªç°‡çš„æ ·æœ¬æ•°ç›®ä¸º<span class="math inline">\(N_1,N_2,...,N_k\)</span>ã€‚ å‡è®¾ä½¿ç”¨å¹³æ–¹è¯¯å·®ä½œä¸ºç›®æ ‡å‡½æ•°ï¼š <span class="math display">\[J(\mu_1, ... \mu_k) = \frac{1}{2}\sum_{j=1}^K\sum_{i=1}^{N_j}(x_i - \mu_j)^2\]</span></p><p>å¯¹å®ƒæ±‚åå¯¼å¹¶ä»¤å…¶ç­‰äºé›¶å¾—ï¼š</p><p><span class="math display">\[\frac{\partial J}{\partial \mu_j} = -\sum_{i=1}^{N_j}(x_i - \mu_j) = 0 \Rightarrow \mu_j = \frac{1}{N_j}\sum_{i=1}^{N_j}x_i\]</span></p><p>æ­£å¥½å’ŒK-meanç®—æ³•ä¸­çš„èšç±»ä¸­å¿ƒæ›´æ–°è§„åˆ™ç›¸åŒï¼Œå³æ¯ä¸ªç±»åˆ«ä¸­å¿ƒæ›´æ–°ä¸ºéš¶å±è¯¥ç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬çš„<strong>å‡å€¼</strong>ï¼Œã€‚æ‰€ä»¥å®é™…ä¸ŠK-meanç®—æ³•çš„æŸå¤±å‡½æ•°å°±æ˜¯ä¸Šé¢çš„<strong>å‡æ–¹è¯¯å·®æŸå¤±</strong>ï¼Œæ›´æ–°è§„åˆ™ä¹Ÿæ˜¯<strong>æ¢¯åº¦ä¸‹é™</strong>ï¼Œè€Œå‡æ–¹è¯¯å·®æŸå¤±æ˜¯å‡è®¾è¯¯å·®æœä»<strong>é«˜æ–¯åˆ†å¸ƒ</strong>ï¼ˆæ¨å¯¼è§<a href="https://www.liuhe.website/index.php?/Articles/single/48" target="_blank" rel="noopener">æ­¤å¤„</a>ï¼‰ï¼ä¹Ÿå°±æ˜¯è¯´ï¼ŒK-meanç®—æ³•æ˜¯å‡è®¾æ¯ä¸ªç°‡çš„è¯¯å·®æ˜¯æœä»æ­£æ€åˆ†å¸ƒçš„ï¼Œè™½ç„¶è¿™ä¸ªå…ˆéªŒæ¡ä»¶å¾ˆå¼ºï¼Œä½†å¦‚æœå®é™…æƒ…å†µä¸æ˜¯è¿™æ ·ï¼ŒK-meanç®—æ³•ä¹Ÿå¯èƒ½ç»™å‡º<strong>å¾ˆå¥½</strong>çš„èšç±»ç»“æœã€‚</p><p><strong>K-meansç®—æ³•è¿˜å¯¹å¼‚å¸¸ç‚¹å’Œåˆå§‹å€¼æ¯”è¾ƒæ•æ„Ÿ</strong></p><p>è‹¥ç°‡ä¸­å«æœ‰å¼‚å¸¸ç‚¹ï¼Œå°†å¯¼è‡´å‡å€¼åç¦»ä¸¥é‡ã€‚ä»¥ä¸€ç»´æ•°æ®ä¸ºä¾‹ : æ•°ç»„ <span class="math inline">\(1, 2, 3, 4, 100\)</span> çš„å‡å€¼ä¸º <span class="math inline">\(22\)</span>ï¼Œæ˜¾ç„¶ç¦»å¤§å¤šæ•°æ•°æ®éƒ½æ¯”è¾ƒè¿œï¼Œè‹¥æ”¹æˆæ±‚æ•°ç»„çš„ä¸­ä½æ•° <span class="math inline">\(3\)</span>ï¼Œåœ¨è¯¥å®ä¾‹ä¸­æ›´ä¸ºç¨³å¦¥ã€‚è¿™ç§èšç±»æ–¹å¼å³<strong>K-Mediodsèšç±»(Kä¸­å€¼èšç±»)</strong>ï¼Œç›¸å½“äºæŠŠæŸå¤±å‡½æ•°æ¢æˆäº†ç»å¯¹è¯¯å·®æŸå¤±ã€‚</p><p>è‹¥ç±»ä¸­å¿ƒåˆå§‹å€¼ä¸åŒï¼ŒK-meansç®—æ³•å¯èƒ½ä¼šå¾—åˆ°å®Œå…¨ä¸åŒçš„ç»“æœï¼ˆå¯èƒ½æ˜¯ä¸å¥½çš„ï¼‰ï¼Œæ¯”å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/1474016250691.png"></p><p><strong>æ€»ç»“</strong></p><ul><li>ä¼˜ç‚¹<ul><li>æ˜¯è§£å†³èšç±»é—®é¢˜çš„ä¸€ç§ç»å…¸ç®—æ³•ï¼Œ<strong>ç®€å•</strong>ã€<strong>å¿«é€Ÿ</strong></li><li>å¯¹å¤„ç†å¤§æ•°æ®é›†ï¼Œè¯¥ç®—æ³•ä¿æŒ<strong>å¯ä¼¸ç¼©æ€§</strong>å’Œ<strong>é«˜æ•ˆç‡</strong></li><li>å½“ç°‡è¿‘ä¼¼ä¸º<strong>é«˜æ–¯åˆ†å¸ƒ</strong>æ—¶ï¼Œå®ƒçš„æ•ˆæœè¾ƒå¥½</li><li>å¯ä½œä¸ºå…¶ä»–èšç±»æ–¹æ³•çš„åŸºç¡€ç®—æ³•ï¼Œå¦‚<a href="#è°±èšç±»">è°±èšç±»</a></li></ul></li><li>ç¼ºç‚¹<ul><li>åœ¨ç°‡çš„å¹³å‡å€¼å¯è¢«å®šä¹‰çš„æƒ…å†µä¸‹æ‰èƒ½ä½¿ç”¨ï¼Œå¯èƒ½ä¸é€‚ç”¨äºæŸäº›åº”ç”¨</li><li>å¿…é¡»äº‹å…ˆç»™å‡º <span class="math inline">\(k\)</span> (è¦ç”Ÿæˆçš„ç°‡çš„æ•°ç›®)ï¼Œè€Œä¸”å¯¹åˆå€¼æ•æ„Ÿ, å¯¹äºä¸åŒçš„åˆå§‹å€¼ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸åŒç»“æœ</li><li>ä¸é€‚åˆäºå‘ç°éå‡¸å½¢çŠ¶çš„ç°‡æˆ–è€…å¤§å°å·®åˆ«å¾ˆå¤§çš„ç°‡</li><li>å¯¹èºå£°å’Œå­¤ç«‹ç‚¹æ•°æ®æ•æ„Ÿ</li></ul></li></ul><h2><span id="å¯†åº¦èšç±»">å¯†åº¦èšç±»</span></h2><p>å¯†åº¦èšç±»æ–¹æ³•çš„æŒ‡å¯¼æ€æƒ³æ˜¯ï¼Œåªè¦æ ·æœ¬ç‚¹çš„<strong>å¯†åº¦</strong>å¤§äºæŸé˜ˆå€¼ï¼Œåˆ™å°†è¯¥æ ·æœ¬æ·»åŠ åˆ°æœ€è¿‘çš„ç°‡ä¸­ã€‚</p><p>è¿™ç±»ç®—æ³•èƒ½å…‹æœåŸºäºè·ç¦»çš„ç®—æ³•åªèƒ½å‘ç°â€œ<em>ç±»åœ†å½¢</em>â€(<em>å‡¸</em>)çš„èšç±»çš„ç¼ºç‚¹ï¼Œå¯å‘ç°<strong>ä»»æ„å½¢çŠ¶çš„ç°‡</strong>, ä¸”<strong>å¯¹å™ªå£°æ•°æ®ä¸æ•æ„Ÿ</strong>ã€‚ä½†è®¡ç®—å¯†åº¦å•å…ƒçš„<strong>è®¡ç®—å¤æ‚åº¦å¤§</strong>ï¼Œéœ€è¦å»ºç«‹ç©ºé—´ç´¢å¼•æ¥é™ä½è®¡ç®—é‡ã€‚å¸¸ç”¨å¯†åº¦èšç±»çš„ç®—æ³•æœ‰ï¼š * DBSCAN * å¯†åº¦æœ€å¤§å€¼ç®—æ³•</p><h3><span id="dbscan">DBSCAN</span></h3><p><strong>Density-Based Spatial Clustering of Applications with Noise</strong></p><p>å®ƒæ˜¯ä¸€ä¸ªæ¯”è¾ƒæœ‰ä»£è¡¨æ€§çš„åŸºäºå¯†åº¦çš„èšç±»ç®—æ³•ã€‚ ä¸åˆ’åˆ†å’Œå±‚æ¬¡èšç±»æ–¹æ³•ä¸åŒï¼Œå®ƒå°†ç°‡å®šä¹‰ä¸º<strong>å¯†åº¦ç›¸è¿çš„ç‚¹çš„æœ€å¤§é›†åˆ</strong>ï¼Œèƒ½å¤ŸæŠŠå…·æœ‰è¶³å¤Ÿé«˜å¯†åº¦çš„åŒºåŸŸåˆ’åˆ†ä¸ºç°‡ï¼Œå¹¶å¯åœ¨æœ‰â€œå™ªå£°â€ çš„æ•°æ®ä¸­å‘ç°ä»»æ„å½¢çŠ¶çš„èšç±»ã€‚</p><p>å…ˆæ¥ä»‹ç»ä¸€äº›ç›¸å…³æ¦‚å¿µï¼š</p><ul><li>å¯¹è±¡çš„ <span class="math inline">\(Îµ\)</span>-é‚»åŸŸ : ç»™å®šå¯¹è±¡åœ¨åŠå¾„ <span class="math inline">\(Îµ\)</span> å†…çš„åŒºåŸŸ</li><li>æ ¸å¿ƒå¯¹è±¡ : å¯¹äºç»™å®šçš„æ•°ç›® <span class="math inline">\(m\)</span>, å¦‚æœä¸€ä¸ªå¯¹è±¡çš„ <span class="math inline">\(Îµ\)</span>- é‚»åŸŸè‡³å°‘åŒ…å« <span class="math inline">\(m\)</span> ä¸ªå¯¹è±¡, åˆ™ç§°è¯¥å¯¹è±¡ä¸º<strong>æ ¸å¿ƒå¯¹è±¡</strong></li><li>ç›´æ¥å¯†åº¦å¯è¾¾ : ç»™å®šä¸€ä¸ªå¯¹è±¡é›†åˆ <span class="math inline">\(D\)</span>, å¦‚æœ <span class="math inline">\(p\)</span> æ˜¯åœ¨ <span class="math inline">\(q\)</span> çš„ <span class="math inline">\(Îµ\)</span>-é‚»åŸŸå†…, è€Œ <span class="math inline">\(q\)</span> æ˜¯ä¸€ä¸ªæ ¸å¿ƒå¯¹è±¡, æˆ‘ä»¬è¯´å¯¹è±¡ <span class="math inline">\(p\)</span> ä»å¯¹è±¡ <span class="math inline">\(q\)</span> å‡ºå‘æ˜¯ç›´æ¥å¯†åº¦å¯è¾¾çš„</li></ul><p>å¦‚å³å›¾ <span class="math inline">\(Îµ=1\)</span>cm, <span class="math inline">\(m=5\)</span>, <img src="/images/1474017928793.png"> <span class="math inline">\(q\)</span>æ˜¯ä¸€ä¸ªæ ¸å¿ƒå¯¹è±¡, ä»å¯¹è±¡ <span class="math inline">\(q\)</span> å‡ºå‘åˆ°å¯¹è±¡ <span class="math inline">\(p\)</span> æ˜¯<strong>ç›´æ¥å¯†åº¦å¯è¾¾</strong>çš„ã€‚</p><ul><li><p>å¯†åº¦å¯è¾¾ : å¦‚æœå­˜åœ¨ä¸€ä¸ªå¯¹è±¡é“¾ <span class="math inline">\(p_1p_2...p_n,p_1=q,p_n=p\)</span>, å¯¹ <span class="math inline">\(p_iâˆˆD\)</span>, <span class="math inline">\((1â‰¤i â‰¤n)\)</span>, <span class="math inline">\(p_{i+1}\)</span> æ˜¯ä» <span class="math inline">\(p_i\)</span> å…³äº <span class="math inline">\(Îµ\)</span> å’Œ <span class="math inline">\(m\)</span> <strong>ç›´æ¥å¯†åº¦å¯è¾¾</strong>çš„, åˆ™å¯¹è±¡ <span class="math inline">\(p\)</span> æ˜¯ä»å¯¹è±¡ <span class="math inline">\(q\)</span> å…³äº <span class="math inline">\(Îµ\)</span> å’Œ <span class="math inline">\(m\)</span> <strong>å¯†åº¦å¯è¾¾</strong>çš„ã€‚å¦‚ä¸‹å›¾:<img src="/images/1474018471590.png"></p></li><li>å¯†åº¦ç›¸è¿ : å¦‚æœå¯¹è±¡é›†åˆ <span class="math inline">\(D\)</span> ä¸­å­˜åœ¨ä¸€ä¸ªå¯¹è±¡ <span class="math inline">\(o\)</span>, ä½¿å¾—å¯¹è±¡ <span class="math inline">\(p\)</span> å’Œ <span class="math inline">\(q\)</span> æ˜¯ä» <span class="math inline">\(o\)</span> å…³äº <span class="math inline">\(Îµ\)</span> å’Œ <span class="math inline">\(m\)</span> å¯†åº¦å¯è¾¾çš„, é‚£ä¹ˆå¯¹è±¡ <span class="math inline">\(p\)</span> å’Œ <span class="math inline">\(q\)</span> æ˜¯å…³äº <span class="math inline">\(Îµ\)</span> å’Œ <span class="math inline">\(m\)</span> å¯†åº¦ç›¸è¿çš„ã€‚å¦‚ä¸‹å›¾ï¼š <img src="/images/1474018209712.png"></li><li><strong>ç°‡</strong> : ä¸€ä¸ªåŸºäºå¯†åº¦çš„ç°‡æ˜¯æœ€å¤§çš„<strong>å¯†åº¦ç›¸è¿</strong>å¯¹è±¡çš„é›†åˆ</li><li><p>å™ªå£° : ä¸åŒ…å«åœ¨ä»»ä½•ç°‡ä¸­çš„å¯¹è±¡ç§°ä¸ºå™ªå£°</p></li></ul><p><strong>DBSCANç®—æ³•æµç¨‹</strong></p><ul><li>å¦‚æœä¸€ä¸ªç‚¹ <span class="math inline">\(p\)</span> çš„ <span class="math inline">\(Îµ\)</span>-é‚»åŸŸåŒ…å«å¤šäº <span class="math inline">\(m\)</span> ä¸ªå¯¹è±¡, åˆ™åˆ›å»ºä¸€ä¸ª <span class="math inline">\(p\)</span> ä½œä¸ºæ ¸å¿ƒå¯¹è±¡çš„æ–°ç°‡</li><li>å¯»æ‰¾å¹¶åˆå¹¶æ ¸å¿ƒå¯¹è±¡<strong>ç›´æ¥</strong>å¯†åº¦å¯è¾¾çš„å¯¹è±¡</li><li>æ²¡æœ‰æ–°ç‚¹å¯ä»¥æ›´æ–°ç°‡æ—¶, ç®—æ³•ç»“æŸ</li></ul><p><img src="/images/1474018857997.png"></p><p>ç”±è¯¥è¿‡ç¨‹æˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼š * æ¯ä¸ªç°‡è‡³å°‘åŒ…å«ä¸€ä¸ªæ ¸å¿ƒå¯¹è±¡ * éæ ¸å¿ƒå¯¹è±¡å¯ä»¥æ˜¯ç°‡çš„ä¸€éƒ¨åˆ†, æ„æˆäº†ç°‡çš„è¾¹ç¼˜(edge) * åŒ…å«è¿‡å°‘å¯¹è±¡çš„ç°‡è¢«è®¤ä¸ºæ˜¯å™ªå£°</p><h3><span id="å¯†åº¦æœ€å¤§å€¼èšç±»">å¯†åº¦æœ€å¤§å€¼èšç±»</span></h3><p>å¯†åº¦æœ€å¤§å€¼èšç±»æ˜¯ä¸€ç§ç®€æ´ä¼˜ç¾çš„èšç±»ç®—æ³•ï¼Œå¯ä»¥è¯†åˆ«å„ç§å½¢çŠ¶çš„ç±»ç°‡ï¼Œå¹¶ä¸”å‚æ•°å¾ˆå®¹æ˜“ç¡®å®šã€‚</p><p><strong>ä¸€äº›å®šä¹‰</strong></p><ul><li><strong>å±€éƒ¨å¯†åº¦</strong> <span class="math inline">\(\rho_i = \sum_j\chi(d_{ij} - d_c)\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(\chi(x) = 1, \ if\ x &lt; 0, \ otherwise \ \chi(x) = 0\)</span>ï¼Œ<span class="math inline">\(d_c\)</span> æ˜¯ä¸€ä¸ªæˆªæ–­è·ç¦»ï¼Œ<span class="math inline">\(Ï_i\)</span> å³åˆ°å¯¹è±¡ <span class="math inline">\(i\)</span> çš„è·ç¦»å°äº <span class="math inline">\(d_c\)</span> çš„å¯¹è±¡çš„ä¸ª æ•°ã€‚ç”±äºè¯¥ç®—æ³•<strong>åªå¯¹ <span class="math inline">\(Ï_i\)</span> çš„ç›¸å¯¹å€¼æ•æ„Ÿ</strong>, æ‰€ä»¥å¯¹ <span class="math inline">\(d_c\)</span> çš„é€‰æ‹©æ˜¯ç¨³å¥çš„, ä¸€ç§æ¨èåšæ³•æ˜¯é€‰æ‹© <span class="math inline">\(d_c\)</span>, ä½¿å¾—å¹³å‡æ¯ä¸ªç‚¹çš„é‚»å±…æ•°ä¸ºæ‰€æœ‰ç‚¹çš„ 1%-2%</li><li><strong>é«˜å±€éƒ¨å¯†åº¦ç‚¹è·ç¦»</strong> <span class="math inline">\(\delta_i = \min_{j:\rho_j &gt; \rho_i}(d_{ij})\)</span><ul><li>ç®€ç§°ï¼šé«˜å¯†è·ç¦»</li><li>åœ¨å¯†åº¦é«˜äºå¯¹è±¡ <span class="math inline">\(i\)</span> çš„æ‰€æœ‰å¯¹è±¡ä¸­, åˆ°å¯¹è±¡ <span class="math inline">\(i\)</span> æœ€è¿‘çš„è·ç¦», å³é«˜å±€éƒ¨å¯†åº¦ç‚¹è·ç¦»</li></ul></li><li>å¯¹äºå¯†åº¦<strong>æœ€å¤§</strong>çš„å¯¹è±¡, è®¾ç½® <span class="math inline">\(Î´_i=\max(d_{ij})\)</span> (å³ : è¯¥é—®é¢˜ä¸­çš„æ— ç©·å¤§)<ul><li>åªæœ‰é‚£äº›å¯†åº¦æ˜¯<strong>å±€éƒ¨æˆ–è€…å…¨å±€æœ€å¤§</strong>çš„ç‚¹æ‰ä¼šæœ‰<strong>è¿œå¤§äºæ­£å¸¸å€¼</strong>çš„é«˜å±€éƒ¨å¯†åº¦ç‚¹è·ç¦»</li></ul></li><li><strong>ç°‡çš„ä¸­å¿ƒ</strong>ï¼šé‚£äº›æœ‰ç€<strong>æ¯”è¾ƒå¤§çš„å±€éƒ¨å¯†åº¦ <span class="math inline">\(Ï_i\)</span> </strong>å’Œ<strong>å¾ˆå¤§çš„é«˜å¯†è·ç¦» <span class="math inline">\(Î´_i\)</span> </strong>çš„ç‚¹è¢«è®¤ä¸ºæ˜¯ç°‡çš„ä¸­å¿ƒ<ul><li>ç¡®å®šç°‡ä¸­å¿ƒä¹‹å, å…¶ä»–ç‚¹æŒ‰ç…§è·ç¦»å·²çŸ¥ç°‡çš„ä¸­å¿ƒæœ€è¿‘è¿›è¡Œåˆ†ç±»</li></ul></li><li><strong>å¼‚å¸¸ç‚¹</strong>ï¼š<strong>é«˜å¯†è·ç¦» <span class="math inline">\(Î´_i\)</span> è¾ƒå¤§</strong>ä½†<strong>å±€éƒ¨å¯†åº¦ <span class="math inline">\(Ï_i\)</span> è¾ƒå°</strong>çš„ç‚¹æ˜¯å¼‚å¸¸ç‚¹</li></ul><p><strong>å¯†åº¦æœ€å¤§å€¼èšç±»è¿‡ç¨‹</strong></p><p>ä¸‹å·¦å›¾æ˜¯æ‰€æœ‰ç‚¹åœ¨äºŒç»´ç©ºé—´çš„åˆ†å¸ƒ, ä¸‹å³å›¾æ˜¯ä»¥ <span class="math inline">\(Ï\)</span> ä¸ºæ¨ªåæ ‡, ä»¥ <span class="math inline">\(Î´\)</span> ä¸ºçºµåæ ‡ç»˜åˆ¶çš„å†³ç­–å›¾ã€‚å¯ä»¥çœ‹åˆ°, <span class="math inline">\(1\)</span>å’Œ <span class="math inline">\(10\)</span> ä¸¤ä¸ªç‚¹çš„ <span class="math inline">\(Ï_i\)</span> å’Œ <span class="math inline">\(Î´_i\)</span> éƒ½æ¯”è¾ƒå¤§, ä½œä¸º<strong>ç°‡çš„ä¸­å¿ƒç‚¹</strong>ã€‚<span class="math inline">\(26\)</span>ã€ <span class="math inline">\(27\)</span>ã€<span class="math inline">\(28\)</span>ä¸‰ä¸ªç‚¹çš„ <span class="math inline">\(Î´_i\)</span> ä¹Ÿæ¯”è¾ƒå¤§, ä½†æ˜¯ <span class="math inline">\(Ï_i\)</span> è¾ƒå°, æ‰€ä»¥æ˜¯<strong>å¼‚å¸¸ç‚¹</strong>ã€‚</p><p><img src="/images/1474028836544.png"></p><p><strong>è¾¹ç•Œå’Œå™ªå£°çš„é‡è®¤è¯†</strong></p><p>åœ¨èšç±»åˆ†æä¸­ï¼Œé€šå¸¸éœ€è¦ç¡®å®šæ¯ä¸ªç‚¹åˆ’åˆ†ç»™æŸä¸ªç°‡çš„<strong>å¯é æ€§</strong>:</p><ul><li>åœ¨è¯¥ç®—æ³•ä¸­ï¼Œå¯ä»¥é¦–å…ˆä¸ºæ¯ä¸ªç°‡å®šä¹‰ä¸€ä¸ª<strong>è¾¹ç•ŒåŒºåŸŸ (border region)</strong>ï¼Œäº¦å³<strong>åˆ’åˆ†ç»™è¯¥ç°‡ä½†æ˜¯è·ç¦»å…¶ä»–ç°‡çš„ç‚¹çš„è·ç¦»å°äº <span class="math inline">\(d_c\)</span> çš„ç‚¹</strong>çš„é›†åˆã€‚ç„¶åä¸ºæ¯ä¸ªç°‡æ‰¾åˆ°å…¶è¾¹ç•ŒåŒºåŸŸçš„<strong>å±€éƒ¨å¯†åº¦æœ€å¤§</strong>çš„ç‚¹ï¼Œä»¤å…¶å±€éƒ¨å¯†åº¦ä¸º <span class="math inline">\(Ï_h\)</span>ã€‚</li><li>è¯¥ç°‡ä¸­æ‰€æœ‰å±€éƒ¨å¯†åº¦å¤§äº <span class="math inline">\(Ï_h\)</span> çš„ç‚¹è¢«è®¤ä¸ºæ˜¯ç°‡æ ¸å¿ƒçš„ä¸€ éƒ¨åˆ†(äº¦å³å°†è¯¥ç‚¹åˆ’åˆ†ç»™è¯¥ç±»ç°‡çš„å¯é æ€§å¾ˆå¤§)ï¼Œå…¶ä½™çš„ç‚¹è¢«è®¤ä¸ºæ˜¯è¯¥ç±»ç°‡çš„<strong>å…‰æ™•(halo)</strong>ï¼Œäº¦å³å¯ä»¥è®¤ä¸ºæ˜¯<strong>å™ªå£°</strong>ã€‚</li></ul><h2><span id="è°±èšç±»">è°±èšç±»</span></h2><h3><span id="åŸºç¡€çŸ¥è¯†">åŸºç¡€çŸ¥è¯†</span></h3><p><strong>ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡</strong></p><p>è‹¥æ•° <span class="math inline">\(\lambda\)</span> å’Œå‘é‡ <span class="math inline">\(\overrightarrow{u}\)</span> å¯¹çŸ©é˜µ <span class="math inline">\(A\)</span> æ»¡è¶³ï¼š <span class="math display">\[A\cdot  \overrightarrow{u}= \lambda \cdot \overrightarrow{u} \]</span> åˆ™ <span class="math inline">\(\lambda\)</span> ç§°ä¸ºçŸ©é˜µ <span class="math inline">\(A\)</span> çš„ä¸€ä¸ªç‰¹å¾å€¼ï¼Œ<span class="math inline">\(\overrightarrow{u}\)</span> ä¸ºå¯¹åº”çš„ç‰¹å¾å‘é‡ã€‚</p><p>åˆ™æœ‰ä»¥ä¸‹ç»“è®ºï¼š * <strong>å®å¯¹ç§°é˜µçš„ç‰¹å¾å€¼æ˜¯å®æ•°</strong> * è¯æ˜ç•¥ * <strong>å®å¯¹ç§°é˜µä¸åŒç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡æ­£äº¤</strong> * è¯æ˜ï¼šä»¤å®å¯¹ç§°çŸ©é˜µä¸º <span class="math inline">\(A\)</span>, å…¶ä¸¤ä¸ªä¸åŒçš„ç‰¹å¾å€¼ <span class="math inline">\(Î»_1,Î»_2\)</span> å¯¹åº”çš„ç‰¹å¾å‘é‡åˆ†åˆ«æ˜¯ <span class="math inline">\(Î¼_1, Î¼_2\)</span>; * <span class="math inline">\(Î»_1,Î»_2,Î¼_1,Î¼_2\)</span> éƒ½æ˜¯<strong>å®æ•°</strong>æˆ–æ˜¯<strong>å®å‘é‡</strong> * æœ‰ <span class="math inline">\(A\mu_1 = \lambda_1\mu_1\)</span>ï¼Œä»è€Œï¼š <span class="math display">\[\begin{array}{lcr}\ \ \ \ \ A\mu_2 = \lambda_2\mu_2 \\\Rightarrow \mu_1^T A\mu_2 = \mu_1^T\lambda_2\mu_2 \\\Rightarrow (A^T\mu_1)^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\Rightarrow (A\mu_1)^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\Rightarrow (\lambda_1\mu_1)^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\Rightarrow \lambda_1\mu_1^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\end{array}\]</span> * å› ä¸º <span class="math inline">\(\lambda_1 \neq \lambda_2\)</span>ï¼Œæ‰€ä»¥ <span class="math inline">\(\mu_1^T\mu_2 = 0\)</span>ï¼Œå³ <span class="math inline">\(\mu_1,\mu_2\)</span> æ­£äº¤ã€‚</p><h3><span id="è°±å’Œè°±èšç±»">è°±å’Œè°±èšç±»</span></h3><ul><li><strong>è°±</strong>ï¼šæ–¹é˜µä½œä¸ºçº¿æ€§ç®—å­ï¼Œå®ƒçš„æ‰€æœ‰<strong>ç‰¹å¾å€¼</strong>çš„å…¨ä½“ç»Ÿç§°æ–¹é˜µçš„<strong>è°±</strong>ã€‚<ul><li>æˆ‘ä»¬è¯´ä¸€ä¸ªäººé ä¸é è°±å„¿ï¼Œå®é™…ä¸Šæ˜¯çœ‹ä»–ä»¥å‰åšè¿‡çš„äº‹çš„<strong>ç¨³å®šç¨‹åº¦</strong>ï¼Œå³<strong>æ–¹å·®</strong>ã€‚</li><li><strong>æ–¹é˜µ</strong>çš„<strong>è°±åŠå¾„</strong>ä¸º<strong>æœ€å¤§çš„ç‰¹å¾å€¼</strong></li><li>æ™®é€šçŸ©é˜µ <span class="math inline">\(A\)</span> çš„<strong>è°±åŠå¾„</strong>: <span class="math inline">\((A^TA)\)</span> çš„<strong>æœ€å¤§ç‰¹å¾å€¼</strong></li></ul></li></ul><p><strong>è°±èšç±»</strong>æ˜¯ä¸€ç§åŸºäº<strong>å›¾è®º</strong>çš„èšç±»æ–¹æ³•, é€šè¿‡å¯¹æ ·æœ¬æ•°æ®çš„<strong>æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong>çš„<strong>ç‰¹å¾å‘é‡</strong>è¿›è¡Œèšç±», ä»è€Œè¾¾åˆ°å¯¹æ ·æœ¬æ•°æ®èšç±»çš„ç›®çš„ã€‚</p><p><strong>è°±åˆ†æçš„æ•´ä½“è¿‡ç¨‹</strong></p><p>ç»™å®šä¸€ç»„æ•°æ® <span class="math inline">\(x_1,x_2,...x_n\)</span>, è®°ä»»æ„ä¸¤ä¸ªç‚¹ä¹‹é—´çš„<strong>ç›¸ä¼¼åº¦</strong>(â€œè·ç¦»â€çš„å‡å‡½æ•°)ä¸º<span class="math inline">\(s_{ij}=&lt;x_i,x_j&gt;\)</span>, å½¢æˆ<strong>ç›¸ä¼¼åº¦å›¾(similarity graph)</strong> : <span class="math inline">\(G=(V,E)\)</span> ã€‚å¦‚æœ <span class="math inline">\(x_i\)</span> å’Œ <span class="math inline">\(x_j\)</span> ä¹‹é—´çš„ç›¸ä¼¼åº¦ <span class="math inline">\(s_{ij}\)</span> å¤§äºä¸€å®šçš„é˜ˆå€¼, é‚£ä¹ˆä¸¤ä¸ªç‚¹æ˜¯è¿æ¥çš„, æƒå€¼è®°åš <span class="math inline">\(s_{ij}\)</span>ã€‚</p><p>æ¥ä¸‹æ¥, å¯ä»¥ç”¨ç›¸ä¼¼åº¦å›¾æ¥è§£å†³æ ·æœ¬æ•°æ®çš„èšç±»é—®é¢˜ : æ‰¾åˆ°å›¾çš„ä¸€ä¸ªåˆ’åˆ†, å½¢æˆè‹¥å¹²ä¸ªç»„(Group), ä½¿å¾—ä¸åŒç»„ä¹‹é—´æœ‰è¾ƒä½çš„æƒå€¼, ç»„å†…æœ‰è¾ƒé«˜çš„æƒå€¼ã€‚</p><p><strong>ä¸€äº›æ¦‚å¿µ</strong></p><ul><li>é‚»æ¥çŸ©é˜µ <span class="math inline">\(W = (w_{ij})\ \ i,j=1,...n\)</span>ï¼Œå®é™…ä¸Šè¯¥çŸ©é˜µå°±æ˜¯ç›¸ä¼¼åº¦çŸ©é˜µï¼Œå³ <span class="math inline">\(w_{ij} = s_{ij}\)</span></li><li>åº¦çŸ©é˜µ <span class="math inline">\(D = (d_{i})\ \ i = 1,...,n\)</span>ï¼Œè¯¥çŸ©é˜µæ˜¯ä¸ªå¯¹è§’é˜µï¼š <span class="math display">\[d_i = \sum_{j=1}^nw_{ij}\]</span></li><li>é«˜æ–¯ç›¸ä¼¼åº¦ <span class="math inline">\(s(x_i, x_j) = \exp(\frac{-||x_i - x_j||^2}{2\sigma^2})\)</span></li><li><strong>LaplaceçŸ©é˜µ</strong>ï¼š<span class="math inline">\(L = D - W\)</span><ul><li><span class="math inline">\(L\)</span> æ˜¯å¯¹ç§°åŠæ­£å®šçŸ©é˜µï¼Œæœ€å°ç‰¹å¾å€¼æ˜¯ <span class="math inline">\(0\)</span>ï¼Œç›¸åº”çš„ç‰¹å¾å‘é‡æ˜¯å…¨ <span class="math inline">\(1\)</span> å‘é‡ <span class="math display">\[\begin{array}{lcr}f^TLf = f^TDf - f^TWf = \sum_{i=1}^nd_if_i^2 - \sum_{i,j=1}^nf_if_jw_{ij} \\= \frac{1}{2}( \sum_{i=1}^nd_if_i^2 - 2\sum_{i,j=1}^nf_if_jw_{ij}  + \sum_{j=1}^nd_jf_j^2) \\= \frac{1}{2}\sum_{i,j=1}^nw_{ij}(f_i-f_j)^2 \geqslant 0\end{array}\]</span></li><li>å…¶ä¸­ï¼Œ<span class="math inline">\(f\)</span> ä¸ºä»»æ„çŸ©é˜µï¼Œæ‰€ä»¥ <span class="math inline">\(L\)</span> ä¸ºåŠæ­£å®šçŸ©é˜µã€‚</li></ul></li><li>Laplace çŸ©é˜µçš„å…¶å®ƒå½¢å¼ï¼š<ul><li>å¯¹ç§°LaplaceçŸ©é˜µ <span class="math inline">\(L_{sym} = D^{-\frac{1}{2}}LD^{\frac{1}{2}} = I - D^{-\frac{1}{2}}WD^{\frac{1}{2}}\)</span></li><li><strong>éšæœºæ¸¸èµ°LaplaceçŸ©é˜µ</strong> <span class="math inline">\(L_{rw} = D^{-1}L = I - D^{-1}W\)</span><ul><li>ä¹‹æ‰€ä»¥å« Random Walk æ˜¯å› ä¸º <span class="math inline">\(d_i = \sum_{j=1}^nw_{ij}\)</span>ï¼Œ<span class="math inline">\(D^{-1}W\)</span> ç›¸å½“äº <span class="math inline">\(W\)</span> çš„å…ƒç´ éƒ½å˜æˆäº† <span class="math inline">\(\frac{w_{ij}}{d_i} = \frac{w_{ij}}{\sum_{j=1}^nw_{ij}}\)</span>ï¼Œç›¸å½“äºåšäº†<strong>å½’ä¸€åŒ–</strong>ã€‚å¦‚æœä»¤ <span class="math inline">\(P = D^{-1}W\)</span>ï¼Œåˆ™ <span class="math inline">\(\sum_{j=1}^np_{ij} = 1\)</span>ï¼Œ<span class="math inline">\(p_{ij}\)</span> å°±å¯ä»¥çœ‹æˆä»ç‚¹ <span class="math inline">\(i\)</span> åˆ° <span class="math inline">\(j\)</span> çš„æ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯ Random Walk æ¨¡å‹äº†ã€‚</li></ul></li></ul></li></ul><p><strong>è°±èšç±»ç®—æ³•</strong></p><ul><li>è¾“å…¥: <span class="math inline">\(n\)</span> ä¸ªç‚¹ <span class="math inline">\(\{p_i\}\)</span>, ç°‡çš„æ•°ç›® <span class="math inline">\(k\)</span></li><li>è®¡ç®— <span class="math inline">\(nÃ—n\)</span> çš„ç›¸ä¼¼åº¦çŸ©é˜µ <span class="math inline">\(W\)</span> å’Œåº¦çŸ©é˜µ <span class="math inline">\(D\)</span>;</li><li>è®¡ç®—æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ <span class="math inline">\(L=D-W\)</span>;</li><li>è®¡ç®— <span class="math inline">\(L\)</span> çš„å‰ <span class="math inline">\(k\)</span> ä¸ªç‰¹å¾å‘é‡ <span class="math inline">\(u_1,u_2,...,u_k\)</span>ï¼ˆ<strong>ä»å°åˆ°å¤§</strong>æ’åˆ—ï¼‰;</li><li>å°† <span class="math inline">\(k\)</span> ä¸ªåˆ—å‘é‡ <span class="math inline">\(u_1,u_2,...,u_k\)</span> ç»„æˆçŸ©é˜µ <span class="math inline">\(U\)</span>, <span class="math inline">\(UâˆˆR^{nÃ—k}\)</span>;</li><li>å¯¹äº <span class="math inline">\(i=1,2,...,n\)</span>, ä»¤ <span class="math inline">\(y_iâˆˆR^k\)</span> æ˜¯ <span class="math inline">\(U\)</span> çš„ç¬¬ <span class="math inline">\(i\)</span> è¡Œçš„å‘é‡;</li><li>ä½¿ç”¨k-meansç®—æ³•å°†ç‚¹ <span class="math inline">\((y_i)_{i=1,2,...,n}\)</span> èšç±»æˆç°‡ <span class="math inline">\(C_1,C_2,...C_k\)</span>;</li><li>è¾“å‡ºç°‡ <span class="math inline">\(A_1,A_2,...A_k\)</span>, å…¶ä¸­, <span class="math inline">\(A_i=\{j\ |\ y_jâˆˆC_i\}\)</span></li></ul><p>ä½¿ç”¨å…¶å®ƒå½¢å¼çš„LaplaceçŸ©é˜µç®—æ³•æ­¥éª¤ç±»ä¼¼ã€‚</p><p>ç”±äºæœ€åèšç±»çš„è¿‡ç¨‹å®é™…ä¸Šè¿˜æ˜¯äº¤ç»™k-meansæ¥åšï¼Œæ‰€ä»¥è°±èšç±»å‰é¢æ‰€æœ‰è¿‡ç¨‹å¯ä»¥çœ‹ä½œæ˜¯ç»™k-meansæä¾›æ›´å¥½çš„ç‰¹å¾ã€‚</p><p><strong>è°±èšç±»ä¸PCAçš„è”ç³»</strong></p><p>è°±èšç±»ä¸­å–LaplaceçŸ©é˜µ <span class="math inline">\(L\)</span> <strong>ä»å°åˆ°å¤§</strong>çš„å‰ <span class="math inline">\(k\)</span> ç‰¹å¾å‘é‡ï¼Œç›¸å½“äºæŠŠæ•°æ®ä» <span class="math inline">\(n\)</span> ä¸ºé™ä½åˆ° <span class="math inline">\(k\)</span> ç»´ï¼Œå°±æ˜¯ä¸€ä¸ª<strong>é™ç»´</strong>çš„è¿‡ç¨‹ï¼Œä¸PCAæ˜¯ç±»ä¼¼çš„ã€‚PCAæ˜¯å–åŸå§‹æ•°æ®çš„<strong>åæ–¹å·®çŸ©é˜µ</strong>çš„å‰ <span class="math inline">\(k\)</span> ä¸ªç‰¹å¾å‘é‡ï¼Œåªä¸è¿‡æ˜¯<strong>ä»å¤§åˆ°å°</strong>æ’åˆ—çš„ã€‚ä¸ºä»€ä¹ˆä¼šæœ‰é¡ºåºåŒºåˆ«å‘¢ï¼ŸåŸå› æ˜¯LaplaceçŸ©é˜µ <span class="math inline">\(L = D - W\)</span> ä¸­çš„å‡å·ï¼Œä¹Ÿå°±æ˜¯ <span class="math inline">\(L\)</span> ä¸­çš„ç‰¹å¾ä¸åŸå§‹æ•°æ®ï¼ˆ<span class="math inline">\(W\)</span>ï¼‰çš„ç‰¹å¾æ˜¯ç›¸åçš„ï¼Œæ‰€ä»¥ä¸PCAå–çš„é¡ºåºç›¸åã€‚</p><p><strong>æ€è€ƒä¸æ€»ç»“</strong></p><ul><li>è°±èšç±»ä¸­çš„ <span class="math inline">\(K\)</span> å¦‚ä½•ç¡®å®š ?<ul><li><span class="math inline">\(k^* = \arg\max_k|\lambda_{k+1} - \lambda_k|\)</span></li></ul></li><li>æœ€åä¸€æ­¥K-Meansçš„ä½œç”¨æ˜¯ä»€ä¹ˆ ?<ul><li>ç›®æ ‡å‡½æ•°æ˜¯å…³äºå­å›¾åˆ’åˆ†æŒ‡ç¤ºå‘é‡çš„å‡½æ•°ï¼Œè¯¥å‘é‡çš„å€¼æ ¹æ®å­å›¾åˆ’åˆ†ç¡®å®šï¼Œæ˜¯ç¦»æ•£çš„ã€‚è¯¥é—®é¢˜æ˜¯NPçš„ï¼Œè½¬æ¢æˆæ±‚è¿ç»­å®æ•°åŸŸä¸Šçš„è§£ï¼Œæœ€åç”¨K-Meansç®—æ³•ç¦»æ•£åŒ–ã€‚</li></ul></li><li>æœªæ­£åˆ™/å¯¹ç§°/éšæœºæ¸¸èµ°æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µï¼Œé¦–é€‰å“ªä¸ªï¼Ÿ<ul><li><strong>éšæœºæ¸¸èµ°æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µ</strong></li></ul></li><li>è°±èšç±»å¯ä»¥ç”¨åˆ‡å‰²å›¾/éšæœºæ¸¸èµ°/æ‰°åŠ¨è®ºç­‰è§£é‡Š</li></ul><h2><span id="å‚è€ƒ">å‚è€ƒ</span></h2><ul><li>Alex Rodriguez, Alessandro Laio. Clustering by fast search and find of density peak. Science. 2014</li><li>Ulrike von Luxburg. A tutorial on spectral clustering. 2007</li><li>Lang K. Fixing two weaknesses of the spectral method. Advances in Neural Information Processing Systems 18, 715â€“722. MIT Press, Cambridge, 2006</li><li>Bach F, Jordan M. Learning spectral clustering. Advances in Neural Information Processing Systems 16 (NIPS). 305â€“ 312. MIT Press, Cambridge,2004</li><li>Andrew Rosenberg, Julia Hirschberg, V-Measure: A conditional entropy-based external cluster evaluation measure, 2007.</li><li>W. M. Rand. Objective criteria for the evaluation of clustering methods. Journal of the American Statistical Association. 1971</li><li>Nguyen Xuan Vinh, Julien Epps, James Bailey, Information theoretic measures for clusterings comparison, ICML 2009</li><li>Peter J. Rousseeuw, Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis. Computational and Applied Mathematics 20: 53â€“65, 1987</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Clustering </tag>
            
            <tag> K-Means </tag>
            
            <tag> DBSCAN </tag>
            
            <tag> è°±èšç±» </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ·±å…¥ç†è§£SVM</title>
      <link href="/2016/09/13/Support%20Vector%20Machine/"/>
      <url>/2016/09/13/Support%20Vector%20Machine/</url>
      
        <content type="html"><![CDATA[<blockquote><p>æ”¯æŒå‘é‡æœºï¼ˆSupport Vector Machine, SVMï¼‰æ˜¯ä¸€ç§åˆ†ç±»æ¨¡å‹ï¼Œå®ƒçš„åŸºæœ¬æ¨¡å‹æ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´ä¸Šçš„é—´éš”æœ€å¤§çš„çº¿æ€§åˆ†ç±»å™¨ã€‚SVM è¿˜åŒ…å«æ ¸æŠ€å·§ï¼Œä½¿å®ƒæˆä¸ºéçº¿æ€§åˆ†ç±»å™¨ã€‚</p></blockquote><!-- toc --><ul><li><a href="#çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœº">çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœº</a><ul><li><a href="#ç¡¬é—´éš”æœ€å¤§åŒ–">ç¡¬é—´éš”æœ€å¤§åŒ–</a></li></ul></li><li><a href="#çº¿æ€§æ”¯æŒå‘é‡æœº">çº¿æ€§æ”¯æŒå‘é‡æœº</a><ul><li><a href="#è½¯é—´éš”æœ€å¤§åŒ–">è½¯é—´éš”æœ€å¤§åŒ–</a></li></ul></li><li><a href="#éçº¿æ€§æ”¯æŒå‘é‡æœº">éçº¿æ€§æ”¯æŒå‘é‡æœº</a><ul><li><a href="#æ ¸å‡½æ•°">æ ¸å‡½æ•°</a></li></ul></li><li><a href="#smo">SMO</a></li><li><a href="#æ€»ç»“æ€è€ƒ">æ€»ç»“æ€è€ƒ</a></li><li><a href="#å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœº">çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœº</span></h2><p>å…ˆæ¥ä»‹ç»ä¸€äº›æ¦‚å¿µã€‚</p><p><strong>åˆ†å‰²è¶…å¹³é¢</strong></p><p>å®šä¹‰ï¼šè®¾ <span class="math inline">\(C\)</span> å’Œ <span class="math inline">\(D\)</span> ä¸ºä¸¤ä¸ç›¸äº¤çš„å‡¸é›†ï¼Œåˆ™å­˜åœ¨å¹³é¢ <span class="math inline">\(P\)</span>ï¼Œ<span class="math inline">\(P\)</span> å¯ä»¥å°† <span class="math inline">\(C\)</span> å’Œ <span class="math inline">\(D\)</span> å®Œå…¨åˆ†ç¦»ï¼Œåˆ™ <span class="math inline">\(P\)</span> ä¸ºä¸¤é›†åˆçš„åˆ†å‰²è¶…å¹³é¢ã€‚</p><p>é‚£ä¹ˆå¦‚ä½•å®šä¹‰ä¸¤ä¸ªé›†åˆçš„â€œæœ€ä¼˜â€åˆ†å‰²è¶…å¹³é¢ï¼Ÿå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¿™äº›çº¿éƒ½å¯ä»¥æŠŠä¸¤ä¸ªé›†åˆå®Œå…¨åˆ†å¼€ï¼Œé‚£ä¹ˆå“ªæ¡çº¿æ˜¯æœ€å¥½çš„ï¼Ÿ</p><p><img src="/images/1473584864752.png"></p><blockquote><p>ä¸¤ä¸ªé›†åˆçš„è·ç¦»ï¼Œå®šä¹‰ä¸ºä¸¤ä¸ªé›†åˆé—´å…ƒç´ çš„æœ€çŸ­è·ç¦»ã€‚</p></blockquote><p>ç›´è§‚ä¸Šæˆ‘ä»¬è®¤ä¸ºå¦‚æœæŸä¸€æ¡åˆ†å‰²çº¿ï¼ˆæˆ–è€…è¶…å¹³é¢ï¼‰ï¼Œä½¿å¾—ä¸¤ä¸ªé›†åˆåˆ°å®ƒçš„<strong>æœ€çŸ­è·ç¦»è·ç¦»æœ€å¤§</strong>ï¼Œé‚£ä¹ˆè¿™æ¡åˆ†å‰²çº¿ï¼ˆæˆ–è¶…å¹³é¢ï¼‰å°±è®¤ä¸ºæ˜¯æœ€ä¼˜çš„ï¼Œå› ä¸ºå®ƒæœ€å¤§åŒ–åœ°åˆ†å¼€äº†ä¸¤ä¸ªé›†åˆã€‚</p><p><img src="/images/1473585333350.png"></p><p>ä¸Šå›¾çº¢çº¿ä¸ºæœ€ä¼˜åˆ†å‰²çº¿ï¼Œå¹³è¡Œäºå®ƒçš„å·¦å³ä¸¤æ¡è™šçº¿ä¸ºä¸¤ä¸ªé›†åˆçš„è¾¹ç•Œï¼Œè¿‡è¾¹ç•Œçš„ç‚¹ï¼ˆå‘é‡ï¼‰èµ·æ”¯æ’‘ä½œç”¨ï¼Œå¥½åƒæŠŠåˆ†å‰²è¶…å¹³é¢æ”¯èµ·æ¥ä¸€æ ·ï¼Œæ‰€ä»¥è¿™äº›ç‚¹å°±å«<strong>æ”¯æ’‘å‘é‡</strong>ã€‚æ‰¾åˆ°äº†æ”¯æ’‘å‘é‡ï¼Œä¹Ÿå°±æ‰¾åˆ°äº†é›†åˆè¾¹ç•Œï¼Œä¹Ÿå°±ç¡®å®šäº†åˆ†å‰²è¶…å¹³é¢ï¼Œé€šè¿‡è¿™ç§æ–¹æ³•åˆ†ç±»çš„æ¨¡å‹å°±å«åš<strong>æ”¯æŒå‘é‡æœº</strong>ã€‚</p><h3><span id="ç¡¬é—´éš”æœ€å¤§åŒ–">ç¡¬é—´éš”æœ€å¤§åŒ–</span></h3><p><strong>è¾“å…¥æ•°æ®</strong></p><p>å‡è®¾ç»™å®šä¸€ä¸ªç‰¹å¾ç©ºé—´ä¸Šçš„è®­ç»ƒæ•°æ®é›† <span class="math display">\[T=\{(x_1,y_1), (x_2,y_2)...(x_N,y_N)\}\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(x_iâˆˆR^n\)</span>ï¼Œ<span class="math inline">\(y_iâˆˆ\{+1,-1\}\)</span>ï¼Œ<span class="math inline">\(i=1,2,...N\)</span>ï¼Œ<span class="math inline">\(x_i\)</span> ä¸ºç¬¬ <span class="math inline">\(i\)</span> ä¸ªå®ä¾‹(è‹¥ <span class="math inline">\(n&gt;1\)</span>ï¼Œ<span class="math inline">\(x_i\)</span> ä¸ºå‘é‡)ï¼›<span class="math inline">\(y_i\)</span> ä¸º <span class="math inline">\(x_i\)</span> çš„ç±»æ ‡è®°ã€‚å½“ <span class="math inline">\(y_i=+1\)</span> æ—¶ï¼Œç§° <span class="math inline">\(x_i\)</span> ä¸ºæ­£ä¾‹ï¼›å½“ <span class="math inline">\(y_i=-1\)</span> æ—¶ï¼Œç§° <span class="math inline">\(x_i\)</span> ä¸ºè´Ÿä¾‹ï¼›<span class="math inline">\((x_i,y_i)\)</span> ç§°ä¸ºæ ·æœ¬ç‚¹ã€‚</p><p>ç»™å®šçº¿æ€§å¯åˆ†è®­ç»ƒæ•°æ®é›†ï¼Œé€šè¿‡<strong>é—´éš”æœ€å¤§åŒ–</strong>å¾—åˆ°çš„åˆ†ç¦»è¶…å¹³é¢ä¸º <span class="math display">\[y(x) = w^T\Phi(x) + b\]</span></p><p>ç›¸åº”çš„åˆ†ç±»å†³ç­–å‡½æ•° <span class="math inline">\(f(x) = sign(w^T\Phi(x) + b)\)</span> ï¼Œè¯¥å†³ç­–å‡½æ•°ç§°ä¸ºçº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºã€‚</p><p><span class="math inline">\(Ï†(x)\)</span> æ˜¯æŸä¸ªç¡®å®šçš„ç‰¹å¾ç©ºé—´è½¬æ¢å‡½æ•°ï¼Œå®ƒçš„ä½œç”¨æ˜¯å°† <span class="math inline">\(x\)</span> æ˜ å°„åˆ°(æ›´é«˜çš„)ç»´åº¦ã€‚æœ€ç®€å•ç›´æ¥çš„ï¼š<span class="math inline">\(\Phi(x) = x\)</span>ã€‚æ±‚è§£åˆ†ç¦»è¶…å¹³é¢é—®é¢˜å¯ä»¥ç­‰ä»·ä¸ºæ±‚è§£ç›¸åº”çš„<strong>å‡¸äºŒæ¬¡è§„åˆ’é—®é¢˜</strong>ã€‚</p><p><img src="/images/1473595785438.png"></p><p><strong>æ¨å¯¼ç›®æ ‡å‡½æ•°</strong></p><blockquote><p>ç‚¹åˆ°ç›´çº¿è·ç¦» å¹³é¢ä¸€ç‚¹ <span class="math inline">\(\overrightarrow{x_0}\)</span> åˆ°ç›´çº¿ <span class="math inline">\(y = \overrightarrow{w}\overrightarrow{x} + b\)</span> çš„è·ç¦»ä¸º <span class="math inline">\(\frac{|\overrightarrow{w}\overrightarrow{x} + b|}{||\overrightarrow{w}||}\)</span>ï¼Œè‹¥ç›´çº¿å˜æ¢ä¸º <span class="math inline">\(y = \frac{\overrightarrow{w}\overrightarrow{x} + b}{||\overrightarrow{w}||}\)</span>ï¼Œåˆ™è·ç¦»ä¸º <span class="math inline">\(|y(\overrightarrow{x_0})|\)</span></p></blockquote><p>æ ¹æ®é¢˜è®¾ <span class="math inline">\(y(x) = w^T\Phi(x) + b\)</span>ï¼Œæœ‰ <span class="math inline">\(y_i(x)\cdot y(x_i) &gt; 0\)</span>ï¼Œ<span class="math inline">\(w\)</span>, <span class="math inline">\(b\)</span> ç­‰æ¯”ä¾‹ç¼©æ”¾ï¼Œåˆ™ <span class="math inline">\(t*y\)</span> çš„å€¼åŒæ ·ç¼©æ”¾ï¼Œä»è€Œæ ·æœ¬ <span class="math inline">\(i\)</span> åˆ°è¶…å¹³é¢çš„è·ç¦»ä¸ºï¼š <span class="math display">\[\frac{y_i\cdot y(x_i)}{||w||} = \frac{y_i \cdot (w^T\Phi(x_i) + b)}{||w||}\]</span></p><p>æˆ‘ä»¬è¦æ±‚<strong>æœ€çŸ­è·ç¦»æœ€å¤§</strong>çš„è¶…å¹³é¢ï¼Œæ‰€ä»¥ç›®æ ‡å‡½æ•°ä¸ºï¼š</p><p><span class="math display">\[\arg \max_{w, b}\{\frac{1}{||w||}\min_i[y_i \cdot (w^T\cdot \Phi(x_i) + b)]\}\]</span></p><p>ç”±äºæˆ‘ä»¬æ€»å¯ä»¥é€šè¿‡ç­‰æ¯”ä¾‹ç¼©æ”¾ <span class="math inline">\(w\)</span> çš„æ–¹æ³•ï¼Œä½¿å¾—ä¸¤ç±»ç‚¹çš„å‡½æ•°å€¼éƒ½æ»¡è¶³ <span class="math inline">\(|y|\geqslant 1\)</span>ï¼ŒåŠ ä¸Šè¿™ä¸ªçº¦æŸä¹‹å ï¼š <span class="math inline">\(\min_i[y_i \cdot (w^T\cdot \Phi(x_i) + b)] = 1\)</span>ï¼Œæ‰€ä»¥ç›®æ ‡å‡½æ•°åŒ–ç®€ä¸ºï¼š</p><p><span class="math display">\[\arg \max_{w,b}\frac{1}{||w||}\]</span> <span class="math display">\[s.t. \ y_i(w^T\cdot \Phi(x_i) + b) \geqslant 1, \ \ i = 1, 2, ... n\]</span></p><p>æˆ‘ä»¬åšä¸€ä¸‹ç®€å•çš„å˜åŒ–ï¼Œå¾—åˆ°ï¼š</p><p><span class="math display">\[\arg \min_{w,b}\frac{1}{2}||w||^2\]</span> <span class="math display">\[s.t. \ y_i(w^T\cdot \Phi(x_i) + b) -1 \geqslant 0, \ \ i = 1, 2, ... n\]</span></p><p>æ±‚ä¸€ä¸ªå¸¦çº¦æŸçš„å‡½æ•°çš„æœ€å€¼ï¼Œé€šå¸¸ä½¿ç”¨<a href="https://www.wikiwand.com/en/Lagrange_multiplier" target="_blank" rel="noopener">Lagrangeä¹˜æ•°æ³•</a>ã€‚</p><blockquote><p>In mathematical optimization, the method of Lagrange multipliers is a strategy for finding the local maxima and minima of a function subject to equality constraints.</p></blockquote><p>Lagrangeå‡½æ•°ä¸ºï¼š</p><p><span class="math display">\[L(w,b,\alpha) = \frac{1}{2}||w||^2- \sum_{i=1}^n\alpha_i(y_i(w^T\cdot \Phi(x_i) + b) - 1)\]</span></p><p>ç”±äºæˆ‘ä»¬è¦æ±‚ $_i 0 $ï¼Œè€Œ <span class="math inline">\((y_i(w^T\cdot \Phi(x_i) + b) - 1)\)</span> æ˜¯ä¸€ä¸ªæ­£å€¼ï¼Œæ‰€ä»¥ <span class="math inline">\(L(w, b, \alpha) \leqslant \frac{1}{2}||w||^2\)</span>ï¼Œå³ <span class="math inline">\(max_\alpha L(w, b, \alpha) = \frac{1}{2}||w||^2\)</span>ï¼Œæ‰€ä»¥åŸé—®é¢˜æ˜¯æå°æå¤§é—®é¢˜ï¼š <span class="math display">\[\min_{w,b}\max_\alpha L(w, b, \alpha)\]</span></p><p>æˆ‘ä»¬å†åšä¸€ä¸‹å˜åŒ–ï¼Œå˜æˆåŸå§‹é—®é¢˜çš„å¯¹å¶é—®é¢˜ï¼š</p><p><span class="math display">\[\max_\alpha\min_{w,b}L(w, b, \alpha)\]</span></p><blockquote><p>ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ<span class="math inline">\(\min_y\max_x f(x, y) \geqslant \max_x\min_y f(x, y)\)</span>ï¼Œç”±äºæˆ‘ä»¬çš„ <span class="math inline">\(L(w, b, \alpha)\)</span> æ»¡è¶³ <a href="https://www.wikiwand.com/en/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions" target="_blank" rel="noopener">KKTæ¡ä»¶</a>ï¼Œæ‰€ä»¥å¯ä»¥å–ç­‰å·ã€‚</p></blockquote><p>ç”±äºå…ˆæ±‚ <span class="math inline">\(\min_{w,b}\)</span>ï¼Œæ‰€ä»¥å°†æ‹‰æ ¼æœ—æ—¥å‡½æ•° <span class="math inline">\(L(w,b,\alpha)\)</span> åˆ†åˆ«å¯¹ <span class="math inline">\(w,b\)</span> æ±‚åå¯¼å¹¶ä»¤å…¶ä¸º <span class="math inline">\(0\)</span> :</p><p><span class="math display">\[\frac{\partial L}{\partial w} = 0 \Rightarrow w = \sum_{i=1}^n\alpha_i y_i \Phi(x_i)\]</span> <span class="math display">\[\frac{\partial L}{\partial b} = 0 \Rightarrow \sum_{i=1}^n\alpha_i y_i = 0\]</span></p><p>æŠŠä¸Šé¢äºŒå¼ä»£å› <span class="math inline">\(L(w, b, \alpha)\)</span>ï¼Œå¹¶åŒ–ç®€å¾—ï¼š</p><p><span class="math display">\[\begin{array}{lcl}L(w, b, \alpha) = \frac{1}{2}||w||^2- \sum_{i=1}^n\alpha_i(y_i(w^T\cdot \Phi(x_i) + b) - 1) \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \frac{1}{2}w^Tw - w^T\sum_{i=1}^n\alpha_iy_i\Phi(x_i) - b\sum_{i=1}^n\alpha_iy_i + \sum_{i=1}^n\alpha_i \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \frac{1}{2}w^T\sum_{i=1}^n\alpha_i y_i \Phi(x_i) - w^T\sum_{i=1}^n\alpha_iy_i\Phi(x_i) - b \cdot 0 + \sum_{i=1}^n\alpha_i \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \sum_{i=1}^n\alpha_i - \frac{1}{2}(\sum_{i=1}^n\alpha_i y_i \Phi(x_i))^T\sum_{i=1}^n\alpha_i y_i \Phi(x_i) \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \sum_{i=1}^n\alpha_i -\frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_jy_iy_j\Phi(x_i)\Phi(x_j)\end{array}\]</span></p><p>ç»§ç»­æ±‚ <span class="math inline">\(\min_{w,b}L(w, b, \alpha)\)</span> å¯¹ <span class="math inline">\(\alpha\)</span> çš„æå¤§ï¼š</p><p><span class="math display">\[\max_\alpha \sum_{i=1}^n\alpha_i - \frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_jy_iy_j\Phi(x_i)\Phi(x_j)\]</span> <span class="math display">\[s.t. \sum_{i=1}^n \alpha_iy_i = 0, \alpha_i \geqslant 0, i = 1, 2, ... n\]</span></p><p>æˆ‘ä»¬å¯¹ç›®æ ‡å‡½æ•°æ·»åŠ è´Ÿå·ï¼Œè½¬åŒ–ä¸ºå¯¹ <span class="math inline">\(\alpha\)</span> æ±‚æå°ï¼š</p><p><span class="math display">\[\min_\alpha \frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_jy_iy_j\Phi(x_i)\Phi(x_j) - \sum_{i=1}^n\alpha_i\]</span> <span class="math display">\[s.t. \sum_{i=1}^n \alpha_iy_i = 0, \alpha_i \geqslant 0, i = 1, 2, ... n\]</span></p><p>ç”¨æŸäº›æ–¹æ³•ï¼ˆæ¯”å¦‚ï¼š<a href="#SMO">SMO</a>ï¼‰æ±‚å¾—æœ€ä¼˜è§£ <span class="math inline">\(\alpha^*\)</span>ï¼Œç„¶åå¯ä»¥è®¡ç®—å‡ºåˆ†éš”è¶…å¹³é¢ï¼š</p><p><span class="math display">\[w^* = \sum_{i=1}^n\alpha_i^*y_i\Phi(x_i)\]</span> <span class="math display">\[b^* = y_i - \sum_{i=1}^n\alpha_i^*y_i\Phi(x_i)\cdot \Phi(x_j)\]</span> <span class="math display">\[w^*\Phi(x) + b^* = 0\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(x_j\)</span> ä¸ºæŸä¸€æ ·æœ¬ï¼Œæ‰€ä»¥åˆ†ç±»å†³ç­–å‡½æ•°ä¸ºï¼š</p><p><span class="math display">\[f(x) = sign(w^*\Phi(x) + b^*)\]</span></p><h2><span id="çº¿æ€§æ”¯æŒå‘é‡æœº">çº¿æ€§æ”¯æŒå‘é‡æœº</span></h2><p>è§£å†³é—®é¢˜ä¹‹åæˆ‘ä»¬å‘ç°ï¼Œæœ‰æ—¶å€™ä¸ä¸€å®šåˆ†ç±»å®Œå…¨æ­£ç¡®çš„è¶…å¹³é¢å°±æ˜¯æœ€å¥½çš„ï¼Œå®¹å¿äº›å°é”™è¯¯å¯èƒ½ä¼šæ›´å¥½ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/1473671960505.png"></p><p>æ˜æ˜¾è™šçº¿æ¯”å®Œå…¨åˆ†å¯¹çš„å®çº¿çœ‹èµ·æ¥è¦å¥½ä¸€äº›ï¼Œå®çº¿å¯èƒ½è¿‡æ‹Ÿåˆäº†ã€‚è€Œä¸”æ›´å¤šçš„æƒ…å†µæ˜¯æ•°æ®é›†æœ¬èº«å°±ä¸æ˜¯çº¿æ€§å¯åˆ†çš„ï¼Œè§£å†³è¿™äº›é—®é¢˜å°±éœ€è¦ç”¨<strong>è½¯é—´éš”æœ€å¤§åŒ–çš„çº¿æ€§æ”¯æŒå‘é‡æœº</strong>äº†ï¼</p><h3><span id="è½¯é—´éš”æœ€å¤§åŒ–">è½¯é—´éš”æœ€å¤§åŒ–</span></h3><p>è‹¥æ•°æ®çº¿æ€§ä¸å¯åˆ†ï¼Œåˆ™å¢åŠ æ¾å¼›å› å­ <span class="math inline">\(Î¾_iâ‰¥0\)</span> , ä½¿å‡½æ•°é—´éš”åŠ ä¸Šæ¾å¼›å˜é‡å¤§äºç­‰äº <span class="math inline">\(1\)</span>ã€‚è¿™æ ·, çº¦æŸæ¡ä»¶å˜æˆ : <span class="math display">\[y_i(w\cdot x_i + b) \geqslant 1 - \xi_i\]</span></p><p>åˆ™ç›®æ ‡å‡½æ•°å˜ä¸ºï¼š</p><p><span class="math display">\[\min_{w,b, \xi}\frac{1}{2}||w||^2 + C\sum_{i=1}^n\xi_i\]</span> <span class="math display">\[s.t. y_i(w\cdot x_i + b) \geqslant 1 - \xi_i, \ \xi_i \geqslant 0, \ i = 1,2, ... n\]</span></p><p>å…¶ä¸­ï¼Œå‚æ•° <span class="math inline">\(C\)</span> ç”¨äºè°ƒèŠ‚å®¹å¿é”™è¯¯çš„ç¨‹åº¦ã€‚å½“ <span class="math inline">\(C \rightarrow +\infty\)</span> æ—¶ï¼Œè¦æœ€å°åŒ–ç›®æ ‡å‡½æ•°ï¼Œ<span class="math inline">\(\xi_i\)</span> åªèƒ½å–éå¸¸éå¸¸å°çš„å€¼ï¼Œå³ <span class="math inline">\(\xi_i \rightarrow 0\)</span>ï¼Œç›¸å½“äºçº¿æ€§å¯åˆ†SVMï¼›å½“ <span class="math inline">\(C\)</span> æ¯”è¾ƒå°æ—¶ï¼Œ<span class="math inline">\(\xi_i\)</span> å¯ä»¥å–å¾—è¾ƒå¤§çš„å€¼ï¼Œä»è€Œå®¹é”™ç‡è¾ƒå¤§ï¼Œå¯é˜²æ­¢è¿‡æ‹Ÿåˆã€‚</p><p>æ„é€ Lagrangeå‡½æ•°ï¼š <span class="math display">\[L(w, b, \xi, \alpha, \mu) = \frac{1}{2}||w||^2 + C\sum_{i=1}^n\xi_i -\sum_{i=1}^n\alpha_i(y_i(w^T\cdot \Phi(x_i) + b) - 1 + \xi_i) - \sum_{i=1}^n\mu_i\xi_i\]</span></p><p>å¯¹ <span class="math inline">\(w, b, \xi\)</span> æ±‚åå¯¼å¹¶ä»¤å…¶ç­‰äº <span class="math inline">\(0\)</span> å¾—ï¼š</p><p><span class="math display">\[\frac{\partial L}{\partial w} = 0 \Rightarrow \sum_{i=1}^n\alpha_iy_i\Phi(x_i)\]</span> <span class="math display">\[\frac{\partial L}{\partial b} = 0 \Rightarrow \sum_{i=1}^n\alpha_i y_i = 0\]</span> <span class="math display">\[\frac{\partial L}{\partial \xi} = 0 \Rightarrow C - \alpha_i - \mu_i = 0\]</span></p><p>å°†ä¸Šé¢ä¸‰å¼ä»£å…¥Lagrangeå‡½æ•°å¾—ï¼š</p><p><span class="math display">\[\min_{w,b,\xi}L(w,b,\xi,\alpha,\mu) = -\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j)) + \sum_{i=1}^n\alpha_i\]</span></p><p>å¯¹ä¸Šå¼æ±‚å…³äº <span class="math inline">\(\alpha\)</span> çš„æå¤§ï¼Œå¾—åˆ°ï¼š</p><p><span class="math display">\[\max_\alpha -\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j)) + \sum_{i=1}^n\alpha_i\]</span> <span class="math display">\[s.t. \sum_{i=0}^n\alpha_iy_i = 0, \ C - \alpha_i - \mu_i = 0, \ \alpha_i \geqslant 0, \mu_i \geqslant 0, i = 1,2...n\]</span></p><p>ç”±äº <span class="math inline">\(C - \alpha_i - \mu_i = 0\)</span>ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼š<span class="math inline">\(0 \leqslant \alpha_i \leqslant C\)</span>ã€‚</p><p>æ•´ç†å¾—åˆ°å¯¹å¶é—®é¢˜ï¼š</p><p><span class="math display">\[\min_\alpha \sum_{i=1}^n\alpha_i-\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j))\]</span> <span class="math display">\[s.t. \sum_{i=0}^n\alpha_iy_i = 0, \ 0 \leqslant \alpha_i \leqslant C,\  i = 1,2...n\]</span></p><p>é€šè¿‡æŸäº›æ–¹æ³•ï¼ˆæ¯”å¦‚ï¼š<a href="#SMO">SMO</a>ï¼‰æ±‚è§£çº¦æŸæœ€ä¼˜åŒ–é—®é¢˜ï¼Œæ±‚å¾—æœ€ä¼˜è§£ <span class="math inline">\(\alpha^*\)</span>ã€‚</p><p>è®¡ç®— <span class="math inline">\(w^*\)</span> å’Œ <span class="math inline">\(b^*\)</span> ï¼š</p><p><span class="math display">\[w^* = \sum_{i=1}^n\alpha_i^*y_i\Phi(x_i)\]</span> <span class="math display">\[b^* = \frac{\max_{i:y_i = -1}w^*\Phi(x_i)+\min_{i:y_i = 1}w^*\Phi(x_i)}{2}\]</span></p><p>æ³¨æ„ï¼š * è®¡ç®— <span class="math inline">\(b^*\)</span>æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ»¡è¶³æ¡ä»¶ <span class="math inline">\(0&lt;Î±_j&lt;C\)</span> çš„å‘é‡ * å®è·µä¸­å¾€å¾€å–<strong>æ”¯æŒå‘é‡</strong>çš„æ‰€æœ‰å€¼å–å¹³å‡ï¼Œä½œä¸º <span class="math inline">\(b^*\)</span></p><p>æ±‚å¾—åˆ†ç¦»è¶…å¹³é¢ï¼š<span class="math inline">\(w^*\Phi(x) + b^* = 0\)</span></p><p>åˆ†ç±»å†³ç­–å‡½æ•°ä¸ºï¼š</p><p><span class="math display">\[f(x) = sign(w^*\Phi(x) + b^*)\]</span></p><p><strong>æŸå¤±å‡½æ•°åˆ†æ</strong></p><p><img src="/images/1473691411792.png"></p><p>è‹¥ä¸€æ­£ä¾‹æ ·æœ¬è½åœ¨ <span class="math inline">\(y=1\)</span> ä¸‹ä¾§æˆ–æ­£å¥½åœ¨çº¿ä¸Šï¼Œåˆ™æƒ©ç½š <span class="math inline">\(\xi = 0\)</span> ï¼›è‹¥è½åœ¨ <span class="math inline">\(y=0\)</span> ä¸ <span class="math inline">\(y=1\)</span> ä¹‹é—´ï¼Œåˆ™æƒ©ç½šä¸ºä¸€ä¸ªå°äº <span class="math inline">\(1\)</span> çš„æ•°ï¼Œå³ <span class="math inline">\(\xi &lt; 1\)</span>ï¼›è‹¥æ­£å¥½è½åœ¨åˆ†å‰²çº¿ä¸Šï¼Œåˆ™ <span class="math inline">\(\xi = 1\)</span> ï¼›è‹¥è¯¥æ ·æœ¬è½åœ¨ <span class="math inline">\(y = 0\)</span> ä¸Šä¾§ï¼Œåˆ™æƒ©ç½šä¸ºå¤§äº <span class="math inline">\(1\)</span> çš„å€¼ï¼Œå³ <span class="math inline">\(\xi &gt; 1\)</span>ã€‚ç”»åœ¨åæ ‡è½´ä¸Šå°±æ˜¯ï¼š</p><p><img src="/images/1473691785170.png"></p><p>å…¶ä¸­ï¼Œè“è‰²çš„çº¿å°±æ˜¯SVMçš„æŸå¤±å‡½æ•°ï¼Œçº¢è‰²çš„çº¿æ˜¯Logisticå›å½’çš„æŸå¤±å‡½æ•°ï¼Œç»¿è‰²çš„çº¿æ˜¯0/1æŸå¤±ã€‚</p><h2><span id="éçº¿æ€§æ”¯æŒå‘é‡æœº">éçº¿æ€§æ”¯æŒå‘é‡æœº</span></h2><p>å¯ä»¥ä½¿ç”¨æ ¸å‡½æ•°ï¼Œå°†åŸå§‹è¾“å…¥ç©ºé—´æ˜ å°„åˆ°æ–°çš„ç‰¹å¾ç©ºé—´ï¼Œä»è€Œï¼Œä½¿å¾—åŸæœ¬çº¿æ€§ä¸å¯åˆ†çš„ æ ·æœ¬å¯èƒ½åœ¨æ ¸ç©ºé—´å¯åˆ†ï¼Œä»è€Œå®ç°éçº¿æ€§æ”¯æŒå‘é‡æœºã€‚</p><h3><span id="æ ¸å‡½æ•°">æ ¸å‡½æ•°</span></h3><p>æˆ‘ä»¬è¦ä¼˜åŒ–çš„ç›®æ ‡å‡½æ•°ä¸ºï¼š <span class="math display">\[\min_\alpha \sum_{i=1}^n\alpha_i-\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j))\]</span></p><p>æˆ‘ä»¬å®šä¹‰æ ¸å‡½æ•° <span class="math inline">\(\kappa(x_i, x_j) = \Phi(x_i) \cdot \Phi(x_j)\)</span>ï¼Œæ¥ä»£æ›¿ <span class="math inline">\(\Phi(x_i)\)</span> ä¸ <span class="math inline">\(\Phi(x_j)\)</span> çš„ç‚¹ç§¯ï¼Œä»è€Œæˆ‘ä»¬ä¸ç”¨è‡ªå·±æå– <span class="math inline">\(x\)</span> çš„ç‰¹å¾ <span class="math inline">\(\Phi(x)\)</span>ï¼Œåªéœ€å®šä¹‰ä¸€ä¸ªæ ¸å‡½æ•°æ¥è¡¨ç¤ºä¸¤ä¸ªæ ·æœ¬çš„<strong>ç›¸ä¼¼åº¦</strong>ã€‚</p><p>å¸¸ç”¨çš„æ ¸å‡½æ•°æœ‰ä»¥ä¸‹å‡ ä¸ªï¼š * å¤šé¡¹å¼æ ¸å‡½æ•°ï¼š<span class="math inline">\(\kappa(x_1, x_2) = (\alpha \cdot ||x_1 - x_2||^a + r)^b\)</span>ï¼Œ<span class="math inline">\(\alpha, a, b, r\)</span> ä¸ºå¸¸æ•° * é«˜æ–¯æ ¸å‡½æ•°RBFï¼š<span class="math inline">\(\kappa(x_1,x_2) = \exp(-\frac{||x_1 - x_2||^2}{2\sigma^2})\)</span> * Sigmoidæ ¸ï¼š<span class="math inline">\(\kappa(x_1,x_2) = \tanh(\gamma\cdot||x_1-x_2||^a+r)\)</span>ï¼Œ<span class="math inline">\(\gamma,a,r\)</span> ä¸ºå¸¸æ•°</p><p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¾€å¾€ä¾èµ–<strong>å…ˆéªŒé¢†åŸŸçŸ¥è¯†</strong>/<strong>äº¤å‰éªŒè¯</strong>ç­‰æ–¹æ¡ˆæ‰èƒ½é€‰æ‹©æœ‰æ•ˆçš„æ ¸å‡½æ•°ï¼›è‹¥æ²¡æœ‰æ›´å¤šå…ˆéªŒä¿¡æ¯ï¼Œåˆ™ä½¿ç”¨<strong>é«˜æ–¯æ ¸å‡½æ•°</strong>ã€‚</p><p><strong>æ ¸å‡½æ•°æ˜ å°„</strong></p><p><img src="/images/1473693232751.png"></p><p>é«˜æ–¯æ ¸å‡½æ•°å…¶å®å¯ä»¥åœ¨æ ·æœ¬å‘¨å›´å½¢æˆä¸€åœˆåœˆç­‰é«˜çº¿ï¼Œä½¿<strong>æ­£æ ·æœ¬ä¸Šå‡å½¢æˆå±±å³°</strong>ï¼Œ<strong>è´Ÿæ ·æœ¬ä¸‹é™å½¢æˆå±±è°·</strong>ï¼Œç„¶åæ€»ä¼šæœ‰ä¸€ä¸ªæˆ–å¤šä¸ªè¶…å¹³é¢å¯ä»¥å®Œç¾åˆ†å‰²ä¸¤ç±»æ ·æœ¬ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚</p><p><img src="/images/1473693532937.png"></p><p>é‚£ä¹ˆå¤šä¸ªå®Œç¾åˆ†å‰²çš„è¶…å¹³é¢å“ªä¸ªæ˜¯æœ€å¥½çš„å‘¢ï¼Ÿæ˜¯ç²‰çº¢è‰²çš„è¿˜æ˜¯é»‘è‰²çš„ï¼Ÿ</p><p>å…¶å®æˆ‘ä»¬åªéœ€è¦æŠŠæ ·æœ¬åˆ°å¹³é¢çš„<strong>æœ€çŸ­è·ç¦»æ±‚</strong>å‡ºæ¥ï¼Œç„¶å<strong>æœ€å¤§åŒ–</strong>è¿™ä¸ªè·ç¦»å°±å¯ä»¥ï¼Œæ²¡é”™ï¼Œå°±æ˜¯<strong>åœ¨æ ¸å‡½æ•°æ˜ å°„çš„ç©ºé—´é‡ŒåšSVM</strong>ï¼è€Œä¸”æ€»æ˜¯å¯ä»¥æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„åˆ†å‰²å¹³é¢æ¥åˆ†å‰²æ•°æ®é›†ï¼Œè¿™ä¹Ÿå°±æ˜¯ SVM + kernel trick å¼‚å¸¸å¼ºå¤§çš„åŸå› ã€‚</p><p><strong>RBF</strong></p><p>åœ¨å¤šè¯´ä¸€ç‚¹é«˜æ–¯æ ¸å‡½æ•°ï¼Œ<span class="math inline">\(\kappa(x_1,x_2) = \exp(-\frac{||x_1 - x_2||^2}{2\sigma^2})\)</span>ã€‚</p><blockquote><p><span class="math inline">\(e^x\)</span> çš„Taylorå±•å¼€ï¼š<span class="math inline">\(e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + ... + \frac{x^n}{n!} + R_n\)</span></p></blockquote><p>æˆ‘ä»¬å¯¹é«˜æ–¯æ ¸å‡½æ•°åšä¸€äº›å˜æ¢å¹¶Taylorå±•å¼€ï¼š</p><p><span class="math display">\[\begin{array}{lcl}\kappa(x_1,x_2) = e^{-\frac{||x_1 - x_2||^2}{2\sigma^2}} = e^{-\frac{(x_1 - x_2)^2}{2\sigma^2}} \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 - 2x_1x_2 + x_2^2}{2\sigma^2}} \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 + x_2^2}{2\sigma^2}} \cdot e^{\frac{x_1x_2}{\sigma^2}} \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 + x_2^2}{2\sigma^2}} \cdot(1 + \frac{1}{\sigma^2}\cdot\frac{x_1x_2}{1!} + (\frac{1}{\sigma^2})^2\cdot\frac{(x_1x_2)^2}{2!} + ... +  (\frac{1}{\sigma^2})^n\cdot\frac{(x_1x_2)^n}{n!} + ...) \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 + x_2^2}{2\sigma^2}} \cdot (1\cdot1 + \frac{1}{1!}\frac{x_1}{\sigma}\frac{x_2}{\sigma} + \frac{1}{2!}\frac{x_1^2}{\sigma^2}\frac{x_2^2}{\sigma^2} + ... + \frac{1}{n!}\frac{x_1^n}{\sigma^n}\frac{x_2^n}{\sigma^n}+...) \\\ \ \ \ \ \ \ \ \ \ \ \ \ = \Phi(x_1)^T\cdot\Phi(x_2)\end{array}\]</span></p><p>å…¶ä¸­ï¼Œ<span class="math inline">\(\Phi(x) = e^{-\frac{x^2}{2\sigma^2}}(1+\sqrt{\frac{1}{1!}}\frac{x}{\sigma} + \sqrt{\frac{1}{2!}}\frac{x^2}{\sigma^2} + ...+\sqrt{\frac{1}{n!}}\frac{x^n}{\sigma^n} + ...)\)</span></p><p>ç”± <span class="math inline">\(\Phi(x)\)</span> ç»“æœå¯è§é«˜æ–¯æ ¸å‡½æ•°å®é™…æŠŠç‰¹å¾æ˜ å°„åˆ°äº†<strong>æ— ç©·ç»´</strong>ï¼Œç„¶åç”±SVMé€‰å‡ºå‡ ä¸ªæœ€ä¼˜ç»´åº¦è¿›è¡Œåˆ†ç±»ã€‚</p><h2><span id="smo">SMO</span></h2><p>SVMä¸­ç³»æ•°çš„æ±‚è§£ï¼š<strong>Sequential Minimal Optimization</strong></p><p><strong>ç®—æ³•æ€æƒ³</strong> * æœ‰å¤šä¸ªæ‹‰æ ¼æœ—æ—¥ä¹˜å­ * æ¯æ¬¡åªé€‰æ‹©å…¶ä¸­<strong>ä¸¤ä¸ªä¹˜å­</strong>åšä¼˜åŒ–ï¼Œå…¶ä»–å› å­è®¤ä¸ºæ˜¯<strong>å¸¸æ•°</strong> * å°†Nä¸ªè§£é—®é¢˜ï¼Œè½¬æ¢æˆä¸¤ä¸ªå˜é‡çš„æ±‚è§£é—®é¢˜ï¼šå¹¶ä¸”ç›®æ ‡å‡½æ•°æ˜¯<strong>å‡¸</strong>çš„</p><p><strong>ç®—æ³•æ­¥éª¤</strong> * è€ƒå¯Ÿç›®æ ‡å‡½æ•°ï¼Œå‡è®¾ <span class="math inline">\(Î±_1\)</span> å’Œ <span class="math inline">\(Î±_2\)</span> æ˜¯å˜é‡ï¼Œå…¶ä»–æ˜¯å®šå€¼ï¼š <span class="math display">\[\min_\alpha \sum_{i=1}^n\alpha_i-\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j\kappa(x_i,x_j)\]</span> <span class="math display">\[s.t. \sum_{i=0}^n\alpha_iy_i = 0, \ 0 \leqslant \alpha_i \leqslant C,\  i = 1,2...n\]</span> * äºŒå˜é‡ä¼˜åŒ–é—®é¢˜ <span class="math display">\[y_1 \neq y_2ï¼Œ\begin{cases} L = \max\{0, \alpha_1 - \alpha2\} \\H = \min\{C, C+\alpha_1-\alpha_2\}\end{cases}\]</span> <span class="math display">\[y_1 = y_2ï¼Œ\begin{cases} L = \max\{0, \alpha_1 + \alpha2 - C\} \\H = \min\{C, \alpha_1+\alpha_2\}\end{cases}\]</span> * è¿­ä»£å…¬å¼ <span class="math display">\[g(x) = \sum_{i=1}^ny_i\alpha_i\kappa(x_i, x) + b\]</span> <span class="math display">\[\eta = \kappa(x_1, x_1) + \kappa(x_2, x_2) - 2\kappa(x_1, x_2) = ||\Phi(x_1) - \Phi(x_2)||^2\]</span> <span class="math display">\[E_i = g(x_i) - y_i = (\sum_{j=1}^ny_j\alpha_j\kappa(x_j, x_i) + b) - y_i,\ \ \ i = 1, 2\]</span> <span class="math display">\[\alpha_j^{new} = \alpha_j^{old} + \frac{y_j(E_i - E_j)}{\eta}\]</span> * è¿­ä»£ <span class="math inline">\(m\)</span> æ¬¡ <span class="math inline">\(\alpha_j\)</span> æ²¡æœ‰å˜åŒ–å°±å¯ä»¥é€€å‡ºè¿­ä»£äº†ï¼Œ<span class="math inline">\(m\)</span> ä¸ºè‡ªå·±è®¾ç½®çš„é˜ˆå€¼ã€‚</p><h2><span id="æ€»ç»“æ€è€ƒ">æ€»ç»“æ€è€ƒ</span></h2><ul><li>SVMå¯ä»¥ç”¨æ¥åˆ’åˆ†å¤šç±»åˆ«å—?<ul><li>ç­”æ¡ˆæ˜¯è‚¯å®šçš„ã€‚</li><li>ç›´æ¥å¤šåˆ†ç±»</li><li>1 vs all</li></ul></li><li>SVMå’ŒLogisticå›å½’çš„æ¯”è¾ƒ<ul><li>ç»å…¸çš„SVMï¼Œç›´æ¥è¾“å‡ºç±»åˆ«ï¼Œä¸ç»™å‡ºåéªŒæ¦‚ç‡</li><li>Logisticå›å½’ï¼Œä¼šç»™å‡ºå±äºå“ªä¸ªç±»åˆ«çš„åéªŒæ¦‚ç‡</li><li>äºŒè€…<strong>ç›®æ ‡å‡½æ•°çš„å¼‚åŒ</strong></li></ul></li><li>SVMä¹Ÿå¯ä»¥ç”¨äºå›å½’é—®é¢˜ï¼šSVR</li></ul><h2><span id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</span></h2><ul><li>æèˆªï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼Œæ¸…åå¤§å­¦å‡ºç‰ˆç¤¾ï¼Œ2012</li><li>Charlie Frogner. Support Vector Machines. 2011</li><li>Corinana Cortes, Vladimir Vapnik. Support-Vector Networks. Machine Learning, 20, 273-297, 1995</li><li>John C. Platt. Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines. 1998</li><li>Andrew W. Moore. Support Vector Machines, 2001</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æå‡æ–¹æ³•ï¼šGBDT , XGBOOST &amp; AdaBoost</title>
      <link href="/2016/09/08/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%EF%BC%9AGBDT%20,%20XGBOOST,%20AdaBoost/"/>
      <url>/2016/09/08/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%EF%BC%9AGBDT%20,%20XGBOOST,%20AdaBoost/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>æå‡</strong> (<em>boosting</em>) æ–¹æ³•æ˜¯ä¸€ç§å¸¸ç”¨çš„ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼Œåº”ç”¨å¹¿æ³›ä¸”æœ‰æ•ˆï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œå®ƒé€šè¿‡æ”¹å˜è®­ç»ƒæ ·æœ¬çš„æƒé‡ï¼Œå­¦ä¹ å¤šä¸ªåˆ†ç±»å™¨ï¼Œå¹¶å°†è¿™äº›åˆ†ç±»å™¨è¿›è¡Œçº¿æ€§ç»„åˆï¼Œæé«˜åˆ†ç±»å™¨æ€§èƒ½ã€‚</p></blockquote><!-- toc --><ul><li><a href="#gbdt">GBDT</a><ul><li><a href="#æå‡çš„æ¦‚å¿µ">æå‡çš„æ¦‚å¿µ</a></li><li><a href="#æå‡ç®—æ³•">æå‡ç®—æ³•</a></li><li><a href="#æ¢¯åº¦æå‡å†³ç­–æ ‘-gbdt">æ¢¯åº¦æå‡å†³ç­–æ ‘ GBDT</a></li></ul></li><li><a href="#xgboost">XGBOOST</a></li><li><a href="#adaboost">AdaBoost</a><ul><li><a href="#è¯¯å·®åˆ†æ">è¯¯å·®åˆ†æ</a></li></ul></li><li><a href="#å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="gbdt">GBDT</span></h2><p>æˆ‘ä»¬çŸ¥é“<strong>éšæœºæ£®æ—</strong>çš„å†³ç­–æ ‘åˆ†åˆ«é‡‡æ ·å»ºç«‹, ç›¸å¯¹<strong>ç‹¬ç«‹</strong>ã€‚ é‚£ä¹ˆå¼•æ¥äº†å¦‚ä¸‹æ€è€ƒ :</p><ul><li>å‡å®šå½“å‰ä¸€å®šå¾—åˆ°äº† <span class="math inline">\(m-1\)</span> é¢—å†³ç­–æ ‘, æ˜¯å¦å¯ä»¥é€šè¿‡ç°æœ‰æ ·æœ¬å’Œå†³ç­–æ ‘çš„ä¿¡æ¯, å¯¹ç¬¬ <span class="math inline">\(m\)</span> é¢—å†³ç­–æ ‘çš„å»ºç«‹äº§ç”Ÿæœ‰ç›Šçš„å½±å“å‘¢ ?</li><li>å„ä¸ªå†³ç­–æ ‘ç»„æˆéšæœºæ£®æ—å, æœ€åçš„æŠ•ç¥¨è¿‡ç¨‹å¯å¦åœ¨å»ºç«‹å†³ç­–æ ‘æ—¶å³ç¡®å®šå‘¢?</li></ul><p>ç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œè¿™ä¹Ÿå°±æ˜¯<strong>æå‡ï¼ˆboostingï¼‰</strong>çš„æ–¹æ³•æ‰€è§£å†³çš„é—®é¢˜ã€‚</p><h3><span id="æå‡çš„æ¦‚å¿µ">æå‡çš„æ¦‚å¿µ</span></h3><p><strong>æå‡</strong>æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ æŠ€æœ¯, å¯ä»¥ç”¨äº<strong>å›å½’å’Œåˆ†ç±»</strong>é—®é¢˜, å®ƒæ¯ä¸€æ­¥äº§ç”Ÿä¸€ä¸ª<strong>å¼±é¢„æµ‹æ¨¡å‹</strong>(å¦‚å†³ç­–æ ‘), å¹¶<strong>åŠ æƒç´¯åŠ </strong>åˆ°æ€»æ¨¡å‹ä¸­ï¼Œæœ€ç»ˆå¾—å¸¦ä¸€ä¸ª<strong>å¼ºé¢„æµ‹æ¨¡å‹</strong>; å¦‚æœæ¯ä¸€æ­¥çš„å¼±é¢„æµ‹æ¨¡å‹ç”Ÿæˆéƒ½æ˜¯ä¾æ®æŸå¤±å‡½æ•°çš„æ¢¯åº¦æ–¹å‘, åˆ™ç§°ä¹‹ä¸º<strong>æ¢¯åº¦æå‡(Gradient boosting)</strong>ã€‚</p><p>æå‡çš„æ–¹æ³•åŸºäºè¿™æ ·ä¸€ä¸ªæ€æƒ³ï¼šå¯¹äºä¸€ä¸ªå¤æ‚ä»»åŠ¡æ¥è¯´ï¼Œå°†å¤šä¸ªä¸“å®¶çš„åˆ¤æ–­è¿›è¡Œé€‚å½“çš„ç»¼åˆæ‰€å¾—å‡ºçš„åˆ¤æ–­ï¼Œè¦æ¯”å…¶ä¸­ä»»ä½•ä¸€ä¸ªä¸“å®¶å•ç‹¬çš„åˆ¤æ–­å¥½ã€‚å®é™…ä¸Šï¼Œå°±æ˜¯â€œ<strong>ä¸‰ä¸ªè‡­çš®åŒ é¡¶ä¸ªè¯¸è‘›äº®</strong>â€çš„é“ç†ã€‚</p><p><strong>æ¢¯åº¦æå‡</strong>ç®—æ³•é¦–å…ˆç»™å®šä¸€ä¸ª<strong>ç›®æ ‡æŸå¤±å‡½æ•°</strong>, å®ƒçš„å®šä¹‰åŸŸæ˜¯æ‰€æœ‰å¯è¡Œçš„<strong>å¼±å‡½æ•°é›†åˆ(åŸºå‡½æ•°)</strong>; æå‡ç®—æ³•é€šè¿‡è¿­ä»£çš„é€‰æ‹©ä¸€ä¸ª<strong>è´Ÿæ¢¯åº¦æ–¹å‘</strong>ä¸Šçš„åŸºå‡½æ•°æ¥é€æ¸é€¼è¿‘å±€éƒ¨æå°å€¼ã€‚è¿™ç§åœ¨å‡½æ•°åŸŸçš„æ¢¯åº¦æå‡è§‚ç‚¹å¯¹æœºå™¨å­¦ä¹ çš„å¾ˆå¤šé¢†åŸŸæœ‰æ·±åˆ»å½±å“ã€‚</p><p><strong>æ¢¯åº¦æå‡</strong>ç®—æ³•å®é™…ä¸Šå’Œ<strong>æ¢¯åº¦ä¸‹é™</strong>ç®—æ³•æ˜¯ä¸€æ ·çš„ï¼Œåªä¸è¿‡çœ‹é—®é¢˜çš„è§’åº¦ä¸åŒï¼Œæ¯”å¦‚åœ¨çº¿æ€§å›å½’ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ¢¯åº¦ä¸‹é™æ¥ä¼˜åŒ–å‚æ•° <span class="math inline">\(\theta\)</span> ï¼Œä½¿æŸå¤±å‡½æ•°èƒ½è¾¾åˆ°ï¼ˆå±€éƒ¨ï¼‰æœ€å°å€¼ï¼›å¦‚æœæˆ‘ä»¬æ¢ä¸ªè§’åº¦ï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„ä¸æ˜¯ <span class="math inline">\(\theta\)</span>ï¼Œè€Œæ˜¯ <span class="math inline">\(h_\theta(x) = \theta^T x\)</span> è¿™ä¸ªå‡½æ•°ï¼Œå†é€šè¿‡æ²¿æ¢¯åº¦æ–¹å‘ä¸‹é™çš„æ–¹æ³•è¾¾åˆ°æŸå¤±å‡½æ•°ï¼ˆå±€éƒ¨ï¼‰æœ€å°å€¼ï¼Œå°±å˜æˆäº†æ¢¯åº¦æå‡ç®—æ³•ã€‚</p><h3><span id="æå‡ç®—æ³•">æå‡ç®—æ³•</span></h3><p>ç»™å®šè¾“å…¥å‘é‡ <span class="math inline">\(x\)</span> å’Œè¾“å‡ºå˜é‡ <span class="math inline">\(y\)</span> ç»„æˆçš„è‹¥å¹²è®­ç»ƒæ ·æœ¬ <span class="math inline">\((x_1, y_1), (x_2,y_2),...,(x_n,y_n)\)</span> , ç›®æ ‡æ˜¯æ‰¾åˆ°è¿‘ä¼¼å‡½æ•° <span class="math inline">\(F(x)\)</span> , ä½¿å¾—æŸå¤±å‡½æ•° <span class="math inline">\(L(y,F(x))\)</span> çš„æŸå¤±å€¼æœ€å°ã€‚</p><p>æŸå¤±å‡½æ•° <span class="math inline">\(L(y,F(x))\)</span> çš„å®šä¹‰ä¸å”¯ä¸€ï¼Œå…¸å‹å®šä¹‰æœ‰ä»¥ä¸‹ä¸¤ç§ï¼š</p><ul><li><span class="math inline">\(L(y,F(x)) = \frac{1}{2}(y - F(x))^2\)</span>ï¼Œè¿™ä¸ªå®šä¹‰å…¶å®é»˜è®¤è¯¯å·®æœä»<strong>é«˜æ–¯åˆ†å¸ƒ</strong></li><li><span class="math inline">\(L(y,F(x)) =| y - F(x) |\)</span>ï¼Œè¿™ä¸ªå®šä¹‰åˆ™è®¤ä¸ºè¯¯å·®æœä»<strong>Laplaceï¼ˆåŒæŒ‡æ•°ï¼‰åˆ†å¸ƒ</strong></li></ul><p>å‡è®¾æœ€ä¼˜è§£ä¸º <span class="math inline">\(F^*(x)\)</span>ï¼Œåˆ™ï¼š</p><p><span class="math display">\[F^*(x) =\arg\min_F E(x, y)[L(y, F(x))]\]</span></p><p>è¯¥å¼çš„æ„æ€å°±æ˜¯ä½¿<strong>æŸå¤±å‡½æ•°æœŸæœ›é£é™©æœ€å°åŒ–</strong>çš„å‚æ•° <span class="math inline">\(F(x)\)</span> ä¸ºæœ€ä¼˜è§£ <span class="math inline">\(F^*(x)\)</span>ã€‚</p><p>æˆ‘ä»¬çŸ¥é“ä»»ä½•å‡½æ•°éƒ½å¯ä»¥è¢«åˆ†è§£ä¸ºä¸€æ—<strong>åŸºå‡½æ•°çš„çº¿æ€§ç»„åˆ</strong>ï¼Œæ¯”å¦‚å‚…ç«‹å¶åˆ†è§£å¯ä»¥æŠŠä»»ä½•å‡½æ•°åˆ†è§£ä¸ºä¸‰è§’å‡½æ•°çš„çº¿æ€§ç»„åˆï¼Œæ‰€ä»¥è¿™é‡Œçš„ <span class="math inline">\(F(x)\)</span> ä¹Ÿä¸ä¾‹å¤–ï¼Œæˆ‘ä»¬å‡è®¾å®ƒæ˜¯ä¸€æ—åŸºå‡½æ•° <span class="math inline">\(f_i(x)\)</span> çš„çº¿æ€§ç»„åˆï¼Œå³ï¼š <span class="math display">\[F(x) = \sum_{i=1}^M\gamma_if_i(x) + const\]</span></p><p><strong>ç®—æ³•æ¨å¯¼</strong></p><p>æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦æå‡æ–¹æ³•å¯»æ‰¾æœ€ä¼˜è§£ <span class="math inline">\(F(x)\)</span>, ä½¿å¾—æŸå¤±å‡½æ•°åœ¨è®­ç»ƒé›†ä¸Šçš„<strong>æœŸæœ›æœ€å°</strong>ã€‚æ–¹æ³•å¦‚ä¸‹:</p><ul><li><p>é¦–å…ˆ, ä»¤ <span class="math inline">\(f_0(x) = 1\)</span>ï¼Œæ±‚å¸¸ç³»æ•° <span class="math inline">\(\gamma_0\)</span> : <span class="math display">\[F_0(x) =\gamma_0f_0(x) =\gamma_0 =\arg\min_\gamma\sum_{i=1}^n L(y_i,\gamma)\]</span></p><ul><li>è‹¥æŸå¤±å‡½æ•°é‡‡ç”¨å¹³æ–¹å®šä¹‰ï¼Œä¸Šå¼å¯ä»¥è§£å¾—ï¼š<span class="math inline">\(F_0(x) =\gamma =\frac{1}{n}\sum_{i=1}^ny_i\)</span></li><li>è‹¥æŸå¤±å‡½æ•°é‡‡ç”¨ç»å¯¹å€¼å®šä¹‰ï¼Œåˆ™è§£ <span class="math inline">\(F_0(x)\)</span> ä¸º <span class="math inline">\(y_1, y_2 ... y_n\)</span> çš„ä¸­ä½æ•°</li></ul></li><li>çŸ¥é“ <span class="math inline">\(F_0(x)\)</span> ä¹‹åï¼Œæ¥ä¸‹æ¥ç”¨é€’æ¨çš„æ€è·¯æ¥æƒ³ï¼Œå¦‚æœå·²çŸ¥ <span class="math inline">\(F_0(x), F_1(x) ... F_{m-1}(x)\)</span> ï¼Œå¦‚ä½•æ±‚ <span class="math inline">\(F_m(x)\)</span> ï¼Ÿäºæ˜¯å¾—åˆ°ä¸‹é¢çš„å…¬å¼ï¼š <span class="math display">\[F_m(x) = F_{m-1}(x) + \arg \min_{f \in H} \sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f(x_i))\]</span></li><li><p>æˆ‘ä»¬å¯ä»¥ç”¨<strong>æ¢¯åº¦ä¸‹é™</strong>çš„æ–¹æ³•è¿‘ä¼¼è®¡ç®—ä¸Šå¼ã€‚è‹¥ä½¿ <span class="math inline">\(\sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f(x_i))\)</span> å–å¾—æœ€å°å€¼ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ <span class="math inline">\(f(x_i)\)</span> æ±‚åå¯¼æ±‚å‡ºæ¢¯åº¦ï¼Œç„¶åæ²¿è´Ÿæ¢¯åº¦æ–¹å‘ä¸‹é™ä¸€ä¸ªæ­¥é•¿ <span class="math inline">\(\gamma_m\)</span>ï¼Œç”±äºè¿™ä¸ªæ­¥é•¿å¯ä»¥é€šè¿‡<strong>çº¿æ€§æœç´¢</strong>æ±‚å‡ºæœ€ä¼˜å€¼ï¼Œæ‰€ä»¥è¯¥æ­¥é•¿ä¸è´Ÿæ¢¯åº¦çš„ä¹˜ç§¯å¯ä»¥è¿‘ä¼¼ä¸ºä¸Šå¼çš„æœ€å°å€¼ï¼Œäºæ˜¯å¾—åˆ°å¦‚ä¸‹çš„æ›´æ–°å…¬å¼ï¼š <span class="math display">\[F_m(x) = F_{m-1}(x) - \gamma_m \sum_{i=1}^n\nabla_fL(y_i, F_{m-1}(x_i))\]</span></p></li></ul><p><strong>æå‡ç®—æ³•</strong></p><ol type="1"><li>åˆå§‹ç»™å®šæ¨¡å‹ä¸ºå¸¸æ•° <span class="math inline">\(F_0(x) = \arg \min_\gamma \sum_{i=1}^n L(y_i, \gamma)\)</span></li><li>å¯¹äº <span class="math inline">\(m=1\)</span> åˆ° <span class="math inline">\(M\)</span><ol type="1"><li>è®¡ç®—<strong>ä¼ªæ®‹å·® (pseudo residuals)</strong> <span class="math inline">\(r_{im} = [\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}]_{F(x) = F_{m-1}(x)}\)</span> <span class="math inline">\(i = 1, 2 ... n\)</span></li><li>ä½¿ç”¨æ•°æ® <span class="math inline">\(\{(\overrightarrow{x_i}, r_{im})\}_{i=1}^n\)</span> è®­ç»ƒ<strong>æ‹Ÿåˆæ®‹å·®</strong>çš„åŸºå‡½æ•° <span class="math inline">\(f_m(x)\)</span> ï¼ˆæ¯”å¦‚ä¸€æ£µå†³ç­–æ ‘ï¼‰</li><li>è®¡ç®—æ­¥é•¿ $<em>m = </em><em>{i=1}^nL(y_i, F</em>{m-1}(x_i) - f_m(x_i)) $<ul><li>ä¸€ç»´ä¼˜åŒ–é—®é¢˜</li></ul></li><li>æ›´æ–°æ¨¡å‹ï¼š<span class="math inline">\(F_m(x) = F_{m-1}(x) - \gamma_m \cdot f_m(x)\)</span></li></ol></li></ol><h3><span id="æ¢¯åº¦æå‡å†³ç­–æ ‘-gbdt">æ¢¯åº¦æå‡å†³ç­–æ ‘ GBDT</span></h3><p>åœ¨æå‡ç®—æ³•ä¸­ï¼Œå¦‚æœåŸºå‡½æ•°é€‰æ‹©çš„æ˜¯å†³ç­–æ ‘ï¼Œé‚£ä¹ˆç®—æ³•åˆå«<strong>æ¢¯åº¦æå‡å†³ç­–æ ‘</strong>ï¼Œä¹Ÿå°±æ˜¯<strong>GBDT</strong>ã€‚</p><p><strong>GBDT</strong></p><ul><li>åœ¨ç¬¬ <span class="math inline">\(m\)</span> æ­¥çš„æ¢¯åº¦æå‡æ˜¯æ ¹æ®ä¼ªæ®‹å·®æ•°æ®è®¡ç®—å†³ç­–æ ‘ <span class="math inline">\(t_m(x)\)</span>ã€‚</li><li><p>ä»¤æ ‘ <span class="math inline">\(t_m(x)\)</span> çš„å¶èŠ‚ç‚¹æ•°ç›®ä¸º <span class="math inline">\(J\)</span>, å³æ ‘ <span class="math inline">\(t_m(x)\)</span> å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸º <span class="math inline">\(J\)</span> ä¸ªä¸ç›¸äº¤åŒºåŸŸ<span class="math inline">\(R_{1m},R_{2m},...,R_{Jm}\)</span> ,å¹¶ä¸”å†³ç­–æ ‘ <span class="math inline">\(t_m(x)\)</span> å¯ä»¥åœ¨æ¯ä¸ªåŒºåŸŸä¸­ç»™å‡ºæŸä¸ªç±»å‹çš„ç¡®å®šæ€§é¢„æµ‹ã€‚ä½¿ç”¨æŒ‡ç¤ºè®°å· <span class="math inline">\(I(x)\)</span>, å¯¹äºè¾“å…¥ <span class="math inline">\(x\)</span>, <span class="math inline">\(t_m(x)\)</span> ä¸º: <span class="math display">\[t_m(x) = \sum_{j=1}^Jb_{jm}I(x \in R_{jm})\]</span></p></li><li><p>å…¶ä¸­ï¼Œ<span class="math inline">\(b_{jm}\)</span> æ˜¯æ ·æœ¬ <span class="math inline">\(x\)</span> åœ¨åŒºåŸŸ <span class="math inline">\(R_{jm}\)</span> çš„é¢„æµ‹å€¼ï¼Œ<span class="math display">\[I(x) = \begin{cases}1, &amp; x == True \\0, &amp; x == False\end{cases}\]</span></p></li><li>ä½¿ç”¨çº¿æ€§æœç´¢è®¡ç®—å­¦ä¹ ç‡,æœ€å°åŒ–æŸå¤±å‡½æ ‘<ul><li><span class="math inline">\(F_m(x) = F_{m-1}(x) + \gamma_m \cdot t_m(x)\)</span></li><li><span class="math inline">\(\gamma_m = \arg \min_\gamma\sum_{i=1}^nL(y_i, F_{m-1}(x_i) + \gamma_mt_m(x_i))\)</span></li></ul></li><li>è¿›ä¸€æ­¥ï¼šå¯¹æ ‘çš„æ¯ä¸ªåŒºåŸŸåˆ†åˆ«è®¡ç®—æ­¥é•¿ï¼Œä»è€Œç³»æ•° <span class="math inline">\(b_{jm}\)</span> è¢«åˆå¹¶åˆ°æ­¥é•¿ä¸­ï¼Œä»è€Œ:<ul><li><span class="math inline">\(F_m(x) = F_{m-1}(x) + \sum_{j=1}^J\gamma_mI(x \in R_{jm})\)</span></li><li><span class="math inline">\(\gamma_{jm} = \arg \min_\gamma\sum_{x_i \in R_{jm}}L(y_i, F_{m-1}(x_i) + \gamma_mt_m(x_i))\)</span></li></ul></li></ul><p><strong>å‚æ•°è®¾ç½®å’Œæ­£åˆ™åŒ–</strong></p><p>å¯¹è®­ç»ƒé›†æ‹Ÿåˆè¿‡é«˜ä¼šé™ä½æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›, éœ€è¦ä½¿ç”¨<strong>æ­£åˆ™åŒ–</strong>æŠ€æœ¯æ¥é™ä½è¿‡æ‹Ÿåˆã€‚</p><ul><li>å¯¹å¤æ‚æ¨¡å‹å¢åŠ æƒ©ç½šé¡¹, å¦‚ : æ¨¡å‹å¤æ‚åº¦æ­£æ¯”äºå¶ç»“ç‚¹æ•°ç›®æˆ–è€…å¶ç»“ç‚¹é¢„æµ‹å€¼çš„å¹³æ–¹å’Œç­‰</li><li>ç”¨å†³ç­–æ ‘å‰ªæ</li><li>å¶ç»“ç‚¹æ•°ç›®æ§åˆ¶äº†æ ‘çš„å±‚æ•°, ä¸€èˆ¬é€‰æ‹© <span class="math inline">\(4â‰¤Jâ‰¤8\)</span></li><li>å¶ç»“ç‚¹åŒ…å«çš„æœ€å°‘æ ·æœ¬æ•°ç›®<ul><li>é˜²æ­¢å‡ºç°è¿‡å°çš„å¶ç»“ç‚¹, é™ä½é¢„æµ‹æ–¹å·®</li></ul></li><li>æ¢¯åº¦æå‡è¿­ä»£æ¬¡æ•° <span class="math inline">\(M\)</span> :<ul><li>å¢åŠ  <span class="math inline">\(M\)</span> å¯é™ä½è®­ç»ƒé›†çš„æŸå¤±å€¼, ä½†æœ‰è¿‡æ‹Ÿåˆé£é™©</li><li>äº¤å‰éªŒè¯</li></ul></li></ul><p><strong>GBDTæ€»ç»“</strong></p><ul><li>å‡½æ•°ä¼°è®¡æœ¬æ¥è¢«è®¤ä¸ºæ˜¯åœ¨å‡½æ•°ç©ºé—´è€Œéå‚æ•°ç©ºé—´çš„æ•°å€¼ä¼˜åŒ–é—®é¢˜ï¼Œè€Œé˜¶æ®µæ€§çš„åŠ æ€§æ‰©å±•å’Œæ¢¯åº¦ä¸‹é™æ‰‹æ®µå°†å‡½æ•°ä¼°è®¡è½¬æ¢æˆå‚æ•°ä¼°è®¡ã€‚</li><li>æŸå¤±å‡½æ•°æ˜¯æœ€å°å¹³æ–¹è¯¯å·®ã€ç»å¯¹å€¼è¯¯å·®ç­‰ï¼Œåˆ™ä¸º<strong>å›å½’é—®é¢˜</strong>ï¼›è€Œè¯¯å·®å‡½æ•°æ¢æˆå¤šç±»åˆ«Logisticä¼¼ç„¶å‡½æ•°ï¼Œåˆ™æˆä¸º<strong>åˆ†ç±»é—®é¢˜</strong>ã€‚</li><li>å¯¹<strong>ç›®æ ‡å‡½æ•°åˆ†è§£æˆè‹¥å¹²åŸºå‡½æ•°çš„åŠ æƒ</strong>å’Œï¼Œæ˜¯å¸¸è§çš„æŠ€æœ¯æ‰‹æ®µï¼š<a href="https://neymarl.github.io/2016/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8A)/" target="_blank" rel="noopener">ç¥ç»ç½‘ç»œ</a>ã€å¾„å‘åŸºå‡½æ•°ã€å‚…ç«‹å¶/å°æ³¢å˜æ¢ã€<a href="https://neymarl.github.io/2016/03/03/Support%20Vector%20Machines%20(SVMs)/" target="_blank" rel="noopener">SVM</a>éƒ½å¯ä»¥çœ‹åˆ°å®ƒçš„å½±å­ã€‚</li></ul><h2><span id="xgboost">XGBOOST</span></h2><p><span class="math display">\[F_m(x)=F_{m-1}(x)+\arg\min_{f\in H}\sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f(x_i))\]</span></p><p>æ™®é€šæå‡ç®—æ³•åŒ…æ‹¬GBDTåœ¨è®¡ç®—ä¸Šå¼å®é‡‡ç”¨çš„æ˜¯<strong>æ¢¯åº¦æå‡</strong>ï¼Œä¹Ÿå°±æ˜¯åªç”¨äº†ä¸€é˜¶å¯¼æ•°ä¿¡æ¯ï¼Œå¦‚æœå¸¸è¯†<strong>äºŒé˜¶å¯¼æ•°</strong>çš„ä¿¡æ¯å‘¢ï¼Ÿ</p><p><strong>ç›®æ ‡å‡½æ•°</strong>ï¼š<span class="math inline">\(J(f_t) = \sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f_t(x_i)) + \Omega(f_t) + C\)</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\Omega(f_t)\)</span> ä¸ºæ­£åˆ™é¡¹ï¼Œ<span class="math inline">\(C\)</span> ä¸ºå¸¸æ•°ï¼Œç›®çš„æ˜¯è¦æ±‚å‡ºä½¿ç›®æ ‡å‡½æ•°æœ€å°çš„ <span class="math inline">\(f_t\)</span>ã€‚</p><blockquote><p>äºŒé˜¶Taylorå±•å¼ï¼š <span class="math display">\[f(x + \triangle x) = f(x) + f&#39;(x)\triangle x + f&#39;&#39;(x)\triangle x^2 + O(x^3)\]</span></p></blockquote><p>ä»¤ï¼š <span class="math display">\[g_i = \frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)}, h_i = \frac{\partial^2 L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)}\]</span></p><p>å¯¹ <span class="math inline">\(J(f_t)\)</span> äºŒé˜¶Taylorå±•å¼€å¹¶çœç•¥é«˜é˜¶æ— ç©·å°å¾—ï¼š</p><p><span class="math display">\[J(f_t) \approx  \sum_{i=1}^n (L(y_i, F_{m-1}(x_i)) + g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)) + \Omega(f_t) + C\]</span></p><blockquote><p><strong>å†³ç­–æ ‘çš„æè¿°</strong> * ä½¿ç”¨å†³ç­–æ ‘å¯¹æ ·æœ¬åšåˆ†ç±»(å›å½’)ï¼Œæ˜¯ä»æ ¹ç»“ç‚¹åˆ°å¶èŠ‚ç‚¹çš„ç»†åŒ–è¿‡ç¨‹ï¼›è½åœ¨ç›¸åŒå¶èŠ‚ç‚¹çš„æ ·æœ¬çš„é¢„æµ‹å€¼æ˜¯ç›¸åŒçš„ * å‡å®šæŸå†³ç­–æ ‘çš„å¶ç»“ç‚¹æ•°ç›®ä¸º <span class="math inline">\(T\)</span>ï¼Œæ¯ä¸ªå¶ç»“ç‚¹çš„æƒå€¼ä¸º <span class="math inline">\(\overrightarrow{w} = (w_1,w_2 ... w_T)\)</span> ï¼Œå†³ç­–æ ‘çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå°±æ˜¯æ„é€ å¦‚ä½•ä½¿ç”¨ç‰¹å¾å¾—åˆ°åˆ’åˆ†ï¼Œä»è€Œå¾—åˆ°è¿™äº›æƒå€¼çš„è¿‡ç¨‹ã€‚<strong>å¶æƒå€¼å°±æ˜¯è¿™ä¸ªå¶èŠ‚ç‚¹çš„é¢„æµ‹ç»“æœ</strong>ï¼Œè‹¥æ˜¯åˆ†ç±»é—®é¢˜ï¼Œä¹Ÿå°±æ˜¯è¿™ç±»æ ·æœ¬çš„æ ‡ç­¾ã€‚ * æ ·æœ¬ <span class="math inline">\(x\)</span> è½åœ¨å¶ç»“ç‚¹ <span class="math inline">\(q\)</span> ä¸­ï¼Œå®šä¹‰æè¿°å†³ç­–æ ‘å‡½æ•°ä¸º: <span class="math inline">\(f_t(x) = w_q(x)\)</span> * ä¸€ä¸ªå†³ç­–æ ‘çš„æ ¸å¿ƒå³â€œæ ‘ç»“æ„â€å’Œâ€œå¶æƒå€¼â€</p></blockquote><p>å†³ç­–æ ‘çš„å¤æ‚åº¦å¯è€ƒè™‘å¶ç»“ç‚¹æ•°å’Œå¶æƒå€¼ï¼Œå¦‚ä½¿ç”¨å¶ç»“ç‚¹æ€»æ•°å’Œå¶æƒå€¼å¹³æ–¹å’Œçš„åŠ æƒï¼š <span class="math display">\[\Omega(f_t) = \gamma \cdot T_t + \lambda \cdot \frac{1}{2}\sum_{j=1}^Tw_j^2 \]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(T_t\)</span> ä¸ºå¶å­çš„ä¸ªæ•°ã€‚</p><p>æˆ‘ä»¬ç»§ç»­æ¥æ¨å¯¼ç›®æ ‡å‡½æ•° <span class="math inline">\(J(f_t)\)</span>ï¼š</p><p><span class="math display">\[\begin{array}{lcl}J(f_t) = \sum_{i=1}^n [L(y_i, F_{m-1}(x_i)) + g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)] + \Omega(f_t) + C \\\ \ \ \ \ \ \ = \sum_{i=1}^n[g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)]+ \Omega(f_t) + C \\\ \ \ \ \ \ \ =\sum_{i=1}^n[g_iw_q(x_i) + \frac{1}{2}h_iw_q^2(x_i)] + \gamma \cdot T_t + \lambda \cdot \frac{1}{2}\sum_{j=1}^Tw_j^2 + C \\\ \ \ \ \ \ \ = \sum_{j=1}^T [(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\sum_{i \in I_j}h_i)w_j^2] + \gamma \cdot T_t + \lambda \cdot \frac{1}{2}\sum_{j=1}^Tw_j^2 + C \\\ \ \ \ \ \ \ = \sum_{j=1}^T[(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\lambda + \sum_{i \in I_j}h_i)w_j^2] + \gamma \cdot T_t + C\end{array}\]</span></p><p>ä»¤ <span class="math inline">\(G_j = \sum_{i \in I_j}g_i\)</span>ï¼Œ<span class="math inline">\(H_j = \sum_{i \in I_j}h_i\)</span>ï¼Œä»è€Œï¼š <span class="math display">\[J(f_t) = \sum_{j=1}^T[G_jw_j + \frac{1}{2}(\lambda + H_j)w_j^2] + \gamma \cdot T_t + C\]</span></p><p>å¯¹ <span class="math inline">\(w_j\)</span> æ±‚åå¯¼å¾—ï¼š <span class="math display">\[\frac{\partial}{\partial w_j}J(f_t) = G_j + (\lambda + H_j)w_j\]</span></p><p>ä»¤ <span class="math inline">\(\frac{\partial J(f_t)}{\partial w_j} = 0\)</span>ï¼Œå¾—ï¼š <span class="math display">\[w_j = -\frac{G_j}{\lambda + H_j}\]</span></p><p>å›ä»£å…¥ç›®æ ‡å‡½æ•°å¾—ï¼š <span class="math display">\[J(f_t) = -\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{\lambda + H_j} + \gamma \cdot T_t\]</span></p><p>è¿™å°±æ˜¯ç›®æ ‡å‡½æ•°æœ€åçš„ç»“æœï¼Œ<strong>å€¼è¶Šå°ä»£è¡¨å†³ç­–æ ‘çš„ç»“æ„è¶Šå¥½</strong>ã€‚</p><p>æˆ‘ä»¬è¦æ„å»ºä¸€é¢—å†³ç­–æ ‘ <span class="math inline">\(f_t\)</span>ï¼Œä½¿ç›®æ ‡å‡½æ•° <span class="math inline">\(J(f_t)\)</span> è¾¾åˆ°æœ€å°ï¼Œæ„å»ºæ—¶å¯å€Ÿé‰´<a href="https://neymarl.github.io/2016/09/02/%E5%86%B3%E7%AD%96%E6%A0%91%20&amp;%20%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%B8%AD%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/" target="_blank" rel="noopener">ID3/C4.5/CART</a>çš„åšæ³•ï¼š</p><ul><li>å¦‚ä½•è¿›è¡Œå­æ ‘åˆ’åˆ†ï¼Ÿ<ul><li>å¯¹äºæŸå¯è¡Œåˆ’åˆ†, è®¡ç®—åˆ’åˆ†åçš„ <span class="math inline">\(J(f_t)\)</span></li><li>å¯¹äºæ‰€æœ‰å¯è¡Œåˆ’åˆ†, é€‰æ‹© <span class="math inline">\(J(f_t)\)</span> é™ä½æœ€å°çš„åˆ†å‰²ç‚¹</li></ul></li><li>æšä¸¾å¯è¡Œçš„åˆ†å‰²ç‚¹, é€‰æ‹©å¢ç›Šæœ€å¤§çš„åˆ’åˆ†, ç»§ç»­åŒæ ·çš„æ“ä½œ, ç›´åˆ°æ»¡è¶³æŸé˜ˆå€¼æˆ–å¾—åˆ°çº¯èŠ‚ç‚¹<ul><li><span class="math inline">\(Gain(\phi) = \frac{1}{2}[\frac{G_L^2}{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda}]\)</span> <img src="/images/1473252993577.png"></li></ul></li></ul><p><strong>XGBOOSTæ€»ç»“</strong></p><ul><li>XGBOOST ä¸ GBDT çš„åŒºåˆ«åœ¨äºæ›´æ–°æ¨¡å‹çš„æ–¹æ³•ä¸åŒï¼Œå…¶ä½™éƒ½æ˜¯ä¸€æ ·çš„</li><li>ç›¸å¯¹äºä¼ ç»Ÿçš„GBDTï¼ŒXGBoostä½¿ç”¨äº†<strong>äºŒé˜¶ä¿¡æ¯</strong>ï¼Œå¯ä»¥æ›´å¿«çš„åœ¨è®­ç»ƒé›†ä¸Šæ”¶æ•›</li><li>ç”±äºâ€œ<strong>éšæœºæ£®æ—æ—</strong>â€æœ¬èº«å…·å¤‡é˜²æ­¢è¿‡æ‹Ÿåˆçš„ä¼˜åŠ¿ï¼Œå› æ­¤XGBoostä»ç„¶ä¸€å®šç¨‹åº¦çš„å…·æœ‰è¯¥ç‰¹æ€§</li><li>XGBoostçš„å®ç°ä¸­ä½¿ç”¨äº†<strong>å¹¶è¡Œ/å¤šæ ¸è®¡ç®—</strong>, å› æ­¤è®­ç»ƒé€Ÿåº¦å¿«; åŒæ—¶å®ƒçš„åŸç”Ÿè¯­è¨€ä¸ºC/C++, è¿™æ˜¯å®ƒé€Ÿåº¦å¿«çš„å®è·µåŸå› </li></ul><h2><span id="adaboost">AdaBoost</span></h2><p><strong>æ€è€ƒ</strong>ï¼šå¦‚æœå¯¹GBDTçš„åŸºå‡½æ•°çš„å­¦ä¹ ä¸­ï¼Œä¸æ­¢è€ƒè™‘å‡½æ•°çš„å‚æ•°å’Œæƒå€¼ï¼Œè€Œæ˜¯å¯¹æ ·æœ¬æœ¬èº«ä¹ŸåŠ æƒï¼Œä¼šå¾—åˆ°ä»€ä¹ˆç»“æœå‘¢ï¼Ÿè¿™å…¶å®å°±æ˜¯Adaboostçš„æ€æƒ³ã€‚</p><p><strong>AdaBoostç®—æ³•</strong></p><ul><li><p>è®¾è®­ç»ƒæ•°æ®é›† <span class="math inline">\(T={(x_1,y_1), (x_2,y_2)...(x_N,y_N)}\)</span>ï¼Œåˆå§‹åŒ–è®­ç»ƒæ•°æ®çš„æƒå€¼åˆ†å¸ƒ <span class="math inline">\(D_1 = (w_{11}, w_{12}, ..., w_{1i}, ...., w_{1N})\)</span>, <span class="math inline">\(w_{1i} = \frac{1}{N}\)</span>, <span class="math inline">\(i = 1, 2, ... N\)</span>ã€‚</p></li><li>å¯¹äº <span class="math inline">\(m = 1, 2, ... M\)</span>ï¼Œ<span class="math inline">\(M\)</span> ä¸ºæ ‘çš„æ£µæ•°:<ul><li><p>ä½¿ç”¨å…·æœ‰æƒå€¼åˆ†å¸ƒ <span class="math inline">\(D_m\)</span> çš„è®­ç»ƒæ•°æ®é›†å­¦ä¹ , å¾—åˆ°åŸºæœ¬åˆ†ç±»å™¨ <span class="math display">\[G_m(x) : x \rightarrow \{-1, 1\}\]</span></p></li><li><p>è®¡ç®— <span class="math inline">\(G_m(x)\)</span> åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„åˆ†ç±»è¯¯å·®ç‡: <span class="math display">\[e_m = P(G_m(x_i) \neq y_i) = \sum_{i=1}^Nw_{mi}I(G_m(x_i) \neq y_i)\]</span></p></li><li><p>è®¡ç®— <span class="math inline">\(G_m(x)\)</span> çš„ç³»æ•° <span class="math display">\[\alpha_m = \frac{1}{2}\log \frac{1-e_m}{e_m}\]</span></p></li><li>æ›´æ–°è®­ç»ƒæ•°æ®é›†çš„æƒå€¼åˆ†å¸ƒ <span class="math display">\[D_{m+1} = (w_{m+1, 1}, w_{m+1, 2}, ...., w_{m+1, i}, ..., w_{m+1, N})\]</span> <span class="math display">\[w_{m+1, i} = \frac{w_{mi}}{Z_m}\exp(-\alpha_m y_iG_m(x_i)), i = 1, 2, ... , N\]</span></li><li>è¿™é‡Œï¼Œ<span class="math inline">\(Z_m\)</span> æ˜¯å½’ä¸€åŒ–å› å­ï¼š <span class="math display">\[Z_m = \sum_{i=1}^Nw_{mi}\exp(-\alpha_my_iG_m(x_i))\]</span></li><li><p>å®ƒä½¿ <span class="math inline">\(D_{m+1}\)</span> æˆä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼ˆå’Œä¸º1ï¼‰ã€‚</p></li></ul></li><li><p>æ„å»ºåŸºæœ¬åˆ†ç±»å™¨çš„çº¿æ€§ç»„åˆ <span class="math display">\[f(x) = \sum_{m=1}^M\alpha_mG_m(x)\]</span></p></li><li><p>å¾—åˆ°æœ€ç»ˆåˆ†ç±»å™¨ï¼š <span class="math display">\[G(x) = sign(f(x)) = sign(\sum_{m=1}^M\alpha_mG_m(x))\]</span></p></li></ul><p><strong>ç®—æ³•è§£é‡Š</strong></p><p>æˆ‘ä»¬å…ˆåˆ†æ <span class="math inline">\(G_m(x)\)</span> çš„ç³»æ•°ï¼š<span class="math inline">\(\alpha_m = \frac{1}{2}\log \frac{1-e_m}{e_m}\)</span>ï¼Œè¿™é‡Œçš„ <span class="math inline">\(e_m\)</span> æ˜¯åˆ†ç±»é”™è¯¯ç‡ã€‚ è¿™ä¸ªå¼å­å®ç°äº†è¿™ä¹ˆä¸€ä¸ªç†è®ºï¼šå¦‚æœä¸€ä¸ªåˆ†ç±»å™¨çš„åˆ†ç±»é”™è¯¯ç‡è¶…è¿‡50%ï¼Œé‚£ä¹ˆè¿™ä¸ªåˆ†ç±»å™¨è¿˜ä¸å¦‚éšæœºåˆ†ç±»ï¼ˆé»˜è®¤å‡åŒ€åˆ†å¸ƒï¼Œéšæœºåˆ†50%é”™è¯¯ç‡ï¼‰æ¥å¾—å¥½ï¼ŒæŠŠè¿™ä¸ªåˆ†ç±»å™¨ç›´æ¥åè½¬æ•ˆæœåè€Œä¼šæ›´å¥½ã€‚</p><ul><li>å¦‚æœ <span class="math inline">\(e_m &lt; 0.5\)</span>ï¼Œåˆ™ <span class="math inline">\(1- e_m &gt; 0.5\)</span>ï¼Œæ‰€ä»¥ <span class="math inline">\(\frac{1-e_m}{e_m} &gt; 1\)</span>ï¼Œå¯ä»¥å¾—åˆ° <span class="math inline">\(\log\frac{1-e_m}{e_m} &gt; 0\)</span>ï¼Œå³ï¼š<span class="math inline">\(\alpha_m &gt; 0\)</span>ï¼Œè¯´æ˜å¦‚æœè¿™ä¸ªåˆ†ç±»å™¨çš„é”™è¯¯ç‡å°äº0.5åˆ™æƒå€¼ä¸ºæ­£ï¼Œè¡¨ç¤ºå¯ä»¥å‚è€ƒè¿™ä¸ªåˆ†ç±»å™¨çš„ç»“æœï¼Œå¹¶ä¸”é”™è¯¯ç‡è¶Šä½åˆ†ç±»å™¨çš„æƒå€¼è¶Šå¤§ï¼›</li><li>å¦‚æœ <span class="math inline">\(e_m &gt; 0.5\)</span>ï¼Œåˆ™ <span class="math inline">\(1- e_m &lt; 0.5\)</span>ï¼Œæ‰€ä»¥ <span class="math inline">\(\frac{1-e_m}{e_m} &lt; 1\)</span>ï¼Œå¯ä»¥å¾—åˆ° <span class="math inline">\(\log\frac{1-e_m}{e_m} &lt; 0\)</span>ï¼Œå³ï¼š<span class="math inline">\(\alpha_m &lt; 0\)</span>ï¼Œå°±ç›¸å½“äºæŠŠåˆ†ç±»å™¨åè½¬ã€‚</li></ul><p>å†æ¥çœ‹æƒå€¼æ›´æ–°å…¬å¼ï¼Œ<span class="math inline">\(w_{m+1, i} = \frac{w_{mi}}{Z_m}\exp(-\alpha_m y_iG_m(x_i)), i = 1, 2, ... , N\)</span></p><ul><li><p>å…ˆçœ‹æŒ‡æ•°ä¸Šçš„ä¸€å°éƒ¨åˆ† : <span class="math inline">\(-\alpha_m y_iG_m(x_i)\)</span>ï¼Œå…¶ä¸­ <span class="math inline">\(-\alpha_m\)</span> ä¸ºè¯¥åˆ†ç±»å™¨çš„æƒå€¼ï¼Œ<span class="math inline">\(y_i\)</span> ä¸ºç¬¬ <span class="math inline">\(i\)</span> ä¸ªæ ·æœ¬çš„å®é™…ç±»åˆ«ä¸” <span class="math inline">\(y_i \in \{-1, 1\}\)</span>ï¼Œ<span class="math inline">\(G_m(x_i)\)</span> ä¸ºé¢„æµ‹ç±»åˆ«ã€‚</p><ul><li>è‹¥é¢„æµ‹ç±»åˆ«ä¸å®é™…ç±»åˆ«ä¸€è‡´ï¼Œåˆ™ <span class="math inline">\(y_iG_m(x_i) &gt; 0\)</span>ï¼Œåä¹‹åˆ™ <span class="math inline">\(y_iG_m(x_i) &lt; 0\)</span></li><li>å¦‚æœè¯¥åˆ†ç±»å™¨æ¯”è¾ƒé è°±çš„è¯ï¼ˆ<span class="math inline">\(e_m &lt; 0.5\)</span>ï¼‰ï¼Œ<span class="math inline">\(\alpha_m\)</span> æ˜¯ä¸ªæ­£æ•°ï¼Œåä¹‹æ˜¯ä¸ªè´Ÿæ•°ã€‚</li><li>ç»¼åˆèµ·æ¥çœ‹ï¼šå¦‚æœé è°±çš„åˆ†ç±»å™¨é¢„æµ‹é”™äº†ï¼ˆæˆ–è€…ä¸é è°±çš„åˆ†ç±»å™¨é¢„æµ‹å¯¹äº†ï¼‰ï¼Œåˆ™ <span class="math inline">\(-\alpha_m y_iG_m(x_i) &gt; 0\)</span>ï¼Œåä¹‹åˆ™ <span class="math inline">\(-\alpha_m y_iG_m(x_i) &lt; 0\)</span></li></ul></li><li><p><span class="math inline">\(Z_m\)</span> æ˜¯ç”¨æ¥å½’ä¸€åŒ–çš„ï¼Œä¸ç”¨çœ‹ï¼ŒæŠŠå…¶ä»–éƒ¨åˆ†åˆèµ·æ¥ï¼š</p><ul><li>å¦‚æœ <span class="math inline">\(-\alpha_m y_iG_m(x_i) &gt; 0\)</span>ï¼Œåˆ™ <span class="math inline">\(\exp(-\alpha_m y_iG_m(x_i)) &gt; 1\)</span>ï¼Œè¿›è€Œå¾—åˆ° <span class="math inline">\(w_{m+1, i} = w_{mi} * ä¸€ä¸ªå¤§äº1çš„æ•°\)</span>ï¼Œå³æƒå€¼å¢åŠ ã€‚</li><li>å¦‚æœ <span class="math inline">\(-\alpha_m y_iG_m(x_i) &lt; 0\)</span>ï¼Œåˆ™ <span class="math inline">\(\exp(-\alpha_m y_iG_m(x_i)) &lt; 1\)</span>ï¼Œè¿›è€Œå¾—åˆ° <span class="math inline">\(w_{m+1, i} = w_{mi} * ä¸€ä¸ªå°äº1çš„æ•°\)</span>ï¼Œå³æƒå€¼é™ä½ã€‚</li></ul></li><li><p><strong>ç»“è®º</strong>ï¼šå¦‚æœåˆ†ç±»å™¨é¢„æµ‹é”™äº†åˆ™å¢åŠ è¯¥æ ·æœ¬çš„æƒå€¼ï¼Œåœ¨ä¸‹æ¬¡åˆ†ç±»æ—¶é‡ç‚¹å…³æ³¨è¯¥æ ·æœ¬ï¼›å¦‚æœåˆ†ç±»æ­£ç¡®åˆ™é™ä½è¯¥æ ·æœ¬çš„æƒå€¼ï¼Œåœ¨ä¸‹æ¬¡åˆ†ç±»æ—¶å¼±åŒ–è¯¥æ ·æœ¬ã€‚ä¹Ÿå°±æ˜¯æ ·æœ¬çš„æƒå€¼åŠ¨æ€å˜åŒ–ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p></li></ul><p><img src="/images/1473337734827.png"></p><h3><span id="è¯¯å·®åˆ†æ">è¯¯å·®åˆ†æ</span></h3><p>AdaBoostç®—æ³•æœ€ç»ˆçš„è¯¯å·®ç•Œä¸ºï¼š</p><p><span class="math display">\[\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant \frac{1}{N}exp(-y_if(x_i)) = \prod_mZ_m\]</span></p><p><strong>è¯æ˜</strong></p><ul><li>å‰åŠéƒ¨åˆ†ï¼šå½“ <span class="math inline">\(G(x_i) \neq y_i\)</span> æ—¶ï¼Œ<span class="math inline">\(y_if(x_i) &lt; 0\)</span>ï¼Œå› è€Œ <span class="math inline">\(exp(-y_if(x_i)) \geqslant 1\)</span>ï¼Œè€Œ <span class="math inline">\(\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant 1\)</span>ï¼Œæ‰€ä»¥ <span class="math inline">\(\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant \frac{1}{N}exp(-y_if(x_i))\)</span>ï¼Œå‰åŠéƒ¨åˆ†å¾—è¯ã€‚ <br></li><li>ååŠéƒ¨åˆ†ï¼š<ul><li><p>ç”± <span class="math inline">\(Z_m\)</span> çš„å®šä¹‰å¼å¾—ï¼š<span class="math inline">\(w_{mi}exp(-\alpha_my_iG_m(x_i)) = Z_mw_{m+1,i}\)</span> <span class="math display">\[\begin{array}{lcl}\frac{1}{N}exp(-y_if(x_i)) \\= \frac{1}{N}\sum_i\exp(- \sum_{m=1}^M\alpha_my_iG_m(x_i)) \\= \sum_iw_{1i}\prod_{m=1}^M\exp(-\alpha_my_iG_m(x_i)) \\= Z_1\sum_i w_{2,1}\prod_{m=2}^M\exp(-\alpha_my_iG_m(x_i)) \\= Z_1Z_2\sum_i w_{3,1}\prod_{m=3}^M\exp(-\alpha_my_iG_m(x_i)) \\= .... \\= Z_1Z_2...Z_{M-1}\sum_i w_{M,1}\exp(-\alpha_my_iG_m(x_i)) \\= \prod_{m=1}^MZ_m\end{array}\]</span></p></li><li><p>ååŠéƒ¨åˆ†å¾—è¯</p></li></ul></li></ul><p>è¿™ä¸€ç»“æœè¯´æ˜ï¼Œå¯ä»¥åœ¨æ¯ä¸€è½®é€‰å–é€‚å½“çš„ <span class="math inline">\(G_m\)</span> ä½¿å¾— <span class="math inline">\(Z_m\)</span> æœ€å°ï¼Œä»è€Œä½¿è®­ç»ƒè¯¯å·®ä¸‹é™æœ€å¿«ã€‚</p><p><strong>è®­ç»ƒè¯¯å·®ç•Œ</strong></p><p><span class="math display">\[\begin{array}{lcl}Z_m = \sum_{i=1}^Nw_{mi}\exp(-\alpha_my_iG_m(x_i)) \\\ \ \ \ \ = \sum_{y_i=G_m(x_i)}w_{mi}e^{-\alpha_m} +  \sum_{y_i\neq G_m(x_i)}w_{mi}e^{\alpha_m}\end{array}\]</span></p><p>å› ä¸º <span class="math inline">\(\alpha_m = \frac{1}{2}\log\frac{1-e_m}{e_m}\)</span>ï¼Œ<span class="math inline">\(\sum_{y_i=G_m(x_i)}w_{mi} = 1 - e_m\)</span>ï¼Œ<span class="math inline">\(\sum_{y_i\neq G_m(x_i)}w_{mi} = e_m\)</span> æ‰€ä»¥ <span class="math display">\[\begin{array}{lcl}Z_m = (1- e_m)e^{-\alpha_m} + e_me^{\alpha_m} \\\ \ \ \ \ = 2\sqrt{e_m(1-e_m)} \\\ \ \ \ \ = \sqrt{1-4\gamma_m^2}\end{array}\]</span> å…¶ä¸­ï¼Œ<span class="math inline">\(\gamma_m = \frac{1}{2} - e_m\)</span>ã€‚</p><p>ç”±æ­¤å¾—åˆ°ï¼š <span class="math display">\[\prod_{m=1}^MZ_m = \prod_{m=1}^M \sqrt{1-4\gamma_m^2} \leqslant \exp(-2\sum_{m=1}^M\gamma_m^2)\]</span></p><p>å– <span class="math inline">\(\gamma_1, \gamma_2....\)</span> çš„æœ€å°å€¼ï¼Œè®°ä¸º <span class="math inline">\(\gamma\)</span>ï¼Œ åˆ™æœ‰ï¼š <span class="math display">\[\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant \exp(-2M\gamma^2)\]</span></p><p>è¿™è¡¨æ˜AdaBoostè®­ç»ƒè¯¯å·®æ˜¯<strong>ä»¥æŒ‡æ•°é€Ÿç‡ä¸‹é™</strong>çš„ï¼</p><p><strong>AdaBoostæ€»ç»“</strong></p><ul><li>AdaBoostç®—æ³•å¯ä»¥çœ‹åšæ˜¯é‡‡ç”¨æŒ‡æ•°æŸå¤±å‡½æ•°çš„æå‡æ–¹æ³•ï¼Œå…¶æ¯ä¸ªåŸºå‡½æ•°çš„å­¦ä¹ ç®—æ³•ä¸ºå‰å‘åˆ†æ­¥ç®—æ³•</li><li>AdaBoostçš„è®­ç»ƒè¯¯å·®æ˜¯ä»¥æŒ‡æ•°é€Ÿç‡ä¸‹é™çš„</li><li>AdaBoostç®—æ³•ä¸éœ€è¦äº‹å…ˆçŸ¥é“ä¸‹ç•Œ <span class="math inline">\(\gamma\)</span>ï¼Œå…·æœ‰<strong>è‡ªé€‚åº”æ€§(Adaptive)</strong>ï¼Œå®ƒèƒ½è‡ªé€‚åº”å¼±åˆ†ç±»å™¨çš„è®­ç»ƒè¯¯å·®ç‡</li></ul><h2><span id="å‚è€ƒæ–‡çŒ®">å‚è€ƒæ–‡çŒ®</span></h2><ul><li>æèˆªï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼Œæ¸…åå¤§å­¦å‡ºç‰ˆç¤¾ï¼Œ2012</li><li>Jerome H. Friedman. Greedy Function Approximation: A Gradient Boosting Machine. February 1999</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Boosting </tag>
            
            <tag> GBDT </tag>
            
            <tag> xgboost </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å†³ç­–æ ‘ &amp; éšæœºæ£®æ—ä¸­çš„å…¬å¼æ¨å¯¼</title>
      <link href="/2016/09/02/%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%B8%AD%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"/>
      <url>/2016/09/02/%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%B8%AD%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p><strong>å†³ç­–æ ‘å­¦ä¹ çš„ç”Ÿæˆç®—æ³•</strong>ä¸»è¦æœ‰ä¸‰ç§ï¼š * ID3 * Iterative Dichotomiser * C4.5 * CART * Classification And Regression Tree</p><p>å†³ç­–æ ‘å»ºç«‹å°±æ˜¯ä»ç‰¹å¾ä¸­é€‰æ‹©ä¸€ä¸ªä½œä¸ºåˆ†ç±»æ¡ä»¶æŠŠæ ·æœ¬åˆ’åˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼Œç„¶åå¯¹æ¯ä¸ªå­é›†åšåŒæ ·çš„äº‹æƒ…ç›´åˆ°æ¯ä¸ªå­é›†éƒ½å±äºç›¸åŒçš„æ ‡ç­¾ã€‚æ‰€ä»¥å»ºç«‹å†³ç­–æ ‘çš„å…³é”®åœ¨äºæ¯æ¬¡åˆ’åˆ†å­é›†çš„æ—¶å€™é€‰æ‹©å“ªä¸ªç‰¹å¾ï¼Œè¿™ä¹Ÿæ˜¯ä¸Šé¢ä¸‰ç§ç®—æ³•çš„æœ€ä¸»è¦åŒºåˆ«ï¼Œä¸‹é¢å°†ä¸€ä¸€æ¢è®¨ã€‚</p><a id="more"></a><h2><span id="id3">ID3</span></h2><p>è¦äº†è§£ID3ç®—æ³•é¦–å…ˆè¦äº†è§£ä¸€ä¸‹<strong>ä¿¡æ¯å¢ç›Š</strong>ç­‰çŸ¥è¯†ã€‚è¯¥ç®—æ³•ä¹Ÿå¯ä»¥å‚è€ƒæˆ‘å‰é¢çš„æ–‡ç« ï¼š<a href="http://www.liuhe.website/index.php?/Articles/single/46" target="_blank" rel="noopener">å†³ç­–æ ‘ä¹‹ID3ç®—æ³•è¯¦è§£</a>ã€‚</p><p><strong>ä¿¡æ¯ç†µ</strong></p><pre><code>åœ¨ä¿¡æ¯è®ºä¸­ï¼Œç†µæ˜¯æ¥æ”¶çš„æ¯æ¡æ¶ˆæ¯ä¸­åŒ…å«çš„ä¿¡æ¯çš„å¹³å‡é‡ï¼Œåˆè¢«ç¨±ç‚ºä¿¡æ¯ç†µã€ä¿¡æºç†µã€å¹³å‡è‡ªä¿¡æ¯é‡ã€‚è¿™é‡Œï¼Œæ¶ˆæ¯ä»£è¡¨æ¥è‡ªåˆ†å¸ƒæˆ–æ•°æ®æµä¸­çš„äº‹ä»¶ã€æ ·æœ¬æˆ–ç‰¹å¾ã€‚ï¼ˆç†µæœ€å¥½ç†è§£ä¸ºä¸ç¡®å®šæ€§çš„é‡åº¦è€Œä¸æ˜¯ç¡®å®šæ€§çš„é‡åº¦ï¼Œå› ä¸ºè¶Šéšæœºçš„ä¿¡æºçš„ç†µè¶Šå¤§ã€‚ï¼‰æ¥è‡ªä¿¡æºçš„å¦ä¸€ä¸ªç‰¹å¾æ˜¯æ ·æœ¬çš„æ¦‚ç‡åˆ†å¸ƒã€‚è¿™é‡Œçš„æƒ³æ³•æ˜¯ï¼Œæ¯”è¾ƒä¸å¯èƒ½å‘ç”Ÿçš„äº‹æƒ…ï¼Œå½“å®ƒå‘ç”Ÿäº†ï¼Œä¼šæä¾›æ›´å¤šçš„ä¿¡æ¯ã€‚ç”±äºä¸€äº›å…¶ä»–çš„åŸå› ï¼ˆä¸‹é¢ä¼šæœ‰è§£é‡Šï¼‰ï¼ŒæŠŠä¿¡æ¯ï¼ˆç†µï¼‰å®šä¹‰ä¸ºæ¦‚ç‡åˆ†å¸ƒçš„å¯¹æ•°çš„ç›¸åæ•°æ˜¯æœ‰é“ç†çš„ã€‚äº‹ä»¶çš„æ¦‚ç‡åˆ†å¸ƒå’Œæ¯ä¸ªäº‹ä»¶çš„ä¿¡æ¯é‡æ„æˆäº†ä¸€ä¸ªéšæœºå˜é‡ï¼Œè¿™ä¸ªéšæœºå˜é‡çš„å‡å€¼ï¼ˆå³æœŸæœ›ï¼‰å°±æ˜¯è¿™ä¸ªåˆ†å¸ƒäº§ç”Ÿçš„ä¿¡æ¯é‡çš„å¹³å‡å€¼ï¼ˆå³ç†µï¼‰ã€‚                      -- from WikiPedia</code></pre><p>ç†µçš„å…¬å¼å®šä¹‰ä¸ºï¼š <span class="math display">\[H(X) = E[-\ln P(x)] = -\sum_i P(x_i)ln(P(x_i)) \]</span></p><p>ç†µçš„ç›´è§‚è§£é‡Šæ˜¯å¯¹<strong>ä¸ç¡®å®šæ€§</strong>çš„åº¦é‡ï¼Œç†µè¶Šå¤§ä¸ç¡®å®šæ€§è¶Šå¤§ï¼Œç†µè¶Šå°ä¸ç¡®å®šæ€§è¶Šå°ã€‚</p><p><span class="math inline">\(H(X)\)</span> éš <span class="math inline">\(P(x_i)\)</span> å˜åŒ–çš„æ›²çº¿ä¸º</p><p><img src="/images/1472795562715.png"></p><p>è®¾éšæœºå˜é‡ <span class="math inline">\(X\)</span> åªèƒ½å–ä¸¤ä¸ªå€¼ <span class="math inline">\(0\)</span> å’Œ <span class="math inline">\(1\)</span>ï¼Œæ˜¾ç„¶å½“å–ä¸¤ä¸ªæ•°çš„æ¦‚ç‡éƒ½ä¸º50%çš„æ—¶å€™ä¸ç¡®å®šæ€§æœ€å¤§ï¼Œå³ç†µæœ€å¤§ä¸º1ï¼›è‹¥å– <span class="math inline">\(0\)</span> æˆ–å– <span class="math inline">\(1\)</span> çš„æ¦‚ç‡ä¸º 100%ï¼Œåˆ™äº‹ä»¶å®Œå…¨ç¡®å®šï¼Œæ­¤æ—¶ç†µä¸º0 ã€‚</p><p><strong>æ¡ä»¶ç†µ</strong></p><p>ä¸‹é¢æ¥è®¨è®ºä¸€ä¸‹æ¡ä»¶ç†µï¼Œå®ƒçš„å®šä¹‰å¼ä¸ºï¼š<span class="math inline">\(H(X, Y) - H(X)\)</span>ã€‚</p><p><span class="math inline">\((X,Y)\)</span> å‘ç”Ÿæ‰€åŒ…å«çš„ç†µ,å‡å» <span class="math inline">\(X\)</span> å•ç‹¬å‘ç”ŸåŒ…å«çš„ç†µï¼š * åœ¨ <span class="math inline">\(X\)</span> å‘ç”Ÿçš„å‰æä¸‹, <span class="math inline">\(Y\)</span> å‘ç”Ÿâ€œæ–°â€å¸¦æ¥çš„ç†µ * è¯¥å¼å­å®šä¹‰ä¸º <span class="math inline">\(X\)</span> å‘ç”Ÿå‰æä¸‹, <span class="math inline">\(Y\)</span> çš„ç†µ: * æ¡ä»¶ç†µ <span class="math inline">\(H(Y|X)\)</span></p><p>æˆ‘ä»¬æ¥æ¨å¯¼ä¸€ä¸‹è¿™ä¸ªå¼å­ç­‰äºä»€ä¹ˆã€‚</p><p><span class="math display">\[\begin{array}{lcl}H(Y|X) = H(X, Y) - H(X) \\= -\sum_{x, y}p(x, y) \ln p(x, y) + \sum_x p(x)\ln p(x) \\= -\sum_{x, y}p(x, y) \ln p(x, y) + \sum_x\sum_y p(x, y) \ln p(x) \\= - \sum_{x, y} p(x, y) (\ln p(x, y) - \ln p(x)) \\= - \sum_{x, y} p(x, y) \ln\frac{p(x, y)}{p(x)} \\= - \sum_{x, y} p(x, y) \ln p(y\ |\ x)\end{array}\]</span></p><p>ç»§ç»­æ¨å¯¼æˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š</p><p><span class="math display">\[\begin{array}{lcl}H(X, Y) - H(X) \\=  - \sum_{x, y} p(x, y) \ln p(y\ |\ x) \\= -\sum_{x, y} p(x) p(y\ |\ x) \ln p(y\ |\ x) \\= \sum_x p(x) (- \sum_y p(y\ |\ x) \ln p(y\ |\ x)) \\= \sum_x p(x) H(Y\ |\ X = x) \\= E[H(Y\ |\ X = x)]\end{array}\]</span></p><p>æ˜¯ç†µçš„<strong>æ•°å­¦æœŸæœ›</strong>ï¼</p><p><strong>ä¿¡æ¯å¢ç›Š</strong></p><ul><li>ä¿¡æ¯å¢ç›Šè¡¨ç¤ºå¾—çŸ¥ç‰¹å¾ <span class="math inline">\(A\)</span> çš„ä¿¡æ¯è€Œä½¿å¾—ç±» <span class="math inline">\(X\)</span> çš„ä¿¡æ¯çš„ä¸ç¡®å®šæ€§å‡å°‘çš„ç¨‹åº¦ã€‚</li><li><strong>ç»éªŒç†µ</strong>ï¼šå½“ç†µå’Œæ¡ä»¶ç†µä¸­çš„æ¦‚ç‡ç”±æ•°æ®ä¼°è®¡(ç‰¹åˆ«æ˜¯æå¤§ä¼¼ç„¶ä¼°è®¡)å¾—åˆ°æ—¶,æ‰€å¯¹åº”çš„ç†µå’Œæ¡ä»¶ç†µåˆ†åˆ«ç§°ä¸º<strong>ç»éªŒç†µ</strong>å’Œ<strong>ç»éªŒæ¡ä»¶ç†µ</strong>ã€‚</li><li><strong>å®šä¹‰</strong>ï¼šç‰¹å¾ <span class="math inline">\(A\)</span> å¯¹è®­ç»ƒæ•°æ®é›† <span class="math inline">\(D\)</span> çš„ä¿¡æ¯å¢ç›Š <span class="math inline">\(g(D,A)\)</span>, å®šä¹‰ä¸ºé›†åˆ <span class="math inline">\(D\)</span> çš„ç»éªŒç†µ <span class="math inline">\(H(D)\)</span> ä¸ç‰¹å¾ <span class="math inline">\(A\)</span> ç»™å®šæ¡ä»¶ä¸‹ <span class="math inline">\(D\)</span> çš„ç»éªŒæ¡ä»¶ç†µ <span class="math inline">\(H(D|A)\)</span> ä¹‹å·®, å³:<ul><li><span class="math inline">\(g(D,A)=H(D)\ â€“ H(D\ |\ A)\)</span></li></ul></li></ul><p><em>åŸºæœ¬è®°å·</em></p><ul><li>è®¾è®­ç»ƒæ•°æ®é›†ä¸º <span class="math inline">\(D\)</span> , <span class="math inline">\(|D|\)</span> è¡¨ç¤ºæ ·æœ¬ä¸ªæ•°ã€‚</li><li>è®¾æœ‰ <span class="math inline">\(K\)</span> ä¸ªç±» <span class="math inline">\(C_k\)</span> , <span class="math inline">\(k = 1, 2, ... K\)</span> , <span class="math inline">\(C_k\)</span> ä¸ºå±äºç±» <span class="math inline">\(C_k\)</span> çš„æ ·æœ¬ä¸ªæ•°, æœ‰: $_k | C_k | = | D | $</li><li>è®¾ç‰¹å¾ <span class="math inline">\(A\)</span> æœ‰ <span class="math inline">\(n\)</span> ä¸ªä¸åŒçš„å–å€¼ <span class="math inline">\(\{a_1, a_2, ... a_n\}\)</span> ,æ ¹æ®ç‰¹å¾ <span class="math inline">\(A\)</span> çš„å–å€¼å°† <span class="math inline">\(D\)</span> åˆ’åˆ†ä¸º <span class="math inline">\(n\)</span> ä¸ªå­é›† <span class="math inline">\(D_1, D_2, ... D_n\)</span> , ä¸º <span class="math inline">\(| D_i |\)</span> ä¸º <span class="math inline">\(D_i\)</span> çš„æ ·æœ¬ä¸ªæ•°ï¼Œæœ‰ï¼š<span class="math inline">\(\sum_i |D_i| = |D|\)</span></li><li>è®°å­é›† <span class="math inline">\(D\)</span> ä¸­å±äºç±» <span class="math inline">\(C\)</span> çš„æ ·æœ¬çš„é›†åˆä¸º <span class="math inline">\(D_{ik}\)</span> ï¼Œ<span class="math inline">\(|D_{ik}|\)</span> ä¸º <span class="math inline">\(D_{ik}\)</span> çš„æ ·æœ¬ä¸ªæ•°ã€‚</li></ul><p><strong>ID3ç®—æ³•</strong></p><ol type="1"><li>è®¡ç®—æ•°æ®é›† <span class="math inline">\(D\)</span> çš„ç»éªŒç†µ <span class="math inline">\(H(D) = -\sum_{k=1}^K \frac{|C_k|}{|D|} log\frac{|C_k|}{|D|}\)</span></li><li>éå†æ‰€æœ‰ç‰¹å¾, å¯¹äºç‰¹å¾ <span class="math inline">\(A\)</span> :<ul><li>è®¡ç®—ç‰¹å¾ <span class="math inline">\(A\)</span> å¯¹æ•°æ®é›† <span class="math inline">\(D\)</span> çš„ç»éªŒæ¡ä»¶ç†µ <span class="math inline">\(H(D\ |\ A)\)</span></li><li>è®¡ç®—ç‰¹å¾ <span class="math inline">\(A\)</span> çš„ä¿¡æ¯å¢ç›Š : <span class="math inline">\(g(D,A)=H(D) â€“ H(D\ |\ A)\)</span></li><li>é€‰æ‹©ä¿¡æ¯å¢ç›Š<strong>æœ€å¤§</strong>çš„ç‰¹å¾ä½œä¸ºå½“å‰çš„åˆ†è£‚ç‰¹å¾</li></ul></li></ol><p><strong>æ¡ä»¶ç»éªŒç†µ <span class="math inline">\(H(D\ |\ A)\)</span> è®¡ç®—æ–¹æ³•</strong></p><p><span class="math display">\[\begin{array}{lcl}H(D\ |\ A) = H(D, A) - H(A) \\= -\sum_{i,k} p(D_k, A_i) \log p(D_k, A_i) \\= - \sum_{i=1}^n p(A_i) \sum_{k=1}^K p(D_k\ |\ A_i) \log p(D_k\ |\ A_i) \\= - \sum_{i=1}^n \frac{|D_i|}{|D|} \sum_{k=1}^K \frac{|D_{ik}|}{|D_i|} \log \frac{|D_{ik}|}{|D_i|}\end{array}\]</span></p><p>ä»¥ä¸Šå°±æ˜¯ ID3 ç®—æ³•çš„æ ¸å¿ƒå†…å®¹ã€‚</p><p>ä½†æ˜¯ID3ç®—æ³•æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œç®—æ³•æ¯æ¬¡é€‰æ‹©ä¸€ä¸ªä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾è¿›è¡Œå­é›†åˆ’åˆ†ï¼Œè¿™æ ·å°±ä¼šå€¾å‘äºé€‰æ‹©ä¸€äº›å–å€¼å¾ˆå¤šè€Œä¸”æ¯ä¸ªå€¼å¯¹åº”çš„æ ·æœ¬å¾ˆå°‘çš„ç‰¹å¾ï¼Œæ¯”å¦‚æ ·æœ¬åºå·ï¼ˆå¦‚æœä½ æŠŠå®ƒåŠ å…¥ç‰¹å¾çš„è¯ï¼‰ï¼Œè‹¥é€‰æ‹©æ ·æœ¬åºå·ä½œä¸ºåˆ’åˆ†å­é›†çš„ç‰¹å¾ï¼Œåˆ™å¯ä¸€æ¬¡åˆ’åˆ†ç»“æŸï¼Œæ‰€æœ‰å­é›†éƒ½å˜ä¸ºå¶å­èŠ‚ç‚¹ï¼Œ<strong>ç†µä¸ºé›¶</strong>ï¼Œä½†æ˜¯è¿™æ ·åˆ†ç±»å¹¶æ²¡æœ‰æ„ä¹‰ï¼Œå› ä¸ºå®ƒå®Œå…¨<strong>è¿‡æ‹Ÿåˆ</strong>äº†è€Œä¸”<strong>æ²¡æœ‰ä»»ä½•é¢„æµ‹èƒ½åŠ›</strong>ã€‚ä¸ºäº†é¿å…è¿™ç§æƒ…å†µçš„å‘ç”Ÿï¼Œæˆ‘ä»¬éœ€è¦æ”¹è¿›è¿™ç§é€‰æ‹©ç‰¹å¾æ ‡å‡†ï¼Œäºæ˜¯å°±æœ‰äº†C4.5å’ŒCARTã€‚</p><h2><span id="c45">C4.5</span></h2><p>C4.5 å¯¹ ID3 çš„ä¸»è¦æ”¹è¿›åœ¨äºæ¯æ¬¡åˆ†å‰²é€‰æ‹©ç‰¹å¾çš„æ ‡å‡†ï¼Œç”±<strong>ä¿¡æ¯å¢ç›Š</strong>æ¢æˆäº†<strong>ä¿¡æ¯å¢ç›Šç‡</strong>ã€‚</p><p><strong>ä¿¡æ¯å¢ç›Šç‡</strong></p><p>å®šä¹‰å¼ï¼š <span class="math display">\[g_r(D, A) = \frac{g(D, A)}{H(A)}\]</span></p><p>å…¶ä¸­ <span class="math inline">\(H(A)\)</span> ä¸ºé€‰æ‹©ç‰¹å¾ <span class="math inline">\(A\)</span> çš„ç†µï¼Œ<span class="math inline">\(H(A) = -\sum_i p(A_i) \log p(A_i) = -\sum \frac{|D_i|}{|D|} \log \frac{|D_i|}{|D|}\)</span></p><h2><span id="cart">CART</span></h2><p><strong>Classification And Regression Tree</strong></p><p>CART å†æ¬¡æ›´æ¢äº†é€‰æ‹©ç‰¹å¾æ ‡å‡†ï¼Œå®ƒé‡‡ç”¨<strong>Giniç³»æ•°</strong>ä½œä¸ºè¯„åˆ¤æ ‡å‡†ã€‚</p><p><strong>Gini ç³»æ•°</strong></p><p>å®šä¹‰å¼ï¼š</p><p><span class="math display">\[Gini(p) = \sum_{k=1}^Kp_k(1-p_k) = 1 - \sum_{k=1}^Kp_k^2 ï¼1 - \sum_{k=1}^K(\frac{|C_k|}{|D|})^2 \]</span></p><p>Giniç³»æ•°çœ‹èµ·æ¥æ¯”è¾ƒçªå…€ï¼Œæ ¹æ®è‘—åæœºå™¨å­¦ä¹ è®²å¸ˆ<a href="http://weibo.com/u/2306141363" target="_blank" rel="noopener">é‚¹åš</a>çš„è§‚ç‚¹ï¼ŒGiniç³»æ•°å®åˆ™æ˜¯å¯¹<strong>ä¿¡æ¯å¢ç›Š</strong>çš„è¿‘ä¼¼ï¼š * å°† <span class="math inline">\(f(x) = -\ln x\)</span> åœ¨ <span class="math inline">\(x = 1\)</span> å¤„<strong>ä¸€é˜¶å±•å¼€</strong>ï¼Œå¿½ç•¥é«˜é˜¶æ— ç©·å°ï¼Œå¾—åˆ° <span class="math inline">\(f(x) \approx 1 - x\)</span> * $H(x) = -<em>{k=1}^Kp_k p_k </em>{k=1}^Kp_k(1 - p_k) = Gini(p) $ * Giniç³»æ•°ä¸ç†µçš„å¯¹æ¯”å›¾å¦‚ä¸‹ï¼š</p><p><img src="/images/1472819902545.png"></p><p><strong>ä¸‰ç§å†³ç­–æ ‘çš„å­¦ä¹ ç®—æ³•</strong></p><ul><li>ID3 : ä½¿ç”¨ä¿¡æ¯å¢ç›Š/äº’ä¿¡æ¯ <span class="math inline">\(g(D,A)\)</span> è¿›è¡Œç‰¹å¾é€‰æ‹©<ul><li>å–å€¼å¤šçš„å±æ€§,æ›´å®¹æ˜“ä½¿æ•°æ®æ›´çº¯ ,å…¶ä¿¡æ¯å¢ç›Šæ›´å¤§ã€‚</li><li>è®­ç»ƒå¾—åˆ°çš„æ˜¯ä¸€æ£µåºå¤§ä¸”æ·±åº¦æµ…çš„æ ‘ : ä¸åˆç†ã€‚</li></ul></li><li>C4.5 : ä¿¡æ¯å¢ç›Šç‡ <span class="math inline">\(g_r(D,A) = g(D,A) / H(A)\)</span></li><li>CART : åŸºå°¼æŒ‡æ•°</li><li>ä¸€ä¸ªå±æ€§çš„<strong>ä¿¡æ¯å¢ç›Š(ç‡)/GiniæŒ‡æ•°è¶Šå¤§</strong>, è¡¨æ˜å±æ€§å¯¹æ ·æœ¬çš„ç†µå‡å°‘çš„èƒ½åŠ›æ›´å¼º, è¿™ä¸ªå±æ€§ä½¿å¾—<strong>æ•°æ®ç”±ä¸ç¡®å®šæ€§å˜æˆç¡®å®šæ€§çš„èƒ½åŠ›è¶Šå¼º</strong>ã€‚</li></ul><p><strong>å†³ç­–æ ‘çš„è¯„ä»·</strong></p><ul><li>å‡å®šæ ·æœ¬çš„æ€»ç±»åˆ«ä¸º <span class="math inline">\(K\)</span> ä¸ª</li><li>å¯¹äºå†³ç­–æ ‘çš„æŸå¶ç»“ç‚¹,å‡å®šè¯¥å¶ç»“ç‚¹å«æœ‰æ ·æœ¬æ•°ç›®ä¸º <span class="math inline">\(n\)</span> , å…¶ä¸­ ç¬¬ <span class="math inline">\(k\)</span> ç±»çš„æ ·æœ¬ç‚¹æ•°ç›®ä¸º <span class="math inline">\(n_k\)</span>, <span class="math inline">\(k=1,2,...,K\)</span>ã€‚<ul><li>è‹¥æŸç±»æ ·æœ¬ <span class="math inline">\(n_j=n\)</span> è€Œ <span class="math inline">\(n_1,...,n_{j-1},n_{j+1},...,n_K=0\)</span>, ç§°è¯¥ç»“ç‚¹ä¸º<strong>çº¯ç»“ç‚¹</strong>;</li><li>è‹¥å„ç±»æ ·æœ¬æ•°ç›® <span class="math inline">\(n_1=n_2=...=n_k=n/K\)</span>, ç§°è¯¥æ ·æœ¬ä¸º<strong>å‡ç»“ç‚¹</strong>ã€‚</li></ul></li><li>çº¯ç»“ç‚¹çš„ç†µ <span class="math inline">\(H_p=0\)</span>, <strong>æœ€å°</strong></li><li>å‡ç»“ç‚¹çš„ç†µ <span class="math inline">\(H_u=\ln K\)</span>, <strong>æœ€å¤§</strong></li><li>å¯¹æ‰€æœ‰å¶ç»“ç‚¹çš„<strong>ç†µæ±‚å’Œ</strong>, è¯¥å€¼<strong>è¶Šå°</strong>è¯´æ˜å¯¹æ ·æœ¬çš„åˆ†ç±»<strong>è¶Šç²¾ç¡®</strong><ul><li>å„å¶ç»“ç‚¹åŒ…å«çš„æ ·æœ¬æ•°ç›®ä¸åŒ,å¯ä½¿ç”¨æ ·æœ¬æ•°åŠ æƒæ±‚ç†µå’Œ</li></ul></li><li><strong>è¯„ä»·å‡½æ•°</strong> :<ul><li><span class="math inline">\(C(T) = \sum_{t \in leaf} N_t \cdot H(t)\)</span></li><li>ç”±äºè¯¥è¯„ä»·å‡½æ•°è¶Šå°è¶Šå¥½, æ‰€ä»¥å¯ä»¥ç§°ä¹‹ä¸ºâ€œæŸå¤±å‡½æ•°â€ã€‚</li></ul></li></ul><p><strong>å‰ªæ</strong></p><p>å†³ç­–æ ‘å¯¹è®­ç»ƒå±äºæœ‰å¾ˆå¥½çš„åˆ†ç±»èƒ½åŠ›, ä½†å¯¹æœªçŸ¥çš„æµ‹è¯•æ•°æ®æœªå¿…æœ‰å¥½çš„åˆ†ç±»èƒ½åŠ›, æ³›åŒ–èƒ½åŠ›å¼±, å³å¯èƒ½å‘ç”Ÿ<strong>è¿‡æ‹Ÿåˆ</strong>ç°è±¡ã€‚</p><p>é€‚å½“çš„å‰ªæå¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆç°è±¡ï¼Œ<strong>ä¸‰ç§å†³ç­–æ ‘çš„å‰ªæè¿‡ç¨‹ç®—æ³•ç›¸åŒ</strong>, åŒºåˆ«ä»…æ˜¯å¯¹äºå½“å‰æ ‘çš„è¯„ä»·æ ‡å‡†ä¸åŒã€‚</p><p><strong>å‰ªææ€»ä½“æ€è·¯</strong></p><ul><li>ç”±å®Œå…¨æ ‘ <span class="math inline">\(T_0\)</span> å¼€å§‹,å‰ªæéƒ¨åˆ†ç»“ç‚¹å¾—åˆ° <span class="math inline">\(T_1\)</span>, å†æ¬¡å‰ªæéƒ¨åˆ†ç»“ç‚¹å¾—åˆ°<span class="math inline">\(T_2\)</span>...ç›´åˆ°ä»…å‰©æ ‘æ ¹çš„æ ‘ <span class="math inline">\(T_k\)</span>;</li><li>åœ¨éªŒè¯æ•°æ®é›†ä¸Šå¯¹è¿™ <span class="math inline">\(k\)</span> ä¸ªæ ‘åˆ†åˆ«è¯„ä»·, é€‰æ‹©æŸå¤±å‡½æ•°æœ€å°çš„æ ‘ <span class="math inline">\(T_Î±\)</span>ã€‚</li></ul><h2><span id="éšæœºæ£®æ—">éšæœºæ£®æ—</span></h2><p><strong>Bagging</strong></p><p>åœ¨è°ˆéšæœºæ£®æ—ä¹‹å‰å…ˆæ¥çœ‹çœ‹ Bagging çš„ç­–ç•¥ * bootstrap aggregation * ä»æ ·æœ¬é›†ä¸­é‡é‡‡æ ·(æœ‰é‡å¤çš„)é€‰å‡º <span class="math inline">\(n\)</span> ä¸ªæ ·æœ¬ * åœ¨æ‰€æœ‰å±æ€§ä¸Š, å¯¹è¿™ <span class="math inline">\(n\)</span> ä¸ªæ ·æœ¬å»ºç«‹åˆ†ç±»å™¨ (ID3ã€C4.5ã€CARTã€SVMã€Logisticå›å½’ç­‰) * é‡å¤ä»¥ä¸Šä¸¤æ­¥ <span class="math inline">\(m\)</span> æ¬¡, å³è·å¾—äº† <span class="math inline">\(m\)</span> ä¸ªåˆ†ç±»å™¨ * å°†æ•°æ®æ”¾åœ¨è¿™ <span class="math inline">\(m\)</span> ä¸ªåˆ†ç±»å™¨ä¸Š,æœ€åæ ¹æ®è¿™ <span class="math inline">\(m\)</span> ä¸ªåˆ†ç±»å™¨çš„æŠ•ç¥¨ç»“æœ, å†³å®šæ•°æ®å±äºå“ªä¸€ç±»</p><blockquote><p>Bootstrapingçš„åç§°æ¥è‡ªæˆè¯­â€œpull up by your own bootstrapsâ€, æ„æ€æ˜¯ä¾é ä½ è‡ªå·±çš„èµ„æº, ç§°ä¸ºè‡ªåŠ©æ³•, å®ƒæ˜¯ä¸€ç§<strong>æœ‰æ”¾å›çš„æŠ½æ ·æ–¹æ³•</strong>ã€‚</p></blockquote><p><img src="/images/1472826789356.png"></p><p><strong>éšæœºæ£®æ—</strong></p><p>éšæœºæ£®æ—å°±æ˜¯åœ¨Baggingçš„åŸºç¡€ä¸Šåšäº†äº›ä¿®æ”¹ï¼š * ä»æ ·æœ¬ä¸­ç”¨ Bootstrap é‡‡å…»å‡º <span class="math inline">\(n\)</span> ä¸ªæ ·æœ¬ * ä»æ‰€æœ‰å±æ€§ä¸­éšæœºé€‰æ‹© <span class="math inline">\(k\)</span> ä¸ªå±æ€§ï¼Œå»ºç«‹ CART æ ‘ * é‡å¤ä»¥ä¸Šæ­¥éª¤ <span class="math inline">\(m\)</span> æ¬¡ï¼Œå³å»ºç«‹äº† <span class="math inline">\(m\)</span> æ£µ CART æ ‘ * è¿™ <span class="math inline">\(m\)</span> ä¸ª CART å½¢æˆéšæœºæ£®æ—,é€šè¿‡æŠ•ç¥¨è¡¨å†³ç»“æœï¼Œå†³å®šæ•°æ®å±äºå“ªä¸€ç±»</p><p>å½“ç„¶å¯ä»¥ä½¿ç”¨å†³ç­–æ ‘ä½œä¸ºåŸºæœ¬åˆ†ç±»å™¨ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨SVMã€Logisticå›å½’ç­‰å…¶ä»–åˆ†ç±»å™¨, ä¹ æƒ¯ä¸Š, è¿™äº›åˆ†ç±»å™¨ç»„æˆçš„â€œæ€»åˆ†ç±»å™¨â€, ä»ç„¶å«åš<strong>éšæœºæ£®æ—</strong>ã€‚ä¸è¿‡éšæœºæ£®æ—çš„æ€æƒ³æ˜¯ä½¿ç”¨å¾ˆå¤šä¸ª<strong>å¼±åˆ†ç±»å™¨</strong>ï¼ˆå—å¼‚å¸¸ç‚¹å½±å“è¾ƒå°ï¼‰æŠ•ç¥¨å¾—å‡ºä¸€ä¸ª<strong>å¼ºåˆ†ç±»å™¨</strong>ï¼Œæ‰€ä»¥æŠŠå°æ ‘ä»¬æ¢æˆSVMã€LRç­‰å¼ºåˆ†ç±»å™¨æ•ˆæœä¸ä¸€å®šä¼šæ›´å¥½ï¼Œåè€Œå¯èƒ½ä¼šæ›´å®¹æ˜“å—å¼‚å¸¸ç‚¹å½±å“ï¼ˆç†è®ºä¸Šï¼‰ã€‚</p><p><strong>æŠ•ç¥¨æœºåˆ¶</strong></p><p>æŠ•ç¥¨æœºåˆ¶ä¸€èˆ¬æœ‰ä»¥ä¸‹å‡ ç§ï¼Œå°‘æ•°æœä»å¤šæ•°ç”¨çš„æ¯”è¾ƒå¤šäº†ï¼š * ç®€å•æŠ•ç¥¨æœºåˆ¶ * ä¸€ç¥¨å¦å†³ * å°‘æ•°æœä»å¤šæ•° * æœ‰æ•ˆå¤šæ•°ï¼ˆåŠ æƒï¼‰ * é˜ˆå€¼è¡¨å†³ * è´å¶æ–¯æŠ•ç¥¨æœºåˆ¶ * Laplaceå¹³æ»‘</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Decision Tree </tag>
            
            <tag> ID3 </tag>
            
            <tag> C4.5 CART </tag>
            
            <tag> éšæœºæ£®æ— </tag>
            
            <tag> Bagging </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>çº¿æ€§å›å½’ä¸­çš„ä¸€äº›å…¬å¼æ¨å¯¼</title>
      <link href="/2016/08/30/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"/>
      <url>/2016/08/30/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<h2><span id="ä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ¨å¯¼æŸå¤±å‡½æ•°">ä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡æ¨å¯¼æŸå¤±å‡½æ•°</span></h2><p><strong>å›å½’æ–¹ç¨‹</strong></p><p><span class="math display">\[h_\theta(x) = \sum^n_{i=0}\theta_ix_i = \theta^Tx\]</span></p><p>è€ƒè™‘ä»»æ„ä¸€æ ·æœ¬ <span class="math inline">\(y^{(i)}\)</span> ï¼Œåˆ™æœ‰ï¼š <span class="math display">\[y^{(i)} = \theta^Tx^{(i)} + \epsilon^{(i)}\]</span> å…¶ä¸­ <span class="math inline">\(\epsilon^{(i)}\)</span> æ˜¯è¯¯å·®ã€‚</p><a id="more"></a><p>ç”±äºæ¯ä¸ªæ ·æœ¬çš„è¯¯å·® <span class="math inline">\(\epsilon^{(i)}\)</span>ï¼š * ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆIDDï¼‰ * å…·æœ‰æœ‰é™çš„æ•°å­¦æœŸæœ›å’Œæ–¹å·®</p><p>æ‰€ä»¥ç”±<a href="https://www.wikiwand.com/zh/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">ä¸­å¿ƒæé™å®šç†</a>å¾—ï¼š<span class="math inline">\(\epsilon^{(i)}\)</span> æœä»å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸ºæŸä¸€å®šå€¼ <span class="math inline">\(\sigma^2\)</span> çš„æ­£æ€åˆ†å¸ƒã€‚</p><blockquote><p><strong>ä¸­å¿ƒæé™å®šç†</strong>æ˜¯æ¦‚ç‡è®ºä¸­çš„ä¸€ç»„å®šç†ã€‚ä¸­å¤®æé™å®šç†è¯´æ˜ï¼Œ<strong>å¤§é‡ç›¸äº’ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œå…¶å‡å€¼çš„åˆ†å¸ƒä»¥æ­£æ€åˆ†å¸ƒä¸ºæé™</strong>ã€‚è¿™ç»„å®šç†æ˜¯æ•°ç†ç»Ÿè®¡å­¦å’Œè¯¯å·®åˆ†æçš„ç†è®ºåŸºç¡€ï¼ŒæŒ‡å‡ºäº†å¤§é‡éšæœºå˜é‡ä¹‹å’Œè¿‘ä¼¼æœä»æ­£æ€åˆ†å¸ƒçš„æ¡ä»¶ã€‚ â€”â€”from WikiPedia</p></blockquote><p>åˆ™ <span class="math inline">\(\epsilon^{(i)}\)</span> çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸ºï¼š <span class="math display">\[P(\epsilon^{(i)}) = \frac{1}{\sqrt{2\pi\sigma}}e^{\frac{-(\epsilon^{(i)})^2}{2\sigma^2}} \]</span></p><p>æŠŠ $ ^{(i)} = y^{(i)} - <sup>Tx</sup>{(i)}$ ä»£å…¥ä¸Šå¼å¾—ï¼š</p><p><span class="math display">\[ P(y^{(i)}|x^{(i)};\theta) = \frac{1}{\sqrt{2\pi\sigma}}\exp(\frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}) \]</span></p><p><span class="math inline">\(\because\)</span> æ‰€æœ‰æ ·æœ¬å‘ç”Ÿçš„æ¦‚ç‡ç‹¬ç«‹åŒåˆ†å¸ƒ <span class="math inline">\(\therefore\)</span> <a href="https://www.wikiwand.com/zh/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">ä¼¼ç„¶å‡½æ•°</a>ä¸ºæ‰€æœ‰æ ·æœ¬å‘ç”Ÿæ¦‚ç‡çš„ä¹˜ç§¯ï¼Œå³ï¼š</p><p><span class="math display">\[\begin{array}{lcl}L(\theta) = \prod^{m}_{i=1} P(y^{(i)}|x^{(i)};\theta) \\ = \prod^{m}_{i=1} \frac{1}{\sqrt{2\pi\sigma}}\exp(\frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2})  \end{array} \]</span></p><blockquote><p>åœ¨æ•°ç†ç»Ÿè®¡å­¦ä¸­ï¼Œ<strong>ä¼¼ç„¶å‡½æ•°</strong>æ˜¯ä¸€ç§å…³äºç»Ÿè®¡æ¨¡å‹ä¸­çš„å‚æ•°çš„å‡½æ•°ï¼Œè¡¨ç¤ºæ¨¡å‹å‚æ•°ä¸­çš„ä¼¼ç„¶æ€§ã€‚ä¼¼ç„¶å‡½æ•°åœ¨ç»Ÿè®¡æ¨æ–­ä¸­æœ‰é‡å¤§ä½œç”¨ï¼Œå¦‚åœ¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡å’Œè´¹é›ªä¿¡æ¯ä¹‹ä¸­çš„åº”ç”¨ç­‰ç­‰ã€‚â€œä¼¼ç„¶æ€§â€ä¸â€œæˆ–ç„¶æ€§â€æˆ–â€œæ¦‚ç‡â€æ„æ€ç›¸è¿‘ï¼Œéƒ½æ˜¯æŒ‡æŸç§äº‹ä»¶å‘ç”Ÿçš„å¯èƒ½æ€§ï¼Œä½†æ˜¯åœ¨ç»Ÿè®¡å­¦ä¸­ï¼Œâ€œä¼¼ç„¶æ€§â€å’Œâ€œæˆ–ç„¶æ€§â€æˆ–â€œæ¦‚ç‡â€åˆæœ‰æ˜ç¡®çš„åŒºåˆ†ã€‚æ¦‚ç‡ç”¨äºåœ¨å·²çŸ¥ä¸€äº›å‚æ•°çš„æƒ…å†µä¸‹ï¼Œé¢„æµ‹æ¥ä¸‹æ¥çš„è§‚æµ‹æ‰€å¾—åˆ°çš„ç»“æœï¼Œè€Œä¼¼ç„¶æ€§åˆ™æ˜¯ç”¨äºåœ¨å·²çŸ¥æŸäº›è§‚æµ‹æ‰€å¾—åˆ°çš„ç»“æœæ—¶ï¼Œå¯¹æœ‰å…³äº‹ç‰©çš„æ€§è´¨çš„å‚æ•°è¿›è¡Œä¼°è®¡ã€‚ â€”â€”from WikiPedia</p></blockquote><p>å¯¹ <span class="math inline">\(L(\theta)\)</span> å–å¯¹æ•°å¾—å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š</p><p><span class="math display">\[\begin{array}{lcl}l(\theta) = \log L(\theta) \\ = \log \prod^{m}_{i=1} \frac{1}{\sqrt{2\pi\sigma}}\exp(\frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2})  \\ = m\log \frac{1}{\sqrt{2\pi\sigma}} + \sum^m_{i=1} \frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2} \\ = m\log \frac{1}{\sqrt{2\pi\sigma}} - \frac{1}{\sigma^2} \cdot \frac{1}{2} \sum^m_{i=1} (y^{(i)} - \theta^Tx^{(i)})^2\end{array}\]</span></p><p>è‹¥è¦ä½¿å¯¹æ•°ä¼¼ç„¶å‡½æ•°å–å¾—æœ€å¤§å€¼ï¼ŒæŠŠå¸¸æ•°é¡¹å’Œå®šå€¼å»æ‰ï¼Œä»¤ <span class="math display">\[J(\theta) = \frac{1}{2}\sum^{m}_{i=1}(y^{(i)} - \theta^Tx^{(i)})^2\]</span> åˆ™ <span class="math inline">\(J(\theta)\)</span> åº”å–å¾—æœ€å°å€¼ï¼Œ å³ä¸ºæŸå¤±å‡½æ•°ï¼ˆç›®æ ‡å‡½æ•°ï¼‰ã€‚</p><hr><h2><span id="æ±‚è§£æœ€å°äºŒä¹˜æ„ä¹‰ä¸‹å‚æ•°æœ€ä¼˜è§£">æ±‚è§£æœ€å°äºŒä¹˜æ„ä¹‰ä¸‹å‚æ•°æœ€ä¼˜è§£</span></h2><p><strong>ç›®æ ‡å‡½æ•°</strong></p><p><span class="math display">\[ J(\theta) = \frac{1}{2}\sum^{m}_{i=1}(y^{(i)} - \theta^Tx^{(i)})^2 = \frac{1}{2}(X\theta - y)^T(X\theta - y)\]</span></p><p><strong>æ±‚æ¢¯åº¦</strong></p><blockquote><p>åœ¨å‘é‡å¾®ç§¯åˆ†ä¸­ï¼Œæ ‡é‡åœºçš„æ¢¯åº¦æ˜¯ä¸€ä¸ªå‘é‡åœºã€‚æ ‡é‡åœºä¸­æŸä¸€ç‚¹çš„æ¢¯åº¦æŒ‡å‘åœ¨é€™é»æ ‡é‡åœºå¢é•¿æœ€å¿«çš„æ–¹å‘ã€‚ â€”â€” from WikiPedia</p></blockquote><p><span class="math display">\[\begin{array}{lcr}\nabla_\theta J(\theta) = \frac{\partial}{\partial \theta}(\frac{1}{2}(X\theta - y)^T(X\theta - y)) \\= \frac{\partial}{\partial \theta}(\frac{1}{2}(\theta^TX^T - y^T)(X\theta - y))\end{array} \\= \frac{\partial}{\partial \theta} (\frac{1}{2}(\theta^TX^TX\theta - \theta^TX^Ty - y^TX\theta + y^Ty) ) \\= \frac{1}{2}(2X^TX\theta - X^Ty - (y^TX)^T) \\= X^TX\theta - X^Ty\]</span></p><p><strong>æ ‡é‡æ±‚æ¢¯åº¦</strong> <img src="/images/1472541353509.png"></p><p><strong>æ±‚é©»ç‚¹</strong></p><p>ä»¤ <span class="math inline">\(\nabla_\theta J(\theta) = 0\)</span>ï¼Œå³ <span class="math inline">\(X^TX\theta - X^Ty = 0\)</span>ï¼Œè§£å¾—ï¼š <span class="math display">\[\theta = (X^TX)^{-1}X^Ty\]</span></p><p>è‹¥ <span class="math inline">\(X^TX\)</span> <strong>ä¸å¯é€†</strong>æˆ–é˜²æ­¢<strong>è¿‡æ‹Ÿåˆ</strong>ï¼Œå¢åŠ  <span class="math inline">\(\lambda\)</span> æ‰°åŠ¨ï¼š <span class="math display">\[\theta = (X^TX + \lambda I)^{-1}X^Ty\]</span></p><p>ä¸Šä¸¤å¼å³ä¸ºæœ€å°äºŒä¹˜æ„ä¹‰ä¸‹çš„å‚æ•°æœ€ä¼˜è§£ã€‚</p><h2><span id="logistic-å›å½’çš„æŸå¤±å‡½æ•°åŠå‚æ•°ä¼°è®¡">Logistic å›å½’çš„æŸå¤±å‡½æ•°åŠå‚æ•°ä¼°è®¡</span></h2><p><strong>Sigmoidå‡½æ•°</strong></p><ul><li>$g(z) =  $</li></ul><p><strong>Sigmoidå‡½æ•°çš„å¯¼æ•°</strong></p><p><span class="math display">\[\begin{array}{lcr}g&#39;(z) = (\frac{1}{1 + e^{-z}})&#39; \\= \frac{e^{-z}}{(1 + e^{-z})^2} \\= \frac{1}{1 + e^{-z}} - \frac{1}{(1 + e^{-z})^2} \\= g(z)(1 - g(z))\end{array}\]</span></p><p><strong>å›å½’æ–¹ç¨‹</strong></p><ul><li><span class="math inline">\(h_\theta(x) = g(\theta^TX) = \frac{1}{1 + e^{-\theta^TX}}\)</span></li></ul><p><strong>æŸå¤±å‡½æ•°</strong></p><p>è®¾ $y {1, 0} $ å¹¶ä¸”æœä»äºŒå‘åˆ†å¸ƒï¼Œå³ï¼š</p><p><span class="math display">\[P(y = 1 | x; \theta) = h_\theta(x)\]</span> <span class="math display">\[P(y = 0 | x; \theta) = 1- h_\theta(x)\]</span></p><p>åˆ™ä»»æ„æ ·æœ¬ <span class="math inline">\(y^{(i)}\)</span> çš„æ¦‚ç‡å¯†åº¦ä¸º</p><p><span class="math display">\[P(y^{(i)} | x^{(i)}; \theta) = h_\theta(x^{(i)})^{y^{(i)}}(1 - h_\theta(x^{(i)}))^{1 - y^{(i)}} \]</span></p><p><span class="math inline">\(\because\)</span> æ‰€æœ‰æ ·æœ¬å‘ç”Ÿçš„æ¦‚ç‡ç‹¬ç«‹åŒåˆ†å¸ƒ <span class="math inline">\(\therefore\)</span> <a href="https://www.wikiwand.com/zh/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">ä¼¼ç„¶å‡½æ•°</a>ä¸ºæ‰€æœ‰æ ·æœ¬å‘ç”Ÿæ¦‚ç‡çš„ä¹˜ç§¯ï¼Œå³ï¼š</p><p><span class="math display">\[\begin{array}{lcr}L(\theta) =  \prod^{m}_{i=1} P(y^{(i)}|x^{(i)};\theta) \\=  \prod^{m}_{i=1} h_\theta(x^{(i)})^{y^{(i)}}(1 - h_\theta(x^{(i)}))^{1 - y^{(i)}}\end{array}\]</span></p><p>å¯¹ä¸¤è¾¹åŒæ—¶å–å¯¹æ•°å¾—å¯¹æ•°ä¼¼ç„¶å‡½æ•°ä¸ºï¼š</p><p><span class="math display">\[\begin{array}{lcr}l(\theta) = \log L(\theta) \\= \log \prod^{m}_{i=1} h_\theta(x^{(i)})^{y^{(i)}}(1 - h_\theta(x^{(i)}))^{1 - y^{(i)}} \\= \sum^m_{i = 1}   y^{(i)} \log h_\theta(x^{(i)}) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))  \\= \sum^m_{i = 1} y^{(i)} \log(\frac{1}{1 + e^{-\theta x^{(i)}}}) + (1 - y^{(i)})\log(\frac{e^{-\theta x^{(i)}}}{1 + e^{-\theta x^{(i)}}}) \\= \sum^m_{i = 1} y^{(i)} \log(\frac{1}{1 + e^{-\theta x^{(i)}}}) + (1 - y^{(i)})\log(\frac{1}{1 + e^{\theta x^{(i)}}}) \\\end{array}\]</span></p><p>ä»¤ $J() = -l() = ^m_{i = 1} y^{(i)} (1 + e<sup>{-x</sup>{(i)}}) + (1 - y^{(i)})(1 + e<sup>{x</sup>{(i)}}) $ï¼Œå³ä¸ºlogisticå›å½’çš„æŸå¤±å‡½æ•°ã€‚</p><p>è‹¥ä»¤ $y {1, -1} $ï¼Œè¿›è¡ŒåŒæ ·çš„æ¨å¯¼å¯å¾—å¦ä¸€ç§å½¢å¼çš„æŸå¤±å‡½æ•°:</p><p><span class="math display">\[J(\theta) = \sum^m_{i = 1} \log(1 + e^{-y^{(i)}\theta x^{(i)}}) \]</span></p><p>è¯æ˜å¦‚ä¸‹ï¼š</p><p><img src="/images/1472545621202.png"></p><p><strong>å‚æ•°ä¼°è®¡</strong></p><p>æ±‚æ¢¯åº¦ï¼Œå¯¹å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼ˆæŸå¤±å‡½æ•°ï¼‰å¯¹ <span class="math inline">\(\theta\)</span> æ±‚åå¯¼å¾— ï¼š</p><p><span class="math display">\[\begin{array}{lcr}\frac{\partial}{\partial \theta_j}l(\theta) = \frac{\partial}{\partial \theta_j}\sum^m_{i = 1}   y^{(i)} \log h_\theta(x^{(i)}) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)})) \\= \sum^m_{i = 1} y^{(i)}\frac{1}{h_\theta(x^{(i)})}\frac{\partial h_\theta(x^{(i)})}{\partial \theta_j} + (1 - y^{(i)}) \frac{1}{1 - h_\theta(x^{(i)})}\frac{-\partial h_\theta(x^{(i)})}{\partial \theta_j}  \\=  \sum^m_{i = 1} y^{(i)}(1 - h_\theta(x^{(i)}))x_j^{(i)} - (1 - y^{(i)}) h_\theta(x^{(i)})x_j^{(i)} \\= \sum^m_{i = 1} (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}\end{array}\]</span></p><p>æ‰€ä»¥å‚æ•°çš„å­¦ä¹ è§„åˆ™ä¸ºï¼š</p><p><span class="math display">\[\theta_j := \theta_j + \alpha(y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)} \]</span></p><p>ä¸çº¿æ€§å›å½’çš„æ›´æ–°è§„åˆ™ç›¸åŒï¼</p><p><strong>å¯¹æ•°çº¿æ€§æ¨¡å‹</strong></p><p><img src="/images/1472546918441.png"></p><h2><span id="softmax-å›å½’">Softmax å›å½’</span></h2><p><img src="/images/1472547052270.png"></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Linear Regression </tag>
            
            <tag> Logistic Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>é˜¿é‡ŒéŸ³ä¹æµè¡Œè¶‹åŠ¿é¢„æµ‹å¤§èµ›æ€»ç»“</title>
      <link href="/2016/07/22/%E9%98%BF%E9%87%8C%E9%9F%B3%E4%B9%90%E6%B5%81%E8%A1%8C%E8%B6%8B%E5%8A%BF%E9%A2%84%E6%B5%8B%E5%A4%A7%E8%B5%9B%E6%80%BB%E7%BB%93/"/>
      <url>/2016/07/22/%E9%98%BF%E9%87%8C%E9%9F%B3%E4%B9%90%E6%B5%81%E8%A1%8C%E8%B6%8B%E5%8A%BF%E9%A2%84%E6%B5%8B%E5%A4%A7%E8%B5%9B%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2><span id="èµ›é¢˜åˆ†æ">èµ›é¢˜åˆ†æ</span></h2><p>é¢˜ç›®è¦æ±‚æ ¹æ®ç”¨æˆ·è¿‡å»å…­ä¸ªæœˆçš„äº¤äº’çºªå½•æ¥é¢„æµ‹æœªæ¥ä¸¤ä¸ªæœˆæ­Œæ‰‹çš„æ’­æ”¾é‡ã€‚</p><a id="more"></a><h2><span id="è§£é¢˜æ€è·¯">è§£é¢˜æ€è·¯</span></h2><h3><span id="æ•°æ®æ„ŸçŸ¥">æ•°æ®æ„ŸçŸ¥</span></h3><p>åˆšå¼€å§‹æ‹¿åˆ°æ•°æ®ä¹‹ååšäº†ä¸€äº›ç®€å•çš„ç»Ÿè®¡ï¼Œå‘ç°è‰ºäººæ•°é‡ä¸æ˜¯å¾ˆå¤šï¼Œåªæœ‰50ä¸ªï¼Œç”¨æˆ·æ•°é‡35ä¸‡å·¦å³ï¼Œè€Œä¸”æ¯ä¸ªç”¨æˆ·çš„å¹³å‡äº¤äº’æ•°é‡å¾ˆä½ï¼ŒåŠå¹´å†…åªæœ‰16æ¬¡ï¼Œä½äºå¹³å‡å€¼çš„ç”¨æˆ·å æ¯”70+%ã€‚æ€»ä½“æ¥çœ‹æ´»è·ƒç”¨æˆ·ä¸å¤šï¼ŒæŠŠæ­Œæ‰‹æ’­æ”¾é‡æ›²çº¿ç”»å‡ºæ¥ä¹‹åå‘ç°å¤§éƒ¨åˆ†çš„æ­Œæ‰‹çš„æ’­æ”¾é‡éƒ½åœ¨2000ä»¥ä¸‹ã€‚</p><h3><span id="é¢„æµ‹ç”¨æˆ·è¡Œä¸º">é¢„æµ‹ç”¨æˆ·è¡Œä¸º</span></h3><p>å¼€å§‹æˆ‘ä»¬æ‰“ç®—é€šè¿‡é¢„æµ‹ç”¨æˆ·çš„æ’­æ”¾è¡Œä¸ºæ¥é¢„æµ‹æ­Œæ‰‹çš„æ’­æ”¾é‡ï¼Œå› ä¸ºæ„Ÿè§‰è¿™æ ·æœ‰ç†æœ‰æ®ï¼Œæ¯”å¦‚ä¸€ä¸ªç”¨æˆ·ä»Šå¤©æ’­æ”¾å¹¶ä¸‹è½½äº†ä¸€é¦–æ­Œæ›²ï¼Œé‚£ä¹ˆä»–æ˜å¤©å¾ˆå¯èƒ½è¿˜ä¼šå¬è¿™é¦–æ­Œç­‰ç­‰ã€‚æ ¹æ®è¿™äº›é€»è¾‘æˆ‘ä»¬ä»å†å²çºªå½•é‡Œæå–å‡ºäº†ä¸€äº›ç‰¹å¾ï¼Œç„¶åç”¨è¿™äº›ç‰¹å¾é¢„æµ‹ä¸‹ä¸€å¤©çš„æ’­æ”¾é‡ï¼ŒæŠŠé¢„æµ‹å¥½çš„å†åŠ å…¥å†å²çºªå½•ç”¨äºé¢„æµ‹ä¸‹ä¸‹ä¸€å¤©ï¼Œå¦‚æ­¤åå¤ç›´åˆ°é¢„æµ‹å®Œ2ä¸ªæœˆçš„æ’­æ”¾é‡ã€‚</p><p>ä½†æ˜¯è¿™æ ·åšæœ‰å‡ ä¸ªé—®é¢˜ï¼š</p><ul><li>é¦–å…ˆï¼Œè®­ç»ƒå‘¨æœŸå¤ªé•¿ã€‚å…‰æå–ç‰¹å¾å°±è¦èŠ±ä¸€ä¸ªå°æ—¶å·¦å³çš„æ—¶é—´ï¼Œå†åŠ ä¸Šè®­ç»ƒï¼Œåˆå¹¶è®­ç»ƒé›†ç­‰ï¼Œä¸€å…±è¦ä¸¤ä¸ªå°æ—¶å·¦å³ï¼Œä½†è¿™æ‰é¢„æµ‹äº†1å¤©ï¼ŒæŠŠ60å¤©éƒ½é¢„æµ‹å®Œéœ€è¦ 60 * 2 = 120 å°æ—¶ï¼Œæ‰€ä»¥è¿™ä¹ˆåšè‚¯å®šä¸è¡Œã€‚</li><li>å…¶æ¬¡ï¼Œå•ä¸ªç”¨æˆ·çš„éšæœºæ€§å¤ªå¼ºï¼Œå¯¼è‡´è®­ç»ƒè¯¯å·®ä¹Ÿéå¸¸å¤§ï¼Œè€Œä¸”è¯¯å·®è¿˜ä¼šç§¯ç´¯ã€‚ äºæ˜¯æˆ‘ä»¬å°±æ”¾å¼ƒäº†è¿™ç§æ–¹æ³•ã€‚</li></ul><h3><span id="æ—¶é—´åºåˆ—åˆ†æ">æ—¶é—´åºåˆ—åˆ†æ</span></h3><p>æ—¶é—´åºåˆ—åˆ†æçš„æ–¹æ³•ä¹Ÿæ˜¯å‚èµ›ååœ¨äº¤æµç¾¤é‡Œå¬è¯´çš„ï¼Œæœ‰äººè¯´ç”¨ARIMAèƒ½åšåˆ°6200ï¼ˆå½“æ—¶ç¬¬ä¸€6500+ï¼‰ï¼Œæˆ‘å°±å»æŸ¥äº†æŸ¥ï¼Œå‘ç°äº†æ—¶é—´åºåˆ—åˆ†æè¿™ä¸ªç†è®ºä½“ç³»ã€‚</p><p>äºæ˜¯æˆ‘ä¹Ÿç”¨ARIMAè¯•äº†ï¼Œä½†æ˜¯é‡åˆ°ä¸€ä¸ªå¾ˆè›‹ç–¼çš„é—®é¢˜ï¼ŒARIMAé¢„æµ‹çš„å¥½åå¾ˆä¾èµ–äºä»–çš„å‚æ•°ï¼è™½ç„¶50ä¸ªæ­Œæ‰‹ä¸å¤šï¼Œä½†æ˜¯ä¸ºæ¯ä¸ªæ­Œæ‰‹å•ç‹¬è°ƒå‚è‚¯å®šä¼šç´¯æ­»ï¼Œå¤§å®¶éƒ½ç”¨ä¸€å¥—å‚æ•°æ•ˆæœåˆä¸å¥½ã€‚è¿™æ—¶æˆ‘åˆå‘ç°äº†Rçš„<code>auto.arima</code>ï¼Œç”¨è¿™ä¸ªå¯ä»¥è‡ªåŠ¨è°ƒå‚ï¼Œä½†ç”¨äº†ä¹‹åå‘ç°æ•ˆæœä¹Ÿæ²¡é‚£ä¹ˆå¥½ï¼Œè®°å¾—å¥½åƒ6000åˆ†å·¦å³å§ã€‚</p><h3><span id="å‡å€¼å¤§æ³•å¥½">å‡å€¼å¤§æ³•å¥½</span></h3><p>åœ¨ç¬¬ä¸€èµ›å­£æœŸé—´æ€»æ˜¯æœ‰äººåœ¨ç¾¤é‡Œè¯´è§„åˆ™è½»æ¾6500ï¼Œæ¨¡å‹æ‰“ä¸è¿‡è§„åˆ™ç­‰ï¼Œä½†ä¸€ç›´ä¸çŸ¥é“è§„åˆ™æ˜¯å•¥ï¼Œæ„Ÿè§‰å¾ˆç¥ç§˜å¾ˆç‰›é€¼ï¼Œåæ¥æ‰æç„¶å¤§æ‚Ÿï¼Œè¿™ä¸ªæ¯”èµ›é‡Œå®ƒä»¬è¯´çš„è§„åˆ™å°±æ˜¯å–å‡å€¼ã€‚</p><p>æˆ‘å°±ä¸€ç‚¹ä¸€ç‚¹è¯•ï¼Œå‘ç°å–æœ€ååå¤©å·¦å³çš„å‡å€¼ç¡®å®å¯ä»¥è¾¾åˆ°6500ï¼Œåˆšå‘ç°çš„æ—¶å€™æ’åè¿˜æŒºé«˜ï¼Œåæ¥å¤§å®¶éƒ½çŸ¥é“äº†æ’åå°±ä¸‹æ¥äº†ï¼Œä¸è¿‡ä¸€ç›´ç¨³å®šåœ¨å‰100åã€‚</p><p>ä»æ­¤ä»¥åæˆ‘çš„æ–¹æ³•å°±ä¸€ç›´å›´ç»•å‡å€¼å±•å¼€ï¼Œå„ç§å˜èŠ±æ ·å‡å€¼ï¼Œæ¯”å¦‚æ»‘åŠ¨çª—å£ã€å¹³æ»‘ä¸€ä¸‹å†å–å‡å€¼ã€STLåˆ†è§£ä¸€ä¸‹å†å–å‡å€¼ç­‰ã€‚</p><h3><span id="å›å½’æ¨¡å‹">å›å½’æ¨¡å‹</span></h3><p>åˆ°äº†ç¬¬äºŒèµ›å­£ï¼Œå¹³å°ä¸Šæ²¡æœ‰æä¾›æ—¶é—´åºåˆ—ç®—æ³•ï¼Œåªèƒ½ç”¨å›å½’æ¨¡å‹äº†ï¼Œå…ˆåè¯•äº†GBDTå’ŒXGBOOSTï¼Œå‰è€…é¢„æµ‹å‡ºæ¥å¥½å¤šè´Ÿå€¼ï¼Œéå¸¸ä¸é è°±ï¼Œä¸é€ æ€ä¹ˆå›äº‹ï¼Œåè€…è¿˜å¯ä»¥ï¼Œè™½ç„¶æ•ˆæœä¸å¦‚å‡å€¼ï¼Œä½†æœ€èµ·ç æ¯”è¾ƒæ¥è¿‘ã€‚</p><p>å›å½’æ¨¡å‹çš„å¥½åä¸»è¦ä¾èµ–äºç‰¹å¾çš„é€‰æ‹©ï¼Œå°±å¥½æ¯”ä½ è¦åˆ¤æ–­ä¸€ä¸ªäººæ˜¯ç”·æ˜¯å¥³ï¼Œå¦‚æœä½ çš„åˆ¤æ–­ä¾æ®æ˜¯å¤´å‘é•¿çŸ­ï¼Œå¤´å‘é•¿è®¤ä¸ºæ˜¯å¥³ç”Ÿï¼Œå¤´å‘çŸ­è®¤ä¸ºæ˜¯ç”·ç”Ÿï¼Œé‚£ä¹ˆä½ åˆ¤æ–­çš„æ­£ç¡®ç‡å¯èƒ½åœ¨95%å·¦å³ï¼›ä½†å¦‚æœä½ çš„åˆ¤æ–­ä¾æ®æ˜¯é‚£ä¸ªäººçš„æŸ“è‰²ä½“æ•°ç›®ï¼Œé‚£ä¹ˆä½ çš„æ­£ç¡®ç‡è‚¯å®šåœ¨99.999%ä»¥ä¸Šã€‚</p><p>æˆ‘åœ¨æŸæ¬¡é€‰æ‹©æ—¶åŠ ä¸Šäº†ä¸‹è½½é‡è¿™ä¸ªç‰¹å¾ï¼Œå‘ç°é¢„æµ‹78æœˆçš„æ•ˆæœè¶…è¿‡äº†å‡å€¼ï¼Œä¸è¿‡ç”±äºæ²¡æœ‰9ã€10æœˆçš„ä¸‹è½½é‡æ•°æ®ï¼Œæ‰€ä»¥ç”¨å‡å€¼æ›¿ä»£ï¼Œæˆ‘æŠŠ78æœˆçš„çœŸå®ä¸‹è½½é‡ä¹Ÿç”¨å‡å€¼æ›¿ä»£ï¼Œé‡æ–°é¢„æµ‹78æœˆçš„æ’­æ”¾é‡å‘ç°ä¹Ÿæ¯”å‡å€¼çš„æ•ˆæœå¥½ã€‚å¯æ˜¯ï¼Œå½“æˆ‘ç”¨è¯¥æ–¹æ³•é¢„æµ‹9ã€10æœˆæ—¶ï¼Œåˆ†æ•°TMDä¹Ÿå˜ä½äº†ï¼çº¿ä¸Šæ•ˆæœåˆæ²¡æœ‰å‡å€¼å¥½ï¼Œå¾ˆé†‰ã€‚åæ¥è¿˜å°è¯•äº†ä¸åŒçš„ç‰¹å¾ã€feature stackç­‰æ–¹æ³•ï¼Œæ•ˆæœéƒ½ä¸å¦‚èŠ±æ ·å‡å€¼ã€‚</p><p>æœ€åæˆ‘åªæœ‰ç¥­å‡ºç›®æµ‹å¤§æ³•ï¼Œæ‰ç¨ç¨æäº†å‡ åˆ†ï¼Œèƒ½ç•™åœ¨å‰50å®å±ä¸‡å¹¸ã€‚</p><h2><span id="èµ›åæ€»ç»“">èµ›åæ€»ç»“</span></h2><p>èµ›åçœ‹äº†å…¶ä»–äººå†™çš„åšå®¢å‘ç°ï¼Œè‡ªå·±æ•°æ®é¢„å¤„ç†åšçš„ä¸å¤Ÿï¼Œé‚£äº›çˆ†å‘ç‚¹å¾ˆå¯èƒ½æ˜¯åˆ·å•çš„ï¼Œåº”è¯¥æ¸…æ´—æ‰ï¼Œä½†å½“æ—¶æ²¡è€ƒè™‘åˆ°ï¼Œè€Œä¸”æ„Ÿè§‰æ¯”èµ›çš„æ—¶å€™æ€ç»´æ¯”è¾ƒå±€é™ï¼Œæ€»æ˜¯å›´ç»•ç€ä¸€ç‚¹è½¬æ¥è½¬å»ï¼Œå¯¼è‡´æœ€åæ•ˆæœä¸€èˆ¬ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> æ•°æ®æŒ–æ˜ </tag>
            
            <tag> å¤©æ±  </tag>
            
            <tag> å¤§æ•°æ®ç«èµ› </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å†³ç­–æ ‘ä¹‹ID3ç®—æ³•è¯¦è§£</title>
      <link href="/2016/07/16/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B9%8BID3%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/"/>
      <url>/2016/07/16/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B9%8BID3%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#å†³ç­–æ ‘ç®€ä»‹">å†³ç­–æ ‘ç®€ä»‹</a><ul><li><a href="#æ„é€ å†³ç­–æ ‘">æ„é€ å†³ç­–æ ‘</a></li></ul></li><li><a href="#id3-ç®—æ³•">ID3 ç®—æ³•</a><ul><li><a href="#æ¦‚æ½">æ¦‚æ½</a></li><li><a href="#ä¿¡æ¯å¢ç›Š">ä¿¡æ¯å¢ç›Š</a></li><li><a href="#åˆ’åˆ†æ•°æ®é›†">åˆ’åˆ†æ•°æ®é›†</a></li><li><a href="#é€’å½’æ„å»ºå†³ç­–æ ‘">é€’å½’æ„å»ºå†³ç­–æ ‘</a></li></ul></li><li><a href="#æ€»ç»“">æ€»ç»“</a></li><li><a href="#å‚è€ƒ">å‚è€ƒ</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="å†³ç­–æ ‘ç®€ä»‹">å†³ç­–æ ‘ç®€ä»‹</span></h2><p>å†³ç­–æ ‘ï¼ˆDecision treeï¼‰ç”±ä¸€ä¸ªå†³ç­–å›¾å’Œå¯èƒ½çš„ç»“æœç»„æˆï¼Œ ç”¨æ¥åˆ›å»ºåˆ°è¾¾ç›®æ ‡çš„è§„åˆ’ã€‚å†³ç­–æ ‘å»ºç«‹å¹¶ç”¨æ¥è¾…åŠ©å†³ç­–ï¼Œæ˜¯ä¸€ç§ç‰¹æ®Šçš„æ ‘ç»“æ„ã€‚å†³ç­–æ ‘æ˜¯ä¸€ä¸ªåˆ©ç”¨åƒæ ‘ä¸€æ ·çš„å›¾å½¢æˆ–å†³ç­–æ¨¡å‹çš„å†³ç­–æ”¯æŒå·¥å…·ï¼ŒåŒ…æ‹¬éšæœºäº‹ä»¶ç»“æœï¼Œèµ„æºä»£ä»·å’Œå®ç”¨æ€§ã€‚å®ƒæ˜¯ä¸€ä¸ªç®—æ³•æ˜¾ç¤ºçš„æ–¹æ³•ã€‚å†³ç­–æ ‘ç»å¸¸åœ¨è¿ç­¹å­¦ä¸­ä½¿ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å†³ç­–åˆ†æä¸­ï¼Œå®ƒå¸®åŠ©ç¡®å®šä¸€ä¸ªèƒ½æœ€å¯èƒ½è¾¾åˆ°ç›®æ ‡çš„ç­–ç•¥ã€‚å¦‚æœåœ¨å®é™…ä¸­ï¼Œå†³ç­–ä¸å¾—ä¸åœ¨æ²¡æœ‰å®Œå¤‡çŸ¥è¯†çš„æƒ…å†µä¸‹è¢«åœ¨çº¿é‡‡ç”¨ï¼Œä¸€ä¸ªå†³ç­–æ ‘åº”è¯¥å¹³è¡Œæ¦‚ç‡æ¨¡å‹ä½œä¸ºæœ€ä½³çš„é€‰æ‹©æ¨¡å‹æˆ–åœ¨çº¿é€‰æ‹©æ¨¡å‹ç®—æ³•ã€‚å†³ç­–æ ‘çš„å¦ä¸€ä¸ªä½¿ç”¨æ˜¯ä½œä¸ºè®¡ç®—æ¡ä»¶æ¦‚ç‡çš„æè¿°æ€§æ‰‹æ®µã€‚</p><p>æ©Ÿå™¨å­¸ç¿’ä¸­ï¼Œæ±ºç­–æ¨¹æ˜¯ä¸€å€‹é æ¸¬æ¨¡å‹ï¼›ä»–ä»£è¡¨çš„æ˜¯å°è±¡å±¬æ€§èˆ‡å°è±¡å€¼ä¹‹é–“çš„ä¸€ç¨®æ˜ å°„é—œä¿‚ã€‚æ¨¹ä¸­æ¯å€‹ç¯€é»è¡¨ç¤ºæŸå€‹å°è±¡ï¼Œè€Œæ¯å€‹åˆ†å‰è·¯å¾‘å‰‡ä»£è¡¨çš„æŸå€‹å¯èƒ½çš„å±¬æ€§å€¼ï¼Œè€Œæ¯å€‹è‘‰çµé»å‰‡å°æ‡‰å¾æ ¹ç¯€é»åˆ°è©²è‘‰ç¯€é»æ‰€ç¶“æ­·çš„è·¯å¾‘æ‰€è¡¨ç¤ºçš„å°è±¡çš„å€¼ã€‚æ±ºç­–æ¨¹åƒ…æœ‰å–®ä¸€è¼¸å‡ºï¼Œè‹¥æ¬²æœ‰è¤‡æ•¸è¼¸å‡ºï¼Œå¯ä»¥å»ºç«‹ç¨ç«‹çš„æ±ºç­–æ¨¹ä»¥è™•ç†ä¸åŒè¼¸å‡ºã€‚ æ•°æ®æŒ–æ˜ä¸­å†³ç­–æ ‘æ˜¯ä¸€ç§ç»å¸¸è¦ç”¨åˆ°çš„æŠ€æœ¯ï¼Œå¯ä»¥ç”¨äºåˆ†ææ•°æ®ï¼ŒåŒæ ·ä¹Ÿå¯ä»¥ç”¨æ¥ä½œé¢„æµ‹ã€‚</p><h3><span id="æ„é€ å†³ç­–æ ‘">æ„é€ å†³ç­–æ ‘</span></h3><p>åœ¨æ„é€ å†³ç­–æ ‘æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è§£å†³çš„ç¬¬ä¸€ä¸ªé—®é¢˜å°±æ˜¯ï¼Œå½“å‰æ•°æ®é›†ä¸Šå“ªä¸ªç‰¹å¾åœ¨åˆ’åˆ†æ•°æ®åˆ†ç±»æ—¶å–å†³å®šæ€§ä½œç”¨ã€‚ä¸ºäº†æ‰¾åˆ°å†³å®šæ€§ç‰¹å¾ï¼Œåˆ’åˆ†å‡ºæœ€å¥½çš„ç»“æœï¼Œæˆ‘ä»¬å¿…é¡»è¯„ä¼°æ¯ä¸ªç‰¹å¾ã€‚å®Œæˆæµ‹è¯•ä¹‹åï¼ŒåŸå§‹æ•°æ®é›†å°±è¢«åˆ’åˆ†ä¸ºå‡ ä¸ªæ•°æ®å­é›†ã€‚å¦‚æœæ•°æ®å­é›†å†…çš„æ•°æ®ä¸å±äºåŒä¸€ç±»å‹ï¼Œåˆ™éœ€è¦é‡å¤åˆ’åˆ†æ•°æ®å­é›†çš„è¿‡ç¨‹ã€‚</p><p>åˆ’åˆ†æ•°æ®å­é›†çš„ä¼ªä»£ç  <code>createBranch()</code>å¦‚ä¸‹æ‰€ç¤ºï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">æ£€æµ‹æ•°æ®é›†ä¸­çš„æ¯ä¸ªå­é¡¹æ˜¯å¦å±äºåŒä¸€åˆ†ç±»:</span><br><span class="line"><span class="keyword">if</span> æ˜¯ <span class="keyword">return</span> ç±»æ ‡ç­¾</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">å¯»æ‰¾åˆ’åˆ†æ•°æ®é›†çš„æœ€å¥½ç‰¹å¾</span><br><span class="line">åˆ’åˆ†æ•°æ®é›†</span><br><span class="line">åˆ›å»ºåˆ†æ”¯èŠ‚ç‚¹</span><br><span class="line"><span class="keyword">for</span> æ¯ä¸ªåˆ’åˆ†çš„å­é›†</span><br><span class="line">è°ƒç”¨createBranchå¹¶å¢åŠ è¿”å›ç»“æœåˆ°åˆ†æ”¯èŠ‚ç‚¹ä¸­</span><br><span class="line"><span class="keyword">return</span> åˆ†æ”¯èŠ‚ç‚¹</span><br></pre></td></tr></table></figure><p>å¯è§åˆ›å»ºå†³ç­–æ ‘å°±æ˜¯åå¤åˆ’åˆ†æ•°æ®é›†çš„è¿‡ç¨‹ï¼Œé‚£ä¹ˆå¦‚ä½•åˆ’åˆ†æ•°æ®é›†ã€ä½•æ—¶åœæ­¢åˆ’åˆ†å°±æ˜¯å†³ç­–æ ‘æ„é€ çš„å…³é”®ï¼Œæœ¬æ–‡ä¸»è¦ä»‹ç»ID3ç®—æ³•åŠå…¶å®ç°ã€‚</p><h2><span id="id3-ç®—æ³•">ID3 ç®—æ³•</span></h2><h3><span id="æ¦‚æ½">æ¦‚æ½</span></h3><p>ID3ç®—æ³•ï¼ˆIterative Dichotomiser 3ï¼‰æ˜¯ä¸€ä¸ªç”±Ross Quinlanå‘æ˜çš„ç”¨äºå†³ç­–æ ‘çš„ç®—æ³•ã€‚</p><p>è¿™ä¸ªç®—æ³•æ˜¯å»ºç«‹åœ¨å¥¥å¡å§†å‰ƒåˆ€çš„åŸºç¡€ä¸Šï¼šè¶Šæ˜¯å°å‹çš„å†³ç­–æ ‘è¶Šä¼˜äºå¤§çš„å†³ç­–æ ‘ã€‚å°½ç®¡å¦‚æ­¤ï¼Œè¯¥ç®—æ³•ä¹Ÿä¸æ˜¯æ€»æ˜¯ç”Ÿæˆæœ€å°çš„æ ‘å½¢ç»“æ„ã€‚è€Œæ˜¯ä¸€ä¸ªå¯å‘å¼ç®—æ³•ã€‚å¥¥å¡å§†å‰ƒåˆ€é˜è¿°äº†ä¸€ä¸ªä¿¡æ¯ç†µçš„æ¦‚å¿µï¼š</p><p><span class="math display">\[I_E(i)=-\sum _{j=1}^{m}f(i,j)\log _2f(i,j)\]</span></p><p>è¿™ä¸ªID3ç®—æ³•å¯ä»¥å½’çº³ä¸ºä»¥ä¸‹å‡ ç‚¹ï¼š * ä½¿ç”¨æ‰€æœ‰æ²¡æœ‰ä½¿ç”¨çš„å±æ€§å¹¶è®¡ç®—ä¸ä¹‹ç›¸å…³çš„æ ·æœ¬ç†µå€¼ * é€‰å–å…¶ä¸­ç†µå€¼æœ€å°çš„å±æ€§ * ç”ŸæˆåŒ…å«è¯¥å±æ€§çš„èŠ‚ç‚¹</p><h3><span id="ä¿¡æ¯å¢ç›Š">ä¿¡æ¯å¢ç›Š</span></h3><p>åˆ’åˆ†æ•°æ®é›†çš„æœ€å¤§åŸåˆ™æ˜¯ï¼š<strong>å°†æ— åºçš„æ•°æ®å˜å¾—æ›´åŠ æœ‰åº</strong>ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¤šç§æ–¹æ³•åˆ’åˆ†æ•°æ®é›†ï¼Œä½†æ˜¯æ¯ç§æ–¹æ³•éƒ½æœ‰å„è‡ªä¼˜ç¼ºç‚¹ã€‚ç»„ç»‡æ‚ä¹±æ— ç« çš„æ•°æ®çš„ä¸€ç§æ–¹æ³•å°±æ˜¯ä½¿ç”¨<em>ä¿¡æ¯è®º</em>åº¦é‡ä¿¡æ¯ã€‚</p><p>åœ¨åˆ’åˆ†æ•°æ®é›†ä¹‹å‰ä¹‹åä¿¡æ¯å‘ç”Ÿçš„å˜åŒ–ç§°ä¸º<strong>ä¿¡æ¯å¢ç›Š</strong>ï¼ŒçŸ¥é“å¦‚ä½•è®¡ç®—ä¿¡æ¯å¢ç›Šï¼Œæˆ‘ä»¬å°±å¯ä»¥è®¡ç®—æ¯ä¸ªç‰¹å¾å€¼åˆ’åˆ†æ•°æ®é›†è·å¾—çš„ä¿¡æ¯å¢ç›Šï¼Œè·å¾—ä¿¡æ¯å¢ç›Šæœ€é«˜çš„ç‰¹å¾å°±æ˜¯æœ€å¥½çš„é€‰æ‹©ã€‚</p><p>é›†åˆä¿¡æ¯çš„åº¦é‡æ–¹å¼è¢«ç§°ä¸ºé¦™å†œç†µæˆ–ç®€ç§°ç†µã€‚</p><p><strong>ç†µï¼ˆentropyï¼‰</strong>å®šä¹‰ä¸ºä¿¡æ¯çš„æœŸæœ›å€¼ï¼Œåœ¨æ˜æ™°è¿™ä¸ªæ¦‚å¿µä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»çŸ¥é“ä¿¡æ¯çš„å®šä¹‰ã€‚å¦‚æœå¾…åˆ†ç±»äº‹åŠ¡å¯èƒ½åˆ’åˆ†åœ¨å¤šä¸ªåˆ†ç±»ä¹‹ä¸­ï¼Œåˆ™ç¬¦å· <span class="math inline">\(x_i\)</span> çš„ä¿¡æ¯å®šä¹‰ä¸º</p><p><span class="math display">\[l(x_i) = -log_2p(x_i)\]</span> å…¶ä¸­ <span class="math inline">\(p(x_i)\)</span> æ˜¯é€‰æ‹©è¯¥åˆ†ç±»çš„æ¦‚ç‡ã€‚</p><p>æ‰€ä»¥è®¡ç®—ç†µçš„å…¬å¼ä¸ºï¼š</p><p><span class="math display">\[H = -\sum_{i=1}^np(x_i)log_2p(x_i)\]</span> å…¶ä¸­ <span class="math inline">\(n\)</span> æ˜¯åˆ†ç±»çš„æ•°ç›®ã€‚</p><p>ä¸‹é¢çš„Pythonä»£ç å°†ç¤ºä¾‹å¦‚ä½•è®¡ç®—ç»™å®šæ•°æ®é›†çš„ç†µã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    numEntries = len(dataSet)</span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        currentLabel = featVec[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">            labelCounts[currentLabel] = <span class="number">0</span></span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob = float(labelCounts[key]) / numEntries</span><br><span class="line">        shannonEnt -= prob * log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br></pre></td></tr></table></figure><p>æŠŠä¸Šè¿°ä»£ç ä¿å­˜ä¸º <code>decisiontree.py</code>ï¼Œåœ¨ä¸ºå…¶æ·»åŠ ä¸€ä¸ªåˆ›å»ºæ•°æ®é›†å‡½æ•°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataSet = [[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br></pre></td></tr></table></figure><p>åœ¨Pythonå‘½ä»¤æç¤ºç¬¦ä¸‹è¾“å…¥ä¸‹åˆ—å‘½ä»¤ï¼š</p><p><img src="/images/1468651153427.png"></p><p>ç†µè¶Šé«˜ï¼Œåˆ™æ··åˆçš„æ•°æ®ä¹Ÿè¶Šå¤šã€‚å¾—åˆ°ç†µä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥æŒ‰ç…§è·å–æœ€å¤§ä¿¡æ¯å¢ç›Šçš„æ–¹æ³•åˆ’åˆ†æ•°æ®é›†ã€‚</p><h3><span id="åˆ’åˆ†æ•°æ®é›†">åˆ’åˆ†æ•°æ®é›†</span></h3><p>æˆ‘ä»¬å°†å¯¹æ¯ä¸ªç‰¹å¾åˆ’åˆ†æ•°æ®é›†çš„ç»“æœè®¡ç®—ä¸€æ¬¡ä¿¡æ¯ç†µï¼Œç„¶ååˆ¤æ–­æŒ‰ç…§å“ªä¸ªç‰¹å¾åˆ’åˆ†æ˜¯æœ€å¥½çš„æ–¹å¼ã€‚</p><p>åœ¨ <code>decisiontree.py</code> ä¸­åŠ å…¥å¦‚ä¸‹ä»£ç ï¼š <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:</span><br><span class="line">            reducedFeatVec = featVec[:axis]</span><br><span class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])</span><br><span class="line">            retDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br></pre></td></tr></table></figure></p><p>ä¸Šè¿°ä»£ç ä½¿ç”¨äº†ä¸‰ä¸ªè¾“å…¥å‚æ•°ï¼šå¾…åˆ’åˆ†æ•°æ®é›†ã€åˆ’åˆ†æ•°æ®é›†çš„ç‰¹å¾ã€éœ€è¦è¿”å›çš„ç‰¹å¾çš„å€¼ã€‚æˆ‘ä»¬å¯ä»¥åœ¨å‰é¢çš„ç®€å•æ ·æœ¬æ•°æ®ä¸Šæµ‹è¯•å‡½æ•° <code>splitDataSet()</code> å‡½æ•°ï¼š</p><p><img src="/images/1468651789771.png"></p><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°†éå†æ•´ä¸ªæ•°æ®é›†ï¼Œå¾ªç¯è®¡ç®—ç†µï¼Œæ‰¾åˆ°æœ€å¥½çš„åˆ’åˆ†æ–¹å¼ï¼Œåœ¨ <code>decisiontree.py</code> ä¸­æ·»åŠ å¦‚ä¸‹å‡½æ•°ï¼š</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeat</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    baseEntroy = calcShannonEnt(dataSet)</span><br><span class="line">    bestInfoGain = <span class="number">0.0</span></span><br><span class="line">    bestFeature = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        uniqueVals = set(featList)</span><br><span class="line">        newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)</span><br><span class="line">            prob = len(subDataSet) / float(len(dataSet))</span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)</span><br><span class="line">        infoGain = baseEntroy - newEntropy</span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; bestInfoGain:</span><br><span class="line">            bestInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br></pre></td></tr></table></figure><p>åœ¨ä¸Šè¿°ä»£ç ä¸­è°ƒç”¨çš„æ•°æ®é›†éœ€è¦æ»¡è¶³ä¸€å®šçš„è¦æ±‚ï¼š 1. æ•°æ®å¿…é¡»æ˜¯ä¸€ç§ç”±åˆ—è¡¨å…ƒç´ ç»„æˆçš„åˆ—è¡¨ï¼Œè€Œä¸”æ‰€æœ‰å…ƒç´ éƒ½è¦å…·æœ‰ç›¸åŒçš„æ•°æ®é•¿åº¦ 2. æ•°æ®çš„æœ€åä¸€åˆ—æˆ–è€…æ¯ä¸ªå®ä¾‹çš„æœ€åä¸€ä¸ªå…ƒç´ æ˜¯å½“å‰ç±»çš„æ ‡ç­¾</p><p>ç°åœ¨æˆ‘ä»¬å¯ä»¥æµ‹è¯•ä¸Šé¢ä»£ç çš„å®é™…è¾“å‡ºç»“æœï¼š <img src="/images/1468652728528.png"></p><p>ä»£ç çš„è¿è¡Œç»“æœå‘Šè¯‰æˆ‘ä»¬ï¼Œç¬¬0ä¸ªç‰¹å¾æ˜¯æœ€å¥½çš„ç”¨äºåˆ’åˆ†æ•°æ®é›†çš„ç‰¹å¾ï¼Œåˆ’åˆ†çš„æ­£ç¡®æ€§è¯·è¯»è€…è‡ªè¡Œæ£€éªŒã€‚</p><h3><span id="é€’å½’æ„å»ºå†³ç­–æ ‘">é€’å½’æ„å»ºå†³ç­–æ ‘</span></h3><p>ç›®å‰æˆ‘ä»¬å·²ç»å­¦ä¹ äº†ä»æ•°æ®é›†æ„é€ å†³ç­–æ ‘ç®—æ³•æ‰€éœ€çš„æ‰€æœ‰å­åŠŸèƒ½æ¨¡å—ï¼Œä¸‹é¢æˆ‘ä»¬é‡‡ç”¨é€’å½’çš„åŸåˆ™æ„å»ºæ•´ä¸ªå†³ç­–æ ‘ã€‚</p><p><strong>é€’å½’ç»“æŸçš„æ¡ä»¶</strong>æ˜¯ï¼šç¨‹åºéå†å®Œæ‰€æœ‰åˆ’åˆ†æ•°æ®é›†çš„å±æ€§ï¼Œæˆ–è€…æ¯ä¸ªåˆ†æ”¯ä¸‹çš„æ‰€æœ‰å®ä¾‹éƒ½å…·æœ‰ç›¸åŒçš„åˆ†ç±»ã€‚</p><p>å¦‚æœæ•°æ®é›†å·²ç»å¤„ç†äº†æ‰€æœ‰å±æ€§ï¼Œä½†ç±»æ ‡ç­¾ä¾ç„¶ä¸æ˜¯å”¯ä¸€çš„ï¼Œæ­¤æ—¶æˆ‘ä»¬éœ€è¦å†³å®šå¦‚ä½•å®šä¹‰è¯¥å¶å­èŠ‚ç‚¹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šé‡‡ç”¨å¤šæ•°è¡¨å†³çš„æ–¹æ³•å†³å®šå¶å­èŠ‚ç‚¹çš„åˆ†ç±»ã€‚</p><p>æ‰“å¼€æ–‡æœ¬ç¼–è¾‘å™¨ï¼Œæ·»åŠ å¦‚ä¸‹ä»£ç åˆ° <code>decisiontree.py</code> ä¸­ï¼š <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys():</span><br><span class="line">            classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">        sortedClassCnt = sorted(classCount.iteritems(),</span><br><span class="line">                                key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">return</span> sortedClassCnt[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span>:</span></span><br><span class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):</span><br><span class="line">        <span class="comment"># ç±»åˆ«å®Œå…¨ç›¸åŒæ—¶ï¼Œåœæ­¢ç»§ç»­åˆ’åˆ†</span></span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># éå†å®Œæ‰€æœ‰ç‰¹å¾æ—¶è¿”å›å‡ºç°æœ€å¤šçš„</span></span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeat = chooseBestFeat(dataSet)</span><br><span class="line">    bestFeatLabel = labels[bestFeat]</span><br><span class="line">    DTree = &#123;bestFeatLabel: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat])</span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    uniqueVals = set(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels = labels[:]</span><br><span class="line">        DTree[bestFeatLabel][value] = createTree(</span><br><span class="line">            splitDataSet(dataSet, bestFeat, value), subLabels)</span><br><span class="line">    <span class="keyword">return</span> DTree</span><br></pre></td></tr></table></figure></p><p>è¿™é‡Œä½¿ç”¨pythonçš„å­—å…¸ç±»å‹å­˜å‚¨æ ‘çš„ä¿¡æ¯ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥å®šä¹‰ç‰¹æ®Šç±»å‹çš„æ•°æ®ç»“æ„ï¼Œä½†åœ¨è¿™é‡Œå®Œå…¨æ²¡æœ‰å¿…è¦ã€‚</p><p>æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹ä¸Šè¿°ä»£ç çš„å®é™…è¾“å‡ºç»“æœï¼š</p><p><img src="/images/1468654341025.png"></p><p>å˜é‡ <code>tree</code> åŒ…å«äº†å¾ˆå¤šä»£è¡¨æ ‘ç»“æ„çš„åµŒå¥—å­—å…¸ã€‚å¦‚æœå€¼æ˜¯ç±»æ ‡ç­¾ï¼Œåˆ™è¯¥èŠ‚ç‚¹æ˜¯å¶å­èŠ‚ç‚¹; å¦‚æœå€¼æ˜¯å¦ä¸€ä¸ªå­—å…¸ï¼Œåˆ™è¯¥å­èŠ‚ç‚¹æ˜¯ä¸€ä¸ªåˆ¤æ–­èŠ‚ç‚¹ï¼Œè¿™ç§æ ¼å¼ç»“æ„ä¸æ–­é‡å¤å°±å½¢æˆäº†ä¸€æ£µæ ‘ã€‚æœ¬ä¾‹ä¸­è¿™æ£µæ ‘åŒ…å«äº†3ä¸ªå¶å­èŠ‚ç‚¹ä»¥åŠä¸¤ä¸ªåˆ¤æ–­èŠ‚ç‚¹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p><figure><img src="./1468655345150.png" alt="Alt text|center"><figcaption>Alt text|center</figcaption></figure><h2><span id="æ€»ç»“">æ€»ç»“</span></h2><p>å†³ç­–æ ‘åˆ†ç±»å™¨å°±åƒå¸¦æœ‰ç»ˆæ­¢å—çš„æµç¨‹å›¾ï¼Œç»ˆæ­¢å—è¡¨ç¤ºåˆ†ç±»ç»“æœã€‚å¼€å§‹å¤„ç†æ•°æ®é›†æ—¶ï¼Œæˆ‘ä»¬é¦–å…ˆè¦æµ‹é‡é›†åˆä¸­æ•°æ®çš„ä¸ä¸€è‡´æ€§ï¼Œä¹Ÿå°±æ˜¯ç†µï¼Œç„¶åå¯»æ‰¾æœ€ä¼˜æ–¹æ¡ˆåˆ’åˆ†æ•°æ®é›†ï¼Œç›´åˆ°æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ•°æ®å±äºåŒä¸€åˆ†ç±»ã€‚ID3ç®—æ³•å¯ç”¨äºåˆ’åˆ†æ ‡ç§°å‹æ•°æ®é›†ã€‚æ„å»ºå†³ç­–æ ‘æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸é‡‡ç”¨é€’å½’çš„æ–¹æ³•å°†æ•°æ®é›†è½¬åŒ–ä¸ºå†³ç­–æ ‘ã€‚</p><p>è¿˜æœ‰å…¶ä»–å†³ç­–æ ‘æ„é€ ç®—æ³•ï¼Œæœ€æµè¡Œçš„æ˜¯C4.5å’ŒCARTï¼Œè¯¦æƒ…è§ä¸‹å›åˆ†è§£ã€‚</p><h2><span id="å‚è€ƒ">å‚è€ƒ</span></h2><p>ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹[ç¾] Peter Harrington https://www.wikiwand.com/en/ID3_algorithm https://www.wikiwand.com/en/Decision_tree</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Decision Tree </tag>
            
            <tag> ID3 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Understanding RNN&amp;LSTM Networks</title>
      <link href="/2016/06/23/Understanding%20RNN%20LSTM%20Networks/"/>
      <url>/2016/06/23/Understanding%20RNN%20LSTM%20Networks/</url>
      
        <content type="html"><![CDATA[<p>è½¬è½½è‡ªï¼šhttp://colah.github.io/posts/2015-08-Understanding-LSTMs/</p><!-- toc --><ul><li><a href="#recurrent-neural-networks">Recurrent Neural Networks</a></li><li><a href="#the-problem-of-long-term-dependencies">The Problem of Long-Term Dependencies</a></li><li><a href="#lstm-networks">LSTM Networks</a><ul><li><a href="#the-core-idea-behind-lstms">The Core Idea Behind LSTMs</a></li><li><a href="#step-by-step-lstm-walk-through">Step-by-Step LSTM Walk Through</a></li><li><a href="#variants-on-long-short-term-memory">Variants on Long Short Term Memory</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="recurrent-neural-networks">Recurrent Neural Networks</span></h2><p>Humans donâ€™t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You donâ€™t throw everything away and start thinking from scratch again. <strong>Your thoughts have persistence.</strong></p><p>Traditional neural networks canâ€™t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. Itâ€™s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.</p><p>Recurrent neural networks address this issue. They are <strong>networks with loops in them</strong>, allowing information to persist.</p><p><img src="/images/1466525670636.png"></p><p>In the above diagram, a chunk of neural network, <span class="math inline">\(A\)</span> , looks at some input <span class="math inline">\(x_t\)</span> and outputs a value <span class="math inline">\(h_t\)</span>. A loop allows information to be passed from one step of the network to the next.</p><p>These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they arenâ€™t all that different than a normal neural network. <strong>A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor</strong>. Consider what happens if we unroll the loop: <img src="/images/1466526020324.png"> An unrolled recurrent neural network.</p><p>This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. Theyâ€™re the natural architecture of neural network to use for such data.</p><p>And they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioningâ€¦ The list goes on. Iâ€™ll leave discussion of the amazing feats one can achieve with RNNs to Andrej Karpathyâ€™s excellent blog post, <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a>. But they really are pretty amazing.</p><p>Essential to these successes is the use of â€œ<strong>LSTM</strong>s,â€ a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. Itâ€™s these LSTMs that this essay will explore.</p><h2><span id="the-problem-of-long-term-dependencies">The Problem of Long-Term Dependencies</span></h2><p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, theyâ€™d be extremely useful. But can they? It depends.</p><p>Sometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in â€œthe clouds are in the sky,â€ we donâ€™t need any further context â€“ itâ€™s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that itâ€™s needed is small, RNNs can learn to use the past information.</p><p><img src="/images/1466526259739.png"></p><p>But there are also cases where we need more context. Consider trying to predict the last word in the text â€œI grew up in Franceâ€¦ I speak fluent French.â€ Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. Itâ€™s entirely possible for the gap between the relevant information and the point where it is needed to become very large.</p><p>Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.</p><p><img src="/images/1466526327635.png"></p><p>In theory, RNNs are absolutely capable of handling such â€œlong-term dependencies.â€ A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs donâ€™t seem to be able to learn them. The problem was explored in depth by <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" target="_blank" rel="noopener">Hochreiter (1991) [German]</a> and <a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="noopener">Bengio, et al. (1994)</a>, who found some pretty fundamental reasons why it might be difficult.</p><p>Thankfully, LSTMs donâ€™t have this problem!</p><h2><span id="lstm-networks">LSTM Networks</span></h2><p><em>Long Short Term Memory networks</em> â€“ usually just called â€œLSTMsâ€ â€“ are a special kind of RNN, capable of learning long-term dependencies. They were introduced by <a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf" target="_blank" rel="noopener">Hochreiter &amp; Schmidhuber (1997)</a>, and were refined and popularized by many people in following work. They work tremendously well on a large variety of problems, and are now widely used.</p><p>LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!</p><p>All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.</p><p><img src="/images/1466608981114.png"> The repeating module in a standard RNN contains a single layer.</p><p>LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.</p><p><img src="/images/1466609034893.png"> The repeating module in an LSTM contains four interacting layers.</p><p>Donâ€™t worry about the details of whatâ€™s going on. Weâ€™ll walk through the LSTM diagram step by step later. For now, letâ€™s just try to get comfortable with the notation weâ€™ll be using. <img src="/images/1466609119993.png"></p><p>In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.</p><h3><span id="the-core-idea-behind-lstms">The Core Idea Behind LSTMs</span></h3><p>The key to LSTMs is the <strong>cell state</strong>, the horizontal line running through the top of the diagram.</p><p>The cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. Itâ€™s very easy for <strong>information to just flow along it unchanged</strong>.</p><p><img src="/images/1466609290827.png"></p><p>The LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called <strong>gates</strong>.</p><p>Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.</p><p><img src="/images/1466609490979.png"></p><p>The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means â€œlet nothing through,â€ while a value of one means â€œlet everything through!â€</p><p><strong>An LSTM has three of these gates, to protect and control the cell state.</strong></p><h3><span id="step-by-step-lstm-walk-through">Step-by-Step LSTM Walk Through</span></h3><p>The first step in our LSTM is to decide what information weâ€™re going to throw away from the cell state. This decision is made by a sigmoid layer called the â€œ<strong>forget gate layer</strong>.â€ It looks at <span class="math inline">\(h_{tâˆ’1}\)</span> and <span class="math inline">\(x_t\)</span>, and outputs a number between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> for each number in the cell state <span class="math inline">\(C_{tâˆ’1}\)</span>. <span class="math inline">\(1\)</span> represents â€œcompletely keep thisâ€ while a <span class="math inline">\(0\)</span> represents â€œcompletely get rid of this.â€</p><p>Letâ€™s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.</p><p><img src="/images/1466609792498.png"></p><p>The next step is to decide what new information weâ€™re going to store in the cell state. This has two parts. First, a sigmoid layer called the â€œ<strong>input gate layer</strong>â€ decides which values weâ€™ll update. Next, a tanh layer creates a vector of new candidate values, <span class="math inline">\(CÌƒ_ t\)</span>, that could be added to the state. In the next step, weâ€™ll combine these two to create an update to the state.</p><p>In the example of our language model, weâ€™d want to add the gender of the new subject to the cell state, to replace the old one weâ€™re forgetting.</p><p><img src="/images/1466610052910.png"></p><p>Itâ€™s now time to update the old cell state, <span class="math inline">\(C_{tâˆ’1}\)</span>, into the new cell state <span class="math inline">\(C_t\)</span>. The previous steps already decided what to do, we just need to actually do it.</p><p>We multiply the old state by <span class="math inline">\(f_t\)</span>, forgetting the things we decided to forget earlier. Then we add <span class="math inline">\(i_tâˆ—CÌƒ_t\)</span>. This is the new candidate values, scaled by how much we decided to update each state value.</p><p>In the case of the language model, this is where weâ€™d actually drop the information about the old subjectâ€™s gender and add the new information, as we decided in the previous steps.</p><p><img src="/images/1466610178378.png"></p><p>Finally, we need to decide what weâ€™re going to output. <strong>This output will be based on our cell state, but will be a filtered version</strong>. First, we run a sigmoid layer which decides what parts of the cell state weâ€™re going to output. Then, we put the cell state through <span class="math inline">\(tanh\)</span> (to push the values to be between <span class="math inline">\(âˆ’1\)</span> and <span class="math inline">\(1\)</span>) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.</p><p>For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case thatâ€™s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if thatâ€™s what follows next.</p><p><img src="/images/1466610206595.png"></p><h3><span id="variants-on-long-short-term-memory">Variants on Long Short Term Memory</span></h3><p>What Iâ€™ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but itâ€™s worth mentioning some of them.</p><p>One popular LSTM variant, introduced by <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener">Gers &amp; Schmidhuber (2000)</a>, is adding â€œpeephole connections.â€ This means that we let the gate layers look at the cell state.</p><p><img src="/images/1466610391326.png"></p><p>The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others.</p><p>Another variation is to use <strong>coupled forget and input gates</strong>. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when weâ€™re going to input something in its place. We only input new values to the state when we forget something older.</p><p><img src="/images/1466610470154.png"></p><p>A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by <a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho, et al. (2014)</a>. It combines the forget and input gates into a single â€œupdate gate.â€ It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.</p><p><img src="/images/1466610557001.png"></p><p>These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by <a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao, et al. (2015)</a>. Thereâ€™s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by <a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al. (2014)</a>.</p><p>Which of these variants is best? Do the differences matter? <a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al. (2015)</a> do a nice comparison of popular variants, finding that theyâ€™re all about the same. <a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz, et al. (2015)</a> tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.</p><h2><span id="conclusion">Conclusion</span></h2><p>Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks!</p><p>Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable.</p><p>LSTMs were a big step in what we can accomplish with RNNs. Itâ€™s natural to wonder: is there another big step? A common opinion among researchers is: â€œYes! There is a next step and itâ€™s attention!â€ The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, <a href="http://arxiv.org/pdf/1502.03044v2.pdf" target="_blank" rel="noopener">Xu, et al. (2015)</a> do exactly this â€“ it might be a fun starting point if you want to explore attention! Thereâ€™s been a number of really exciting results using attention, and it seems like a lot more are around the cornerâ€¦</p><p>Attention isnâ€™t the only exciting thread in RNN research. For example, Grid LSTMs by <a href="http://arxiv.org/pdf/1507.01526v1.pdf" target="_blank" rel="noopener">Kalchbrenner, et al. (2015)</a> seem extremely promising. Work using RNNs in generative models â€“ such as <a href="http://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="noopener">Gregor, et al. (2015)</a>, <a href="http://arxiv.org/pdf/1506.02216v3.pdf" target="_blank" rel="noopener">Chung, et al. (2015)</a>, or <a href="http://arxiv.org/pdf/1411.7610v3.pdf" target="_blank" rel="noopener">Bayer &amp; Osendorfer (2015)</a> â€“ also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> LSTM </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Large Scale Machine Learning</title>
      <link href="/2016/03/24/Large%20Scale%20Machine%20Learning/"/>
      <url>/2016/03/24/Large%20Scale%20Machine%20Learning/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li><li><a href="#mini-batch-gradient-descent">Mini-Batch Gradient Descent</a><ul><li><a href="#stochastic-gradient-descent-convergence">Stochastic Gradient Descent Convergence</a></li></ul></li><li><a href="#online-learning">Online Learning</a></li><li><a href="#map-reduce-and-data-parallelism">Map Reduce and Data Parallelism</a></li></ul><!-- tocstop --><a id="more"></a><p>We mainly <strong>benefit</strong> from a very large dataset when our algorithm has <strong>high variance</strong> when <span class="math inline">\(m\)</span> is small. Recall that if our algorithm has high bias, more data will not have any benefit.</p><p>Datasets can often approach such sizes as <span class="math inline">\(m = 100,000,000\)</span>. In this case, our gradient descent step will have to make a summation over all one hundred million examples. We will want to try to avoid this -- the approaches for doing so are described below.</p><h1><span id="stochastic-gradient-descent">Stochastic Gradient Descent</span></h1><p>Stochastic gradient descent is an alternative to classic (or batch) gradient descent and is more efficient and scalable to large data sets.</p><p>Stochastic gradient descent is written out in a different but similar way: <span class="math display">\[ cost(\theta,(x^{(i)}, y^{(i)})) = \dfrac{1}{2}(h_{\theta}(x^{(i)}) - y^{(i)})^2 \]</span></p><p>The only difference in the above cost function is the elimination of the <span class="math inline">\(m\)</span> constant within <span class="math inline">\(\dfrac{1}{2}\)</span>. <span class="math display">\[ J_{train}(\theta) = \dfrac{1}{m} \displaystyle \sum_{i=1}^m cost(\theta, (x^{(i)}, y^{(i)})) \]</span></p><p><span class="math inline">\(J_{train}\)</span> is now just the average of the cost applied to all of our training examples.</p><p>The algorithm is as follows 1. Randomly 'shuffle' the dataset 2. For <span class="math inline">\(i = 1\dots m\)</span> <span class="math display">\[\Theta_j := \Theta_j - \alpha (h_{\Theta}(x^{(i)}) - y^{(i)}) \cdot x^{(i)}_j\]</span> (for <span class="math inline">\(j = 0,\dots,n\)</span>)</p><p>This algorithm will only try to <strong>fit one training example at a time</strong>.</p><p>This way we can make progress in gradient descent without having to scan all <span class="math inline">\(m\)</span> training examples first.</p><p>Stochastic gradient descent will be unlikely to converge at the global minimum and will instead <strong>wander around it randomly</strong>, but usually yields a result that is close enough.</p><p>Stochastic gradient descent will usually take 1-10 passes through your data set to get near the global minimum.</p><h1><span id="mini-batch-gradient-descent">Mini-Batch Gradient Descent</span></h1><p>Mini-batch gradient descent can sometimes be even faster than stochastic gradient descent. Instead of using all <span class="math inline">\(m\)</span> examples as in batch gradient descent, and instead of using only 1 example as in stochastic gradient descent, we will use some in-between number of examples <span class="math inline">\(b\)</span>.</p><p>Typical values for <span class="math inline">\(b\)</span> range from 2-100 or so.</p><p>For example, with <span class="math inline">\(b = 10\)</span> and <span class="math inline">\(m = 1000\)</span>: Repeat: For <span class="math inline">\(i = 1,11,21,31,\dots,991\)</span>: <span class="math display">\[\theta_j := \theta_j - \alpha \dfrac{1}{10} \displaystyle \sum_{k=i}^{i+9} (h_\theta(x^{(k)}) - y^{(k)})x_j^{(k)}\]</span> (for each <span class="math inline">\(j = 0, \dots, n\)</span>)</p><p>We're simply summing over ten examples at a time.</p><p>The advantage of computing more than one example at a time is that we can use vectorized implementations over the <span class="math inline">\(b\)</span> examples.</p><h2><span id="stochastic-gradient-descent-convergence">Stochastic Gradient Descent Convergence</span></h2><p>How do we choose the learning rate <span class="math inline">\(\alpha\)</span> for stochastic gradient descent? Also, how do we debug stochastic gradient descent to make sure it is getting as close as possible to the global optimum?</p><p>One strategy is to plot the average cost of the hypothesis applied to every 1000 or so training examples. We can compute and save these costs during the gradient descent iterations.</p><p>With a smaller learning rate, it is <strong>possible</strong> that you may get a slightly better solution with stochastic gradient descent. That is because stochastic gradient descent will oscillate and jump around the global minimum, and it will make smaller random jumps with a smaller learning rate.</p><p>If you increase the number of examples you average over to plot the performance of your algorithm, the plot's line will become smoother.</p><p>With a very small number of examples for the average, the line will be too noisy and it will be difficult to find the trend.</p><p>One strategy for trying to actually converge at the global minimum is to slowly decrease <span class="math inline">\(\alpha\)</span> over time. For example <span class="math display">\[\alpha = \dfrac{const1}{iterationNumber + const2}\]</span>.</p><p>However, this is not often done because people don't want to have to fiddle with even more parameters.</p><h1><span id="online-learning">Online Learning</span></h1><p>With a continuous stream of users to a website, we can run an endless loop that gets <span class="math inline">\((x,y)\)</span>, where we collect some user actions for the features in <span class="math inline">\(x\)</span> to predict some behavior <span class="math inline">\(y\)</span>.</p><p>You can update <span class="math inline">\(\theta\)</span> for each individual <span class="math inline">\((x,y)\)</span> pair as you collect them. This way, you can adapt to new pools of users, since you are continuously updating theta.</p><h1><span id="map-reduce-and-data-parallelism">Map Reduce and Data Parallelism</span></h1><p>We can divide up batch gradient descent and dispatch the cost function for a subset of the data to many different machines so that we can train our algorithm in parallel.</p><p>You can split your training set into <span class="math inline">\(z\)</span> subsets corresponding to the number of machines you have. On each of those machines calculate <span class="math inline">\(\displaystyle \sum_{i=p}^{q}(h_{\theta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}\)</span>, where we've split the data starting at <span class="math inline">\(p\)</span> and ending at <span class="math inline">\(q\)</span>.</p><p>MapReduce will take all these dispatched (or 'mapped') jobs and 'reduce' them by calculating: <span class="math display">\[ \Theta_j := \Theta_j - \alpha \dfrac{1}{z}(temp_j^{(1)} + temp_j^{(2)} + \cdots + temp_j^{(z)})\]</span> For all <span class="math inline">\(j = 0, \dots, n\)</span>.</p><p>This is simply taking the computed cost from all the machines, calculating their average, multiplying by the learning rate, and updating theta.</p><p>Your learning algorithm is MapReduceable if it can be expressed as <strong>computing sums of functions over the training set</strong>. Linear regression and logistic regression are easily parallelizable.</p><p>For neural networks, you can compute forward propagation and back propagation on subsets of your data on many machines. Those machines can report their derivatives back to a 'master' server that will combine them.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> MapReduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ¨èç³»ç»Ÿ ï¼ˆRecommender Systemsï¼‰</title>
      <link href="/2016/03/19/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%20%EF%BC%88Recommender%20Systems%EF%BC%89/"/>
      <url>/2016/03/19/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%20%EF%BC%88Recommender%20Systems%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#problem-formulation">Problem Formulation</a></li><li><a href="#content-based-recommendations">Content Based Recommendations</a></li><li><a href="#collaborative-filtering">Collaborative Filtering</a><ul><li><a href="#collaborative-filtering-algorithm">Collaborative Filtering Algorithm</a><ul><li><a href="#vectorization-low-rank-matrix-factorization">Vectorization: Low Rank Matrix Factorization</a></li><li><a href="#implementation-detail-mean-normalization">Implementation Detail: Mean Normalization</a></li></ul></li></ul></li></ul><!-- tocstop --><a id="more"></a><h1><span id="problem-formulation">Problem Formulation</span></h1><p>Recommendation is currently a very popular application of machine learning.</p><p>Say we are trying to recommend movies to customers. We can use the following definitions * $n_u = $ number of users * $n_m = $ number of movies * <span class="math inline">\(r(i,j) = 1\)</span> if user <span class="math inline">\(j\)</span> has rated movie <span class="math inline">\(i\)</span> * $y(i,j) = $ rating given by user <span class="math inline">\(j\)</span> to movie <span class="math inline">\(i\)</span> (defined only if <span class="math inline">\(r(i,j) = 1\)</span>)</p><h1><span id="content-based-recommendations">Content Based Recommendations</span></h1><p>We can introduce two features, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> which represents how much romance or how much action a movie may have (on a scale of <span class="math inline">\(0 - 1\)</span>).</p><p>One approach is that we could do linear regression for every single user. For each user <span class="math inline">\(j\)</span>, learn a parameter <span class="math inline">\(\theta^{(j)} \in \mathbb{R}^3\)</span>. Predict user <span class="math inline">\(j\)</span> as rating movie <span class="math inline">\(i\)</span> with <span class="math inline">\((\theta^{(j)})^Tx^{(i)}\)</span> stars.</p><ul><li>$^{(j)} = $ parameter vector for user <span class="math inline">\(j\)</span></li><li>$x^{(i)} = $ feature vector for movie <span class="math inline">\(i\)</span></li><li>For user <span class="math inline">\(j\)</span>, movie <span class="math inline">\(i\)</span>, predicted rating: <span class="math inline">\((\theta^{(j)})^T(x^{(i)})\)</span></li><li>$m^{(j)} = $ number of movies rated by user <span class="math inline">\(j\)</span></li></ul><p>To learn <span class="math inline">\(\theta^{(j)}\)</span>, we do the following <span class="math display">\[min_{\theta^{(j)}} = \dfrac{1}{2}\displaystyle \sum_{i:r(i,j)=1} ((\theta^{(j)})^T(x^{(i)}) - y^{(i,j)})^2 + \dfrac{\lambda}{2} \sum_{k=1}^n(\theta_k^{(j)})^2\]</span> This is our familiar linear regression. The base of the first summation is choosing all <span class="math inline">\(i\)</span> such that <span class="math inline">\(r(i,j) = 1\)</span>.</p><p>To get the parameters for all our users, we do the following: <span class="math display">\[min_{\theta^{(1)},\dots,\theta^{(n_u)}} = \dfrac{1}{2}\displaystyle \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} ((\theta^{(j)})^T(x^{(i)}) - y^{(i,j)})^2 + \dfrac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2\]</span> We can apply our linear regression gradient descent update using the above cost function.</p><p>The only real difference is that we eliminate the constant <span class="math inline">\(\dfrac{1}{m}\)</span>.</p><h1><span id="collaborative-filtering">Collaborative Filtering</span></h1><p><strong>ååŒè¿‡æ»¤</strong></p><p>It can be very difficult to find features such as &quot;amount of romance&quot; or &quot;amount of action&quot; in a movie. To figure this out, we can use <strong>feature finders</strong>.</p><p>We can let the users tell us how much they like the different genres, providing their parameter vector immediately for us.</p><p>To infer the features from given parameters, we use the squared error function with regularization over all the users: <span class="math display">\[min_{x^{(1)},\dots,x^{(n_m)}} \dfrac{1}{2} \displaystyle \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1} ((\theta^{(j)})^T x^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2\]</span></p><p>You can also randomly guess the values for theta to guess the features repeatedly. You will actually converge to a good set of features.</p><h2><span id="collaborative-filtering-algorithm">Collaborative Filtering Algorithm</span></h2><p>To speed things up, we can simultaneously minimize our features and our parameters:</p><p><span class="math display">\[ \large J(x,\theta) = \dfrac{1}{2} \displaystyle \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2 + \dfrac{\lambda}{2}\sum_{j=1}^{n_u} \sum_{k=1}^{n} (\theta_k^{(j)})^2\]</span></p><p>It looks very complicated, but we've only <strong>combined the cost function</strong> for <strong>theta</strong> and the cost function for <strong>x</strong>.</p><p>Because the algorithm can learn them itself, the bias units where <span class="math inline">\(x_0 = 1\)</span> have been removed, therefore <span class="math inline">\(x \in \mathbb{R}^n\)</span> and <span class="math inline">\(\theta \in \mathbb{R}^n\)</span>.</p><p>These are the steps in the algorithm:</p><ol type="1"><li>Initialize <span class="math inline">\(x^{(i)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)}\)</span> to small random values. This serves to break symmetry(å¯¹ç§°æ€§) and ensures that the algorithm learns features <span class="math inline">\(x^{(i)},...,x^{(n_m)}\)</span> that are different from each other.</li><li>Minimize <span class="math inline">\(J(x^{(i)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)})\)</span> using gradient descent (or an advanced optimization algorithm). E.g. for every <span class="math inline">\(j=1,...,n_u,i=1,...n_m\)</span>: <span class="math display">\[x_k^{(i)} := x_k^{(i)} - \alpha\left (\displaystyle \sum_{j:r(i,j)=1}{((\theta^{(j)})^T x^{(i)} - y^{(i,j)}) \theta_k^{(j)}} + \lambda x_k^{(i)} \right)\]</span> <span class="math display">\[\theta_k^{(j)} := \theta_k^{(j)} - \alpha\left (\displaystyle \sum_{i:r(i,j)=1}{((\theta^{(j)})^T x^{(i)} - y^{(i,j)}) x_k^{(i)}} + \lambda \theta_k^{(j)} \right)\]</span></li><li>For a user with parameters <span class="math inline">\(\theta\)</span> and a movie with (learned) features <span class="math inline">\(x\)</span>, predict a star rating of <span class="math inline">\(\theta^Tx\)</span>.</li></ol><h3><span id="vectorization-low-rank-matrix-factorization">Vectorization: Low Rank Matrix Factorization</span></h3><p><strong>ä½ç§©çŸ©é˜µåˆ†è§£</strong></p><p>Given matrices <span class="math inline">\(X\)</span> (each row containing features of a particular movie) and <span class="math inline">\(\Theta\)</span> (each row containing the weights for those features for a given user), then the full matrix <span class="math inline">\(Y\)</span> of all predicted ratings of all movies by all users is given simply by: <span class="math inline">\(Y = X\Theta^T\)</span>.</p><p>Predicting how similar two movies <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are can be done using the distance between their respective feature vectors <span class="math inline">\(x\)</span>. Specifically, we are looking for a small value of <span class="math inline">\(||x^{(i)} - x^{(j)}||\)</span>.</p><h3><span id="implementation-detail-mean-normalization">Implementation Detail: Mean Normalization</span></h3><p>If the ranking system for movies is used from the previous lectures, then new users (who have watched no movies), will be assigned new movies incorrectly. Specifically, they will be assigned <span class="math inline">\(\theta\)</span> with all components equal to zero due to the minimization of the regularization term. That is, we assume that the new user will rank all movies 0, which does not seem intuitively correct.</p><p>We rectify this problem by normalizing the data relative to the mean. First, we use a matrix Y to store the data from previous ratings, where the <span class="math inline">\(i\)</span>th row of Y is the ratings for the <span class="math inline">\(i\)</span>th movie and the <span class="math inline">\(j\)</span>th column corresponds to the ratings for the <span class="math inline">\(j\)</span>th user.</p><p>We can now define a vector <span class="math display">\[\mu = [\mu_1, \mu_2, \dots , \mu_{n_m}] \]</span> such that <span class="math display">\[\mu_i = \frac{\sum_{j:r(i,j)=1}{Y_{i,j}}}{\sum_{j}{r(i,j)}}\]</span></p><p>Which is effectively the mean of the previous ratings for the <span class="math inline">\(i\)</span> th movie (where only movies that <strong>have been watched by users are counted</strong>). We now can normalize the data by subtracting <span class="math inline">\(u\)</span>, the mean rating, from the actual ratings for each user (column in matrix <span class="math inline">\(Y\)</span>):</p><p>As an example, consider the following matrix <span class="math inline">\(Y\)</span> and mean ratings <span class="math inline">\(\mu\)</span>: <span class="math display">\[Y = \begin{bmatrix} 5 &amp; 5 &amp; 0 &amp; 0 \newline 4 &amp; ? &amp; ? &amp; 0 \newline 0 &amp; 0 &amp; 5 &amp; 4 \newline 0 &amp; 0 &amp; 5 &amp; 0 \newline \end{bmatrix}, \quad \mu = \begin{bmatrix} 2.5 \newline 2 \newline 2.25 \newline 1.25 \newline \end{bmatrix} \]</span> The resulting <span class="math inline">\(Y&#39;\)</span> vector is: <span class="math display">\[ Y&#39; = \begin{bmatrix} 2.5 &amp; 2.5 &amp; -2.5 &amp; -2.5 \newline 2 &amp; ? &amp; ? &amp; -2 \newline -.2.25 &amp; -2.25 &amp; 3.75 &amp; 1.25 \newline -1.25 &amp; -1.25 &amp; 3.75 &amp; -1.25 \end{bmatrix} \]</span></p><p>Now we must slightly modify the linear regression prediction to include the mean normalization term: <span class="math display">\[(\theta^{(j)})^T x^{(i)} + \mu_i\]</span> Now, for a new user, the initial predicted values will be equal to the <span class="math inline">\(\mu\)</span> term instead of simply being initialized to zero, which is more accurate.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Recommender Systems </tag>
            
            <tag> Collaborative Filtering </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Anomaly Detection</title>
      <link href="/2016/03/19/Anomaly%20Detection/"/>
      <url>/2016/03/19/Anomaly%20Detection/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#problem-motivation">Problem Motivation</a></li><li><a href="#gaussian-distribution">Gaussian Distribution</a></li><li><a href="#algorithm">Algorithm</a></li><li><a href="#developing-and-evaluating-an-anomaly-detection-system">Developing and Evaluating an Anomaly Detection System</a></li><li><a href="#anomaly-detection-vs-supervised-learning">Anomaly Detection vs. Supervised Learning</a></li><li><a href="#choosing-what-features-to-use">Choosing What Features to Use</a></li><li><a href="#multivariate-gaussian-distribution">Multivariate Gaussian Distribution</a></li><li><a href="#anomaly-detection-using-the-multivariate-gaussian-distribution">Anomaly Detection using the Multivariate Gaussian Distribution</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="problem-motivation">Problem Motivation</span></h1><p>Just like in other learning problems, we are given a dataset <span class="math inline">\({x^{(1)}, x^{(2)},\dots,x^{(m)}}\)</span>.</p><p>We are then given a new example, <span class="math inline">\(x_{test}\)</span>, and we want to know whether this new example is abnormal/anomalous.</p><p>We define a &quot;model&quot; <span class="math inline">\(p(x)\)</span> that tells us the probability the example is not anomalous. We also use a threshold <span class="math inline">\(\epsilon\)</span> (epsilon) as a dividing line so we can say which examples are anomalous and which are not.</p><p>A very common application of anomaly detection is detecting fraud: * $x^{(i)} = $ features of user <span class="math inline">\(i\)</span>'s activities * Model <span class="math inline">\(p(x)\)</span> from the data. * Identify unusual users by checking which have <span class="math inline">\(p(x) &lt; \epsilon\)</span>.</p><p>If our anomaly detector is flagging <strong>too many</strong> anomalous examples, then we need to <strong>decrease</strong> our threshold <span class="math inline">\(\epsilon\)</span></p><h1><span id="gaussian-distribution">Gaussian Distribution</span></h1><p>The Gaussian Distribution is a familiar bell-shaped curve that can be described by a function <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span></p><p>Let <span class="math inline">\(x \in \mathbb{R}\)</span>. If the probability distribution of <span class="math inline">\(x\)</span> is Gaussian with mean <span class="math inline">\(\mu\)</span>, variance <span class="math inline">\(\sigma^2\)</span>, then: <span class="math display">\[ x \sim \mathcal{N}(\mu, \sigma^2)\]</span></p><p>The little <span class="math inline">\(\sim\)</span> or 'tilde' can be read as &quot;distributed as.&quot;</p><p>The Gaussian Distribution is parameterized by a mean and a variance.</p><p>Mu, or <span class="math inline">\(\mu\)</span>, describes the center of the curve, called the mean. The width of the curve is described by sigma, or <span class="math inline">\(\sigma\)</span>, called the standard deviation.</p><p>The full function is as follows: <span class="math display">\[\large p(x;\mu,\sigma^2) = \dfrac{1}{\sigma\sqrt{(2\pi)}}e^{-\dfrac{1}{2}(\dfrac{x - \mu}{\sigma})^2}\]</span> We can estimate the parameter <span class="math inline">\(\mu\)</span> from a given dataset by simply taking the average of all the examples: <span class="math display">\[\mu = \dfrac{1}{m}\displaystyle \sum_{i=1}^m x^{(i)}\]</span> We can estimate the other parameter, <span class="math inline">\(\sigma^2\)</span>, with our familiar squared error formula: <span class="math display">\[\sigma^2 = \dfrac{1}{m}\displaystyle \sum_{i=1}^m(x^{(i)} - \mu)^2\]</span></p><h1><span id="algorithm">Algorithm</span></h1><p>Given a training set of examples, <span class="math inline">\(\lbrace x^{(1)},\dots,x^{(m)}\rbrace\)</span> where each example is a vector, <span class="math inline">\(x \in \mathbb{R}^n\)</span>. <span class="math display">\[p(x) = p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma^2_2)\cdots p(x_n;\mu_n,\sigma^2_n)\]</span></p><p>In statistics, this is called an &quot;independence assumption&quot; on the values of the features inside training example <span class="math inline">\(x\)</span>.</p><p>More compactly, the above expression can be written as follows: <span class="math display">\[ p(x) = \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2)\]</span></p><p><strong>The algorithm</strong></p><ol type="1"><li>Choose features <span class="math inline">\(x_i\)</span> that you think might be indicative of anomalous examples.</li><li>Fit parameters <span class="math inline">\(\mu_1,\dots,\mu_n,\sigma_1^2,\dots,\sigma_n^2\)</span>.</li><li>Calculate <span class="math inline">\(\mu_j = \dfrac{1}{m}\displaystyle \sum_{i=1}^m x_j^{(i)}\)</span></li><li>Calculate <span class="math inline">\(\sigma^2_j = \dfrac{1}{m}\displaystyle \sum_{i=1}^m(x_j^{(i)} - \mu_j)^2\)</span></li><li>Given a new example <span class="math inline">\(x\)</span>, compute <span class="math inline">\(p(x)\)</span>: <span class="math display">\[p(x) = \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2) = \prod\limits^n_{j=1} \dfrac{1}{\sqrt{2\pi}\sigma_j}exp(-\dfrac{(x_j - \mu_j)^2}{2\sigma^2_j})\]</span></li><li>Anomaly if <span class="math inline">\(p(x) &lt; \epsilon\)</span></li></ol><p>A vectorized version of the calculation for <span class="math inline">\(\mu\)</span> is <span class="math display">\[\mu = \dfrac{1}{m}\displaystyle \sum_{i=1}^m x^{(i)}\]</span></p><p>You can vectorize <span class="math inline">\(\sigma^2\)</span> similarly.</p><h1><span id="developing-and-evaluating-an-anomaly-detection-system">Developing and Evaluating an Anomaly Detection System</span></h1><p>To evaluate our learning algorithm, we take some labeled data, categorized into anomalous and non-anomalous examples (<span class="math inline">\(y = 0\)</span> if normal, <span class="math inline">\(y = 1\)</span> if anomalous).</p><p>Among that data, take a large proportion of <strong>good</strong>, non-anomalous data for the training set on which to train <span class="math inline">\(p(x)\)</span>.</p><p>Then, take a smaller proportion of mixed anomalous and non-anomalous examples (you will usually have many more non-anomalous examples) for your cross-validation and test sets.</p><p>For example, we may have a set where 0.2% of the data is anomalous. We take 60% of those examples, all of which are good (<span class="math inline">\(y=0\)</span>) for the training set. We then take 20% of the examples for the cross-validation set (with 0.1% of the anomalous examples) and another 20% from the test set (with another 0.1% of the anomalous).</p><p>In other words, we split the data 60/20/20 training/CV/test and then split the anomalous examples 50/50 between the CV and test sets.</p><p><strong>Algorithm evaluation</strong>:</p><ol type="1"><li>Fit model <span class="math inline">\(p(x)\)</span> on training set <span class="math inline">\(\lbrace x^{(1)},\dots,x^{(m)} \rbrace\)</span></li><li>On a cross validation/test example <span class="math inline">\(x\)</span>, predict:<ul><li>If <span class="math inline">\(p(x) &lt; \epsilon\)</span> (anomaly), then <span class="math inline">\(y = 1\)</span></li><li>If <span class="math inline">\(p(x) \geq \epsilon\)</span> (normal), then <span class="math inline">\(y = 0\)</span></li></ul></li></ol><p>Possible evaluation metrics * True positive, false positive, false negative, true negative. * Precision/recall * <span class="math inline">\(F_1\)</span> score</p><p>Note that we use the cross-validation set to choose parameter <span class="math inline">\(\epsilon\)</span></p><h1><span id="anomaly-detection-vs-supervised-learning">Anomaly Detection vs. Supervised Learning</span></h1><p>When do we use anomaly detection and when do we use supervised learning?</p><p><strong>Use anomaly detection when...</strong></p><ul><li>We have a very small number of positive examples (<span class="math inline">\(y=1\)</span> ... 0-20 examples is common) and a large number of negative (<span class="math inline">\(y=0\)</span>) examples.</li><li>We have many different &quot;types&quot; of anomalies and it is hard for any algorithm to learn from positive examples what the anomalies look like; future anomalies may look nothing like any of the anomalous examples we've seen so far.</li></ul><p><strong>Use supervised learning when...</strong> * We have a large number of both positive and negative examples. In other words, the training set is more evenly divided into classes. * We have enough positive examples for the algorithm to get a sense of what new positives examples look like. The future positive examples are likely similar to the ones in the training set.</p><h1><span id="choosing-what-features-to-use">Choosing What Features to Use</span></h1><p>The features will greatly affect how well your anomaly detection algorithm works.</p><p>We can check that our features are gaussian by plotting a histogram of our data and checking for the bell-shaped curve.</p><p>Some transforms we can try on an example feature <span class="math inline">\(x\)</span> that does not have the bell-shaped curve are: * <span class="math inline">\(log(x)\)</span> * <span class="math inline">\(log(x+1)\)</span> * <span class="math inline">\(log(x + c)\)</span> for some constant * <span class="math inline">\(\sqrt{x}\)</span> * <span class="math inline">\(x^{1/3}\)</span></p><p>We can play with each of these to try and achieve the gaussian shape in our data.</p><p>There is an <strong>error analysis procedure</strong> for anomaly detection that is very similar to the one in supervised learning.</p><p>Our goal is for <span class="math inline">\(p(x)\)</span> to be large for normal examples and small for anomalous examples.</p><p>One common problem is when <span class="math inline">\(p(x)\)</span> is similar for both types of examples. In this case, you need to examine the anomalous examples that are giving high probability in detail and try to figure out new features that will better distinguish the data.</p><p>In general, choose features that might take on unusually large or small values in the event of an anomaly.</p><h1><span id="multivariate-gaussian-distribution">Multivariate Gaussian Distribution</span></h1><p>The multivariate gaussian distribution is an extension of anomaly detection and may (or may not) catch more anomalies.</p><p>Instead of modeling <span class="math inline">\(p(x_1),p(x_2),\dots\)</span> separately, we will model <span class="math inline">\(p(x)\)</span> all in one go. Our parameters will be: <span class="math inline">\(\mu \in \mathbb{R}^n\)</span> and <span class="math inline">\(\Sigma \in \mathbb{R}^{n \times n}\)</span> <span class="math display">\[p(x;\mu,\Sigma) = \dfrac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(-1/2(x-\mu)^T\Sigma^{-1}(x-\mu))\]</span></p><p>The important effect is that we can model oblong gaussian contours, allowing us to better fit data that might not fit into the normal circular contours.</p><p>Varying <span class="math inline">\(\Sigma\)</span> changes the shape, width, and orientation of the contours. Changing <span class="math inline">\(\mu\)</span> will move the center of the distribution.</p><h1><span id="anomaly-detection-using-the-multivariate-gaussian-distribution">Anomaly Detection using the Multivariate Gaussian Distribution</span></h1><p>When doing anomaly detection with multivariate gaussian distribution, we compute <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> normally. We then compute <span class="math inline">\(p(x)\)</span> using the new formula in the previous section and flag an anomaly if <span class="math inline">\(p(x) &lt; \epsilon\)</span>.</p><p>The original model for <span class="math inline">\(p(x)\)</span> corresponds to a multivariate Gaussian where the contours of <span class="math inline">\(p(x;\mu,\Sigma)\)</span> are axis-aligned.</p><p>The multivariate Gaussian model can automatically capture correlations between different features of x.</p><p>However, the <strong>original model</strong> maintains some advantages: it is <strong>computationally cheaper</strong> (no matrix to invert, which is costly for large number of features) and it performs well even with <strong>small training set size</strong> (in multivariate Gaussian model, it should be greater than the number of features for <span class="math inline">\(\Sigma\)</span> to be invertible).</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Dimensionality Reduction</title>
      <link href="/2016/03/13/Dimensionality%20Reduction/"/>
      <url>/2016/03/13/Dimensionality%20Reduction/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#motivation-i-data-compression">Motivation I: Data Compression</a></li><li><a href="#motivation-ii-visualization">Motivation II: Visualization</a></li><li><a href="#principal-component-analysis-problem-formulation">Principal Component Analysis Problem Formulation</a></li><li><a href="#principal-component-analysis-algorithm">Principal Component Analysis Algorithm</a></li><li><a href="#choosing-the-number-of-principal-components">Choosing the Number of Principal Components</a></li><li><a href="#reconstruction-from-compressed-representation">Reconstruction from Compressed Representation</a></li><li><a href="#advice-for-applying-pca">Advice for Applying PCA</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="motivation-i-data-compression">Motivation I: Data Compression</span></h1><p>We may want to reduce the dimension of our features if we have a lot of redundant data.</p><p>To do this, we find two highly correlated features, plot them, and make a new line that seems to describe both features accurately. We place all the new features on this single line.</p><p>Doing dimensionality reduction will <strong>reduce the total data</strong> we have to store in computer memory and will <strong>speed up our learning algorithm</strong>.</p><p>Note: in dimensionality reduction, we are reducing our features rather than our number of examples. Our variable <span class="math inline">\(m\)</span> will stay the same size; <span class="math inline">\(n\)</span>, the number of features each example from <span class="math inline">\(x^{(1)}\)</span> to <span class="math inline">\(x^{(m)}\)</span> carries, will be reduced.</p><h1><span id="motivation-ii-visualization">Motivation II: Visualization</span></h1><p>It is not easy to visualize data that is more than three dimensions. We can reduce the dimensions of our data to 3 or less in order to plot it.</p><p>We need to find new features, <span class="math inline">\(z_1, z_2\)</span> (and perhaps <span class="math inline">\(z_3\)</span>) that can effectively summarize all the other features.</p><p>Example: hundreds of features related to a country's economic system may all be combined into one feature that you call &quot;Economic Activity.&quot;</p><h1><span id="principal-component-analysis-problem-formulation">Principal Component Analysis Problem Formulation</span></h1><p>The most popular dimensionality reduction algorithm is <em>Principal Component Analysis</em> (<strong>PCA</strong>)</p><p><strong>Problem formulation</strong></p><p>Given two features, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, we want to find a single line that effectively describes both features at once. We then map our old features onto this new line to get a new single feature.</p><p>The same can be done with three features, where we map them to a plane.</p><p>The <strong>goal</strong> of PCA is to reduce the average of all the distances of every feature to the projection line. This is the <strong>projection error</strong>.</p><ul><li>Reduce from 2d to 1d: find a direction (a vector <span class="math inline">\(u^{(1)} \in \mathbb{R}^n\)</span>) onto which to project the data so as to minimize the projection error.</li></ul><p>The more general case is as follows:</p><ul><li>Reduce from n-dimension to k-dimension: Find <span class="math inline">\(k\)</span> vectors <span class="math inline">\(u^{(1)}, u^{(2)}, \dots, u^{(k)}\)</span> onto which to project the data so as to minimize the projection error.</li></ul><p>If we are converting from 3d to 2d, we will project our data onto two directions (a plane), so <span class="math inline">\(k\)</span> will be 2.</p><p><strong>PCA is not linear regression</strong> * In linear regression, we are minimizing the squared error from every point to our predictor line. These are vertical distances. * In PCA, we are minimizing the shortest distance, or shortest orthogonal distances, to our data points.</p><p>More generally, in linear regression we are taking all our examples in <span class="math inline">\(x\)</span> and applying the parameters in <span class="math inline">\(\Theta\)</span> to predict <span class="math inline">\(y\)</span>.</p><p>In PCA, we are taking a number of features <span class="math inline">\(x_1, x_2, \dots, x_n\)</span>, and finding a closest common dataset among them. We aren't trying to predict any result and we aren't applying any theta weights to the features.</p><h1><span id="principal-component-analysis-algorithm">Principal Component Analysis Algorithm</span></h1><p>Before we can apply PCA, there is a data pre-processing step we must perform:</p><p><strong>Data preprocessing</strong></p><ol type="1"><li>Let <span class="math inline">\(Î¼=\frac{1}{m}\sum^{m}_{i=1}x^{(i)}\)</span>.</li><li>Replace each <span class="math inline">\(x^{(i)}\)</span> with <span class="math inline">\(x^{(i)}âˆ’Î¼\)</span>.</li><li>Let <span class="math inline">\(Ïƒ^2_j=\frac{1}{m}\sum_i(x^{(i)}_j)^2\)</span></li><li>Replace each <span class="math inline">\(x^{(i)}_j\)</span> with <span class="math inline">\(\frac{x^{(i)}_j}{Ïƒ_j}\)</span>.</li></ol><p>Above, we first subtract the mean of each feature from the original feature. Then we scale all the features (<span class="math inline">\(x_j^{(i)} = \dfrac{x_j^{(i)} - \mu_j}{s_j}\)</span>) We can define specifically what it means to reduce from 2d to 1d data as follows: <span class="math display">\[x^{(i)} \in \mathbb{R}^2 \rightarrow z^{(i)} \in \mathbb{R}\]</span> The <span class="math inline">\(z\)</span> values are all real numbers and are the projections of our features onto <span class="math inline">\(u^{(1)}\)</span>.</p><p>So, PCA has two tasks: figure out <span class="math inline">\(u^{(1)},\dots,u^{(k)}\)</span> and also to find <span class="math inline">\(z_1, z_2, \dots, z_m\)</span>.</p><p><strong>Mathematical proof</strong></p><p>We would like to automatically select the direction <span class="math inline">\(u\)</span> corresponding to the first of the two figures shown above.</p><p>To formalize this, note that given a unit vector <span class="math inline">\(u\)</span> and a point <span class="math inline">\(x\)</span>, the length of the projection of <span class="math inline">\(x\)</span> onto <span class="math inline">\(u\)</span> is given by <span class="math inline">\(x^Tu\)</span>. I.e., if <span class="math inline">\(x^{(i)}\)</span> is a point in our dataset ,then its projection onto <span class="math inline">\(u\)</span> is distance <span class="math inline">\(x^Tu\)</span> from the origin. Hence, to maximize the variance of the projections, we would like to choose a unit-length <span class="math inline">\(u\)</span> so as to <strong>maximize</strong>:</p><p><span class="math display">\[\frac{1}{m}\sum^m_{i=1}(x^{(i)T}u)^2 = \frac{1}{m}\sum^m_{i=1}u^tx^{(i)}x^{(i)T}u = u^T(\frac{1}{m}\sum^m_{i=1}x^{(i)}x^{(i)T})u\]</span></p><p>If you havenâ€™t seen this before, try using the method of <a href="https://www.wikiwand.com/en/Lagrange_multiplier" target="_blank" rel="noopener">Lagrange multipliers(æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•)</a> to maximize <span class="math inline">\(u^TÎ£u\)</span> subject to that <span class="math inline">\(u^Tu= 1\)</span>. You should be able to show that <span class="math inline">\(Î£u=Î»u\)</span>, for some <span class="math inline">\(Î»\)</span>, which implies <span class="math inline">\(u\)</span> is an eigenvector of <span class="math inline">\(Î£\)</span>, with eigenvalue <span class="math inline">\(Î»\)</span>. Because <span class="math inline">\(Î£\)</span> is symmetric(å¯¹ç§°çš„), the <span class="math inline">\(u_i\)</span> â€™s will (or always can be chosen to be) orthogonal(æ­£äº¤çš„ ) to each other.</p><p>We easily recognize that the maximizing this subject to <span class="math inline">\(||u||^2= 1\)</span> gives the principal eigenvector of <span class="math inline">\(Î£ =\frac{1}{m}\sum^m_{i=1}x^{(i)}x^{(i)T}\)</span>, which is just the empirical <strong>covariance matrix</strong> of the data (assuming it has <strong>zero mean</strong>).</p><p>To summarize, we have found that if we wish to find a 1-dimensional subspace with with to approximate the data, we should choose <span class="math inline">\(u\)</span> to be the principal eigenvector of <span class="math inline">\(Î£\)</span>. More generally, if we wish to project our data into a k-dimensional subspace (k &lt; n), we should choose <span class="math inline">\(u_1\)</span>, . . . , <span class="math inline">\(u_k\)</span> to be the top <span class="math inline">\(k\)</span> eigenvectors of <span class="math inline">\(Î£\)</span>. The <span class="math inline">\(u_i\)</span>â€™s now form a new, orthogonal basis for the data.</p><p>Then, to represent <span class="math inline">\(x^{(i)}\)</span> in this basis, we need only compute the corresponding vector <span class="math display">\[y^{(i)}=\begin{bmatrix}u^T_1x^{(i)}     \\u^T_2x^{(i)}    \\\vdots  \\u^T_kx^{(i)}\end{bmatrix}âˆˆ\mathbb{R}^k\]</span></p><p>Thus, whereas <span class="math inline">\(x^{(i)}âˆˆ\mathbb{R}^n\)</span>, the vector <span class="math inline">\(y^{(i)}\)</span> now gives a lower,k-dimensional, approximation/representation for <span class="math inline">\(x^{(i)}\)</span>. <strong>PCA</strong> is therefore also referred to as a <strong>dimensionality reduction</strong> algorithm. The vectors <span class="math inline">\(u_1\)</span>, . . . , <span class="math inline">\(u_k\)</span> are called the first <span class="math inline">\(k\)</span> principal components of the data.</p><p><strong>The PCA Algorithm</strong></p><p>1.<strong>Compute &quot;covariance matrix&quot;</strong> <span class="math display">\[ \large \Sigma = \dfrac{1}{m}\sum^m_{i=1}(x^{(i)})(x^{(i)})^T \]</span> This can be vectorized in Octave as: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;</span><br></pre></td></tr></table></figure></p><p>We denote the covariance matrix with a <strong>capital sigma</strong> (which happens to be the same symbol for summation, confusingly---they represent entirely different things).</p><p>Note that <span class="math inline">\(x^{(i)}\)</span> is an <span class="math inline">\(n \times 1\)</span> vector, <span class="math inline">\((x^{(i)})^T\)</span> is an <span class="math inline">\(1 \times n\)</span> vector and <span class="math inline">\(X\)</span> is a <span class="math inline">\(m \times n\)</span> matrix (row-wise stored examples). The product of those will be an <span class="math inline">\(n \times n\)</span> matrix, which are the dimensions of <span class="math inline">\(\Sigma\)</span>.</p><p>2.<strong>Compute &quot;eigenvectors&quot; of covariance matrix <span class="math inline">\(\Sigma\)</span></strong> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[U,S,V] = svd(Sigma);</span><br></pre></td></tr></table></figure></p><p><code>svd()</code> is the 'singular value decomposition(å¥‡å¼‚å€¼åˆ†è§£)', a built-in Octave function.</p><p>What we actually want out of <code>svd()</code> is the '<code>U</code>' matrix of the Sigma covariance matrix: <span class="math inline">\(U \in \mathbb{R}^{n \times n}\)</span>. U contains <span class="math inline">\(u^{(1)},\dots,u^{(n)}\)</span>, which is exactly what we want.</p><p>3.<strong>Take the first <span class="math inline">\(k\)</span> columns of the U matrix and compute <span class="math inline">\(z\)</span></strong></p><p>We'll assign the first <span class="math inline">\(k\)</span> columns of U to a variable called '<strong>Ureduce</strong>'. This will be an <span class="math inline">\(n \times k\)</span> matrix. We compute z with: <span class="math display">\[ \large z^{(i)} = Ureduce^T \cdot x^{(i)} \]</span></p><p><span class="math inline">\(Ureduce^T\)</span> will have dimensions <span class="math inline">\(k \times n\)</span> while <span class="math inline">\(x^{(i)}\)</span> will have dimensions <span class="math inline">\(n \times 1\)</span>. The product <span class="math inline">\(Ureduce^T \cdot x^{(i)}\)</span> will have dimensions <span class="math inline">\(k \times 1\)</span>.</p><p>To <strong>summarize</strong>, the whole algorithm in octave is roughly: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;  <span class="comment">% compute the covariance matrix</span></span><br><span class="line">[U,S,V] = svd(Sigma);    <span class="comment">% compute our projected directions</span></span><br><span class="line">Ureduce = U(:,<span class="number">1</span>:k);      <span class="comment">% take the first k directions</span></span><br><span class="line">z = Ureduce' * x;        <span class="comment">% compute the projected data points</span></span><br></pre></td></tr></table></figure></p><h1><span id="choosing-the-number-of-principal-components">Choosing the Number of Principal Components</span></h1><p>How do we choose <span class="math inline">\(k\)</span>, also called the number of principal components? Recall that <span class="math inline">\(k\)</span> is the dimension we are reducing to.</p><p>One way to choose <span class="math inline">\(k\)</span> is by using the following formula: * Given the average squared projection error: <span class="math inline">\(\dfrac{1}{m}\sum^m_{i=1}||x^{(i)} - x_{approx}^{(i)}||^2\)</span> * Also given the total variation in the data: <span class="math inline">\(\dfrac{1}{m}\sum^m_{i=1}||x^{(i)}||^2\)</span> * Choose <span class="math inline">\(k\)</span> to be the smallest value such that: <span class="math display">\[\large \dfrac{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)} - x_{approx}^{(i)}||^2}{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)}||^2} \leq 0.01\]</span></p><p>In other words, the squared projection error divided by the total variation should be less than one percent, so that <strong>99% of the variance is retained</strong>.</p><p><strong>Algorithm for choosing <span class="math inline">\(k\)</span></strong></p><ol type="1"><li>Try PCA with <span class="math inline">\(k = 1, 2, \dots\)</span></li><li>Compute <span class="math inline">\(U_{reduce}, z, x\)</span></li><li>Check the formula given above that 99% of the variance is retained. If not, go to step one and increase <span class="math inline">\(k\)</span>.</li></ol><p>This procedure would actually be horribly inefficient. In Octave, we will call svd: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[U,S,V] = svd(Sigma)</span><br></pre></td></tr></table></figure></p><p>Which gives us a matrix S. We can actually check for 99% of retained variance using the S matrix as follows: <span class="math display">\[ \dfrac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}} \geq 0.99 \]</span></p><h1><span id="reconstruction-from-compressed-representation">Reconstruction from Compressed Representation</span></h1><p>If we use PCA to compress our data, how can we uncompress our data, or go back to our original number of features?</p><p>To go from 1-dimension back to 2d we do: <span class="math inline">\(z \in \mathbb{R} \rightarrow x \in \mathbb{R}^2\)</span>.</p><p>We can do this with the equation: <span class="math inline">\(x_{approx}^{(1)} = U_{reduce} \cdot z^{(1)}\)</span>.</p><p>Note that we can only get approximations of our original data.</p><h1><span id="advice-for-applying-pca">Advice for Applying PCA</span></h1><p>The most common use of PCA is to <strong>speed up supervised learning</strong>.</p><p>Given a training set with a large number of features (e.g. <span class="math inline">\(x^{(1)},\dots,x^{(m)} \in \mathbb{R}^{10000}\)</span>) we can use PCA to reduce the number of features in each example of the training set (e.g. <span class="math inline">\(z^{(1)},\dots,z^{(m)} \in \mathbb{R}^{1000}\)</span>).</p><p>Note that we should define the PCA reduction from <span class="math inline">\(x^{(i)}\)</span> to <span class="math inline">\(z^{(i)}\)</span> only on the training set and not on the cross-validation or test sets. You can apply the mapping <span class="math inline">\(z^{(i)}\)</span> to your cross-validation and test sets after it is defined on the training set.</p><p><strong>Applications</strong> * Compressions * Reduce space of data * Speed up algorithm * Visualization of data * Choose k = 2 or k = 3</p><p><strong>Bad use of PCA</strong>: trying to prevent overfitting. We might think that reducing the features with PCA would be an effective way to address overfitting. It might work, but is not recommended because it does not consider the values of our results <span class="math inline">\(y\)</span>. Using just regularization will be at least as effective.</p><p>Don't assume you need to do PCA. <strong>Try your full machine learning algorithm without PCA first</strong>. Then use PCA if you find that you need it.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> PCA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>èšç±»ï¼ˆClusteringï¼‰</title>
      <link href="/2016/03/10/%E8%81%9A%E7%B1%BB%EF%BC%88Clustering%EF%BC%89/"/>
      <url>/2016/03/10/%E8%81%9A%E7%B1%BB%EF%BC%88Clustering%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#unsupervised-learning-introduction">Unsupervised Learning: Introduction</a></li><li><a href="#k-means-algorithm">K-Means Algorithm</a></li><li><a href="#optimization-objective">Optimization Objective</a></li><li><a href="#random-initialization">Random Initialization</a></li><li><a href="#choosing-the-number-of-clusters">Choosing the Number of Clusters</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="unsupervised-learning-introduction">Unsupervised Learning: Introduction</span></h1><p>Unsupervised learning is contrasted from supervised learning because it uses an unlabeled training set rather than a labeled one.</p><p>In other words, we don't have the vector <span class="math inline">\(y\)</span> of expected results, we only have a dataset of features where we can find structure. Clustering is good for: * Market segmentation * Social network analysis * Organizing computer clusters * Astronomical data analysis</p><h1><span id="k-means-algorithm">K-Means Algorithm</span></h1><p>The K-Means Algorithm is the most popular and widely used algorithm for automatically grouping data into coherent subsets.</p><ol type="1"><li>Randomly initialize two points in the dataset called the cluster centroids.</li><li>Cluster assignment: assign all examples into one of two groups based on which cluster centroid the example is closest to.</li><li>Move centroid: compute the averages for all the points inside each of the two cluster centroid groups, then move the cluster centroid points to those averages.</li><li>Re-run (2) and (3) until we have found our clusters.</li></ol><p>Our main variables are: * <span class="math inline">\(K\)</span> (number of clusters) * Training set <span class="math inline">\({x^{(1)}, x^{(2)}, \dots,x^{(m)}}\)</span> * Where <span class="math inline">\(x^{(i)} \in \mathbb{R}^n\)</span></p><p>Note that we <strong>will not use</strong> the <span class="math inline">\(x_0 = 1\)</span> convention.</p><p><strong>The algorithm</strong>: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Randomly initialize K cluster centroids mu(1), mu(2), ..., mu(K)</span><br><span class="line">Repeat:</span><br><span class="line">   for i = 1 to m:</span><br><span class="line">      c(i) := index (from 1 to K) of cluster centroid closest to x(i)</span><br><span class="line">   for k = 1 to K:</span><br><span class="line">      mu(k) := average (mean) of points assigned to cluster k</span><br></pre></td></tr></table></figure></p><p>The <strong>first for-loop</strong> is the 'Cluster Assignment' step. We make a vector c where c(i) represents the centroid assigned to example x(i).</p><p>We can write the operation of the Cluster Assignment step more mathematically as follows: <span class="math display">\[c^{(i)} = argmin_k\ ||x^{(i)} - \mu_k||^2\]</span> That is, each <span class="math inline">\(c^{(i)}\)</span> contains the index of the centroid that has minimal distance to <span class="math inline">\(x^{(i)}\)</span>.</p><p>By convention, we square the right-hand-side, which makes the function we are trying to minimize more sharply increasing. It is mostly just a convention.</p><p>The <strong>second for-loop</strong> is the 'Move Centroid' step where we move each centroid to the average of its group.</p><p>More formally, the equation for this loop is as follows: <span class="math display">\[ \mu_k = \dfrac{1}{n}[x^{(k_1)} + x^{(k_2)} + \dots + x^{(k_n)}] \in \mathbb{R}^n\]</span> Where each of <span class="math inline">\(x^{(k_1)}, x^{(k_2)}, \dots, x^{(k_n)}\)</span> are the training examples assigned to group $ _k$.</p><p>If you have a cluster centroid with 0 points assigned to it, you can randomly <strong>re-initialize</strong> that centroid to a new point. You can also simply <strong>eliminate</strong> that cluster group.</p><p>After a number of iterations the algorithm will converge, where new iterations do not affect the clusters.</p><p>Note on non-separated clusters: some datasets have no real inner separation or natural structure. K-means can still evenly segment your data into <span class="math inline">\(K\)</span> subsets, so can still be useful in this case.</p><h1><span id="optimization-objective">Optimization Objective</span></h1><p>Recall some of the parameters we used in our algorithm: * $c^{(i)} = $ index of cluster (1,2,...,K) to which example <span class="math inline">\(x^{(i)}\)</span> is currently assigned * $_k = $ cluster centroid $ kÂ (<em>k ^n)$ * $</em>{c^{(i)}} = $ cluster centroid of cluster to which example <span class="math inline">\(x^{(i)}\)</span> has been assigned</p><p>Using these variables we can define our cost function: <span class="math display">\[ \large J(c^{(i)},\dots,c^{(m)},\mu_1,\dots,\mu_K) = \dfrac{1}{m}\sum_{i=1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2 \]</span> Our optimization objective is to minimize all our parameters using the above cost function: <span class="math display">\[ \large min_{c,\mu}\ J(c,\mu) \]</span></p><p>That is, we are finding all the values in sets <span class="math inline">\(c\)</span>, representing all our clusters, and <span class="math inline">\(\mu\)</span>, representing all our centroids, that will minimize <strong>the average of the distances</strong> of every training example to its corresponding cluster centroid.</p><p>The above cost function is often called the <strong>distortion</strong>(å˜å½¢) of the training examples.</p><p>In the <strong>cluster assignment</strong> step, our goal is to: Minimize <span class="math inline">\(J(\dots)\)</span> with <span class="math inline">\(c^{(1)},\dots,c^{(m)}\)</span> (holding <span class="math inline">\(\mu_1,\dots,\mu_K\)</span> fixed)</p><p>In the <strong>move centroid</strong> step, our goal is to: Minimize <span class="math inline">\(J(\dots)\)</span> with <span class="math inline">\(\mu_1,\dots,\mu_K\)</span></p><p>With k-means, it is <strong>not possible for the cost function to sometimes increase</strong>. It should always descend.</p><h1><span id="random-initialization">Random Initialization</span></h1><p>There's one particular recommended method for randomly initializing your cluster centroids.</p><ol type="1"><li>Have <span class="math inline">\(K &lt; m\)</span>. That is, make sure the number of your clusters is less than the number of your training examples.</li><li>Randomly pick <span class="math inline">\(K\)</span> training examples. (Not mentioned in the lecture, but also be sure the selected examples are <strong>unique</strong>).</li><li>Set <span class="math inline">\(\mu_1,\dots,\mu_k\)</span> equal to these <span class="math inline">\(K\)</span> examples.</li></ol><p>K-means <strong>can get stuck in local optima</strong>. To decrease the chance of this happening, you can run the algorithm on many different random initializations. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for i = 1 to 100:</span><br><span class="line">   randomly initialize k-means</span><br><span class="line">   run k-means to get &apos;c&apos; and &apos;m&apos;</span><br><span class="line">   compute the cost function (distortion) J(c,m)</span><br><span class="line">pick the clustering that gave us the lowest cost</span><br></pre></td></tr></table></figure></p><h1><span id="choosing-the-number-of-clusters">Choosing the Number of Clusters</span></h1><p>Choosing <span class="math inline">\(K\)</span> can be quite arbitrary and ambiguous.</p><p><strong>The elbow method</strong>: plot the cost <span class="math inline">\(J\)</span> and the number of clusters <span class="math inline">\(K\)</span>. The cost function should reduce as we increase the number of clusters, and then flatten out. Choose <span class="math inline">\(K\)</span> at the point where the cost function starts to flatten out.</p><p>However, fairly often, the curve is very gradual, so there's no clear elbow.</p><p>Note: <span class="math inline">\(J\)</span> will always decrease as <span class="math inline">\(K\)</span> is increased. The one exception is if k-means gets stuck at a bad local optimum.</p><p>Another way to choose <span class="math inline">\(K\)</span> is to observe how well k-means performs on a <strong>downstream purpose</strong>. In other words, you choose <span class="math inline">\(K\)</span> that proves to be most useful for some goal you're trying to achieve from using these clusters.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Clustering </tag>
            
            <tag> K-Means </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å·ç§¯ç¥ç»ç½‘ç»œ(CNN)</title>
      <link href="/2016/03/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/"/>
      <url>/2016/03/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/</url>
      
        <content type="html"><![CDATA[<p>å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Network, CNNï¼‰æ˜¯ä¸€ç§å‰é¦ˆç¥ç»ç½‘ç»œï¼Œå®ƒçš„äººå·¥ç¥ç»å…ƒå¯ä»¥å“åº”ä¸€éƒ¨åˆ†è¦†ç›–èŒƒå›´å†…çš„å‘¨å›´å•å…ƒï¼Œå¯¹äºå¤§å‹å›¾åƒå¤„ç†æœ‰å‡ºè‰²è¡¨ç°ã€‚</p><!-- toc --><ul><li><a href="#æ¦‚æ½">æ¦‚æ½</a></li><li><a href="#layers-used-to-build-convnets">Layers used to build ConvNets</a><ul><li><a href="#å·ç§¯å±‚convolutional-layer">å·ç§¯å±‚ï¼ˆConvolutional layerï¼‰</a></li><li><a href="#æ± åŒ–å±‚pooling-layer">æ± åŒ–å±‚(Pooling Layer)</a></li><li><a href="#å…¨è¿æ¥å±‚fully-connected-layer">å…¨è¿æ¥å±‚ï¼ˆFully-connected layerï¼‰</a></li></ul></li><li><a href="#å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„">å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„</a><ul><li><a href="#layer-patterns">Layer Patterns</a></li><li><a href="#layer-sizing-patterns">Layer Sizing Patterns</a></li><li><a href="#case-studies">Case Studies</a></li></ul></li><li><a href="#å‚è€ƒ">å‚è€ƒ</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="æ¦‚æ½">æ¦‚æ½</span></h1><p><strong>å·ç§¯ç¥ç»ç½‘ç»œ</strong>ï¼ˆConvolutional Neural Networks / CNNs / ConvNetsï¼‰ä¸æ™®é€šç¥ç»ç½‘ç»œéå¸¸ç›¸ä¼¼ï¼Œå®ƒä»¬éƒ½ç”±å…·æœ‰å¯å­¦ä¹ çš„æƒé‡å’Œåç½®å¸¸é‡(biases)çš„ç¥ç»å…ƒç»„æˆã€‚æ¯ä¸ªç¥ç»å…ƒéƒ½æ¥æ”¶ä¸€äº›è¾“å…¥ï¼Œå¹¶åšä¸€äº›ç‚¹ç§¯è®¡ç®—ï¼Œè¾“å‡ºæ˜¯æ¯ä¸ªåˆ†ç±»çš„åˆ†æ•°ï¼Œæ™®é€šç¥ç»ç½‘ç»œé‡Œçš„ä¸€äº›è®¡ç®—æŠ€å·§åˆ°è¿™é‡Œä¾æ—§é€‚ç”¨ã€‚</p><p>æ‰€ä»¥å“ªé‡Œä¸åŒå‘¢ï¼Ÿå·ç§¯ç¥ç»ç½‘ç»œé»˜è®¤è¾“å…¥æ˜¯å›¾åƒï¼Œå¯ä»¥è®©æˆ‘ä»¬æŠŠç‰¹å®šçš„æ€§è´¨ç¼–ç å…¥ç½‘ç»œç»“æ„ï¼Œä½¿æ˜¯æˆ‘ä»¬çš„å‰é¦ˆå‡½æ•°æ›´åŠ æœ‰æ•ˆç‡ï¼Œå¹¶å‡å°‘äº†å¤§é‡å‚æ•°ã€‚</p><p><strong>å…·æœ‰ä¸‰ç»´ä½“ç§¯çš„ç¥ç»å…ƒ(3D volumes of neurons)</strong> å·ç§¯ç¥ç»ç½‘ç»œåˆ©ç”¨è¾“å…¥æ˜¯å›¾ç‰‡çš„ç‰¹ç‚¹ï¼ŒæŠŠç¥ç»å…ƒè®¾è®¡æˆä¸‰ä¸ªç»´åº¦ ï¼š <strong>width</strong>, <strong>height</strong>, <strong>depth</strong>(æ³¨æ„è¿™ä¸ªdepthä¸æ˜¯ç¥ç»ç½‘ç»œçš„æ·±åº¦ï¼Œè€Œæ˜¯ç”¨æ¥æè¿°ç¥ç»å…ƒçš„) ã€‚æ¯”å¦‚è¾“å…¥çš„å›¾ç‰‡å¤§å°æ˜¯ 32 Ã— 32 Ã— 3 (rgb)ï¼Œé‚£ä¹ˆè¾“å…¥ç¥ç»å…ƒå°±ä¹Ÿå…·æœ‰ 32Ã—32Ã—3 çš„ç»´åº¦ã€‚ä¸‹é¢æ˜¯å›¾è§£ï¼š</p><p><img src="/images/1457405418840.png"> ä¼ ç»Ÿç¥ç»ç½‘ç»œ</p><p><img src="/images/1457405426800.png"> å·ç§¯ç¥ç»ç½‘ç»œ</p><p>ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œç”±å¾ˆå¤šå±‚ç»„æˆï¼Œå®ƒä»¬çš„è¾“å…¥æ˜¯ä¸‰ç»´çš„ï¼Œè¾“å‡ºä¹Ÿæ˜¯ä¸‰ç»´çš„ï¼Œæœ‰çš„å±‚æœ‰å‚æ•°ï¼Œæœ‰çš„å±‚ä¸éœ€è¦å‚æ•°ã€‚</p><h1><span id="layers-used-to-build-convnets">Layers used to build ConvNets</span></h1><p>å·ç§¯ç¥ç»ç½‘ç»œé€šå¸¸åŒ…å«ä»¥ä¸‹å‡ ç§å±‚ï¼š</p><ul><li><strong>å·ç§¯å±‚ï¼ˆConvolutional layerï¼‰</strong>ï¼Œå·ç§¯ç¥ç»ç½‘è·¯ä¸­æ¯å±‚å·ç§¯å±‚ç”±è‹¥å¹²å·ç§¯å•å…ƒç»„æˆï¼Œæ¯ä¸ªå·ç§¯å•å…ƒçš„å‚æ•°éƒ½æ˜¯é€šè¿‡åå‘ä¼ æ’­ç®—æ³•ä¼˜åŒ–å¾—åˆ°çš„ã€‚å·ç§¯è¿ç®—çš„ç›®çš„æ˜¯æå–è¾“å…¥çš„ä¸åŒç‰¹å¾ï¼Œç¬¬ä¸€å±‚å·ç§¯å±‚å¯èƒ½åªèƒ½æå–ä¸€äº›ä½çº§çš„ç‰¹å¾å¦‚è¾¹ç¼˜ã€çº¿æ¡å’Œè§’ç­‰å±‚çº§ï¼Œæ›´å¤šå±‚çš„ç½‘ç»œèƒ½ä»ä½çº§ç‰¹å¾ä¸­è¿­ä»£æå–æ›´å¤æ‚çš„ç‰¹å¾ã€‚</li><li><strong>çº¿æ€§æ•´æµå±‚ï¼ˆRectified Linear Units layer, ReLU layerï¼‰</strong>ï¼Œè¿™ä¸€å±‚ç¥ç»çš„æ´»æ€§åŒ–å‡½æ•°ï¼ˆActivation functionï¼‰ä½¿ç”¨çº¿æ€§æ•´æµï¼ˆRectified Linear Units, ReLUï¼‰<span class="math inline">\(f(x) = max(0, x)\)</span>ã€‚</li><li><strong>æ± åŒ–å±‚ï¼ˆPooling layerï¼‰</strong>ï¼Œé€šå¸¸åœ¨å·ç§¯å±‚ä¹‹åä¼šå¾—åˆ°ç»´åº¦å¾ˆå¤§çš„ç‰¹å¾ï¼Œå°†ç‰¹å¾åˆ‡æˆå‡ ä¸ªåŒºåŸŸï¼Œå–å…¶æœ€å¤§å€¼æˆ–å¹³å‡å€¼ï¼Œå¾—åˆ°æ–°çš„ã€ç»´åº¦è¾ƒå°çš„ç‰¹å¾ã€‚</li><li><strong>å…¨è¿æ¥å±‚ï¼ˆ Fully-Connected layerï¼‰</strong>, æŠŠæ‰€æœ‰å±€éƒ¨ç‰¹å¾ç»“åˆå˜æˆå…¨å±€ç‰¹å¾ï¼Œç”¨æ¥è®¡ç®—æœ€åæ¯ä¸€ç±»çš„å¾—åˆ†ã€‚</li></ul><p>ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œå„å±‚åº”ç”¨<a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">å®ä¾‹</a>ï¼š <img src="/images/1457406468399.png"></p><h2><span id="å·ç§¯å±‚convolutional-layer">å·ç§¯å±‚ï¼ˆConvolutional layerï¼‰</span></h2><p><strong>å±€éƒ¨æ„ŸçŸ¥ï¼ˆLocal Connectivityï¼‰</strong></p><p>æ™®é€šç¥ç»ç½‘ç»œæŠŠè¾“å…¥å±‚å’Œéšå«å±‚è¿›è¡Œâ€œ<strong>å…¨è¿æ¥(Full Connected)</strong>â€œçš„è®¾è®¡ã€‚ä»è®¡ç®—çš„è§’åº¦æ¥è®²ï¼Œç›¸å¯¹è¾ƒå°çš„å›¾åƒä»æ•´å¹…å›¾åƒä¸­è®¡ç®—ç‰¹å¾æ˜¯å¯è¡Œçš„ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ˜¯æ›´å¤§çš„å›¾åƒï¼ˆå¦‚ 96x96 çš„å›¾åƒï¼‰ï¼Œè¦é€šè¿‡è¿™ç§å…¨è”é€šç½‘ç»œçš„è¿™ç§æ–¹æ³•æ¥å­¦ä¹ æ•´å¹…å›¾åƒä¸Šçš„ç‰¹å¾ï¼Œä»è®¡ç®—è§’åº¦è€Œè¨€ï¼Œå°†å˜å¾—éå¸¸è€—æ—¶ã€‚ä½ éœ€è¦è®¾è®¡ 10 çš„ 4 æ¬¡æ–¹ï¼ˆ=10000ï¼‰ä¸ªè¾“å…¥å•å…ƒï¼Œå‡è®¾ä½ è¦å­¦ä¹  100 ä¸ªç‰¹å¾ï¼Œé‚£ä¹ˆå°±æœ‰ 10 çš„ 6 æ¬¡æ–¹ä¸ªå‚æ•°éœ€è¦å»å­¦ä¹ ã€‚ä¸ 28x28 çš„å°å—å›¾åƒç›¸æ¯”è¾ƒï¼Œ 96x96 çš„å›¾åƒä½¿ç”¨å‰å‘è¾“é€æˆ–è€…åå‘ä¼ å¯¼çš„è®¡ç®—æ–¹å¼ï¼Œè®¡ç®—è¿‡ç¨‹ä¹Ÿä¼šæ…¢ 10 çš„ 2 æ¬¡æ–¹ï¼ˆ=100ï¼‰å€ã€‚</p><p>å·ç§¯å±‚è§£å†³è¿™ç±»é—®é¢˜çš„ä¸€ç§ç®€å•æ–¹æ³•æ˜¯å¯¹éšå«å•å…ƒå’Œè¾“å…¥å•å…ƒé—´çš„è¿æ¥åŠ ä»¥é™åˆ¶ï¼š<strong>æ¯ä¸ªéšå«å•å…ƒä»…ä»…åªèƒ½è¿æ¥è¾“å…¥å•å…ƒçš„ä¸€éƒ¨åˆ†</strong>ã€‚ä¾‹å¦‚ï¼Œæ¯ä¸ªéšå«å•å…ƒä»…ä»…è¿æ¥è¾“å…¥å›¾åƒçš„ä¸€å°ç‰‡ç›¸é‚»åŒºåŸŸã€‚ï¼ˆå¯¹äºä¸åŒäºå›¾åƒè¾“å…¥çš„è¾“å…¥å½¢å¼ï¼Œä¹Ÿä¼šæœ‰ä¸€äº›ç‰¹åˆ«çš„è¿æ¥åˆ°å•éšå«å±‚çš„è¾“å…¥ä¿¡å·â€œè¿æ¥åŒºåŸŸâ€é€‰æ‹©æ–¹å¼ã€‚å¦‚éŸ³é¢‘ä½œä¸ºä¸€ç§ä¿¡å·è¾“å…¥æ–¹å¼ï¼Œä¸€ä¸ªéšå«å•å…ƒæ‰€éœ€è¦è¿æ¥çš„è¾“å…¥å•å…ƒçš„å­é›†ï¼Œå¯èƒ½ä»…ä»…æ˜¯ä¸€æ®µéŸ³é¢‘è¾“å…¥æ‰€å¯¹åº”çš„æŸä¸ªæ—¶é—´æ®µä¸Šçš„ä¿¡å·ã€‚)</p><p>æ¯ä¸ªéšå«å•å…ƒè¿æ¥çš„è¾“å…¥åŒºåŸŸå¤§å°å«rç¥ç»å…ƒçš„<strong>æ„Ÿå—é‡(receptive field)</strong>ã€‚</p><p>ç”±äºå·ç§¯å±‚çš„ç¥ç»å…ƒä¹Ÿæ˜¯ä¸‰ç»´çš„ï¼Œæ‰€ä»¥ä¹Ÿå…·æœ‰æ·±åº¦ã€‚å·ç§¯å±‚çš„å‚æ•°åŒ…å«ä¸€ç³»åˆ—è¿‡æ»¤å™¨ï¼ˆfilterï¼‰ï¼Œæ¯ä¸ªè¿‡æ»¤å™¨è®­ç»ƒä¸€ä¸ªæ·±åº¦ï¼Œæœ‰å‡ ä¸ªè¿‡æ»¤å™¨è¾“å‡ºå•å…ƒå°±å…·æœ‰å¤šå°‘æ·±åº¦ã€‚</p><p>å…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ ·ä¾‹è¾“å…¥å•å…ƒå¤§å°æ˜¯32Ã—32Ã—3, è¾“å‡ºå•å…ƒçš„æ·±åº¦æ˜¯5, å¯¹äºè¾“å‡ºå•å…ƒä¸åŒæ·±åº¦çš„åŒä¸€ä½ç½®ï¼Œä¸è¾“å…¥å›¾ç‰‡è¿æ¥çš„åŒºåŸŸæ˜¯ç›¸åŒçš„ï¼Œä½†æ˜¯å‚æ•°ï¼ˆè¿‡æ»¤å™¨ï¼‰ä¸åŒã€‚</p><p><img src="/images/1457406711273.png"></p><p>è™½ç„¶æ¯ä¸ªè¾“å‡ºå•å…ƒåªæ˜¯è¿æ¥è¾“å…¥çš„ä¸€éƒ¨åˆ†ï¼Œä½†æ˜¯å€¼çš„è®¡ç®—æ–¹æ³•æ˜¯æ²¡æœ‰å˜çš„ï¼Œéƒ½æ˜¯æƒé‡å’Œè¾“å…¥çš„ç‚¹ç§¯ï¼Œç„¶ååŠ ä¸Šåç½®ï¼Œè¿™ç‚¹ä¸æ™®é€šç¥ç»ç½‘ç»œæ˜¯ä¸€æ ·çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p><p><img src="/images/1457407298878.png"></p><p><strong>ç©ºé—´æ’åˆ—ï¼ˆSpatial arrangementï¼‰</strong></p><p>ä¸€ä¸ªè¾“å‡ºå•å…ƒçš„å¤§å°æœ‰ä»¥ä¸‹ä¸‰ä¸ªé‡æ§åˆ¶ï¼š<strong>depth</strong>, <strong>stride</strong> å’Œ <strong>zero-padding</strong>ã€‚</p><ul><li><strong>æ·±åº¦(depth)</strong> : é¡¾åæ€ä¹‰ï¼Œå®ƒæ§åˆ¶è¾“å‡ºå•å…ƒçš„æ·±åº¦ï¼Œä¹Ÿå°±æ˜¯filterçš„ä¸ªæ•°ï¼Œè¿æ¥åŒä¸€å—åŒºåŸŸçš„ç¥ç»å…ƒä¸ªæ•°ã€‚åˆåï¼š<strong>depth column</strong></li><li><strong>æ­¥å¹…(stride)</strong>ï¼šå®ƒæ§åˆ¶åœ¨åŒä¸€æ·±åº¦çš„ç›¸é‚»ä¸¤ä¸ªéšå«å•å…ƒï¼Œä¸ä»–ä»¬ç›¸è¿æ¥çš„è¾“å…¥åŒºåŸŸçš„è·ç¦»ã€‚å¦‚æœæ­¥å¹…å¾ˆå°ï¼ˆæ¯”å¦‚ stride = 1ï¼‰çš„è¯ï¼Œç›¸é‚»éšå«å•å…ƒçš„è¾“å…¥åŒºåŸŸçš„é‡å éƒ¨åˆ†ä¼šå¾ˆå¤š; æ­¥å¹…å¾ˆå¤§åˆ™é‡å åŒºåŸŸå˜å°‘ã€‚</li><li><strong>è¡¥é›¶(zero-padding)</strong> ï¼š æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨è¾“å…¥å•å…ƒå‘¨å›´è¡¥é›¶æ¥æ”¹å˜è¾“å…¥å•å…ƒæ•´ä½“å¤§å°ï¼Œä»è€Œæ§åˆ¶è¾“å‡ºå•å…ƒçš„ç©ºé—´å¤§å°ã€‚</li></ul><p>æˆ‘ä»¬å…ˆå®šä¹‰å‡ ä¸ªç¬¦å·ï¼š</p><ul><li><span class="math inline">\(W\)</span> : è¾“å…¥å•å…ƒçš„å¤§å°ï¼ˆå®½æˆ–é«˜ï¼‰</li><li><span class="math inline">\(F\)</span> : æ„Ÿå—é‡(receptive field)</li><li><span class="math inline">\(S\)</span> : æ­¥å¹…ï¼ˆstrideï¼‰</li><li><span class="math inline">\(P\)</span> : è¡¥é›¶ï¼ˆzero-padding)çš„æ•°é‡</li><li><span class="math inline">\(K\)</span> : æ·±åº¦ï¼Œè¾“å‡ºå•å…ƒçš„æ·±åº¦</li></ul><p>åˆ™å¯ä»¥ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—ä¸€ä¸ªç»´åº¦ï¼ˆå®½æˆ–é«˜ï¼‰å†…ä¸€ä¸ªè¾“å‡ºå•å…ƒé‡Œå¯ä»¥æœ‰å‡ ä¸ªéšè—å•å…ƒï¼š <span class="math display">\[\frac{W - F + 2P}{S} + 1\]</span> å¦‚æœè®¡ç®—ç»“æœä¸æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œåˆ™è¯´æ˜ç°æœ‰å‚æ•°ä¸èƒ½æ­£å¥½é€‚åˆè¾“å…¥ï¼Œæ­¥å¹…ï¼ˆstrideï¼‰è®¾ç½®çš„ä¸åˆé€‚ï¼Œæˆ–è€…éœ€è¦è¡¥é›¶ï¼Œè¯æ˜ç•¥ï¼Œä¸‹é¢ç”¨ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜ä¸€ä¸‹ã€‚</p><p>è¿™æ˜¯ä¸€ä¸ªä¸€ç»´çš„ä¾‹å­ï¼Œå·¦è¾¹æ¨¡å‹è¾“å…¥å•å…ƒæœ‰5ä¸ªï¼Œå³<span class="math inline">\(W = 5\)</span>, è¾¹ç•Œå„è¡¥äº†ä¸€ä¸ªé›¶ï¼Œå³<span class="math inline">\(P = 1\)</span>ï¼Œæ­¥å¹…æ˜¯1ï¼Œ å³<span class="math inline">\(S = 1\)</span>ï¼Œæ„Ÿå—é‡æ˜¯3ï¼Œå› ä¸ºæ¯ä¸ªè¾“å‡ºéšè—å•å…ƒè¿æ¥3ä¸ªè¾“å…¥å•å…ƒï¼Œå³<span class="math inline">\(F = 3\)</span>ï¼Œæ ¹æ®ä¸Šé¢å…¬å¼å¯ä»¥è®¡ç®—å‡ºè¾“å‡ºéšè—å•å…ƒçš„ä¸ªæ•°æ˜¯ï¼š<span class="math inline">\(\frac{5 - 3 + 2}{1} + 1 = 5\)</span>ï¼Œä¸å›¾ç¤ºå»åˆã€‚å³è¾¹é‚£ä¸ªæ¨¡å‹æ˜¯æŠŠæ­¥å¹…å˜ä¸º2ï¼Œå…¶ä½™ä¸å˜ï¼Œå¯ä»¥ç®—å‡ºè¾“å‡ºå¤§å°ä¸ºï¼š<span class="math inline">\(\frac{5 - 3 + 2}{2} + 1 = 3\)</span>ï¼Œä¹Ÿä¸å›¾ç¤ºå»åˆã€‚è‹¥æŠŠæ­¥å¹…æ”¹ä¸º3ï¼Œåˆ™å…¬å¼ä¸èƒ½æ•´é™¤ï¼Œè¯´æ˜æ­¥å¹…ä¸º3ä¸èƒ½æ°å¥½å»åˆè¾“å…¥å•å…ƒå¤§å°ã€‚</p><p><img src="/images/1457416670778.png"></p><p>å¦å¤–ï¼Œç½‘ç»œçš„æƒé‡åœ¨å›¾çš„å³ä¸Šè§’ï¼Œè®¡ç®—æ–¹æ³•å’Œæ™®é€šç¥ç»ç½‘è·¯ä¸€æ ·ã€‚</p><p><strong>å‚æ•°å…±äº«(Parameter Sharing)</strong></p><p>åº”ç”¨å‚æ•°å…±äº«å¯ä»¥å¤§é‡å‡å°‘å‚æ•°æ•°é‡ï¼Œå‚æ•°å…±äº«åŸºäºä¸€ä¸ªå‡è®¾ï¼šå¦‚æœå›¾åƒä¸­çš„ä¸€ç‚¹ï¼ˆx1, y1ï¼‰åŒ…å«çš„ç‰¹å¾å¾ˆé‡è¦ï¼Œé‚£ä¹ˆå®ƒåº”è¯¥å’Œå›¾åƒä¸­çš„å¦ä¸€ç‚¹ï¼ˆx2, y2ï¼‰ä¸€æ ·é‡è¦ã€‚æ¢ç§è¯´æ³•ï¼Œæˆ‘ä»¬æŠŠåŒä¸€æ·±åº¦çš„å¹³é¢å«åš<strong>æ·±åº¦åˆ‡ç‰‡(depth slice)</strong>ï¼ˆ(e.g. a volume of size [55x55x96] has 96 depth slices, each of size [55x55])ï¼‰ï¼Œé‚£ä¹ˆåŒä¸€ä¸ªåˆ‡ç‰‡åº”è¯¥å…±äº«åŒä¸€ç»„æƒé‡å’Œåç½®ã€‚æˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•æ¥å­¦ä¹ è¿™äº›æƒå€¼ï¼Œåªéœ€è¦å¯¹åŸå§‹ç®—æ³•åšä¸€äº›å°çš„æ”¹åŠ¨ï¼Œ è¿™é‡Œå…±äº«æƒå€¼çš„æ¢¯åº¦æ˜¯æ‰€æœ‰å…±äº«å‚æ•°çš„æ¢¯åº¦çš„æ€»å’Œã€‚</p><p>æˆ‘ä»¬ä¸ç¦ä¼šé—®ä¸ºä»€ä¹ˆè¦æƒé‡å…±äº«å‘¢ï¼Ÿä¸€æ–¹é¢ï¼Œé‡å¤å•å…ƒèƒ½å¤Ÿå¯¹ç‰¹å¾è¿›è¡Œè¯†åˆ«ï¼Œè€Œä¸è€ƒè™‘å®ƒåœ¨å¯è§†åŸŸä¸­çš„ä½ç½®ã€‚å¦ä¸€æ–¹é¢ï¼Œæƒå€¼å…±äº«ä½¿å¾—æˆ‘ä»¬èƒ½æ›´æœ‰æ•ˆçš„è¿›è¡Œç‰¹å¾æŠ½å–ï¼Œå› ä¸ºå®ƒæå¤§çš„å‡å°‘äº†éœ€è¦å­¦ä¹ çš„è‡ªç”±å˜é‡çš„ä¸ªæ•°ã€‚é€šè¿‡æ§åˆ¶æ¨¡å‹çš„è§„æ¨¡ï¼Œå·ç§¯ç½‘ç»œå¯¹è§†è§‰é—®é¢˜å¯ä»¥å…·æœ‰å¾ˆå¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚</p><p><strong>å·ç§¯ï¼ˆConvolutionï¼‰</strong></p><p>å¦‚æœåº”ç”¨å‚æ•°å…±äº«çš„è¯ï¼Œå®é™…ä¸Šæ¯ä¸€å±‚è®¡ç®—çš„æ“ä½œå°±æ˜¯è¾“å…¥å±‚å’Œæƒé‡çš„<strong>å·ç§¯</strong>ï¼è¿™ä¹Ÿå°±æ˜¯å·ç§¯ç¥ç»ç½‘ç»œåå­—çš„ç”±æ¥ã€‚</p><p>å…ˆæŠ›å¼€å·ç§¯è¿™ä¸ªæ¦‚å¿µä¸ç®¡ã€‚ä¸ºç®€ä¾¿èµ·è§ï¼Œè€ƒè™‘ä¸€ä¸ªå¤§å°ä¸º5Ã—5çš„å›¾åƒï¼Œå’Œä¸€ä¸ª3Ã—3çš„å·ç§¯æ ¸ã€‚è¿™é‡Œçš„å·ç§¯æ ¸å…±æœ‰9ä¸ªå‚æ•°ï¼Œå°±è®°ä¸º <span class="math inline">\(Î˜=[Î¸_{ij}]_{3Ã—3}\)</span> å§ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œå·ç§¯æ ¸å®é™…ä¸Šæœ‰9ä¸ªç¥ç»å…ƒï¼Œä»–ä»¬çš„è¾“å‡ºåˆç»„æˆä¸€ä¸ª3Ã—3çš„çŸ©é˜µï¼Œç§°ä¸ºç‰¹å¾å›¾ã€‚ç¬¬ä¸€ä¸ªç¥ç»å…ƒè¿æ¥åˆ°å›¾åƒçš„ç¬¬ä¸€ä¸ª3Ã—3çš„å±€éƒ¨ï¼Œç¬¬äºŒä¸ªç¥ç»å…ƒåˆ™è¿æ¥åˆ°ç¬¬äºŒä¸ªå±€éƒ¨ï¼ˆæ³¨æ„ï¼Œæœ‰é‡å ï¼å°±è·Ÿä½ çš„ç›®å…‰æ‰«è§†æ—¶ä¹Ÿæ˜¯è¿ç»­æ‰«è§†ä¸€æ ·ï¼‰ã€‚å…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><p><img src="/images/1457419579658.png"></p><p>å›¾çš„ä¸Šæ–¹æ˜¯ç¬¬ä¸€ä¸ªç¥ç»å…ƒçš„è¾“å‡ºï¼Œä¸‹æ–¹æ˜¯ç¬¬äºŒä¸ªç¥ç»å…ƒçš„è¾“å‡ºã€‚æ¯ä¸ªç¥ç»å…ƒçš„è¿ç®—ä¾æ—§æ˜¯</p><p><span class="math display">\[f(x)=act(\sum_{i,j}^{n}Î¸_{(nâˆ’i)(nâˆ’j)}x_{ij}+b)\]</span></p><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¹³æ—¶æˆ‘ä»¬åœ¨è¿ç®—æ—¶ï¼Œä¹ æƒ¯ä½¿ç”¨ <span class="math inline">\(Î¸_{ij}x_{ij}\)</span> è¿™ç§å†™æ³•ï¼Œä½†äº‹å®ä¸Šï¼Œæˆ‘ä»¬è¿™é‡Œä½¿ç”¨çš„æ˜¯ <span class="math inline">\(Î¸_{(nâˆ’i)(nâˆ’j)}x_{ij}\)</span>ã€‚</p><p>ç°åœ¨æˆ‘ä»¬å›å¿†ä¸€ä¸‹ç¦»æ•£å·ç§¯è¿ç®—ã€‚å‡è®¾æœ‰äºŒç»´ç¦»æ•£å‡½æ•° <span class="math inline">\(f(x,y)\)</span> , <span class="math inline">\(g(x,y)\)</span> ï¼Œ é‚£ä¹ˆå®ƒä»¬çš„å·ç§¯å®šä¹‰ä¸º <span class="math display">\[f(m,n)âˆ—g(m,n)=\sum_{u}^{âˆ}\sum_{v}^{âˆ}f(u,v)g(mâˆ’u,nâˆ’v)\]</span></p><p>ç°åœ¨å‘ç°äº†å§ï¼ä¸Šé¢ä¾‹å­ä¸­çš„9ä¸ªç¥ç»å…ƒå‡å®Œæˆè¾“å‡ºåï¼Œå®é™…ä¸Šç­‰ä»·äºå›¾åƒå’Œå·ç§¯æ ¸çš„å·ç§¯æ“ä½œï¼</p><p><strong>Numpy examples</strong></p><p>ä¸‹é¢ç”¨numpyçš„ä»£ç å…·ä½“çš„è¯´æ˜ä¸€ä¸‹ä¸Šé¢çš„æ¦‚å¿µå’Œå…¬å¼ç­‰ã€‚</p><p>å‡è®¾è¾“å…¥å­˜å‚¨åœ¨ä¸€ä¸ªnumpy array <code>X</code>é‡Œï¼Œé‚£ä¹ˆï¼š * ä½äº (x, y) çš„ depth column æ˜¯ <code>X[x, y, :]</code> * æ·±åº¦ä¸º d çš„ depth slice æ˜¯ <code>X[:, :, d]</code></p><p>å‡è®¾Xçš„å¤§å°æ˜¯<code>X.shape: (11,11,4)</code>ï¼Œå¹¶ä¸”ä¸ç”¨è¡¥é›¶ï¼ˆP ï¼ 0ï¼‰ï¼Œè¿‡æ»¤å™¨ï¼ˆæ„Ÿå—é‡ï¼‰å¤§å°F ï¼ 5ï¼Œæ­¥å¹…ä¸º2ï¼ˆSï¼ 2ï¼‰ã€‚é‚£ä¹ˆè¾“å‡ºå•å…ƒçš„ç©ºé—´å¤§å°åº”è¯¥ä¸º (11 - 5) / 2 + 1 = 4ï¼Œå³å®½å’Œé«˜éƒ½ä¸º4 ã€‚å‡è®¾è¾“å‡ºå­˜å‚¨åœ¨ <code>V</code> ä¸­ï¼Œé‚£ä¹ˆå®ƒçš„è®¡ç®—æ–¹å¼åº”è¯¥ä¸ºï¼š</p><ul><li><code>V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0</code></li><li><code>V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0</code></li><li><code>V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0</code></li><li><code>V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0</code></li><li></li><li><code>V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1</code></li><li><code>V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1</code></li><li><code>V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1</code></li><li><code>V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1</code></li><li><code>V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1</code></li><li><code>V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1</code></li></ul><p>æ³¨æ„åœ¨numpyä¸­ <code>*</code> è¡¨ç¤ºä¸¤ä¸ªæ•°ç»„å¯¹åº”å…ƒç´ ç›¸ä¹˜ã€‚</p><p><strong>å·ç§¯å±‚æ€»ç»“(Summary)</strong></p><ul><li>æ¥æ”¶ä¸‰ç»´è¾“å…¥ <span class="math inline">\(W_1 * H_1 * D_1\)</span></li><li>éœ€è¦ç»™å‡º4ä¸ªå‚æ•°ï¼ˆhyperparametersï¼‰ï¼š<ul><li>Number of filters <span class="math inline">\(K\)</span>,</li><li>their spatial extent <span class="math inline">\(F\)</span>,</li><li>the stride <span class="math inline">\(S\)</span>,</li><li>the amount of zero padding <span class="math inline">\(P\)</span>.</li></ul></li><li>è¾“å‡ºä¸€ä¸ªä¸‰ç»´å•å…ƒ <span class="math inline">\(W_2 * H_2 * D_2\)</span>ï¼Œå…¶ä¸­ï¼š<ul><li><span class="math inline">\(W_2 = \frac{W_1 - F + 2P}{S} + 1\)</span></li><li><span class="math inline">\(H_2 = \frac{H_1 - F + 2P}{S} + 1\)</span></li><li><span class="math inline">\(D_2 = K\)</span><br></li></ul></li><li>åº”ç”¨æƒå€¼å…±äº«ï¼Œæ¯ä¸ªfilterä¼šäº§ç”Ÿ<span class="math inline">\(F * F * D_1\)</span> ä¸ªæƒé‡ï¼Œæ€»å…± $(F * F * D_1) * K $ ä¸ªæƒé‡å’Œ <span class="math inline">\(K\)</span> ä¸ªåç½®ã€‚</li><li>åœ¨è¾“å‡ºå•å…ƒï¼Œç¬¬dä¸ªæ·±åº¦åˆ‡ç‰‡çš„ç»“æœæ˜¯ç”±ç¬¬dä¸ªfilter å’Œè¾“å…¥å•å…ƒåšå·ç§¯è¿ç®—ï¼Œç„¶åå†åŠ ä¸Šåç½®è€Œæ¥ã€‚</li></ul><h2><span id="æ± åŒ–å±‚pooling-layer">æ± åŒ–å±‚(Pooling Layer)</span></h2><p><strong>æ± åŒ–ï¼ˆpoolï¼‰</strong>å³<strong>ä¸‹é‡‡æ ·ï¼ˆdownsamplesï¼‰</strong>ï¼Œç›®çš„æ˜¯ä¸ºäº†å‡å°‘ç‰¹å¾å›¾ã€‚æ± åŒ–æ“ä½œå¯¹æ¯ä¸ªæ·±åº¦åˆ‡ç‰‡ç‹¬ç«‹ï¼Œè§„æ¨¡ä¸€èˆ¬ä¸º 2ï¼Š2ï¼Œç›¸å¯¹äºå·ç§¯å±‚è¿›è¡Œå·ç§¯è¿ç®—ï¼Œæ± åŒ–å±‚è¿›è¡Œçš„è¿ç®—ä¸€èˆ¬æœ‰ä»¥ä¸‹å‡ ç§ï¼š * æœ€å¤§æ± åŒ–ï¼ˆMax Poolingï¼‰ã€‚å–4ä¸ªç‚¹çš„æœ€å¤§å€¼ã€‚è¿™æ˜¯æœ€å¸¸ç”¨çš„æ± åŒ–æ–¹æ³•ã€‚ * å‡å€¼æ± åŒ–ï¼ˆMean Poolingï¼‰ã€‚å–4ä¸ªç‚¹çš„å‡å€¼ã€‚ * é«˜æ–¯æ± åŒ–ã€‚å€Ÿé‰´é«˜æ–¯æ¨¡ç³Šçš„æ–¹æ³•ã€‚ä¸å¸¸ç”¨ã€‚ * å¯è®­ç»ƒæ± åŒ–ã€‚è®­ç»ƒå‡½æ•° ff ï¼Œæ¥å—4ä¸ªç‚¹ä¸ºè¾“å…¥ï¼Œå‡ºå…¥1ä¸ªç‚¹ã€‚ä¸å¸¸ç”¨ã€‚</p><p>æœ€å¸¸è§çš„æ± åŒ–å±‚æ˜¯è§„æ¨¡ä¸º2*2ï¼Œ æ­¥å¹…ä¸º2ï¼Œå¯¹è¾“å…¥çš„æ¯ä¸ªæ·±åº¦åˆ‡ç‰‡è¿›è¡Œä¸‹é‡‡æ ·ã€‚æ¯ä¸ªMAXæ“ä½œå¯¹å››ä¸ªæ•°è¿›è¡Œï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š <img src="/images/1457434159635.png"></p><p>æ± åŒ–æ“ä½œå°†ä¿å­˜<strong>æ·±åº¦å¤§å°ä¸å˜</strong>ã€‚</p><p>å¦‚æœæ± åŒ–å±‚çš„è¾“å…¥å•å…ƒå¤§å°ä¸æ˜¯äºŒçš„æ•´æ•°å€ï¼Œä¸€èˆ¬é‡‡å–è¾¹ç¼˜è¡¥é›¶ï¼ˆzero-paddingï¼‰çš„æ–¹å¼è¡¥æˆ2çš„å€æ•°ï¼Œç„¶åå†æ± åŒ–ã€‚</p><p><strong>æ± åŒ–å±‚æ€»ç»“(Summary)</strong></p><ul><li>æ¥æ”¶å•å…ƒå¤§å°ä¸ºï¼š<span class="math inline">\(W_1 * H_1 * D_1\)</span></li><li>éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼ˆhyperparametersï¼‰ï¼š<ul><li>their spatial extent <span class="math inline">\(F\)</span>,</li><li>the stride <span class="math inline">\(S\)</span>,</li></ul></li><li>è¾“å‡ºå¤§å°ï¼š<span class="math inline">\(W_2 * H_2 * D_2\)</span>ï¼Œå…¶ä¸­ï¼š<ul><li><span class="math inline">\(W_2=\frac{W_1âˆ’F}{S}\)</span></li><li><span class="math inline">\(H_2=\frac{H_1âˆ’F}{S}+1\)</span></li><li><span class="math inline">\(D_2=D_1\)</span></li></ul></li><li>ä¸éœ€è¦å¼•å…¥æ–°æƒé‡</li></ul><h2><span id="å…¨è¿æ¥å±‚fully-connected-layer">å…¨è¿æ¥å±‚ï¼ˆFully-connected layerï¼‰</span></h2><p>å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚å¯ä»¥ç›¸äº’è½¬æ¢ï¼š * å¯¹äºä»»æ„ä¸€ä¸ªå·ç§¯å±‚ï¼Œè¦æŠŠå®ƒå˜æˆå…¨è¿æ¥å±‚åªéœ€è¦æŠŠæƒé‡å˜æˆä¸€ä¸ªå·¨å¤§çš„çŸ©é˜µï¼Œå…¶ä¸­å¤§éƒ¨åˆ†éƒ½æ˜¯0 é™¤äº†ä¸€äº›ç‰¹å®šåŒºå—ï¼ˆå› ä¸ºå±€éƒ¨æ„ŸçŸ¥ï¼‰ï¼Œè€Œä¸”å¥½å¤šåŒºå—çš„æƒå€¼è¿˜ç›¸åŒï¼ˆç”±äºæƒé‡å…±äº«ï¼‰ã€‚ * ç›¸ååœ°ï¼Œå¯¹äºä»»ä½•ä¸€ä¸ªå…¨è¿æ¥å±‚ä¹Ÿå¯ä»¥å˜ä¸ºå·ç§¯å±‚ã€‚æ¯”å¦‚ï¼Œä¸€ä¸ª<span class="math inline">\(K ï¼ 4096\)</span> çš„å…¨è¿æ¥å±‚ï¼Œè¾“å…¥å±‚å¤§å°ä¸º <span class="math inline">\(7*7*512\)</span>ï¼Œå®ƒå¯ä»¥ç­‰æ•ˆä¸ºä¸€ä¸ª <span class="math inline">\(F=7,\ P=0,\ S=1,\ K=4096\)</span> çš„å·ç§¯å±‚ã€‚æ¢è¨€ä¹‹ï¼Œæˆ‘ä»¬æŠŠ filter size æ­£å¥½è®¾ç½®ä¸ºæ•´ä¸ªè¾“å…¥å±‚å¤§å°ã€‚</p><h1><span id="å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„">å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„</span></h1><h2><span id="layer-patterns">Layer Patterns</span></h2><p>å¸¸è§çš„å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„æ˜¯è¿™æ ·çš„ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</span><br></pre></td></tr></table></figure></p><p>å †å å‡ ä¸ªå·ç§¯å’Œæ•´æµå±‚ï¼Œå†åŠ ä¸€ä¸ªæ± åŒ–å±‚ï¼Œé‡å¤è¿™ä¸ªæ¨¡å¼çŸ¥é“å›¾ç‰‡å·²ç»è¢«åˆå¹¶å¾—æ¯”è¾ƒå°äº†ï¼Œç„¶åå†ç”¨å…¨è¿æ¥å±‚æ§åˆ¶è¾“å‡ºã€‚</p><p>ä¸Šè¿°è¡¨è¾¾å¼ä¸­ <code>?</code> æ„å‘³ç€0æ¬¡æˆ–1æ¬¡ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼š<code>N &gt;= 0 &amp;&amp; N &lt;= 3</code>, <code>M &gt;= 0</code>, <code>K &gt;= 0 &amp;&amp; K &lt; 3</code>ã€‚</p><p>æ¯”å¦‚ä½ å¯ä»¥ç»„åˆå‡ºä»¥ä¸‹å‡ ç§æ¨¡å¼ï¼š * <code>INPUT -&gt; FC</code>, å®ç°äº†ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œ è¿™é‡Œ <code>N = M = K = 0</code> * <code>INPUT -&gt; CONV -&gt; RELU -&gt; FC</code> * <code>INPUT -&gt; [CONV -&gt; RELU -&gt; POOL]*2 -&gt; FC -&gt; RELU -&gt; FC</code>. Here we see that there is a single <code>CONV</code> layer between every <code>POOL</code> layer. * <code>INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]*3 -&gt; [FC -&gt; RELU]*2 -&gt; FC</code> Here we see two CONV layers stacked before every POOL layer. This is generally a good idea for larger and deeper networks, because multiple stacked CONV layers can develop more complex features of the input volume before the destructive pooling operation.</p><h2><span id="layer-sizing-patterns">Layer Sizing Patterns</span></h2><ul><li><strong>Input layer</strong> : åº”è¯¥æ˜¯2çš„æ•´æ•°æ¬¡å¹‚ã€‚æ¯”å¦‚32ï¼Œ64ï¼Œ 128ç­‰ã€‚</li><li><strong>Conv Layer</strong> : ä½¿ç”¨å°çš„è¿‡æ»¤å™¨ï¼ˆfilterï¼‰ï¼Œ$ F = 3Â orÂ F = 5$, æ­¥å¹… <span class="math inline">\(S=1\)</span>ï¼Œå¦‚æœä¸èƒ½æ°å¥½æ‹Ÿåˆè¾“å…¥å±‚ï¼Œè¿˜è¦è¾¹ç¼˜è¡¥é›¶ã€‚å¦‚æœä½¿ç”¨ <span class="math inline">\(F = 3,\ P = 1\)</span>ï¼Œé‚£ä¹ˆè¾“å‡ºå¤§å°å°†ä¸è¾“å…¥ä¸€æ ·ã€‚å¦‚æœç”¨æ›´å¤§çš„è¿‡æ»¤å™¨ï¼ˆæ¯”å¦‚7*7ï¼‰ï¼Œä¸€èˆ¬åªä¼šåœ¨ç´§æŒ¨ç€åŸå§‹è¾“å…¥å›¾ç‰‡çš„å·ç§¯å±‚æ‰ä¼šçœ‹åˆ°ã€‚</li><li><strong>Pool Layer</strong> : <span class="math inline">\(F = 2,\ S = 2\)</span></li></ul><h2><span id="case-studies">Case Studies</span></h2><p>å¤§ç‰›ä»¬æ„å»ºçš„ç½‘ç»œ</p><ul><li><strong>LeNet</strong>. The first successful applications of Convolutional Networks were developed by Yann LeCun in 1990's. Of these, the best known is the <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target="_blank" rel="noopener">LeNet</a> architecture that was used to read zip codes, digits, etc.</li><li><strong>AlexNet</strong>. The first work that popularized Convolutional Networks in Computer Vision was the <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="noopener">AlexNet</a>, developed by Alex Krizhevsky, Ilya Sutskever and Geoff Hinton. The AlexNet was submitted to the <a href="http://www.image-net.org/challenges/LSVRC/2014/" target="_blank" rel="noopener">ImageNet ILSVRC challenge</a> in 2012 and significantly outperformed the second runner-up (top 5 error of 16% compared to runner-up with 26% error). The Network had a similar architecture basic as LeNet, but was deeper, bigger, and featured Convolutional Layers stacked on top of each other (previously it was common to only have a single CONV layer immediately followed by a POOL layer).</li><li><strong>ZF Net</strong>. The ILSVRC 2013 winner was a Convolutional Network from Matthew Zeiler and Rob Fergus. It became known as the <a href="http://arxiv.org/abs/1311.2901" target="_blank" rel="noopener">ZFNet</a> (short for Zeiler &amp; Fergus Net). It was an improvement on AlexNet by tweaking the architecture hyperparameters, in particular by expanding the size of the middle convolutional layers.</li><li><strong>GoogLeNet</strong>. The ILSVRC 2014 winner was a Convolutional Network from <a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Szegedy et al.</a> from Google. Its main contribution was the development of an Inception Module that dramatically reduced the number of parameters in the network (4M, compared to AlexNet with 60M). Additionally, this paper uses Average Pooling instead of Fully Connected layers at the top of the ConvNet, eliminating a large amount of parameters that do not seem to matter much.</li><li><strong>VGGNet</strong>. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the <a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="noopener">VGGNet</a>. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end. It was later found that despite its slightly weaker classification performance, the VGG ConvNet features outperform those of GoogLeNet in multiple transfer learning tasks. Hence, the VGG network is currently the most preferred choice in the community when extracting CNN features from images. In particular, their <a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="noopener">pretrained model</a> is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M).</li><li><strong>ResNet</strong>. <a href="http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Residual Network</a> developed by Kaiming He et al. was the winner of ILSVRC 2015. It features an interesting architecture with special skip connections and features heavy use of batch normalization. The architecture is also missing fully connected layers at the end of the network. The reader is also referred to Kaiming's presentation (<a href="https://www.youtube.com/watch?v=1PGLj-uKT1w" target="_blank" rel="noopener">video</a>, <a href="http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf" target="_blank" rel="noopener">slides</a>), and some <a href="https://github.com/gcr/torch-residual-networks" target="_blank" rel="noopener">recent experiments</a> that reproduce these networks in Torch.</li></ul><h1><span id="å‚è€ƒ">å‚è€ƒ</span></h1><p><a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">CS231n: Convolutional Neural Networks for Visual Recognition</a> <a href="https://www.wikiwand.com/zh-hans/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" target="_blank" rel="noopener">å·ç§¯ç¥ç»ç½‘ç»œ-ç»´åŸºç™¾ç§‘</a> <a href="http://deeplearning.stanford.edu/wiki/index.php/%E5%8D%B7%E7%A7%AF%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96" target="_blank" rel="noopener">å·ç§¯ç‰¹å¾æå–</a> <a href="http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi" target="_blank" rel="noopener">å·ç§¯ç¥ç»ç½‘ç»œå…¨é¢è§£æ</a></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>åˆè¯†SVM</title>
      <link href="/2016/03/03/Support%20Vector%20Machines%20(SVMs)/"/>
      <url>/2016/03/03/Support%20Vector%20Machines%20(SVMs)/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#optimization-objective">Optimization Objective</a></li><li><a href="#large-margin-intuition">Large Margin Intuition</a></li><li><a href="#mathematics-behind-large-margin-classification">Mathematics Behind Large Margin Classification</a></li><li><a href="#kernels-i">Kernels I</a></li><li><a href="#kernels-ii">Kernels II</a></li><li><a href="#using-an-svm">Using An SVM</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="optimization-objective">Optimization Objective</span></h2><p>The Support Vector Machine (SVM) is yet another type of supervised machine learning algorithm. It is sometimes cleaner and more powerful.</p><p>Recall that in logistic regression, we use the following rules: * if <span class="math inline">\(y=1\)</span>, then <span class="math inline">\(h_Î¸(x)â‰ˆ1\)</span> and <span class="math inline">\(Î˜^Txâ‰«0\)</span> * if <span class="math inline">\(y=0\)</span>, then <span class="math inline">\(h_Î¸(x)â‰ˆ0\)</span> and <span class="math inline">\(Î˜^Txâ‰ª0\)</span></p><p>Recall the cost function for (unregularized) logistic regression:</p><p><span class="math display">\[J(Î¸)=\frac{1}{m}\sum_{i=1}^mâˆ’y^{(i)}\log(h_Î¸(x^{(i)}))âˆ’(1âˆ’y^{(i)})\log(1âˆ’h_Î¸(x^{(i)}))\]</span> <span class="math display">\[=\frac{1}{m}\sum_{i=1}^mâˆ’y^{(i)}\log(\frac{1}{1+e^{âˆ’Î¸^Tx^{(i)}}})âˆ’(1âˆ’y^{(i)})\log(1âˆ’\frac{1}{1+e^{âˆ’Î¸^Tx^{(i)}}})\]</span></p><p>To make a support vector machine, we will modify the first term of the cost function <span class="math inline">\((âˆ’\log(h_Î¸(x))=âˆ’\log(\frac{1}{1+e^{âˆ’Î¸^Tx}}))\)</span> so that when <span class="math inline">\(Î¸^Tx\)</span> (from now on, we shall refer to this as <span class="math inline">\(z\)</span>) is greater than 1, it outputs 0. Furthermore, for values of <span class="math inline">\(z\)</span> less than 1, we shall use a straight decreasing line instead of the sigmoid curve.(In the literature, this is called a hinge loss function.)</p><p><img src="/images/1456900464932.png"></p><p>Similarly, we modify the second term of the cost function <span class="math inline">\((âˆ’\log(1âˆ’h_Î¸(x))=âˆ’log(1âˆ’\frac{1}{1+e^{âˆ’Î¸^Tx}}))\)</span> so that when <span class="math inline">\(z\)</span> is less than -1, it outputs 0. We also modify it so that for values of <span class="math inline">\(z\)</span> greater than -1, we use a straight increasing line instead of the sigmoid curve.</p><p><img src="/images/1456900546259.png"></p><p>We shall denote these as <span class="math inline">\(\text{cost}_1(z)\)</span> and <span class="math inline">\(\text{cost}_0(z)\)</span> (respectively, note that <span class="math inline">\(\text{cost}_1(z)\)</span> is the cost for classifying when y=1, and <span class="math inline">\(\text{cost}_0(z)\)</span> is the cost for classifying when <span class="math inline">\(y=0\)</span>), and we may define them as follows (where k is an arbitrary constant defining the magnitude(å¤§å°) of the slope of the line): <span class="math display">\[z = \theta^Tx\]</span> <span class="math display">\[\text{cost}_0(z) = \max(0, k(1+z))\]</span> <span class="math display">\[\text{cost}_1(z) = \max(0, k(1-z))\]</span></p><p>Recall the full cost function from (regularized) logistic regression:</p><p><span class="math display">\[ J(\theta) = \frac{1}{m} \sum_{i=1}^m y^{(i)}(-\log(h_\theta(x^{(i)}))) + (1 - y^{(i)})(-\log(1 - h_\theta(x^{(i)}))) + \dfrac{\lambda}{2m}\sum_{j=1}^n \Theta^2_j \]</span></p><p>Note that the negative sign has been distributed into the sum in the above equation.</p><p>We may transform this into the cost function for support vector machines by substituting <span class="math inline">\(\text{cost}_0(z)\)</span> and <span class="math inline">\(\text{cost}_1(z)\)</span>:</p><p><span class="math display">\[ J(\theta) = \frac{1}{m} \sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{\lambda}{2m}\sum_{j=1}^n \Theta^2_j \]</span></p><p>We can optimize this a bit by multiplying this by <span class="math inline">\(m\)</span> (thus removing the <span class="math inline">\(m\)</span> factor in the denominators). Note that this does not affect our optimization, since we're simply multiplying our cost function by a positive constant (for example, minimizing <span class="math inline">\((u-5)^2 + 1\)</span> gives us 5; multiplying it by 10 to make it <span class="math inline">\(10(u-5)^2 + 10\)</span> still gives us 5 when minimized). <span class="math display">\[ J(\theta) = \sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{\lambda}{2}\sum_{j=1}^n \Theta^2_j \]</span></p><p>Furthermore, convention dictates that we regularize using a factor <span class="math inline">\(C\)</span>, instead of <span class="math inline">\(\lambda\)</span>, like so: <span class="math display">\[ J(\theta) = C\sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \]</span></p><p>This is equivalent to multiplying the equation by <span class="math inline">\(C = \dfrac{1}{\lambda}\)</span>, and thus results in the same values when optimized. Now, when we wish to regularize more (that is, reduce overfitting), we decrease <span class="math inline">\(C\)</span>, and when we wish to regularize less (that is, reduce underfitting), we increase <span class="math inline">\(C\)</span>.</p><p>Finally, note that the hypothesis of the Support Vector Machine is not interpreted as the probability of <span class="math inline">\(y\)</span> being 1 or 0 (as it is for the hypothesis of logistic regression). Instead, it outputs either 1 or 0. (In technical terms, it is a discriminant function.)</p><p><span class="math display">\[ h_\theta(x) = \begin{cases} 1 &amp; \text{if} \ \Theta^Tx \geq 0 \\ 0 &amp; \text{otherwise} \end{cases} \]</span></p><h2><span id="large-margin-intuition">Large Margin Intuition</span></h2><p>A useful way to think about Support Vector Machines is to think of them as <strong>Large Margin Classifiers</strong>. * If <span class="math inline">\(y = 1\)</span>, we want <span class="math inline">\(\Theta^Tx \geq 1\)</span> (not just <span class="math inline">\(\geq 0\)</span>) * If <span class="math inline">\(y = 0\)</span>, we want <span class="math inline">\(\Theta^Tx \leq -1\)</span> (not just <span class="math inline">\(&lt; 0\)</span>)</p><p>Now when we set our constant <span class="math inline">\(C\)</span> to a very large value (e.g. 100,000), our optimizing function will constrain(å¼ºè¿«) <span class="math inline">\(\Theta\)</span> such that the equation <span class="math inline">\(A\)</span> (the summation of the cost of each example) equals 0. We impose(å¼ºåŠ ) the following constraints on <span class="math inline">\(\Theta\)</span>:</p><p><span class="math display">\[ \Theta^Tx \geq 1\ if\ y = 1\ and\ \Theta^Tx \leq -1\ if\ y=0 \]</span></p><p>If <span class="math inline">\(C\)</span> is very large, we must choose <span class="math inline">\(\Theta\)</span> parameters such that: <span class="math display">\[ \sum_{i=1}^m y^{(i)}\text{cost}_1(\Theta^Tx) + (1 - y^{(i)})\text{cost}_0(\Theta^Tx) = 0 \]</span></p><p>This reduces our cost function to: <span class="math display">\[ \large \begin{align*} J(\theta) = C \cdot 0 + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \newline = \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \end{align*} \]</span></p><p>Recall the decision boundary from logistic regression (the line separating the positive and negative examples). In SVMs, the decision boundary has the special property that it is <strong>as far away as possible</strong> from both the positive and the negative examples.</p><p>The distance of the decision boundary to the nearest example is called the margin. Since SVMs maximize this margin, it is often called a Large Margin Classifier.</p><p>The SVM will separate the negative and positive examples by a <strong>large margin</strong>.</p><p>This large margin is only achieved when <span class="math inline">\(C\)</span> is very large.</p><p>Data is linearly separable when a straight line can separate the positive and negative examples.</p><p>If we have outlier examples that we don't want to affect the decision boundary, then we can reduce <span class="math inline">\(C\)</span>.</p><p>Increasing and decreasing <span class="math inline">\(C\)</span> is similar to respectively decreasing and increasing <span class="math inline">\(\lambda\)</span>, and can simplify our decision boundary.</p><h2><span id="mathematics-behind-large-margin-classification">Mathematics Behind Large Margin Classification</span></h2><p><strong>Vector Inner Product</strong></p><p>Say we have two vectors, <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>: <span class="math display">\[ \begin{align*} u = \begin{bmatrix} u_1 \newline u_2 \end{bmatrix} &amp; v = \begin{bmatrix} v_1 \newline v_2 \end{bmatrix} \end{align*} \]</span></p><p>The length of vector <span class="math inline">\(v\)</span> is denoted <span class="math inline">\(||v||\)</span>, and it describes the line on a graph from origin (0,0) to <span class="math inline">\((v_1,v_2)\)</span>.</p><p>The length of vector <span class="math inline">\(v\)</span> can be calculated with <span class="math inline">\(\sqrt{v_1^2 + v_2^2}\)</span> by the Pythagorean theorem(å‹¾è‚¡å®šç†).</p><p>The projection(æŠ•å½±) of vector <span class="math inline">\(v\)</span> onto vector <span class="math inline">\(u\)</span> is found by taking a right angle from <span class="math inline">\(u\)</span> to the end of <span class="math inline">\(v\)</span>, creating a right triangle.</p><ul><li>$p = $ length of projection of <span class="math inline">\(v\)</span> onto the vector <span class="math inline">\(u\)</span>.</li><li><span class="math inline">\(u^Tv= p \cdot ||u||\)</span></li></ul><p>Note that $ u^Tv = ||u|| ||v|| $ where $ $ is the angle between <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>. Also, $ p = ||v|| $. If you substitute <span class="math inline">\(p\)</span> for $ ||v|| $, you get <span class="math inline">\(u^Tv= p \cdot ||u||\)</span>.</p><p>So the product <span class="math inline">\(u^Tv\)</span> is equal to the length of the projection times the length of vector <span class="math inline">\(u\)</span>.</p><p>In our example, since <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are vectors of the same length, <span class="math inline">\(u^Tv = v^Tu\)</span>. <span class="math display">\[u^Tv = v^Tu = p \cdot ||u|| = u_1v_1 + u_2v_2 \]</span></p><p>If the angle between the lines for <span class="math inline">\(v\)</span> and <span class="math inline">\(u\)</span> is greater than 90 degrees, then the projection <span class="math inline">\(p\)</span> will be negative. <span class="math display">\[ \begin{align*} &amp;min_\Theta \dfrac{1}{2}\sum_{j=1}^n \Theta_j^2 \newline &amp;= \dfrac{1}{2}(\Theta_1^2 + \Theta_2^2 + \dots + \Theta_n^2) \newline &amp;= \dfrac{1}{2}(\sqrt{\Theta_1^2 + \Theta_2^2 + \dots + \Theta_n^2})^2 \newline &amp;= \dfrac{1}{2}||\Theta ||^2 \newline \end{align*} \]</span></p><p>We can use the same rules to rewrite <span class="math inline">\(\Theta^Tx^{(i)}\)</span>:</p><p><span class="math display">\[ \Theta^Tx^{(i)} = p^{(i)} \cdot ||\Theta || = \Theta_1x_1^{(i)} + \Theta_2x_2^{(i)} + \dots + \Theta_nx_n^{(i)} \]</span></p><p>So we now have a new optimization objective by substituting <span class="math inline">\(p^{(i)} \cdot ||\Theta ||\)</span> in for <span class="math inline">\(\Theta^Tx^{(i)}\)</span>: * If <span class="math inline">\(y = 1\)</span>, we want <span class="math inline">\(p^{(i)} \cdot ||\Theta || \geq 1\)</span> * If <span class="math inline">\(y = 0\)</span>, we want <span class="math inline">\(p^{(i)} \cdot ||\Theta || \leq -1\)</span></p><p>The reason this causes a &quot;large margin&quot; is because: the vector for $$ is perpendicular(å‚ç›´çš„ã€æ­£äº¤çš„) to the decision boundary. In order for our optimization objective (above) to hold true, we need the absolute value of our projections <span class="math inline">\(p^{(i)}\)</span> to be as large as possible.</p><p>If <span class="math inline">\(\Theta_0 = 0\)</span>, then all our decision boundaries will intersect (0,0). If $ _0 0 $, the support vector machine will still find a large margin for the decision boundary.</p><h2><span id="kernels-i">Kernels I</span></h2><p>Kernels allow us to make complex, non-linear classifiers using Support Vector Machines.</p><p>Given <span class="math inline">\(x\)</span>, compute new feature depending on proximity(æ¥è¿‘åº¦) to landmarks <span class="math inline">\(l^{(1)},\ l^{(2)},\ l^{(3)}\)</span>.</p><p>To do this, we find the &quot;similarity&quot; of <span class="math inline">\(x\)</span> and some landmark <span class="math inline">\(l^{(i)}\)</span>: <span class="math display">\[ f_i = similarity(x, l^{(i)}) = \exp(-\dfrac{||x - l^{(i)}||^2}{2\sigma^2}) \]</span></p><p>This &quot;similarity&quot; function is called a Gaussian Kernel. It is a specific example of a kernel. The similarity function can also be written as follows: <span class="math display">\[ f_i = similarity(x, l^{(i)}) = \exp(-\dfrac{\sum^n_{j=1}(x_j-l_j^{(i)})^2}{2\sigma^2}) \]</span></p><p>There are a couple properties of the similarity function: * If <span class="math inline">\(x \approx l^{(i)}\)</span>, then <span class="math inline">\(f_i = \exp(-\dfrac{\approx 0^2}{2\sigma^2}) \approx 1\)</span> * If <span class="math inline">\(x\)</span> is far from <span class="math inline">\(l^{(i)}\)</span>, then <span class="math inline">\(f_i = \exp(-\dfrac{(large\ number)^2}{2\sigma^2}) \approx 0\)</span></p><p>In other words, if <span class="math inline">\(x\)</span> and the landmark are close, then the similarity will be close to 1, and if <span class="math inline">\(x\)</span> and the landmark are far away from each other, the similarity will be close to 0.</p><p>Each landmark gives us the features in our hypothesis: <span class="math display">\[ \begin{align*} l^{(1)} \rightarrow f_1 \newline l^{(2)} \rightarrow f_2 \newline l^{(3)} \rightarrow f_3 \newline \dots \newline h_\Theta(x) = \Theta_1f_1 + \Theta_2f_2 + \Theta_3f_3 + \dots \end{align*} \]</span></p><p><span class="math inline">\(\sigma^2\)</span> is a parameter of the Gaussian Kernel, and it can be modified to increase or decrease the drop-off of our feature <span class="math inline">\(f_i\)</span>.</p><p>Combined with looking at the values inside <span class="math inline">\(\Theta\)</span>, we can choose these landmarks to get the general shape of the decision boundary.</p><h2><span id="kernels-ii">Kernels II</span></h2><p>One way to get the landmarks is to put them in the exact same locations as all the training examples. This gives us <span class="math inline">\(m\)</span> landmarks, with one landmark per training example.</p><p>Given example <span class="math inline">\(x\)</span>:</p><ul><li><span class="math inline">\(f_1 = similarity(x,l^{(1)})\)</span>,</li><li><span class="math inline">\(f_2 = similarity(x,l^{(2)})\)</span>,</li><li><span class="math inline">\(f_3 = similarity(x,l^3)\)</span>,</li><li>and so on.</li></ul><p>This gives us a &quot;feature vector,&quot; <span class="math inline">\(f^{(i)}\)</span> of all our features for example <span class="math inline">\(x^{(i)}\)</span>. We may also set <span class="math inline">\(f_0 = 1\)</span> to correspond with <span class="math inline">\(\Theta_0\)</span>. Thus given training example <span class="math inline">\(x^{(i)}\)</span>: <span class="math display">\[ x^{(i)} \rightarrow \begin{bmatrix} f_1^{(i)} = similarity(x^{(i)}, l^{(1)}) \newline f_2^{(i)} = similarity(x^{(i)}, l^{(2)}) \newline \dots \newline f_m^{(i)} = similarity(x^{(i)}, l^{(m)}) \newline \end{bmatrix} \]</span></p><p>Now to get the parameters <span class="math inline">\(\Theta\)</span> we can use the SVM minimization algorithm but with <span class="math inline">\(f^{(i)}\)</span> substituted in for <span class="math inline">\(x^{(i)}\)</span>: <span class="math display">\[ \large min_\Theta C \sum_{i=1}^m y^{(i)}\text{cost}_1(\Theta^Tf^{(i)}) + (1 - y^{(i)})\text{cost}_0(\theta^Tf^{(i)}) + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \]</span></p><p>Using kernels to generate <span class="math inline">\(f^{(i)}\)</span> is not exclusive to SVMs and may also be applied to logistic regression. However, because of computational optimizations on SVMs, kernels combined with SVMs is much faster than with other algorithms, so kernels are almost always found combined only with SVMs.</p><p><strong>Choosing SVM Parameters</strong></p><p>Choosing <span class="math inline">\(C\)</span> (recall that <span class="math inline">\(C = \dfrac{1}{\lambda}\)</span>) * If <span class="math inline">\(C\)</span> is large, then we get higher variance/lower bias * If <span class="math inline">\(C\)</span> is small, then we get lower variance/higher bias</p><p>The other parameter we must choose is <span class="math inline">\(\sigma^2\)</span> from the Gaussian Kernel function:</p><ul><li>With a large <span class="math inline">\(\sigma^2\)</span>, the features <span class="math inline">\(f_i\)</span> vary more smoothly, causing higher bias and lower variance.</li><li>With a small <span class="math inline">\(\sigma^2\)</span>, the features <span class="math inline">\(f_i\)</span> vary less smoothly, causing lower bias and higher variance.</li></ul><h2><span id="using-an-svm">Using An SVM</span></h2><p>There are lots of good SVM libraries already written. A. Ng often uses 'liblinear' and 'libsvm'. In practical application, you should use one of these libraries rather than rewrite the functions.</p><p>In practical application, the choices you do need to make are:</p><ul><li>Choice of parameter C</li><li>Choice of kernel (similarity function)<ul><li>No kernel (&quot;linear&quot; kernel) -- gives standard linear classifier</li><li>Choose when <span class="math inline">\(n\)</span> is large and when <span class="math inline">\(m\)</span> is small</li><li>Gaussian Kernel (above) -- need to choose <span class="math inline">\(\sigma^2\)</span></li><li>Choose when <span class="math inline">\(n\)</span> is small and <span class="math inline">\(m\)</span> is large</li></ul></li></ul><p>The library may ask you to provide the kernel function.</p><p>Note: do perform <strong>feature scaling</strong> before using the Gaussian Kernel.</p><p>Note: not all similarity functions are valid kernels. They must satisfy &quot;Mercer's Theorem,&quot; which guarantees that the SVM package's optimizations run correctly and do not diverge.</p><p>You want to train <span class="math inline">\(C\)</span> and the parameters for the kernel function using the <strong>training</strong> and <strong>cross-validation</strong> datasets.</p><p><strong>Multi-class Classification</strong></p><p>Many SVM libraries have multi-class classification built-in.</p><p>You can use the one-vs-all method just like we did for logistic regression, where <span class="math inline">\(y \in {1,2,3,\dots,K}\)</span> with <span class="math inline">\(\Theta^{(1)}, \Theta^{(2)}, \dots,\Theta{(K)}\)</span>. We pick class <span class="math inline">\(i\)</span> with the largest <span class="math inline">\((\Theta^{(i)})^Tx\)</span>.</p><p><strong>Logistic Regression vs. SVMs</strong></p><ul><li>If <span class="math inline">\(n\)</span> is large (relative to <span class="math inline">\(m\)</span>), then use logistic regression, or SVM without a kernel (the &quot;linear kernel&quot;)</li><li>If <span class="math inline">\(n\)</span> is small and <span class="math inline">\(m\)</span> is intermediate, then use SVM with a Gaussian Kernel</li><li>If <span class="math inline">\(n\)</span> is small and <span class="math inline">\(m\)</span> is large, then manually create/add more features, then use logistic regression or SVM without a kernel.</li></ul><p>In the first case, we don't have enough examples to need a complicated polynomial hypothesis. In the second example, we have enough examples that we may need a complex non-linear hypothesis. In the last case, we want to increase our features so that logistic regression becomes applicable.</p><p>Note: a neural network is likely to work well for any of these situations, but may be <strong>slower</strong> to train.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Machine Learning System Design</title>
      <link href="/2016/02/29/Machine%20Learning%20System%20Design/"/>
      <url>/2016/02/29/Machine%20Learning%20System%20Design/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#prioritizing-what-to-work-on">Prioritizing What to Work On</a></li><li><a href="#error-analysis">Error Analysis</a></li><li><a href="#error-metrics-for-skewed-classes">Error Metrics for Skewed Classes</a></li><li><a href="#trading-off-precision-and-recall">Trading Off Precision and Recall</a></li><li><a href="#data-for-machine-learning">Data for Machine Learning</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="prioritizing-what-to-work-on">Prioritizing What to Work On</span></h2><p>Different ways we can approach a machine learning problem:</p><ul><li>Collect lots of data (for example &quot;honeypot&quot; project but doesn't always work)</li><li>Develop sophisticated features (for example: using email header data in spam emails)</li><li>Develop algorithms to process your input in different ways (recognizing misspellings in spam).</li></ul><p>It is difficult to tell which of the options will be helpful. Error Analysis</p><h2><span id="error-analysis">Error Analysis</span></h2><p>The recommended approach to solving machine learning problems is:</p><ul><li>Start with a simple algorithm, implement it quickly, and test it early.</li><li>Plot learning curves to decide if more data, more features, etc. will help</li><li>Error analysis: manually examine the errors on examples in the cross validation set and try to spot a trend.</li></ul><p>It's important to get error results as a single, numerical value. Otherwise it is difficult to assess your algorithm's performance. You may need to process your input before it is useful. For example, if your input is a set of words, you may want to treat the same word with different forms (fail/failing/failed) as one word, so must use &quot;stemming software&quot; to recognize them all as one.</p><h2><span id="error-metrics-for-skewed-classes">Error Metrics for Skewed Classes</span></h2><p>It is sometimes difficult to tell whether a reduction in error is actually an improvement of the algorithm.</p><p>For example: In predicting a cancer diagnoses where 0.5% of the examples have cancer, we find our learning algorithm has a 1% error. However, if we were to simply classify every single example as a 0, then our error would reduce to 0.5% even though we did not improve the algorithm.</p><p>This usually happens with skewed(å€¾æ–œ) classes; that is, when our class is very rare in the entire data set.</p><p>Or to say it another way, when we have lot more examples from one class than from the other class.</p><p>For this we can use <strong>Precision/Recall</strong>.</p><p>Predicted: 1, Actual: 1 --- True positive Predicted: 0, Actual: 0 --- True negative Predicted: 0, Actual, 1 --- False negative Predicted: 1, Actual: 0 --- False positive</p><table><colgroup><col style="width: 55%"><col style="width: 44%"></colgroup><thead><tr class="header"><th style="text-align: center;">table</th><th style="text-align: center;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Predicted: 1, Actual: 1 --- True positive</td><td style="text-align: center;">Predicted: 1, Actual: 0 --- False positive</td></tr><tr class="even"><td style="text-align: center;">Predicted: 0, Actual, 1 --- False negative</td><td style="text-align: center;">Predicted: 0, Actual: 0 --- True negative</td></tr></tbody></table><p><strong>Precision</strong> : of all patients we predicted where y=1, what fraction actually has cancer?</p><p><span class="math display">\[\frac{True\ Positives}{Total\ number\ of\ predicted\ positives}=\frac{True\ Positives}{True\ Positives + False\ positives}\]</span></p><p><strong>Recall</strong> : Of all the patients that actually have cancer, what fraction did we correctly detect as having cancer?</p><p><span class="math display">\[\frac{True\ Positives}{Number\ of\ actual\ positives}=\frac{True\ Positives}{True\ Positives + False\ negatives}\]</span></p><p>These two metrics give us a better sense of how our classifier is doing. We want <strong>both</strong> precision and recall to be <strong>high</strong>.</p><p>In the example at the beginning of the section, if we classify all patients as 0, then our recall will be <span class="math inline">\(\frac{0}{0+f}=0\)</span>, so despite having a lower error percentage, we can quickly see it has worse <strong>recall</strong>.</p><p>Note 1: if an algorithm predicts only negatives like it does in one of exercises, the precision is not defined, it is impossible to divide by 0. F1 score will not be defined too.</p><p>Note 2: a manual calculation of precision and other functions is a error prone process. it is very easy though to create an Excel file for this. Put into it a table 2*2 for all necessary input values, label them like &quot;TruePositives&quot;, &quot;FalsePositives&quot;, and on other cells of Excel add formulas like =SUM(TruePositive, FalsePositive, TrueNegative, FalseNegative), label this one AllExamples. Then on another cell label Accuracy and a formula: =SUM(TruePositive,TrueNegative)/AllExamples. The same with others. After 10 minutes you will have a spreadsheet for all examples and questions.</p><h2><span id="trading-off-precision-and-recall">Trading Off Precision and Recall</span></h2><p>We might want a confident prediction of two classes using logistic regression. One way is to increase our threshold:</p><p><span class="math display">\[Predict\ 1\ if:\ h_Î¸(x)â‰¥0.7\]</span> <span class="math display">\[Predict\ 0\ if:\ h_Î¸(x)&lt;0.7\]</span></p><p>This way, we only predict cancer if the patient has a 70% chance.</p><p>Doing this, we will have <strong>higher precision</strong> but <strong>lower recall</strong> (refer to the definitions in the previous section).</p><p>In the opposite example, we can lower our threshold:</p><p><span class="math display">\[Predict\ 1\ if:\ h_Î¸(x)â‰¥0.3\]</span> <span class="math display">\[Predict\ 0\ if:\ h_Î¸(x)&lt;0.3\]</span></p><p>That way, we get a very safe prediction. This will cause <strong>higher recall</strong> but <strong>lower precision</strong>.</p><ul><li>The greater the threshold, the greater the precision and the lower the recall.</li><li>The lower the threshold, the greater the recall and the lower the precision.</li></ul><p>In order to turn these two metrics into one single number, we can take the <span class="math inline">\(F\)</span> value.</p><p>One way is to take the <strong>average</strong>: <span class="math display">\[\frac{P+R}{2}\]</span></p><p>This does not work well. If we predict all <span class="math inline">\(y=0\)</span> then that will bring the average up despite having 0 recall. If we predict all examples as <span class="math inline">\(y=1\)</span>, then the very high recall will bring up the average despite having 0 precision.</p><p>A better way is to compute the <span class="math inline">\(F\ Score\)</span> (or <strong>F1 score</strong>):</p><p><span class="math display">\[F\ Score=2\frac{PR}{P+R}\]</span></p><p>In order for the <span class="math inline">\(F\ Score\)</span> to be large, both <strong>precision</strong> and <strong>recall</strong> must be <strong>large</strong>.</p><p>We want to train precision and recall on the <strong>cross validation set</strong> so as not to bias our test set.</p><h2><span id="data-for-machine-learning">Data for Machine Learning</span></h2><p>How much data should we train on?</p><p>In certain cases, an &quot;inferior(å·®çš„) algorithm,&quot; if given enough data, can outperform(èƒœè¿‡) a superior algorithm with less data.</p><p>We must choose our features to have <strong>enough</strong> information. A useful test is: Given input x, would a human expert be able to confidently predict y?</p><p><strong>Rationale(åŸç†) for large data</strong>: if we have a <strong>low bias</strong> algorithm (many features or hidden units making a very complex function), then the larger the training set we use, the less we will have overfitting (and the more accurate the algorithm will be on the test set).</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> F1 </tag>
            
            <tag> Recall </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>åº”ç”¨æœºå™¨å­¦ä¹ çš„ä¸€äº›å»ºè®®</title>
      <link href="/2016/02/27/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/"/>
      <url>/2016/02/27/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#deciding-what-to-try-next">Deciding What to Try Next</a></li><li><a href="#evaluating-a-hypothesis">Evaluating a Hypothesis</a></li><li><a href="#the-test-set-error">The test set error</a></li><li><a href="#model-selection-and-trainvalidationtest-sets">Model Selection and Train/Validation/Test Sets</a></li><li><a href="#diagnosing-bias-vs-variance">Diagnosing Bias vs. Variance</a></li><li><a href="#regularization-and-biasvariance">Regularization and Bias/Variance</a></li><li><a href="#learning-curves">Learning Curves</a></li><li><a href="#deciding-what-to-do-next-revisited">Deciding What to Do Next Revisited</a><ul><li><a href="#diagnosing-neural-networks">Diagnosing Neural Networks</a></li></ul></li><li><a href="#model-selection">Model Selection:</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="deciding-what-to-try-next">Deciding What to Try Next</span></h2><p>Errors in your predictions can be troubleshooted by: * Getting more training examples * Trying smaller sets of features * Trying additional features * Trying polynomial features * Increasing or decreasing <span class="math inline">\(\lambda\)</span></p><p>Don't just pick one of these avenues at random. We'll explore diagnostic techniques for choosing one of the above solutions in the following sections.</p><h2><span id="evaluating-a-hypothesis">Evaluating a Hypothesis</span></h2><p>A hypothesis may have low error for the training examples but still be inaccurate (because of overfitting).</p><p>With a given dataset of training examples, we can split up the data into two sets: a training set and a test set.</p><p>The new procedure using these two sets is then: 1. Learn <span class="math inline">\(\Theta\)</span> and minimize <span class="math inline">\(J_{train}(\Theta)\)</span> using the training set 2. Compute the test set error <span class="math inline">\(J_{test}(\Theta)\)</span></p><h2><span id="the-test-set-error">The test set error</span></h2><p>For linear regression: <span class="math display">\[J_{test}(\Theta) = \dfrac{1}{2m_{test}} \sum_{i=1}^{m_{test}}(h_\Theta(x^{(i)}_{test}) - y^{(i)}_{test})^2\]</span> For classification ~ Misclassification error (aka 0/1 misclassification error): <span class="math display">\[err(h_\Theta(x),y) = \begin{matrix} 1 &amp; \mbox{if } h_\Theta(x) \geq 0.5\ and\ y = 0\ or\ h_\Theta(x) &lt; 0.5\ and\ y = 1\newline 0 &amp; \mbox otherwise \end{matrix} \]</span> This gives us a binary 0 or 1 error result based on a misclassification.</p><p>The average test error for the test set is <span class="math display">\[ \large \text{Test Error} = \dfrac{1}{m_{test}} \sum^{m_{test}}_{i=1} err(h_\Theta(x^{(i)}_{test}), y^{(i)}_{test}) \]</span></p><p>This gives us the proportion(æ¯”ä¾‹) of the test data that was misclassified.</p><h2><span id="model-selection-and-trainvalidationtest-sets">Model Selection and Train/Validation/Test Sets</span></h2><p>Just because a learning algorithm fits a training set well, that does not mean it is a good hypothesis.</p><p>The error of your hypothesis as measured on the data set with which you trained the parameters will be lower than any other data set.</p><p>In order to choose the model of your hypothesis, you can test each degree of polynomial and look at the error result.</p><p><strong>Without the Validation Set</strong> 1. Optimize the parameters in <span class="math inline">\(\Theta\)</span> using the training set for each polynomial degree. 2. Find the polynomial degree <span class="math inline">\(d\)</span> with the least error using the test set. 3. Estimate the generalization error also using the test set with <span class="math inline">\(J_{test}(\Theta^{(d)})\)</span>, (d = theta from polynomial with lower error);</p><p>In this case, we have trained one variable, <span class="math inline">\(d\)</span>, or the degree of the polynomial, using the test set. This will cause our error value to be greater for any other set of data.</p><p>To solve this, we can introduce a third set, the <strong>Cross Validation Set</strong>, to serve as an intermediate set that we can train <span class="math inline">\(d\)</span> with. Then our test set will give us an accurate, non-optimistic error.</p><p>One example way to break down our dataset into the three sets is: * Training set: 60% * Cross validation set: 20% * Test set: 20%</p><p>We can now calculate three separate error values for the three different sets.</p><p><strong>With the Validation Set</strong> 1. Optimize the parameters in <span class="math inline">\(\Theta\)</span> using the training set for each polynomial degree. 2. Find the polynomial degree <span class="math inline">\(d\)</span> with the least error using the cross validation set. 3. Estimate the generalization error using the test set with <span class="math inline">\(J_{test}(\Theta^{(d)})\)</span>, (d = theta from polynomial with lower error);</p><p>This way, the degree of the polynomial <span class="math inline">\(d\)</span> has not been trained using the test set.</p><h2><span id="diagnosing-bias-vs-variance">Diagnosing Bias vs. Variance</span></h2><p>In this section we examine the relationship between the degree of the polynomial <span class="math inline">\(d\)</span> and the underfitting or overfitting of our hypothesis.</p><ul><li>We need to distinguish whether <strong>bias</strong>(åç¦») or <strong>variance</strong>(æ–¹å·®) is the problem contributing to bad predictions.</li><li><strong>High bias</strong> is <strong>underfitting</strong> and <strong>high variance</strong> is <strong>overfitting</strong>. We need to find a golden mean between these two.</li></ul><p>The training error will tend to <strong>decrease</strong> as we increase the degree <span class="math inline">\(d\)</span> of the polynomial.</p><p>At the same time, the cross validation error will tend to <strong>decrease</strong> as we increase <span class="math inline">\(d\)</span> up to a point, and then it will <strong>increase</strong> as <span class="math inline">\(d\)</span> is increased, forming a convex curve.</p><ul><li>High bias (underfitting): both <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be high. Also, <span class="math inline">\(J_{CV}(\Theta) \approx J_{train}(\Theta)\)</span>.</li><li>High variance (overfitting): <span class="math inline">\(J_{train}(\Theta)\)</span> will be low and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be much greater than <span class="math inline">\(J_{train}(\Theta)\)</span>.</li></ul><p>The is represented in the figure below:</p><p><img src="/images/1456537039223.png"></p><h2><span id="regularization-and-biasvariance">Regularization and Bias/Variance</span></h2><p>Instead of looking at the degree <span class="math inline">\(d\)</span> contributing to bias/variance, now we will look at the regularization parameter <span class="math inline">\(\lambda\)</span>.</p><ul><li>Large <span class="math inline">\(\lambda\)</span>: High bias (underfitting)</li><li>Intermediate <span class="math inline">\(\lambda\)</span>: just right</li><li>Small <span class="math inline">\(\lambda\)</span>: High variance (overfitting)</li></ul><p>A large lambda heavily penalizes all the <span class="math inline">\(\Theta\)</span> parameters, which greatly simplifies the line of our resulting function, so causes underfitting.</p><p>The relationship of <span class="math inline">\(\lambda\)</span> to the training set and the variance set is as follows:</p><ul><li>Low <span class="math inline">\(\lambda\)</span>: <span class="math inline">\(J_{train}(\Theta)\)</span> is low and <span class="math inline">\(J_{CV}(\Theta)\)</span> is high (<strong>high variance/overfitting</strong>).</li><li>Intermediate <span class="math inline">\(\lambda\)</span>: <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> are somewhat low and <span class="math inline">\(J_{train}(\Theta) \approx J_{CV}(\Theta)\)</span>.</li><li>Large <span class="math inline">\(\lambda\)</span>: both <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be high (<strong>underfitting/high bias</strong>)</li></ul><p>The figure below illustrates the relationship between lambda and the hypothesis:</p><p><img src="/images/1456537437295.png"></p><p>In order to choose the model and the regularization <span class="math inline">\(\lambda\)</span>, we need: 1. Create a list of lambda (i.e. <span class="math inline">\(\lambda \in \lbrace0, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1.28, 2.56, 5.12, 10.24\rbrace\)</span>); 2. Select a lambda to compute; 3. Create a model set like degree of the polynomial or others; 4. Select a model to learn <span class="math inline">\(\Theta\)</span>; 5. Learn the parameter <span class="math inline">\(\Theta\)</span> for the model selected, using <span class="math inline">\(J_{train}(\Theta)\)</span> with <span class="math inline">\(\lambda\)</span> selected (this will learn <span class="math inline">\(\Theta\)</span> for the next step); 6. Compute the train error using the learned <span class="math inline">\(\Theta\)</span> (computed with <span class="math inline">\(\lambda\)</span> ) on the <span class="math inline">\(J_{train}(\Theta)\)</span> without regularization or <span class="math inline">\(\lambda\)</span> = 0; 7. Compute the cross validation error using the learned <span class="math inline">\(\Theta\)</span> (computed with <span class="math inline">\(\lambda\)</span>) on the <span class="math inline">\(J_{CV}(\Theta)\)</span> without regularization or <span class="math inline">\(\lambda\)</span> = 0; 8. Do this for the entire model set and lambdas, then select the best combo that produces the lowest error on the cross validation set; 9. Now if you need visualize to help you understand your decision, you can plot to the figure like above with: (<span class="math inline">\(\lambda\)</span> x Cost <span class="math inline">\(J_{train}(\Theta)\)</span>) and (<span class="math inline">\(\lambda\)</span> x Cost <span class="math inline">\(J_{CV}(\Theta)\)</span>); 10. Now using the best combo <span class="math inline">\(\Theta\)</span> and <span class="math inline">\(\lambda\)</span>, apply it on <span class="math inline">\(J_{test}(\Theta)\)</span> to see if it have a good generalization of the problem. 11. To help decide the best polynomial degree and <span class="math inline">\(\lambda\)</span> to use, we can diagnose(è¯Šæ–­) with the learning curves, that is the next subject.</p><h2><span id="learning-curves">Learning Curves</span></h2><p>Training 3 examples will easily have 0 errors because we can always find a quadratic curve that exactly touches 3 points.</p><ul><li>As the training set gets larger, the error for a quadratic function increases.</li><li>The error value will plateau out after a certain <span class="math inline">\(m\)</span>, or training set size.</li></ul><p><strong>With high bias</strong></p><ul><li><strong>Low training set size</strong>: causes <span class="math inline">\(J_{train}(\Theta)\)</span> to be low and <span class="math inline">\(J_{CV}(\Theta)\)</span> to be high.</li><li><strong>Large training set size</strong>: causes both <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> to be high with <span class="math inline">\(J_{train}(\Theta) \approx J_{CV}(\Theta)\)</span>.</li></ul><p>If a learning algorithm is suffering from <strong>high bias</strong>, getting more training data will <strong>not (by itself) help much</strong>.</p><p>For high variance, we have the following relationships in terms of the training set size: <strong>With high variance</strong></p><ul><li><strong>Low training set size</strong>: <span class="math inline">\(J_{train}(\Theta)\)</span> will be low and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be high.</li><li><strong>Large training set size</strong>: <span class="math inline">\(J_{train}(\Theta)\)</span> increases with training set size and <span class="math inline">\(J_{CV}(\Theta)\)</span> continues to decrease without leveling off. Also, <span class="math inline">\(J_{train}(\Theta) &lt; J_{CV}(\Theta)\)</span> but the difference between them remains significant.</li></ul><p>If a learning algorithm is suffering from <strong>high variance</strong>, getting more training data is <strong>likely to help</strong>.</p><p><img src="/images/1456538443823.png"> <img src="/images/1456538447332.png"></p><h2><span id="deciding-what-to-do-next-revisited">Deciding What to Do Next Revisited</span></h2><p>Our decision process can be broken down as follows:</p><ul><li>Getting more training examples<ul><li>Fixes high variance</li></ul></li><li>Trying smaller sets of features<ul><li>Fixes high variance</li></ul></li><li>Adding features<ul><li>Fixes high bias</li></ul></li><li>Adding polynomial features<ul><li>Fixes high bias</li></ul></li><li>Decreasing <span class="math inline">\(\lambda\)</span><ul><li>Fixes high bias</li></ul></li><li>Increasing <span class="math inline">\(\lambda\)</span><ul><li>Fixes high variance</li></ul></li></ul><h3><span id="diagnosing-neural-networks">Diagnosing Neural Networks</span></h3><ul><li>A neural network with <strong>fewer</strong> parameters is prone(å€¾å‘äº) to <strong>underfitting</strong>. It is also computationally cheaper.</li><li>A <strong>large</strong> neural network with more parameters is prone to <strong>overfitting</strong>. It is also computationally expensive. In this case you can use regularization (increase <span class="math inline">\(\lambda\)</span>) to address the overfitting.</li></ul><p>Using a <strong>single hidden layer</strong> is a good <strong>starting default</strong>. You can train your neural network on a number of hidden layers using your cross validation set.</p><h2><span id="model-selection">Model Selection:</span></h2><ul><li>Choosing M the order of polynomials.</li><li>How can we tell which parameters Î˜ to leave in the model (known as &quot;model selection&quot;)?</li></ul><p>There are several ways to solve this problem:</p><ol type="1"><li>Get more data (very difficult).</li><li>Choose the model which best fits the data without overfitting (very difficult).</li><li>Reduce the opportunity for overfitting through regularization.</li></ol><p><strong>Bias: approximation(è¿‘ä¼¼å€¼) error (Difference between expected value and optimal value)</strong> * High Bias = UnderFitting (BU) * <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> both will be high and <span class="math inline">\(J_{train}(\Theta) \approx J_{CV}(\Theta)\)</span></p><p><strong>Variance: estimation(ä¼°è®¡) error due to finite(æœ‰é™çš„) data</strong> * High Variance = OverFitting (VO) * <span class="math inline">\(J_{train}(\Theta)\)</span> is low and <span class="math inline">\(J_{CV}(\Theta) \gg J_{train}(\Theta)\)</span></p><p><strong>Intuition for the bias-variance trade-off:</strong></p><ul><li>Complex model =&gt; sensitive to data =&gt; much affected by changes in X =&gt; high variance, low bias.</li><li>Simple model =&gt; more rigid =&gt; does not change as much with changes in X =&gt; low variance, high bias.</li></ul><p>One of the most important goals in learning: finding a model that is just right in the bias-variance trade-off.</p><p><strong>Regularization Effects:</strong></p><ul><li>Small values of Î» allow model to become finely tuned to noise leading to large variance =&gt; overfitting.</li><li>Large values of Î» pull weight parameters to zero leading to large bias =&gt; underfitting.</li></ul><p><strong>Model Complexity Effects:</strong></p><ul><li>Lower-order polynomials (low model complexity) have high bias and low variance. In this case, the model fits poorly consistently.</li><li>Higher-order polynomials (high model complexity) fit the training data extremely well and the test data extremely poorly. These have low bias on the training data, but very high variance.</li></ul><p>In reality, we would want to choose a model somewhere in between, that can generalize well but also fits the data reasonably well.</p><p><strong>A typical rule of thumb when running diagnostics is:</strong></p><ul><li>More training examples fixes high variance but not high bias.</li><li>Fewer features fixes high variance but not high bias.</li><li>Additional features fixes high bias but not high variance.</li><li>The addition of polynomial and interaction features fixes high bias but not high variance.</li><li>When using gradient descent, decreasing lambda can fix high bias and increasing lambda can fix high variance (lambda is the regularization parameter).</li><li>When using neural networks, small neural networks are more prone to under-fitting and big neural networks are prone to over-fitting. Cross-validation of network size is a way to choose alternatives.</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Bias </tag>
            
            <tag> Variance </tag>
            
            <tag> Overfitting </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç¥ç»ç½‘ç»œ(Neural Network)(ä¸‹)</title>
      <link href="/2016/02/22/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8B)/"/>
      <url>/2016/02/22/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8B)/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#cost-function">Cost Function</a></li><li><a href="#backpropagation-algorithm">Backpropagation Algorithm</a></li><li><a href="#backpropagation-intuition">Backpropagation Intuition</a></li><li><a href="#implementation-note-unrolling-parameters">Implementation Note: Unrolling Parameters</a></li><li><a href="#gradient-checking">Gradient Checking</a></li><li><a href="#putting-it-together">Putting it Together</a></li><li><a href="#nn-for-linear-systems">NN for linear systems</a><ul><li><a href="#introduction">Introduction</a></li><li><a href="#testing-your-linear-nn">Testing your linear NN</a></li></ul></li><li><a href="#reference">Reference</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="cost-function">Cost Function</span></h2><p>Let's first define a few variables that we will need to use: * <span class="math inline">\(L\)</span> = total number of layers in the network * <span class="math inline">\(s_l\)</span>= number of units (not counting bias unit) in layer <span class="math inline">\(l\)</span> * <span class="math inline">\(K\)</span> = number of output units/classes</p><p>Recall that in neural networks, we may have many output nodes. We denote <span class="math inline">\(h_Î˜(x)_k\)</span> as being a hypothesis that results in the <span class="math inline">\(k^{th}\)</span> output.</p><p>Our cost function for neural networks is going to be a <strong>generalization</strong> of the one we used for logistic regression.</p><p>Recall that the cost function for regularized logistic regression was:</p><p><span class="math display">\[J(Î¸)=âˆ’\frac{1}{m}[âˆ‘^m_{i=1}y^{(i)}log(h_Î¸(x^{(i)}))+(1âˆ’y^{(i)})log(1âˆ’h_Î¸(x^{(i)}))]+\frac{Î»}{2m}âˆ‘^n_{j=1}Î¸^2_j\]</span></p><p>For neural networks, it is going to be slightly more complicated:</p><p><span class="math inline">\(J(Î˜)=âˆ’\frac{1}{m}[âˆ‘^m_{i=1}âˆ‘_{k=1}^Ky^{(i)}_klog((h_Î˜(x^{(i)}))_k)+(1âˆ’y^{(i)}_k)log(1âˆ’(h_Î˜(x^{(i)}))_k)]+\frac{Î»}{2m}\sum_{l=1}^{Lâˆ’1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1}(Î˜^{(l)}_{j,i})^2\)</span></p><figure><img src="/images/1473765472300.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>We have added a few nested summations to account for our multiple output nodes. In the first part of the equation, between the square brackets, we have an additional nested summation that loops through the number of output nodes.</p><p>In the regularization part, after the square brackets, we must account for multiple theta matrices. <strong>The number of columns in our current theta matrix is equal to the number of nodes in our current layer (including the bias unit)</strong>. <strong>The number of rows in our current theta matrix is equal to the number of nodes in the next layer (excluding the bias unit)</strong>. As before with logistic regression, we square every term.</p><p>Note: * the double sum simply adds up the logistic regression costs calculated for each cell in the output layer; * the triple sum simply adds up the squares of all the individual Î˜s in the entire network. * the i in the triple sum does <strong>not</strong> refer to training example i</p><h2><span id="backpropagation-algorithm">Backpropagation Algorithm</span></h2><p>&quot;Backpropagation&quot; is neural-network terminology(æœ¯è¯­) for minimizing our cost function, just like what we were doing with gradient descent in logistic and linear regression.</p><p>Our goal is to compute: <span class="math display">\[min_Î˜J(Î˜)\]</span></p><p>That is, we want to minimize our cost function <span class="math inline">\(J\)</span> using an optimal set of parameters in theta.</p><p>In this section we'll look at the equations we use to compute the partial derivative of <span class="math inline">\(J(Î˜)\)</span>: <span class="math display">\[\frac{âˆ‚}{âˆ‚Î˜^{(l)}_{i,j}}J(Î˜)\]</span></p><p>In backpropagation we're going to compute for every node: <span class="math inline">\(Î´^{(l)}_j\)</span> = &quot;<strong>error</strong>&quot; of node <span class="math inline">\(j\)</span> in layer <span class="math inline">\(l\)</span></p><p>Recall that <span class="math inline">\(a^{(l)}_j\)</span> is activation node <span class="math inline">\(j\)</span> in layer <span class="math inline">\(l\)</span>.</p><p>For the last layer, we can compute the vector of delta values with: <span class="math display">\[Î´^{(L)}=a^{(L)}âˆ’y\]</span></p><figure><img src="/images/1473765394042.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>Where <span class="math inline">\(L\)</span> is our total number of layers and <span class="math inline">\(a^{(L)}\)</span> is the vector of activation units for the last layer. So our &quot;<strong>error values</strong>&quot; for the last layer are simply the differences of our actual results in the last layer and the correct outputs in <span class="math inline">\(y\)</span>.</p><p>To get the delta values of the layers before the last layer, we can use an equation that steps us back from right to left: <span class="math display">\[Î´^{(l)}=((Î˜^{(l)})^TÎ´^{(l+1)}) .âˆ— gâ€²(z^{(l)})\]</span></p><figure><img src="/images/1473765325959.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>The delta values of layer <span class="math inline">\(l\)</span> are calculated by multiplying the delta values in the next layer with the theta matrix of layer <span class="math inline">\(l\)</span>. We then element-wise multiply that with a function called <span class="math inline">\(g&#39;\)</span>, or <em>g-prime</em>, which is the derivative of the activation function <span class="math inline">\(g\)</span> evaluated with the input values given by <span class="math inline">\(z^{(l)}\)</span>.</p><p>The <em>g-prime</em> derivative terms can also be written out as: <span class="math display">\[gâ€²(z^{(l)})=a^{(l)} .âˆ— (1âˆ’a^{(l)})\]</span></p><p>This can be shown and proved in calculus.</p><p><span class="math display">\[g(z)=\frac{1}{1+e^{âˆ’z}}\]</span> <span class="math display">\[\begin{array}{lcr}\frac{âˆ‚g(z)}{âˆ‚z}=âˆ’(\frac{1}{1+e^{âˆ’z}})^2\frac{âˆ‚}{âˆ‚z}(1+e^{âˆ’z}) \\\ \ \ \ \ \ \ \ \ =âˆ’(\frac{1}{1+e^{âˆ’z}})^2e^{âˆ’z}(âˆ’1) \\\ \ \ \ \ \ \ \ \ =(\frac{1}{1+e^{âˆ’z}})(\frac{1}{1+e^{âˆ’z}})(e^{âˆ’z}) \\\ \ \ \ \ \ \ \ \ =(\frac{1}{1+e^{âˆ’z}})(\frac{e^{âˆ’z}}{1+e^{âˆ’z}}) \\\ \ \ \ \ \ \ \ \ =g(z)(1âˆ’g(z))\end{array}\]</span></p><p>The full backpropagation equation for the inner nodes is then: <span class="math display">\[Î´^{(l)}=((Î˜^{(l)})^TÎ´^{(l+1)}) .âˆ— a^{(l)} .âˆ— (1âˆ’a^{(l)})\]</span></p><p>We can compute our partial derivative terms by multiplying our activation values and our error values for each training example t: <span class="math display">\[\frac{âˆ‚J(Î˜)}{âˆ‚Î˜^{(l)}_{i,j}}=\frac{1}{m}\sum^m_{t=1}a^{(t)(l)}_jÎ´^{(t)(l+1)}_i\]</span></p><p><img src="/images/1473766072648.png" alt="Alt text"> <span class="math display">\[\frac{\partial}{\partial W^{(l)}_{ij}} J(W,b;x,y)= \frac{\partial}{\partial z^{(l+1)}_{i}}J(W,b;x,y) \cdot \frac{\partial z^{(l+1)}_i}{\partial W^{(l)}_{ij}} = a^{(l)}_j\delta^{(l+1)}_i\]</span></p><p>This however <strong>ignores regularization</strong>, which we'll deal with later.</p><p>Note: <span class="math inline">\(Î´^{l+1}\)</span> and <span class="math inline">\(a^{l+1}\)</span> are vectors with <span class="math inline">\(s_{l+1}\)</span> elements. Similarly, <span class="math inline">\(a^{(l)}\)</span> is a vector with <span class="math inline">\(s_l\)</span> elements. Multiplying them produces a matrix that is <span class="math inline">\(s_{l+1}\)</span> by <span class="math inline">\(s_l\)</span> which is the <strong>same dimension</strong> as <span class="math inline">\(Î˜^{(l)}\)</span>. That is, the process produces a gradient term for every element in <span class="math inline">\(Î˜^{(l)}\)</span>. (Actually, <span class="math inline">\(Î˜^{(l)}\)</span> has <span class="math inline">\(s_{l+1} + 1\)</span> rows, so the dimensionality is not exactly the same).</p><p>We can now take all these equations and put them together into a backpropagation algorithm:</p><figure><img src="/images/1456125275491.png" alt="Backpropagation Algorithm"><figcaption>Backpropagation Algorithm</figcaption></figure><p><strong>Backpropagation Algorithm</strong></p><ul><li>Given training set {(<span class="math inline">\(x^{(1)}\)</span>, <span class="math inline">\(y^{(1)}\)</span>)â‹¯(<span class="math inline">\(x^{(m)}\)</span>, <span class="math inline">\(y^{(m)}\)</span>)}</li><li>Set <span class="math inline">\(Î”^{(l)}_{i,j} := 0\)</span> for all (<span class="math inline">\(l\)</span>, <span class="math inline">\(i\)</span>, <span class="math inline">\(j\)</span>)</li><li>For training example <span class="math inline">\(t=1\)</span> to <span class="math inline">\(m\)</span>:<ul><li>Set <span class="math inline">\(a^{(1)} := x^{(t)}\)</span></li><li>Perform <strong>forward propagation</strong> to compute <span class="math inline">\(a^{(l)}\)</span> for <span class="math inline">\(l=2,3,â€¦,L\)</span></li><li>Using <span class="math inline">\(y^{(t)}\)</span>, compute <span class="math inline">\(Î´^{(L)}=a^{(L)}âˆ’y^{(t)}\)</span></li><li>Compute <span class="math inline">\(Î´^{(Lâˆ’1)}\)</span>,<span class="math inline">\(Î´^{(Lâˆ’2)}\)</span>,â€¦,<span class="math inline">\(Î´^{(2)}\)</span> using <span class="math inline">\(Î´^{(l)}=((Î˜^{(l)})^TÎ´^{(l+1)}) .âˆ— a^{(l)} .âˆ— (1âˆ’a^{(l)})\)</span></li><li><span class="math inline">\(Î”^{(l)}_{i,j} :=Î”^{(l)}_{i,j}+a^{(l)}_jÎ´^{(l+1)}_i\)</span> or with vectorization, <span class="math inline">\(Î”^{(l)} :=Î”^{(l)}+Î´^{(l+1)}(a^{(l)})^T\)</span></li></ul></li><li><span class="math inline">\(D^{(l)}_{i,j} := \frac{1}{m}(Î”^{(l)}_{i,j}+Î»Î˜^{(l)}_{i,j})\)</span> If <span class="math inline">\(jâ‰ 0\)</span></li><li><span class="math inline">\(D^{(l)}_{i,j} := \frac{1}{m}Î”^{(l)}_{i,j}\)</span> If <span class="math inline">\(j=0\)</span></li></ul><p>The capital-delta matrix is used as an &quot;<strong>accumulator</strong>&quot; to add up our values as we go along and eventually compute our partial derivative.</p><p>The actual proof is quite involved, but, the <span class="math inline">\(D^{(l)}_{i,j}\)</span> terms are the partial derivatives and the results we are looking for: <span class="math inline">\(D^{(l)}_{i,j} = \frac{âˆ‚J(Î˜)}{âˆ‚Î˜^{(l)}_{i,j}}\)</span>.</p><h2><span id="backpropagation-intuition">Backpropagation Intuition</span></h2><p>The cost function is: <span class="math inline">\(J(Î˜)=âˆ’\frac{1}{m}[âˆ‘^m_{i=1}âˆ‘_{k=1}^Ky^{(i)}_klog((h_Î˜(x^{(i)}))_k)+(1âˆ’y^{(i)}_k)log(1âˆ’(h_Î˜(x^{(i)}))_k)]+\frac{Î»}{2m}\sum_{l=1}^{Lâˆ’1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1}(Î˜^{(l)}_{j,i})^2\)</span></p><p>If we consider simple non-multiclass classification (k = 1) and disregard regularization, the cost is computed with: <span class="math display">\[cost(t)=y^{(t)}log(h_Î¸(x^{(t)}))+(1âˆ’y^{(t)})log(1âˆ’h_Î¸(x^{(t)}))\]</span></p><p>More intuitively you can think of that equation roughly as: <span class="math display">\[cost(t)â‰ˆ(h_Î¸(x^{(t)})âˆ’y^{(t)})^2\]</span></p><p>Intuitively, <span class="math inline">\(Î´^{(l)}_j\)</span> is the &quot;error&quot; for <span class="math inline">\(a^{(l)}_j\)</span> (unit <span class="math inline">\(j\)</span> in layer <span class="math inline">\(l\)</span>)</p><p>More formally, the delta values are actually the derivative of the cost function: <span class="math display">\[Î´^{(l)}_j=\frac{âˆ‚}{âˆ‚z^{(l)}_j}cost(t)\]</span></p><p>Recall that our derivative is the slope of a line tangent to the cost function, so the steeper the slope the more incorrect we are.</p><p>Note: In lecture, sometimes <strong>i</strong> is used to <strong>index a training example</strong>. Sometimes it is used to <strong>index a unit in a layer</strong>. In the Back Propagation Algorithm described here, <strong>t</strong> is used to <strong>index a training example</strong> rather than overloading the use of i.</p><h2><span id="implementation-note-unrolling-parameters">Implementation Note: Unrolling Parameters</span></h2><p>With neural networks, we are working with sets of matrices: <span class="math inline">\(Î˜_1\)</span>, <span class="math inline">\(Î˜_2\)</span>, <span class="math inline">\(Î˜_3\)</span>,â€¦ <span class="math inline">\(D_1\)</span>, <span class="math inline">\(D_2\)</span>, <span class="math inline">\(D_2\)</span>,â€¦</p><p>In order to use optimizing functions such as &quot;<code>fminunc()</code>&quot;, we will want to &quot;<strong>unroll</strong>&quot; all the elements and put them into one long vector: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]</span><br><span class="line">deltaVector = [ D1(:); D2(:); D3(:) ]</span><br></pre></td></tr></table></figure></p><p>If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11, then we can get back our original matrices from the &quot;unrolled&quot; versions as follows: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Theta1 = <span class="built_in">reshape</span>(thetaVector(<span class="number">1</span>:<span class="number">110</span>),<span class="number">10</span>,<span class="number">11</span>)</span><br><span class="line">Theta2 = <span class="built_in">reshape</span>(thetaVector(<span class="number">111</span>:<span class="number">220</span>),<span class="number">10</span>,<span class="number">11</span>)</span><br><span class="line">Theta3 = <span class="built_in">reshape</span>(thetaVector(<span class="number">221</span>:<span class="number">231</span>),<span class="number">1</span>,<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><h2><span id="gradient-checking">Gradient Checking</span></h2><p>Gradient checking will assure that our backpropagation works as intended. We can approximate the derivative of our cost function with: <span class="math display">\[\frac{âˆ‚}{âˆ‚Î˜}J(Î˜) â‰ˆ \frac{J(Î˜+Ïµ)âˆ’J(Î˜âˆ’Ïµ)}{2Ïµ}\]</span></p><p>With multiple theta matrices, we can approximate the derivative with respect to <span class="math inline">\(Î˜_j\)</span> as follows: <span class="math display">\[\frac{âˆ‚}{âˆ‚Î˜_j}J(Î˜) â‰ˆ \frac{J(Î˜_1,â€¦,Î˜_{j+Ïµ},â€¦,Î˜_n)âˆ’J(Î˜_1,â€¦,Î˜_{jâˆ’Ïµ},â€¦,Î˜_n)}{2Ïµ}\]</span></p><p>A good small value for <span class="math inline">\(Ïµ\)</span> (epsilon), guarantees the math above to become true. If the value be much smaller, may we will end up with numerical problems. The professor Andrew usually uses the value <span class="math inline">\(Ïµ=10^{âˆ’4}\)</span>.</p><p>We are only adding or subtracting epsilon to the <span class="math inline">\(Î˜_j\)</span> matrix. In octave we can do it as follows: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">epsilon = <span class="number">1e-4</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n,</span><br><span class="line">  thetaPlus = theta;</span><br><span class="line">  thetaPlus(<span class="built_in">i</span>) += epsilon;</span><br><span class="line">  thetaMinus = theta;</span><br><span class="line">  thetaMinus(<span class="built_in">i</span>) -= epsilon;</span><br><span class="line">  gradApprox(<span class="built_in">i</span>) = (J(thetaPlus) - J(thetaMinus))/(<span class="number">2</span>*epsilon)</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure></p><p>We then want to check that <code>gradApprox</code> â‰ˆ <code>deltaVector</code>.</p><p>Once you've verified <strong>once</strong> that your backpropagation algorithm is correct, then you don't need to compute gradApprox again. <strong>The code to compute gradApprox is very slow</strong>.</p><h2><span id="putting-it-together">Putting it Together</span></h2><p>First, <strong>pick a network architecture</strong>; choose the <strong>layout</strong> of your neural network, including how many hidden units in each layer and how many layers total. * Number of input units = dimension of features <span class="math inline">\(x^{(i)}\)</span> * Number of output units = number of classes * Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units) * Defaults: 1 hidden layer. If more than 1 hidden layer, then the same number of units in every hidden layer.</p><p><strong>Training a Neural Network</strong></p><ol type="1"><li>Randomly initialize the weights</li><li>Implement forward propagation to get <span class="math inline">\(h_Î¸(x^{(i)})\)</span></li><li>Implement the cost function</li><li>Implement backpropagation to compute partial derivatives</li><li>Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.</li><li>Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.</li></ol><p>When we perform forward and back propagation, we loop on every training example: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:m,</span><br><span class="line">   Perform forward propagation and backpropagation using example (x(<span class="built_in">i</span>),y(<span class="built_in">i</span>))</span><br><span class="line">   (Get activations a(l) and delta terms d(l) <span class="keyword">for</span> l = <span class="number">2</span>,...,L</span><br></pre></td></tr></table></figure></p><h2><span id="nn-for-linear-systems">NN for linear systems</span></h2><h3><span id="introduction">Introduction</span></h3><p>The NN we created for classification can easily be modified to have a linear output.</p><p>First solve the 4th programming exercise. You can create a new function script, nnCostFunctionLinear.m, with the following characteristics * There is only one output node, so you do not need the 'num_labels' parameter. * Since there is one linear output, you do not need to convert y into a logical matrix. * You still need a non-linear function in the hidden layer. * The non-linear function is often the <code>tanh()</code> function - it has an output range from -1 to +1, and its gradient is easily implemented. Let <span class="math inline">\(g(z)=tanh(z)\)</span>. * The gradient of tanh is <span class="math inline">\(gâ€²(z)=1âˆ’g(z)^2\)</span>. Use this in backpropagation in place of the sigmoid gradient. * Use linear regression for the NN output (do not use a sigmoid function on the output layer). * Cost computation: Use the linear cost function for <span class="math inline">\(J\)</span> (from ex1 and ex5) for the unregularized portion. For the regularized portion, use the same method as ex4. * Where <code>reshape()</code> is used to form the Theta matrices, replace 'num_labels' with '1'.</p><p>You will also need to create a <code>predictLinear()</code> function, using the <code>tanh()</code> function in the hidden layer, and a linear output.</p><h3><span id="testing-your-linear-nn">Testing your linear NN</span></h3><p>Here is a test case for your <code>nnCostFunctionLinear()</code> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% inputs</span></span><br><span class="line">nn_params = [<span class="number">31</span> <span class="number">16</span> <span class="number">15</span> <span class="number">-29</span> <span class="number">-13</span> <span class="number">-8</span> <span class="number">-7</span> <span class="number">13</span> <span class="number">54</span> <span class="number">-17</span> <span class="number">-11</span> <span class="number">-9</span> <span class="number">16</span>]'/ <span class="number">10</span>;</span><br><span class="line">il = <span class="number">1</span>;</span><br><span class="line">hl = <span class="number">4</span>;</span><br><span class="line">X = [<span class="number">1</span> ; <span class="number">2</span> ; <span class="number">3</span>];</span><br><span class="line">y = [<span class="number">1</span> ; <span class="number">4</span> ; <span class="number">9</span>];</span><br><span class="line">lambda = <span class="number">0.01</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% command</span></span><br><span class="line">[<span class="built_in">j</span> g] = nnCostFunctionLinear(nn_params, il, hl, X, y, lambda)</span><br><span class="line"></span><br><span class="line"><span class="comment">% results</span></span><br><span class="line"><span class="built_in">j</span> =  <span class="number">0.020815</span></span><br><span class="line">g =</span><br><span class="line">    <span class="number">-0.0131002</span></span><br><span class="line">    <span class="number">-0.0110085</span></span><br><span class="line">    <span class="number">-0.0070569</span></span><br><span class="line">     <span class="number">0.0189212</span></span><br><span class="line">    <span class="number">-0.0189639</span></span><br><span class="line">    <span class="number">-0.0192539</span></span><br><span class="line">    <span class="number">-0.0102291</span></span><br><span class="line">     <span class="number">0.0344732</span></span><br><span class="line">     <span class="number">0.0024947</span></span><br><span class="line">     <span class="number">0.0080624</span></span><br><span class="line">     <span class="number">0.0021964</span></span><br><span class="line">     <span class="number">0.0031675</span></span><br><span class="line">    <span class="number">-0.0064244</span></span><br></pre></td></tr></table></figure></p><p>Now create a script that uses the 'ex5data1.mat' from ex5, but without creating the polynomial terms. With 8 units in the hidden layer and MaxIter set to 200, you should be able to get a final cost value of 0.3 to 0.4. The results will vary a bit due to the random Theta initialization. If you plot the training set and the predicted values for the training set (using your <code>predictLinear()</code> function), you should have a good match.</p><h2><span id="reference">Reference</span></h2><ul><li><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">æœºå™¨å­¦ä¹  Andrew Ng</a></li><li><a href="http://deeplearning.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">UFLDLæ•™ç¨‹</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Neural Network </tag>
            
            <tag> Dense </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ç¥ç»ç½‘ç»œ(Neural Network)(ä¸Š)</title>
      <link href="/2016/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8A)/"/>
      <url>/2016/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8A)/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#éçº¿æ€§å‡æƒ³å‡½æ•°">éçº¿æ€§å‡æƒ³å‡½æ•°</a></li><li><a href="#ç¥ç»å’Œå¤§è„‘">ç¥ç»å’Œå¤§è„‘</a></li><li><a href="#æ¨¡å‹è§£é‡Š">æ¨¡å‹è§£é‡Š</a><ul><li><a href="#vectorized-implementation">Vectorized implementation</a></li></ul></li><li><a href="#ä¸¾ä¾‹è¯´æ˜">ä¸¾ä¾‹è¯´æ˜</a><ul><li><a href="#x_1-and-x_2"><span class="math inline">\(x_1\)</span> AND <span class="math inline">\(x_2\)</span></a></li><li><a href="#nor-or-xnor">NORã€ORã€XNOR</a></li></ul></li><li><a href="#multiclass-classification">Multiclass Classification</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="éçº¿æ€§å‡æƒ³å‡½æ•°">éçº¿æ€§å‡æƒ³å‡½æ•°</span></h2><p>å¯¹ä¸€ä¸ªéå¸¸å¤æ‚çš„æ•°æ®é›†è¿›è¡Œçº¿æ€§å›å½’æ˜¯ä¸æ˜æ™ºçš„ã€‚å‡è®¾ä½ è¦æ„é€ ä¸€ä¸ªåŒ…å«å¾ˆå¤šéçº¿æ€§é¡¹çš„é€»è¾‘å›å½’å‡½æ•°ï¼š <span class="math display">\[g(\theta_0 + \theta_1x^2_1 + \theta_2x_1x_2 + \theta_3x_1x_3 + \theta_4x^2_2 + \theta_5x_2x_3 + \theta_6x^2_3)\]</span></p><p>æ€»å…±æœ‰6ä¸ªå‚æ•°ã€‚äº‹å®ä¸Š ï¼Œå½“å¤šé¡¹å¼é¡¹æ•°è¶³å¤Ÿå¤šæ—¶ï¼Œé‚£ä¹ˆå¯èƒ½èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ªåˆ†å¼€æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„åˆ†ç•Œçº¿ï¼Œå½“åªæœ‰ä¸¤é¡¹æ—¶ï¼Œè¿™ç§æ–¹æ³•ç¡®å®èƒ½å¾—åˆ°ä¸é”™çš„ç»“æœã€‚å› ä¸ºä½ å¯ä»¥æŠŠ <span class="math inline">\(x_1\)</span> å’Œ <span class="math inline">\(x_2\)</span> çš„æ‰€æœ‰ç»„åˆéƒ½åŒ…å«åˆ°å¤šé¡¹å¼ä¸­ã€‚ä½†æ˜¯å¯¹äºè®¸å¤šå¤æ‚çš„æœºå™¨å­¦ä¹ é—®é¢˜ï¼Œæ¶‰åŠçš„é¡¹å¾€å¾€å¤šäºä¸¤é¡¹ã€‚æˆ‘ä»¬ä¹‹å‰å·²ç»è®¨è®ºè¿‡æˆ¿ä»·é¢„æµ‹çš„é—®é¢˜ï¼Œå‡è®¾ç°åœ¨è¦å¤„ç†çš„æ˜¯å…³äºä½æˆ¿çš„åˆ†ç±»é—®é¢˜è€Œä¸æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ã€‚å‡è®¾ä½ å¯¹ä¸€æ ‹æˆ¿å­çš„å¤šæ–¹é¢ç‰¹ç‚¹éƒ½æœ‰æ‰€äº†è§£ï¼Œä½ æƒ³é¢„æµ‹æˆ¿å­åœ¨æœªæ¥åŠå¹´å†…èƒ½è¢«å–å‡ºå»çš„æ¦‚ç‡ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚æˆ‘ä»¬å¯ä»¥æƒ³å‡ºå¾ˆå¤šç‰¹å¾ï¼Œå¯¹äºä¸åŒçš„æˆ¿å­æœ‰å¯èƒ½æœ‰ä¸Šç™¾ä¸ªç‰¹å¾ï¼Œå¯¹äºè¿™ç±»é—®é¢˜ï¼Œå¦‚æœè¦åŒ…å«æ‰€æœ‰çš„äºŒæ¬¡é¡¹ï¼Œå³ä½¿åªåŒ…å«äºŒé¡¹å¼æˆ–å¤šé¡¹å¼çš„è®¡ç®—ï¼Œæœ€ç»ˆçš„å¤šé¡¹å¼ä¹Ÿä¼šæœ‰å¾ˆå¤šã€‚</p><p>åŒ…å«æ‰€æœ‰ <span class="math inline">\(n\)</span> ä¸ªç‰¹å¾ <span class="math inline">\(r\)</span> æ¬¡é¡¹çš„å¤šé¡¹å¼é¡¹çš„ä¸ªæ•°æ˜¯ï¼š<span class="math inline">\(\frac{(n+r-1)!}{r!(n-1)!}\)</span></p><p>æ¯”å¦‚æœ‰100ä¸ªç‰¹å¾ï¼Œé‚£ä¹ˆæ‰€æœ‰äºŒæ¬¡é¡¹çš„ä¸ªæ•°ä¸º <span class="math inline">\(\frac{(100 + 2 - 1)!}{(2*(100 - 1)!)} = 5050\)</span></p><p>We can approximate the growth of the number of new features we get with all quadratic terms with <span class="math inline">\(O(n^2/2)\)</span>. And if you wanted to include all cubic terms in your hypothesis, the features would grow asymptotically at <span class="math inline">\(O(n^3)\)</span>. These are very steep growths, so as the number of our features increase, the number of quadratic or cubic features increase very rapidly and becomes quickly impractical.</p><p>ç¥ç»ç½‘ç»œæä¾›äº†ä¸€ç§å¯è¡Œçš„æ–¹å¼æ¥åº”ç”¨æœ‰è®¸å¤šç‰¹å¾çš„å¤æ‚çš„å‡½æ•°çš„å­¦ä¹ ã€‚</p><h2><span id="ç¥ç»å’Œå¤§è„‘">ç¥ç»å’Œå¤§è„‘</span></h2><p>ç¥ç»ç½‘ç»œæ¨¡å‹å°±æ˜¯æ¨¡ä»¿æˆ‘ä»¬å¤§è„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚</p><p>æˆ‘ä»¬çš„å¤§è„‘åªç”¨ä¸€ä¸ªå­¦ä¹ ç®—æ³•å­¦ä¹ æ‰€æœ‰ä¸åŒçš„å‡½æ•°ã€‚ç§‘å­¦å®¶å°è¯•åˆ‡æ–­è¿æ¥è€³æœµä¸æ§åˆ¶å¬è§‰çš„çš„ç¥ç»å¹¶æŠŠå…‰æ„Ÿåº”å™¨å®˜ä¸Šå’Œæ§åˆ¶å¬è§‰çš„ç¥ç»é‡æ–°è¿æ¥èµ·æ¥ï¼Œç»“æœæ§åˆ¶å¬è§‰çš„ç¥ç»å­¦ä¼šäº†çœ‹(see)ã€‚</p><p>è¿™å«ç¥ç»å¯å¡‘æ€§(<a href="https://www.wikiwand.com/en/Neuroplasticity" target="_blank" rel="noopener">Neuroplasticity</a>)ï¼Œå¹¶æœ‰è®¸å¤šä¾‹å­è¯æ˜å®ƒæ˜¯æ­£ç¡®çš„ã€‚</p><h2><span id="æ¨¡å‹è§£é‡Š">æ¨¡å‹è§£é‡Š</span></h2><p>Let's examine how we will represent a hypothesis function using neural networks.</p><p>At a very simple level, neurons are basically computational units that take input (dendritesæ ‘çª) as electrical input (called &quot;spikes&quot;) that are channeled to outputs (axonsè½´çª).</p><p>In our model, our dendrites are like the input features (x1â‹¯xn), and the output is the result of our hypothesis function.</p><p>In this model our <span class="math inline">\(x_0\)</span> input node is sometimes called the &quot;bias unit.&quot; It is always equal to 1.</p><p>In neural networks, we use the same logistic function as in classification: <span class="math inline">\(\frac{1}{1+e^{âˆ’Î¸^Tx}}\)</span>. In neural networks however we sometimes call it a sigmoid (logistic) activation function.</p><p>Our &quot;theta&quot; parameters are sometimes instead called &quot;weights&quot; in the neural networks model.</p><p>Visually, a simplistic representation looks like: <span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2\end{bmatrix}â†’[   ]â†’h_Î¸(x)\]</span></p><p>Our input nodes (layer 1) go into another node (layer 2), and are output as the hypothesis function.</p><p>The first layer is called the &quot;input layer&quot; and the final layer the &quot;output layer,&quot; which gives the final value computed on the hypothesis.</p><p>We can have intermediate layers of nodes between the input and output layers called the &quot;hidden layer.&quot; We label these intermediate or &quot;hidden&quot; layer nodes <span class="math inline">\(a^2_0â‹¯a^2_n\)</span> and call them &quot;activation units.&quot;</p><p><span class="math inline">\(a^{(j)}_i\)</span> = <strong>&quot;activation&quot; of unit i in layer j</strong> <span class="math inline">\(Î˜^{(j)}\)</span> = <strong>matrix of weights controlling function mapping from layer j to layer j+1</strong></p><p>If we had one hidden layer, it would look visually something like:</p><p><span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2 \\x_3\end{bmatrix}â†’\begin{bmatrix}a_1^{(2)}  \\a_2^{(2)} \\a_3^{(2)} \end{bmatrix}â†’h_Î¸(x)\]</span></p><p>The values for each of the &quot;activation&quot; nodes is obtained as follows:</p><p><span class="math display">\[a^{(2)}_1=g(Î˜^{(1)}_{10}x_0+Î˜^{(1)}_{11}x_1+Î˜^{(1)}_{12}x_2+Î˜^{(1)}_{13}x_3)\]</span> <span class="math display">\[a^{(2)}_2=g(Î˜^{(1)}_{20}x_0+Î˜^{(1)}_{21}x_1+Î˜^{(1)}_{22}x_2+Î˜^{(1)}_{23}x_3)\]</span> <span class="math display">\[a^{(2)}_3=g(Î˜^{(1)}_{30}x_0+Î˜^{(1)}_{31}x_1+Î˜^{(1)}_{32}x_2+Î˜^{(1)}_{33}x_3)\]</span> <span class="math display">\[h_\theta(x) = a^{(3)}_1 = g(Î˜^{(2)}_{10}a_0^{(2)}+Î˜^{(2)}_{11}a^{(2)}_1+Î˜^{(2)}_{12}a_2^{(2)}+Î˜^{(2)}_{13}a_3^{(2)})\]</span></p><p>This is saying that we compute our activation nodes by using a <span class="math inline">\(3Ã—4\)</span> matrix of parameters. We apply each row of the parameters to our inputs to obtain the value for one activation node. Our hypothesis output is the logistic function applied to the sum of the values of our activation nodes, which have been multiplied by yet another parameter matrix <span class="math inline">\(Î˜^{(2)}\)</span> containing the weights for our second layer of nodes.</p><p>Each layer gets its own matrix of weights, <span class="math inline">\(Î˜^{(j)}\)</span>.</p><p>The dimensions of these matrices of weights is determined as follows: <strong>If network has <span class="math inline">\(s_j\)</span> units in layer <span class="math inline">\(j\)</span> and <span class="math inline">\(s_{j+1}\)</span> units in layer <span class="math inline">\(j+1\)</span>, then <span class="math inline">\(Î˜^{(j)}\)</span> will be of dimension <span class="math inline">\(s_{j+1}Ã—(s_j+1)\)</span>.</strong></p><p>The <span class="math inline">\(+1\)</span> comes from the addition in <span class="math inline">\(Î˜^{(j)}\)</span> of the &quot;bias nodes,&quot; <span class="math inline">\(x_0\)</span> and <span class="math inline">\(Î˜^{(j)}_0\)</span>. In other words the output nodes will not include the bias nodes while the inputs will.</p><p>Example: layer 1 has 2 input nodes and layer 2 has 4 activation nodes. Dimension of <span class="math inline">\(Î˜^{(1)}\)</span> is going to be <span class="math inline">\(4Ã—3\)</span> where <span class="math inline">\(s_j=2\)</span> and <span class="math inline">\(s_{j+1}=4\)</span>, so <span class="math inline">\(s_{j+1}Ã—(s_j+1)=4Ã—3\)</span>.</p><h3><span id="vectorized-implementation">Vectorized implementation</span></h3><p>We're going to define a new variable <span class="math inline">\(z^{(j)}_k\)</span> that encompasses the parameters inside our <span class="math inline">\(g\)</span> function. In our previous example if we replaced the variable <span class="math inline">\(z\)</span> for all the parameters we would get: <span class="math display">\[a^{(2)}_1=g(z^{(2)}_1)\]</span> <span class="math display">\[a^{(2)}_2=g(z^{(2)}_2)\]</span> <span class="math display">\[a^{(2)}_3=g(z^{(2)}_3)\]</span></p><p>In other words, for layer <span class="math inline">\(j=2\)</span> and node <span class="math inline">\(k\)</span>, the variable z will be:</p><p><span class="math inline">\(z^{(2)}_k=Î˜^{(1)}_{k,0}x_0+Î˜^{(1)}_{k,1}x_1+â‹¯+Î˜^{(1)}_{k,n}x_n\)</span></p><p>The vector representation of <span class="math inline">\(x\)</span> and <span class="math inline">\(z^{(j)}\)</span> is:</p><p><span class="math display">\[x=\begin{bmatrix}x_0  \\x_1 \\\vdots \\x_n\end{bmatrix} z(j)=\begin{bmatrix}z_1^{(j)}  \\z_2^{(j)} \\\vdots \\z_n^{(j)}\end{bmatrix}\]</span></p><p>Setting <span class="math inline">\(x=a^{(1)}\)</span>, we can rewrite the equation as: <span class="math display">\[z^{(j)} = Î˜^{(jâˆ’1)}a^{(jâˆ’1)}\]</span></p><p>We are multiplying our matrix <span class="math inline">\(Î˜^{(jâˆ’1)}\)</span> with dimensions <span class="math inline">\(s_jÃ—(n+1)\)</span> (where <span class="math inline">\(s_j\)</span> is the number of our activation nodes) by our vector <span class="math inline">\(a^{(jâˆ’1)}\)</span> with height <span class="math inline">\((n+1)\)</span>. This gives us our vector <span class="math inline">\(z^{(j)}\)</span> with height <span class="math inline">\(s_j\)</span>. Now we can get a vector of our activation nodes for layer <span class="math inline">\(j\)</span> as follows: <span class="math display">\[a^{(j)}=g(z^{(j)})\]</span></p><p>Where our function <span class="math inline">\(g\)</span> can be applied element-wise to our vector <span class="math inline">\(z^{(j)}\)</span>.</p><p>We can then add a bias unit (equal to 1) to layer <span class="math inline">\(j\)</span> after we have computed <span class="math inline">\(a^{(j)}\)</span>. This will be element <span class="math inline">\(a^{(j)}_0\)</span> and will be equal to 1.</p><p>To compute our final hypothesis, let's first compute another z vector: <span class="math display">\[z^{(j+1)}=Î˜^{(j)}a^{(j)}\]</span></p><p>We get this final <span class="math inline">\(z\)</span> vector by multiplying the next theta matrix after <span class="math inline">\(Î˜^{(jâˆ’1)}\)</span> with the values of all the activation nodes we just got.</p><p>This last theta matrix (<span class="math inline">\(Î˜^{(j)}\)</span>) will have only one row so that our result is a single number. We then get our final result with: <span class="math display">\[h_Î˜(x)=a^{(j+1)}=g(z^{(j+1)})\]</span></p><p>Notice that in this <strong>last step</strong>, between layer <span class="math inline">\(j\)</span>and layer <span class="math inline">\(j+1\)</span>, we are doing exactly the same thing as we did in logistic regression.</p><p>Adding all these intermediate layers in neural networks allows us to more elegantly produce interesting and more complex non-linear hypotheses.</p><h2><span id="ä¸¾ä¾‹è¯´æ˜">ä¸¾ä¾‹è¯´æ˜</span></h2><h3><span id="x_1-and-x_2"><span class="math inline">\(x_1\)</span> AND <span class="math inline">\(x_2\)</span></span></h3><p>A simple example of applying neural networks is by predicting <span class="math inline">\(x_1\)</span> <strong>AND</strong> <span class="math inline">\(x_2\)</span>, which is the logical <em>'and'</em> operator and is only true if both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are <span class="math inline">\(1\)</span>.</p><p>The graph of our functions will look like: <span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2\end{bmatrix}â†’[g(z^{(2)})]â†’h_Î˜(x)\]</span></p><p>Remember that <span class="math inline">\(x_0\)</span> is our bias variable and is always 1.</p><p>Let's set our first theta matrix as: <span class="math inline">\(Î˜^{(1)} = [\)</span> <span class="math inline">\(-30\)</span> <span class="math inline">\(20\)</span> <span class="math inline">\(20]\)</span></p><p>This will cause the output of our hypothesis to only be positive if both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are <span class="math inline">\(1\)</span>. In other words: <span class="math inline">\(h_Î˜(x)=g(âˆ’30+20x_1+20x_2)\)</span></p><p><span class="math inline">\(x_1=0\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=0\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(âˆ’30) â‰ˆ 0\)</span> <span class="math inline">\(x_1=0\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=1\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(âˆ’10)â‰ˆ0\)</span> <span class="math inline">\(x_1=1\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=0\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(âˆ’10)â‰ˆ0\)</span> <span class="math inline">\(x_1=1\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=1\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(10)â‰ˆ1\)</span></p><p>So we have constructed one of the fundamental operations in computers by using a small neural network rather than using an actual AND gate. Neural networks can also be used to simulate all the other logical gates.</p><h3><span id="nor-or-xnor">NORã€ORã€XNOR</span></h3><p>The <span class="math inline">\(Î˜^{(1)}\)</span> matrices for <span class="math inline">\(AND\)</span>, <span class="math inline">\(NOR\)</span>, and <span class="math inline">\(OR\)</span> are:</p><p><span class="math inline">\(AND\)</span>: <span class="math display">\[Î˜^{(1)} = \begin{bmatrix}-30 &amp; 20 &amp; 20\end{bmatrix}\]</span></p><p><span class="math inline">\(NOR\)</span>: <span class="math display">\[Î˜^{(1)} = \begin{bmatrix}10 &amp; -20 &amp; -20\end{bmatrix}\]</span></p><p><span class="math inline">\(OR\)</span>: <span class="math display">\[Î˜^{(1)}=\begin{bmatrix}-10 &amp; 20 &amp; 20\end{bmatrix}\]</span></p><p>We can combine these to get the <span class="math inline">\(XNOR\)</span> logical operator (which gives 1 if <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are both 0 or both 1). <span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2\end{bmatrix}â†’\begin{bmatrix}a_1^{(2)}  \\a_2^{(2)} \\\end{bmatrix}â†’[a^{(3)}]â†’h_Î˜(x)\]</span></p><p>For the transition between the first and second layer, we'll use a <span class="math inline">\(Î˜^{(1)}\)</span> matrix that combines the values for <span class="math inline">\(AND\)</span> and <span class="math inline">\(NOR\)</span>: <span class="math display">\[Î˜^{(1)}=\begin{bmatrix}-30 &amp; 20 &amp; 20 \\10 &amp; -20 &amp; -20\end{bmatrix}\]</span> For the transition between the second and third layer, we'll use a <span class="math inline">\(Î˜^{(2)}\)</span> matrix that uses the value for <span class="math inline">\(OR\)</span>: <span class="math display">\[Î˜^{(2)}=\begin{bmatrix}-10 &amp; 20 &amp; 20\end{bmatrix}\]</span></p><p>Let's write out the values for all our nodes: <span class="math inline">\(a^{(2)}=g(Î˜^{(1)}â‹…x)\)</span> <span class="math inline">\(a^{(3)}=g(Î˜^{(2)}â‹…a^{(2)})\)</span> <span class="math inline">\(h_Î˜(x)=a^{(3)}\)</span></p><p>And there we have the <span class="math inline">\(XNOR\)</span> operator using one hidden layer!</p><h2><span id="multiclass-classification">Multiclass Classification</span></h2><p>To classify data into multiple classes, we let our hypothesis function return a vector of values. Say we wanted to classify our data into one of four final resulting classes:</p><p><span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2 \\\vdots \\x_n\end{bmatrix} â†’ \begin{bmatrix}a_0^{(2)}  \\a_1^{(2)} \\a_2^{(2)} \\\vdots \\\end{bmatrix} â†’ \begin{bmatrix}a_0^{(3)}  \\a_1^{(3)} \\a_2^{(3)} \\\vdots \\\end{bmatrix}â†’ ... â†’ \begin{bmatrix}h_\theta(x)_1  \\h_\theta(x)_2 \\h_\theta(x)_3 \\h_\theta(x)_4 \\\end{bmatrix} â†’\]</span></p><p>Our final layer of nodes, when multiplied by its theta matrix, will result in another vector, on which we will apply the <span class="math inline">\(g()\)</span> logistic function to get a vector of hypothesis values.</p><p>Our resulting hypothesis for one set of inputs may look like: <span class="math display">\[h_Î˜(x)=\begin{bmatrix}0 \\0 \\1 \\0\end{bmatrix}\]</span></p><p>In which case our resulting class is the third one down, or <span class="math inline">\(h_Î˜(x)_3\)</span>.</p><p>We can define our set of resulting classes as <span class="math inline">\(y\)</span>: <span class="math display">\[y(i)=\begin{bmatrix}1 \\0 \\0 \\0\end{bmatrix},\begin{bmatrix}0 \\1 \\0 \\0\end{bmatrix}, \begin{bmatrix}0 \\0 \\1 \\0\end{bmatrix}, \begin{bmatrix}0 \\0 \\0 \\1\end{bmatrix}\]</span></p><p>Our final value of our hypothesis for a set of inputs will be one of the elements in <span class="math inline">\(y\)</span>.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Neural Network </tag>
            
            <tag> Dense </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æ­£åˆ™åŒ–è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜</title>
      <link href="/2016/02/07/%E6%AD%A3%E5%88%99%E5%8C%96%E8%A7%A3%E5%86%B3%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/"/>
      <url>/2016/02/07/%E6%AD%A3%E5%88%99%E5%8C%96%E8%A7%A3%E5%86%B3%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<blockquote><p>å‰è¨€ï¼šé€šå¸¸ä¸€ä¸ªå­¦ä¹ æ¼”ç®—æ³•æ˜¯å€Ÿç”±è®­ç»ƒèŒƒä¾‹æ¥è®­ç»ƒçš„ã€‚äº¦å³é¢„æœŸç»“æœçš„èŒƒä¾‹æ˜¯å¯çŸ¥çš„ã€‚è€Œå­¦ä¹ è€…åˆ™è¢«è®¤ä¸ºé¡»è¾¾åˆ°å¯ä»¥é¢„æµ‹å‡ºå…¶å®ƒèŒƒä¾‹çš„æ­£ç¡®çš„ç»“æœï¼Œå› æ­¤ï¼Œåº”é€‚ç”¨äºä¸€èˆ¬åŒ–çš„æƒ…å†µè€Œéåªæ˜¯è®­ç»ƒæ—¶æ‰€ä½¿ç”¨çš„ç°æœ‰èµ„æ–™ï¼ˆæ ¹æ®å®ƒçš„å½’çº³åå‘ï¼‰ã€‚ç„¶è€Œï¼Œå­¦ä¹ è€…å´ä¼šå»é€‚åº”è®­ç»ƒèµ„æ–™ä¸­å¤ªç‰¹åŒ–ä½†åˆéšæœºçš„ç‰¹å¾ï¼Œç‰¹åˆ«æ˜¯åœ¨å½“å­¦ä¹ è¿‡ç¨‹å¤ªä¹…æˆ–èŒƒä¾‹å¤ªå°‘æ—¶ã€‚åœ¨è¿‡é€‚çš„è¿‡ç¨‹ä¸­ï¼Œå½“é¢„æµ‹è®­ç»ƒèŒƒä¾‹ç»“æœçš„è¡¨ç°å¢åŠ æ—¶ï¼Œåº”ç”¨åœ¨æœªçŸ¥èµ„æ–™çš„è¡¨ç°åˆ™å˜æ›´å·®ã€‚â€”â€”From <a href="https://zh.wikipedia.org/zh-hans/%E9%81%8E%E9%81%A9?oldformat=true" target="_blank" rel="noopener">WikiPedia</a></p></blockquote><a id="more"></a><!-- toc --><ul><li><a href="#è¿‡åº¦æ‹Ÿåˆoverfittingé—®é¢˜">è¿‡åº¦æ‹Ÿåˆ(Overfitting)é—®é¢˜</a></li><li><a href="#ä»£ä»·å‡½æ•°cost-function">ä»£ä»·å‡½æ•°ï¼ˆCost Functionï¼‰</a></li><li><a href="#æ­£åˆ™åŒ–çº¿æ€§å›å½’">æ­£åˆ™åŒ–çº¿æ€§å›å½’</a><ul><li><a href="#æ¢¯åº¦ä¸‹é™gradient-descent">æ¢¯åº¦ä¸‹é™(Gradient Descent)</a></li><li><a href="#æ­£è§„æ–¹ç¨‹normal-equation">æ­£è§„æ–¹ç¨‹(Normal Equation)</a></li></ul></li><li><a href="#æ­£åˆ™åŒ–é€»è¾‘å›å½’">æ­£åˆ™åŒ–é€»è¾‘å›å½’</a><ul><li><a href="#ä»£ä»·å‡½æ•°">ä»£ä»·å‡½æ•°</a></li><li><a href="#æ¢¯åº¦ä¸‹é™">æ¢¯åº¦ä¸‹é™</a></li></ul></li></ul><!-- tocstop --><h2><span id="è¿‡åº¦æ‹Ÿåˆoverfittingé—®é¢˜">è¿‡åº¦æ‹Ÿåˆ(Overfitting)é—®é¢˜</span></h2><p>æ­£åˆ™åŒ–(Regularzation)å°±æ˜¯è¢«è®¾è®¡ä¸ºè§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜çš„ã€‚</p><p>åœ¨ä¸€ä¸ªå‡½æ•°æ‹Ÿåˆæ•°æ®é›†çš„æ—¶å€™ä¼šå‡ºç°ä¸‰ç§æƒ…å†µï¼šæ¬ æ‹Ÿåˆ(<strong>high bias</strong> or <strong>underfitting</strong>)ã€æ­£å¥½æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆ(<strong>overfitting</strong> or <strong>high variance</strong>)ã€‚</p><ul><li><p>æ¬ æ‹Ÿåˆ(<strong>high bias</strong> or <strong>underfitting</strong>)æ˜¯æˆ‘ä»¬çš„å‡æƒ³å‡½æ•°å¯¹æ•°æ®è¶‹åŠ¿æ‹Ÿåˆç¨‹åº¦éå¸¸ç³Ÿç³•ï¼Œé€ æˆè¿™ç§æƒ…å†µé€šå¸¸æ˜¯ç”±äºå‡½æ•°å¤ªç®€å•æˆ–è€…ä½¿ç”¨çš„å‚æ•°éå¸¸å°‘ï¼›</p></li><li><p>è¿‡æ‹Ÿåˆ(<strong>overfitting</strong> or <strong>high variance</strong>)æ˜¯å‡æƒ³å‡½æ•°å¯¹è®­ç»ƒæ•°æ®æ‹Ÿåˆçš„éå¸¸å¥½ï¼Œä½†æ˜¯å¯¹æœªçŸ¥æ•°æ®çš„é¢„æµ‹å´ä¸å°½å¦‚äººæ„ï¼Œé€šå¸¸æ˜¯ç”±å‡è±¡å‡½æ•°éå¸¸å¤æ‚å¹¶ä¸”ä½¿ç”¨çš„å‚æ•°éå¸¸å¤šï¼Œä½¿å‡½æ•°äº§ç”Ÿè®¸å¤šä¸å¿…è¦çš„æ³¢æµªã€‚</p></li></ul><p>è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ä¸»è¦æœ‰ä¸¤ä¸ªæ–¹æ³•ï¼š 1. å‡å°‘ç‰¹å¾ï¼ˆå‚æ•°ï¼‰çš„æ•°é‡ * è‡ªå·±å†³å®šä¿ç•™å“ªäº›ç‰¹å¾ * ç”¨ä¸€äº›é€‰æ‹©ç®—æ³•æ¥å†³å®šä¿ç•™å“ªäº›ç‰¹å¾ 2. æ­£åˆ™åŒ– * ä¿ç•™æ‰€æœ‰ç‰¹å¾ï¼ˆå‚æ•°ï¼‰ï¼Œä½†æ˜¯å‡å°å‚æ•°<span class="math inline">\(\theta_j\)</span>çš„å€¼ã€‚</p><h2><span id="ä»£ä»·å‡½æ•°cost-function">ä»£ä»·å‡½æ•°ï¼ˆCost Functionï¼‰</span></h2><p>å‡è®¾æˆ‘ä»¬ç”¨ä¸€ä¸ªäºŒæ¬¡å‡½æ•°æ¥æ‹Ÿåˆä¸€äº›æ•°æ®,å®ƒç»™äº†æˆ‘ä»¬ä¸€ä¸ªå¯¹æ•°æ®å¾ˆå¥½çš„æ‹Ÿåˆï¼Œç„¶è€Œå¦‚æœæˆ‘ä»¬ç”¨ä¸€ä¸ªæ›´é«˜æ¬¡çš„å¤šé¡¹å¼å»æ‹Ÿåˆï¼Œæ¯”å¦‚ <span class="math inline">\(Î¸_0+Î¸_1x+Î¸_2x^2+Î¸_3x^3+Î¸_4x^4\)</span>ï¼Œæˆ‘ä»¬æœ€ç»ˆå¯èƒ½å¾—åˆ°ä¸€ä¸ªæ›²çº¿èƒ½éå¸¸å¥½åœ°æ‹Ÿåˆè®­ç»ƒé›†ï¼Œä½†æ˜¯å®ƒè¿‡åº¦æ‹Ÿåˆäº†æ•°æ®ï¼Œä¸€èˆ¬æ€§å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚</p><p>è®©æˆ‘ä»¬è€ƒè™‘ä¸‹é¢çš„å‡è®¾ï¼šæˆ‘ä»¬æƒ³è¦åŠ ä¸Šæƒ©ç½šé¡¹ä»è€Œä½¿å‚æ•° <span class="math inline">\(Î¸_3\)</span> å’Œ <span class="math inline">\(Î¸_4\)</span> è¶³å¤Ÿçš„å°ï¼Œè€Œé¿å…ç›´æ¥åˆ æ‰å®ƒä»¬ï¼Œåªéœ€å¦‚ä¸‹ä¿®æ”¹ä»£ä»·å‡½æ•°ï¼š <span class="math display">\[\min_Î¸ \frac{1}{2m}(\sum^m_{i=1}(h_Î¸(x^{(i)})âˆ’y^{(i)})^2+1000â‹…Î¸^2_3+1000â‹…Î¸^2_4)\]</span></p><p>æˆ‘ä»¬å¯¹ä»£ä»·å‡½æ•°æ·»åŠ ä¸€äº›äº†é¡¹ï¼šåŠ ä¸Š 1000 ä¹˜ä»¥ <span class="math inline">\(Î¸_3\)</span> çš„å¹³æ–¹ï¼Œå†åŠ ä¸Š 1000 ä¹˜ä»¥ <span class="math inline">\(Î¸_4\)</span> çš„å¹³æ–¹ï¼Œ1000 åªæ˜¯æˆ‘éšä¾¿å†™çš„æŸä¸ªè¾ƒå¤§çš„æ•°å­—è€Œå·²ã€‚ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬è¦æœ€å°åŒ–è¿™ä¸ªå‡½æ•°ï¼Œä¸ºäº†ä½¿è¿™ä¸ªæ–°çš„ä»£ä»·å‡½æ•°æœ€å°åŒ–ï¼Œæˆ‘ä»¬è¦è®© <span class="math inline">\(Î¸_3\)</span> å’Œ <span class="math inline">\(Î¸_4\)</span> å°½å¯èƒ½å¾—å°ï¼Œå¯¹å§ï¼Ÿå¦‚æœæˆ‘ä»¬è¿™ä¹ˆåšäº†ï¼Œ<span class="math inline">\(Î¸_3\)</span> å’Œ <span class="math inline">\(Î¸_4\)</span>å¯èƒ½ä¼šè¶‹è¿‘äºï¼ï¼Œç»“æœæ¥è¿‘æˆä¸€ä¸ªäºŒæ¬¡å‡½æ•°ã€‚</p><p>æ›´ä¸€èˆ¬åœ°å¯ä»¥è¡¨æ˜ï¼Œè¿™äº›å‚æ•°çš„å€¼è¶Šå°é€šå¸¸å¯¹åº”äºè¶Šå…‰æ»‘çš„å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯æ›´åŠ ç®€å•çš„å‡½æ•°ã€‚å› æ­¤ï¼Œå°±ä¸æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚</p><p>ç”±äºåœ¨å®é™…åº”ç”¨ä¸­å‚æ•°å¯èƒ½å¾ˆå¤šï¼Œæ¯”å¦‚æœ‰100ä¸ªï¼Œéœ€è¦ç”¨æ­£åˆ™åŒ–ï¼Œä½†æ˜¯æˆ‘ä¸çŸ¥é“å…·ä½“å“ªä¸ªå‚æ•°æˆ–å“ªå‡ ä¸ªå‚æ•°éœ€è¦ç¼©å°ï¼Œæ‰€ä»¥æˆ‘ä»¬åªèƒ½è®©æ‰€æœ‰å‚æ•°ä»<span class="math inline">\(Î¸_1\)</span> <span class="math inline">\(Î¸_2\)</span> <span class="math inline">\(Î¸_3\)</span> ç›´åˆ° <span class="math inline">\(Î¸_{100}\)</span> çš„å€¼å˜å°ã€‚(é¡ºä¾¿è¯´ä¸€ä¸‹ï¼ŒæŒ‰ç…§æƒ¯ä¾‹æ¥è®²ï¼Œæˆ‘ä»¬ä»ç¬¬ä¸€ä¸ªè¿™é‡Œå¼€å§‹ï¼Œæ‰€ä»¥æˆ‘å®é™…ä¸Šæ²¡æœ‰å»æƒ©ç½š <span class="math inline">\(Î¸_0\)</span> , å› æ­¤ <strong><span class="math inline">\(Î¸_0\)</span> çš„å€¼æ˜¯å¤§çš„</strong>, è¿™å°±æ˜¯ä¸€ä¸ªçº¦å®šã€‚)</p><p>æ‰€ä»¥ä»£ä»·å‡½æ•°è¢«ä¿®æ”¹ä¸ºï¼š <span class="math display">\[\min_Î¸ \frac{1}{2m}[\sum^m_{i=1}(h_Î¸(x^{(i)})âˆ’y^{(i)})^2+\lambda \sum^n_{j=1}\theta^2_j]\]</span></p><p>å…¶ä¸­ <span class="math inline">\(\lambda\)</span> ä¸º<strong>æ­£åˆ™åŒ–å‚æ•°(regularization parameter)</strong>ã€‚</p><p><span class="math inline">\(\lambda\)</span> è¦åšçš„å°±æ˜¯æ§åˆ¶åœ¨ä¸¤ä¸ªä¸åŒç›®æ ‡ä¸­çš„<strong>å¹³è¡¡</strong>å…³ç³»ã€‚ç¬¬ä¸€ä¸ªç›®æ ‡å°±æ˜¯æˆ‘ä»¬æƒ³è¦ä½¿<strong>å‡è®¾æ›´å¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®</strong>ï¼Œæˆ‘ä»¬å¸Œæœ›å‡è®¾èƒ½å¤Ÿå¾ˆå¥½çš„é€‚åº”è®­ç»ƒé›†; è€Œç¬¬äºŒä¸ªç›®æ ‡æ˜¯æˆ‘ä»¬æƒ³è¦<strong>ä¿æŒå‚æ•°å€¼è¾ƒå°</strong>ã€‚é€šè¿‡æ­£åˆ™åŒ–ç›®æ ‡å‡½æ•°ï¼Œå®ƒä¼šæ‰¾åˆ°è¿™ä¸¤è€…ä¹‹é—´çš„å¹³è¡¡ï¼Œä»è€Œä¿æŒå‡è®¾çš„å½¢å¼ç›¸å¯¹ç®€å•, æ¥é¿å…è¿‡åº¦çš„æ‹Ÿåˆã€‚</p><p>ä¸è¿‡ï¼Œå¦‚æœ <span class="math inline">\(\lambda\)</span> è®¾ç½®è¿‡å¤§ï¼Œå‡æƒ³å‡½æ•°å¯èƒ½ä¼šè¿‡äºå…‰æ»‘å¹³å¦è€Œå¯¼è‡´æ¬ æ‹Ÿåˆ(underfitting)ã€‚</p><h2><span id="æ­£åˆ™åŒ–çº¿æ€§å›å½’">æ­£åˆ™åŒ–çº¿æ€§å›å½’</span></h2><p>å¯¹äºçº¿æ€§å›å½’çš„æ±‚è§£ï¼Œæˆ‘ä»¬ä¹‹å‰æ¨å¯¼äº†ä¸¤ç§å­¦ä¹ ç®—æ³•ï¼Œä¸€ç§åŸºäº<strong>æ¢¯åº¦ä¸‹é™</strong>ï¼Œä¸€ç§åŸºäº<strong>æ­£è§„æ–¹ç¨‹</strong>ã€‚æˆ‘ä»¬å°†ç»§ç»­æŠŠè¿™ä¸¤ä¸ªç®—æ³•æ¨å¹¿åˆ°<strong>æ­£åˆ™åŒ–çº¿æ€§å›å½’</strong>ä¸­å» ã€‚</p><h3><span id="æ¢¯åº¦ä¸‹é™gradient-descent">æ¢¯åº¦ä¸‹é™(Gradient Descent)</span></h3><p>å› ä¸ºæˆ‘ä»¬ä¸æƒ©ç½šç¬¬é›¶é¡¹å‚æ•°ï¼Œæ‰€ä»¥æˆ‘ä»¬æŠŠæ¢¯åº¦ä¸‹é™çš„è¿­ä»£æ–¹ç¨‹ä¸­æ›´æ–° <span class="math inline">\(\theta_0\)</span> å’Œæ›´æ–°å…¶ä»–å‚æ•°åˆ†å¼€ï¼Œå˜ä¸ºå¦‚ä¸‹å½¢å¼ï¼š <span class="math inline">\(Repeat\{\)</span> <span class="math display">\[\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)}\]</span> <span class="math display">\[\theta_j := \theta_j - \alpha [(\frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}) + \frac{\lambda}{m}\theta_j]\]</span> <span class="math inline">\(\}\)</span></p><p>è¿™ä¸€é¡¹ <span class="math inline">\(\frac{\lambda}{m}\theta_j\)</span> å°±æ˜¯æ­£åˆ™åŒ–ã€‚</p><p>ç¬¬äºŒä¸ªæ–¹ç¨‹ä¹Ÿå¯ä»¥åˆå¹¶åŒç±»é¡¹å˜æˆï¼š <span class="math display">\[\theta_j := \theta_j(1 - \alpha\frac{\lambda}{m}) - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\]</span></p><p>ç”±äº <span class="math inline">\(Î±\frac{Î»}{m}\)</span> é€šå¸¸æ˜¯å¾ˆå°çš„ï¼Œæ‰€ä»¥æ–¹ç¨‹çš„ç¬¬ä¸€é¡¹ <span class="math inline">\(1 - \alpha\frac{\lambda}{m}\)</span> ä¸€èˆ¬æ¥è¯´å°†æ˜¯ä¸€ä¸ªæ¯”1å°ä¸€ç‚¹ç‚¹çš„å€¼ã€‚æˆ‘ä»¬å¯ä»¥æŠŠå®ƒæƒ³æˆä¸€ä¸ªåƒ0.99ä¸€æ ·çš„æ•°å­—ï¼Œæ‰€ä»¥å¯¹ <span class="math inline">\(Î¸_j\)</span> æ›´æ–°çš„ç»“æœå¯ä»¥çœ‹ä½œæ˜¯è¢«æ›¿æ¢ä¸º <span class="math inline">\(Î¸_j\)</span> çš„0.99å€ï¼Œä¹Ÿå°±æ˜¯ <span class="math inline">\(Î¸_j\)</span> ä¹˜ä»¥0.99æŠŠ <span class="math inline">\(Î¸_j\)</span> å‘ 0 å‹ç¼©äº†ä¸€ç‚¹ç‚¹ï¼Œæ‰€ä»¥è¿™ä½¿å¾— <span class="math inline">\(Î¸_j\)</span> å°äº†ä¸€ç‚¹ï¼Œæ›´æ­£å¼åœ°è¯´ Î¸j çš„å¹³æ–¹èŒƒæ•°æ›´å°äº†ã€‚å¦å¤–ï¼Œæ–¹ç¨‹çš„ç¬¬äºŒé¡¹å®é™…ä¸Šè·Ÿæˆ‘ä»¬åŠ å…¥äº†æ­£åˆ™é¡¹ä¹‹å‰ä¸€æ ·ã€‚</p><h3><span id="æ­£è§„æ–¹ç¨‹normal-equation">æ­£è§„æ–¹ç¨‹(Normal Equation)</span></h3><p>æ­£åˆ™åŒ–çš„æ­£è§„æ–¹ç¨‹å¦‚ä¸‹ï¼š <span class="math display">\[\theta = (X^TX + \lambda \cdot L)^{-1}X^Ty\]</span> å…¶ä¸­ï¼Œ<span class="math display">\[L = \begin{bmatrix}0     \\&amp; 1 \\&amp; &amp; 1 \\ &amp; &amp; &amp; \ddots &amp; \\  &amp; &amp;  &amp; &amp; 1\end{bmatrix}\]</span> å®ƒçš„ç»´åº¦æ˜¯<span class="math inline">\((n+1)Ã—(n+1)\)</span>ã€‚</p><p>å³ä½¿ <span class="math inline">\(X^TX\)</span> æ˜¯ä¸å¯é€†çš„ï¼Œæ­£åˆ™åŒ–ä¹‹åï¼Œå³åŠ ä¸Š <span class="math inline">\(\lambda \cdot L\)</span> ä¹‹åï¼Œè¯¥çŸ©é˜µ <span class="math inline">\(X^TX + \lambda \cdot L\)</span> ä¸€å®šæ˜¯å¯é€†çš„ã€‚</p><h2><span id="æ­£åˆ™åŒ–é€»è¾‘å›å½’">æ­£åˆ™åŒ–é€»è¾‘å›å½’</span></h2><h3><span id="ä»£ä»·å‡½æ•°">ä»£ä»·å‡½æ•°</span></h3><p>å¤ä¹ ä¸€ä¸‹é€»è¾‘å›å½’çš„ä»£ä»·å‡½æ•°ï¼š <span class="math display">\[J(\theta) = -\frac{1}{m}\sum^{m}_{i = 1}[y^{(i)}\log(h_\theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\theta(x^{(i)}))]\]</span></p><p>æˆ‘ä»¬é€šè¿‡åœ¨æœ€åå¤šåŠ ä¸Šä¸€é¡¹æ¥å®Œæˆæ­£åˆ™åŒ–ï¼š <span class="math display">\[J(\theta) = -\frac{1}{m}\sum^{m}_{i = 1}[y^{(i)}\log(h_\theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\theta(x^{(i)}))] + \frac{\lambda}{2m}\sum^{n}_{j=1}\theta_j^2\]</span></p><p>å‘é‡å½¢å¼ä¸ºï¼š <span class="math display">\[J(\theta) = -\frac{1}{m}(\log(g(X\theta))^Ty + \log(1-g(X\theta))^T(1-y)) + \frac{\lambda}{2m}temp^Ttemp\]</span> å…¶ä¸­ <span class="math inline">\(temp = \theta;temp(1) = 0;\)</span></p><p><strong>æ³¨æ„ä»1å¼€å§‹è€Œä¸æ˜¯ä»0å¼€å§‹ï¼</strong></p><h3><span id="æ¢¯åº¦ä¸‹é™">æ¢¯åº¦ä¸‹é™</span></h3><p><span class="math inline">\(Repeat\{\)</span> <span class="math display">\[\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)}\]</span> <span class="math display">\[\theta_j := \theta_j - \alpha [(\frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}) + \frac{\lambda}{m}\theta_j]\]</span> <span class="math inline">\(\}\)</span></p><p>é™¤äº† <span class="math inline">\(h_\theta\)</span> è¡¨ç¤ºä¸åŒä»¥å¤–ï¼Œå…¶ä»–ä¸çº¿æ€§å›å½’çš„æ–¹ç¨‹ä¸€æ ·ã€‚</p><p>æœ€åå…³äºæ¢¯åº¦ï¼ˆåå¯¼æ•°ï¼‰çš„å‘é‡å½¢å¼ï¼š <span class="math display">\[\frac{\partial}{\partial\theta}J(\theta) = \frac{1}{m}[X^T(g(X\theta) - \overrightarrow{y}) + \lambda_v .* \theta]\]</span> å…¶ä¸­<span class="math inline">\(\lambda_v = \begin{bmatrix} 0 &amp; \lambda &amp; \lambda &amp; \cdots &amp; \lambda \\ \end{bmatrix}^T\)</span></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Regularization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Logistic Regression</title>
      <link href="/2016/02/03/Logistic%20Regression/"/>
      <url>/2016/02/03/Logistic%20Regression/</url>
      
        <content type="html"><![CDATA[<p>Now we are switching from regression problems to <strong>classification problems</strong>. Don't be confused by the name &quot;Logistic Regression&quot;; it is named that way for historical reasons and is actually an approach to <strong>classification</strong> problems, <strong>not regression</strong> problems.</p><a id="more"></a><!-- toc --><ul><li><a href="#classification">Classification</a></li><li><a href="#hypothesis-representation">Hypothesis Representation</a></li><li><a href="#decision-boundary">Decision Boundary</a></li><li><a href="#cost-function">Cost Function</a></li><li><a href="#simplified-cost-function-and-gradient-descent">Simplified Cost Function and Gradient Descent</a><ul><li><a href="#gradient-descent">Gradient Descent</a></li></ul></li><li><a href="#advanced-optimization">Advanced Optimization</a></li><li><a href="#multiclass-classification-one-vs-all">Multiclass Classification: One-vs-all</a></li></ul><!-- tocstop --><h2><span id="classification">Classification</span></h2><p>Instead of our output vector <span class="math inline">\(y\)</span> being a continuous range of values, it will only be 0 or 1. <span class="math display">\[yâˆˆ\{0,1\}\]</span></p><p>Where 0 is usually taken as the &quot;<strong>negative class</strong>&quot; and 1 as the &quot;<strong>positive class</strong>&quot;, but you are free to assign any representation to it.</p><p>We're only doing two classes for now, called a &quot;<strong>Binary Classification Problem</strong>.&quot;</p><p>One method is to use linear regression and map all predictions greater than 0.5 as a 1 and all less than 0.5 as a 0. This method doesn't work well because <em>classification is not actually a linear function</em>.</p><h2><span id="hypothesis-representation">Hypothesis Representation</span></h2><p>Our hypothesis should satisfy: <span class="math display">\[0â‰¤h_Î¸(x)â‰¤1\]</span></p><p>Our new form uses the &quot;<strong>Sigmoid Function</strong>&quot;, also called the &quot;<strong>Logistic Function</strong>&quot;: <span class="math display">\[hÎ¸(x)=g(Î¸^Tx)\]</span> <span class="math display">\[z=Î¸^Tx\]</span> <span class="math display">\[g(z)=\frac{1}{1+e^{âˆ’z}}\]</span></p><figure><img src="/images/1454474534412.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>The function <span class="math inline">\(g(z)\)</span>, shown here, maps any real number to the (0, 1) interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification. Try playing with interactive plot of sigmoid function <a href="https://www.desmos.com/calculator/bgontvxotm" target="_blank" rel="noopener">here</a>.</p><p>We start with our old hypothesis (linear regression), except that we want to restrict the range to 0 and 1. This is accomplished by plugging <span class="math inline">\(Î¸^Tx\)</span> into the Logistic Function.</p><p><span class="math inline">\(h_Î¸\)</span> will give us the <strong>probability</strong> that our output is 1. For example, <span class="math inline">\(h_Î¸(x)=0.7\)</span> gives us the probability of 70% that our output is 1.</p><p><span class="math display">\[h_Î¸(x)=P(y=1âˆ£x ;Î¸)=1âˆ’P(y=0âˆ£x ;Î¸)\]</span> <span class="math display">\[P(y=0âˆ£x;Î¸)+P(y=1âˆ£x ;Î¸)=1\]</span> Our probability that our prediction is 0 is just the complement of our probability that it is 1 (e.g. if probability that it is 1 is 70%, then the probability that it is 0 is 30%).</p><h2><span id="decision-boundary">Decision Boundary</span></h2><p>In order to get our discrete 0 or 1 classification, we can translate the output of the hypothesis function as follows:</p><p><span class="math display">\[h_Î¸(x)â‰¥0.5â†’y=1\]</span> <span class="math display">\[h_Î¸(x)&lt;0.5â†’y=0\]</span></p><p>The way our logistic function <span class="math inline">\(g\)</span> behaves is that when its input is greater than or equal to zero, its output is greater than or equal to 0.5:</p><p><span class="math display">\[g(z)â‰¥0.5\]</span> when <span class="math inline">\(zâ‰¥0\)</span></p><p>Remember.-</p><p><span class="math display">\[z=0,e^0=1,g(z)=1/2\]</span> <span class="math display">\[zâ†’âˆ,e^{âˆ’âˆ}â†’0,g(z)=1\]</span> <span class="math display">\[zâ†’âˆ’âˆ,e^âˆâ†’âˆ,g(z)=0\]</span></p><p>So if our input to g is <span class="math inline">\(Î¸^TX\)</span>, then that means:</p><p><span class="math display">\[h_Î¸(x)=g(Î¸^Tx)â‰¥0.5\]</span> when<span class="math inline">\(Î¸^Txâ‰¥0\)</span></p><p>From these statements we can now say:</p><p><span class="math display">\[Î¸^Txâ‰¥0â†’y=1\]</span> <span class="math display">\[Î¸^Tx&lt;0â†’y=0\]</span></p><p>The <strong>decision boundary</strong> is the line that separates the area where y=0 and where y=1. It is created by our hypothesis function.</p><p><strong>Example</strong>:</p><p><span class="math display">\[Î¸=\begin{bmatrix}5 \\-1 \\0\\\end{bmatrix}\]</span> <span class="math inline">\(y=1\)</span> if <span class="math inline">\(5+(âˆ’1)x1+0x2â‰¥0\)</span> <span class="math inline">\(5âˆ’x1â‰¥0\)</span> <span class="math inline">\(âˆ’x1â‰¥âˆ’5\)</span> <span class="math inline">\(x1â‰¤5\)</span></p><p>Our decision boundary then is a straight vertical line placed on the graph where <span class="math inline">\(x_1=5\)</span>, and everything to the left of that denotes <span class="math inline">\(y=1\)</span>, while everything to the right denotes <span class="math inline">\(y=0\)</span>.</p><p>Again, the input to the sigmoid function <span class="math inline">\(g(z)\)</span> (e.g. <span class="math inline">\(Î¸^TX\)</span>) need not be linear, and could be a function that describes a circle (e.g. <span class="math inline">\(z=Î¸_0+Î¸_1x^2_1+Î¸_2x^2_2\)</span>) or any shape to fit our data.</p><h2><span id="cost-function">Cost Function</span></h2><p>We <strong>cannot</strong> use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function. Instead, our cost function for logistic regression looks like:</p><p><span class="math display">\[J(Î¸)=\frac{1}{m}âˆ‘_{i=1}^mCost(h_Î¸(x^{(i)}),y^{(i)})\]</span></p><p><span class="math inline">\(Cost(h_Î¸(x),y)=âˆ’log(h_Î¸(x))\)</span> <code>if</code> <span class="math inline">\(y = 1\)</span> $Cost(h_Î¸(x),y)=âˆ’log(1âˆ’h_Î¸(x)) $ <code>if</code> <span class="math inline">\(y = 0\)</span></p><p><img src="/images/1454494932330.png" alt="Alt text"> <img src="/images/1454494937253.png" alt="Alt text"></p><p>The more our hypothesis is off from <span class="math inline">\(y\)</span>, the larger the cost function output. If our hypothesis is equal to <span class="math inline">\(y\)</span>, then our cost is <span class="math inline">\(0\)</span>:</p><p><span class="math inline">\(Cost(h_Î¸(x),y)=0\)</span> <span class="math inline">\(if\)</span> <span class="math inline">\(h_Î¸(x)=y\)</span> <span class="math inline">\(Cost(h_Î¸(x),y)â†’âˆ\)</span> <span class="math inline">\(if\)</span> <span class="math inline">\(y=0\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(h_Î¸(x)â†’1\)</span> <span class="math inline">\(Cost(h_Î¸(x),y)â†’âˆ\)</span> <span class="math inline">\(if\)</span> <span class="math inline">\(y=1\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(h_Î¸(x)â†’0\)</span></p><p>If our correct answer '<span class="math inline">\(y\)</span>' is 0, then the cost function will be 0 if our hypothesis function also outputs 0. If our hypothesis approaches 1, then the cost function will approach infinity.</p><p>If our correct answer '<span class="math inline">\(y\)</span>' is 1, then the cost function will be 0 if our hypothesis function outputs 1. If our hypothesis approaches 0, then the cost function will approach infinity.</p><p><strong>Note</strong> that writing the cost function in this way guarantees that <span class="math inline">\(J(Î¸)\)</span> is convex for logistic regression.</p><h2><span id="simplified-cost-function-and-gradient-descent">Simplified Cost Function and Gradient Descent</span></h2><p>We can compress our cost function's two conditional cases into one case:</p><p><span class="math display">\[Cost(h_Î¸(x),y)=âˆ’ylog(h_Î¸(x))âˆ’(1âˆ’y)log(1âˆ’h_Î¸(x))\]</span></p><p>Notice that when y is equal to 1, then the second term <span class="math inline">\(((1âˆ’y)log(1âˆ’h_Î¸(x)))\)</span> will be zero and will not affect the result. If y is equal to 0, then the first term <span class="math inline">\((âˆ’ylog(h_Î¸(x)))\)</span> will be zero and will not affect the result.</p><p>We can fully write out our entire cost function as follows:</p><p><span class="math display">\[J(Î¸)=âˆ’\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(h_Î¸(x^{(i)}))+(1âˆ’y^{(i)})\log(1âˆ’h_Î¸(x^{(i)}))]\]</span></p><p>A <strong>vectorized</strong> implementation is:</p><p><span class="math display">\[J(Î¸)=âˆ’\frac{1}{m}(\log(g(XÎ¸))^Ty+\log(1âˆ’g(XÎ¸))^T(1âˆ’y))\]</span></p><h3><span id="gradient-descent">Gradient Descent</span></h3><p>Remember that the general form of gradient descent is: <span class="math inline">\(Repeat\{\)</span> <span class="math display">\[Î¸_j := Î¸_jâˆ’Î±\frac{âˆ‚}{âˆ‚Î¸_j}J(Î¸)\]</span> <span class="math inline">\(\}\)</span></p><p>We can work out the derivative part using calculus to get: <span class="math inline">\(Repeat\{\)</span> <span class="math display">\[Î¸_j := Î¸_jâˆ’\frac{Î±}{m}\sum_{i=1}^m(h_Î¸(x^{(i)})âˆ’y^{(i)})x^{(i)}_j\]</span> <span class="math inline">\(\}\)</span></p><p>Notice that this algorithm is <strong>identical</strong> to the one we used in <strong>linear regression</strong>. We still have to simultaneously update all values in theta.</p><p>A <strong>vectorized</strong> implementation is:</p><p><span class="math display">\[Î¸ :=Î¸ âˆ’ \frac{Î±}{m}X^T(g(XÎ¸)âˆ’ \overrightarrow{y} )\]</span></p><h2><span id="advanced-optimization">Advanced Optimization</span></h2><p>&quot;<strong>Conjugate gradient</strong>&quot;, &quot;<strong>BFGS</strong>&quot;, and &quot;<strong>L-BFGS</strong>&quot; are more sophisticated, faster ways to optimize theta instead of using gradient descent. A. Ng suggests you do not write these more sophisticated algorithms yourself (unless you are an expert in numerical computing) but use them pre-written from libraries. Octave provides them.</p><p>We first need to provide a function that computes the following two equations:<span class="math inline">\(J(Î¸)\)</span>, <span class="math inline">\(\frac{âˆ‚}{âˆ‚Î¸_j}J(Î¸)\)</span></p><p>We can write a single function that returns both of these: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[jVal, gradient]</span> = <span class="title">costFunction</span><span class="params">(theta)</span></span></span><br><span class="line">  jval = [...code to compute J(theta)...];</span><br><span class="line">  gradient = [...code to compute derivative of J(theta)...];</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p><p>Then we can use octave's &quot;<code>fminunc()</code>&quot; optimization algorithm along with the &quot;<code>optimset()</code>&quot; function that creates an object containing the options we want to send to &quot;<code>fminunc()</code>&quot;. (Note: the value for <code>MaxIter</code> should be an integer, not a character string - errata in the video at 7:30) <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">100</span>);</span><br><span class="line">initialTheta = <span class="built_in">zeros</span>(<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure></p><p>We give to the function &quot;<code>fminunc()</code>&quot; our cost function, our initial vector of theta values, and the &quot;<code>options</code>&quot; object that we created beforehand.</p><h2><span id="multiclass-classification-one-vs-all">Multiclass Classification: One-vs-all</span></h2><p>Now we will approach the classification of data into more than two categories. Instead of <span class="math inline">\(y = \{0,1\}\)</span> we will expand our definition so that <span class="math inline">\(y = \{0,1...n\}\)</span>.</p><p>In this case we divide our problem into <span class="math inline">\(n+1\)</span> (+1 because the index starts at 0) binary classification problems; in each one, we predict the probability that '<span class="math inline">\(y\)</span>' is a member of one of our classes.</p><p><span class="math display">\[yâˆˆ\{0,1...n\}\]</span> <span class="math display">\[h^{(0)}_Î¸(x)=P(y=0âˆ£x ;Î¸)\]</span> <span class="math display">\[h^{(1)}_Î¸(x)=P(y=1âˆ£x ;Î¸)\]</span> <span class="math display">\[â‹¯\]</span> <span class="math display">\[h^{(n)}_Î¸(x)=P(y=nâˆ£x ;Î¸)\]</span> <span class="math display">\[prediction=\max_i(h^{(i)}_Î¸(x))\]</span></p><p>We are basically choosing one class and then lumping all the others into a single second class. We do this repeatedly, applying binary logistic regression to each case, and then use the hypothesis that returned the highest value as our prediction.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Logistic Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Octave Tutorial</title>
      <link href="/2016/02/01/Octave%20Tutorial/"/>
      <url>/2016/02/01/Octave%20Tutorial/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#basic-operations">Basic Operations</a></li><li><a href="#moving-data-around">Moving Data Around</a><ul><li><a href="#dimensions">Dimensions</a></li><li><a href="#loading-data">Loading data</a></li><li><a href="#indexing">Indexing</a></li></ul></li><li><a href="#computing-on-data">Computing on Data</a><ul><li><a href="#matrix-operation">Matrix operation</a></li><li><a href="#useful-functions">Useful functions</a></li></ul></li><li><a href="#plotting-data">Plotting Data</a></li><li><a href="#control-statements-for-while-if-statements">Control statements: <code>for</code>, <code>while</code>, <code>if</code> statements</a></li><li><a href="#functions">Functions</a></li><li><a href="#vectorization">Vectorization</a></li><li><a href="#working-on-and-submitting-programming-exercises">Working on and Submitting Programming Exercises</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="basic-operations">Basic Operations</span></h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% Change Octave prompt  </span></span><br><span class="line">PS1(<span class="string">'&gt;&gt; '</span>);</span><br><span class="line"><span class="comment">%% Change working directory in windows example:</span></span><br><span class="line">cd <span class="string">'c:/path/to/desired/directory name'</span></span><br><span class="line"><span class="comment">%% Note that it uses normal slashes and does not use escape characters for the empty spaces.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% elementary operations</span></span><br><span class="line"><span class="number">5</span>+<span class="number">6</span></span><br><span class="line"><span class="number">3</span><span class="number">-2</span></span><br><span class="line"><span class="number">5</span>*<span class="number">8</span></span><br><span class="line"><span class="number">1</span>/<span class="number">2</span></span><br><span class="line"><span class="number">2</span>^<span class="number">6</span></span><br><span class="line"><span class="number">1</span> == <span class="number">2</span>  <span class="comment">% false</span></span><br><span class="line"><span class="number">1</span> ~= <span class="number">2</span>  <span class="comment">% true.  note, not "!="</span></span><br><span class="line"><span class="number">1</span> &amp;&amp; <span class="number">0</span></span><br><span class="line"><span class="number">1</span> || <span class="number">0</span></span><br><span class="line">xor(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%% variable assignment</span></span><br><span class="line">a = <span class="number">3</span>; <span class="comment">% semicolon suppresses output</span></span><br><span class="line">b = <span class="string">'hi'</span>;</span><br><span class="line">c = <span class="number">3</span>&gt;=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Displaying them:</span></span><br><span class="line">a = <span class="built_in">pi</span></span><br><span class="line"><span class="built_in">disp</span>(a)</span><br><span class="line"><span class="built_in">disp</span>(sprintf(<span class="string">'2 decimals: %0.2f'</span>, a))</span><br><span class="line"><span class="built_in">disp</span>(sprintf(<span class="string">'6 decimals: %0.6f'</span>, a))</span><br><span class="line">format long</span><br><span class="line">a</span><br><span class="line">format short</span><br><span class="line">a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%%  vectors and matrices</span></span><br><span class="line">A = [<span class="number">1</span> <span class="number">2</span>; <span class="number">3</span> <span class="number">4</span>; <span class="number">5</span> <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">v = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line">v = [<span class="number">1</span>; <span class="number">2</span>; <span class="number">3</span>]</span><br><span class="line">v = [<span class="number">1</span>:<span class="number">0.1</span>:<span class="number">2</span>]  <span class="comment">% from 1 to 2, with stepsize of 0.1. Useful for plot axes</span></span><br><span class="line">v = <span class="number">1</span>:<span class="number">6</span>        <span class="comment">% from 1 to 6, assumes stepsize of 1 (row vector)</span></span><br><span class="line"></span><br><span class="line">C = <span class="number">2</span> * <span class="built_in">ones</span>(<span class="number">2</span>,<span class="number">3</span>)  <span class="comment">% same as C = [2 2 2; 2 2 2]</span></span><br><span class="line">w = <span class="built_in">ones</span>(<span class="number">1</span>,<span class="number">3</span>)    <span class="comment">% 1x3 vector of ones</span></span><br><span class="line">w = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">w = <span class="built_in">rand</span>(<span class="number">1</span>,<span class="number">3</span>)  <span class="comment">% drawn from a uniform distribution </span></span><br><span class="line">w = <span class="built_in">randn</span>(<span class="number">1</span>,<span class="number">3</span>) <span class="comment">% drawn from a normal distribution (mean=0, var=1)</span></span><br><span class="line">w = <span class="number">-6</span> + <span class="built_in">sqrt</span>(<span class="number">10</span>)*(<span class="built_in">randn</span>(<span class="number">1</span>,<span class="number">10000</span>));  <span class="comment">% (mean = -6, var = 10) - note: add the semicolon</span></span><br><span class="line">hist(w)     <span class="comment">% plot histogram using 10 bins (default)</span></span><br><span class="line">hist(w,<span class="number">50</span>)  <span class="comment">% plot histogram using 50 bins</span></span><br><span class="line"><span class="comment">% note: if hist() crashes, try "graphics_toolkit('gnu_plot')" </span></span><br><span class="line"></span><br><span class="line">I = <span class="built_in">eye</span>(<span class="number">4</span>)    <span class="comment">% 4x4 identity matrix</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% help function</span></span><br><span class="line">help <span class="built_in">eye</span></span><br><span class="line">help <span class="built_in">rand</span></span><br><span class="line">help help</span><br></pre></td></tr></table></figure><h2><span id="moving-data-around">Moving Data Around</span></h2><h3><span id="dimensions">Dimensions</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% dimensions</span></span><br><span class="line">sz = <span class="built_in">size</span>(A) <span class="comment">% 1x2 matrix: [(number of rows) (number of columns)]</span></span><br><span class="line"><span class="built_in">size</span>(A,<span class="number">1</span>)  <span class="comment">% number of rows</span></span><br><span class="line"><span class="built_in">size</span>(A,<span class="number">2</span>)  <span class="comment">% number of cols</span></span><br><span class="line"><span class="built_in">length</span>(v)  <span class="comment">% size of longest dimension</span></span><br></pre></td></tr></table></figure><h3><span id="loading-data">Loading data</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% loading data</span></span><br><span class="line">pwd    <span class="comment">% show current directory (current path)</span></span><br><span class="line">cd <span class="string">'C:\Users\ang\Octave files'</span>   <span class="comment">% change directory </span></span><br><span class="line">ls     <span class="comment">% list files in current directory </span></span><br><span class="line">load q1y.dat    <span class="comment">% alternatively, load('q1y.dat')</span></span><br><span class="line">load q1x.dat</span><br><span class="line">who    <span class="comment">% list variables in workspace</span></span><br><span class="line">whos   <span class="comment">% list variables in workspace (detailed view) </span></span><br><span class="line">clear q1y       <span class="comment">% clear w/ no argt clears all</span></span><br><span class="line">v = q1x(<span class="number">1</span>:<span class="number">10</span>);  <span class="comment">% first 10 elements of q1x (counts down the columns)</span></span><br><span class="line">save hello.mat v;   <span class="comment">% save variable v into file hello.mat</span></span><br><span class="line">save hello.txt v -ascii; <span class="comment">% save as ascii</span></span><br><span class="line"><span class="comment">% fopen, fread, fprintf, fscanf also work  [[not needed in class]]</span></span><br></pre></td></tr></table></figure><h3><span id="indexing">Indexing</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% indexing</span></span><br><span class="line">A(<span class="number">3</span>,<span class="number">2</span>)  <span class="comment">% indexing is (row,col)</span></span><br><span class="line">A(<span class="number">2</span>,:)  <span class="comment">% get the 2nd row. </span></span><br><span class="line">        <span class="comment">% ":" means every element along that dimension</span></span><br><span class="line">A(:,<span class="number">2</span>)  <span class="comment">% get the 2nd col</span></span><br><span class="line">A([<span class="number">1</span> <span class="number">3</span>],:) <span class="comment">% print all  the elements of rows 1 and 3</span></span><br><span class="line"></span><br><span class="line">A(:,<span class="number">2</span>) = [<span class="number">10</span>; <span class="number">11</span>; <span class="number">12</span>]     <span class="comment">% change second column</span></span><br><span class="line">A = [A, [<span class="number">100</span>; <span class="number">101</span>; <span class="number">102</span>]]; <span class="comment">% append column vec</span></span><br><span class="line">A(:) <span class="comment">% Select all elements as a column vector.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Putting data together </span></span><br><span class="line">A = [<span class="number">1</span> <span class="number">2</span>; <span class="number">3</span> <span class="number">4</span>; <span class="number">5</span> <span class="number">6</span>]</span><br><span class="line">B = [<span class="number">11</span> <span class="number">12</span>; <span class="number">13</span> <span class="number">14</span>; <span class="number">15</span> <span class="number">16</span>] <span class="comment">% same dims as A</span></span><br><span class="line">C = [A B] or [A,B]- concatenating A and B matrices side by side</span><br><span class="line">C = [A; B] - Concatenating A and B top and bottom</span><br></pre></td></tr></table></figure><h2><span id="computing-on-data">Computing on Data</span></h2><h3><span id="matrix-operation">Matrix operation</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% initialize variables</span></span><br><span class="line">A = [<span class="number">1</span> <span class="number">2</span>;<span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span>]</span><br><span class="line">B = [<span class="number">11</span> <span class="number">12</span>;<span class="number">13</span> <span class="number">14</span>;<span class="number">15</span> <span class="number">16</span>]</span><br><span class="line">C = [<span class="number">1</span> <span class="number">1</span>;<span class="number">2</span> <span class="number">2</span>]</span><br><span class="line">v = [<span class="number">1</span>;<span class="number">2</span>;<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">%% matrix operations</span></span><br><span class="line">A * C  <span class="comment">% matrix multiplication</span></span><br><span class="line">A .* B <span class="comment">% element-wise multiplication</span></span><br><span class="line"><span class="comment">% A .* C  or A * B gives error - wrong dimensions</span></span><br><span class="line">A .^ <span class="number">2</span> <span class="comment">% element-wise square of each element in A</span></span><br><span class="line"><span class="number">1.</span>/v   <span class="comment">% element-wise reciprocal</span></span><br><span class="line"><span class="built_in">log</span>(v)  <span class="comment">% functions like this operate element-wise on vecs or matrices </span></span><br><span class="line"><span class="built_in">exp</span>(v)</span><br><span class="line"><span class="built_in">abs</span>(v)</span><br><span class="line"></span><br><span class="line">-v  <span class="comment">% -1*v</span></span><br><span class="line"></span><br><span class="line">v + <span class="built_in">ones</span>(<span class="built_in">length</span>(v), <span class="number">1</span>)  </span><br><span class="line"><span class="comment">% v + 1  % same</span></span><br><span class="line"></span><br><span class="line">A'  <span class="comment">% matrix transpose</span></span><br></pre></td></tr></table></figure><h3><span id="useful-functions">Useful functions</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% misc useful functions</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% max  (or min)</span></span><br><span class="line">a = [<span class="number">1</span> <span class="number">15</span> <span class="number">2</span> <span class="number">0.5</span>]</span><br><span class="line">val = <span class="built_in">max</span>(a)</span><br><span class="line">[val,ind] = <span class="built_in">max</span>(a) <span class="comment">% val -  maximum element of the vector a and index - index value where maximum occur</span></span><br><span class="line">val = <span class="built_in">max</span>(A) <span class="comment">% if A is matrix, returns max from each column</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% find</span></span><br><span class="line">a &lt; <span class="number">3</span></span><br><span class="line"><span class="built_in">find</span>(a &lt; <span class="number">3</span>)</span><br><span class="line">A = <span class="built_in">magic</span>(<span class="number">3</span>)</span><br><span class="line">[r,c] = <span class="built_in">find</span>(A&gt;=<span class="number">7</span>)  <span class="comment">% row, column indices for values matching comparison</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% sum, prod</span></span><br><span class="line">sum(a)</span><br><span class="line">prod(a)</span><br><span class="line"><span class="built_in">floor</span>(a) <span class="comment">% or ceil(a)</span></span><br><span class="line"><span class="built_in">max</span>(<span class="built_in">rand</span>(<span class="number">3</span>),<span class="built_in">rand</span>(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">max</span>(A,[],<span class="number">1</span>) -  maximum along columns(defaults to columns - <span class="built_in">max</span>(A,[]))</span><br><span class="line"><span class="built_in">max</span>(A,[],<span class="number">2</span>) - maximum along rows</span><br><span class="line">A = <span class="built_in">magic</span>(<span class="number">9</span>)</span><br><span class="line">sum(A,<span class="number">1</span>)</span><br><span class="line">sum(A,<span class="number">2</span>)</span><br><span class="line">sum(sum( A .* <span class="built_in">eye</span>(<span class="number">9</span>) ))</span><br><span class="line">sum(sum( A .* <span class="built_in">flipud</span>(<span class="built_in">eye</span>(<span class="number">9</span>)) ))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">% Matrix inverse (pseudo-inverse)</span></span><br><span class="line">pinv(A)        <span class="comment">% inv(A'*A)*A'</span></span><br></pre></td></tr></table></figure><h2><span id="plotting-data">Plotting Data</span></h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% plotting</span></span><br><span class="line">t = [<span class="number">0</span>:<span class="number">0.01</span>:<span class="number">0.98</span>];</span><br><span class="line">y1 = <span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">4</span>*t); </span><br><span class="line"><span class="built_in">plot</span>(t,y1);</span><br><span class="line">y2 = <span class="built_in">cos</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">4</span>*t);</span><br><span class="line"><span class="built_in">hold</span> on;  <span class="comment">% "hold off" to turn off</span></span><br><span class="line"><span class="built_in">plot</span>(t,y2,<span class="string">'r'</span>);</span><br><span class="line">xlabel(<span class="string">'time'</span>);</span><br><span class="line">ylabel(<span class="string">'value'</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'sin'</span>,<span class="string">'cos'</span>);</span><br><span class="line">title(<span class="string">'my plot'</span>);</span><br><span class="line">print -dpng <span class="string">'myPlot.png'</span></span><br><span class="line">close;           <span class="comment">% or,  "close all" to close all figs</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); <span class="built_in">plot</span>(t, y1);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>); <span class="built_in">plot</span>(t, y2);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>), clf;  <span class="comment">% can specify the figure number</span></span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>);  <span class="comment">% Divide plot into 1x2 grid, access 1st element</span></span><br><span class="line"><span class="built_in">plot</span>(t,y1);</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>);  <span class="comment">% Divide plot into 1x2 grid, access 2nd element</span></span><br><span class="line"><span class="built_in">plot</span>(t,y2);</span><br><span class="line">axis([<span class="number">0.5</span> <span class="number">1</span> <span class="number">-1</span> <span class="number">1</span>]);  <span class="comment">% change axis scale</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% display a matrix (or image) </span></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line">imagesc(<span class="built_in">magic</span>(<span class="number">15</span>)), colorbar, colormap gray;</span><br><span class="line"><span class="comment">% comma-chaining function calls.  </span></span><br><span class="line">a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span></span><br><span class="line">a=<span class="number">1</span>;b=<span class="number">2</span>;c=<span class="number">3</span>;</span><br></pre></td></tr></table></figure><h2><span id="control-statements-for-while-if-statements">Control statements: <code>for</code>, <code>while</code>, <code>if</code> statements</span></h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">v = <span class="built_in">zeros</span>(<span class="number">10</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">10</span>, </span><br><span class="line">    v(<span class="built_in">i</span>) = <span class="number">2</span>^<span class="built_in">i</span>;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"><span class="comment">% Can also use "break" and "continue" inside for and while loops to control execution.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">i</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">i</span> &lt;= <span class="number">5</span>,</span><br><span class="line">  v(<span class="built_in">i</span>) = <span class="number">100</span>; </span><br><span class="line">  <span class="built_in">i</span> = <span class="built_in">i</span>+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">i</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">true</span>, </span><br><span class="line">  v(<span class="built_in">i</span>) = <span class="number">999</span>; </span><br><span class="line">  <span class="built_in">i</span> = <span class="built_in">i</span>+<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">i</span> == <span class="number">6</span>,</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">end</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> v(<span class="number">1</span>)==<span class="number">1</span>,</span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">'The value is one!'</span>);</span><br><span class="line"><span class="keyword">elseif</span> v(<span class="number">1</span>)==<span class="number">2</span>,</span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">'The value is two!'</span>);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">'The value is not one or two!'</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2><span id="functions">Functions</span></h2><p>To create a function, type the function code in a text editor (e.g. gedit or notepad), and save the file as &quot;<code>functionName.m</code>&quot;</p><p>Example function: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">squareThisNumber</span><span class="params">(x)</span></span></span><br><span class="line"></span><br><span class="line">y = x^<span class="number">2</span>;</span><br></pre></td></tr></table></figure></p><p>To call the function in Octave, do either:</p><ol type="1"><li><p>Navigate to the directory of the <code>functionName.m</code> file and call the function: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Navigate to directory:</span></span><br><span class="line">    cd /path/to/function</span><br><span class="line"></span><br><span class="line">    <span class="comment">% Call the function:</span></span><br><span class="line">    functionName(args)</span><br></pre></td></tr></table></figure></p></li><li><p>Add the directory of the function to the load <strong>path</strong> and save it: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% To add the path for the current session of Octave:</span></span><br><span class="line">    addpath(<span class="string">'/path/to/function/'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">% To remember the path for future sessions of Octave, after executing addpath above, also do:</span></span><br><span class="line">    savepath</span><br></pre></td></tr></table></figure></p></li></ol><p>Octave's functions can return more than one value: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[y1, y2]</span> = <span class="title">squareandCubeThisNo</span><span class="params">(x)</span></span></span><br><span class="line">y1 = x^<span class="number">2</span></span><br><span class="line">y2 = x^<span class="number">3</span></span><br></pre></td></tr></table></figure></p><p>Call the above function this way: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[a,b] = squareandCubeThisNo(x)</span><br></pre></td></tr></table></figure></p><h2><span id="vectorization">Vectorization</span></h2><p>Vectorization is the process of taking code that relies on <strong>loops</strong> and converting it into <strong>matrix operations</strong>. It is more efficient, more elegant, and more concise.</p><p>As an example, let's compute our prediction from a hypothesis. Theta is the vector of fields for the hypothesis and x is a vector of variables.</p><p>With loops: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">prediction = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:n+<span class="number">1</span>,</span><br><span class="line">  prediction += theta(<span class="built_in">j</span>) * x(<span class="built_in">j</span>);</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure></p><p>With vectorization: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = theta' * x;</span><br></pre></td></tr></table></figure></p><p>If you recall the definition multiplying vectors, you'll see that this one operation does the element-wise multiplication and overall sum in a very concise notation.</p><h2><span id="working-on-and-submitting-programming-exercises">Working on and Submitting Programming Exercises</span></h2><ol type="1"><li>Download and extract the assignment's zip file.</li><li>Edit the proper file 'a.m', where a is the name of the exercise you're working on.</li><li>Run octave and cd to the assignment's extracted directory</li><li>Run the 'submit' function and enter the assignment number, your email, and a password (found on the top of the &quot;Programming Exercises&quot; page on coursera)</li></ol>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Octave </tag>
            
            <tag> Matlab </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linear Regression with Multiple Variables</title>
      <link href="/2016/01/31/Linear%20Regression%20with%20Multiple%20Variables/"/>
      <url>/2016/01/31/Linear%20Regression%20with%20Multiple%20Variables/</url>
      
        <content type="html"><![CDATA[<h2><span id="multiple-features">Multiple Features</span></h2><p>Linear regression with multiple variables is also known as &quot;<strong>multivariate linear regression</strong>&quot;.</p><p>We now introduce notation for equations where we can have any number of input variables.</p><a id="more"></a><ul><li><span class="math inline">\(x^{(i)}_j\)</span> = value of feature j in the <span class="math inline">\(i^{th}\)</span> training example</li><li><span class="math inline">\(x^{(i)}\)</span> = the column vector of all the feature inputs of the <span class="math inline">\(i^{th}\)</span> training example</li><li><span class="math inline">\(m\)</span> = the number of training examples</li><li><span class="math inline">\(n\)</span> = <span class="math inline">\(âˆ£x^{(i)}âˆ£\)</span> (the number of features)</li></ul><p>Now define the multivariable form of the hypothesis function as follows, accomodating these multiple features:</p><p><span class="math display">\[h_Î¸(x)=Î¸_0+Î¸_1x_1 + Î¸_2x_2 + Î¸_3x_3 +â‹¯+ Î¸_nx_n\]</span></p><p>In order to have little intuition about this function, we can think about <span class="math inline">\(Î¸_0\)</span> as the basic price of a house, <span class="math inline">\(Î¸_1\)</span> as the price per square meter, <span class="math inline">\(Î¸_2\)</span> as the price per floor, etc. <span class="math inline">\(x_1\)</span> will be the number of square meters in the house, <span class="math inline">\(x_2\)</span> the number of floors, etc.</p><p>Using the definition of matrix multiplication, our <strong>multivariable hypothesis function</strong> can be concisely represented as:</p><p><span class="math display">\[h_Î¸(x)=\begin{bmatrix}Î¸_0      &amp; \cdots &amp; Î¸_n      \\\end{bmatrix}\begin{bmatrix}x_0\\ \\\vdots \\\\x_n      \\\end{bmatrix} = Î¸^{T}x\]</span></p><p>This is a vectorization of our hypothesis function for one training example; see the lessons on vectorization to learn more.</p><p>[<strong>Note</strong>: So that we can do matrix operations with theta and x, we will set <span class="math inline">\(x^{(i)}_0 = 1\)</span>, for all values of <span class="math inline">\(i\)</span>. This makes the two vectors <span class="math inline">\(\theta\)</span> and <span class="math inline">\(x^{(i)}\)</span> match each other element-wise (that is, have the same number of elements: n+1).]</p><p>Now we can collect all <em>m</em> training examples each with <em>n</em> features and record them in an <strong>n+1 by m</strong> matrix. In this matrix we let the value of the subscript (feature) also represent the row number (except the initial row is the &quot;zeroth&quot; row), and the value of the superscript (the training example) also represent the column number, as shown here: <span class="math display">\[X = \begin{bmatrix}x^{(1)}_0 &amp; x^{(2)}_0     &amp; \cdots &amp;  x^{(m)}_0     \\x^{(1)}_1 &amp; x^{(2)}_1     &amp; \cdots &amp;  x^{(m)}_1     \\&amp; &amp; \vdots  &amp; \\x^{(1)}_n &amp; x^{(2)}_n     &amp; \cdots &amp;  x^{(m)}_n     \end{bmatrix} = \begin{bmatrix}1 &amp; 1     &amp; \cdots &amp;  1     \\x^{(1)}_1 &amp; x^{(2)}_1     &amp; \cdots &amp;  x^{(m)}_1     \\&amp; &amp; \vdots  &amp; \\x^{(1)}_n &amp; x^{(2)}_n     &amp; \cdots &amp;  x^{(m)}_n     \end{bmatrix}\]</span></p><p>Notice above that the first column is the first training example (like the vector above), the second column is the second training example, and so forth.</p><p>Now we can define <span class="math inline">\(h_Î¸(X)\)</span> as a row vector that gives the value of <span class="math inline">\(h_Î¸(x)\)</span> at each of the <em>m</em> training examples: <span class="math display">\[hÎ¸(X)=\begin{bmatrix}Î¸_0x^{(1)}_0+Î¸_1x^{(1)}_1+...+Î¸_nx^{(1)}_n       &amp; \cdots &amp; Î¸_0x^{(m)}_0+Î¸_1x^{(m)}_1+...+Î¸_nx^{(m)}_n      \\\end{bmatrix}\]</span></p><h2><span id="cost-function">Cost function</span></h2><p>For the parameter vector <span class="math inline">\(Î¸\)</span> (of type <span class="math inline">\(R^{n+1}\)</span> or in <span class="math inline">\(R^{(n+1)Ã—1}\)</span>), the cost function is:</p><p><span class="math display">\[J(\theta) = \frac{1}{2m}\sum^{m}_{i = 1}(h_\theta(x^{(i)}) - y^{(i)})^2\]</span></p><p>The vectorized version is:</p><p><span class="math display">\[J(\theta) = \frac{1}{2m}(X\theta - \overrightarrow{y})^T(X\theta - \overrightarrow{y})\]</span></p><p>Where <span class="math inline">\(\overrightarrow{y}\)</span> denotes the vector of all <em>y</em> values, <span class="math inline">\(X\)</span> represent a matrix of training examples <span class="math inline">\(x^{(i)}\)</span> stored <strong>row-wise</strong>.</p><h2><span id="gradient-descent-for-multiple-variables">Gradient Descent for Multiple Variables</span></h2><p>The gradient descent equation itself is generally the same form; we just have to repeat it for our '<strong>n</strong>' features:</p><p><strong>repeat until convergence:{</strong> <span class="math display">\[\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_0\]</span> <span class="math display">\[\theta_1 := \theta_1 - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_1\]</span> <span class="math display">\[\theta_2 := \theta_2 - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_2\]</span> <span class="math display">\[...\]</span> <strong>}</strong></p><p>In other words:</p><p><strong>repeat until convergence:{</strong> <span class="math display">\[\theta_j := \theta_j - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_j\]</span> <strong>for <span class="math inline">\(j\)</span> <span class="math inline">\(:=\)</span> <span class="math inline">\(0\)</span>...<span class="math inline">\(n\)</span></strong> <strong>}</strong></p><h2><span id="matrix-notation">Matrix Notation</span></h2><p>The Gradient Descent rule can be expressed as:</p><p><span class="math display">\[\theta := \theta - \alpha \bigtriangledown J(\theta)\]</span></p><p>Where <span class="math inline">\(\bigtriangledown J(\theta)\)</span> is a column vector of the form:</p><p><span class="math display">\[\bigtriangledown J(\theta) = \begin{bmatrix}\frac{\partial J(\theta)}{\partial \theta_0}\\\frac{\partial J(\theta)}{\partial \theta_1}\\\vdots \\\frac{\partial J(\theta)}{\partial \theta_n}\\\end{bmatrix}\]</span></p><p>The j-th component of the gradient is the summation of the product of two terms: <span class="math display">\[\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\sum^m_{i = 1}(h_\theta(x^{(i)}) - y^{(i)}) x^{(i)}_j\]</span></p><p>Sometimes, the summation of the product of two terms can be expressed as the product of two vectors.</p><p>Here, the term <span class="math inline">\(x^{(i)}_j\)</span> represents the <span class="math inline">\(m\)</span> elements of the j-th column <span class="math inline">\(\overrightarrow {x_j}\)</span> (j-th feature <span class="math inline">\(\overrightarrow {x_j}\)</span>) of the training set <span class="math inline">\(X\)</span>.</p><p>The other term <span class="math inline">\((h_\theta(x^{(i)}) - y^{(i)})\)</span> is the vector of the deviations between the predictions <span class="math inline">\(h_\theta(x^{(i)})\)</span> and the true values <span class="math inline">\(y^{(i)}\)</span> . Re-writing <span class="math inline">\(\frac{\partial J(\theta)}{\partial \theta_j}\)</span> , we have: <span class="math display">\[\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\overrightarrow{x_j}^T(X\theta - \overrightarrow{y})\]</span> <span class="math display">\[\bigtriangledown J(\theta) = \frac{1}{m}X^T(X\theta - \overrightarrow{y})\]</span></p><p>Finally, the matrix notation (vectorized) of the Gradient Descent rule is: <span class="math display">\[\theta := \theta - \frac{\alpha}{m}X^T(X\theta - \overrightarrow{y})\]</span></p><h2><span id="feature-normalization">Feature Normalization</span></h2><p>We can speed up gradient descent by having each of our input values in roughly the same range. This is because <span class="math inline">\(\theta\)</span> will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.</p><p>The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Ideally: <span class="math inline">\(-1 \le x_i \le 1\)</span> or <span class="math inline">\(-0.5 \le x_i \le 0.5\)</span></p><p>These aren't exact requirements; we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few.</p><p>Two techniques to help with this are <strong>feature scaling</strong> and <strong>mean normalization</strong>. * Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. * Mean normalization involves subtracting the average value for an input variable from the values for that input variable, resulting in a new average value for the input variable of just zero.</p><p>To implement both of these techniques, adjust your input values as shown in this formula: <span class="math display">\[x_i := \frac{x_i - \mu_i}{s_i}\]</span></p><p>Where <span class="math inline">\(\mu_i\)</span> is the <strong>average</strong> of all the values and <span class="math inline">\(s_i\)</span> is the maximum of the range of values <em>minus</em> the minimum or is the <em>standard deviation</em>.</p><p><strong>Example</strong>: <span class="math inline">\(x_i\)</span> is housing prices in range 100-2000. Then, <span class="math inline">\(x_i := \frac{price - 1000}{1900}\)</span>, where 1000 is the average price and 1900 is the maximum (2000) minus the minimum (100).</p><h2><span id="gradient-descent-tips">Gradient Descent Tips</span></h2><p><strong>Debugging gradient descent</strong> Make a plot with <strong>number of iterations</strong> on the x-axis. Now plot the cost function, <span class="math inline">\(J(\theta)\)</span> over the number of iterations of gradient descent. If <span class="math inline">\(J(\theta)\)</span> ever increases, then you probably need to decrease <span class="math inline">\(\alpha\)</span>.</p><p><strong>Automatic convergence test</strong> Declare convergence if <span class="math inline">\(J(\theta)\)</span> decreases by less than <span class="math inline">\(\epsilon\)</span> in one iteration, where <span class="math inline">\(\epsilon\)</span> is some small value such as <span class="math inline">\(10^{-3}\)</span>. However in practice it's difficult to choose this threshold value.</p><p>It has been proven that if learning rate <span class="math inline">\(\alpha\)</span> is sufficiently small, then <span class="math inline">\(J(\theta)\)</span> will decrease on every iteration. <em>Andrew Ng</em> recommends decreasing <span class="math inline">\(\alpha\)</span> by multiples of 3.</p><h2><span id="features-and-polynomial-regression">Features and Polynomial Regression</span></h2><p>We can improve our features and the form of our hypothesis function in a couple different ways.</p><p>We can <strong>combine multiple features into one</strong>. For example, we can combine <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> into a new feature <span class="math inline">\(x_3\)</span> by taking <span class="math inline">\(x_1 \cdot x_2\)</span>.</p><h3><span id="polynomial-regression">Polynomial Regression</span></h3><p>Our hypothesis function need not be linear (a straight line) if that does not fit the data well.</p><p>We can <strong>change the behavior or curve</strong> of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).</p><p>For example, if our hypothesis function is <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1\)</span> then we can simply <strong>duplicate</strong> the instances of <span class="math inline">\(x_1\)</span> to get the quadratic function <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2\)</span> or the cubic function <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2 + \theta_3x_1^3\)</span></p><p>In the cubic version, we have created new features <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span> where <span class="math inline">\(x_2 = x_1^2\)</span> and <span class="math inline">\(x_3 = x_1^3\)</span>.</p><p>To make it a square root function, we could do: <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2\sqrt{x_1}\)</span></p><p>One important thing to keep in mind is, if you choose your features this way then <strong>feature scaling</strong> becomes very important.</p><p>eg. if <span class="math inline">\(x_1\)</span> has range 1 - 1000 then <span class="math inline">\(x_1^2\)</span> range of becomes 1 - 1000000 and that of <span class="math inline">\(x_1^3\)</span> becomes 1 - 1000000000</p><h2><span id="normal-equation">Normal Equation</span></h2><p>The &quot;normal equation&quot; is a version of finding the optimum <strong>without iteration</strong>.</p><p>The <a href="http://www.wikiwand.com/zh-hans/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="noopener">proof</a> for this equation requires knowledge of linear algebra and is fairly involved, so you do not need to worry about the details.</p><p><span class="math display">\[\theta = (X^TX)^{-1}X^Ty\]</span></p><p>There is <strong>no need to do feature scaling</strong> with the normal equation.</p><p>The following is a comparison of gradient descent and the normal equation: | Gradient Descent | Normal Equation | | :--- | :--- | | Need to choose <span class="math inline">\(\alpha\)</span> | No need to choose <span class="math inline">\(\alpha\)</span> | | Needs many iterations | No need to iterate | | Works well when n is large | Slow if n is very large |</p><p>With the normal equation, computing the inversion has complexity <span class="math inline">\(O(n^3)\)</span>. So if we have a very large number of features, the normal equation will be slow. In practice, according to <em>A. Ng</em>, when <strong>n</strong> exceeds <strong>10,000</strong> it might be a good time to go from a normal solution to an iterative process.</p><h3><span id="normal-equation-demonstration">Normal Equation Demonstration</span></h3><ul><li><span class="math inline">\(\theta\)</span> is a <span class="math inline">\((n+1)\)</span> x <span class="math inline">\(1\)</span> matrix</li><li><span class="math inline">\(X\)</span> is a <span class="math inline">\(m\)</span> x <span class="math inline">\((n+1)\)</span> matrix so <span class="math inline">\(X^T\)</span> is a <span class="math inline">\((n+1)\)</span> x <span class="math inline">\(m\)</span> matrix</li><li><span class="math inline">\(\overrightarrow{y}\)</span> is a <span class="math inline">\(m\)</span> x <span class="math inline">\(1\)</span> vector</li></ul><p><span class="math inline">\(X\theta = \overrightarrow{y}\)</span> The point is to inverse <span class="math inline">\(X\)</span> , but as <span class="math inline">\(X\)</span> is not a square matrix we need to use <span class="math inline">\(X^T\)</span> to have a square matrix <span class="math inline">\((X^T)X\theta = (X^T)\overrightarrow{y}\)</span></p><p>Associative matrix multiplication <span class="math inline">\((X^TX)\theta = X^T\overrightarrow{y}\)</span> Assuming <span class="math inline">\((X^TX)\)</span> invertible <span class="math inline">\(\theta = (X^TX)^{-1}X^T\overrightarrow{y}\)</span></p><h3><span id="normal-equation-noninvertibility">Normal Equation Noninvertibility</span></h3><p>When implementing the normal equation in octave we want to use the <code>pinv</code> function rather than <code>inv</code>.</p><p><span class="math inline">\(X^TX\)</span> may be <strong>noninvertible</strong>. The common causes are: * Redundant features, where two features are very closely related (i.e. they are linearly dependent) * Too many features (e.g. <span class="math inline">\(m \le n\)</span>). In this case, delete some features or use &quot;<strong>regularization</strong>&quot; (to be explained in a later lesson).</p><p>Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Linear Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linear Regression with One Variable</title>
      <link href="/2016/01/30/Linear%20Regression%20with%20One%20Variable/"/>
      <url>/2016/01/30/Linear%20Regression%20with%20One%20Variable/</url>
      
        <content type="html"><![CDATA[<h2><span id="model-representation">Model Representation</span></h2><p>Recall that in <em>regression problems</em>, we are taking input variables and trying to map the output onto a <em>continuous</em> expected result function.</p><p>Linear regression with one variable is also known as &quot;<strong>univariate linear regression</strong>.&quot;</p><p>Univariate linear regression is used when you want to predict a <strong>single output</strong> value from a <strong>single input</strong> value. We're doing <strong>supervised learning</strong> here, so that means we already have an idea what the input/output cause and effect should be.</p><a id="more"></a><h2><span id="the-hypothesis-function">The Hypothesis Function</span></h2><p>Our hypothesis function has the general form:</p><p><span class="math inline">\(h_Î¸(x)=Î¸_0+Î¸_1x\)</span></p><p>We give to <span class="math inline">\(h_Î¸\)</span> values for <span class="math inline">\(Î¸_0\)</span> and <span class="math inline">\(Î¸_1\)</span> to get our output '<span class="math inline">\(y\)</span>'. In other words, we are trying to create a function called <span class="math inline">\(h_Î¸\)</span> that is able to reliably map our input data (the x's) to our output data (the y's).</p><p><strong>Example</strong>: | x (input) | y (output)| | :--- | :--- | | 0 | 4 | | 1 | 7 | | 2 | 7| | 3 | 8|</p><p>Now we can make a random guess about our <span class="math inline">\(h_Î¸\)</span> function: <span class="math inline">\(Î¸_0=2\)</span> and <span class="math inline">\(Î¸_1=2\)</span>. The hypothesis function becomes <span class="math inline">\(h_Î¸(x)=2+2x\)</span>.</p><p>So for input of 1 to our hypothesis, y will be 4. This is off by 3.</p><h2><span id="cost-function">Cost Function</span></h2><p>We can measure the accuracy of our hypothesis function by using a <strong>cost function</strong>. This takes an average (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's compared to the actual output y's.</p><p><span class="math inline">\(J(Î¸_0,Î¸_1)=\frac{1}{2m}âˆ‘_{i=1}^{m}(h_Î¸(x_i)âˆ’y_i)^2\)</span></p><p>To break it apart, it is <span class="math inline">\(\frac{1}{2}\overline{x}\)</span> where <span class="math inline">\(\overline{x}\)</span> is the mean of the squares of <span class="math inline">\(h_Î¸(x_i) - y_i\)</span>, or the difference between the predicted value and the actual value.</p><p>This function is otherwise called the &quot;<strong>Squared error function</strong>&quot;, or <strong>Mean squared error</strong>(å‡æ–¹è¯¯å·®). The mean is halved <span class="math inline">\((\frac{1}{2m})\)</span> as a convenience for the computation of the <em>gradient descent</em>(æ¢¯åº¦ä¸‹é™), as the derivative(å¯¼æ•°) term of the square function will cancel out the <span class="math inline">\(\frac{1}{2}\)</span> term.</p><p>Now we are able to concretely measure the accuracy of our predictor function against the correct results we have so that we can predict new results we don't have.</p><figure><img src="/images/1454124395514.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="gradient-descent">Gradient Descent</span></h2><p>So we have our hypothesis function and we have a way of measuring how accurate it is. Now what we need is a way to automatically improve our hypothesis function. That's where gradient descent comes in.</p><p>Imagine that we graph our hypothesis function based on its fields <span class="math inline">\(Î¸_0\)</span> and <span class="math inline">\(Î¸_1\)</span> (actually we are graphing the cost function for the combinations of parameters). This can be kind of confusing; we are moving up to a higher level of abstraction. We are not graphing x and y itself, but the guesses of our hypothesis function.</p><p>We put <span class="math inline">\(Î¸_0\)</span> on the x axis and <span class="math inline">\(Î¸_1\)</span> on the z axis, with the cost function on the vertical y axis. The points on our graph will be the result of the <strong>cost function</strong> using our hypothesis with those specific theta parameters.</p><p>We will know that we have succeeded when our cost function is at the very bottom of the pits in our graph, i.e. when its value is the <em>minimum</em>.</p><p>The way we do this is by taking the <strong>derivative</strong> (the line tangent to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down that derivative by the parameter <span class="math inline">\(Î±\)</span>, called the <strong>learning rate</strong>.</p><p>The gradient descent equation is:</p><p><em>repeat until convergence(æ”¶æ•›):</em>{ <span class="math inline">\(Î¸_j : = Î¸_j âˆ’ Î± \frac{âˆ‚}{âˆ‚Î¸_j}J(Î¸_0,Î¸_1)\)</span> <code>for j=0 and j=1</code> }</p><p>Intuitively, this could be thought of as:</p><p>repeat until convergence:{ <span class="math inline">\(Î¸_j : = Î¸_j âˆ’ Î±\)</span>[Slope of tangent aka derivative] }</p><p><strong>Simultaneous update</strong></p><p><span class="math inline">\(temp0 := \theta - \alpha\frac{\partial}{\partial\theta_0}J(\theta_0, \theta_1)\)</span> <span class="math inline">\(temp1 := \theta - \alpha\frac{\partial}{\partial\theta_1}J(\theta_0, \theta_1)\)</span> <span class="math inline">\(\theta_0 := temp0\)</span> <span class="math inline">\(\theta_1 := temp1\)</span></p><p><strong>Learning rate <span class="math inline">\(\alpha\)</span></strong></p><figure><img src="/images/1454134071519.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="gradient-descent-for-linear-regression">Gradient Descent for Linear Regression</span></h2><p>When specifically applied to the case of linear regression, a new form of the gradient descent equation can be derived. We can substitute our actual cost function and our actual hypothesis function and modify the equation to (the derivation of the formulas are out of the scope of this course, but a really great one can be <a href="http://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables/189792#189792" target="_blank" rel="noopener">found here</a>:</p><p><em>repeat until convergence</em>: { <span class="math inline">\(Î¸_0 : = Î¸_0 âˆ’ Î±\frac{1}{m}âˆ‘_{i=1}^{m}(h_Î¸(x_i)âˆ’y_i)\)</span> <span class="math inline">\(Î¸_1 : = Î¸_1 âˆ’ Î±\frac{1}{m}âˆ‘_{i=1}^{m}(h_Î¸(x_i)âˆ’y_i)x_i\)</span> }</p><p>where <span class="math inline">\(m\)</span> is the size of the training set, <span class="math inline">\(Î¸_0\)</span> a constant that will be changing simultaneously with <span class="math inline">\(Î¸_1\)</span> and <span class="math inline">\(x_i,y_i\)</span> are values of the given training set.</p><p>Note that we have separated out the two cases for <span class="math inline">\(Î¸_j\)</span> and that for <span class="math inline">\(Î¸_1\)</span> we are multiplying <span class="math inline">\(x_i\)</span> at the end due to the derivative.</p><p>The point of all this is that if we start with a guess for our hypothesis and then repeatedly apply these gradient descent equations, our hypothesis will become more and more accurate.</p><p><strong>Batch Gradient Descent</strong></p><p>Batch : Each step of gradient descent uses all the training examples.</p><h2><span id="whats-next">What's Next</span></h2><p>Instead of using linear regression on just one input variable, we'll generalize and expand our concepts so that we can predict data with multiple input variables. Also, we'll solve for <span class="math inline">\(Î¸_0\)</span> and <span class="math inline">\(Î¸_1\)</span> exactly without needing an iterative function like gradient descent.</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Linear Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Introduction to machine learning</title>
      <link href="/2016/01/29/Introduction%20to%20machine%20learning/"/>
      <url>/2016/01/29/Introduction%20to%20machine%20learning/</url>
      
        <content type="html"><![CDATA[<h2><span id="what-is-machine-learning">What is Machine Learning?</span></h2><p>Two definitions of Machine Learning are offered. Arthur Samuel described it as: &quot;the field of study that gives computers the ability to learn without being explicitly programmed.&quot; This is an older, informal definition.</p><blockquote><p>Tom Mitchell provides a more modern definition: &quot;A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.&quot;</p></blockquote><a id="more"></a><p><strong>Example: playing checkers.</strong></p><ul><li>E = the experience of playing many games of checkers</li><li>T = the task of playing checkers.</li><li>P = the probability that the program will win the next game.</li></ul><h2><span id="supervised-learning">Supervised Learning</span></h2><blockquote><p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p></blockquote><p>Supervised learning problems are categorized into <strong>regression</strong> and <strong>classification</strong> problems. * In a <strong>regression</strong> problem, we are trying to predict results within a <strong>continuous</strong> output, meaning that we are trying to map input variables to some continuous function. * In a <strong>classification</strong> problem, we are instead trying to predict results in a <strong>discrete</strong> output. In other words, we are trying to <strong>map input variables into discrete categories</strong>.</p><p><strong>Example:</strong></p><p>Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a <strong>continuous</strong> output, so this is a <strong>regression</strong> problem.</p><p>We could turn this example into a classification problem by instead making our output about whether the house &quot;<em>sells for more or less than the asking price.</em>&quot; Here we are classifying the houses based on price into two <strong>discrete</strong> categories.</p><h2><span id="unsupervised-learning">Unsupervised Learning</span></h2><blockquote><p>Unsupervised learning, on the other hand, allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.</p></blockquote><p>We can derive this structure by <strong>clustering</strong> the data based on relationships among the variables in the data.</p><p>With unsupervised learning there is no feedback based on the prediction results, i.e., there is no teacher to correct you. Itâ€™s not just about clustering. For example, associative memory is unsupervised learning.</p><p><strong>Example:</strong></p><p><strong>Clustering</strong>: Take a collection of 1000 essays written on the US Economy, and find a way to automatically group these essays into a small number that are somehow similar or related by different variables, such as word frequency, sentence length, page count, and so on.</p><p><strong>Associative</strong>: Suppose a doctor over years of experience forms associations in his mind between patient characteristics and illnesses that they have. If a new patient shows up then based on this patientâ€™s characteristics such as symptoms, family medical history, physical attributes, mental outlook, etc the doctor associates possible illness or illnesses based on what the doctor has seen before with similar patients. This is not the same as rule based reasoning as in expert systems. In this case we would like to <em>estimate a mapping function from patient characteristics into illnesses</em>.</p><blockquote><p>From : https://www.coursera.org/learn/machine-learning/supplement/X64SM/introduction</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>è®°å½•ï¼šåœ¨ Docker ä¸Šé…ç½® PHP åº”ç”¨</title>
      <link href="/2016/01/17/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%9C%A8%20Docker%20%E4%B8%8A%E9%85%8D%E7%BD%AE%20PHP%20%E5%BA%94%E7%94%A8/"/>
      <url>/2016/01/17/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%9C%A8%20Docker%20%E4%B8%8A%E9%85%8D%E7%BD%AE%20PHP%20%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>ä»€ä¹ˆæ˜¯Docker</strong> dockerçš„è‹±æ–‡æœ¬æ„æ˜¯ç å¤´å·¥äººï¼Œä¹Ÿå°±æ˜¯æ¬è¿å·¥ï¼Œè¿™ç§æ¬è¿å·¥æ¬è¿çš„æ˜¯é›†è£…ç®±ï¼ˆContainerï¼‰ï¼Œé›†è£…ç®±é‡Œé¢è£…çš„å¯ä¸æ˜¯å•†å“è´§ç‰©ï¼Œè€Œæ˜¯ä»»æ„ç±»å‹çš„Appï¼ŒDockeræŠŠAppï¼ˆå«Payloadï¼‰è£…åœ¨Containerå†…ï¼Œé€šè¿‡Linux ContaineræŠ€æœ¯çš„åŒ…è£…å°†Appå˜æˆä¸€ç§æ ‡å‡†åŒ–çš„ã€å¯ç§»æ¤çš„ã€è‡ªç®¡ç†çš„ç»„ä»¶ï¼Œè¿™ç§ç»„ä»¶å¯ä»¥åœ¨ä½ çš„latopä¸Šå¼€å‘ã€è°ƒè¯•ã€è¿è¡Œï¼Œæœ€ç»ˆéå¸¸æ–¹ä¾¿å’Œä¸€è‡´åœ°è¿è¡Œåœ¨productionç¯å¢ƒä¸‹ã€‚</p></blockquote><a id="more"></a><h2><span id="èµ·">èµ·</span></h2><p>èµ·å› æ˜¯è…¾è®¯äº‘çš„å­¦ç”Ÿå®¡æ ¸é€šè¿‡äº†ï¼Œç„¶åå°±èŠ±ä¸€å—é’±ä¹°äº†ä¸ªæœåŠ¡å™¨ï¼Œå°±æƒ³åœ¨è…¾è®¯äº‘ä¸Šä¹Ÿé…ç½®ä¸‹æˆ‘çš„ï¼ˆå‰ï¼‰åšå®¢ï¼Œä½†æ˜¯åˆä¸æƒ³æ¯æ¬¡éƒ½é‡æ–°é…ç½®ç¯å¢ƒï¼Œäºæ˜¯å°±æƒ³åˆ°äº†Dockerï¼ŒæŠ˜è…¾äº†ä¸¤ä¸‰å¤©ç½‘ç«™æ€»ç®—æ˜¯å¯ä»¥è·‘äº†ï¼Œè¿™é‡Œè®°å½•ä¸€ä¸‹è¸©å‘è¿‡ç¨‹ã€‚</p><blockquote><p>Dockerçš„æ ¸å¿ƒåº•å±‚æŠ€æœ¯æ˜¯LXCï¼ˆLinux Containerï¼‰ï¼ŒDockeråœ¨å…¶ä¸Šé¢åŠ äº†è–„è–„çš„ä¸€å±‚ï¼Œæ·»åŠ äº†è®¸å¤šæœ‰ç”¨çš„åŠŸèƒ½ã€‚<a href="http://stackoverflow.com/questions/17989306/what-does-docker-add-to-lxc-tools-the-userspace-lxc-tools" target="_blank" rel="noopener">è¿™ç¯‡stackoverflow</a>ä¸Šçš„é—®é¢˜å’Œç­”æ¡ˆå¾ˆå¥½åœ°è¯ é‡Šäº†Dockerå’ŒLXCçš„åŒºåˆ«ï¼Œèƒ½å¤Ÿè®©ä½ æ›´å¥½çš„äº†è§£ä»€ä¹ˆæ˜¯Dockerï¼Œ ç®€å•ç¿»è¯‘ä¸‹å°±æ˜¯ä»¥ä¸‹å‡ ç‚¹ï¼š * Dockeræä¾›äº†ä¸€ç§å¯ç§»æ¤çš„é…ç½®æ ‡å‡†åŒ–æœºåˆ¶ï¼Œå…è®¸ä½ ä¸€è‡´æ€§åœ°åœ¨ä¸åŒçš„æœºå™¨ä¸Šè¿è¡ŒåŒä¸€ä¸ªContainerï¼›è€ŒLXCæœ¬èº«å¯èƒ½å› ä¸ºä¸åŒæœºå™¨çš„ä¸åŒé…ç½®è€Œæ— æ³•æ–¹ä¾¿åœ°ç§»æ¤è¿è¡Œï¼› Dockerä»¥Appä¸ºä¸­å¿ƒï¼Œä¸ºåº”ç”¨çš„éƒ¨ç½²åšäº†å¾ˆå¤šä¼˜åŒ–ï¼Œè€ŒLXCçš„å¸®åŠ©è„šæœ¬ä¸»è¦æ˜¯èšç„¦äºå¦‚ä½•æœºå™¨å¯åŠ¨åœ°æ›´å¿«å’Œè€—æ›´å°‘çš„å†…å­˜ï¼› * Dockerä¸ºAppæä¾›äº†ä¸€ç§è‡ªåŠ¨åŒ–æ„å»ºæœºåˆ¶ï¼ˆDockerfileï¼‰ï¼ŒåŒ…æ‹¬æ‰“åŒ…ï¼ŒåŸºç¡€è®¾æ–½ä¾èµ–ç®¡ç†å’Œå®‰è£…ç­‰ç­‰ï¼› * Dockeræä¾›äº†ä¸€ç§ç±»ä¼¼gitçš„Containerç‰ˆæœ¬åŒ–çš„æœºåˆ¶ï¼Œå…è®¸ä½ å¯¹ä½ åˆ›å»ºè¿‡çš„å®¹å™¨è¿›è¡Œç‰ˆæœ¬ç®¡ç†ï¼Œä¾é è¿™ç§æœºåˆ¶ï¼Œä½ è¿˜å¯ä»¥ä¸‹è½½åˆ«äººåˆ›å»ºçš„Containerï¼Œç”šè‡³åƒgité‚£æ ·è¿›è¡Œåˆå¹¶ï¼› * Docker Containeræ˜¯å¯é‡ç”¨çš„ï¼Œä¾èµ–äºç‰ˆæœ¬åŒ–æœºåˆ¶ï¼Œä½ å¾ˆå®¹æ˜“é‡ç”¨åˆ«äººçš„Containerï¼ˆå«Imageï¼‰ï¼Œä½œä¸ºåŸºç¡€ç‰ˆæœ¬è¿›è¡Œæ‰©å±•ï¼› * Docker Containeræ˜¯å¯å…±äº«çš„ï¼Œæœ‰ç‚¹ç±»ä¼¼githubä¸€æ ·ï¼Œ* Dockeræœ‰è‡ªå·±çš„INDEXï¼Œä½ å¯ä»¥åˆ›å»ºè‡ªå·±çš„Dockerç”¨æˆ·å¹¶ä¸Šä¼ å’Œä¸‹è½½Docker Imageï¼› * Dockeræä¾›äº†å¾ˆå¤šçš„å·¥å…·é“¾ï¼Œå½¢æˆäº†ä¸€ä¸ªç”Ÿæ€ç³»ç»Ÿï¼›è¿™äº›å·¥å…·çš„ç›®æ ‡æ˜¯è‡ªåŠ¨åŒ–ã€ä¸ªæ€§åŒ–å’Œé›†æˆåŒ–ï¼ŒåŒ…æ‹¬å¯¹PAASå¹³å°çš„æ”¯æŒç­‰ï¼›</p></blockquote><hr><p>æˆ‘ä¹‹å‰å…¶å®æ˜¯ä¹°è¿‡ä¸€æœ¬Dockerçš„ä¹¦çš„ï¼Œä½†æ˜¯è¿˜æ²¡æ¥å¾—åŠæ€ä¹ˆçœ‹ï¼Œè¿™æ¬¡çªç„¶è¦ç”¨å°±èµ¶ç´§ç¿»äº†ç¿»ï¼Œä¹ŸGoogleäº†ä¸€ä¸‹ï¼Œå‘ç°äº†è¿™ä¸ªç½‘ç«™ : <a href="http://dockerpool.com/static/books/docker_practice/index.html" target="_blank" rel="noopener">Docker â€”â€” ä»å…¥é—¨åˆ°å®è·µ</a>ï¼Œç»“æœå‘ç°ä¹¦é‡Œçš„å†…å®¹å’Œè¿™é‡ŒåŸºæœ¬ä¸€æ ·ï¼Œè¿åå­—ä¹Ÿå·®ä¸å¤šï¼Œæ—©çŸ¥é“å°±ä¸ä¹°ä¹¦äº†ã€‚</p><p>å°±è¿™æ ·å¼€å§‹äº†å­¦ä¹ Dockerä¹‹æ—…ã€‚</p><h2><span id="æ‰¿">æ‰¿</span></h2><p>æˆ‘çš„ç½‘ç«™ç¯å¢ƒæ˜¯nginx+php+mysqlï¼Œé‰´äºæ•°æ®åº“è¿˜ç”¨åŸæ¥æœåŠ¡å™¨ä¸Šçš„å°±å¥½ï¼Œæ‰€ä»¥åªéœ€è¦é…ç½®nginxä¸phpã€‚</p><p>è¿™é‡Œæœ‰ä¸¤ä¸ªé€‰é¡¹ï¼š * nginxå’Œphpæ”¾åˆ°ä¸€ä¸ªdockeré‡Œ * æŠŠnginxå’Œphpåˆ†å¼€æ”¾åˆ°ä¸¤ä¸ªdockeré‡Œ</p><p>å‰è€…æ˜æ˜¾çœ‹èµ·æ¥ç®€å•ä¸€äº›ï¼Œå› ä¸ºä¸æ¶‰åŠå®¹å™¨äº’è”ç­‰é—®é¢˜è¿˜çœäº‹ï¼Œä½†å…¶å®è¿™ç§å°†æ‰€æœ‰æœåŠ¡æ”¾åœ¨ä¸€ä¸ªå®¹å™¨å†…çš„æ¨¡å¼æœ‰ä¸ªå½¢è±¡çš„éå®˜æ–¹ç§°å‘¼ï¼šFat Containerã€‚ä¸ä¹‹ç›¸å¯¹çš„æ˜¯å°†æœåŠ¡åˆ†æ‹†åˆ°å®¹å™¨çš„æ¨¡å¼ã€‚ä»Dockerçš„è®¾è®¡å¯ä»¥çœ‹åˆ°ï¼Œæ„å»ºé•œåƒçš„è¿‡ç¨‹ä¸­å¯ä»¥æŒ‡å®šå”¯ä¸€ä¸€ä¸ªå®¹å™¨å¯åŠ¨çš„æŒ‡ä»¤ï¼Œ<strong>å› æ­¤Dockerå¤©ç„¶é€‚åˆä¸€ä¸ªå®¹å™¨åªè¿è¡Œä¸€ç§æœåŠ¡</strong>ï¼Œè€Œè¿™ä¹Ÿæ˜¯å®˜æ–¹æ›´æ¨å´‡çš„ã€‚</p><p>ç”±äºæˆ‘ä¸€å¼€å§‹å¹¶ä¸çŸ¥é“ä¸€ä¸ªdockeråªèƒ½è¿è¡Œä¸€ä¸ªæœåŠ¡ï¼Œæ‰€ä»¥æˆ‘é€‰äº†ç¬¬ä¸€ç§æ–¹æ¡ˆï¼Œç„¶åå°±å¤šè¸©äº†ä¸€ä¸ªå¤§å‘ã€‚</p><p>å½“æ—¶é‡åˆ°è¿™ä¹ˆä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼šæˆ‘ç”¨Dockerfileåˆ›å»ºé•œåƒï¼ŒDockerfileæœ€ååŒ…å«è¿™ä¹ˆä¸¤æ¡å¯åŠ¨æœåŠ¡çš„å‘½ä»¤ <figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"nginx"</span>]</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"php-fpm"</span>]</span></span><br></pre></td></tr></table></figure></p><p>nginxå¤©ç”Ÿå°±æ˜¯åå°æœåŠ¡ï¼Œè€Œphp-fpmä¸€è¿™ç§æ–¹å¼å¯ä»¥å‰å°è¿è¡Œï¼Œçœ‹èµ·æ¥è¿™ç§ç»„åˆæŒºå¥½ï¼Œå®¹å™¨å¯åŠ¨ä¹‹åä¹Ÿä¸ä¼šç«‹åˆ»ç»ˆæ­¢ï¼Œè€Œæ˜¯ä¸€ç›´åœ¨è¿è¡Œï¼Œä½†æ˜¯è®¿é—®ä¸äº†ç½‘ç«™ï¼ï¼</p><p>è¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ å› ä¸ºnginxåœ¨æœ€åé‚£ä¸ªå®¹å™¨é‡Œæ²¡æœ‰å¯åŠ¨ï¼Œå…·ä½“ä¸ºä»€ä¹ˆæ²¡æœ‰å¯åŠ¨æˆ‘ä¹Ÿä¸æ˜¯å¾ˆæ¸…æ¥šï¼Œè¿™ä¹Ÿå°±æ˜¯è¯´Dockerå¤©ç„¶é€‚åˆä¸€ä¸ªå®¹å™¨åªè¿è¡Œä¸€ç§æœåŠ¡çš„åŸå› å§ã€‚å¯æ˜¯å¦‚æœåªä¿ç•™nginxçš„è¯ï¼Œä¹Ÿä¼šå› ä¸ºå®ƒæ˜¯åå°è¿è¡Œæ‰€ä»¥å®¹å™¨åˆšè¿è¡Œå°±ä¼šåœæ­¢ã€‚</p><p>ç„¶åæˆ‘å°±å¥½å¥‡åˆ«äººçš„nginxæ˜¯æ€ä¹ˆè¿è¡Œçš„ã€‚æˆ‘å°±çœ‹äº†çœ‹<a href="https://hub.docker.com/_/nginx/" target="_blank" rel="noopener">nginxçš„å®˜æ–¹é•œåƒ</a>ï¼Œå†å®ƒçš„dockerfileæœ€åå†™çš„æ˜¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</span><br></pre></td></tr></table></figure></p><p>æŸ¥äº†æŸ¥ç„¶åçŸ¥é“é€šè¿‡è¿™ä¸ªå‚æ•°å¯ä»¥è®©nginxå‰å°è¿è¡Œï¼Œè€Œä¸ä¼šä½¿å®¹å™¨ç›´æ¥åœæ­¢ã€‚</p><p>ç„¶åæˆ‘å°±æŠŠDockerfileä¿®æ”¹æˆè¿™æ ·ï¼š <figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"php-fpm"</span>]</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"nginx"</span>, <span class="string">"-g"</span>, <span class="string">"daemon off;"</span>]</span></span><br></pre></td></tr></table></figure></p><p>å¤§å®¶åº”è¯¥ä¹Ÿçœ‹å‡ºæ¥äº†ï¼Œè¿™æ ·å°±å–œé—»ä¹è§åœ°è§£æä¸äº†phpäº†ã€‚</p><h2><span id="è½¬">è½¬</span></h2><p>æ¥ç€æˆ‘å°±å¥½å¥‡åˆ«äººçš„é›†æˆå¥½å¤šæœåŠ¡çš„dockeræ˜¯æ€ä¹ˆå¯åŠ¨çš„ï¼Œgoogleåˆ°äº†å‡ ä¸ªè¿™æ ·çš„åº”ç”¨ï¼Œç„¶åå°±å‘ç°äº†<a href="http://supervisord.org/" target="_blank" rel="noopener">supervisord</a>ï¼Œè¿™ä¸ªä¸œä¸œæ˜¯ä¸€ä¸ªè¿›ç¨‹ç®¡ç†å™¨ï¼Œå¯ä»¥å®Œç¾è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œåªéœ€ä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[supervisord]</span><br><span class="line">nodaemon=true</span><br><span class="line"></span><br><span class="line">[program:php-fpm]</span><br><span class="line">command=php-fpm</span><br><span class="line"></span><br><span class="line">[program:nginx]</span><br><span class="line">command=nginx</span><br></pre></td></tr></table></figure></p><p>é…ç½®å’Œå¯åŠ¨å‘½ä»¤å°±å¯ä»¥å†™æˆï¼š <figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ADD</span><span class="bash"> ./supervisord.conf /etc/supervisord.conf</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"supervisord"</span>]</span></span><br></pre></td></tr></table></figure></p><h2><span id="åˆ">åˆ</span></h2><p>è¿™æ ·å›°æ‰°æˆ‘å¥½ä¹…çš„é—®é¢˜å°±è§£å†³äº†ã€‚ä¸è¿‡è¿™åªæ˜¯æˆ‘è¸©åˆ°çš„æ€»å¤šå‘çš„å…¶ä¸­ä¹‹ä¸€ï¼Œç®—æ˜¯æ¯”è¾ƒå¤§çš„ä¸€ä¸ªï¼Œä¹Ÿæ˜¯ç¨å¾®æœ‰ç‚¹åˆ†äº«ä»·å€¼çš„ä¸€ä¸ªï¼Œç›¸æ¯”è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆè€Œè¨€ï¼Œè§£å†³è¿™ä¸ªé—®é¢˜çš„è¿‡ç¨‹æ›´æœ‰ä»·å€¼ä¸€äº›å§ï¼Œæ•…åœ¨æ­¤è®°å½•ä¸€ä¸‹ã€‚</p><p>ps : è¿˜æœ‰ä¸ªå°å‘ä¹Ÿå€¼å¾—æ³¨æ„ä¸€ä¸‹ï¼Œæˆ‘ç”¨centos7ä½œä¸ºåŸºç¡€é•œåƒï¼Œé€šè¿‡yumå®‰è£…çš„phpä¸è‡ªå¸¦mysqliæ¨¡å—ï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£…<code>RUN yum install -y php-mysqli</code>ï¼Œè¿™ä¸ªå½“æ—¶æ‰¾é—®é¢˜ä¹Ÿæ‰¾äº†å¥½ä¹…ã€‚</p><blockquote><p><strong>å‚è€ƒ</strong> http://dockerpool.com/static/books/docker_practice/index.html http://tech.uc.cn/?p=2726 http://avnpc.com/pages/build-php-develop-env-by-docker</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> PHP </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>TCP/IP æµ…æ</title>
      <link href="/2016/01/10/IP%20%E6%B5%85%E6%9E%90/"/>
      <url>/2016/01/10/IP%20%E6%B5%85%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#å»ºç«‹tcpè¿æ¥çš„è¿‡ç¨‹">å»ºç«‹TCPè¿æ¥çš„è¿‡ç¨‹</a></li><li><a href="#tcpä¼ è¾“çš„è¿‡ç¨‹">TCPä¼ è¾“çš„è¿‡ç¨‹</a></li><li><a href="#ç»“æŸè¿æ¥">ç»“æŸè¿æ¥</a></li><li><a href="#tcpæ•°æ®ä¼ è¾“ä¸åŒäºudpä¹‹å¤„">TCPæ•°æ®ä¼ è¾“ä¸åŒäºUDPä¹‹å¤„</a></li><li><a href="#tcpè¿æ¥çš„å„ç§çŠ¶æ€">tcpè¿æ¥çš„å„ç§çŠ¶æ€</a></li><li><a href="#å®è·µéƒ¨åˆ†">å®è·µéƒ¨åˆ†</a><ul><li><a href="#æŠ“åŒ…">æŠ“åŒ…</a></li><li><a href="#socket-æœåŠ¡å™¨">Socket æœåŠ¡å™¨</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="å»ºç«‹tcpè¿æ¥çš„è¿‡ç¨‹">å»ºç«‹TCPè¿æ¥çš„è¿‡ç¨‹</span></h2><p><strong>ä¸‰è·¯æ¡æ‰‹</strong></p><p><img src="/images/1452307217663.png"></p><blockquote><p>TCPç”¨ä¸‰è·¯æ¡æ‰‹ï¼ˆthree-way handshakeï¼‰è¿‡ç¨‹åˆ›å»ºä¸€ä¸ªè¿æ¥ã€‚åœ¨è¿æ¥åˆ›å»ºè¿‡ç¨‹ä¸­ï¼Œå¾ˆå¤šå‚æ•°è¦è¢«åˆå§‹åŒ–ï¼Œä¾‹å¦‚åºå·è¢«åˆå§‹åŒ–ä»¥ä¿è¯æŒ‰åºä¼ è¾“å’Œè¿æ¥çš„å¼ºå£®æ€§ã€‚</p></blockquote><p>ä¸€å¯¹ç»ˆç«¯åŒæ—¶åˆå§‹åŒ–ä¸€ä¸ªå®ƒä»¬ä¹‹é—´çš„è¿æ¥æ˜¯å¯èƒ½çš„ã€‚ä½†é€šå¸¸æ˜¯ç”±ä¸€ç«¯æ‰“å¼€ä¸€ä¸ªå¥—æ¥å­—ï¼ˆsocketï¼‰ç„¶åç›‘å¬æ¥è‡ªå¦ä¸€æ–¹çš„è¿æ¥ï¼Œè¿™å°±æ˜¯é€šå¸¸æ‰€æŒ‡çš„è¢«åŠ¨æ‰“å¼€ï¼ˆpassive openï¼‰ã€‚æœåŠ¡å™¨ç«¯è¢«è¢«åŠ¨æ‰“å¼€ä»¥åï¼Œç”¨æˆ·ç«¯å°±èƒ½å¼€å§‹åˆ›å»ºä¸»åŠ¨æ‰“å¼€ï¼ˆactive openï¼‰ã€‚</p><ol type="1"><li>å®¢æˆ·ç«¯é€šè¿‡å‘æœåŠ¡å™¨ç«¯å‘é€ä¸€ä¸ª<code>SYN</code>æ¥åˆ›å»ºä¸€ä¸ªä¸»åŠ¨æ‰“å¼€ï¼Œä½œä¸ºä¸‰è·¯æ¡æ‰‹çš„ä¸€éƒ¨åˆ†ã€‚å®¢æˆ·ç«¯æŠŠè¿™æ®µè¿æ¥çš„åºå·è®¾å®šä¸ºéšæœºæ•° <strong>A</strong>ã€‚</li><li>æœåŠ¡å™¨ç«¯åº”å½“ä¸ºä¸€ä¸ªåˆæ³•çš„<code>SYN</code>å›é€ä¸€ä¸ª<code>SYN/ACK</code>ã€‚<code>ACK</code> çš„ç¡®è®¤ç åº”ä¸º <strong>A+1</strong>ï¼Œ<code>SYN/ACK</code> åŒ…æœ¬èº«åˆæœ‰ä¸€ä¸ªéšæœºåºå· <strong>B</strong>ã€‚</li><li>æœ€åï¼Œå®¢æˆ·ç«¯å†å‘é€ä¸€ä¸ª<code>ACK</code>ã€‚å½“æœåŠ¡ç«¯å—åˆ°è¿™ä¸ª<code>ACK</code>çš„æ—¶å€™ï¼Œå°±å®Œæˆäº†ä¸‰è·¯æ¡æ‰‹ï¼Œå¹¶è¿›å…¥äº†è¿æ¥åˆ›å»ºçŠ¶æ€ã€‚æ­¤æ—¶åŒ…åºå·è¢«è®¾å®šä¸ºæ”¶åˆ°çš„ç¡®è®¤å· <strong>A+1</strong>ï¼Œè€Œå“åº”åˆ™ä¸º <strong>B+1</strong>ã€‚</li></ol><p><a href="https://neymarl.github.io/2016/01/02/Wireshark%20%E6%8A%93%E5%8C%85%E6%8C%87%E5%8D%97/#tcp-%E4%B8%89%E8%B7%AF%E6%8F%A1%E6%89%8B%E5%88%86%E6%9E%90" target="_blank" rel="noopener">å®ä¾‹å‚çœ‹è¿™é‡Œ</a></p><h2><span id="tcpä¼ è¾“çš„è¿‡ç¨‹">TCPä¼ è¾“çš„è¿‡ç¨‹</span></h2><p><strong>åºåˆ—å·å’Œç¡®è®¤</strong></p><p>åœ¨TCPçš„è¿æ¥åˆ›å»ºçŠ¶æ€ï¼Œä¸¤ä¸ªä¸»æœºçš„TCPå±‚é—´è¦äº¤æ¢<strong>åˆå§‹åºå·ï¼ˆISN:initial sequence numberï¼‰</strong>ã€‚è¿™äº›åºå·ç”¨äºæ ‡è¯†å­—èŠ‚æµä¸­çš„æ•°æ®ï¼Œå¹¶ä¸”è¿˜æ˜¯<strong>å¯¹åº”ç”¨å±‚çš„æ•°æ®å­—èŠ‚è¿›è¡Œè®°æ•°</strong>çš„æ•´æ•°ã€‚</p><p>é€šå¸¸åœ¨æ¯ä¸ªTCPæŠ¥æ–‡æ®µä¸­éƒ½æœ‰ä¸€å¯¹åºå·å’Œç¡®è®¤å·ã€‚<strong>TCPæŠ¥æ–‡å‘é€è€…è®¤ä¸ºè‡ªå·±çš„å­—èŠ‚ç¼–å·ä¸ºåºå·ï¼Œè€Œè®¤ä¸ºæ¥æ”¶è€…çš„å­—èŠ‚ç¼–å·ä¸ºç¡®è®¤å·ã€‚</strong></p><p>TCPæŠ¥æ–‡çš„æ¥æ”¶è€…ä¸ºäº†ç¡®ä¿å¯é æ€§ï¼Œåœ¨æ¥æ”¶åˆ°ä¸€å®šæ•°é‡çš„è¿ç»­å­—èŠ‚æµåæ‰å‘é€ç¡®è®¤ã€‚è¿™æ˜¯å¯¹TCPçš„ä¸€ç§æ‰©å±•ï¼Œé€šå¸¸ç§°ä¸º<strong>é€‰æ‹©ç¡®è®¤ï¼ˆSelective Acknowledgementï¼‰</strong>ã€‚é€‰æ‹©ç¡®è®¤ä½¿å¾—TCPæ¥æ”¶è€…å¯ä»¥å¯¹ä¹±åºåˆ°è¾¾çš„æ•°æ®å—è¿›è¡Œç¡®è®¤ã€‚<strong>æ¯ä¸€ä¸ªå­—èŠ‚ä¼ è¾“è¿‡åï¼ŒISNå·éƒ½ä¼šé€’å¢1ã€‚</strong></p><p>é€šè¿‡ä½¿ç”¨åºå·å’Œç¡®è®¤å·ï¼ŒTCPå±‚å¯ä»¥æŠŠæ”¶åˆ°çš„æŠ¥æ–‡æ®µä¸­çš„å­—èŠ‚æŒ‰æ­£ç¡®çš„é¡ºåºäº¤ä»˜ç»™åº”ç”¨å±‚ã€‚åºå·æ˜¯32ä½çš„æ— ç¬¦å·æ•°ï¼Œåœ¨å®ƒå¢å¤§åˆ°232-1æ—¶ï¼Œä¾¿ä¼šå›ç»•åˆ°0ã€‚å¯¹äºISNçš„é€‰æ‹©æ˜¯TCPä¸­å…³é”®çš„ä¸€ä¸ªæ“ä½œï¼Œå®ƒå¯ä»¥ç¡®ä¿å¼ºå£®æ€§å’Œå®‰å…¨æ€§ã€‚</p><p><strong>æ•°æ®ä¼ è¾“å®ä¾‹</strong></p><p>æ‰“å¼€WiresharkæŠ“åŒ…ï¼Œç„¶åæµè§ˆå™¨è¾“å…¥ http://www.liuhe.websiteï¼Œç­‰åŠ è½½å®Œæ¯•åœæ­¢æŠ“åŒ…ã€‚</p><p>æ‰¾åˆ°<img src="/images/1452309211801.png">è¿™æ¡HTTPè¯·æ±‚ï¼Œç„¶åFollow TCP streamï¼Œå¾—åˆ°å¦‚å›¾æ‰€ç¤ºç•Œé¢ï¼š <img src="/images/1452309279437.png"></p><p>å‰é¢ä¸‰æ¡TCPæŠ¥æ–‡æ˜¯ä¸‰è·¯æ¡æ‰‹å»ºç«‹TCPè¿æ¥çš„è¿‡ç¨‹ï¼Œç´§æ¥ç€å®¢æˆ·ç«¯å‘é€ç¬¬ä¸€ä¸ªåŒ…å«åºåˆ—å·1å’Œ766å­—èŠ‚æ•°æ®çš„æŠ¥æ–‡ç»™æœåŠ¡å™¨ã€‚ <img src="/images/1452309404266.png"></p><p>æœåŠ¡å™¨æ¥æ”¶åˆ°TCPæŠ¥æ–‡ä¹‹åè¿”å›ä¸€æ¡ç¡®è®¤æŠ¥æ–‡ï¼Œè¯¥æŠ¥æ–‡å†…åªæœ‰æŠ¥å¤´ï¼Œæ²¡æœ‰æ•°æ®ï¼Œç”¨ç¡®è®¤å·767æ¥è¡¨ç¤ºå·²å®Œå…¨æ”¶åˆ°ã€‚å¦‚å›¾æ‰€ç¤ºï¼š <img src="/images/1452313151381.png"></p><p>ç„¶åæœåŠ¡å™¨ç»§ç»­å‘é€HTTPå“åº”ï¼ŒTCPæŠ¥æ–‡åŒ…å«åºåˆ—å·1å’Œ201å­—èŠ‚æ•°æ®ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š <img src="/images/1452313422647.png"></p><p>å®¢æˆ·ç«¯ä»¥ä¸€ä¸ªæ²¡æœ‰æ•°æ®çš„TCPæŠ¥æ–‡æ®µæ¥å›å¤ï¼ˆåªå«æŠ¥å¤´ï¼‰ï¼Œç”¨ç¡®è®¤å·202æ¥è¡¨ç¤ºå·²å®Œå…¨æ”¶åˆ°å¹¶è¯·æ±‚ä¸‹ä¸€ä¸ªæŠ¥æ–‡æ®µã€‚ <img src="/images/1452314346326.png"></p><p>å°±è¿™æ ·ä¸€ç›´ç»§ç»­ä¸‹å»ç›´åˆ°æ•°æ®ä¼ è¾“å®Œæ¯•ã€‚</p><hr><p>ç„¶è€Œå½“è¿™äº›æ•°æ®åŒ…éƒ½æ˜¯ç›¸è¿çš„æƒ…å†µä¸‹ï¼Œæ¥æ”¶æ–¹æ²¡æœ‰å¿…è¦æ¯ä¸€æ¬¡éƒ½å›åº”ã€‚æ¯”å¦‚ï¼Œä»–æ”¶åˆ°ç¬¬1åˆ°5æ¡TCPæŠ¥æ–‡æ®µï¼Œåªéœ€å›åº”ç¬¬äº”æ¡å°±è¡Œäº†ã€‚å¦‚æœç¬¬3æ¡TCPæŠ¥æ–‡æ®µè¢«ä¸¢å¤±äº†ï¼Œå°½ç®¡ä»–æ”¶åˆ°äº†ç¬¬4å’Œ5æ¡ï¼Œç„¶è€Œä»–åªèƒ½å›åº”ç¬¬2æ¡ã€‚ å‘é€æ–¹åœ¨å‘é€äº†ç¬¬ä¸‰æ¡ä»¥åï¼Œæ²¡èƒ½æ”¶åˆ°å›åº”ï¼Œå› æ­¤å½“æ—¶é’Ÿï¼ˆtimerï¼‰è¿‡æ—¶ï¼ˆexpireï¼‰æ—¶ï¼Œä»–é‡å‘ç¬¬ä¸‰æ¡ã€‚ï¼ˆæ¯æ¬¡å‘é€è€…å‘é€ä¸€æ¡TCPæŠ¥æ–‡æ®µåï¼Œéƒ½ä¼šå†æ¬¡å¯åŠ¨ä¸€æ¬¡æ—¶é’Ÿï¼šRTTï¼‰ã€‚ <img src="/images/1452314666698.png"></p><h2><span id="ç»“æŸè¿æ¥">ç»“æŸè¿æ¥</span></h2><p>è¿æ¥ç»ˆæ­¢ä½¿ç”¨äº†<strong>å››è·¯æ¡æ‰‹è¿‡ç¨‹ï¼ˆfour-way handshakeï¼‰</strong>ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­æ¯ä¸ªç»ˆç«¯çš„è¿æ¥éƒ½èƒ½ç‹¬ç«‹åœ°è¢«ç»ˆæ­¢ã€‚å› æ­¤ï¼Œä¸€ä¸ªå…¸å‹çš„æ‹†æ¥è¿‡ç¨‹éœ€è¦æ¯ä¸ªç»ˆç«¯éƒ½æä¾›ä¸€å¯¹<code>FIN</code>å’Œ<code>ACK</code>ã€‚</p><p><img src="/images/1452314985544.png"></p><p>ä¸è¿‡æˆ‘åœ¨æŠ“åŒ…æ—¶å‘ç°å…³é—­è¿æ¥æ—¶æ˜¯æœåŠ¡å™¨å‘é€äº†ACKå’ŒFINï¼Œç„¶åå®¢æˆ·ç«¯è¿”å›ACKç¡®è®¤å…³é—­ï¼Œå¯èƒ½æ˜¯å®¢æˆ·ç«¯ç¬¬ä¸€ä¸ªå‘å‡ºæ¥çš„FINæ²¡æŠ“åˆ°è¿˜æ˜¯æ€ä¹ˆå›äº‹ä¸å¤ªæ¸…æ¥šã€‚ <img src="/images/1452315669659.png"></p><p>##ä¸Unix sockæ–‡ä»¶çš„åŒºåˆ«</p><p>Unix domain socket æˆ–è€… IPC socketæ˜¯ä¸€ç§ç»ˆç«¯ï¼Œå¯ä»¥ä½¿åŒä¸€å°æ“ä½œç³»ç»Ÿä¸Šçš„ä¸¤ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹è¿›è¡Œæ•°æ®é€šä¿¡ã€‚ä¸Internet socketä¸åŒçš„æ˜¯ï¼Œå®ƒ<strong>ä¸éœ€è¦ç»è¿‡ç½‘ç»œåè®®æ ˆï¼Œä¸éœ€è¦æ‰“åŒ…æ‹†åŒ…ã€è®¡ç®—æ ¡éªŒå’Œã€ç»´æŠ¤åºå·å’Œåº”ç­”ç­‰</strong>ï¼Œåªæ˜¯å°†åº”ç”¨å±‚æ•°æ®ä»ä¸€ä¸ªè¿›ç¨‹æ‹·è´åˆ°å¦ä¸€ä¸ªè¿›ç¨‹ã€‚</p><p>Unix domain sockets ä½¿ç”¨ç³»ç»Ÿæ–‡ä»¶çš„åœ°å€æ¥ä½œä¸ºè‡ªå·±çš„èº«ä»½ã€‚å®ƒå¯ä»¥è¢«ç³»ç»Ÿè¿›ç¨‹å¼•ç”¨ã€‚æ‰€ä»¥ä¸¤ä¸ªè¿›ç¨‹å¯ä»¥åŒæ—¶æ‰“å¼€ä¸€ä¸ªUnix domain socketsæ¥è¿›è¡Œé€šä¿¡ã€‚ä¸è¿‡<strong>è¿™ç§é€šä¿¡æ–¹å¼æ˜¯å‘ç”Ÿåœ¨ç³»ç»Ÿå†…æ ¸é‡Œè€Œä¸ä¼šåœ¨ç½‘ç»œé‡Œä¼ æ’­</strong>ã€‚</p><h2><span id="tcpæ•°æ®ä¼ è¾“ä¸åŒäºudpä¹‹å¤„">TCPæ•°æ®ä¼ è¾“ä¸åŒäºUDPä¹‹å¤„</span></h2><ul><li>æœ‰åºæ•°æ®ä¼ è¾“</li><li>é‡å‘ä¸¢å¤±çš„æ•°æ®åŒ…</li><li>èˆå¼ƒé‡å¤çš„æ•°æ®åŒ…</li><li>æ— é”™è¯¯æ•°æ®ä¼ è¾“</li><li>é˜»å¡/æµé‡æ§åˆ¶</li><li>é¢å‘è¿æ¥ï¼ˆç¡®è®¤æœ‰åˆ›å»ºä¸‰æ–¹äº¤æ¡ï¼Œè¿æ¥å·²åˆ›å»ºæ‰ä½œä¼ è¾“ã€‚ï¼‰</li></ul><h2><span id="tcpè¿æ¥çš„å„ç§çŠ¶æ€">tcpè¿æ¥çš„å„ç§çŠ¶æ€</span></h2><p>ä¸‹é¢ä¸º TCP çŠ¶æ€ç åˆ—è¡¨ï¼Œä»¥ S æŒ‡ä»£æœåŠ¡å™¨ï¼ŒC æŒ‡ä»£å®¢æˆ·ç«¯ï¼ŒS&amp;C è¡¨ç¤ºä¸¤è€…ï¼ŒS/C è¡¨ç¤ºä¸¤è€…ä¹‹ä¸€ï¼š[1]</p><ul><li><strong>LISTEN</strong> S ç­‰å¾…ä»ä»»æ„è¿œç¨‹ TCP ç«¯å£çš„è¿æ¥è¯·æ±‚ã€‚ä¾¦å¬çŠ¶æ€ã€‚</li><li><strong>SYN-SENT</strong> C åœ¨å‘é€è¿æ¥è¯·æ±‚åç­‰å¾…åŒ¹é…çš„è¿æ¥è¯·æ±‚ã€‚é€šè¿‡<code>connect()</code>å‡½æ•°å‘æœåŠ¡å™¨å‘å‡ºä¸€ä¸ªåŒæ­¥ï¼ˆSYNCï¼‰ä¿¡å·åè¿›å…¥æ­¤çŠ¶æ€ã€‚</li><li><strong>SYN-RECEIVED</strong> S å·²ç»æ”¶åˆ°å¹¶å‘é€åŒæ­¥ï¼ˆSYNCï¼‰ä¿¡å·ä¹‹åç­‰å¾…ç¡®è®¤ï¼ˆACKï¼‰è¯·æ±‚ã€‚</li><li><strong>ESTABLISHED</strong> S&amp;C è¿æ¥å·²ç»æ‰“å¼€ï¼Œæ”¶åˆ°çš„æ•°æ®å¯ä»¥å‘é€ç»™ç”¨æˆ·ã€‚æ•°æ®ä¼ è¾“æ­¥éª¤çš„æ­£å¸¸æƒ…å†µã€‚æ­¤æ—¶è¿æ¥ä¸¤ç«¯æ˜¯å¹³ç­‰çš„ã€‚</li><li><strong>FIN-WAIT-1</strong> S&amp;C ä¸»åŠ¨å…³é—­ç«¯è°ƒç”¨<code>close()</code>å‡½æ•°å‘å‡ºFINè¯·æ±‚åŒ…ï¼Œè¡¨ç¤ºæœ¬æ–¹çš„æ•°æ®å‘é€å…¨éƒ¨ç»“æŸï¼Œç­‰å¾…TCPè¿æ¥å¦ä¸€ç«¯çš„ç¡®è®¤åŒ…æˆ–FINè¯·æ±‚åŒ…ã€‚</li><li><strong>FIN-WAIT-2</strong> S&amp;C ä¸»åŠ¨å…³é—­ç«¯åœ¨FIN-WAIT-1çŠ¶æ€ä¸‹æ”¶åˆ°ç¡®è®¤åŒ…ï¼Œè¿›å…¥ç­‰å¾…è¿œç¨‹ TCP çš„è¿æ¥ç»ˆæ­¢è¯·æ±‚çš„åŠå…³é—­çŠ¶æ€ã€‚è¿™æ—¶å¯ä»¥æ¥æ”¶æ•°æ®ï¼Œä½†ä¸å†å‘é€æ•°æ®ã€‚</li><li><strong>CLOSE-WAIT</strong> S&amp;C è¢«åŠ¨å…³é—­ç«¯æ¥åˆ°FINåï¼Œå°±å‘å‡ºACKä»¥å›åº”FINè¯·æ±‚ï¼Œå¹¶è¿›å…¥ç­‰å¾…æœ¬åœ°ç”¨æˆ·çš„è¿æ¥ç»ˆæ­¢è¯·æ±‚çš„åŠå…³é—­çŠ¶æ€ã€‚è¿™æ—¶å¯ä»¥å‘é€æ•°æ®ï¼Œä½†ä¸å†æ¥æ”¶æ•°æ®ã€‚</li><li><strong>CLOSING</strong> S&amp;C åœ¨å‘å‡ºFINåï¼Œåˆæ”¶åˆ°å¯¹æ–¹å‘æ¥çš„FINåï¼Œè¿›å…¥ç­‰å¾…å¯¹æ–¹å¯¹è¿æ¥ç»ˆæ­¢ï¼ˆFINï¼‰çš„ç¡®è®¤ï¼ˆACKï¼‰çš„çŠ¶æ€ã€‚å°‘è§ã€‚</li><li><strong>LAST-ACK</strong> S&amp;C è¢«åŠ¨å…³é—­ç«¯å…¨éƒ¨æ•°æ®å‘é€å®Œæˆä¹‹åï¼Œå‘ä¸»åŠ¨å…³é—­ç«¯å‘é€FINï¼Œè¿›å…¥ç­‰å¾…ç¡®è®¤åŒ…çš„çŠ¶æ€ã€‚</li><li><strong>TIME-WAIT</strong> S/C ä¸»åŠ¨å…³é—­ç«¯æ¥æ”¶åˆ°FINåï¼Œå°±å‘é€ACKåŒ…ï¼Œç­‰å¾…è¶³å¤Ÿæ—¶é—´ä»¥ç¡®ä¿è¢«åŠ¨å…³é—­ç«¯æ”¶åˆ°äº†ç»ˆæ­¢è¯·æ±‚çš„ç¡®è®¤åŒ…ã€‚ã€æŒ‰ç…§ RFC 793ï¼Œä¸€ä¸ªè¿æ¥å¯ä»¥åœ¨ TIME-WAIT ä¿è¯æœ€å¤§å››åˆ†é’Ÿï¼Œå³æœ€å¤§åˆ†æ®µå¯¿å‘½ï¼ˆmaximum segment lifetimeï¼‰çš„2å€ã€‘</li><li><strong>CLOSED</strong> S&amp;C å®Œå…¨æ²¡æœ‰è¿æ¥ã€‚</li></ul><p><strong>TCPçŠ¶æ€è½¬æ¢å›¾è§£</strong> <img src="/images/1452349572799.png"> ä¸Šå›¾æè¿°äº† TCP çš„11ç§çŠ¶æ€çš„è½¬æ¢å…³ç³»ã€‚ * å›¾ä¸­çš„åœ†è§’çŸ©å½¢è¡¨ç¤ºçŠ¶æ€ï¼Œç®­å¤´è¡¨ç¤ºçŠ¶æ€ä¹‹é—´çš„è½¬æ¢ã€‚ * å›¾ä¸­ç”¨ç²—çº¿è¡¨ç¤ºå®¢æˆ·ç«¯ä¸»åŠ¨å’Œè¢«åŠ¨çš„æœåŠ¡å™¨ç«¯å»ºç«‹è¿æ¥çš„æ­£å¸¸è¿‡ç¨‹ï¼š * <strong>å®¢æˆ·ç«¯çš„çŠ¶æ€å˜è¿ç”¨ç²—å®çº¿</strong> * <strong>æœåŠ¡å™¨ç«¯çš„çŠ¶æ€å˜è¿ç”¨ç²—è™šçº¿</strong> * ç»†çº¿ç”¨äºä¸å¸¸è§çš„åºåˆ—ï¼Œå¦‚å¤ä½ã€åŒæ—¶æ‰“å¼€ã€åŒæ—¶å…³é—­ç­‰ã€‚ * å›¾ä¸­çš„æ¯æ¡çŠ¶æ€å˜æ¢çº¿ä¸Šå‡æ ‡æœ‰<strong>â€œäº‹ä»¶ï¼åŠ¨ä½œâ€</strong>ï¼š * äº‹ä»¶æ˜¯æŒ‡ç”¨æˆ·æ‰§è¡Œäº†ç³»ç»Ÿè°ƒç”¨ï¼ˆ CONNECT ã€ LISTEN ã€ SEND æˆ– CLOSE ï¼‰ã€æ”¶åˆ°ä¸€ä¸ªæŠ¥æ–‡æ®µï¼ˆ SYN ã€ FIN ã€ ACK æˆ– RST ï¼‰ã€æˆ–è€…æ˜¯å‡ºç°äº†è¶…è¿‡ä¸¤å€æœ€å¤§çš„åˆ†ç»„ç”Ÿå‘½æœŸçš„æƒ…å†µï¼› * åŠ¨ä½œæ˜¯æŒ‡å‘é€ä¸€ä¸ªæŠ¥æ–‡æ®µï¼ˆ SYN ã€ FIN æˆ– ACK ï¼‰æˆ–ä»€ä¹ˆä¹Ÿæ²¡æœ‰ï¼ˆç”¨â€œï¼â€è¡¨ç¤ºï¼‰ã€‚</p><p><strong>ç²—å®çº¿è¡¨ç¤ºå®¢æˆ·çš„æ­£å¸¸è·¯å¾„ï¼›ç²—è™šçº¿è¡¨ç¤ºæœåŠ¡å™¨çš„æ­£å¸¸è·¯å¾„ï¼›ç»†çº¿è¡¨ç¤ºä¸å¸¸è§çš„äº‹ä»¶ã€‚</strong>æ¯ä¸ªè¿æ¥å‡å¼€å§‹äº CLOSED çŠ¶æ€ã€‚å½“ä¸€æ–¹æ‰§è¡Œäº†è¢«åŠ¨çš„è¿æ¥åŸè¯­ï¼ˆ LISTEN ï¼‰æˆ–ä¸»åŠ¨çš„è¿æ¥åŸè¯­ï¼ˆ CONNECT ï¼‰æ—¶ï¼Œå®ƒä¾¿ä¼šè„±ç¦» CLOSED çŠ¶æ€ã€‚å¦‚æœæ­¤æ—¶å¦ä¸€æ–¹æ‰§è¡Œäº†ç›¸å¯¹åº”çš„è¿æ¥åŸè¯­ï¼Œè¿æ¥ä¾¿å»ºç«‹äº†ï¼Œå¹¶ä¸”çŠ¶æ€å˜ä¸º ESTABLISHED ã€‚ä»»ä½•ä¸€æ–¹å‡å¯ä»¥é¦–å…ˆè¯·æ±‚é‡Šæ”¾è¿æ¥ï¼Œå½“è¿æ¥è¢«é‡Šæ”¾åï¼ŒçŠ¶æ€åˆå›åˆ°äº† CLOSED ã€‚</p><p><strong>æ­£å¸¸çŠ¶æ€è½¬æ¢è¿‡ç¨‹</strong></p><ol type="1"><li>æœåŠ¡å™¨ç«¯é¦–å…ˆæ‰§è¡Œ LISTEN åŸè¯­è¿›å…¥è¢«åŠ¨æ‰“å¼€çŠ¶æ€ï¼ˆ LISTEN ï¼‰ï¼Œç­‰å¾…å®¢æˆ·ç«¯è¿æ¥ï¼›</li><li>å½“å®¢æˆ·ç«¯çš„ä¸€ä¸ªåº”ç”¨ç¨‹åºå‘å‡º CONNECT å‘½ä»¤åï¼Œæœ¬åœ°çš„ TCP å®ä½“ä¸ºå…¶åˆ›å»ºä¸€ä¸ªè¿æ¥è®°å½•å¹¶æ ‡è®°ä¸º SYN SENT çŠ¶æ€ï¼Œç„¶åç»™æœåŠ¡å™¨å‘é€ä¸€ä¸ª SYN æŠ¥æ–‡æ®µï¼›</li><li>æœåŠ¡å™¨æ”¶åˆ°ä¸€ä¸ª SYN æŠ¥æ–‡æ®µï¼Œå…¶ TCP å®ä½“ç»™å®¢æˆ·ç«¯å‘é€ç¡®è®¤ ACK æŠ¥æ–‡æ®µåŒæ—¶å‘é€ä¸€ä¸ª SYN ä¿¡å·ï¼Œè¿›å…¥ SYN RCVD çŠ¶æ€ï¼›</li><li>å®¢æˆ·ç«¯æ”¶åˆ° SYN + ACK æŠ¥æ–‡æ®µï¼Œå…¶ TCP å®ä½“ç»™æœåŠ¡å™¨ç«¯å‘é€å‡ºä¸‰æ¬¡æ¡æ‰‹çš„æœ€åä¸€ä¸ª ACK æŠ¥æ–‡æ®µï¼Œå¹¶è½¬æ¢ä¸º ESTABLISHED çŠ¶æ€ï¼›</li><li>æœåŠ¡å™¨ç«¯æ”¶åˆ°ç¡®è®¤çš„ ACK æŠ¥æ–‡æ®µï¼Œå®Œæˆäº†ä¸‰æ¬¡æ¡æ‰‹ï¼Œäºæ˜¯ä¹Ÿè¿›å…¥ ESTABLISHED çŠ¶æ€ã€‚ åœ¨æ­¤çŠ¶æ€ä¸‹ï¼ŒåŒæ–¹å¯ä»¥è‡ªç”±ä¼ è¾“æ•°æ®ã€‚å½“ä¸€ä¸ªåº”ç”¨ç¨‹åºå®Œæˆæ•°æ®ä¼ è¾“ä»»åŠ¡åï¼Œå®ƒéœ€è¦å…³é—­ TCP è¿æ¥ã€‚å‡è®¾ä»ç”±å®¢æˆ·ç«¯å‘èµ·ä¸»åŠ¨å…³é—­è¿æ¥ã€‚</li><li>å®¢æˆ·ç«¯æ‰§è¡Œ CLOSE åŸè¯­ï¼Œæœ¬åœ°çš„ TCP å®ä½“å‘é€ä¸€ä¸ª FIN æŠ¥æ–‡æ®µå¹¶ç­‰å¾…å“åº”çš„ç¡®è®¤ï¼ˆè¿›å…¥çŠ¶æ€ FIN WAIT 1 ï¼‰ï¼›</li><li>æœåŠ¡å™¨æ”¶åˆ°ä¸€ä¸ª FIN æŠ¥æ–‡æ®µï¼Œå®ƒç¡®è®¤å®¢æˆ·ç«¯çš„è¯·æ±‚å‘å›ä¸€ä¸ª ACK æŠ¥æ–‡æ®µï¼Œè¿›å…¥ CLOSE WAIT çŠ¶æ€ï¼›</li><li>å®¢æˆ·ç«¯æ”¶åˆ°ç¡®è®¤ ACK æŠ¥æ–‡æ®µï¼Œå°±è½¬ç§»åˆ° FIN WAIT 2 çŠ¶æ€ï¼Œæ­¤æ—¶è¿æ¥åœ¨ä¸€ä¸ªæ–¹å‘ä¸Šå°±æ–­å¼€äº†ï¼›</li><li>æœåŠ¡å™¨ç«¯åº”ç”¨å¾—åˆ°é€šå‘Šåï¼Œä¹Ÿæ‰§è¡Œ CLOSE åŸè¯­å…³é—­å¦ä¸€ä¸ªæ–¹å‘çš„è¿æ¥ï¼Œå…¶æœ¬åœ° TCP å®ä½“å‘å®¢æˆ·ç«¯å‘é€ä¸€ä¸ª FIN æŠ¥æ–‡æ®µï¼Œå¹¶è¿›å…¥ LAST ACK çŠ¶æ€ï¼Œç­‰å¾…æœ€åä¸€ä¸ª ACK ç¡®è®¤æŠ¥æ–‡æ®µï¼›</li><li>å®¢æˆ·ç«¯æ”¶åˆ° FIN æŠ¥æ–‡æ®µå¹¶ç¡®è®¤ï¼Œè¿›å…¥ TIMED WAIT çŠ¶æ€ï¼Œæ­¤æ—¶åŒæ–¹è¿æ¥å‡å·²ç»æ–­å¼€ï¼Œä½† TCP è¦ç­‰å¾…ä¸€ä¸ª 2 å€æŠ¥æ–‡æ®µæœ€å¤§ç”Ÿå­˜æ—¶é—´ MSL ï¼ˆ Maximum Segment Lifetime ï¼‰ï¼Œç¡®ä¿è¯¥è¿æ¥çš„æ‰€æœ‰åˆ†ç»„å…¨éƒ¨æ¶ˆå¤±ï¼Œä»¥é˜²æ­¢å‡ºç°ç¡®è®¤ä¸¢å¤±çš„æƒ…å†µã€‚å½“å®šæ—¶å™¨è¶…æ—¶åï¼Œ TCP åˆ é™¤è¯¥è¿æ¥è®°å½•ï¼Œè¿”å›åˆ°åˆå§‹çŠ¶æ€ï¼ˆ CLOSED ï¼‰ã€‚</li><li>æœåŠ¡å™¨æ”¶åˆ°æœ€åä¸€ä¸ªç¡®è®¤ ACK æŠ¥æ–‡æ®µï¼Œå…¶ TCP å®ä½“ä¾¿é‡Šæ”¾è¯¥è¿æ¥ï¼Œå¹¶åˆ é™¤è¿æ¥è®°å½•ï¼Œè¿”å›åˆ°åˆå§‹çŠ¶æ€ï¼ˆ CLOSED ï¼‰ã€‚</li></ol><p><del>å…³äºæ“ä½œç³»ç»Ÿæ€ä¹ˆç»´æŠ¤å†…æ ¸è¿˜ä¸ºæ‰¾åˆ°ç›¸å…³èµ„æ–™</del></p><h2><span id="å®è·µéƒ¨åˆ†">å®è·µéƒ¨åˆ†</span></h2><h3><span id="æŠ“åŒ…">æŠ“åŒ…</span></h3><p>å…³äºWiresharkæŠ“åŒ…è¯¦è§<a href="http://www.liuhe.website/index.php?/Articles/single/20" target="_blank" rel="noopener">è¿™é‡Œ</a></p><h3><span id="socket-æœåŠ¡å™¨">Socket æœåŠ¡å™¨</span></h3><p>ç”¨pythonå†™çš„ç®€å•SocketæœåŠ¡å™¨ï¼Œå®ç°äº†å¦‚ä¸‹åŠŸèƒ½ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ç»‘å®šä¸€ä¸ªæœ¬åœ°ç«¯å£</span><br><span class="line">åœ¨æµè§ˆå™¨ä¸­è®¿é—®http://localhost:&lt;your_port&gt;/hello</span><br><span class="line">æ˜¾ç¤ºä¸€ä¸ªhello world</span><br><span class="line"></span><br><span class="line">åœ¨æµè§ˆå™¨ä¸­è®¿é—®http://localhost:&lt;your_port&gt;/info?name=xxx&amp;age=xxx</span><br><span class="line">æ˜¾ç¤ºhello, I&apos;m &lt;name_in_the_url&gt; and xxx years old.</span><br><span class="line"></span><br><span class="line">é€šè¿‡postmanè¡¨å•æäº¤http://localhost:&lt;your_port&gt;/form</span><br><span class="line">æ•°æ®</span><br><span class="line">username=xxx</span><br><span class="line">password=xxx</span><br><span class="line">å¯ä»¥ç®€å•çš„å­˜å‚¨ï¼Œä¹Ÿå¯ä»¥ä¸å­˜å‚¨</span><br><span class="line">ç›´æ¥åœ¨ç½‘é¡µä¸Šæ˜¾ç¤ºå‡ºæ¥</span><br><span class="line">I&apos;m &lt;username_posted&gt; and my password is &lt;password_posted&gt;</span><br></pre></td></tr></table></figure></p><p>ä¸»è¦ä»£ç å¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">class SimpleSocketServer:</span><br><span class="line">    def __init__(self, addr, bufsize):</span><br><span class="line">        self.s = socket(AF_INET, SOCK_STREAM)   # ç½‘ç»œé€šä¿¡, TCP</span><br><span class="line">        self.s.bind(addr)                       # ç»‘å®šçš„IPä¸ç«¯å£</span><br><span class="line">        self.s.listen(5)                        # å¼€å§‹TCPç›‘å¬, å¹¶æŒ‡å®šæœ€å¤šå…è®¸å¤šå°‘ä¸ªå®¢æˆ·è¿æ¥åˆ°æœåŠ¡å™¨</span><br><span class="line">        self.GET = &#123;&#125;   # å­˜å‚¨GETçš„å‚æ•°</span><br><span class="line">        self.POST = &#123;&#125;  # å­˜å‚¨POSTçš„å‚æ•°</span><br><span class="line">        self.bufsize = bufsize</span><br><span class="line"></span><br><span class="line">    def __del__(self):</span><br><span class="line">        self.s.close()</span><br><span class="line"></span><br><span class="line">    def listen(self):</span><br><span class="line">        while True:</span><br><span class="line">            self.GET = &#123;&#125;    # åˆå§‹åŒ–ä¸ºç©ºå­—å…¸</span><br><span class="line">            self.POST = &#123;&#125;</span><br><span class="line">            print &apos;Waiting for connection...&apos;</span><br><span class="line">            conn, addr = self.s.accept()    # æ¥å—TCPè¿æ¥ï¼Œå¹¶è¿”å›æ–°çš„å¥—æ¥å­—ä¸IPåœ°å€</span><br><span class="line">            print &apos;Connected by &apos;, addr     # è¾“å‡ºå®¢æˆ·ç«¯çš„IPåœ°å€</span><br><span class="line">            data = conn.recv(self.bufsize)  # æ¥æ”¶æ•°æ®</span><br><span class="line">            self.response(data, conn)</span><br><span class="line">            conn.close()</span><br><span class="line"></span><br><span class="line">    def response(self, data, conn):</span><br><span class="line">        print data</span><br><span class="line">        if self.isGET(data):    # åˆ¤æ–­æ–¹æ³•æ˜¯GETè¿˜æ˜¯POST</span><br><span class="line">            str = self.what(data, &apos;GET&apos;)   # è·å–HTTPè¯·æ±‚è·¯å¾„</span><br><span class="line">            if str == &apos;hello&apos;:</span><br><span class="line">                conn.send(&apos;Hello World!&apos;)</span><br><span class="line">            elif str == &apos;info&apos;:</span><br><span class="line">                if not &apos;name&apos; in self.GET or not &apos;age&apos; in self.GET:</span><br><span class="line">                    conn.send(&apos;What the fuck !&apos;) # é”™è¯¯ä¿¡æ¯</span><br><span class="line">                else:</span><br><span class="line">                    conn.send(&quot;hello, I&apos;m &quot; + self.GET[&apos;name&apos;] + &quot; and &quot;</span><br><span class="line">                              + self.GET[&apos;age&apos;] + &quot; years old.&quot;)</span><br><span class="line">        elif self.isPOST(data):</span><br><span class="line">            str = self.what(data, &apos;POST&apos;)</span><br><span class="line">            if str == &apos;form&apos;:</span><br><span class="line">                if not &apos;username&apos; in self.POST or not &apos;password&apos; in self.POST:</span><br><span class="line">                    conn.send(&apos;What the fuck !&apos;)</span><br><span class="line">                else:</span><br><span class="line">                    conn.send(&quot;I&apos;m &quot; + self.POST[&apos;username&apos;] + &quot; and my password is &quot; + self.POST[&apos;password&apos;] + &quot;.&quot;)</span><br><span class="line"></span><br><span class="line">    def what(self, data, method=&apos;GET&apos;):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">è§£æHTTPè¯·æ±‚è·¯å¾„å’Œå‚æ•°ï¼Œè¿”å›è·¯å¾„ï¼Œå‚æ•°å­˜åœ¨GETæˆ–POSTå­—å…¸é‡Œ</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        i = 0</span><br><span class="line">        # find &apos;/&apos;</span><br><span class="line">        while i &lt; len(data):</span><br><span class="line">            if data[i] == &apos;/&apos;:</span><br><span class="line">                break</span><br><span class="line">            i += 1</span><br><span class="line">        str = &apos;&apos;</span><br><span class="line">        i = i + 1</span><br><span class="line">        while i &lt; len(data) and data[i] != &apos; &apos; and data[i] != &apos;?&apos;:</span><br><span class="line">            str += data[i]</span><br><span class="line">            i += 1</span><br><span class="line">        if(data[i] == &apos;?&apos;):</span><br><span class="line">            i += 1</span><br><span class="line">        while i &lt; len(data) and data[i] != &apos; &apos;:</span><br><span class="line">            key = &apos;&apos;</span><br><span class="line">            value = &apos;&apos;</span><br><span class="line">            # get key</span><br><span class="line">            while i &lt; len(data) and data[i] != &apos; &apos; and data[i] != &apos;=&apos;:</span><br><span class="line">                key += data[i]</span><br><span class="line">                i += 1</span><br><span class="line">            if data[i] != &apos;=&apos;:</span><br><span class="line">                break</span><br><span class="line">            i += 1</span><br><span class="line">            # get value</span><br><span class="line">            while i &lt; len(data) and data[i] != &apos; &apos; and data[i] != &apos;&amp;&apos;:</span><br><span class="line">                value += data[i]</span><br><span class="line">                i += 1</span><br><span class="line">            if value:</span><br><span class="line">                self.GET[key] = value</span><br><span class="line">                if method == &apos;POST&apos;:</span><br><span class="line">                    self.POST[key] = value</span><br><span class="line">            if data[i] == &apos;&amp;&apos;:</span><br><span class="line">                i += 1</span><br><span class="line">        return str</span><br><span class="line"></span><br><span class="line">    def isGET(self, data):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">åˆ¤æ–­æ˜¯å¦ä¸ºGETè¯·æ±‚</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        if data[0] == &apos;G&apos; and data[1] == &apos;E&apos; and data[2] == &apos;T&apos;:</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            return False</span><br><span class="line"></span><br><span class="line">    def isPOST(self, data):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">åˆ¤æ–­æ˜¯å¦ä¸ºPOSTè¯·æ±‚</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        if data[0] == &apos;P&apos; and data[1] == &apos;O&apos;:</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            return False</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> è®¡ç®—æœºç½‘ç»œ </tag>
            
            <tag> TCP/IP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æµ·é‡æ•°æ®æŒ–æ˜ï¼ˆä¸‰ï¼‰ï¼šFinding Similar Sets</title>
      <link href="/2016/01/04/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AFinding%20Similar%20Sets/"/>
      <url>/2016/01/04/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AFinding%20Similar%20Sets/</url>
      
        <content type="html"><![CDATA[<blockquote><p>æ­¤ç³»åˆ—ä¸ºCouseraä¸ŠStandfordçš„<a href="https://class.coursera.org/mmds-002" target="_blank" rel="noopener">Mining Massive Datasets</a>è¯¾ç¨‹å­¦ä¹ ç¬”è®°ã€‚ è¿™æ˜¯è¯¥ç³»åˆ—çš„ç¬¬ä¸‰ç¯‡ç¬”è®°ï¼š<strong>Finding Similar Sets</strong></p></blockquote><a id="more"></a><!-- toc --><ul><li><a href="#åº”ç”¨ä»‹ç»-applications">åº”ç”¨ä»‹ç» Applications</a><ul><li><a href="#ç›¸ä¼¼æ–‡æ¡£-similar-documents">ç›¸ä¼¼æ–‡æ¡£ Similar Documents</a></li></ul></li><li><a href="#shingles">Shingles</a><ul><li><a href="#shingles-å’Œç›¸ä¼¼åº¦çš„å…³ç³»">Shingles å’Œç›¸ä¼¼åº¦çš„å…³ç³»</a></li><li><a href="#å‹ç¼©">å‹ç¼©</a></li></ul></li><li><a href="#minhashing">Minhashing</a><ul><li><a href="#jaccard-similarity">Jaccard Similarity</a></li><li><a href="#from-sets-to-boolean-matrices">From Sets to Boolean Matrices</a></li><li><a href="#four-types-of-rows">Four Types of Rows</a></li><li><a href="#minhashing-1">Minhashing</a></li><li><a href="#æ€§è´¨">æ€§è´¨</a></li><li><a href="#minhashing-çš„å®ç°">Minhashing çš„å®ç°</a></li></ul></li><li><a href="#locality-sensitive-hashing">Locality-Sensitive Hashing</a><ul><li><a href="#lsh">LSH</a><ul><li><a href="#lsh-for-minhashing-signatures">LSH for Minhashing Signatures</a></li></ul></li><li><a href="#hash-function-for-one-bucket">Hash Function for One Bucket</a></li><li><a href="#analysis-of-lsh">Analysis of LSH</a></li><li><a href="#lsh-summary">LSH Summary</a></li></ul></li><li><a href="#applications-of-lsh">Applications of LSH</a><ul><li><a href="#å®ä½“è§£æ-entity-resolution">å®ä½“è§£æ Entity Resolution</a></li><li><a href="#æŒ‡çº¹åŒ¹é…-fingerprint-matching">æŒ‡çº¹åŒ¹é… Fingerprint Matching</a></li><li><a href="#finding-duplicate-news-articles">Finding Duplicate News Articles</a></li></ul></li></ul><!-- tocstop --><h2><span id="åº”ç”¨ä»‹ç»-applications">åº”ç”¨ä»‹ç» Applications</span></h2><p>è®¸å¤šæ•°æ®æŒ–æ˜çš„é—®é¢˜éƒ½å¯ä»¥è¢«åŒ–ä¸ºæ˜¯æ‰¾ç›¸ä¼¼é›†çš„é—®é¢˜ï¼Œæ¯”å¦‚ï¼š 1. å…·æœ‰å¾ˆå¤šç›¸ä¼¼å•è¯çš„é¡µé¢å¯ä»¥è¢«è®¤ä¸ºæ˜¯ç›¸åŒçš„ä¸»é¢˜.. 2. æ‰¾å…·æœ‰ç›¸ä¼¼å“å‘³çš„NetFlix(ä¸€å®¶åœ¨ä¸–ç•Œå¤šå›½æä¾›ç½‘è·¯éšé€‰ä¸²æµå½±ç‰‡çš„å…¬å¸)ç”¨æˆ·ï¼Œå‘ä»–ä»¬æ¨èç”µå½±ã€‚ 3. å®ä½“è§£æ(Entity resolution)</p><h3><span id="ç›¸ä¼¼æ–‡æ¡£-similar-documents">ç›¸ä¼¼æ–‡æ¡£ Similar Documents</span></h3><p>ç»™å®šä¸€å †æ–‡æ¡£ï¼Œæ¯”å¦‚webé¡µé¢ï¼Œæ‰¾åˆ°å…·æœ‰å¤§é‡ç›¸åŒæ–‡å­—çš„æ–‡æ¡£å¯¹ï¼Œå¯ä»¥ç”¨æ¥å‘ç°ï¼š * é•œåƒç«™ç‚¹ã€‚åº”ç”¨ï¼šç½‘é¡µå»é‡ * æŠ„è¢­ï¼ŒåŒ…æ‹¬å¤§é‡å¼•ç”¨ã€‚ * æ¥è‡ªä¸åŒçš„ç«™ç‚¹çš„ç›¸ä¼¼çš„æ–‡ç« ï¼Œæ¯”å¦‚å¤šå®¶åª’ä½“éƒ½æŠ¥é“æŸä¸€äº‹ä»¶ã€‚</p><p><strong>åŸºæœ¬æŠ€æœ¯</strong></p><ol type="1"><li><strong>Shingling</strong> : æŠŠæ–‡æ¡£ï¼Œé‚®ä»¶ç­‰ç­‰è½¬æ¢æˆé›†åˆã€‚</li><li><strong>Minhashing</strong> : æŠŠå¤§çš„é›†åˆè½¬æ¢æˆçŸ­çš„æ ‡å¿—(signature)å¹¶ä¸”ä¿æŒç€ç›¸ä¼¼æ€§ã€‚</li><li><strong>Locality-sensitive hashing</strong> : ä¸“æ³¨äºå¯èƒ½ç›¸ä¼¼çš„æ ‡å¿—å¯¹å„¿(pairs of signature)ã€‚</li></ol><p><strong>å›¾è§£</strong></p><p><img src="/images/1451286062856.png"></p><h2><span id="shingles">Shingles</span></h2><blockquote><p><strong>k-shingle</strong> æˆ– <strong>k-gram</strong> æ˜¯æŒ‡æ–‡æ¡£ä¸­è¿ç»­å‡ºç°çš„ <strong>k</strong> ä¸ªå­—ç¬¦æ„æˆçš„åºåˆ—ã€‚</p></blockquote><p>ä¸¾ä¾‹è¯´æ˜ï¼š ç»™å®š <code>k=2 , doc = abcab</code> ã€‚ æ¯ä¸¤ä¸ªå­—ç¬¦æ„æˆä¸€ä¸ªshingle, å³ï¼š <code>ab</code>, <code>bc</code>, <code>ca</code>, <code>ab</code>ï¼Œæ‰€ä»¥2-Shinglesçš„é›†åˆå°±ä¸ºï¼š<code>{ab, bc, ca}</code></p><p>è¿™æ ·å°±å¯ä»¥ç”¨ä¸€ä¸ª<code>k-shingles</code>çš„é›†åˆè¡¨ç¤ºä¸€ä¸ªæ–‡æ¡£ï¼</p><h3><span id="shingles-å’Œç›¸ä¼¼åº¦çš„å…³ç³»">Shingles å’Œç›¸ä¼¼åº¦çš„å…³ç³»</span></h3><p>å¦‚æœæˆ‘ä»¬å‘æƒ³ä¸¤ä¸ªæ–‡æ¡£ä¸­æœ‰å¤§é‡çš„shinglesç›¸åŒï¼Œé‚£ä¹ˆè¿™ä¸¤ä¸ªæ–‡æ¡£å°±æ˜¯ç›¸ä¼¼çš„è€Œä¸”å¾ˆç›´è§‚ã€‚</p><p>å¦‚æœæ”¹å˜æ–‡æ¡£ä¸­çš„ä¸€ä¸ªå•è¯ï¼Œåªä¼šå½±å“è¿™ä¸ªå•è¯å‰å<code>k</code>ä¸ªå­—ç¬¦çš„<code>k-shingles</code>ã€‚</p><p>å¦‚æœé‡æ–°æŠŠæ–‡æ¡£ä¸­çš„æ®µè½æ’åºï¼Œåªä¼šå½±å“æ®µè½è¾¹ç•Œå‘¨å›´çš„<code>2k</code>ä¸ª<code>k-shingles</code>ã€‚</p><p><em>ä¸¾ä¾‹è¯´æ˜</em> <code>k = 3</code>ï¼Œ &quot;The dog which chased the cat&quot; <strong>vs</strong> &quot;The dog that chased the cat&quot;</p><p>ç¬¬äºŒå¥æŠŠç¬¬ä¸€å¥çš„<code>which</code>æ”¹æˆäº†<code>that</code>ï¼Œå¤„ç†ä¹‹åä¹‹åªæœ‰7ä¸ª<code>3-shingles</code> è¢«æ›¿æ¢äº†ï¼Œåˆ†åˆ«æ˜¯ï¼š<code>'g w'</code>, <code>' wh'</code>, <code>'whi'</code> , <code>'hic'</code>, <code>'ich'</code>, <code>'ch '</code>å’Œ <code>'h c'</code>ã€‚</p><h3><span id="å‹ç¼©">å‹ç¼©</span></h3><p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¦‚æœkå–çš„æ¯”è¾ƒå¤§çš„è¯ï¼ˆæ¯”å¦‚æ¯”è¾ƒè®ºæ–‡é€šå¸¸å–k=9ï¼‰ï¼Œshinglesä¼šå¾ˆé•¿ï¼Œå°±æ¯”è¾ƒæµªè´¹ç©ºé—´äº†ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠshinglesé€šè¿‡hashæ“ä½œå˜æˆä¸€ä¸ªæ•´æ•°ï¼ˆ4ä¸ªå­—èŠ‚ï¼‰ï¼Œæˆ‘ä»¬ç®¡è¿™ä¸ªæ•´æ•°å« <code>tokens</code>ã€‚ä¹‹åå°±å¯ä»¥ç”¨ä¸€ç»„<code>token</code>æ¥è¡¨ç¤ºä¸€ä¸ªæ–‡æ¡£äº†ã€‚</p><p>Two documents could (rarely) appear to have shingles in common, when in fact only the hash values were shared.</p><h2><span id="minhashing">Minhashing</span></h2><h3><span id="jaccard-similarity">Jaccard Similarity</span></h3><p>æ°å¡å¾·ç›¸ä¼¼ç³»æ•°</p><p>ä¸¤ä¸ªé›†åˆçš„Jaccard Similarityå®šä¹‰ï¼šäº¤é›†é™¤ä»¥å¹¶é›†ã€‚</p><blockquote><p><span class="math inline">\(Sim(C_1, C_2) =\frac{ |C_1 \cap C_2|} {|C_1 \cup C_2|}\)</span></p></blockquote><p><img src="/images/1451358527521.png"></p><p>æ¯”å¦‚ä¸Šå›¾ï¼Œä¸¤ä¸ªé›†åˆçš„äº¤é›†ä¸º <span class="math inline">\(3\)</span>ï¼Œå¹¶é›†ä¸º <span class="math inline">\(8\)</span>, æ‰€ä»¥ç›¸ä¼¼ç³»æ•°ä¸ºï¼š<span class="math inline">\(\frac{3}{8}\)</span></p><h3><span id="from-sets-to-boolean-matrices">From Sets to Boolean Matrices</span></h3><p>æŠŠé›†åˆè½¬æ¢æˆå¸ƒå°”çŸ©é˜µ</p><p>ä¸ºäº†æ–¹ä¾¿è®¡ç®—Jaccard Similarityï¼Œæˆ‘ä»¬éœ€è¦æŠŠé›†åˆè½¬æ¢æˆçŸ©é˜µã€‚</p><ul><li><p>çŸ©é˜µçš„è¡Œè¡¨ç¤ºé›†åˆä¸­çš„å„ä¸ªå…ƒç´ ï¼Œæ¯”å¦‚æ¯ä¸ª<code>k-shingles</code></p></li><li><p>çŸ©é˜µçš„åˆ—è¡¨ç¤ºå„ä¸ªé›†åˆï¼Œæ¯”å¦‚æ¯ä¸ªæ–‡æ¡£çš„<code>k-shingles</code>é›†åˆ</p></li><li><p>å¦‚æœè¡Œ <span class="math inline">\(e\)</span> æ˜¯åˆ— <span class="math inline">\(S\)</span> çš„ä¸€ä¸ªæˆå‘˜ï¼Œé‚£ä¹ˆåœ¨<span class="math inline">\(e\)</span>è¡Œ<span class="math inline">\(S\)</span>åˆ—çš„å€¼ä¸º<span class="math inline">\(1\)</span>ï¼Œå¦åˆ™ä¸º<span class="math inline">\(0\)</span></p></li><li><p>ä¸¤åˆ—ä¹‹é—´çš„ç›¸ä¼¼åº¦å°±æ˜¯Jaccard ç›¸ä¼¼åº¦ã€‚</p></li><li><p>é€šå¸¸æƒ…å†µä¸‹ï¼Œè¿™ä¼šæ˜¯ä¸€ä¸ªç¨€ç–çŸ©é˜µã€‚</p></li></ul><p><strong>ä¸¾ä¸ªä¾‹å­</strong> <img src="/images/1451359226406.png"></p><p>å›¾ä¸­çŸ©é˜µåªæœ‰ä¸¤åˆ—<span class="math inline">\(C_1\)</span>å’Œ<span class="math inline">\(C_2\)</span>ï¼Œä»–ä»¬çš„ç›¸ä¼¼åº¦å°±ç­‰äºéƒ½ä¸º<span class="math inline">\(1\)</span>çš„è¡Œé™¤ä»¥è‡³å°‘æœ‰ä¸€ä¸ªä¸º<span class="math inline">\(1\)</span>çš„è¡Œï¼Œå³ï¼š &gt; <span class="math inline">\(Sim(C_1, C_2) = 2/5 = 0.4\)</span></p><h3><span id="four-types-of-rows">Four Types of Rows</span></h3><p>ç»™å®šä¸¤åˆ—<span class="math inline">\(C_1\)</span>å’Œ<span class="math inline">\(C_2\)</span>ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸‹å››ç§ç±»å‹çš„è¡Œï¼š <img src="/images/1451359444350.png"></p><p>ç°åœ¨å¯ä»¥è¿™ä¹ˆè®¡ç®—Jaccardç›¸ä¼¼åº¦äº†ï¼š<span class="math inline">\(Sim(C_1, C_2) = \frac{a}{a + b + c}\)</span></p><h3><span id="minhashing">Minhashing</span></h3><p>å‡è®¾è¡Œæ˜¯éšæœºæ’åˆ—çš„ï¼Œå®šä¹‰ <span class="math inline">\(minhash\)</span> <span class="math inline">\(function\)</span> <span class="math inline">\(h(C)\)</span> = the number of the first (in the permuted order) row in which column C has 1 å¦‚æœæ²¡çœ‹æ‡‚åé¢æœ‰ä¾‹å­ã€‚</p><p>é€šå¸¸ç”¨ä¸€äº›ï¼ˆæ¯”å¦‚100ï¼‰ç‹¬ç«‹çš„hash functionæ¥ä¸ºæ¯åˆ—åˆ›å»º<span class="math inline">\(Signature\)</span>ã€‚</p><p>è¿™äº›signatureså­˜å‚¨åœ¨ä¸€ä¸ª<span class="math inline">\(signature\)</span> <span class="math inline">\(matrix\)</span>â€“ whose columns represent the sets and the rows represent the minhash values, in order for that column.</p><p><strong>ä¾‹å­</strong></p><p>è¾“å…¥çŸ©é˜µï¼š <img src="/images/1451362719714.png"></p><p>ä¸Šå›¾å³ä¾§ä¸ºè¾“å…¥çŸ©é˜µï¼Œå·¦ä¾§ä¸º3ç»„éšæœºæ’åˆ—ã€‚</p><p>å…ˆçœ‹ç¬¬ä¸€ç»„ï¼ˆç´«è‰²çš„ï¼‰ * æ’åˆ—çš„ç¬¬ä¸€è¡Œæ˜¯çŸ©é˜µçš„ç¬¬äº”è¡Œï¼Œè¯¥è¡Œç¬¬äºŒåˆ—å’Œç¬¬å››åˆ—ä¸º<span class="math inline">\(1\)</span>, å…¶ä½™ä¸º<span class="math inline">\(0\)</span>, æ‰€ä»¥è¯¥ç»„çš„minhash valueä¸º<code>0 1 0 1</code>; * æ’åˆ—çš„ç¬¬äºŒè¡Œæ˜¯çŸ©é˜µçš„ç¬¬å…­è¡Œï¼Œè¯¥è¡Œç¬¬ä¸€åˆ—å’Œç¬¬ä¸‰è¡Œä¸º<span class="math inline">\(1\)</span>,å…¶ä½™ä¸º<span class="math inline">\(0\)</span>ï¼Œæ‰€ä»¥minhash valueçš„ç¬¬äºŒã€å››è¡Œä¸å˜ï¼Œç¬¬ä¸€ã€ä¸‰è¡Œæ”¹ä¸ºå½“å‰è¡Œå·ï¼Œå³ï¼š<code>2 1 2 1</code>; * ç”±äºæ¯åˆ—éƒ½éé›¶ï¼Œè¿™ç»„å°±ç»“æŸäº†ï¼Œæœ€åçš„minhash valueå°±æ˜¯<code>2 1 2 1</code>ã€‚</p><p>åœ¨çœ‹ç¬¬äºŒç»„ï¼ˆé»„è‰²çš„ï¼‰ * æ’åˆ—çš„ç¬¬ä¸€è¡Œæ˜¯çŸ©é˜µçš„ç¬¬ä¸‰è¡Œï¼Œè¯¥è¡Œçš„ç¬¬äºŒåˆ—å’Œç¬¬å››åˆ—ä¸º<span class="math inline">\(1\)</span>ï¼Œå…¶ä½™åˆ—ä¸º<span class="math inline">\(0\)</span>ï¼Œæ‰€ä»¥minhash valueçš„ç¬¬äºŒã€å››åˆ—å˜ä¸ºå½“å‰è¡Œå·ï¼Œç¬¬ä¸€ã€ä¸‰åˆ—ä¸å˜ï¼Œå³ï¼š<code>0 1 0 1</code> * æ’åˆ—çš„ç¬¬äºŒè¡Œæ˜¯çŸ©é˜µçš„ç¬¬äºŒè¡Œï¼Œè¯¥è¡Œç¬¬ä¸€ã€å››åˆ—ä¸º<span class="math inline">\(1\)</span>ï¼Œå…¶ä½™ä¸º<span class="math inline">\(0\)</span>ï¼Œç”±äºminhash valueçš„ç¬¬å››åˆ—å€¼ä¸ä¸º0ï¼Œæ‰€ä»¥ç¬¬å››åˆ—å€¼ä¸å˜ï¼Œç¬¬ä¸€åˆ—å€¼å˜ä¸ºå½“å‰è¡Œå¥½ï¼Œå³ï¼š<code>2 1 0 1</code> * æ’åˆ—çš„ç¬¬ä¸‰è¡Œæ˜¯çŸ©é˜µçš„å››è¡Œï¼Œè¯¥è¡Œç¬¬ä¸€ã€å››åˆ—å€¼ä¸º<span class="math inline">\(1\)</span>ï¼Œè€Œminhash valueé‡Œçš„ä¸€ã€å››åˆ—å·²ä¸ä¸º0,æ‰€ä»¥æ²¡æœ‰å˜åŒ–ï¼Œå³è¿˜æ˜¯ï¼š<code>2 1 0 1</code> * æ’åˆ—çš„ç¬¬å››è¡Œæ˜¯çŸ©é˜µçš„ç¬¬ä¸€è¡Œï¼Œè¯¥è¡Œç¬¬ä¸€ã€ä¸‰åˆ—å€¼ä¸º<span class="math inline">\(1\)</span>ï¼Œæ‰€ä»¥minhash valueçš„ç¬¬ä¸‰åˆ—å˜ä¸ºå½“å‰è¡Œå·ï¼Œå…¶ä½™ä¸å˜ï¼Œå³ï¼š<code>2 1 4 1</code></p><p>ç¬¬ä¸‰ç»„ç•™ç»™è¯»è€…è‡ªå·±ç»ƒä¹ ï¼Œæ€»ä½“çš„æ ‡å¿—çŸ©é˜µ(Signature matrix)å°±æ˜¯ï¼š <img src="/images/1451363798021.png"></p><h3><span id="æ€§è´¨">æ€§è´¨</span></h3><p>æ‰€æœ‰æ’åˆ—çš„<span class="math inline">\(h(C_1) = h(C_2)\)</span>çš„æ¦‚ç‡ç­‰äºè¿™ä¸¤åˆ—çš„Jaccardç›¸ä¼¼åº¦ï¼š &gt; <span class="math inline">\(P(h(C_1) = h(C_2)) = Sim(C_1, C_2)\)</span></p><p>éƒ½ç­‰äº<span class="math inline">\(\frac{a}{a+b+c}\)</span>ï¼</p><p><strong>Why?</strong></p><p><span class="math inline">\(h(C_1) = h(C_2)\)</span>åªæœ‰åœ¨aç±»å‹çš„è¡Œä¸­å‡ºç°ï¼Œæ‰€ä»¥<span class="math inline">\(h(C_1) = h(C_2)\)</span>è¿™ä¸ªäº‹ä»¶å°±ç›¸å½“äºaç±»å‹çš„è¡Œå‡ºç°ï¼Œé‚£ä¹ˆ<span class="math inline">\(h(C_1) = h(C_2)\)</span>çš„æ¦‚ç‡å°±æ˜¯aç±»å‹çš„è¡Œå‡ºç°çš„æ¦‚ç‡ï¼Œå³<span class="math inline">\(\frac{a}{a+b+c}\)</span>ã€‚</p><p><strong>æ ‡å¿—çš„ç›¸ä¼¼åº¦</strong></p><ul><li>The <strong>similarity of signatures</strong> is the fraction of the minhash functions in which they agree.<ul><li>Thinking of signatures as columns of integers, the similarity of signatures is the fraction of rows in which they agree.</li></ul></li><li>Thus, the expected similarity of two signatures equals the Jaccard similarity of the columns or sets that the signatures represent.<ul><li>And the longer the signatures, the smaller will be the expected error.</li></ul></li></ul><p><strong>Minhashçš„ä¾‹å­</strong> è¾“å…¥çŸ©é˜µå’Œä¸Šé¢é‚£ä¸ªä¾‹å­ç›¸åŒï¼š <img src="./1451362719714.png" alt="Input Matrix"></p><p>å¾—åˆ°æ ‡å¿—çŸ©é˜µï¼š <img src="/images/1451363798021.png"></p><p>æˆ‘ä»¬æ¥è®¡ç®—ä¸€ä¸‹å®é™…çš„Jaccardç›¸ä¼¼åº¦ä¸Signatureçš„ç›¸ä¼¼åº¦ã€‚</p><p>å…ˆçœ‹ç¬¬ä¸€åˆ—å’Œç¬¬äºŒåˆ—ï¼Œåœ¨è¾“å…¥çŸ©é˜µä¸­æ²¡æœ‰<span class="math inline">\(a\)</span>ç±»å‹çš„è¡Œï¼Œæ‰€ä»¥Jaccardç›¸ä¼¼åº¦ä¸ºé›¶; åœ¨æ ‡å¿—çŸ©é˜µMä¸­ç¬¬ä¸€ã€äºŒåˆ—ä¹Ÿæ²¡æœ‰ç›¸åŒçš„ä¸€è¡Œï¼ŒSignatureç›¸ä¼¼åº¦ä¹Ÿä¸ºé›¶ã€‚</p><p>å†çœ‹ç¬¬ä¸€ã€ä¸‰åˆ—ï¼Œè¾“å…¥çŸ©é˜µä¸­åªæœ‰ä¸€è¡Œé<span class="math inline">\(a\)</span>ç±»å‹ï¼Œæ‰€ä»¥Jaccardç›¸ä¼¼åº¦ä¸º<span class="math inline">\(0.75\)</span>; è€Œæ ‡å¿—çŸ©é˜µä¸­æœ‰ä¸¤è¡Œå€¼ç›¸åŒï¼Œä¸€è¡Œå€¼ä¸åŒï¼Œæ‰€ä»¥Signatureç›¸ä¼¼åº¦ä¸º<span class="math inline">\(0.67\)</span></p><p>åŒç†ç¬¬2ã€4åˆ—çš„Jaccardç›¸ä¼¼åº¦ä¸º<span class="math inline">\(0.75\)</span>ï¼ŒSignatureç›¸ä¼¼åº¦ä¸º<span class="math inline">\(1.00\)</span></p><p>æ•´ç†ä¸€ä¸‹ï¼š | Similarity | 1-3 | 2-4 | 1-2| | :--- | :--- | :--- | :-- | |Jaccard | 0.75 | 0.75 | 0 | |Signature | 0.67 | 1.00 | 0 |</p><p>å¯è§ç”±äºæ’åˆ—çš„ç»„æ•°è¾ƒå°‘è¿˜æ˜¯æœ‰ä¸€å®šè¯¯å·®çš„ã€‚</p><h3><span id="minhashing-çš„å®ç°">Minhashing çš„å®ç°</span></h3><p>å›°éš¾ï¼š * å‡è®¾æ•°æ®é‡éå¸¸å¤§ï¼Œæ¯”å¦‚åäº¿è¡Œ; * æŠŠåäº¿è¡Œåšéšæœºæ’åˆ—æ˜¯ä¸ç°å®çš„ï¼Œä¹Ÿæ²¡æœ‰å¿…è¦ã€‚ * ä¸è¿‡å°±ç®—æ˜¯ç”¨ä¹‹å‰çš„éšæœºæ’åˆ—åºåˆ—ï¼Œè¦* 100ä¸ªéšæœºæ’åˆ—åºåˆ—ï¼Œæ¯ä¸ªåºåˆ—æœ‰åäº¿ä¸ªé¡¹ï¼Œå…‰å­˜å‚¨è¿™äº›åºåˆ—å°±è¦å¤§çº¦40TBã€‚ * éšæœºè¯»å–å¯èƒ½ä¼šå¯¼è‡´ç³»ç»ŸæŠ–åŠ¨ã€‚</p><p>ä¸€ä¸ªå¥½çš„è¯»å–rowså®è·µæ˜¯å‡†å¤‡å¾ˆå¤šï¼ˆæ¯”å¦‚100ä¸ªï¼‰hash functionï¼Œé¿å…ç”Ÿäº§åºåˆ—ã€‚</p><p>å¯¹äºæ¯ä¸€åˆ— <span class="math inline">\(c\)</span> å’Œæ¯ä¸ªhash function <span class="math inline">\(h_j\)</span>ï¼Œ åªå­˜å‚¨ä¸€ä¸ªå€¼<span class="math inline">\(M(i, c)\)</span>ã€‚</p><p>ç›®æ ‡æ˜¯è®© <span class="math inline">\(M(i, c)\)</span> æˆä¸ºæ¯ä¸ª <span class="math inline">\(h_i(r)\)</span> çš„æœ€å°å€¼ï¼Œ <span class="math inline">\(h_i(r)\)</span>ç­‰äº<span class="math inline">\(r\)</span> where column c has 1 in row r * h i (r) gives order of rows for i th permutation</p><p><strong>å…·ä½“ç®—æ³•</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for each row r do begin</span><br><span class="line">for each hash function h_i do</span><br><span class="line">compute h_i(r);</span><br><span class="line">for each column c</span><br><span class="line">if c has 1 in row r</span><br><span class="line">for each hash function h_i do</span><br><span class="line">if h_i(r) is samller than M(i, c) then</span><br><span class="line">M(i, c) = h_i(r)</span><br><span class="line">end;</span><br></pre></td></tr></table></figure><p>ä¸¾ä¾‹ï¼š <img src="/images/1451367036074.png"></p><p>è¾“å…¥çŸ©é˜µå¦‚å›¾æ‰€ç¤ºï¼Œå–ä¸¤ä¸ªhash function : <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h(x) = x mod 5</span><br><span class="line">g(x) = (2x + 1) mod 5</span><br></pre></td></tr></table></figure></p><p>å…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼š <img src="/images/1451367200601.png"></p><p>æœ€åçš„ç»“æœçš„ç›¸ä¼¼åº¦çš„ <span class="math inline">\(0\)</span>, å®é™…çš„Jaccardç›¸ä¼¼åº¦æ˜¯<span class="math inline">\(\frac{1}{5}\)</span> ## Locality-Sensitive Hashing å±€éƒ¨æ•æ„Ÿå“ˆå¸Œ</p><h3><span id="lsh">LSH</span></h3><p>åŸºæœ¬æ€æƒ³ï¼šGenerate from the collection of all elements (signatures in our example) a small list of <strong>candidate pairs</strong>: pairs of elements whose similarity must be evaluated.</p><p>ç®€å•æ¥è¯´å°±æ˜¯ä»æˆ‘ä»¬Minhashingå¾—åˆ°çš„æ ‡è®°çŸ©é˜µç”Ÿæˆå¯èƒ½ç›¸ä¼¼çš„æ–‡æ¡£å¯¹åˆ—è¡¨ã€‚</p><p>å€™é€‰ç›¸ä¼¼æ–‡æ¡£å¯¹ =&gt; è¿™ä¸€å¯¹çš„Jaccardç›¸ä¼¼åº¦å¿…é¡»è¢«å‡†ç¡®è®¡ç®—å‡ºæ¥</p><p><strong>æ–¹æ³•</strong></p><ul><li>é€‰ä¸€ä¸ªç›¸ä¼¼åº¦æ ‡å‡† <span class="math inline">\(t\)</span>ï¼Œå¹¶ä¸” <span class="math inline">\(t &lt; 1\)</span>ï¼Œå¦‚æœä¸¤ä¸ªæ–‡æ¡£çš„ç›¸ä¼¼åº¦å¤§äº <span class="math inline">\(t\)</span>ï¼Œåˆ™è®¤ä¸ºè¿™ä¸¤ä¸ªæ–‡æ¡£ç›¸ä¼¼ã€‚</li><li>å¦‚æœåˆ—<span class="math inline">\(c\)</span>å’Œåˆ—<span class="math inline">\(d\)</span>è¢«è§†ä¸ºå€™é€‰æ–‡æ¡£å¯¹ï¼Œé‚£ä¹ˆä»–ä»¬ä¸€å®šè¦æ»¡è¶³ <span class="math inline">\(M(i, c) = M(i, d) &gt;= t\)</span> ï¼Œå…¶ä¸­<span class="math inline">\(M\)</span>æ˜¯æ ‡è®°çŸ©é˜µã€‚</li></ul><h4><span id="lsh-for-minhashing-signatures">LSH for Minhashing Signatures</span></h4><p><strong>æ€»ä½“æ€æƒ³</strong>ï¼šæŠŠæ ‡è®°çŸ©é˜µé‡Œçš„hashå¾ˆå¤šéï¼Œåªæœ‰hashåˆ°åŒä¸€ä¸ªæ¡¶(bucket)é‡Œçš„åˆ—æ‰è¢«è®¤ä¸ºæ˜¯å¯èƒ½ç›¸ä¼¼çš„ã€‚</p><p><strong>Partion Into Bands</strong></p><p><img src="/images/1451568313351.png"></p><p>å¦‚å›¾æ‰€ç¤ºï¼ŒæŠŠæ ‡è®°çŸ©é˜µçš„æ‰€æœ‰è¡Œåˆ†æˆ <span class="math inline">\(b\)</span> ä¸ª<em>å¸¦(bands)</em>ï¼Œæ¯ä¸ªå¸¦æœ‰ <span class="math inline">\(r\)</span> è¡Œã€‚å¯¹äºæ¯æ¡å¸¦ï¼Œå¯¹å¸¦é‡Œé¢æ¯åˆ—è¿›è¡Œhashï¼Œåˆ†åˆ«hashåˆ°kä¸ªæ¡¶ä¸­ï¼Œå¹¶è®©kå°½å¯èƒ½å¾—å¤§ã€‚</p><p>åªæœ‰æœ‰&gt;=1çš„bandå“ˆå¸Œåˆ°åŒä¸€ä¸ªæ¡¶ä¸­ï¼Œå°±æŠŠè¿™ä¸¤åˆ—å½“ä½œå€™é€‰ç›¸ä¼¼å¯¹ã€‚</p><h3><span id="hash-function-for-one-bucket">Hash Function for One Bucket</span></h3><p><img src="/images/1451568830329.png"></p><p><strong>Example - Bands</strong></p><p>å‡è®¾æœ‰ 100,000 åˆ—ï¼Œæ¯åˆ—æœ‰100ä¸ªæ ‡è®°ï¼Œå› æ­¤å­˜å‚¨æ ‡è®°éœ€è¦40MB; æˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°æ‰€ä»¥ç›¸ä¼¼åº¦å¤§äº80%çš„æ–‡æ¡£å¯¹ï¼Œç”¨ä¸Šé¢çš„æ–¹æ³•ï¼ŒæŠŠæ ‡è®°åˆ†ä¸º20ä¸ªå¸¦ï¼Œæ¯ä¸ªå¸¦é‡Œæœ‰5ä¸ªæ ‡è®°ã€‚</p><p>è¿™æ ·çš„è¯ï¼Œå¦‚æœæ–‡æ¡£<span class="math inline">\(C_1\)</span>å’Œ<span class="math inline">\(C_2\)</span>çš„ç›¸ä¼¼åº¦æ˜¯<strong>80%</strong>ï¼Œé‚£ä¹ˆä»–ä»¬çš„ä»»æ„ä¸€ä¸ªå¸¦çš„5ä¸ªæ ‡è®°éƒ½ç›¸åŒçš„æ¦‚ç‡æ˜¯: <span class="math inline">\((0.8)^5 = 0.328\)</span> ï¼Œçœ‹èµ·æ¥å¥½åƒä¸å¤§ï¼Œä½†æ˜¯åªè¦æœ‰ä»»æ„ä¸€ä¸ªå¸¦éƒ½ç›¸åŒå°±è¢«è®¤ä¸ºæ˜¯å€™é€‰å¯¹ï¼Œæ‰€ä»¥ä»–ä»¬ä¸è¢«é€‰ä¸Šçš„æ¦‚ç‡ï¼Œå³20ä¸ªå¸¦éƒ½ä¸ç›¸åŒçš„æ¦‚ç‡ä¸ºï¼š<span class="math inline">\((1-0.328)^{20} = 0.00035\)</span>ï¼Œä¹Ÿå°±æ˜¯<strong>æ¯3000ä¸ªç›¸ä¼¼åº¦ä¸º80%çš„æ–‡æ¡£å¯¹é‡Œæ‰ä¼šæœ‰ä¸€å¯¹æ¼é€‰</strong>ã€‚</p><p>æˆ‘ä»¬å†è€ƒè™‘æ–‡æ¡£<span class="math inline">\(C_1\)</span>å’Œ<span class="math inline">\(C_2\)</span>åªæœ‰<strong>40%</strong>çš„ç›¸ä¼¼åº¦ï¼Œé‚£ä¹ˆä»–ä»¬ä»»æ„ä¸€ä¸ªå¸¦çš„5ä¸ªæ ‡è®°éƒ½ç›¸åŒçš„æ¦‚ç‡ä¸º <span class="math inline">\((0.4)^5 = 0.01\)</span>ï¼Œåˆ™æ–‡æ¡£<span class="math inline">\(C_1\)</span>å’Œ<span class="math inline">\(C_2\)</span>è¢«é€‰ä¸ºå€™é€‰å¯¹çš„æ¦‚ç‡ï¼Œå³ä»–ä»¬ä¸­æœ‰ä¸€ä¸ªå¸¦å®Œå…¨ç›¸åŒçš„æ¦‚ç‡ä¸º: $C_{20}^1 Ã— 0.01 = 0.2 $ï¼Œå°±æ˜¯è¯´æ¯5ä¸ª40%ç›¸ä¼¼åº¦çš„æ–‡æ¡£å¯¹é‡Œå°±æœ‰ä¸€å¯¹ä¼šè¢«è¯¯é€‰ä¸ºå€™é€‰å¯¹ã€‚<strong>ä½†æ˜¯</strong>ç›¸ä¼¼åº¦å°äº40%çš„æ–‡æ¡£å¯¹é‡Œè¯¯é€‰çš„æ¦‚ç‡å°±éå¸¸å°äº†ã€‚</p><h3><span id="analysis-of-lsh">Analysis of LSH</span></h3><figure><img src="./1451629865035.png" alt="What We Want"><figcaption>What We Want</figcaption></figure><p>æˆ‘ä»¬å¸Œæœ›LSHè¾¾åˆ°çš„æ•ˆæœæ˜¯ç›¸ä¼¼åº¦åœ¨æˆ‘ä»¬è®¾å®šçš„é˜ˆå€¼ä¹‹ä¸‹çš„æ–‡æ¡£å¯¹éƒ½ä¸è¢«é€‰è¿›å€™é€‰æ–‡æ¡£å¯¹ï¼Œè€Œåœ¨å…¶ä¹‹ä¸Šçš„æ–‡æ¡£å¯¹éƒ½é€‰è¿›æ¥ï¼Œ<strong>ä¸è¯¯é€‰ä¸€ä¸ªä¹Ÿä¸é”™é€‰ä¸€ä¸ª</strong>ï¼Œè¿™æ˜¯æœ€ç†æƒ³çš„æƒ…å†µï¼Œæˆ‘ä»¬çš„ç›®æ ‡å°±æ˜¯å‘å®ƒé æ‹¢ã€‚</p><p>å¦‚æœä¸ä½¿ç”¨åˆ†å¸¦çš„æ–¹æ³•ï¼Œç›´æ¥ä¸€è¡Œä¸€è¡Œçš„çœ‹ï¼Œä¼šå‡ºç°ä¸‹å›¾æ‰€ç¤ºçš„é—®é¢˜ï¼š <img src="/images/1451630150113.png"></p><p>è¿™ä¸ªå›¾çºµå‘æ˜¯æ ‡è®°å®Œå…¨ç›¸åŒçš„æ¦‚ç‡ï¼Œæ¨ªå‘æ˜¯ç›¸ä¼¼åº¦ï¼Œç”±äºç›¸ä¼¼åº¦ç­‰äºæ ‡è®°(minhash value)ç›¸åŒçš„æ¦‚ç‡ï¼Œæ‰€ä»¥å®é™…æ›²çº¿å°±æ˜¯è¿™ä¸ªçŸ©å½¢çš„å¯¹è§’çº¿ï¼Œä¸ç†æƒ³çŠ¶å†µçš„æ›²çº¿ç›¸å·®ç”šè¿œï¼Œå¯è§è¯¯å·®æ˜¯éå¸¸å¤§çš„ã€‚</p><p>å¦‚æœæŠŠæ‰€æœ‰è¡Œåˆ†æˆbå¸¦ï¼Œæ¯ä¸ªå¸¦æœ‰rè¡Œï¼Œé‚£ä¹ˆæ›²çº¿å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š <img src="/images/1451631757641.png"></p><p>å¯ä»¥å¾—åˆ°åœ¨é˜ˆå€¼ <span class="math inline">\(t\)</span> çº¦ç­‰äº <span class="math inline">\((\frac{1}{b})^{\frac{1}{r}}\)</span> æ—¶ï¼Œæ›²çº¿ä¸ç†æƒ³çŠ¶æ€é¢‡ä¸ºæ¥è¿‘ï¼Œè¯¯å·®éå¸¸å°ã€‚</p><p>æ•°å€¼ä¸¾ä¾‹ï¼š<span class="math inline">\(b = 20, r = 5\)</span> <img src="/images/1451631969408.png"></p><p>å¯è§æ–‡æ¡£ç›¸ä¼¼åº¦åœ¨70%ä»¥ä¸Šæ˜¯å¾ˆå®¹æ˜“è¢«é€‰è¿›çš„ï¼Œåœ¨40%ä¸€ä¸‹æ˜¯å¾ˆéš¾é€‰è¿›çš„ï¼Œå¦‚æœé˜ˆå€¼å®šåœ¨70%çš„è¯ä¸”æ–‡æ¡£ç›¸ä¼¼åº¦åˆ†å¸ƒæ¯”è¾ƒå‡åŒ€çš„å’Œè¯¯å·®ä¼šå¾ˆå°ã€‚</p><h3><span id="lsh-summary">LSH Summary</span></h3><p>Tune to <strong>get</strong> almost all pairs with similar signatures, but <strong>eliminate</strong> most pairs that do not have similar signatures.</p><p><strong>Check</strong> that candidate pairs really do have similar signatures.</p><p><em>Optional</em>: In another pass through data, check that the remaining candidate pairs really represent similar <em>sets</em> . ## Applications of LSH</p><h3><span id="å®ä½“è§£æ-entity-resolution">å®ä½“è§£æ Entity Resolution</span></h3><blockquote><p><strong>å®ä½“è§£æ(Entity Resolution)</strong>æ˜¯é€šè¿‡æ£€æµ‹è®°å½•æ¥åˆ¤æ–­è¿™äº›è®°å½•æ˜¯å¦æ¥è‡ªåŒä¸€ä¸ªå®ä½“ã€‚å®ä½“å¯ä»¥æ˜¯äººã€å…¬å¸ã€äº‹ä»¶ç­‰ç­‰ã€‚</p></blockquote><p><strong>Typically</strong>, we want to merge records if their values in corresponding fields are similar.</p><p><strong>Matching Customer Records</strong></p><p>è¿™é—¨è¯¾çš„è€å¸ˆæ›¾ç»åº”ç”¨LSHè§£å†³è¿‡ä¸€ä¸ªå®é™…é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜å¤§æ¦‚æ˜¯è¿™æ ·ï¼šæœ‰ä¸¤ä¸ªå…¬å¸Aå’ŒBï¼Œå…¬å¸Aç­”åº”æŠŠä¸€éƒ¨åˆ†é¡¾å®¢æ‹‰æ‹¢åˆ°å…¬å¸Bï¼Œç„¶åBç»™Aä¸€å®šçš„è´¹ç”¨ï¼Œä¸€å¼€å§‹æŒºå¥½ï¼Œå¯æ˜¯å¥½æ™¯ä¸é•¿ï¼Œä»–ä»¬å°±å¼€å§‹äº‰è®ºåˆ°åº•æœ‰å¤šå°‘é¡¾å®¢æ˜¯ä»Aå…¬å¸è¿‡å»çš„ï¼Œä¸ºæ­¤åµå¾—ä¸å¯å¼€äº¤ã€‚</p><p><strong>ä»»åŠ¡</strong>å°±æ˜¯é€šè¿‡ä¸¤ä¸ªå…¬å¸çš„æ•°æ®åº“åˆ¤æ–­æœ‰å¤šå°‘é¡¾å®¢æ˜¯ä»Aå…¬å¸è¿‡å»çš„ã€‚</p><p>æ³¨ï¼šåŒä¸€ä¸ªé¡¾å®¢åœ¨ä¸¤ä¸ªå…¬å¸çš„æ•°æ®é‡Œå¯èƒ½ä¼šæœ‰ä¸€äº›åå·®ï¼Œæ¯”å¦‚ç”µè¯å·ç å˜äº†æˆ–è€…åœ°å€å˜äº†æˆ–è€…ä¸€ä¸ªç”¨çš„æ˜¯å°åå¦ä¸€ä¸ªç”¨çš„æ˜¯å…¨åç­‰ç­‰ã€‚</p><p><strong>ç°çŠ¶</strong> æ¯ä¸ªå…¬å¸å¤§æ¦‚æœ‰1ç™¾ä¸‡æ¡è®°å½•æè¿°çš„é¡¾å®¢å¯èƒ½æ˜¯è¢«Aå…¬å¸é€åˆ°Bå…¬å¸çš„ã€‚æ¯æ¡è®°å½•åŒ…æ‹¬åå­—ã€ä½å€å’Œç”µè¯ï¼Œä½†æ˜¯å¤„äºç§ç§åŸå› ï¼Œå‡ºè‡ªåŒä¸€ä¸ªäººçš„è®°å½•ä¹Ÿå¯èƒ½ä¸å®Œå…¨ç›¸åŒ(åŸå› å¦‚ä¸Š)ã€‚</p><p><strong>æ–¹æ¡ˆ</strong> 1. å®šä¸€ä¸ªé‡åº¦ã€‚æ¯”å¦‚æ¯å¯¹è®°å½•æœ‰300åˆ†çš„ç›¸ä¼¼åº¦ï¼Œæ¯ä¸ªå±æ€§100åˆ†ã€‚ä¸¤æ¡è®°å½•å…·æœ‰ç›¸åŒçš„åœ°å€å’Œç”µè¯ä½†æ˜¯åå­—æ‹¼å†™æœ‰å°çš„å·®åˆ«ï¼Œè¿™ç§å°±ç»™290åˆ†ï¼Œå¦‚æœåå­—åŒºåˆ«å¾ˆå¤§å¯èƒ½å°±æ˜¯240åˆ†ç­‰ã€‚</p><ol start="2" type="1"><li>æŠŠç»è¿‡LSHç­›é€‰çš„æ‰€æœ‰å€™é€‰è®°å½•çš„åˆ†æ•°ç®—å‡ºæ¥ï¼Œåˆ†é«˜çš„å°±è®¤ä¸ºæ˜¯åŒä¸€ä¸ªäººã€‚</li></ol><p><strong>é—®é¢˜</strong></p><p>éœ€è¦è®¡ç®— <span class="math inline">\((1 Ã— 10^6)^2\)</span> å¯¹ä¸ªåˆ†æ•°å€¼ï¼Œå¤ªå¤§äº†ã€‚</p><p><strong>è§£å†³æ–¹æ³• : A Simple LSH</strong></p><p>å®šä¹‰3ä¸ªå“ˆå¸Œå‡½æ•°ï¼Œåˆ†åˆ« hash åå­—ã€åœ°å€å’Œç”µè¯ã€‚å¦‚æœä¸‰ä¸ªå±æ€§æœ‰ä¸€ä¸ªæ˜¯ç›¸åŒçš„å°±æŠŠå…·ä½“åˆ†æ•°ç®—å‡ºæ¥ã€‚</p><p>è¿™ç§æ–¹æ³•ä¹Ÿä¼šä¸¢å¤±ä¸€äº›æ¯ä¸ªå±æ€§çš„æœ‰ç‚¹å°åŒºåˆ«çš„è®°å½•å¯¹ï¼Œä¸è¿‡æ²¡å…³ç³»ï¼Œæ¦‚ç‡éå¸¸å°ã€‚</p><p><em>é¢å¤–</em> &gt; <em>How do we hash strings such as names so there is one bucket for each string?</em> <strong>Answer</strong> : Sort the strings instead.</p><h3><span id="æŒ‡çº¹åŒ¹é…-fingerprint-matching">æŒ‡çº¹åŒ¹é… Fingerprint Matching</span></h3><p><strong>æŒ‡çº¹çš„å­˜å‚¨æ–¹æ³•</strong> ç”¨ä¸€ç³»åˆ—<strong>ç»†èŠ‚ç‰¹å¾(minutiae)</strong>ä»£è¡¨ä¸€ä¸ªæŒ‡çº¹ã€‚ * These are features of a fingerprint, e.g., points where two ridges come together or a ridge ends.</p><p><strong>LSH for Fingerprints</strong></p><p>æŠŠç½‘æ ¼é“ºåœ¨æŒ‡çº¹ä¸Šï¼Œç›¸åŒçš„æŒ‡çº¹ä¼šé‡åˆã€‚å…·æœ‰ç»†èŠ‚ç‰¹å¾(minutiae)çš„æ–¹æ ¼çš„é›†åˆå°±å¯ä»¥è¡¨ç¤ºä¸€ä¸ªæŒ‡çº¹ã€‚å¦å¤–ï¼Œtreat minutiae near a grid boundary as if also present in adjacent grid points.</p><p><img src="/images/1451741534631.png"></p><p><strong>æŠŠLSHåº”ç”¨åˆ°æŒ‡çº¹åŒ¹é…</strong></p><ul><li>æŒ‡çº¹ = æ–¹æ ¼çš„é›†åˆ</li><li>ä¸éœ€è¦minhashï¼Œå› ä¸ºæ–¹æ ¼æ•°ä¸æ˜¯å¾ˆå¤šï¼Œè€Œä¸”ä¹Ÿä¸æ˜¯ç¨€ç–çŸ©é˜µ</li><li>ç”¨ä¸€ä¸ª<strong>ä½å‘é‡(bit-vector)</strong>è¡¨ç¤ºä¸€ä¸ªæŒ‡çº¹ï¼šå¦‚æœé‚£ä¸ªæ–¹æ ¼æœ‰minutiaeï¼Œåˆ™è¿™ä¸ªä½çš„å€¼æ˜¯1ã€‚è¿™ç§æ–¹æ³•ç›¸å¯¹äºç›´æ¥å­˜æ•´æ•°èŠ‚çœäº†å¾ˆå¤šç©ºé—´ã€‚</li><li>éšæœºä»ä½å‘é‡ä¸­å–3ä¸ªé›†åˆï¼Œæ¯ä¸ªé›†åˆæœ‰3ä¸ªæ–¹æ ¼ï¼ˆ3ä½ï¼‰ã€‚</li><li>å¯¹äºæ¯ä¸€ä¸ªé›†åˆï¼Œåªæœ‰ä¸‰ä½å…¨éƒ¨ä¸º1æ‰è¢«è®¤ä¸ºæ˜¯Candidate Pairs ã€‚</li><li>Funny sort of â€˜bucketization.â€</li></ul><p>æ‹¿ä¸€ä¸ªä¾‹å­è¯´æ˜ç®—æ³•çš„æ•ˆæœã€‚</p><p><strong>å‡è®¾</strong> ä¸€èˆ¬çš„åªæœ‰æœ‰20%çš„æ ¼å­æœ‰minutiaeï¼Œå¦‚æœä¸¤ä¸ªæŒ‡çº¹æ¥è‡ªåŒä¸€ä¸ªæ‰‹æŒ‡ï¼Œé‚£ä¹ˆä»–ä»¬åº”è¯¥æœ‰80%çš„æ–¹æ ¼æ˜¯ç›¸åŒçš„ã€‚</p><p><strong>è®¡ç®—</strong> ä»»æ„ä¸¤ä¸ªæŒ‡çº¹é›†åˆåœ¨ä¸‰ä¸ªæ ¼å­å†…éƒ½æœ‰minutiaeçš„æ¦‚ç‡ä¸º <span class="math inline">\((0.2)^6 = 0.000064\)</span></p><p>æ¥è‡ªåŒä¸€ä¸ªæ‰‹æŒ‡çš„ä¸¤ä¸ªæŒ‡çº¹é›†åˆåœ¨ä¸‰ä¸ªæ ¼å­å†…éƒ½æœ‰minutiaeçš„æ¦‚ç‡ä¸º <span class="math inline">\(((0.2)(0.8))^3 = 0.004096\)</span></p><p>åœ¨1024ä¸ªé›†åˆä¸­è‡³å°‘æœ‰ä¸€ä¸ªé›†åˆæ»¡è¶³ä¸Šè¿°è¦æ±‚çš„æ¦‚ç‡ä¸º <span class="math inline">\(1 - (1 - 0.004096)^{1024} = 0.985\)</span></p><p>ä¸æ˜¯æ¥è‡ªåŒä¸€ä¸ªæ‰‹æŒ‡ä½†æ˜¯è¢«é€‰ä¸Šçš„æ¦‚ç‡ä¸º <span class="math inline">\(1-(1-0.000064)^{1024} = 0.063\)</span>ï¼Œä¹Ÿå°±æ˜¯æœ‰6.3%çš„æ¦‚ç‡è¯¯é€‰ï¼Œå¹¶ä¸æ˜¯å¾ˆç†æƒ³ï¼Œä¸è¿‡æˆ‘ä»¬å¯ä»¥é€šè¿‡å¢åŠ é›†åˆé‡Œçš„æ–¹æ ¼æ•°ï¼Œæ¯”å¦‚å˜æˆ4æˆ–5ä¸ªï¼Œæ¥é™ä½è¯¯é€‰ç‡ã€‚</p><h3><span id="finding-duplicate-news-articles">Finding Duplicate News Articles</span></h3><p><strong>Problem</strong> : the same article, say from the Associated Press, appears on the Web site of many newspapers, but looks quite different.</p><p>ä¸æ‰¾ç›¸ä¼¼æ–‡æ¡£ä¸åŒçš„åœ°æ–¹åœ¨äºï¼š * æ¯ä»½æ–°é—»æœ‰è‡ªå·±çš„logoå’Œè¯­è¨€æè¿° * ä¸åŒçš„å¹¿å‘Š * å¯èƒ½è¿˜æœ‰åˆ°å…¶ä»–æ–‡ç« çš„é“¾æ¥ * ä¹Ÿå¯èƒ½å¯¹åŸå§‹æ–‡ç« è¿›è¡Œäº†åˆ å‡</p><p><strong>Special Shingling Technique</strong></p><p>é€šè¿‡è§‚å¯Ÿå¯ä»¥å‘ç°ï¼Œæ–°é—»æ­£æ–‡ä¸­ä¼šå‡ºç°å¾ˆå¤šåœç”¨è¯(stop words)ï¼Œç„¶è€Œå¹¿å‘Šä¸­å´æ²¡æœ‰ã€‚</p><p><a href="http://www.wikiwand.com/zh-hans/%E5%81%9C%E7%94%A8%E8%AF%8D" target="_blank" rel="noopener">åœç”¨è¯</a>å°±æ˜¯æ²¡ä»€ä¹ˆå®é™…å«ä¹‰çš„è¯ï¼Œæ¯”å¦‚ï¼š â€œ<strong>I</strong> recommend <strong>that you</strong> buy Sudzo <strong>for your</strong> laundry.â€ åœç”¨è¯å°±æ˜¯åŠ ç²—çš„é‚£äº›ã€‚å¦‚æœæ˜¯å¹¿å‘Šçš„è¯å¯èƒ½å°±åªæœ‰ â€œBuy Sudzoâ€ äº†ã€‚</p><p>è¿™ä¸ªç‰¹æ®Šçš„Shinglingå°±æ˜¯é€‰åœç”¨è¯ä»¥åŠå®ƒåé¢çš„ä¸¤ä¸ªè¯ä½œä¸ºShinglesï¼Œæ‹¿ä¸Šé¢é‚£å°±è¯ä¸¾ä¾‹ï¼Œshingleså°±æ˜¯ <code>I recommend that</code>ã€<code>that you buy</code>ã€<code>you buy Sudzo</code>ç­‰ç­‰ã€‚</p><p><strong>Why it Works</strong></p><ul><li>By requiring each shingle to have a stop word, they biased the mapping from documents to shingles so it picked more shingles from the article than from the ads.</li><li>Pages with the same article, but different ads, have higher Jaccard similarity than those with the same ads, different articles.</li></ul><p><strong>Enter LSH</strong></p><ul><li>Their first attempt at minhashing was very inefficient.</li><li>They were unaware of the importance of doing the minhashing row by row.</li><li>Since their data was column by column, they needed to sort once before minhashing.</li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•°æ®æŒ–æ˜ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Wireshark æŠ“åŒ…æŒ‡å—</title>
      <link href="/2016/01/02/Wireshark%20%E6%8A%93%E5%8C%85%E6%8C%87%E5%8D%97/"/>
      <url>/2016/01/02/Wireshark%20%E6%8A%93%E5%8C%85%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#wireshark-ä»‹ç»">Wireshark ä»‹ç»</a></li><li><a href="#wireshark-å¼€å§‹æŠ“åŒ…">Wireshark å¼€å§‹æŠ“åŒ…</a></li><li><a href="#wireshark-çª—å£ä»‹ç»">Wireshark çª—å£ä»‹ç»</a></li><li><a href="#wireshark-è¿‡æ»¤å™¨">Wireshark è¿‡æ»¤å™¨</a><ul><li><a href="#æ•æ‰è¿‡æ»¤å™¨">æ•æ‰è¿‡æ»¤å™¨</a></li><li><a href="#æ˜¾ç¤ºè¿‡æ»¤å™¨">æ˜¾ç¤ºè¿‡æ»¤å™¨</a></li></ul></li><li><a href="#å°åŒ…åˆ—è¡¨">å°åŒ…åˆ—è¡¨</a></li><li><a href="#tcp-åŒ…è§£æ">TCP åŒ…è§£æ</a></li><li><a href="#tcp-ä¸‰è·¯æ¡æ‰‹åˆ†æ">TCP ä¸‰è·¯æ¡æ‰‹åˆ†æ</a></li><li><a href="#å‚è€ƒ">å‚è€ƒ</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="wireshark-ä»‹ç»">Wireshark ä»‹ç»</span></h2><p>Wiresharkæ˜¯éå¸¸æµè¡Œçš„ç½‘ç»œå°åŒ…åˆ†æè½¯ä»¶ï¼ŒåŠŸèƒ½ååˆ†å¼ºå¤§ã€‚å¯ä»¥æˆªå–å„ç§ç½‘ç»œå°åŒ…ï¼Œæ˜¾ç¤ºç½‘ç»œå°åŒ…çš„è¯¦ç»†ä¿¡æ¯ã€‚ <a href="http://www.wireshark.org/" target="_blank" rel="noopener">å®˜æ–¹ä¸‹è½½åœ°å€</a></p><h2><span id="wireshark-å¼€å§‹æŠ“åŒ…">Wireshark å¼€å§‹æŠ“åŒ…</span></h2><p>psï¼šåœ¨Linuxä¸Šè¿è¡ŒWiresharkæŠ“åŒ…å¯èƒ½ä¼šé‡åˆ°æƒé™é—®é¢˜ï¼Œ<a href="https://wiki.wireshark.org/CaptureSetup" target="_blank" rel="noopener">è§£å†³æ–¹æ¡ˆå¯ä»¥å‚è€ƒè¿™é‡Œ</a></p><p>å¼€å§‹ç•Œé¢ï¼š <img src="/images/1451724415086.png"></p><p>é€‰æ‹©ä½ æ­£åœ¨ç”¨çš„ç½‘å¡ï¼Œç„¶åç‚¹èœå•ä¸­çš„é²¨é±¼å›¾æ ‡å°±å¯ä»¥è¿›è¡ŒæŠ“åŒ…äº†ï¼</p><h2><span id="wireshark-çª—å£ä»‹ç»">Wireshark çª—å£ä»‹ç»</span></h2><p><img src="/images/1451724570752.png"></p><p>WireShark ä¸»è¦åˆ†ä¸ºè¿™å‡ ä¸ªç•Œé¢</p><ol type="1"><li><p>Display Filter(æ˜¾ç¤ºè¿‡æ»¤å™¨)ï¼Œ ç”¨äºè¿‡æ»¤</p></li><li><p>Packet List Pane(å°åŒ…åˆ—è¡¨)ï¼Œ æ˜¾ç¤ºæ•è·åˆ°çš„å°åŒ…ï¼Œ æœ‰æºåœ°å€å’Œç›®æ ‡åœ°å€ï¼Œç«¯å£å·ã€‚ é¢œè‰²ä¸åŒï¼Œä»£è¡¨</p></li><li><p>Packet Details Pane(å°åŒ…è¯¦ç»†ä¿¡æ¯), æ˜¾ç¤ºå°åŒ…ä¸­çš„å­—æ®µ</p></li><li><p>Dissector Pane(16è¿›åˆ¶æ•°æ®)</p></li><li><p>Miscellanous(åœ°å€æ ï¼Œæ‚é¡¹)</p></li></ol><h2><span id="wireshark-è¿‡æ»¤å™¨">Wireshark è¿‡æ»¤å™¨</span></h2><p>Wiresharkæœ‰ä¸¤ç§è¿‡æ»¤å™¨ï¼Œåˆ†åˆ«æ˜¯<strong>æ˜¾ç¤ºè¿‡æ»¤å™¨</strong>ä¸<strong>æ•æ‰è¿‡æ»¤å™¨</strong>ã€‚</p><p><strong>åŒºåˆ«</strong> * æ•æ‰è¿‡æ»¤å™¨ï¼ˆCaptureFiltersï¼‰ï¼šç”¨äºå†³å®šå°†ä»€ä¹ˆæ ·çš„ä¿¡æ¯è®°å½•åœ¨æ•æ‰ç»“æœä¸­ã€‚éœ€è¦åœ¨å¼€å§‹æ•æ‰å‰è®¾ç½®ã€‚ * æ˜¾ç¤ºè¿‡æ»¤å™¨ï¼ˆDisplayFiltersï¼‰ï¼šåœ¨æ•æ‰ç»“æœä¸­è¿›è¡Œè¯¦ç»†æŸ¥æ‰¾ã€‚ä»–ä»¬å¯ä»¥åœ¨å¾—åˆ°æ•æ‰ç»“æœåéšæ„ä¿®æ”¹ã€‚</p><p><strong>ä¸¤ç§è¿‡æ»¤å™¨çš„ç›®çš„æ˜¯ä¸åŒçš„ã€‚</strong> * æ•æ‰è¿‡æ»¤å™¨æ˜¯æ•°æ®ç»è¿‡çš„ç¬¬ä¸€å±‚è¿‡æ»¤å™¨ï¼Œå®ƒç”¨äºæ§åˆ¶æ•æ‰æ•°æ®çš„æ•°é‡ï¼Œä»¥é¿å…äº§ç”Ÿè¿‡å¤§çš„æ—¥å¿—æ–‡ä»¶ã€‚ * æ˜¾ç¤ºè¿‡æ»¤å™¨æ˜¯ä¸€ç§æ›´ä¸ºå¼ºå¤§ï¼ˆå¤æ‚ï¼‰çš„è¿‡æ»¤å™¨ã€‚å®ƒå…è®¸æ‚¨åœ¨æ—¥å¿—æ–‡ä»¶ä¸­è¿…é€Ÿå‡†ç¡®åœ°æ‰¾åˆ°æ‰€éœ€è¦çš„è®°å½•ã€‚</p><h3><span id="æ•æ‰è¿‡æ»¤å™¨">æ•æ‰è¿‡æ»¤å™¨</span></h3><p><img src="/images/1451724862160.png"></p><ul><li><p><strong>Protocol</strong>ï¼ˆåè®®ï¼‰: å¯èƒ½çš„å€¼: <code>ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp</code>. å¦‚æœæ²¡æœ‰ç‰¹åˆ«æŒ‡æ˜æ˜¯ä»€ä¹ˆåè®®ï¼Œåˆ™é»˜è®¤ä½¿ç”¨æ‰€æœ‰æ”¯æŒçš„åè®®ã€‚</p></li><li><p><strong>Direction</strong>ï¼ˆæ–¹å‘ï¼‰: å¯èƒ½çš„å€¼: <code>src, dst, src and dst, src or dst</code> å¦‚æœæ²¡æœ‰ç‰¹åˆ«æŒ‡æ˜æ¥æºæˆ–ç›®çš„åœ°ï¼Œåˆ™é»˜è®¤ä½¿ç”¨ <code>src or dst</code> ä½œä¸ºå…³é”®å­—ã€‚ ä¾‹å¦‚ï¼Œ <code>host 10.2.2.2</code> ä¸ <code>src or dst host 10.2.2.2</code> æ˜¯ä¸€æ ·çš„ã€‚</p></li><li><p><strong>Host(s)</strong>: å¯èƒ½çš„å€¼ï¼š <code>net, port, host, portrange</code>. å¦‚æœæ²¡æœ‰æŒ‡å®šæ­¤å€¼ï¼Œåˆ™é»˜è®¤ä½¿ç”¨<code>host</code>å…³é”®å­—ã€‚ ä¾‹å¦‚ï¼Œ<code>src 10.1.1.1</code>ä¸<code>src host 10.1.1.1</code>ç›¸åŒã€‚</p></li><li><p><strong>Logical Operations</strong>ï¼ˆé€»è¾‘è¿ç®—ï¼‰: å¯èƒ½çš„å€¼ï¼š<code>not, and, or</code>. å¦(<code>not</code>)å…·æœ‰æœ€é«˜çš„ä¼˜å…ˆçº§ã€‚æˆ–(<code>or</code>)å’Œä¸(<code>and</code>)å…·æœ‰ç›¸åŒçš„ä¼˜å…ˆçº§ï¼Œè¿ç®—æ—¶ä»å·¦è‡³å³è¿›è¡Œã€‚ ä¾‹å¦‚ï¼Œ <code>not tcp port 3128 and tcp port 23</code> ä¸ <code>(not tcp port 3128) and tcp port 23</code>ç›¸åŒã€‚ <code>not tcp port 3128 and tcp port 23</code> ä¸ <code>not (tcp port 3128 and tcp port 23)</code>ä¸åŒã€‚</p></li></ul><p>ä¾‹å­ï¼š * <code>tcp dst port 3128</code> //æ•æ‰ç›®çš„TCPç«¯å£ä¸º<code>3128</code>çš„å°åŒ…ã€‚ * <code>ip src host 10.1.1.1</code> //æ•æ‰æ¥æºIPåœ°å€ä¸º<code>10.1.1.1</code>çš„å°åŒ…ã€‚ * <code>host 10.1.2.3</code> //æ•æ‰ç›®çš„æˆ–æ¥æºIPåœ°å€ä¸º<code>10.1.2.3</code>çš„å°åŒ…ã€‚ * <code>ether host e0-05-c5-44-b1-3c</code> //æ•æ‰ç›®çš„æˆ–æ¥æºMACåœ°å€ä¸º<code>e0-05-c5-44-b1-3c</code>çš„å°åŒ…ã€‚å¦‚æœä½ æƒ³æŠ“æœ¬æœºä¸æ‰€æœ‰å¤–ç½‘é€šè®¯çš„æ•°æ®åŒ…æ—¶ï¼Œå¯ä»¥å°†è¿™é‡Œçš„macåœ°å€æ¢æˆè·¯ç”±çš„macåœ°å€å³å¯ã€‚ * <code>src portrange 2000-2500</code> //æ•æ‰æ¥æºä¸ºUDPæˆ–TCPï¼Œå¹¶ä¸”ç«¯å£å·åœ¨<code>2000</code>è‡³<code>2500</code>èŒƒå›´å†…çš„å°åŒ…ã€‚ * <code>not imcp</code> //æ˜¾ç¤ºé™¤äº†icmpä»¥å¤–çš„æ‰€æœ‰å°åŒ…ã€‚ï¼ˆicmpé€šå¸¸è¢«pingå·¥å…·ä½¿ç”¨ï¼‰ * <code>src host 10.7.2.12 and not dst net 10.200.0.0/16</code> //æ˜¾ç¤ºæ¥æºIPåœ°å€ä¸º<code>10.7.2.12</code>ï¼Œä½†ç›®çš„åœ°ä¸æ˜¯<code>10.200.0.0/16</code>çš„å°åŒ…ã€‚ * <code>(src host 10.4.1.12 or src net 10.6.0.0/16) and tcp dst portrange 200-10000 and dst net 10.0.0.0/8</code> //æ•æ‰æ¥æºIPä¸º<code>10.4.1.12</code>æˆ–è€…æ¥æºç½‘ç»œä¸º<code>10.6.0.0/16</code>ï¼Œç›®çš„åœ°TCPç«¯å£å·åœ¨<code>200</code>è‡³<code>10000</code>ä¹‹é—´ï¼Œå¹¶ä¸”ç›®çš„ä½äºç½‘ç»œ <code>10.0.0.0/8</code>å†…çš„æ‰€æœ‰å°åŒ…ã€‚ * <code>src net 192.168.0.0 mask 255.255.255.0</code> //æ•æ‰æºåœ°å€ä¸º<code>192.168.0.0</code>ç½‘ç»œå†…çš„æ‰€æœ‰å°åŒ…ã€‚</p><h3><span id="æ˜¾ç¤ºè¿‡æ»¤å™¨">æ˜¾ç¤ºè¿‡æ»¤å™¨</span></h3><p><img src="/images/1451725452855.png"></p><p>å®ä¾‹ï¼š <img src="/images/1451725468174.png"></p><p><strong>è¿‡æ»¤è¡¨è¾¾å¼çš„è§„åˆ™</strong></p><p>è¡¨è¾¾å¼è§„åˆ™</p><ol type="1"><li><p><strong>åè®®è¿‡æ»¤</strong> æ¯”å¦‚TCPï¼Œåªæ˜¾ç¤ºTCPåè®®ã€‚</p></li><li><p><strong>IP è¿‡æ»¤</strong> æ¯”å¦‚ <code>ip.src ==192.168.1.102</code> æ˜¾ç¤ºæºåœ°å€ä¸º192.168.1.102ï¼Œ <code>ip.dst==192.168.1.102</code>, ç›®æ ‡åœ°å€ä¸º192.168.1.102</p></li><li><p><strong>ç«¯å£è¿‡æ»¤</strong> <code>tcp.port ==80</code>, ç«¯å£ä¸º80çš„ <code>tcp.srcport == 80</code>, åªæ˜¾ç¤ºTCPåè®®çš„æ„¿ç«¯å£ä¸º80çš„ã€‚</p></li><li><p><strong>Httpæ¨¡å¼è¿‡æ»¤</strong> http.request.method==&quot;GET&quot;, åªæ˜¾ç¤ºHTTP GETæ–¹æ³•çš„ã€‚</p></li></ol><h2><span id="å°åŒ…åˆ—è¡¨">å°åŒ…åˆ—è¡¨</span></h2><p>å°åŒ…åˆ—è¡¨çš„é¢æ¿ä¸­æ˜¾ç¤ºï¼Œç¼–å·ï¼Œæ—¶é—´æˆ³ï¼Œæºåœ°å€ï¼Œç›®æ ‡åœ°å€ï¼Œåè®®ï¼Œé•¿åº¦ï¼Œä»¥åŠå°åŒ…ä¿¡æ¯ã€‚ ä½ å¯ä»¥çœ‹åˆ°ä¸åŒçš„åè®®ç”¨äº†ä¸åŒçš„é¢œè‰²æ˜¾ç¤ºã€‚</p><p>ä½ ä¹Ÿå¯ä»¥ä¿®æ”¹è¿™äº›æ˜¾ç¤ºé¢œè‰²çš„è§„åˆ™ï¼Œ View -&gt;Coloring Rules.</p><p><img src="/images/1451725740486.png"></p><p><strong>è¯¦ç»†ä¿¡æ¯</strong></p><p>è¿™ä¸ªé¢æ¿æ˜¯æˆ‘ä»¬æœ€é‡è¦çš„ï¼Œç”¨æ¥æŸ¥çœ‹åè®®ä¸­çš„æ¯ä¸€ä¸ªå­—æ®µã€‚</p><p>å„è¡Œä¿¡æ¯åˆ†åˆ«ä¸º * <strong>Frame</strong>: ç‰©ç†å±‚çš„æ•°æ®å¸§æ¦‚å†µ * <strong>Ethernet II</strong>: æ•°æ®é“¾è·¯å±‚ä»¥å¤ªç½‘å¸§å¤´éƒ¨ä¿¡æ¯ * <strong>Internet Protocol Version 4</strong>: äº’è”ç½‘å±‚IPåŒ…å¤´éƒ¨ä¿¡æ¯ * <strong>Transmission Control Protocol</strong>: ä¼ è¾“å±‚Tçš„æ•°æ®æ®µå¤´éƒ¨ä¿¡æ¯ï¼Œæ­¤å¤„æ˜¯TCP * <strong>Hypertext Transfer Protocol</strong>: åº”ç”¨å±‚çš„ä¿¡æ¯ï¼Œæ­¤å¤„æ˜¯HTTPåè®®</p><p><strong>å¯¹åº”çš„OSIä¸ƒå±‚æ¨¡å‹</strong> <img src="/images/1451725855652.png"></p><h2><span id="tcp-åŒ…è§£æ">TCP åŒ…è§£æ</span></h2><p>ä»ä¸‹å›¾å¯ä»¥çœ‹åˆ°wiresharkæ•è·åˆ°çš„TCPåŒ…ä¸­çš„æ¯ä¸ªå­—æ®µã€‚</p><p><img src="/images/1451725951459.png"></p><h2><span id="tcp-ä¸‰è·¯æ¡æ‰‹åˆ†æ">TCP ä¸‰è·¯æ¡æ‰‹åˆ†æ</span></h2><p>ä¸‰è·¯æ¡æ‰‹çš„è¿‡ç¨‹ä¸ºï¼š</p><p><img src="/images/1451726004003.png"></p><p>æˆ‘ä»¬ç”¨wiresharkå®é™…åˆ†æä¸‹ä¸‰æ¬¡æ¡æ‰‹çš„è¿‡ç¨‹</p><p>æ‰“å¼€wireshark, å¼€å§‹æŠ“åŒ…åæ‰“å¼€æµè§ˆå™¨è¾“å…¥ http://www.liuhe.website</p><p>åœ¨wiresharkä¸­è¾“å…¥httpè¿‡æ»¤ï¼Œ ç„¶åé€‰ä¸­Destinationä¸º<code>139.129.38.159</code> ä¸” <code>GET / HTTP/1.1</code>çš„é‚£æ¡è®°å½•ï¼Œå³é”®ç„¶åç‚¹å‡» â€œå¯¹è¯è¿‡æ»¤å™¨-&gt;TCPâ€.</p><p>è¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†å¾—åˆ°ä¸æµè§ˆå™¨æ‰“å¼€ç½‘ç«™ç›¸å…³çš„æ•°æ®åŒ…ï¼Œå°†å¾—åˆ°å¦‚ä¸‹å›¾ <img src="/images/1451726264665.png"></p><p>å›¾ä¸­å¯ä»¥çœ‹åˆ°wiresharkæˆªè·åˆ°äº†ä¸‰æ¬¡æ¡æ‰‹çš„ä¸‰ä¸ªæ•°æ®åŒ…ã€‚ç¬¬å››ä¸ªåŒ…æ‰æ˜¯HTTPçš„ï¼Œ è¿™è¯´æ˜HTTPçš„ç¡®æ˜¯ä½¿ç”¨TCPå»ºç«‹è¿æ¥çš„ã€‚</p><p><strong>ç¬¬ä¸€æ¬¡æ¡æ‰‹</strong> å®¢æˆ·ç«¯é€šè¿‡å‘æœåŠ¡å™¨ç«¯å‘é€ä¸€ä¸ª<code>SYN</code>æ¥åˆ›å»ºä¸€ä¸ªä¸»åŠ¨æ‰“å¼€ï¼Œä½œä¸ºä¸‰è·¯æ¡æ‰‹çš„ä¸€éƒ¨åˆ†ã€‚å®¢æˆ·ç«¯æŠŠè¿™æ®µè¿æ¥çš„åºå·è®¾å®šä¸ºéšæœºæ•°<strong>A</strong>ã€‚</p><p><img src="/images/1451726663334.png"></p><p><strong>ç¬¬äºŒæ¬¡æ¡æ‰‹</strong> æœåŠ¡å™¨ç«¯åº”å½“ä¸ºä¸€ä¸ªåˆæ³•çš„<code>SYN</code>å›é€ä¸€ä¸ª<code>SYN/ACK</code>ã€‚<code>ACK</code> çš„ç¡®è®¤ç åº”ä¸º <strong>A+1</strong>ï¼Œ<code>SYN/ACK</code> åŒ…æœ¬èº«åˆæœ‰ä¸€ä¸ªéšæœºåºå· <strong>B</strong>ã€‚</p><p><img src="/images/1451726946164.png"></p><p><strong>ç¬¬ä¸‰æ¬¡æ¡æ‰‹</strong> æœ€åï¼Œå®¢æˆ·ç«¯å†å‘é€ä¸€ä¸ª<code>ACK</code>ã€‚å½“æœåŠ¡ç«¯å—åˆ°è¿™ä¸ª<code>ACK</code>çš„æ—¶å€™ï¼Œå°±å®Œæˆäº†ä¸‰è·¯æ¡æ‰‹ï¼Œå¹¶è¿›å…¥äº†è¿æ¥åˆ›å»ºçŠ¶æ€ã€‚æ­¤æ—¶åŒ…åºå·è¢«è®¾å®šä¸ºæ”¶åˆ°çš„ç¡®è®¤å· <strong>A+1</strong>ï¼Œè€Œå“åº”åˆ™ä¸º <strong>B+1</strong>ã€‚</p><p><img src="/images/1451727158983.png"></p><p>å°±è¿™æ ·é€šè¿‡äº†TCPä¸‰æ¬¡æ¡æ‰‹ï¼Œå»ºç«‹äº†è¿æ¥ã€‚</p><h2><span id="å‚è€ƒ">å‚è€ƒ</span></h2><p><a href="http://www.cnblogs.com/tankxiao/archive/2012/10/10/2711777.html#start" target="_blank" rel="noopener">WiresharkåŸºæœ¬ä»‹ç»å’Œå­¦ä¹ TCPä¸‰æ¬¡æ¡æ‰‹</a></p><p><a href="http://fangxin.blog.51cto.com/1125131/735178" target="_blank" rel="noopener">WiresharkæŠ“åŒ…å·¥å…·ä½¿ç”¨æ•™ç¨‹ä»¥åŠå¸¸ç”¨æŠ“åŒ…è§„åˆ™</a></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> è®¡ç®—æœºç½‘ç»œ </tag>
            
            <tag> Wireshark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>C++å…³äºå¯¹è±¡ä¼ å€¼ä¸ä¼ å¼•ç”¨çš„æ€»ç»“</title>
      <link href="/2015/12/28/C++%E5%85%B3%E4%BA%8E%E5%AF%B9%E8%B1%A1%E4%BC%A0%E5%80%BC%E4%B8%8E%E4%BC%A0%E5%BC%95%E7%94%A8%E7%9A%84%E6%80%BB%E7%BB%93/"/>
      <url>/2015/12/28/C++%E5%85%B3%E4%BA%8E%E5%AF%B9%E8%B1%A1%E4%BC%A0%E5%80%BC%E4%B8%8E%E4%BC%A0%E5%BC%95%E7%94%A8%E7%9A%84%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2><span id="ä¼ å€¼vsä¼ å¼•ç”¨">ä¼ å€¼VSä¼ å¼•ç”¨</span></h2><p>C++åœ¨ä¼ é€’<strong>å¯¹è±¡ç±»å‹</strong>çš„å‚æ•°æ—¶å€™æœ‰ä¸¤ç§æƒ…å†µï¼š</p><ul><li>å¦‚æœæ˜¯å¼•ç”¨å°±ç›¸å½“äºç›´æ¥æŠŠè¿™ä¸ªå¯¹è±¡æœ¬èº«ä¼ é€’è¿‡å»äº†</li><li>è‹¥æ˜¯ä¼ å€¼åˆ™éœ€åœ¨è¿›å…¥å‡½æ•°ä¹‹å‰é€šè¿‡<strong>æ‹·è´æ„é€ å‡½æ•°</strong>å»ºç«‹ä¸€ä¸ªä¸´æ—¶å¯¹è±¡ï¼ˆå¦‚æœæ²¡æœ‰è‡ªå·±å†™æ‹·è´æ„é€ å‡½æ•°åˆ™æ˜¯<strong>æµ…æ‹·è´</strong>ï¼‰ï¼Œç„¶åå†ç¦»å¼€å‡½æ•°ä¹‹åè¿™ä¸ªä¸´æ—¶å¯¹è±¡ä¼šè‡ªåŠ¨é”€æ¯ï¼ˆè°ƒç”¨äº†<strong>ææ„å‡½æ•°</strong>ï¼‰</li></ul><a id="more"></a><h3><span id="æ·±æ‹·è´vsæµ…æ‹·è´">æ·±æ‹·è´VSæµ…æ‹·è´</span></h3><p>æµ…æ‹·è´å³<strong>ç›´æ¥å¤åˆ¶</strong>å¯¹è±¡é‡Œçš„å­—æ®µ ##### æ·±æ‹·è´æ˜¯å¦‚æœè¯¥å­—æ®µä¸æ˜¯æŒ‡é’ˆåˆ™ç›´æ¥å¤åˆ¶ï¼Œè‹¥æ˜¯æŒ‡é’ˆåˆ™æ–°ç”³è¯·ä¸€å—å†…å­˜ç©ºé—´å¤åˆ¶æŒ‡é’ˆæŒ‡å‘çš„å†…å®¹</p><h2><span id="ä¸è¦åœ¨æ‹·è´æ„é€ å‡½æ•°é‡Œä¿®æ”¹æºå¯¹è±¡">ä¸è¦åœ¨æ‹·è´æ„é€ å‡½æ•°é‡Œä¿®æ”¹æºå¯¹è±¡</span></h2><p>è¿™ç‚¹æˆ‘è§‰å¾—å°¤å…¶é‡è¦ã€‚ ä¹‹æ‰€ä»¥è¿™ä¹ˆè¯´æ˜¯å› ä¸ºæ‹·è´æ„é€ å‡½æ•°çš„è°ƒç”¨<strong>ä¸æ˜¯é‚£ä¹ˆå¯æ§çš„</strong>,ä¸åƒæ™®é€šå‡½æ•°ä¸€æ ·ï¼Œåªè¦ä½ ä¸ä¸»åŠ¨è°ƒç”¨å°±ä¸ä¼šæ‰§è¡Œã€‚<strong>æ‹·è´æ„é€ å‡½æ•°å¾ˆå¯èƒ½åœ¨ä½ ä¸çŸ¥é“çš„åœ°æ–¹ä¼šè¢«è°ƒç”¨</strong>ï¼Œæ¯”å¦‚ä¸Šè¿°<strong>å‡½æ•°ä¼ å€¼</strong>ã€‚è‹¥æ˜¯åœ¨è°ƒç”¨æ‹·è´æ„é€ å‡½æ•°çš„æ—¶å€™æ”¹å˜äº†æºå¯¹è±¡å¾ˆå¯èƒ½ä¼šé€ æˆæ„æƒ³ä¸åˆ°çš„ç»“æœï¼Œé™¤éä½ è€ƒè™‘å¾—å¾ˆå‘¨å…¨ï¼Œç¡®è®¤æ‰€ä»¥ä¼šè°ƒç”¨æ‹·è´æ„é€ å‡½æ•°çš„åœ°æ–¹éƒ½éœ€è¦æ”¹å˜æºå¯¹è±¡ã€‚ æ‰€ä»¥æ¨èå†™æ‹·è´æ„é€ å‡½æ•°çš„æ—¶å€™åŠ ä¸Š<code>const</code>ï¼š <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Object(<span class="keyword">const</span> Object&amp; obj);</span><br></pre></td></tr></table></figure></p><h2><span id="æ‹·è´æ„é€ å‡½æ•°çš„è°ƒç”¨">æ‹·è´æ„é€ å‡½æ•°çš„è°ƒç”¨</span></h2><h4><span id="æ‹·è´æ„é€ å‡½æ•°ä¸æ˜¯æ‰€æœ‰å¯¹è±¡çš„èµ‹å€¼éƒ½ä¼šè°ƒç”¨åªæœ‰å†åˆ›å»ºå¯¹è±¡çš„æ—¶å€™èµ‹å€¼æ‰ä¼šè°ƒç”¨">æ‹·è´æ„é€ å‡½æ•°ä¸æ˜¯æ‰€æœ‰å¯¹è±¡çš„èµ‹å€¼éƒ½ä¼šè°ƒç”¨ï¼Œåªæœ‰å†åˆ›å»ºå¯¹è±¡çš„æ—¶å€™èµ‹å€¼æ‰ä¼šè°ƒç”¨ï¼ï¼ï¼</span></h4><p>æ¯”å¦‚ï¼š <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    A()&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"A!"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    A(A&amp; a)&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Copy"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    A a;        <span class="comment">// A!</span></span><br><span class="line">    A b = a;    <span class="comment">// Copy</span></span><br><span class="line">    A c;        <span class="comment">// A!</span></span><br><span class="line">    c = a;      <span class="comment">// ä¸è¾“å‡º</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>ä¸Šè¿°ä»£ç è¾“å‡º <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A!</span><br><span class="line">Copy</span><br><span class="line">A!</span><br></pre></td></tr></table></figure></p><p>å¯è§åªä¼šåœ¨<code>A b = a</code>è¿™å¥è¯çš„æ—¶å€™è°ƒç”¨æ‹·è´æ„é€ å‡½æ•°ï¼Œè€Œä¸‹é¢çš„<code>c = a</code>åˆ™ä¸ä¼šè°ƒç”¨ï¼</p><p>é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class A</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    A()&#123;</span><br><span class="line">        cout &lt;&lt; &quot;A!&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    A(A&amp; a)&#123;</span><br><span class="line">        cout &lt;&lt; &quot;Copy&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class B</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    B()&#123;</span><br><span class="line">        cout &lt;&lt; &quot;B!&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    B(const A&amp; a)&#123;</span><br><span class="line">        cout &lt;&lt; &quot;B(A)!&quot; &lt;&lt; endl;</span><br><span class="line">        this-&gt;a = a;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    A a;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    A a;        // A!</span><br><span class="line">    B b1;       // A! B!</span><br><span class="line">    b1.a = a;   // </span><br><span class="line">    B b2(a);    // A! B(A)!</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>ç¨‹åºè¾“å‡ºå¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A!</span><br><span class="line">A!</span><br><span class="line">B!</span><br><span class="line">A!</span><br><span class="line">B(A)!</span><br></pre></td></tr></table></figure></p><p>æˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹ï¼š æ‰§è¡Œ<code>A a</code>è°ƒç”¨æ„é€ å‡½æ•°è¾“å‡º<code>A!</code></p><p>ç»§ç»­æ‰§è¡Œ<code>B b1</code>å…ˆè°ƒç”¨Açš„æ„é€ å‡½æ•°å†è°ƒç”¨Bçš„æ„é€ å‡½æ•°è¾“å‡º<code>A! B!</code></p><p>ç»§ç»­æ‰§è¡Œ<code>b1.a = a</code>ç»™b1é‡Œçš„aèµ‹å€¼ï¼Œ<strong>è¿™å¥è¯æ²¡æœ‰è¾“å‡º</strong>ï¼Œä¹Ÿå°±æ˜¯è¯´<strong>æ²¡æœ‰è°ƒç”¨Açš„æ‹·è´æ„é€ å‡½æ•°</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ª<strong>æµ…æ‹·è´</strong>ã€‚</p><p>ç»§ç»­æ‰§è¡Œ<code>B b2(a)</code>ï¼Œè°ƒç”¨Bçš„æœ‰å‚æ„é€ å‡½æ•°å¹¶åœ¨æ„é€ å‡½æ•°é‡Œç»™aèµ‹å€¼ï¼Œè¾“å‡º<code>A! B(A)!</code>ï¼Œæ²¡æœ‰è¾“å‡º<code>Copy</code>ï¼Œè¯´æ˜ä¹Ÿ<strong>æ²¡æœ‰è°ƒç”¨Açš„æ‹·è´æ„é€ å‡½æ•°</strong>ï¼Œä¹Ÿæ˜¯ä¸€ä¸ª<strong>æµ…æ‹·è´</strong>ã€‚</p><p>é‚£å¦‚æœAä¸­æœ‰å¤æ‚çš„æŒ‡é’ˆç±»å‹å­—æ®µï¼Œæˆ‘æƒ³æ‰§è¡Œ<strong>æ·±æ‹·è´</strong>è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ</p><p>æˆ‘åªæƒ³åˆ°ä¸€ä¸ªä¸æ˜¯å¾ˆèªæ˜çš„è§£å†³åŠæ³•ï¼š å¯ä»¥ç”¨å…ˆé€šè¿‡<strong>æ‹·è´æ„é€ å‡½æ•°</strong>æ„é€ ä¸€ä¸ªAå¯¹è±¡<strong>ï¼ˆæ·±æ‹·è´ï¼‰</strong>ï¼Œå†æŠŠå®ƒçš„å€¼èµ‹ç»™Bé‡Œçš„Aå¯¹è±¡<strong>ï¼ˆæµ…æ‹·è´ï¼‰</strong>ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    A a;                // A!</span><br><span class="line">    </span><br><span class="line">    A* t = new A(a);    // Copy</span><br><span class="line">    B b;                // A! B!</span><br><span class="line">    b.a = *t;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A!</span><br><span class="line">Copy</span><br><span class="line">A!</span><br><span class="line">B!</span><br></pre></td></tr></table></figure></p><p>è¿™æ ·åšå¯ä»¥ä½¿<code>b.a</code>è¾¾åˆ°<strong>æ·±æ‹·è´</strong>çš„ç›®çš„ï¼Œå³<code>b.a</code>å’Œ<code>a</code>é‡Œçš„æŒ‡é’ˆæŒ‡å‘ä¸åŒçš„å†…å­˜åœ°å€ï¼Œè€Œåœ°å€ä¸Šå­˜å‚¨çš„å€¼æ˜¯ä¸€æ ·çš„ã€‚ä¹‹æ‰€ä»¥ç”¨<code>new</code>ä¸€ä¸ªæŒ‡é’ˆè€Œä¸æ˜¯ç›´æ¥åˆ›å»ºå˜é‡æ˜¯å› ä¸º<code>new</code>å‡ºçš„ç©ºé—´å¯ä»¥å­˜æ´»æ•´ä¸ªç¨‹åºè¿è¡ŒæœŸé—´å­˜æ´»ï¼Œè€Œç›´æ¥åˆ›å»ºå˜é‡çš„è¯å¯èƒ½ä¼šå› ä¸ºå‡½æ•°è¿”å›è€Œæ¶ˆå¤±ã€‚è¿™é‡Œçš„<code>t</code>åªæ˜¯ä¸€ä¸ªä¸­ä»‹ï¼Œä¹‹åä¹Ÿä¸è¦å¯¹å…¶è¿›è¡Œæ“ä½œï¼Œä¼šå½±å“åˆ°<code>b.a</code>é‡Œçš„æŒ‡é’ˆå­—æ®µæŒ‡å‘çš„å€¼ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æµ·é‡æ•°æ®æŒ–æ˜ï¼ˆäºŒï¼‰ï¼šLink Analysis and PageRank</title>
      <link href="/2015/12/27/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ALink%20Analysis%20and%20PageRank/"/>
      <url>/2015/12/27/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ALink%20Analysis%20and%20PageRank/</url>
      
        <content type="html"><![CDATA[<blockquote><p>æ­¤ç³»åˆ—ä¸ºCouseraä¸ŠStandfordçš„<a href="https://class.coursera.org/mmds-002" target="_blank" rel="noopener">Mining Massive Datasets</a>è¯¾ç¨‹å­¦ä¹ ç¬”è®°ã€‚ è¿™æ˜¯è¯¥ç³»åˆ—çš„ç¬¬äºŒç¯‡ç¬”è®°ï¼š<strong>Link Analysis and PageRank</strong></p></blockquote><a id="more"></a><h2><span id="é“¾æ¥åˆ†æ-link-analysis">é“¾æ¥åˆ†æ Link Analysis</span></h2><h3><span id="å›¾ç±»æ•°æ®-graph-data">å›¾ç±»æ•°æ® Graph Data</span></h3><figure><img src="/images/1450882068603.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>å›¾ç”±ä¸€ç»„èŠ‚ç‚¹å’Œä¸€ç»„è¾¹ç»„æˆï¼Œæ ¹æ®è¾¹æœ‰æ²¡æœ‰æ–¹å‘å¯ä»¥åˆ†ä¸ºæœ‰å‘å›¾å’Œæ— å‘å›¾ã€‚</p><p>ç¤¾äº¤ç½‘ç»œå¯ä»¥ç”¨å›¾æ¥æè¿°ã€åª’ä½“ç½‘ç»œå¯ä»¥ç”¨å›¾æ¥æè¿°ã€ä¿¡æ¯ç½‘ç»œä¹Ÿå¯ä»¥ç”¨å›¾æ¥æè¿°ã€äº’è”ç½‘æ›´å¯ä»¥ç”¨å›¾æ¥æè¿°ï¼ <img src="/images/1450882333263.png" alt="Alt text"></p><p>Webä¹Ÿå¯ä»¥çœ‹ä½œä¸€å¼ å›¾ã€‚</p><h3><span id="web-as-a-graph">Web as a Graph</span></h3><ul><li>Web å¯ä»¥çœ‹ä½œä¸€ä¸ªæœ‰å‘å›¾<ul><li>èŠ‚ç‚¹ï¼š ç½‘é¡µ</li><li>è¾¹ ï¼š è¶…é“¾æ¥</li></ul></li></ul><p>Webç½‘ç»œå›¾ä¸¾ä¾‹ï¼š</p><figure><img src="/images/1450882695999.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h3><span id="how-to-organize-the-web">How to organize the Web?</span></h3><p>æ—©äº›æ—¶å€™ï¼Œäº’è”ç½‘åˆšèµ·æ­¥çš„æ—¶ä»£ï¼Œäººä»¬æ‰‹åŠ¨ç»„ç»‡<strong>ç½‘é¡µç›®å½•(Web directories)</strong>ï¼Œåƒé›…è™ã€DMOZç­‰ã€‚</p><p>ç°åœ¨éƒ½æ˜¯é‡‡ç”¨<strong>ç½‘é¡µæœç´¢(Web Search)</strong>çš„å½¢å¼ï¼Œä¿¡æ¯æ£€ç´¢åŠæ³•: åœ¨ä¸€ä¸ªå°çš„ã€å¯ä¿¡ä»»çš„é¡µé¢é›†åˆä¸­å¯»æ‰¾ç›¸å…³çš„ç½‘é¡µã€‚</p><p><strong>ä½†æ˜¯</strong>ï¼Œ Webéå¸¸å¤§ï¼Œæ—å­å¤§äº†ä»€ä¹ˆé¸Ÿéƒ½æœ‰ï¼Œå……æ»¡ä¸å¯ä¿¡ä»»çš„çš„ç½‘é¡µã€å¥‡æ€ªçš„ä¸œè¥¿ã€åƒåœ¾é‚®ä»¶ç­‰ã€‚</p><blockquote><p><strong>åšWebæœç´¢æœ‰ä¸¤å¤§æŒ‘æˆ˜</strong>ï¼š 1. è¯¥ä¿¡ä»»å“ªäº›ç½‘é¡µï¼Ÿ 2. ä»€ä¹ˆæ˜¯æœ€å¥½ç»“æœï¼Ÿ</p></blockquote><p>å¯¹äºç¬¬ä¸€ç‚¹ï¼Œå¯ä»¥è®¤ä¸º<strong>å¯ä¿¡ä»»çš„é¡µé¢é‡Œçš„é“¾æ¥ä¸€èˆ¬éƒ½äº’ç›¸æŒ‡å‘</strong>ï¼Œè¿™æ ·å°±å¯ä»¥ç¡®å®šå¤§éƒ¨åˆ†çš„å¯ä¿¡ä»»ç½‘é¡µï¼Œä½†å¹¶ä¸æ˜¯ç»å¯¹çš„ã€‚ å¯¹äºç¬¬äºŒç‚¹ï¼Œåœ¨æœç´¢å¼•æ“ä¸Šæœç´¢çš„ç»å¤§éƒ¨åˆ†éƒ½æ˜¯æ²¡æœ‰æœ€å¥½çš„ç­”æ¡ˆçš„ï¼Œæ€ä¹ˆæä¾›ç”¨æˆ·æœ€æƒ³è¦çš„ç­”æ¡ˆæ˜¯ä¸ªé—®é¢˜ã€‚</p><h3><span id="ranking-nodes-on-the-graph">Ranking Nodes on the Graph</span></h3><p><strong>ä¸æ˜¯æ‰€æœ‰ç½‘é¡µéƒ½ä¸€æ ·â€œé‡è¦â€œï¼</strong> æ¯”å¦‚ï¼šhttps://www.baidu.com/ vs http://www.liuhe.website/ å¾ˆå®¹æ˜“åˆ¤æ–­ç†Ÿè½»ç†Ÿé‡ã€‚</p><p>åœ¨Webè¿™ä¸ªå›¾é‡Œï¼Œæ¯ä¸ªèŠ‚ç‚¹ç›¸è¿çš„è¾¹æ•°å·®å¼‚å¾ˆå¤§ï¼</p><p>é“¾æ¥åˆ†æç®—æ³•ç®€ä»‹ï¼š <img src="/images/1450884497971.png" alt="Alt text"></p><h2><span id="pagerank">PageRank</span></h2><h3><span id="the-quotflowquot-formulation">The &quot;Flow&quot; Formulation</span></h3><blockquote><p>è®¡ç®—èŠ‚ç‚¹ï¼ˆç½‘é¡µï¼‰æƒé‡çš„æƒ³æ³•ï¼š<strong>æŠŠé“¾æ¥å½“ä½œæƒé‡ï¼ˆLinks as votesï¼‰</strong></p></blockquote><p>åŸºæœ¬æƒ³æ³•æ˜¯è¿™æ ·çš„ï¼Œ<strong>å¦‚æœä¸€ä¸ªç½‘é¡µå¾ˆé‡è¦ï¼Œé‚£ä¹ˆæŒ‡å‘å®ƒå’Œå®ƒæŒ‡å‘åˆ«çš„ç½‘é¡µçš„é“¾æ¥åº”è¯¥å¾ˆå¤š</strong>ã€‚æœ‰ä¸€ä¸ªé—®é¢˜å°±æ˜¯è€ƒè™‘æŒ‡å‘å®ƒçš„é“¾æ¥è¿˜æ˜¯å®ƒæŒ‡å‡ºå»çš„é“¾æ¥å‘¢ï¼Ÿ</p><p>å¦‚æœè€ƒè™‘æŒ‡å‡ºå»çš„é“¾æ¥çš„è¯ï¼Œé‚£åªè¦å¤§å®¶éƒ½åœ¨è‡ªå·±çš„ç½‘é¡µä¸Šæ”¾ä¸€å¤§å †é“¾æ¥å°±å¯ä»¥æé«˜PageRankäº†ï¼Œè¿™æ ·å¹¶ä¸èƒ½ååº”ä¸€ä¸ªç½‘ç«™çš„é‡è¦ç¨‹åº¦ï¼Œæ‰€ä»¥æˆ‘ä»¬<strong>è€ƒè™‘æŒ‡å‘è¯¥ç½‘é¡µçš„é“¾æ¥</strong>ã€‚</p><p>é‚£ä¹ˆè¿˜æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæ˜¯ä¸æ˜¯æ‰€æœ‰æŒ‡å‘ä½ çš„é“¾æ¥éƒ½ä¸€æ ·é‡è¦ï¼Ÿï¼Ÿ æ˜¾ç„¶ä¸æ˜¯ï¼ å¦‚æœGoogleé¦–é¡µæœ‰æŒ‡å‘ä½ çš„é“¾æ¥ï¼Œä½ çš„æµé‡å¾ˆå¯èƒ½å°±ä¼šçˆ†å¢ï¼Œä½†æ˜¯<a href="www.liuhe.website">æˆ‘çš„é¦–é¡µ</a>å¦‚æœåŠ ä¸ŠæŒ‡å‘ä½ çš„é“¾æ¥å¯èƒ½å¹¶ä¸ä¼šå¸¦æ¥ä»€ä¹ˆæµé‡ã€‚</p><p>æ‰€ä»¥æ¯ä¸ªé“¾æ¥å¸¦æ¥çš„æƒé‡æ˜¯ä¸ä¸€æ ·çš„ï¼Œ<strong>æ¥è‡ªé‡è¦çš„ç½‘ç«™çš„é“¾æ¥æƒé‡åº”è¯¥æ›´é«˜äº›</strong>ã€‚</p><p>ä¸€ä¸ªä¾‹å­ï¼š <img src="/images/1450923574723.png" alt="ä¸€ä¸ªä¾‹å­"></p><h3><span id="ç®€å•çš„é€’å½’å…¬å¼">ç®€å•çš„é€’å½’å…¬å¼</span></h3><p>æ¯ä¸ªé“¾æ¥çš„æƒé‡ä¸å…¶æºç½‘ç«™çš„é‡è¦ç¨‹åº¦æˆæ¯”ä¾‹ã€‚</p><p>è®¾é¡µé¢ <span class="math inline">\(j\)</span> çš„æƒé‡ä¸º <span class="math inline">\(r_j\)</span> ï¼Œè¯¥é¡µæœ‰ <span class="math inline">\(n\)</span> ä¸ªæŒ‡å‘å…¶ä»–é¡µé¢çš„é“¾æ¥ï¼Œé‚£ä¹ˆï¼Œæ¯ä¸ªé“¾æ¥ç»™é‚£ä¸ªç½‘ç«™å¸¦æ¥çš„æƒé‡ä¸º $ r_j / n $ ã€‚</p><p>é¡µé¢ <span class="math inline">\(j\)</span> è‡ªå·±çš„æƒé‡æ¥è‡ªæ‰€æœ‰æŒ‡å‘å®ƒçš„é“¾æ¥çš„æƒé‡ä¹‹å’Œã€‚</p><p>å¾ˆç®€å•å§ï¼Ÿè¿™å°±æ˜¯&quot;Flow&quot;æ¨¡å‹ã€‚</p><figure><img src="/images/1450924042138.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>æˆ‘ä»¬å°è¯•è§£ä¸€ä¸‹ä¸Šå›¾ä¸­çš„æ–¹ç¨‹ç»„ï¼Œå³ï¼š $ r_y = r_y / 2 + r_a / 2 $ $ r_a = r_y / 2 + r_m $ $ r_m = r_a / 2 $</p><p>å‘ç°è§£å¹¶ä¸å”¯ä¸€ï¼Œåªèƒ½è§£å¾—ä¸¤ä¸¤ä¹‹é—´çš„å…³ç³»ï¼ŒåŸå› åœ¨äºæ–¹ç¨‹ç»„é‡Œæ²¡æœ‰å¸¸æ•°ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åŠ ä¸€ä¸ªæ¡ä»¶ï¼š $ r_y + r_a + r_m = 1 $</p><p>è¿™æ ·è§£å¾—ï¼š$ r_y = , r_a = , r_m =  $</p><p>åƒè¿™ç§å°è§„æ¨¡ä¾‹å­æˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨é«˜æ–¯æ¶ˆå…ƒæ³•çƒè§£ï¼Œä½†æ˜¯åƒwebè¿™ä¹ˆå¤§çš„å›¾è‚¯å®šä¸å¯èƒ½äººå·¥æ±‚è§£ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ›´å¥½çš„è®¡ç®—æ–¹æ³•ã€‚</p><h3><span id="matrix-formulation">Matrix Formulation</span></h3><blockquote><p>è­¦å‘Šï¼šä»¥ä¸‹å†…å®¹ä¼šæ¶‰åŠçº¿æ€§ä»£æ•°ä»¥åŠæ¦‚ç‡è®ºã€‚</p></blockquote><p>æˆ‘ä»¬ç”¨é‚»æ¥çŸ©é˜µ <span class="math inline">\(M\)</span> æ¥è¡¨ç¤ºå›¾ï¼Œè®¾é¡µé¢ <span class="math inline">\(i\)</span> æœ‰ $ d_i $ ä¸ªå¤–é“¾ï¼Œå¦‚æœ $ i -&gt; j $ ï¼Œé‚£ä¹ˆ $ M_{ji} =  $ å¦åˆ™ $ M_{ji} = 0 $ å…¶ä¸­ <span class="math inline">\(M\)</span> æ˜¯ä¸€ä¸ªåˆ—éšæœºçŸ©é˜µï¼Œæ¯åˆ—çš„å’Œç­‰äº1.</p><p>æˆ‘ä»¬å†ç”¨ä¸€ä¸ªå‘é‡ <span class="math inline">\(r\)</span> æ¥è¡¨ç¤ºæ‰€æœ‰é¡µé¢çš„PageRankï¼Œ$ r_i $ æ˜¯é¡µé¢ <span class="math inline">\(i\)</span> çš„å¾—åˆ†ï¼Œå¹¶ä¸” $ _i r_i = 1 $</p><p>ç°åœ¨ï¼Œä¸ŠèŠ‚çš„æ–¹ç¨‹($ r_j = _{i j}  $)å°±å¯ä»¥è¯¥å†™æˆï¼š $  = M  $</p><p>ç”¨ä¸ªä¾‹å­è§£é‡Šä¸€ä¸‹ï¼š å‡è®¾é¡µé¢ <span class="math inline">\(i\)</span> é“¾å‘3ä¸ªé¡µé¢ï¼ŒåŒ…æ‹¬ <span class="math inline">\(j\)</span> ï¼Œå¦‚å›¾æ‰€ç¤ºï¼š <img src="/images/1450973732761.png" alt="Alt text"></p><p>çŸ©é˜µä¹˜æ³•æ˜¯è¿™æ ·çš„ï¼Œç»“æœçŸ©é˜µçš„ <span class="math inline">\([i, j]\)</span> å…ƒç´ æ˜¯ $A_{i0} * B_{0j} + A_{i1} * B_{1i} + ... + A_{in} * B_{nj} $ å¾—åˆ°çš„ã€‚ <img src="/images/1450973811824.png" alt="Alt text"></p><p>æ‰€ä»¥ <span class="math inline">\(M\)</span> åœ¨ä¸ $r $ ç›¸ä¹˜çš„ç»“æœä¹Ÿæ˜¯ä¸€ä¸ªåˆ—å‘é‡ï¼Œè¿™ä¸ªåˆ—å‘é‡ç¬¬ <span class="math inline">\(i\)</span> ä¸ªå…ƒç´ çš„å€¼å°±ç­‰äºçŸ©é˜µ <span class="math inline">\(M\)</span> çš„ç¬¬ <span class="math inline">\(j\)</span> è¡Œä¹˜ä»¥ <span class="math inline">\(\vec r\)</span> ï¼Œæ•°å­¦è¡¨è¾¾å¼å°±æ˜¯ $ r_j = <em>{k=0}^{n} M</em>{jk}*r_i $ï¼Œç”±é‚»æ¥çŸ©é˜µæ‰€è¡¨ç¤ºçš„æ„ä¹‰å¯çŸ¥ï¼Œè¿™ä¸ä¹‹å‰çš„Flow Equationæ˜¯ç­‰æ•ˆçš„ã€‚</p><p>ä¸€ä¸ªä¾‹å­ï¼š <img src="/images/1451041071423.png" alt="Alt text"></p><h3><span id="ç‰¹å¾å‘é‡å…¬å¼">ç‰¹å¾å‘é‡å…¬å¼</span></h3><p>æˆ‘ä»¬å…ˆæ¥å¤ä¹ ä¸€ä¸‹ä»€ä¹ˆæ˜¯ç‰¹å¾å€¼(eigenvalue)å’Œç‰¹å¾å‘é‡(eigenvector)ã€‚</p><blockquote><p>å¦‚æœè¡¨è¾¾å¼ï¼š$ A x = x $ æˆç«‹ï¼Œåˆ™ç§°<span class="math inline">\(\vec x\)</span>ä¸ºçŸ©é˜µ<span class="math inline">\(A\)</span>çš„ç‰¹å¾å‘é‡ï¼Œ <span class="math inline">\(\lambda\)</span>ä¸ºçŸ©é˜µ<span class="math inline">\(A\)</span>çš„ç‰¹å¾å€¼ï¼Œå…¶ä¸­ <span class="math inline">\(\vec x\)</span>æ˜¯ä»»æ„å‘é‡ï¼Œ <span class="math inline">\(\lambda\)</span>æ˜¯å¸¸æ•°ã€‚</p></blockquote><p>ä¹‹å‰å¾—åˆ°çš„çŸ©é˜µå…¬å¼ä¸ºï¼š<span class="math inline">\(\vec r = M \cdot \vec r\)</span>ï¼Œæ­£å¥½æ˜¯ç¬¦åˆä¸Šè¿°è¡¨è¾¾å¼ï¼ŒçŸ©é˜µ<span class="math inline">\(M\)</span>çš„ç‰¹å¾å‘é‡å°±æ˜¯<span class="math inline">\(\vec r\)</span>ï¼Œç‰¹å¾å€¼å°±æ˜¯<span class="math inline">\(1\)</span>ã€‚</p><p>æœ‰äº†è¿™ä¸ªé‡å¤§å‘ç°ä¹‹åå°±å¯ä»¥é«˜æ•ˆçš„è®¡ç®— <span class="math inline">\(\vec r\)</span> äº†ï¼Œæˆ‘ä»¬ç®¡è¿™ä¸ªæ–¹æ³•å«<strong>å¹‚è¿­ä»£(Power iteration)</strong></p><h3><span id="å¹‚è¿­ä»£-power-iteration">å¹‚è¿­ä»£ Power Iteration</span></h3><p><strong>å¹‚è¿­ä»£</strong> * å‡è®¾æœ‰Nä¸ªwebé¡µé¢ * åˆå§‹åŒ–ï¼š$ r^{(0)} = [1/N, .... 1/N]^T $ * è¿­ä»£ï¼š$ r^{(t+1)} = M r^{(t)} $ * ç»ˆæ­¢æ¡ä»¶ï¼š$ |r<sup>{(t+1)}-r</sup>{(t)}|_1 &lt; $ * å…¶ä¸­ $ |x|_1 = _{i=1}^{N}|x_i| $</p><p>çœ‹äº†è¿™ä¸ªä¹‹åæ˜¯ä¸æ˜¯è§‰å¾—å¾ˆå¥½å®ç°ï¼Ÿå°±æ˜¯ä¸€ä¸ª<code>while</code>å¾ªç¯è€Œå·²ã€‚ è¿˜æ˜¯é‚£ä¸ªä¾‹å­ï¼š <img src="/images/1451042010630.png" alt="Alt text"> ç»è¿‡nè½®è¿­ä»£ä¹‹åï¼Œ<span class="math inline">\(\vec r\)</span> çš„å€¼ç¨³å®šåœ¨$ [6/15, 6/15, 3/15]^T$ ï¼Œä¸ä¹‹å‰è§£æ–¹ç¨‹ç»„çš„ç»“æœä¸€è‡´ã€‚</p><h3><span id="random-walk-interpretation">Random Walk Interpretation</span></h3><blockquote><p>ç°åœ¨æˆ‘ä»¬çŸ¥é“PageRankæ€ä¹ˆé«˜æ•ˆçš„è®¡ç®—äº†ï¼Œé‚£ä¹ˆ<strong>æ€ä¹ˆç†è§£è¿™ä¸ªç½‘é¡µçš„â€œé‡è¦â€œç¨‹åº¦è¿™ä¸ªæ•°å€¼çš„å…·ä½“æ„æ€å‘¢</strong>ï¼Ÿè¿™é‡Œæä¾›äº†ä¸€ç§è§£é‡Šï¼šéšæœºæ¼«æ¸¸è§£é‡Šã€‚</p></blockquote><p>å‡è®¾æœ‰ä¸€ä¸ªæ¼«æ­¥è€…éšæœºåœ°åœ¨ç½‘é¡µä¸­æ¼«æ¸¸ï¼š * åœ¨ <span class="math inline">\(t\)</span> æ—¶åˆ»ï¼Œè¿™ä¸ªäººåœ¨æŸä¸ªé¡µé¢ <span class="math inline">\(i\)</span> * åœ¨ <span class="math inline">\(t+1\)</span> æ—¶åˆ»ï¼Œæ¼«æ­¥è€…ä»é¡µé¢ <span class="math inline">\(i\)</span> çš„é“¾æ¥ä¸­éšæœºé€‰äº†ä¸€æ¡ * ç»ç”±é‚£ä¸ªé“¾æ¥åˆ°è¾¾äº† <span class="math inline">\(j\)</span> é¡µé¢ * æ— é™é‡å¤è¿™ä¸€è¿‡ç¨‹</p><p>æˆ‘ä»¬å†ä»¤ä¸€ä¸ªå‘é‡ <span class="math inline">\(p(t)\)</span>ï¼Œå®ƒçš„ç¬¬ <span class="math inline">\(i\)</span> ä¸ªå€¼å³<span class="math inline">\(p_i(t)\)</span>è¡¨ç¤ºåœ¨ <span class="math inline">\(t\)</span> æ—¶åˆ»è¿™ä¸ªæ¼«æ­¥è€…åœ¨é¡µé¢ <span class="math inline">\(i\)</span> çš„æ¦‚ç‡ã€‚ æ‰€ä»¥ <span class="math inline">\(p(t)\)</span> è¡¨ç¤ºæ‰€æœ‰é¡µé¢çš„æ¦‚ç‡åˆ†å¸ƒã€‚</p><p>é‚£ä¹ˆæ¼«æ­¥è€…åœ¨ <span class="math inline">\(t+1\)</span> æ—¶åˆ»åœ¨å“ªï¼Ÿ ç”±äºé€‰æ‹©æ¯ä¸ªé“¾æ¥æ˜¯éšæœºçš„ï¼Œæ‰€ä»¥ <span class="math inline">\(t+1\)</span> æ—¶åˆ»æ¼«æ­¥è€…åœ¨å½“å‰é¡µé¢æŒ‡å‘çš„æ¯ä¸ªé¡µé¢çš„æ¦‚ç‡éƒ½ç›¸ç­‰ï¼Œéƒ½ç­‰äºå½“å‰é¡µé¢çš„<em>å‡ºåº¦åˆ†ä¹‹ä¸€</em>ï¼Œæ‰€ä»¥æœ‰ï¼š $ p(t+1) = M p(t) $ å¯è§è¿™å’ŒPageRankçš„æ–¹ç¨‹æ˜¯ä¸€æ ·çš„ã€‚</p><p>è®¾æ¼«æ­¥è€…ä¼šè¾¾åˆ°ä¸€ä¸ªç¨³æ€ï¼š $ p(t+1) = M p(t) = p(t) $ åœ¨è¿™ä¸ªç¨³æ€ï¼Œæ¼«æ­¥è€…åœ¨ä»¥åä»»ä½•æ—¶åˆ»å‡ºç°åœ¨æŸä¸ªé¡µé¢çš„æ¦‚ç‡éƒ½ç›¸ç­‰ï¼Œè¿™æ—¶ <span class="math inline">\(p(t)\)</span> æ˜¯ä¸€ä¸ª<strong>å¹³ç¨³åˆ†å¸ƒ(stationary distribution)</strong>ã€‚</p><p>æ‰€ä»¥ç»“è®ºå°±æ˜¯ï¼š * <strong><span class="math inline">\(\vec r\)</span> çš„å€¼æ˜¯éšæœºæ¼«æ­¥çš„å¹³ç¨³åˆ†å¸ƒ</strong> * ä¸€ä¸ªç½‘é¡µçš„PageRankå¾—åˆ†ä»£è¡¨äº†ä¸€ä¸ªéšæœºæ¼«æ­¥è€…åœ¨æ— é™çš„æ¼«æ­¥è¿‡ç¨‹ä¸­åœ¨æŸä¸ªæ—¶é—´ <span class="math inline">\(t\)</span> å‡ºç°åœ¨è¿™ä¸ªé¡µé¢çš„æ¦‚ç‡ï¼</p><h3><span id="å­˜åœ¨æ€§å’Œå”¯ä¸€æ€§">å­˜åœ¨æ€§å’Œå”¯ä¸€æ€§</span></h3><p>è¿™ä¸ªéšæœºæ¼«æ­¥è¿‡ç¨‹æ˜¯ä¸€ä¸ª<a href="https://www.wikiwand.com/zh-cn/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE" target="_blank" rel="noopener">é©¬å°”ç§‘å¤«è¿‡ç¨‹</a> æ‰€ä»¥æœ‰ï¼š &gt; å¯¹äºæ»¡è¶³<strong>ä¸€å®šæ¡ä»¶</strong>çš„å›¾ï¼Œå…¶<strong>å¹³ç¨³åˆ†å¸ƒæ˜¯å”¯ä¸€</strong>çš„ï¼Œå¹¶ä¸”<strong>ç»ˆå°†ä¼šè¾¾åˆ°å¹³ç¨³åˆ†å¸ƒæ— è®ºåœ¨ <span class="math inline">\(t=0\)</span> æ—¶åˆ»çš„æ¦‚ç‡åˆå§‹å€¼æ˜¯ä»€ä¹ˆ</strong>ã€‚</p><h3><span id="the-google-formulation">The Google Formulation</span></h3><p>ä¸Šé¢è¯´è¦æ»¡è¶³<strong>ä¸€å®šæ¡ä»¶</strong>ï¼Œå…¶å¹³ç¨³åˆ†å¸ƒæ‰ä¼šå”¯ä¸€å¹¶ä¸”æ— è®ºåˆå§‹å€¼æ˜¯ä»€ä¹ˆï¼Œæ¥ä¸‹æ¥å°±è¦æ¢è®¨è¿™ä¸€å®šæ¡ä»¶æ˜¯ä»€ä¹ˆã€‚</p><p>é¦–å…ˆæ¥çœ‹ä¸‰ä¸ªé—®é¢˜ï¼š</p><p>$ r_j^{(t+1)} = _{i j} $ æˆ–è€… $ r = M r $</p><ul><li>è¿™ä¸ªä¸œè¥¿ï¼ˆ<span class="math inline">\(\vec r\)</span>ï¼‰æ˜¯å¦æ”¶æ•›ï¼Ÿ</li><li>è¿™ä¸ªä¸œè¥¿æ˜¯å¦æ”¶æ•›åˆ°æˆ‘ä»¬æœŸå¾…çš„ç»“æœï¼Ÿ</li><li>å¾—åˆ°çš„ç»“æœæ˜¯å¦æœ‰æ„ä¹‰ï¼Ÿ</li></ul><p>æˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªå›ç­”ã€‚</p><h4><span id="does-this-converge">Does this converge?</span></h4><p>èœ˜è››é™·é˜±(Spider trap)ï¼š</p><p>å‡è®¾å›¾ä¸­åªæœ‰ä¸¤ä¸ªèŠ‚ç‚¹Aå’ŒBï¼Œå¦‚å›¾æ‰€ç¤ºï¼š <img src="/images/1451047252190.png" alt="Alt text"> åˆå§‹åŒ– $ r_a = 1, r_b = 0 $ï¼ŒæŒ‰ç…§å…¬å¼è¿­ä»£ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸‹ç»“æœï¼š <img src="/images/1451047369971.png" alt="Alt text"> 0å’Œ1ä¸æ–­åè½¬ï¼Œä¸ä¼šæ”¶æ•›ã€‚å†æ¥çœ‹ä¸‹ä¸€ä¸ªé—®é¢˜ã€‚</p><h4><span id="does-it-converge-to-what-we-want">Does it converge to what we want?</span></h4><p>æ­»èƒ¡åŒé—®é¢˜(Dead end problem)ï¼š</p><p>å‡è®¾å›¾ä¸­åªæœ‰ä¸¤ä¸ªèŠ‚ç‚¹aå’Œbï¼Œå¦‚å›¾æ‰€ç¤ºï¼š <img src="/images/1451047684408.png" alt="Alt text"> åˆå§‹åŒ– $ r_a = 1, r_b = 0 $ï¼Œä»£å…¥å…¬å¼è¿­ä»£å¾—åˆ°ä»¥ä¸‹ç»“æœï¼š <img src="/images/1451047788390.png" alt="Alt text"> æœ€ç»ˆæ”¶æ•›åˆ°0ï¼Œè¿™æ˜¾ç„¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚</p><p>ä¸¤ä¸ªé—®é¢˜æ€»ç»“ä¸€ä¸‹ï¼š <img src="/images/1451047864892.png" alt="Alt text"></p><h3><span id="problem-spider-traps">Problem : Spider Traps</span></h3><p>å‡è®¾æœ‰å›¾ï¼š <img src="/images/1451047965042.png" alt="Alt text"> å…¶é‚»æ¥çŸ©é˜µ <span class="math inline">\(M\)</span> ä¸ºï¼š <img src="/images/1451048025790.png" alt="Alt text"> å¸¦å…¥å…¬å¼è¿­ä»£ï¼Œç»“æœä¸ºï¼š <img src="/images/1451048077292.png" alt="Alt text"></p><p>æœ€ç»ˆï¼Œ<span class="math inline">\(r_m = 1\)</span> è€Œ $r_y = r_a = 0 $ ã€‚è¿™ä»æ¼«æ­¥è€…çš„è§’åº¦å¾ˆå¥½ç†è§£ï¼Œåœ¨ç»è¿‡ä¸€æ®µæ—¶é—´ä¹‹åï¼Œæ¼«æ­¥è€…åˆ°è¾¾äº† <span class="math inline">\(m\)</span> èŠ‚ç‚¹ï¼Œç„¶è€Œ <span class="math inline">\(m\)</span> èŠ‚ç‚¹åªæœ‰æŒ‡å‘è‡ªå·±çš„é“¾æ¥ï¼Œç„¶åå°±åªèƒ½ä¸€ç›´åœç•™åœ¨ <span class="math inline">\(m\)</span> ï¼Œæ‰€ä»¥æœ€åçš„æ¦‚ç‡ä¸€å®šæ˜¯1, è€Œå…¶ä»–ä¸¤ä¸ªèŠ‚ç‚¹çš„æ¦‚ç‡å°±å˜æˆäº†0 ã€‚</p><p><em>è§£å†³æ–¹æ¡ˆ</em></p><p><strong>éšæœºä¼ é€ Random Teleports</strong></p><p>Googleè§£å†³è¿™ä¸ªé—®é¢˜çš„åŠæ³•æ˜¯ï¼šåˆ°è¾¾æŸä¸ªèŠ‚ç‚¹å * æœ‰ <span class="math inline">\(\beta\)</span> çš„æ¦‚ç‡éšæœºæ‰¾ä¸€ä¸ªé“¾æ¥è¿‡å» * å‰©ä¸‹ <span class="math inline">\(1-\beta\)</span> çš„æ¦‚ç‡è·³åˆ°ä¸€ä¸ªéšæœºçš„é¡µé¢ * ä¸€èˆ¬ <span class="math inline">\(\beta\)</span> çš„å€¼åœ¨ <span class="math inline">\(0.8\)</span> åˆ° <span class="math inline">\(0.9\)</span> ä¹‹é—´</p><p>è¿™æ ·å°±ä½¿å¾—æ¼«æ­¥è€…åœ¨åˆ°è¾¾mèŠ‚ç‚¹ä¹‹åæœ‰ä¸€å®šçš„æ¦‚ç‡è·³å‡ºå»ï¼ <img src="/images/1451048656880.png" alt="Alt text"></p><h3><span id="problem-dead-ends">Problem : Dead Ends</span></h3><p>å‡è®¾æœ‰å›¾ï¼š <img src="/images/1451048764950.png" alt="Alt text"> å…¶é‚»æ¥çŸ©é˜µä¸ºï¼š <img src="/images/1451048788083.png" alt="Alt text"> ç”±äºmèŠ‚ç‚¹æ²¡æœ‰é“¾æ¥åˆ°å…¶ä»–ç•Œé¢ï¼Œæ‰€ä»¥mçš„é‚£ä¸€åˆ—éƒ½ç­‰äºé›¶ã€‚ ä»£å…¥å…¬å¼è¿­ä»£ï¼Œå¾—åˆ°ç»“æœï¼š <img src="/images/1451048888879.png" alt="Alt text"></p><p>æ¼«æ­¥è€…åˆ°è¾¾mä¹‹åå‘ç°æ˜¯æ­»èƒ¡åŒï¼Œæ— è·¯å¯èµ°äº†ï¼Œç„¶è€Œä»–ä¹Ÿä¸ä¼šåœ¨måœç•™ï¼Œæ‰€ä»¥æœ€åå‡ºç°åœ¨ä¸‰ä¸ªèŠ‚ç‚¹çš„æ¦‚ç‡éƒ½ç­‰äº0 ã€‚</p><p><em>è§£å†³æ–¹æ¡ˆ</em></p><p>ä¾æ—§æ˜¯<strong>ä¼ é€</strong>ï¼</p><p>å½“æ¼«æ­¥è€…åˆ°è¾¾æ­»èƒ¡åŒæ—¶ï¼Œä¼ é€çš„æ¦‚ç‡å˜ä¸º <span class="math inline">\(1.0\)</span> ï¼Œéšæœºä¼ é€åˆ°ä»»æ„é¡µé¢ï¼Œç„¶åå›¾å°±å˜æˆäº†å¦‚ä¸‹ï¼š <img src="/images/1451049151567.png" alt="Alt text"> é‚»æ¥çŸ©é˜µå˜ä¸ºï¼š <img src="/images/1451049212444.png" alt="Alt text"></p><p>è¿™æ ·é—®é¢˜å°±è§£å†³äº†ï¼Œæ¼«æ­¥è¿™æ¯æ¬¡åˆ°mä¹‹åï¼Œå‘ç°å»æ‰€æœ‰é¡µé¢çš„æ¦‚ç‡éƒ½ç›¸åŒä¸”ä¸ä¸ºé›¶ï¼Œç›¸å½“äºéšæœºè·³è½¬åˆ°ä¸€ä¸ªé¡µé¢ã€‚</p><h3><span id="ä¸ºä»€ä¹ˆä¼ é€å¯ä»¥è§£å†³è¿™äº›é—®é¢˜">ä¸ºä»€ä¹ˆä¼ é€å¯ä»¥è§£å†³è¿™äº›é—®é¢˜ï¼Ÿ</span></h3><p>æˆ‘ä»¬çŸ¥é“æ±‚è§£PageRankçš„è¿‡ç¨‹å®é™…ä¸Šæ˜¯ä¸€ä¸ªé©¬å°”ç§‘å¤«è¿‡ç¨‹ï¼Œä¹Ÿå«é©¬å°”ç§‘å¤«é“¾ã€‚</p><p><strong>é©¬å°”ç§‘å¤«é“¾(Markov chains)</strong>ï¼š * æ‹¥æœ‰ä¸€ç»„çŠ¶æ€ <span class="math inline">\(X\)</span> * è½¬ç§»çŸ©é˜µ <span class="math inline">\(P\)</span> ï¼Œä¸” <span class="math inline">\(P_{ij} = P(X_t=i | X_{t-1} = j)\)</span>ï¼Œ<span class="math inline">\(P_{ij}\)</span> çš„æ„æ€å°±æ˜¯å·²çŸ¥ä¸Šä¸€æ­¥åœ¨ <span class="math inline">\(j\)</span>ï¼Œç°åœ¨è¿™æ­¥åœ¨ <span class="math inline">\(i\)</span> çš„æ¦‚ç‡ * <span class="math inline">\(\pi\)</span> æ˜¯æ¯ä¸ªçŠ¶æ€ <span class="math inline">\(x\)</span> ç‰¹å®šçš„å¹³ç¨³åˆ†å¸ƒ * ç›®æ ‡å°±æ˜¯æ‰¾åˆ° <span class="math inline">\(\pi\)</span> ä½¿å¾— <span class="math inline">\(\pi = P \pi\)</span></p><p><strong>æ¡ä»¶</strong>ï¼š å¯¹äº<strong>ä»»æ„çš„åˆå§‹å‘é‡</strong>ï¼Œåªè¦é©¬å°”ç§‘å¤«è½¬ç§»çŸ©é˜µ <span class="math inline">\(P\)</span> æ»¡è¶³<strong>éšæœºçš„(stochastic)</strong>ï¼Œ<strong>ä¸å¯çº¦çš„(irreducible)</strong>å’Œ<strong>éå‘¨æœŸçš„(aperiodic)</strong>ï¼Œé‚£ä¹ˆå¯¹çŸ©é˜µ <span class="math inline">\(P\)</span> åº”ç”¨å¹‚è¿­ä»£å°±ä¸€å®šä¼šæ”¶æ•›åˆ°ä¸€ä¸ªä¸å˜çš„å‘é‡ã€‚</p><p>æˆ‘ä»¬æ¥è®¨è®ºä¸€ä¸‹ä¸ºä»€ä¹ˆéšæœºä¼ é€å¯ä»¥è®©çŸ©é˜µ <span class="math inline">\(M\)</span> æ»¡è¶³ä¸Šè¿°æ¡ä»¶ã€‚</p><h4><span id="make-m-stochastic">Make M Stochastic</span></h4><p><strong>éšæœº(Stochastic)</strong>çš„æ„æ€å°±æ˜¯æ¯åˆ—çš„å’ŒåŠ èµ·æ¥ç­‰äº<span class="math inline">\(1\)</span></p><p>æˆ‘ä»¬çŸ¥é“ä¸‹é¢çš„å›¾ä¼šé€ æˆæ­»èƒ¡åŒé—®é¢˜(Dead End)ï¼š <img src="/images/1451048764950.png" alt="Alt text"> å¦‚æœè®©å…¶åœ¨æ²¡æœ‰å‡ºåº¦çš„èŠ‚ç‚¹å¯ä»¥éšæœºè·³è½¬åˆ°ä»»æ„èŠ‚ç‚¹çš„è¯å°±ç›¸å½“ä¸åœ¨ <span class="math inline">\(m\)</span> èŠ‚ç‚¹ä¸Šæ–°åŠ äº†å‡ æ¡è¾¹ï¼š <img src="/images/1451132954313.png" alt="Alt text"> è¿™æ · <span class="math inline">\(m\)</span> çš„å‡ºåº¦å°±å˜æˆäº†3ï¼ŒçŸ©é˜µ <span class="math inline">\(M\)</span> ä¹Ÿå˜æˆäº†ï¼š <img src="/images/1451133022738.png" alt="Alt text"> ç°åœ¨ <span class="math inline">\(M\)</span> çŸ©é˜µå°±æ»¡è¶³äº†éšæœºæ€§ï¼Œæ¯åˆ—çš„å’Œéƒ½ç­‰äº <span class="math inline">\(1\)</span>ã€‚</p><p>æˆ‘ä»¬æŠŠæ–°çŸ©é˜µè®°åš <span class="math inline">\(A\)</span>ï¼Œæœ‰å¦‚ä¸‹è®¡ç®—å…¬å¼ï¼š &gt; $ A = M + a^T(e) $</p><p>å¦‚æœèŠ‚ç‚¹ <span class="math inline">\(i\)</span> æ²¡æœ‰å‡ºåº¦åˆ™ <span class="math inline">\(a_i=1\)</span>ï¼Œå¦åˆ™ <span class="math inline">\(a_i=0\)</span> ; $ e$ æ˜¯å•ä½è¡Œå‘é‡ã€‚</p><h4><span id="make-m-aperiodic">Make M Aperiodic</span></h4><p><strong>å‘¨æœŸæ€§(periodic)</strong>å®šä¹‰ï¼šå¦‚æœå­˜åœ¨ä¸€ä¸ª $k&gt;1 $ ä½¿å¾—ä¸¤æ¬¡åˆ°è¾¾åŒä¸€ä¸ªçŠ¶æ€çš„é—´éš”æ€»æ˜¯ <span class="math inline">\(k\)</span> çš„æ•´æ•°å€ï¼Œé‚£ä¹ˆè¿™æ¡é“¾å°±æ˜¯å…·æœ‰å‘¨æœŸæ€§çš„ã€‚</p><figure><img src="/images/1451134156887.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>ä¸Šå›¾å°±æ˜¯ä¸€ä¸ªå…·æœ‰å‘¨æœŸæ€§çš„é“¾ï¼Œæ¯éš”ä¸¤æ­¥å°±ä¼šå›åˆ°åŒä¸€çŠ¶æ€ã€‚ åŠ ä¸Šéšæœºä¼ é€å°±å˜æˆäº†ï¼š <img src="/images/1451134263267.png" alt="Alt text"> è¿™æ ·ä¸è®ºæ¯éš”å¤šå°‘æ­¥ä¹Ÿä¸ä¸€å®šä¼šå›åˆ°åŒä¸€çŠ¶æ€ï¼Œå³<strong>ä¸å…·æœ‰å‘¨æœŸæ€§</strong>ã€‚</p><h4><span id="make-m-irreducible">Make M Irreducible</span></h4><p><strong>ä¸å¯çº¦(Irreducible)</strong>çš„æ„æ€æ˜¯ï¼šå¯¹äºä»»ä½•çŠ¶æ€ï¼Œéƒ½æœ‰ä»è¿™ä¸ªçŠ¶æ€è·³åˆ°ä»»æ„å¦ä¸€ä¸ªçŠ¶æ€çš„å¯èƒ½æ€§ã€‚</p><p>å¦‚å›¾ï¼Œå…¶ä¸­ç»¿è‰²çš„çº¿æ˜¯åŠ ä¸Šéšæœºè·³è½¬ä¹‹åï¼š <img src="/images/1451134621312.png" alt="Alt text"></p><h3><span id="random-jumps">Random Jumps</span></h3><p>ä»å‰é¢çš„åˆ†æå¯çŸ¥ï¼Œéšæœºè·³è½¬å¯ä»¥æ˜¯ <span class="math inline">\(M\)</span> æ»¡è¶³éšæœºã€éå‘¨æœŸå’Œä¸å¯çº¦çš„æ€§è´¨ï¼Œè¿™å°±æ˜¯Googleçš„è§£å†³æ–¹æ¡ˆã€‚</p><ul><li>åœ¨æ¯ä¸€æ­¥ï¼Œæ¼«æ­¥è€…æœ‰ä¸¤ä¸ªé€‰æ‹©ï¼š<ul><li><span class="math inline">\(\beta\)</span> çš„å¯èƒ½æ€§éšæœºé€‰ä¸€ä¸ªé“¾æ¥</li><li><span class="math inline">\(1-\beta\)</span> çš„å¯èƒ½æ€§è·³è½¬åˆ°éšæœºé¡µé¢</li></ul></li></ul><p><strong>PageRank è®¡ç®—æ–¹ç¨‹</strong> å°±å˜æˆäº†ï¼š &gt; $ r_j = _{i j}  + (1-) $</p><p>å…¶ä¸­ <span class="math inline">\(\sum _{i \to j} \beta \frac{r_i}{d_i}\)</span> æ˜¯å…·æœ‰ <span class="math inline">\(\beta\)</span> çš„æ¦‚ç‡éšæœºé€‰æ‹©ä¸€ä¸ªé“¾æ¥ï¼Œ<span class="math inline">\((1-\beta)\frac{1}{n}\)</span> æ˜¯ <span class="math inline">\(1-\beta\)</span> çš„æ¦‚ç‡è·³è½¬åˆ°éšæœºé¡µé¢ï¼Œå…¶ä¸­ <span class="math inline">\(n\)</span> æ˜¯å›¾ä¸­èŠ‚ç‚¹ä¸ªæ•°ã€‚</p><p>æˆ‘ä»¬è¿˜æ‰“ç®—ç”¨å¹‚è¿­ä»£æ–¹æ³•è®¡ç®—PageRankï¼Œæ‰€ä»¥è¿˜éœ€è¦å˜æˆçŸ©é˜µå½¢å¼ã€‚</p><p><strong>The Google Matrix A</strong> &gt; $ A = M + (1 - ) e e^T $</p><p><strong>What is <span class="math inline">\(\beta\)</span> ?</strong> å®è·µè¡¨æ˜ <span class="math inline">\(\beta\)</span> å–åœ¨ $0.8 $~ <span class="math inline">\(0.9\)</span> ä¹‹é—´è¾ƒå¥½ï¼Œå…¶ä¸­ <span class="math inline">\(\beta=0.85\)</span> æ—¶æ¯éš”äº”æ­¥è·³è½¬ä¸€æ¬¡ã€‚</p><p>è¿˜æ˜¯ä¸¾ä¹‹å‰é‚£ä¸ªä¾‹å­ã€‚ã€‚ã€‚ å›¾ä¸ºï¼š <img src="/images/1451135546704.png" alt="Alt text"></p><p>çŸ©é˜µ <span class="math inline">\(\beta M\)</span> ä¸ºï¼š <img src="/images/1451135595638.png" alt="Alt text"></p><p>è·³è½¬çŸ©é˜µä¸ºï¼š <img src="/images/1451135650772.png" alt="Alt text"></p><p>æ‰€ä»¥GoogleçŸ©é˜µ <span class="math inline">\(A\)</span> å°±æ˜¯å®ƒä»¬çš„å’Œï¼š <img src="/images/1451135678520.png" alt="Alt text"></p><p>è¿›è¡Œå¹‚è¿­ä»£ï¼Œç»“æœä¸ºï¼š <img src="/images/1451135730531.png" alt="Alt text"></p><p>å¯è§ï¼Œä¿®æ­£ä¹‹åçš„PageRankä¾æ—§æ˜¯måˆ†æœ€é«˜ï¼Œä½†ä¹Ÿä¸ä¼šæœ‰èœ˜è››é™·é˜±çš„é—®é¢˜ï¼Œæ¯”è¾ƒå®Œç¾ï¼</p><h3><span id="å®é™…ä¸Šæ˜¯å¦‚ä½•è®¡ç®—pagerankçš„">å®é™…ä¸Šæ˜¯å¦‚ä½•è®¡ç®—PageRankçš„ï¼Ÿ</span></h3><p>è®¡ç®—PageRankå°±æ˜¯ä¸€ä¸ªå¹‚è¿­ä»£çš„è¿‡ç¨‹ï¼ŒæŒ‰ç…§å…¬å¼ï¼š <span class="math inline">\(r^{new} = A \cdot r^{old}\)</span>ï¼Œçœ‹ä¼¼å¾ˆç®€å•ã€‚</p><p>å¦‚æœæˆ‘ä»¬æœ‰è¶³å¤Ÿçš„å†…å­˜æ¥è£…ä¸‹ <span class="math inline">\(A, r^{old}, r^{new}\)</span> çš„è¯ç¡®å®å¾ˆç®€å•ï¼Œæˆ‘ä»¬æ¥ç®—ä¸€ä¸‹åˆ°åº•å¤Ÿä¸å¤Ÿã€‚</p><p>å‡è®¾æœ‰ <span class="math inline">\(N = 1 Ã— 10^{9}\)</span> ä¸ªç½‘é¡µï¼Œå­˜æ¯ä¸ªç½‘é¡µåªéœ€è¦4ä¸ªå­—èŠ‚ï¼Œå³åªå­˜ä¸€ä¸ªèŠ‚ç‚¹IDï¼Œé‚£ä¹ˆå­˜å‚¨åœ°å€+IDå°±éœ€è¦ 2 billion * 4 byteï¼Œçº¦ç­‰äº8GB</p><p>å¦‚æœè¦å­˜å‚¨çŸ©é˜µAï¼Œéœ€è¦å­˜å‚¨ <span class="math inline">\(N^2\)</span> ä¸ªåœ°å€+IDï¼Œå¤§æ¦‚éœ€è¦ <span class="math inline">\(10^{18}\)</span> å­—èŠ‚è¿™ä¸ªæ•°é‡çº§çš„å†…å­˜ç©ºé—´ï¼Œæ˜¾ç„¶æ˜¯æ²¡æœ‰é‚£ä¹ˆå¤§çš„ï¼</p><p>æˆ‘ä»¬è€ƒè™‘çŸ©é˜µ <span class="math inline">\(M\)</span> çš„å€¼çš„åˆ†å¸ƒï¼Œ å¦‚æœ $ j i $ é‚£ä¹ˆ $ M_{ij} = 1/|d_j| $ ï¼Œå¦åˆ™ $ M_{ij} = 0 $ï¼Œå®é™…æƒ…å†µæ˜¯æ¯ä¸ªç½‘é¡µä¸€èˆ¬åªæœ‰10ä¸ªåˆ°100ä¸ªé“¾æ¥ï¼Œå³ä½¿æ•´ä¸ªwebæœ‰1 billion+ ä¸ªç½‘é¡µï¼Œæ‰€ä»¥çŸ©é˜µ <span class="math inline">\(M\)</span> å¤§éƒ¨åˆ†å€¼éƒ½ä¸º0ï¼Œæå°‘æ•°å€¼é0 ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä»…å­˜å‚¨éé›¶å€¼æ¥æå¤§åœ°å‡å°‘æ‰€éœ€å­˜å‚¨ç©ºé—´ã€‚</p><p>è€ŒçŸ©é˜µ <span class="math inline">\(A\)</span> å°±ä¸ä¸€æ ·äº†ï¼Œ$ A = M + (1 - ) e e^T $ï¼Œæ¯ä¸ªå€¼éƒ½æ˜¯éé›¶çš„ï¼Œå› ä¸ºçŸ©é˜µ <span class="math inline">\(M\)</span> ä¸­ç­‰äº0çš„æƒ…å†µåœ¨ <span class="math inline">\(A\)</span> ä¸­éƒ½è¢«èµ‹äºˆäº†éšæœºè·³è½¬åˆ°ä»»æ„èŠ‚ç‚¹çš„å¯èƒ½æ€§ã€‚</p><p>ç”±äº <span class="math inline">\(A\)</span> ä¸èƒ½ç›´æ¥æ”¾åœ¨å†…å­˜é‡Œè®¡ç®—ï¼Œè€Œ <span class="math inline">\(M\)</span> å¯ä»¥ï¼Œæ‰€ä»¥è¦æƒ³æ–¹è®¾æ³•æŠŠ <span class="math inline">\(A\)</span> çš„è¿­ä»£å˜æˆ <span class="math inline">\(M\)</span> çš„è¿­ä»£ã€‚</p><h4><span id="å…¬å¼å˜å½¢">å…¬å¼å˜å½¢</span></h4><p>åŸå…¬å¼ä¸ºï¼š$ r = A r $ å…¶ä¸­ $A_{ij} = M_{ij} +  $</p><p>æŠŠå®ƒå±•å¼€ï¼š <span class="math inline">\(r_i = \sum_{j=1}^{N}A_{ij} \cdot r_j\)</span> <img src="/images/1451140624364.png" alt="Alt text"></p><p>æœ€åæˆ‘ä»¬å¾—åˆ°ï¼š &gt; $ r = M r + []_N $</p><p>è¿™é‡Œå‡è®¾ <span class="math inline">\(M\)</span> ä¸­æ²¡æœ‰dead-endsï¼Œå…¶ä¸­ <span class="math inline">\([x]_n\)</span> è¡¨ç¤ºä¸€ä¸ªé¡¹å…¨éƒ¨ä¸º <span class="math inline">\(x\)</span> çš„å‘é‡ã€‚</p><p>ç»è¿‡äº†è¿™æ ·çš„å˜å½¢ï¼Œæˆ‘ä»¬åœ¨æ¯æ¬¡è¿­ä»£ä¸­åªéœ€è¦ï¼š * è®¡ç®— $ r^{new} = M r^{old}$ * åœ¨ <span class="math inline">\(r^{new}\)</span> çš„æ¯ä¸€é¡¹ä¸ŠåŠ ä¸Šå¸¸é‡ $ (1-)/N$ * å¦‚æœ <span class="math inline">\(M\)</span> ä¸­æœ‰dead-end çš„è¯ï¼Œé‚£ä¹ˆ $_i r_i^{new} &lt; 1 $ ï¼Œæˆ‘ä»¬è¿˜éœ€è¦é‡æ–°åˆ†é…ä¸€ä¸‹ä½™ä¸‹éƒ¨åˆ†ï¼Œä½¿å…¶å’Œç­‰äº1.</p><h4><span id="æœ€ç»ˆçš„ç®—æ³•">æœ€ç»ˆçš„ç®—æ³•</span></h4><ul><li>è¾“å…¥ ï¼š å›¾ <span class="math inline">\(G\)</span> å’Œ å‚æ•° <span class="math inline">\(\beta\)</span><ul><li><span class="math inline">\(G\)</span> æ˜¯æœ‰å‘å›¾è€Œä¸”å¯ä»¥æœ‰ <strong>spider traps</strong> å’Œ <strong>dead ends</strong></li><li>æ¦‚ç‡å‚æ•° <span class="math inline">\(\beta\)</span></li></ul></li><li>è¾“å‡ºï¼šPagerank å‘é‡ <span class="math inline">\(\vec r\)</span> <img src="/images/1451141342964.png" alt="Alt text"></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•°æ®æŒ–æ˜ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>è®°å½•ï¼šå¾®ä¿¡åå°å¼€å‘</title>
      <link href="/2015/12/26/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%BE%AE%E4%BF%A1%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
      <url>/2015/12/26/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%BE%AE%E4%BF%A1%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<p>å¾®ä¿¡æ¥å£æ–‡æ¡£ http://mp.weixin.qq.com/wiki/home/index.html æµ‹è¯•å· http://mp.weixin.qq.com/debug/cgi-bin/sandbox?t=sandbox/login</p><a id="more"></a><h3><span id="memcacheç¼“å­˜access_token">Memcacheç¼“å­˜access_token</span></h3><p><a href="http://www.liuhe.website/index.php?/Articles/single/15" target="_blank" rel="noopener">Memcacheå®‰è£…ä¸é…ç½®</a></p><h3><span id="é€šè¿‡curlå‘èµ·httpè¯·æ±‚">é€šè¿‡cURLå‘èµ·httpè¯·æ±‚</span></h3><p>phpæ‰‹å†Œ http://php.net/manual/zh/book.curl.php</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">function</span> <span class="title">http_request</span><span class="params">($url)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    $ch = curl_init(); <span class="comment">// åˆå§‹åŒ–</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_URL, $url); <span class="comment">// éœ€è¦è·å–çš„URLåœ°å€</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_CUSTOMREQUEST, <span class="string">"GET"</span>); <span class="comment">// getçš„æ–¹å¼</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, <span class="keyword">false</span>); <span class="comment">// ä¿¡ä»»ä»»ä½•è¯ä¹¦</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, <span class="keyword">false</span>); <span class="comment">// ä¸è¿›è¡Œä»»ä½•éªŒè¯</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_RETURNTRANSFER, <span class="number">1</span>); <span class="comment">// å°†curl_exec()è·å–çš„ä¿¡æ¯ä»¥æ–‡ä»¶æµçš„å½¢å¼è¿”å›ï¼Œè€Œä¸æ˜¯ç›´æ¥è¾“å‡º</span></span><br><span class="line">    $output = curl_exec($ch); <span class="comment">// å‘å‡ºè¯·æ±‚</span></span><br><span class="line">    curl_close($ch); <span class="comment">// å…³é—­cURL</span></span><br><span class="line">    <span class="keyword">return</span> $output;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="å¤„ç†jsonæ•°æ®">å¤„ç†JSONæ•°æ®</span></h3><p><a href="http://www.liuhe.website/index.php?/Articles/single/7" target="_blank" rel="noopener">åœ¨phpè¯­è¨€ä¸­ä½¿ç”¨json</a></p><h3><span id="è§£æxml">è§£æxml</span></h3><h4><span id="xml_parser">xml_parser</span></h4><p>phpæ‰‹å†Œ http://php.net/manual/zh/book.xml.php</p><p>å»ºç«‹XMLè§£æå™¨ï¼š<code>$p = xml_parser_creat()</code> å¼€å§‹è§£æä¸€ä¸ªXMLæ–‡æ¡£ : <code>xml_parse($data)</code> å°†XMLè§£æåˆ°æ•°ç»„ : <code>xml_parse_into_struct($p, $data, $vals, $index)</code> é‡Šæ”¾è§£é‡Šå™¨ï¼š<code>xml_parser_free($p)</code> <del>ä½†æ˜¯ç”¨è¿™ä¸ªæ–¹æ³•è§£æå¾®ä¿¡å‘æ¥çš„æ•°æ®åŒ…å¤±è´¥äº†</del></p><h4><span id="simplexmlelement">SimpleXMLElement</span></h4><p>phpæ‰‹å†Œ http://php.net/manual/zh/class.simplexmlelement.php</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// è§£ææˆå…³è”æ•°ç»„</span></span><br><span class="line">$msg = (<span class="keyword">array</span>) simplexml_load_string($data, <span class="string">'SimpleXMLElement'</span>, LIBXML_NOCDATA);</span><br></pre></td></tr></table></figure><h4><span id="èœå•çš„clickäº‹ä»¶å“åº”å¤±è´¥">èœå•çš„CLICKäº‹ä»¶å“åº”å¤±è´¥</span></h4><p>æœªçŸ¥</p><h4><span id="å›¾æ–‡ç´ æä¸Šä¼ ä¹‹ååªå‰©å›¾äº†">å›¾æ–‡ç´ æä¸Šä¼ ä¹‹ååªå‰©å›¾äº†</span></h4><p>å› ä¸ºå†…å®¹å­—ç¬¦æ•°è¶…äº†ï¼Œæ¢äº†çŸ­ä¸€ç‚¹çš„å°±å¯ä»¥äº†ã€‚</p><h2><span id="js-sdk">js-sdk</span></h2><p>åŸŸååªéœ€è¦å¡«åˆ°<code>.com</code>ä¹‹ç±»çš„ï¼Œåé¢ä¸ç”¨ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> PHP </tag>
            
            <tag> Wechat </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>å®‰è£…Memcache</title>
      <link href="/2015/12/24/%E5%AE%89%E8%A3%85Memcache/"/>
      <url>/2015/12/24/%E5%AE%89%E8%A3%85Memcache/</url>
      
        <content type="html"><![CDATA[<p>http://php.net/manual/zh/book.memcache.php</p><a id="more"></a><blockquote><p>æœåŠ¡å™¨ç«¯ä¸»è¦æ˜¯å®‰è£…memcacheæœåŠ¡å™¨ç«¯ï¼Œç›®å‰çš„æœ€æ–°ç‰ˆæœ¬æ˜¯ memcached-1.3.0 ã€‚ ä¸‹è½½ï¼šhttp://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz å¦å¤–ï¼ŒMemcacheç”¨åˆ°äº†libeventè¿™ä¸ªåº“ç”¨äºSocketçš„å¤„ç†ï¼Œæ‰€ä»¥è¿˜éœ€è¦å®‰è£…libeventï¼Œlibeventçš„æœ€æ–°ç‰ˆæœ¬æ˜¯libevent-1.3ã€‚ï¼ˆå¦‚æœä½ çš„ç³»ç»Ÿå·²ç»å®‰è£…äº†libeventï¼Œå¯ä»¥ä¸ç”¨å®‰è£…ï¼‰ å®˜ç½‘ï¼šhttp://www.monkey.org/<sub>provos/libevent/ ä¸‹è½½ï¼šhttp://www.monkey.org/</sub>provos/libevent-1.3.tar.gz</p></blockquote><p>ç”¨wgetæŒ‡ä»¤ç›´æ¥ä¸‹è½½è¿™ä¸¤ä¸ªä¸œè¥¿.ä¸‹è½½å›æºæ–‡ä»¶åã€‚ 1. å…ˆå®‰è£…libeventã€‚è¿™ä¸ªä¸œè¥¿åœ¨é…ç½®æ—¶éœ€è¦æŒ‡å®šä¸€ä¸ªå®‰è£…è·¯å¾„ï¼Œå³<code>./configure â€“prefix=/usr</code>ï¼›ç„¶å<code>make</code>ï¼›ç„¶å<code>make install</code>ï¼› 2. å†å®‰è£…memcachedï¼Œåªæ˜¯éœ€è¦åœ¨é…ç½®æ—¶éœ€è¦æŒ‡å®šlibeventçš„å®‰è£…è·¯å¾„å³<code>./configure â€“with-libevent=/usr</code>ï¼›ç„¶å<code>make &amp;&amp; make install</code>ï¼› è¿™æ ·å°±å®Œæˆäº†Linuxä¸‹MemcacheæœåŠ¡å™¨ç«¯çš„å®‰è£…ã€‚è¯¦ç»†çš„æ–¹æ³•å¦‚ä¸‹ï¼š</p><h4><span id="åˆ†åˆ«æŠŠmemcachedå’Œlibeventä¸‹è½½å›æ¥æ”¾åˆ°-tmp-ç›®å½•ä¸‹">åˆ†åˆ«æŠŠmemcachedå’Œlibeventä¸‹è½½å›æ¥ï¼Œæ”¾åˆ° <code>/tmp</code> ç›®å½•ä¸‹ï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cd /tmp</span><br><span class="line"># wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz</span><br><span class="line"># wget http://www.monkey.org/~provos/libevent-1.2.tar.gz</span><br></pre></td></tr></table></figure><h4><span id="å…ˆå®‰è£…libevent">å…ˆå®‰è£…libeventï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># tar zxvf libevent-1.2.tar.gz</span><br><span class="line"># cd libevent-1.2</span><br><span class="line"># ./configure â€“prefix=/usr</span><br><span class="line"># make</span><br><span class="line"># make install</span><br></pre></td></tr></table></figure><h4><span id="æµ‹è¯•libeventæ˜¯å¦å®‰è£…æˆåŠŸ">æµ‹è¯•libeventæ˜¯å¦å®‰è£…æˆåŠŸï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ls -al /usr/lib | grep libevent</span><br><span class="line">lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -&gt; libevent-1.2.so.1.0.3</span><br><span class="line">-rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3</span><br><span class="line">-rw-râ€“râ€“ 1 root root 454156 11?? 12 17:38 libevent.a</span><br><span class="line">-rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la</span><br><span class="line">lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -&gt; libevent-1.2.so.1.0.3</span><br></pre></td></tr></table></figure><h4><span id="å®‰è£…memcachedåŒæ—¶éœ€è¦å®‰è£…ä¸­æŒ‡å®šlibeventçš„å®‰è£…ä½ç½®">å®‰è£…memcachedï¼ŒåŒæ—¶éœ€è¦å®‰è£…ä¸­æŒ‡å®šlibeventçš„å®‰è£…ä½ç½®ï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># cd /tmp</span><br><span class="line"># tar zxvf memcached-1.2.0.tar.gz</span><br><span class="line"># cd memcached-1.2.0</span><br><span class="line"># ./configure â€“with-libevent=/usr</span><br><span class="line"># make</span><br><span class="line"># make install</span><br></pre></td></tr></table></figure><h4><span id="æµ‹è¯•æ˜¯å¦æˆåŠŸå®‰è£…memcached">æµ‹è¯•æ˜¯å¦æˆåŠŸå®‰è£…memcachedï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># ls -al /usr/local/bin/mem*</span><br><span class="line">-rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached</span><br><span class="line">-rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug</span><br></pre></td></tr></table></figure><h3><span id="å®‰è£…memcacheçš„phpæ‰©å±•">å®‰è£…Memcacheçš„PHPæ‰©å±•</span></h3><h4><span id="åœ¨httppeclphpnetpackagememcache-é€‰æ‹©ç›¸åº”æƒ³è¦ä¸‹è½½çš„memcacheç‰ˆæœ¬">åœ¨http://pecl.php.net/package/memcache é€‰æ‹©ç›¸åº”æƒ³è¦ä¸‹è½½çš„memcacheç‰ˆæœ¬ã€‚</span></h4><h4><span id="å®‰è£…phpçš„memcacheæ‰©å±•">å®‰è£…PHPçš„memcacheæ‰©å±•</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar vxzf memcache-2.2.1.tgz</span><br><span class="line">cd memcache-2.2.1</span><br><span class="line">/usr/local/php/bin/phpize</span><br><span class="line">./configure --enable-memcache --with-php-config=/usr/bin/php-config --with-zlib-dir</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">// è‹¥ phpizeæ²¡æœ‰æ‰¾åˆ°</span><br><span class="line">// è§£å†³æ–¹æ³•ï¼š</span><br><span class="line">yum install php-devel</span><br></pre></td></tr></table></figure><h4><span id="ä¸Šè¿°å®‰è£…å®Œåä¼šæœ‰ç±»ä¼¼è¿™æ ·çš„æç¤º">ä¸Šè¿°å®‰è£…å®Œåä¼šæœ‰ç±»ä¼¼è¿™æ ·çš„æç¤ºï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Installing shared extensions: </span><br><span class="line">/...</span><br><span class="line">/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/</span><br></pre></td></tr></table></figure><h4><span id="æŠŠphpiniä¸­çš„extension_dir-ä¿®æ”¹ä¸º">æŠŠphp.iniä¸­çš„extension_dir = â€œ./â€ä¿®æ”¹ä¸º</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">extension_dir = â€œ/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/â€</span><br></pre></td></tr></table></figure><h4><span id="æ·»åŠ ä¸€è¡Œæ¥è½½å…¥memcacheæ‰©å±•">æ·»åŠ ä¸€è¡Œæ¥è½½å…¥memcacheæ‰©å±•ï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">extension=memcache.so</span><br></pre></td></tr></table></figure><h3><span id="memcachedçš„åŸºæœ¬è®¾ç½®">memcachedçš„åŸºæœ¬è®¾ç½®</span></h3><h4><span id="å¯åŠ¨memcacheçš„æœåŠ¡å™¨ç«¯">å¯åŠ¨Memcacheçš„æœåŠ¡å™¨ç«¯ï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># /usr/local/bin/memcached -d -m 10 -u root -l 127.0.0.1 -p 12000 -c 256 -P /tmp/memcached.pid</span><br><span class="line"></span><br><span class="line">è‹¥å‡ºç°é”™è¯¯ï¼š/usr/local/bin/memcached: error while loading shared libraries: libevent-1.3.so.1: cannot open shared object file: No such file or directory</span><br><span class="line"></span><br><span class="line">ç›´æ¥è®¾ç½®é“¾æ¥</span><br><span class="line"></span><br><span class="line">#ln -s /usr/local/libevent/lib/libevent-1.3.so.1 /lib64/libevent-1.3.so.1</span><br></pre></td></tr></table></figure><blockquote><ul><li>-dé€‰é¡¹æ˜¯å¯åŠ¨ä¸€ä¸ªå®ˆæŠ¤è¿›ç¨‹ï¼Œ</li><li>-mæ˜¯åˆ†é…ç»™Memcacheä½¿ç”¨çš„å†…å­˜æ•°é‡ï¼Œå•ä½æ˜¯MBï¼Œæˆ‘è¿™é‡Œæ˜¯10MBï¼Œ</li><li>-uæ˜¯è¿è¡ŒMemcacheçš„ç”¨æˆ·ï¼Œæˆ‘è¿™é‡Œæ˜¯rootï¼Œ</li><li>-læ˜¯ç›‘å¬çš„æœåŠ¡å™¨IPåœ°å€</li><li>-pæ˜¯è®¾ç½®Memcacheç›‘å¬çš„ç«¯å£ï¼Œæˆ‘è¿™é‡Œè®¾ç½®äº†12000ï¼Œæœ€å¥½æ˜¯1024ä»¥ä¸Šçš„ç«¯å£ï¼Œ</li><li>-cé€‰é¡¹æ˜¯æœ€å¤§è¿è¡Œçš„å¹¶å‘è¿æ¥æ•°ï¼Œé»˜è®¤æ˜¯1024ï¼Œæˆ‘è¿™é‡Œè®¾ç½®äº†256ï¼ŒæŒ‰ç…§ä½ æœåŠ¡å™¨çš„è´Ÿè½½é‡æ¥è®¾å®šï¼Œ</li><li>-Pæ˜¯è®¾ç½®ä¿å­˜Memcacheçš„pidæ–‡ä»¶ï¼Œæˆ‘è¿™é‡Œæ˜¯ä¿å­˜åœ¨ <code>/tmp/memcached.pid</code></li></ul></blockquote><h4><span id="å¦‚æœè¦ç»“æŸmemcacheè¿›ç¨‹æ‰§è¡Œ">å¦‚æœè¦ç»“æŸMemcacheè¿›ç¨‹ï¼Œæ‰§è¡Œï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># kill `cat /tmp/memcached.pid`</span><br></pre></td></tr></table></figure><p>ä¹Ÿå¯ä»¥å¯åŠ¨å¤šä¸ªå®ˆæŠ¤è¿›ç¨‹ï¼Œä¸è¿‡ç«¯å£ä¸èƒ½é‡å¤ã€‚</p><h4><span id="é‡å¯æœºå™¨">é‡å¯æœºå™¨</span></h4><h3><span id="memcacheç¯å¢ƒæµ‹è¯•">Memcacheç¯å¢ƒæµ‹è¯•ï¼š</span></h3><p>è¿è¡Œä¸‹é¢çš„phpæ–‡ä»¶ï¼Œå¦‚æœæœ‰è¾“å‡ºThis is a test!ï¼Œå°±è¡¨ç¤ºç¯å¢ƒæ­å»ºæˆåŠŸã€‚ <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt; ?php</span><br><span class="line">$mem=newMemcache;</span><br><span class="line">$mem-&gt;connect(â€œ<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>â€, <span class="number">12000</span>);</span><br><span class="line">$memâˆ’&gt;set(â€²keyâ€²,â€˜Thisisatest!â€²,<span class="number">0</span>,<span class="number">60</span>);</span><br><span class="line">$val = $memâˆ’&gt;get(â€²keyâ€²);</span><br><span class="line"><span class="keyword">echo</span> $val;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> Memcache </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>æµ·é‡æ•°æ®æŒ–æ˜ï¼ˆä¸€ï¼‰ï¼šMapReduce</title>
      <link href="/2015/12/22/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AMapReduce/"/>
      <url>/2015/12/22/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AMapReduce/</url>
      
        <content type="html"><![CDATA[<blockquote><p>æ­¤ç³»åˆ—ä¸ºCouseraä¸ŠStandfordçš„<a href="https://class.coursera.org/mmds-002" target="_blank" rel="noopener">Mining Massive Datasets</a>è¯¾ç¨‹å­¦ä¹ ç¬”è®°ã€‚ è¿™æ˜¯è¯¥ç³»åˆ—çš„ç¬¬ä¸€ç¯‡ç¬”è®°ï¼š<strong>MapReduce</strong></p></blockquote><a id="more"></a><h2><span id="åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ-distributed-file-systems">åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ Distributed File Systems</span></h2><h3><span id="cluster-architecture">Cluster Architecture</span></h3><p>ä¼ ç»Ÿçš„æ•°æ®æŒ–æ˜éƒ½åœ¨ä¸€å°ä¸»æœºä¸Šæå®šï¼Œè€Œå¦‚ä»Šæ•°æ®é‡ä¹‹å¤§æ—©å·²ä¸æ˜¯ä¸€å°ä¸»æœºå¯ä»¥å¤„ç†çš„äº†ï¼Œæ‹¿Googleä¸¾ä¾‹ï¼š</p><ul><li><strong>100äº¿</strong>ä¸ªç½‘é¡µ</li><li>æ¯ä¸ªç½‘é¡µå¹³å‡å¤§å° = <strong>20KB</strong></li><li>æ€»å…± 10 billion * 20 KB = <strong>200TB</strong></li><li>ç£ç›˜è¯»å–é€Ÿåº¦ = <strong>50 MB/sec </strong></li><li>æ€»å…±è¯»å–æ—¶é—´ = å››ç™¾ä¸‡ç§’ = <strong>46å¤©</strong></li><li>è¯»å–æ•°æ®æ—¶é—´ç”šè‡³æ¯”å¤„ç†æ•°æ®æ—¶é—´è¿˜è¦é•¿</li></ul><p>æ‰€ä»¥ç°åœ¨çš„é›†ç¾¤æ¶æ„(Cluster Architecture)æ˜¯è¿™æ ·çš„ï¼š <img src="/images/1450707371717.png" alt="Alt text"></p><p>æ„æˆæ ‘å½¢ç»“æ„ï¼Œä¸Šé¢çš„èŠ‚ç‚¹éƒ½æ˜¯äº¤æ¢æœºï¼Œåº•å±‚å¶å­èŠ‚ç‚¹æ˜¯Linuxä¸»æœºé›†ç¾¤ï¼Œæ¯ä¸ªé›†ç¾¤åŒ…å«14-64ä¸ªä¸»æœºèŠ‚ç‚¹ã€‚</p><p>è¿™ç§é›†ç¾¤æ¶æ„è™½ç„¶å¯ä»¥é€šè¿‡å¹¶å‘å¤„ç†è§£å†³IOé—®é¢˜ï¼Œä½†æ˜¯å®ƒä¹Ÿé¢ä¸´æ–°çš„é—®é¢˜ï¼š * LinuxèŠ‚ç‚¹ä¼šæŒ‚æ‰ * å¦‚ä½•åšåˆ°å³ä½¿æŸä¸ªä¸»æœºæŒ‚äº†ä¹Ÿèƒ½æ°¸ä¹…ä¿å­˜å…¶ä¸­çš„æ•°æ®ï¼Ÿ * å¦‚ä½•å¤„ç†åœ¨è®¡ç®—ä¸­èŠ‚ç‚¹æŒ‚æ‰çš„æƒ…å†µï¼Ÿ</p><ul><li>ç½‘ç»œç“¶é¢ˆ<ul><li>ç›®å‰ç½‘ç»œå¸¦å®½ = 1 Gbps</li><li>ç§»åŠ¨10TBçš„æ•°æ®å¤§çº¦éœ€è¦ä¸€å¤©</li></ul></li><li>ç¼–å†™åˆ†å¸ƒå¼çš„ç¨‹åºæ¯”è¾ƒå›°éš¾ï¼<ul><li>éœ€è¦ä¸€ä¸ªç®€å•çš„æ¨¡å‹æ¥æ¶ˆé™¤å¤§éƒ¨åˆ†å›°éš¾</li></ul></li></ul><h3><span id="mapreduce">MapReduce</span></h3><blockquote><p>Map-Reduce è§£å†³äº†é›†ç¾¤è®¡ç®—çš„ä¸€äº›å›°éš¾ä¸æŒ‘æˆ˜ã€‚ * <strong>ä»¥å†—ä½™çš„æ–¹å¼æŠŠæ•°æ®å­˜å‚¨åœ¨å¤šä¸ªèŠ‚ç‚¹</strong>ä¸Šæ¥ä¿æŒæ•°æ®çš„æ°¸ä¹…æ€§å’Œå¯ç”¨æ€§ã€‚ * <strong>è®©è®¡ç®—é è¿‘æ•°æ®</strong>æ¥æœ€å°åŒ–æ•°æ®çš„ç§»åŠ¨ã€‚ * <strong>ç®€å•çš„ç¼–ç¨‹æ¨¡å‹</strong></p></blockquote><h3><span id="å†—ä½™å­˜å‚¨åŸºç¡€è®¾æ–½-redundant-storage-infrastructure">å†—ä½™å­˜å‚¨åŸºç¡€è®¾æ–½ Redundant Storage Infrastructure</span></h3><ul><li>åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ<ul><li>Google GFS</li><li>Hadoop HDFS</li></ul></li><li>å…¸å‹ä½¿ç”¨åœºæ™¯<ul><li>æ•°æ®é‡å¤§</li><li>å°‘æ›´æ–°</li><li>è¯»å–é¢‘ç¹</li></ul></li></ul><p>æ–‡ä»¶åˆ†å¸ƒç³»ç»Ÿå°±åƒä»¥ä¸‹ï¼š <img src="/images/1450709258137.png" alt="Alt text"> <strong>æ¯ä¸€â€œå—â€çš„æœåŠ¡å™¨ä¹Ÿæœ‰è®¡ç®—åŠŸèƒ½ï¼Œä¸å…‰æ˜¯å­˜å‚¨æ•°æ®ï¼</strong> <img src="/images/1450709278438.png" alt="Alt text"></p><h2><span id="è®¡ç®—æ¨¡å‹-conputational-model">è®¡ç®—æ¨¡å‹ Conputational model</span></h2><h3><span id="word-count">Word Count</span></h3><blockquote><p>ä¸€ä¸ªä¾‹å­ Word Countï¼š * æœ‰ä¸€ä¸ªéå¸¸å¤§çš„æ–‡æœ¬æ–‡ä»¶ * éœ€è¦ç»Ÿè®¡æ¯ä¸ªå•è¯å‡ºç°çš„æ¬¡æ•°</p></blockquote><ul><li>Case 1 : æ•´ä¸ªæ–‡ä»¶æ— æ³•è¯»å–è¿›å†…å­˜ï¼Œä½†æ˜¯æ‰€æœ‰çš„<code>&lt;word, count&gt;</code>é”®å€¼å¯¹å¯ä»¥å­˜å‚¨åœ¨å†…å­˜é‡Œã€‚</li></ul><p>è¿™ç§æƒ…å†µæˆ‘ä»¬å¯ä»¥ç®€å•å†™ä¸€ä¸ªHash Tableï¼Œä»¥wordä½œä¸ºkeyï¼Œcountä½œä¸ºvalueæ¥å®ç°ã€‚</p><ul><li>Case 2 : è¿<code>&lt;word, count&gt;</code>éƒ½æ— æ³•å®Œå…¨ä¿å­˜åœ¨å†…å­˜é‡Œã€‚</li></ul><p>è¿™ç§æƒ…å†µå¯ä»¥ç”¨ä¸€æ¡Linuxå‘½ä»¤æ¥è§£å†³ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words(doc.txt) | sort | uniq -c</span><br></pre></td></tr></table></figure></p><p><code>words</code>æ˜¯ä¸€ä¸ªç¨‹åºï¼Œç”¨æ¥æŠŠæ–‡ä»¶è¾“å‡ºæˆå•è¯ï¼Œä¸€è¡Œä¸€ä¸ªã€‚</p><p>è¿™ç§æ–¹æ³•æ­£æ˜¯MapReduceæ¨¡å‹çš„è®¡ç®—æ–¹æ³•ï¼Œè€Œä¸”è¿˜å¤©ç„¶åœ°å¯ä»¥å¹¶è¡Œè®¡ç®—ã€‚</p><h3><span id="æ•´ä½“æ¦‚æ½">æ•´ä½“æ¦‚æ½</span></h3><figure><img src="/images/1450710473291.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h3><span id="å…·ä½“åˆ†æ">å…·ä½“åˆ†æ</span></h3><h4><span id="map">Map</span></h4><p>è¾“å…¥ä¸€äº›åŸå§‹çš„é”®å€¼å¯¹ï¼Œè¾“å‡ºä¸­é—´çŠ¶æ€çš„é”®å€¼å¯¹ï¼Œä¸€å¯¹ä¸€æˆ–ä¸€å¯¹å¤šï¼Œåœ¨ä¸Šè¿°ä¾‹å­é‡Œå°±æ˜¯<code>words</code>è¿™ä¸ªç¨‹åºï¼Œè¾“å…¥æ–‡ä»¶åï¼Œè¾“å‡º<code>&lt;word, 1&gt;</code>çš„é”®å€¼å¯¹ã€‚ <img src="/images/1450710723670.png" alt="Alt text"></p><h4><span id="reduce">Reduce</span></h4><p>æŠŠä¸­é—´çŠ¶æ€çš„é”®å€¼å¯¹æŒ‰ç…§<code>key</code>åˆ†ç»„æ•´ç†ï¼Œè¾“å‡ºçš„é”®å€¼å¯¹éƒ½å·²ç»åˆ†å¥½ç»„ï¼Œåœ¨ä¸Šè¿°ä¾‹å­ä¸­å°±æ˜¯<code>sort</code>è¿™ä¸ªå‘½ä»¤ã€‚</p><p>æœ€åæ˜¯æŠŠæ¯ç»„é”®å€¼å¯¹çš„<code>value</code>åˆå¹¶æˆä¸€ä¸ªã€‚ <img src="/images/1450711030365.png" alt="Alt text"></p><p>æ•´ä¸ªå¤„ç†è¿‡ç¨‹ä¸­ï¼Œç¨‹åºå‘˜åªéœ€è¦å†™ä¸¤ä¸ªå‡½æ•°ï¼š<code>Map(k, v)</code>å’Œ<code>Reduce(K, &lt;V&gt;*)</code>ï¼Œå¯¹äºè§£å†³ä¸åŒçš„é—®é¢˜ä¸¤ä¸ªå‡½æ•°çš„å®ç°å„æœ‰ä¸åŒï¼Œä½†æ˜¯æ¡†æ¶éƒ½æ˜¯è¿™ä¸€ä¸ªã€‚ <img src="/images/1450711170607.png" alt="Alt text"></p><h3><span id="å¹¶è¡Œè®¡ç®—">å¹¶è¡Œè®¡ç®—</span></h3><ol type="1"><li>å¤§æ–‡ä»¶æ‹†åˆ†æˆå¤šä¸ªéƒ¨åˆ†</li><li>æ¯éƒ¨åˆ†æ–‡ä»¶åˆ†åˆ«åœ¨ä¸€ä¸ªä¸»æœºä¸Šè¿›è¡ŒMapè®¡ç®—ã€‚</li><li>é€šè¿‡HashæŠŠæ‰€æœ‰ä¸»æœºMapä¹‹åçš„å¯¼å…¥åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªä¸»æœºé‡Œï¼Œä½¿å…·æœ‰åŒä¸€ä¸ª<code>key</code>çš„é”®å€¼å¯¹éƒ½å‡ºç°åœ¨ä¸€ä¸ªä¸»æœºé‡Œï¼Œå¹¶åœ¨æ¯ä¸ªä¸»æœºé‡Œåˆ†åˆ«è¿›è¡Œæ’åºã€‚</li><li>åœ¨å„ä¸ªä¸»æœºé‡Œåˆ†åˆ«Reduce</li></ol><figure><img src="/images/1450711387926.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>ä¼ªç ç¤ºä¾‹ï¼š <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">map(key, value):</span><br><span class="line">    <span class="comment"># key: document name; value: text of the document</span></span><br><span class="line">    <span class="keyword">for</span> each word w <span class="keyword">in</span> value:</span><br><span class="line">        emit(w, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">reduce(key, values):</span><br><span class="line">    <span class="comment"># key: a word; value: an iterator over counts</span></span><br><span class="line">    result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> each count v <span class="keyword">in</span> values:</span><br><span class="line">        result += v</span><br><span class="line">    emit(key, result)</span><br></pre></td></tr></table></figure></p><h3><span id="examples">Examples</span></h3><p><img src="/images/1450712456661.png" alt="Alt text"> <img src="/images/1450712474358.png" alt="Alt text"></p><h2><span id="è°ƒåº¦å’Œæ•°æ®æµåŠ¨-scheduling-and-data-flow">è°ƒåº¦å’Œæ•°æ®æµåŠ¨ Scheduling and Data Flow</span></h2><p>æè¿°Map-Reduceçš„å·¥ä½œå›¾ï¼š <img src="/images/1450747181061.png" alt="Alt text"></p><p>å¹¶è¡Œå¤„ç†æ¨¡å‹ï¼Œä¸Šä¸€èŠ‚å·²ç»æè¿°è¿‡äº†ï¼š <img src="/images/1450747276231.png" alt="Alt text"></p><h3><span id="environment">Environment</span></h3><p>Map-Reduceè¿‡ç¨‹éœ€è¦è€ƒè™‘çš„é—®é¢˜ï¼š * å¯¹è¾“å…¥æ•°æ®<strong>åˆ’åˆ†</strong> * ç¨‹åºçš„æ‰§è¡Œåœ¨ä¸€å¤§å †æœºå™¨é‡Œè¿›è¡Œ<strong>è°ƒåº¦</strong> * æ‰§è¡Œ<strong>æŒ‰<code>key</code>åˆ†ç»„</strong>è¿™ä¸€æ­¥éª¤ * å¤„ç†èŠ‚ç‚¹(æœºå™¨)<strong>å´©æºƒ</strong> * ç®¡ç†å¿…è¦åœ°æœºå™¨ä¹‹é—´çš„<strong>é€šä¿¡</strong></p><h3><span id="data-flow">Data Flow</span></h3><blockquote><p>è¾“å…¥å’Œæœ€ç»ˆè¾“å‡ºæ˜¯å‚¨å­˜åœ¨åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿä¸Šçš„(DFS)ï¼Œè°ƒåº¦è€…åº”å°½é‡è°ƒåº¦Mapä»»åŠ¡&quot;é è¿‘&quot;è¾“å…¥æ•°æ®å®é™…æ‰€å­˜å‚¨çš„åœ°æ–¹ï¼Œè®©è®¡ç®—é è¿‘æ•°æ®ã€‚</p></blockquote><blockquote><p>ä¸­é—´ç»“æœå­˜å‚¨åœ¨Mapå·¥ä½œè€…å’ŒReduceå·¥ä½œè€…<strong>æœ¬åœ°</strong>çš„æ–‡ä»¶ç³»ç»Ÿé‡Œã€‚</p></blockquote><blockquote><p>ä¸€ä¸ªMap-Reduceä»»åŠ¡çš„è¾“å‡ºé€šå¸¸æ˜¯å¦ä¸€ä¸ªMap-Reduceä»»åŠ¡çš„çš„è¾“å…¥ã€‚</p></blockquote><h3><span id="coordination">Coordination</span></h3><blockquote><p>æ¯ä¸ªMap-Reduceä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªMasterèŠ‚ç‚¹ï¼ŒMasterèŠ‚ç‚¹éœ€è¦è´Ÿè´£æ€»ä½“ä»»åŠ¡çš„åè°ƒä¸è°ƒåº¦ã€‚</p></blockquote><p>MasterèŠ‚ç‚¹éœ€è¦è€ƒè™‘çš„é—®é¢˜ï¼š * æ¯ä¸ªèŠ‚ç‚¹çš„<strong>ä»»åŠ¡çŠ¶æ€</strong>ï¼šç©ºé—²çš„(idle), æ­£åœ¨å·¥ä½œçš„(in-progress), å·²å®Œæˆçš„(completed) * æœ‰ç©ºé—²ä»»åŠ¡çš„è¯å°±æ‰¾å¯ç”¨çš„èŠ‚ç‚¹å»å¤„ç† * å½“ä¸€ä¸ªMapä»»åŠ¡å®Œæˆæ—¶ï¼Œå·¥ä½œè€…å‘MasterèŠ‚ç‚¹å‘é€<em>R</em>ä¸ªä¸­é—´æ–‡ä»¶çš„ä½ç½®å’Œå¤§å°ï¼Œ<em>R</em>æ˜¯Reduceå·¥ä½œè€…çš„ä¸ªæ•°ï¼Œæ¯ä¸ªReduceå·¥ä½œè€…è·å¾—ä¸€ä¸ªä¸­é—´æ–‡ä»¶ã€‚ * MasterèŠ‚ç‚¹æŠŠæ•°æ®æ¨é€åˆ°ReducersèŠ‚ç‚¹ã€‚ * MasterèŠ‚ç‚¹è¿˜è¦æ—¶ä¸æ—¶åœ°pingä¸€ä¸‹å·¥ä½œè€…çœ‹æœºå™¨æ˜¯å¦è¿˜æ´»ç€ã€‚</p><h3><span id="å¤±è´¥å¤„ç†åŠæ³•">å¤±è´¥å¤„ç†åŠæ³•</span></h3><ul><li>å¤„ç†Mapä»»åŠ¡çš„èŠ‚ç‚¹æŒ‚äº†</li></ul><p>ç”±äºMapä»»åŠ¡è¾“å‡ºçš„ä¸­é—´ç»“æœæ˜¯å­˜å‚¨åœ¨æœ¬åœ°çš„ï¼Œæ‰€ä»¥æœºå™¨æŒ‚äº†è¾“å‡ºçš„æ•°æ®ä¹Ÿå°±æ²¡äº†ï¼Œåªèƒ½é‡æ–°åšäº†ã€‚ <strong>æŠŠæŒ‚äº†èŠ‚ç‚¹çš„Mapä»»åŠ¡é‡è®¾æˆç©ºé—²</strong>ï¼Œä¸ç®¡æŒ‚ä¹‹å‰æ˜¯å¤„ç†ä¸­è¿˜æ˜¯å·²å®Œæˆï¼Œåæ­£æ•°æ®éƒ½æ²¡äº†ï¼Œç„¶åç­‰ç€æœ‰å…¶ä»–å¯ç”¨èŠ‚ç‚¹æ¥å®Œæˆè¿™ä¸ªèŠ‚ç‚¹çš„å·¥ä½œã€‚</p><ul><li>å¤„ç†Reduceä»»åŠ¡çš„èŠ‚ç‚¹æŒ‚äº†</li></ul><p>ç”±äºReduceä»»åŠ¡è¾“å‡ºçš„æœ€ç»ˆç»“æœæ˜¯ä¿å­˜åœ¨åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿä¸Šçš„ï¼Œæˆ‘ä»¬å‰é¢å·²ç»è®¨è®ºè¿‡äº†ï¼Œä¸€ä¸ªèŠ‚ç‚¹åäº†æ²¡å…³ç³»ï¼Œè¿˜æœ‰å…¶ä»–èŠ‚ç‚¹ä¿å­˜ç€å¤‡ä»½ï¼Œæ‰€ä»¥å¦‚æœè¯¥èŠ‚ç‚¹æ˜¯å®ŒæˆReduceä»»åŠ¡ä¹‹åæŒ‚çš„é‚£å°±ä¸ç”¨ç®¡äº†ï¼Œæ•°æ®è¿˜åœ¨; å¦‚æœæ˜¯æ²¡å®Œæˆå°±æŒ‚äº†ï¼Œé‚£å°±éœ€è¦é‡åšäº†ã€‚ <strong>åªæŠŠæ²¡åšå®Œå°±æŒ‚äº†çš„ä»»åŠ¡é‡è®¾ä¸ºç©ºé—²</strong>ï¼Œç­‰ç€å…¶ä»–èŠ‚ç‚¹æœ‰ç©ºæ¥ä½œã€‚</p><ul><li>MasterèŠ‚ç‚¹æŒ‚äº†æ€ä¹ˆåŠ</li></ul><p>å¤±å»äº†é¢†å¯¼è€…è¿™ä¸ª<strong>ä»»åŠ¡åªèƒ½ç»ˆæ­¢</strong>ï¼Œç„¶åç­‰å¾…ä»å¤´é‡æ–°å¼€å§‹å’¯ã€‚ ä¸è¿‡æœºå™¨çš„å¹³å‡ä½¿ç”¨å¯¿å‘½åœ¨1000å¤©å·¦å³ï¼Œå•å°æœºå™¨æŒ‚æ‰çš„æ¦‚ç‡æ˜¯å¾ˆå°çš„ï¼Œåœ¨Mapä»»åŠ¡å’ŒReduceä»»åŠ¡èŠ‚ç‚¹çš„é›†ç¾¤é‡Œï¼Œå¾ˆå¯èƒ½ä¼šå‡ºç°æœ‰ä¸€ä¸¤å°æŒ‚æ‰çš„æƒ…å†µï¼Œ<strong>å¯¹äºMasterè¿™ä¸ªå•ä¸€èŠ‚ç‚¹æ¥è®²ï¼ŒæŒ‚æ‰çš„å‡ ç‡éå¸¸å°</strong>ï¼Œå¯ä»¥ä¸è€ƒè™‘ã€‚</p><h3><span id="mapå’Œreduceçš„å·¥ä½œæ•°é‡">Mapå’ŒReduceçš„å·¥ä½œæ•°é‡</span></h3><p>è®¾æœ‰<em>M</em>ä¸ªMapä»»åŠ¡ï¼Œ<em>R</em>ä¸ªReduceä»»åŠ¡ï¼Œæˆ‘ä»¬çš„ç›®çš„å°±æ˜¯ç¡®å®šMå’ŒRã€‚</p><p>æ‹‡æŒ‡è§„åˆ™ï¼ˆç»éªŒï¼‰ï¼š * è®©Mè¿œå¤§äºé›†ç¾¤é‡ŒèŠ‚ç‚¹ä¸ªæ•° * æ¯ä¸ªDFSåŒºå—å¤„ç†ä¸€ä¸ªmapä»»åŠ¡ï¼Œå¯ä»¥å‡å°‘å•ä¸ªèŠ‚ç‚¹çš„ä»»åŠ¡é‡ * æé«˜åŠ¨æ€è´Ÿè½½å‡è¡¡å’Œä»æŒ‚æ‰èŠ‚ç‚¹æ¢å¤çš„é€Ÿåº¦ * é€šå¸¸Ræ¯”Må°</p><h2><span id="ä¼˜åŒ–-refinements">ä¼˜åŒ– Refinements</span></h2><h3><span id="combiners">Combiners</span></h3><p>é€šå¸¸ä¸€ä¸ªMapä»»åŠ¡ä¼šå¤„ç†å‡ºè®¸å¤šä¸ªå…·æœ‰ç›¸åŒ<code>key</code>çš„é”®å€¼å¯¹ï¼Œç›´æ¥æŠŠè¿™æ ·çš„æ•°æ®ä¼ ç»™Reducerä¼šå¾ˆå·¨å¤§ï¼Œç½‘ç»œå¸¦å®½å ç”¨å¤šï¼Œæœ‰æ—¶å€™å¯ä»¥åœ¨ä¼ è¾“å‰<strong>é¢„åˆå¹¶</strong>ä¸€ä¸‹ï¼Œæå¤§çš„å‡å°‘äº†æ•°æ®é‡ï¼Œå‘é€é€Ÿåº¦ä¹Ÿæ˜¾è‘—æé«˜ã€‚</p><p>åˆå¹¶(combine)å‡½æ•°é€šå¸¸ä¸Reduceå‡½æ•°æ˜¯ä¸€æ ·çš„ã€‚</p><p>å›åˆ°ä¹‹å‰Word Countçš„ä¾‹å­ Mapä»»åŠ¡è¾“å‡ºç»“æœä¸­å¯èƒ½ä¼šæœ‰å¤§é‡çš„<code>&lt;word, 1&gt;</code>å…·æœ‰ç›¸åŒçš„<code>key</code>,æ¯”å¦‚<code>the</code>å¯èƒ½å‡ºç°äº†1000æ¬¡ï¼Œé‚£ä¹ˆé‡Œé¢å°±æœ‰1000ä¸ª<code>('the', 1)</code>ï¼Œè¿™æ—¶å€™å¯ä»¥é€šè¿‡é¢„åˆå¹¶æŠŠå…·æœ‰ç›¸åŒ<code>key</code>çš„é”®å€¼å¯¹åˆå¹¶ï¼Œå°±å˜ä¸ºäº†<code>('the', 1000)</code>ï¼Œç„¶åå†æ¨é€åˆ°Reduceä»»åŠ¡ä¸­ï¼Œæå¤§å‡å°‘äº†ä¼ è¾“æ•°æ®é‡ã€‚ å¦‚å›¾æ‰€ç¤ºï¼š <img src="/images/1450752050711.png" alt="Alt text"></p><p>ä½†é¢„åˆå¹¶å¹¶ä¸æ˜¯ä»€ä¹ˆæ—¶å€™éƒ½ç®¡ç”¨çš„ï¼Œå®ƒè¦æ±‚<strong>Reduceå‡½æ•°æ»¡è¶³äº¤æ¢å¾‹å’Œç»“åˆå¾‹</strong>ã€‚</p><p>ä¸¾ä¸ªä¾‹å­ï¼Œæ¯”å¦‚æ±‚å’Œ(sum)æ»¡è¶³äº¤æ¢å¾‹å’Œç»“åˆå¾‹ï¼Œå³<code>a + b = b + a</code>å’Œ<code>(a + b) + c = a + (b + c)</code>ï¼Œæ‰€ä»¥å®ƒå¯ä»¥åœ¨æœ¬åœ°é¢„å¤„ç†ã€‚</p><p>å¦‚æœReduceå‡½æ•°æ˜¯æ±‚å¹³å‡å€¼(Average)å‘¢ï¼Ÿ æˆ‘ä»¬éƒ½è¿‡æŠŠå¤§æ•°æ®åˆ†æˆäº†å¾ˆå¤šå°å—ï¼Œåœ¨æ¯ä¸ªå°å—é‡Œè¿›è¡Œmapï¼Œç„¶åæŠŠè¾“å‡ºç»“æœå…·æœ‰ç›¸åŒ<code>key</code>çš„é”®å€¼å¯¹åŠ èµ·æ¥å†å–å¹³å‡ï¼Œç„¶åå‘é€ç»™Reduceä»»åŠ¡ï¼ŒReduceæŠŠæ¯ä¸ªå°å—çš„å¹³å‡å€¼åŠ èµ·æ¥å†å–å¹³å‡ï¼Œå¾—åˆ°æœ€ç»ˆç»“æœã€‚</p><p>å¾—åˆ°çš„æ˜¯æ­£ç¡®ç»“æœå—ï¼Ÿ <strong>æ˜¾ç„¶ä¸æ˜¯ï¼</strong></p><p><strong>æ±‚å¹³å‡å€¼è¿™ä¸ªè¿ç®—ä¸æ»¡è¶³ç»“åˆå¾‹</strong>ï¼Œåˆ†æˆå°å—å–å¹³å‡ç„¶ååŠ èµ·æ¥å†å–å¹³å‡ä¸ç›´æ¥æŠŠæ‰€æœ‰æ•°æ®åŠ èµ·æ¥å–å¹³å‡æ˜¯ä¸ç›¸ç­‰çš„ï¼</p><p>æ‰€ä»¥<strong>è¿™ä¸ªä¾‹å­ä¸èƒ½ç”¨ä¸Reduceä¸€æ ·çš„åˆå¹¶å‡½æ•°</strong>ï¼Œä½†ä¹Ÿä¸æ˜¯æ²¡æœ‰åŠæ³•ï¼Œå¯ä»¥åªæ±‚å‡ºå®ƒä»¬çš„å’Œï¼Œä¸å–å¹³å‡ï¼Œç„¶åå‘é€åˆ°Reduceé‡Œï¼ŒReduceå‡½æ•°æŠŠæ‰€æœ‰çš„åŒºå—çš„å’ŒåŠ èµ·æ¥å†å–å¹³å‡ï¼Œå¾—åˆ°çš„å°±æ˜¯æ­£ç¡®ç»“æœäº†ã€‚</p><p>å†æ¢ä¸€ä¸ªï¼Œå¦‚æœè¦æ±‚ä¸­ä½æ•°(Median)å‘¢ï¼Ÿ é‚£å°±æ²¡è¾™äº†ï¼Œåªèƒ½ç›´æ¥ä¼ åŸå§‹mapè¾“å‡ºæ•°æ®äº†ã€‚</p><h3><span id="åˆ†å—å‡½æ•°">åˆ†å—å‡½æ•°</span></h3><figure><img src="/images/1450753330650.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="å®ç°-implementations">å®ç° Implementations</span></h2><ul><li>Hadoop<ul><li>å¼€æºã€ç”¨javaå®ç°</li><li>ä½¿ç”¨HDFSä½œä¸ºç¨³å®šçš„å­˜å‚¨</li><li>ä¸‹è½½ï¼š http://lucene.apache.org/hadoop/</li></ul></li><li>Hive, Pig<ul><li>åœ¨hadoop MapReduceå±‚ä¸Šé¢çš„æŠ½è±¡</li></ul></li><li>Google MapReduce<ul><li>ä½¿ç”¨Google File Systemä½œä¸ºå­˜å‚¨</li><li>åªæœ‰googleå†…éƒ¨å¯ä»¥ä½¿ç”¨</li></ul></li></ul><figure><img src="/images/1450753341548.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="èµ„æºå’Œå»¶ä¼¸é˜…è¯»">èµ„æºå’Œå»¶ä¼¸é˜…è¯»</span></h2><p>è¯¾ä»¶pdfä¸‹è½½</p><p>å»¶ä¼¸é˜…è¯»ï¼š <a href="http://research.google.com/archive/mapreduce.html" target="_blank" rel="noopener">MapReduce: Simplified Data Processing on Large Clusters</a></p><p><a href="http://research.google.com/archive/gfs.html" target="_blank" rel="noopener">The Google File System</a></p><p>èµ„æºï¼š</p><ul><li>Hadoop Wiki<ul><li><a href="http://wiki.apache.org/hadoop/" target="_blank" rel="noopener">ä»‹ç»</a></li><li><a href="http://wiki.apache.org/hadoop/GettingStartedWithHadoop" target="_blank" rel="noopener">Getting Start</a></li><li><a href="http://wiki.apache.org/hadoop/HadoopMapReduce" target="_blank" rel="noopener">MapReduce æ¦‚æ½</a></li><li>http://wiki.apache.org/lucene-hadoop/HadoopMapRedClasses</li><li><a href="http://wiki.apache.org/hadoop/EclipseEnvironment" target="_blank" rel="noopener">Eclipseç¯å¢ƒ</a></li></ul></li><li><p><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">Hadoop å®˜ç½‘</a></p></li><li><p><a href="http://www.apache.org/dyn/closer.cgi/lucene/" target="_blank" rel="noopener">é•œåƒ</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ•°æ®æŒ–æ˜ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>è®°å½•ï¼šç”¨PHPå®ç°ç®€å•webæ¡†æ¶</title>
      <link href="/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/"/>
      <url>/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>è¿™ä¸ªæ¡†æ¶åŠŸèƒ½æ¯”è¾ƒç®€å•ï¼Œåªæœ‰urlæ‹¦æˆªåŠè‡ªå®šä¹‰ã€åŠ è½½é™æ€æ¨¡æ¿ä¸¤ä¸ªåŠŸèƒ½ï¼Œä¹‹å‰çš„åšå®¢ä¹Ÿæ˜¯åŸºäºè¿™ä¸ªæ¡†æ¶å®ç°çš„ã€‚ç¬¬ä¸€éƒ¨åˆ†æ˜¯è®°å½•å®ç°è¿™ä¸ªæ¡†æ¶æ‰€éœ€çš„phpåŸºç¡€çŸ¥è¯†ï¼Œç¬¬äºŒéƒ¨åˆ†æ˜¯è¿™ä¸¤ä¸ªåŠŸèƒ½çš„å®ç°æ–¹æ³•ã€‚æœ€åè¿˜æœ‰å®ç°è‡ªåŠ¨ç™»å½•çš„æœ€ä½³å®è·µã€‚</p></blockquote><a id="more"></a><h2><span id="phpåŸºç¡€ç›¸å…³">phpåŸºç¡€ç›¸å…³</span></h2><h3><span id="_server"><code>$_SERVER</code></span></h3><blockquote><p>æœåŠ¡å™¨å’Œæ‰§è¡Œç¯å¢ƒä¿¡æ¯</p></blockquote><p><a href="http://php.net/manual/zh/reserved.variables.server.php" target="_blank" rel="noopener">phpæ‰‹å†Œ</a></p><p>å‡ ä¸ªç”¨åˆ°çš„é¡¹ï¼š * <code>'REQUEST_METHOD'</code> : è®¿é—®é¡µé¢ä½¿ç”¨çš„è¯·æ±‚æ–¹æ³•ï¼›ä¾‹å¦‚ï¼Œ<code>â€œGETâ€</code>,<code>â€œHEADâ€</code>ï¼Œ<code>â€œPOSTâ€</code>ï¼Œ<code>â€œPUTâ€</code>ã€‚ * <code>'REQUEST_URI'</code> : URI ç”¨æ¥æŒ‡å®šè¦è®¿é—®çš„é¡µé¢ã€‚ä¾‹å¦‚ <code>â€œ/index.htmlâ€</code>ã€‚</p><h3><span id="date">Date</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date(format,timestamp)</span><br></pre></td></tr></table></figure><div class="line-block">å‚æ•° | æè¿° |<br>:--- | : --- |<br>format | å¿…éœ€ã€‚è§„å®šå¦‚ä½•è¿”å›ç»“æœã€‚|<br>timestamp | å¯é€‰ã€‚ |</div><h4><span id="æ ¼å¼åŒ–æ–¹å¼è¯´æ˜">æ ¼å¼åŒ–æ–¹å¼è¯´æ˜</span></h4><table><thead><tr class="header"><th style="text-align: left;">æ ¼å¼åŒ–æ–¹å¼</th><th style="text-align: left;">è¯´æ˜</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">Y</td><td style="text-align: left;">4ä½æ•°å­—å¹´ï¼Œyä¸º2ä½æ•°å­—ï¼Œå¦‚99å³1999å¹´</td></tr><tr class="even"><td style="text-align: left;">m</td><td style="text-align: left;">æ•°å­—æœˆä»½ï¼Œå‰é¢æœ‰å‰å¯¼0ï¼Œå¦‚01ã€‚n ä¸ºæ— å‰å¯¼0æ•°å­—æœˆä»½</td></tr><tr class="odd"><td style="text-align: left;">F</td><td style="text-align: left;">æœˆä»½ï¼Œå®Œæ•´çš„æ–‡æœ¬æ ¼å¼ï¼Œä¾‹å¦‚ January æˆ–è€… March</td></tr><tr class="even"><td style="text-align: left;">M</td><td style="text-align: left;">ä¸‰ä¸ªå­—æ¯ç¼©å†™è¡¨ç¤ºçš„æœˆä»½ï¼Œä¾‹å¦‚ Jan æˆ–è€… Mar</td></tr><tr class="odd"><td style="text-align: left;">d</td><td style="text-align: left;">æœˆä»½ä¸­çš„ç¬¬å‡ å¤©ï¼Œå‰é¢æœ‰å‰å¯¼0ï¼Œå¦‚03ã€‚j ä¸ºæ— å‰å¯¼0çš„å¤©æ•°</td></tr><tr class="even"><td style="text-align: left;">w</td><td style="text-align: left;">æ˜ŸæœŸä¸­çš„ç¬¬å‡ å¤©ï¼Œä»¥æ•°å­—è¡¨ç¤ºï¼Œ0è¡¨ç¤ºæ˜ŸæœŸå¤©</td></tr><tr class="odd"><td style="text-align: left;">z</td><td style="text-align: left;">å¹´ä»½ä¸­çš„ç¬¬å‡ å¤©ï¼ŒèŒƒå›´0-366</td></tr><tr class="even"><td style="text-align: left;">W</td><td style="text-align: left;">å¹´ä»½ä¸­çš„ç¬¬å‡ å‘¨ï¼Œå¦‚ç¬¬32å‘¨</td></tr><tr class="odd"><td style="text-align: left;">H</td><td style="text-align: left;">24å°æ—¶æ ¼å¼ï¼Œæœ‰å‰å¯¼0ï¼Œhä¸º12å°æ—¶æ ¼å¼</td></tr><tr class="even"><td style="text-align: left;">G</td><td style="text-align: left;">24å°æ—¶æ ¼å¼ï¼Œæ— å‰å¯¼0ï¼Œgä¸ºå¯¹åº”12å°æ—¶æ ¼å¼</td></tr><tr class="odd"><td style="text-align: left;">i</td><td style="text-align: left;">åˆ†é’Ÿæ ¼å¼ï¼Œæœ‰å‰å¯¼0</td></tr><tr class="even"><td style="text-align: left;">s</td><td style="text-align: left;">ç§’æ ¼å¼ï¼Œæœ‰å‰å¯¼0</td></tr><tr class="odd"><td style="text-align: left;">A</td><td style="text-align: left;">å¤§å†™ä¸Šä¸‹åˆï¼Œå¦‚AMï¼Œaä¸ºå°å†™</td></tr></tbody></table><p><strong>ä¾‹å­</strong> <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Result with date():&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(<span class="string">"l"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(<span class="string">"l dS \of F Y h:i:s A"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Oct 3,1975 was on a "</span>.date(<span class="string">"l"</span>, mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)).<span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(DATE_RFC822) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(DATE_ATOM,mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)) . <span class="string">"&lt;br /&gt;&lt;br /&gt;"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Result with gmdate():&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(<span class="string">"l"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(<span class="string">"l dS \of F Y h:i:s A"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Oct 3,1975 was on a "</span>.gmdate(<span class="string">"l"</span>, mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)).<span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(DATE_RFC822) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(DATE_ATOM,mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p><p>ç»“æœï¼š &gt; Result with <code>date()</code>: Tuesday Tuesday 24th of January 2006 02:41:22 PM Oct 3,1975 was on a Friday Tue, 24 Jan 2006 14:41:22 CET 1975-10-03T00:00:00+0100</p><blockquote><p>Result with <code>gmdate()</code>: Tuesday Tuesday 24th of January 2006 01:41:22 PM Oct 3,1975 was on a Thursday Tue, 24 Jan 2006 13:41:22 GMT 1975-10-02T23:00:00+0000</p></blockquote><h3><span id="å­—ç¬¦ä¸²">å­—ç¬¦ä¸²</span></h3><p><code>explode()</code>åˆ†å‰²å­—ç¬¦ä¸²ï¼Œè¿”å›æ•°ç»„ã€‚ <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explode(delimiter, string)</span><br></pre></td></tr></table></figure></p><h4><span id="éšæœºå­—ç¬¦ä¸²">éšæœºå­—ç¬¦ä¸²</span></h4><ol type="1"><li>é¢„ç½®ä¸€ä¸ªçš„å­—ç¬¦ä¸² $chars ï¼ŒåŒ…æ‹¬ a â€“ zï¼ŒA â€“ Zï¼Œ0 â€“ 9ï¼Œä»¥åŠä¸€äº›ç‰¹æ®Šå­—ç¬¦ã€‚</li><li>åœ¨ $chars å­—ç¬¦ä¸²ä¸­éšæœºå–ä¸€ä¸ªå­—ç¬¦ã€‚</li><li>é‡å¤ç¬¬äºŒæ­¥næ¬¡ï¼Œå¯å¾—é•¿åº¦ä¸ºnçš„å­—ç¬¦ä¸²ã€‚</li></ol><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">generate_password</span><span class="params">( $length = <span class="number">8</span> )</span> </span>&#123;  </span><br><span class="line"><span class="comment">// å¯†ç å­—ç¬¦é›†ï¼Œå¯ä»»æ„æ·»åŠ ä½ éœ€è¦çš„å­—ç¬¦  </span></span><br><span class="line">    $chars = â€˜abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@<span class="comment">#$%^&amp;*()-_ []&#123;&#125;&lt;&gt;~`+=,.;:/?|â€™;  </span></span><br><span class="line">    $password = â€;  </span><br><span class="line">    <span class="keyword">for</span> ( $i = <span class="number">0</span>; $i &lt; $length; $i++ )  </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="comment">// è¿™é‡Œæä¾›ä¸¤ç§å­—ç¬¦è·å–æ–¹å¼  </span></span><br><span class="line">        <span class="comment">// ç¬¬ä¸€ç§æ˜¯ä½¿ç”¨ substr æˆªå–$charsä¸­çš„ä»»æ„ä¸€ä½å­—ç¬¦ï¼›  </span></span><br><span class="line">        <span class="comment">// ç¬¬äºŒç§æ˜¯å–å­—ç¬¦æ•°ç»„ $chars çš„ä»»æ„å…ƒç´   </span></span><br><span class="line">        <span class="comment">// $password .= substr($chars,     mt_rand(0, strlen($chars) â€“ 1), 1);  </span></span><br><span class="line">         $password .= $chars[ mt_rand(<span class="number">0</span>,     strlen($chars) - <span class="number">1</span>) ];  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> $password;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="åŠ å¯†">åŠ å¯†</span></h3><p>sha256 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$password = hash(<span class="string">'sha256'</span>, $identifier . $_POST[<span class="string">'password'</span>]);</span><br></pre></td></tr></table></figure></p><h3><span id="session">Session</span></h3><p>æ¯æ¬¡ç”¨ä¹‹å‰ä¸€å®šè¦<code>session_start()</code>ï¼š <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session_start();</span><br><span class="line">$_SESSION[$var] = xxxx;</span><br></pre></td></tr></table></figure></p><h3><span id="cookie">Cookie</span></h3><h4><span id="å¦‚ä½•åˆ›å»º-cookie">å¦‚ä½•åˆ›å»º cookieï¼Ÿ</span></h4><p><code>setcookie()</code>å‡½æ•°ç”¨äºè®¾ç½® cookieã€‚</p><p>è¯­æ³• <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setcookie(name, value, expire, path, domain);</span><br></pre></td></tr></table></figure></p><p>ä¾‹å­ åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºåä¸º &quot;user&quot; çš„ cookieï¼ŒæŠŠä¸ºå®ƒèµ‹å€¼ &quot;Alex Porter&quot;ã€‚æˆ‘ä»¬ä¹Ÿè§„å®šäº†æ­¤ cookie åœ¨ä¸€å°æ—¶åè¿‡æœŸï¼š <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line">setcookie(<span class="string">"user"</span>, <span class="string">"Alex Porter"</span>, time()+<span class="number">3600</span>);</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line"></span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>æ³¨é‡Šï¼šåœ¨å‘é€ cookie æ—¶ï¼Œcookie çš„å€¼ä¼šè‡ªåŠ¨è¿›è¡Œ URL ç¼–ç ï¼Œåœ¨å–å›æ—¶è¿›è¡Œè‡ªåŠ¨è§£ç ï¼ˆä¸ºé˜²æ­¢ URL ç¼–ç ï¼Œè¯·ä½¿ç”¨ <code>setrawcookie()</code> å–è€Œä»£ä¹‹ï¼‰ã€‚</p></blockquote><h4><span id="å¦‚ä½•å–å›-cookie-çš„å€¼">å¦‚ä½•å–å› Cookie çš„å€¼ï¼Ÿ</span></h4><p>PHP çš„<code>$_COOKIE</code>å˜é‡ç”¨äºå–å› cookie çš„å€¼ã€‚ åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å–å›äº†åä¸º <code>&quot;user&quot;</code>çš„ cookie çš„å€¼ï¼Œå¹¶æŠŠå®ƒæ˜¾ç¤ºåœ¨äº†é¡µé¢ä¸Šï¼š <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="comment">// Print a cookie</span></span><br><span class="line"><span class="keyword">echo</span> $_COOKIE[<span class="string">"user"</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// A way to view all cookies</span></span><br><span class="line">print_r($_COOKIE);</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p><h4><span id="å¦‚ä½•åˆ é™¤-cookie">å¦‚ä½•åˆ é™¤ cookieï¼Ÿ</span></h4><p>å½“åˆ é™¤ cookie æ—¶ï¼Œæ‚¨åº”å½“ä½¿è¿‡æœŸæ—¥æœŸå˜æ›´ä¸ºè¿‡å»çš„æ—¶é—´ç‚¹ã€‚ åˆ é™¤çš„ä¾‹å­ï¼š <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line"><span class="comment">// set the expiration date to one hour ago</span></span><br><span class="line">setcookie(<span class="string">"user"</span>, <span class="string">""</span>, time()<span class="number">-3600</span>);</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p><h3><span id="å˜å‚">å˜å‚</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">variable</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="keyword">echo</span> func_num_args();         <span class="comment">//è¾“å‡ºå‚æ•°ä¸ªæ•°</span></span><br><span class="line">     $varArray = func_get_args();     <span class="comment">//è·å–å‚æ•°ï¼Œè¿”å›å‚æ•°æ•°ç»„</span></span><br><span class="line">     <span class="keyword">foreach</span>($varArray <span class="keyword">as</span> $value)</span><br><span class="line">         <span class="keyword">echo</span> $value;</span><br><span class="line">     </span><br><span class="line">     <span class="keyword">echo</span> func_get_arg;       <span class="comment">//è·å–å•ä¸ªå‚æ•°</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><h3><span id="åå°„">åå°„</span></h3><p>å‚è€ƒï¼š<a href="http://blog.csdn.net/hguisu/article/details/7357421" target="_blank" rel="noopener">PHPçš„åå°„æœºåˆ¶</a> <a href="http://php.net/manual/zh/book.reflection.php" target="_blank" rel="noopener">phpæ‰‹å†Œ</a></p><h4><span id="å»ºç«‹åå°„ç±»">å»ºç«‹åå°„ç±»</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$class = <span class="keyword">new</span> ReflectionClass(<span class="string">'Person'</span>);<span class="comment">//å»ºç«‹ Personè¿™ä¸ªç±»çš„åå°„ç±»  </span></span><br><span class="line">$instance  = $class-&gt;newInstanceArgs($args);<span class="comment">//ç›¸å½“äºå®ä¾‹åŒ–Person ç±»</span></span><br></pre></td></tr></table></figure><h4><span id="è·å–å±æ€§properties">è·å–å±æ€§(Properties)</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$properties = $class-&gt;getProperties();  </span><br><span class="line"><span class="keyword">foreach</span>($properties <span class="keyword">as</span> $property) &#123;  </span><br><span class="line">    <span class="keyword">echo</span> $property-&gt;getName().<span class="string">"\n"</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="è·å–æ³¨é‡Š">è·å–æ³¨é‡Š</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">foreach</span>($properties <span class="keyword">as</span> $property) &#123;  </span><br><span class="line">    <span class="keyword">if</span>($property-&gt;isProtected()) &#123;  </span><br><span class="line">        $docblock = $property-&gt;getDocComment();  </span><br><span class="line">        preg_match(<span class="string">'/ type\=([a-z_]*) /'</span>, $property-&gt;getDocComment(), $matches);  </span><br><span class="line">        <span class="keyword">echo</span> $matches[<span class="number">1</span>].<span class="string">"\n"</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="è·å–ç±»çš„æ–¹æ³•">è·å–ç±»çš„æ–¹æ³•</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>($class-&gt;hasMethod($methodName))&#123;</span><br><span class="line">$method = $class-&gt;getMethod($methodName);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="æ‰§è¡Œç±»çš„æ–¹æ³•">æ‰§è¡Œç±»çš„æ–¹æ³•</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$instance-&gt;getBiography(); <span class="comment">//æ‰§è¡ŒPerson é‡Œçš„æ–¹æ³•getBiography  </span></span><br><span class="line"><span class="comment">//æˆ–è€…ï¼š  </span></span><br><span class="line">$ec=$class-&gt;getmethod(<span class="string">'getName'</span>);  <span class="comment">//è·å–Person ç±»ä¸­çš„getNameæ–¹æ³•  </span></span><br><span class="line">$ec-&gt;invoke($instance);       <span class="comment">//æ‰§è¡ŒgetName æ–¹æ³• </span></span><br><span class="line"><span class="comment">// æˆ–è€…ï¼š</span></span><br><span class="line">$method-&gt;invokeArgs($instance, $params); <span class="comment">// $paramsä¸ºæ•°ç»„</span></span><br></pre></td></tr></table></figure><h2><span id="uri">URI</span></h2><blockquote><p>uriç»“æ„ï¼š<code>apppath/class/method/params</code> uriç¤ºä¾‹ : <code>www.liuhe.website/index.php?/Articles/single/13</code></p></blockquote><p>å®ç°æ–¹æ³•ï¼š</p><ul><li>åœ¨<code>index.php</code>ä¸­é€šè¿‡<code>$_SERVER['REQUEST_URI']</code>è·å–uriï¼Œç„¶åè·å–<code>className</code>, <code>methodName</code>ä»¥åŠ<code>params</code>ã€‚</li><li>includeç›¸åº”æ§åˆ¶å™¨çš„æ–‡ä»¶ï¼Œå³<code>controller/$className.php</code>ã€‚</li><li>å»ºç«‹åå°„ç±»ï¼Œè°ƒç”¨ç›¸å…³methodä¼ å…¥ç›¸åº”å‚æ•°ã€‚</li><li>é˜²æ­¢ç›´æ¥é€šè¿‡æ–‡ä»¶ç›®å½•è®¿é—®(é€šè¿‡æœåŠ¡å™¨é…ç½®rewriteå®ç°)</li></ul><p>code: <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Parse uri , instantiate the class</span></span><br><span class="line"><span class="comment"> * and invoke the method</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">parseRequestUri</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">isset</span>($_SERVER[<span class="string">'REQUEST_URI'</span>])) &#123;</span><br><span class="line">        <span class="keyword">$this</span>-&gt;uri_string = $_SERVER[<span class="string">'REQUEST_URI'</span>];</span><br><span class="line">        <span class="keyword">$this</span>-&gt;segments = explode(<span class="string">'/'</span>, <span class="keyword">$this</span>-&gt;uri_string);</span><br><span class="line">        <span class="comment">// var_dump($this-&gt;segments);</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * get the class name, method name and the params</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (count(<span class="keyword">$this</span>-&gt;segments) &lt;= <span class="number">2</span>) &#123;</span><br><span class="line">            $className = <span class="string">'Articles'</span>;</span><br><span class="line">            $methodName = <span class="string">'home'</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            $className = <span class="keyword">$this</span>-&gt;segments[<span class="number">2</span>];</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">isset</span>(<span class="keyword">$this</span>-&gt;segments[<span class="number">3</span>])) &#123;</span><br><span class="line">                $methodName = <span class="keyword">$this</span>-&gt;segments[<span class="number">3</span>];</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 404 Error</span></span><br><span class="line">                <span class="keyword">$this</span>-&gt;_404Error(<span class="string">"Empty Method"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> ($_SERVER[<span class="string">'REQUEST_METHOD'</span>] == <span class="string">'GET'</span> || $_SERVER[<span class="string">'REQUEST_METHOD'</span>] == <span class="string">'POST'</span>) &#123;</span><br><span class="line">            $params = <span class="keyword">array</span>();</span><br><span class="line">            $len = count(<span class="keyword">$this</span>-&gt;segments);</span><br><span class="line">            <span class="keyword">if</span> ($len &gt; <span class="number">4</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> ($i = <span class="number">4</span>; $i &lt; $len; $i++) &#123;</span><br><span class="line">                    array_push($params, <span class="keyword">$this</span>-&gt;segments[$i]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            $classFile = <span class="string">"controller/$className.php"</span>;</span><br><span class="line">            <span class="keyword">if</span> (!file_exists($classFile)) &#123;</span><br><span class="line">                <span class="comment">// 404 error</span></span><br><span class="line">                <span class="keyword">$this</span>-&gt;_404Error(<span class="string">"File Not Found"</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * build reflection class, invoke the method</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">require</span> <span class="string">"$classFile"</span>;</span><br><span class="line">            $rc = <span class="keyword">new</span> ReflectionClass($className);</span><br><span class="line">            <span class="keyword">if</span> (!$rc-&gt;hasMethod($methodName)) &#123;</span><br><span class="line">                <span class="comment">// 404 error</span></span><br><span class="line">                <span class="keyword">$this</span>-&gt;_404Error(<span class="string">"Method Not Found"</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            $instance = $rc-&gt;newInstance();</span><br><span class="line">            $method = $rc-&gt;getMethod($methodName);</span><br><span class="line">            $method-&gt;invokeArgs($instance, $params);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">echo</span> <span class="string">"not set REQUEST_URI"</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2><span id="åŠ è½½é™æ€æ¨¡æ¿å¸¦å‚æ•°">åŠ è½½é™æ€æ¨¡æ¿ï¼ˆå¸¦å‚æ•°ï¼‰</span></h2><p>å®ç°æ–¹æ³•ï¼š * å®šä¹‰å‚æ•°ç»“æ„ï¼ˆå ä½ç¬¦ï¼‰ï¼š<code></code> * i ä¸ºç¬¬iä¸ªå‚æ•° * æŠŠæ¨¡æ¿æ–‡ä»¶åŠ è½½åˆ°å†…å­˜ï¼Œç”¨å­—ç¬¦ä¸²æ›¿æ¢å‡½æ•°æ›¿æ¢ä¸Šè¿°å ä½ç¬¦ã€‚</p><p>codeï¼š <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Load a static template</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@var</span> string, array</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">load</span><span class="params">($page = <span class="string">''</span>, $args = array<span class="params">()</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">empty</span>($page)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    $fileName = <span class="string">"static/$page"</span>;</span><br><span class="line">    $file = fopen($fileName, <span class="string">"r"</span>);</span><br><span class="line">    $content = fread($file, filesize($fileName));</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">empty</span>($args)) &#123;</span><br><span class="line">        $i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (strpos($content, <span class="string">"&#123;&#123;args[$i]&#125;&#125;"</span>) !== <span class="keyword">false</span>) &#123;</span><br><span class="line">            $content = str_replace(<span class="string">"&#123;&#123;args[$i]&#125;&#125;"</span>, $args[$i], $content);</span><br><span class="line">            $i += <span class="number">1</span>;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">echo</span> <span class="string">"$content"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2><span id="å®ç°è‡ªåŠ¨ç™»å½•">å®ç°è‡ªåŠ¨ç™»å½•</span></h2><blockquote><p>ä»¥ä¸‹éƒ¨åˆ†æ¥è‡ªStackOverflow</p></blockquote><h3><span id="improved-persistent-login-cookie-best-practice">Improved Persistent Login Cookie Best Practice</span></h3><ol type="1"><li>When the user successfully logs in with Remember Me checked, a login cookie is issued in addition to the standard session management cookie.</li><li>The login cookie contains a series identifier and a token. The series and token are <strong>unguessable random numbers </strong>from a suitably large space. Both are stored together in a database table, <strong>the token is hashed </strong>(sha256 is fine).</li><li>When a non-logged-in user visits the site and presents a login cookie, the series identifier is looked up in the database.<ol type="1"><li>If the series identifier is present and the hash of the token matches the hash for that series identifier, the user is considered authenticated. <strong>A new token is generated</strong>, a new hash for the token is stored over the old record, and a new login cookie is issued to the user (it's okay to re-use the series identifier).</li><li>If the series is present but the token does not match, a theft is assumed. The user receives a strongly worded warning and <strong>all of the user's remembered sessions are deleted.</strong></li><li>If the username and series are not present, the login cookie is ignored.</li></ol></li></ol><p>This approach provides defense-in-depth. If someone manages to leak the database table, it does not give an attacker an open door for impersonating users.</p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Mysqli ä½¿ç”¨</title>
      <link href="/2015/12/19/Mysqli%20%E4%BD%BF%E7%94%A8/"/>
      <url>/2015/12/19/Mysqli%20%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h3><span id="è¿æ¥æ•°æ®åº“å¹¶è·å–ç›¸å…³ä¿¡æ¯">è¿æ¥æ•°æ®åº“å¹¶è·å–ç›¸å…³ä¿¡æ¯</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$mysqli=@<span class="keyword">new</span> mysqli(<span class="string">"localhost"</span>, <span class="string">"root"</span>, <span class="string">""</span>, <span class="string">"mysql"</span>);</span><br><span class="line"><span class="comment">//å¦‚æœè¿æ¥é”™è¯¯</span></span><br><span class="line"><span class="keyword">if</span>(mysqli_connect_errno())&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"è¿æ¥æ•°æ®åº“å¤±è´¥ï¼š"</span>.mysqli_connect_error();</span><br><span class="line">    $mysqli=<span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">exit</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//è·å–å½“å‰å­—ç¬¦é›†</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;character_set_name().<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//è·å–å®¢æˆ·ç«¯ä¿¡æ¯</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;get_client_info().<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//è·å–mysqlä¸»æœºä¿¡æ¯</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;host_info.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//è·å–æœåŠ¡å™¨ä¿¡æ¯</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;server_info.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//è·å–æœåŠ¡å™¨ç‰ˆæœ¬</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;server_version.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//å…³é—­æ•°æ®åº“è¿æ¥</span></span><br><span class="line">$mysqli-&gt;close();</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="æŸ¥è¯¢æ•°æ®">æŸ¥è¯¢æ•°æ®</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//æ„é€ SQLè¯­å¥</span></span><br><span class="line">$query = <span class="string">"SELECT * FROM  designer order by ID LIMIT 3"</span>;</span><br><span class="line"><span class="comment">//æ‰§è¡ŒSQLè¯­å¥</span></span><br><span class="line">$result = $mysqli-&gt;query($query);</span><br><span class="line"><span class="comment">//éå†ç»“æœ</span></span><br><span class="line"><span class="keyword">while</span>($row = $result-&gt;fetch_array(MYSQLI_BOTH))&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"id"</span>.$row[<span class="string">'id'</span>].<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//é‡Šæ”¾ç»“æœé›†</span></span><br><span class="line">$result-&gt;free();</span><br></pre></td></tr></table></figure><p>åœ¨è¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fetch_array(MYSQLI_BOTH)</span><br></pre></td></tr></table></figure></p><p>è¿™ä¸ªæ–¹æ³•ï¼Œå‚æ•°æœ‰ä¸‰ä¸ªï¼Œåˆ†åˆ«æ˜¯ <code>MYSQLI_BOTH</code>ï¼Œ<code>MYSQLI_NUM</code>ï¼Œ<code>MYSQLI_ASSOC</code>ã€‚</p><p>å¦‚æœå‚æ•°ä¼ å…¥äº† <code>MYSQLI_BOTH</code>ï¼Œè¿”å›æ•°ç»„çš„ç´¢å¼•æ—¢åŒ…æ‹¬æ•°å­—å’Œåç§°ã€‚ <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">array</span> (size=<span class="number">26</span>)</span><br><span class="line">  <span class="number">0</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="string">'id'</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="number">1</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="string">'name'</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="number">2</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="string">'email'</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="number">3</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br><span class="line">  <span class="string">'phone'</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><p>å¦‚æœå‚æ•°ä¼ å…¥äº† <code>MYSQLI_NUM</code>ï¼Œè¿”å›æ•°ç»„çš„ç´¢å¼•åªåŒ…å«æ•°å­—ã€‚ <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">array</span> (size=<span class="number">13</span>)</span><br><span class="line">  <span class="number">0</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="number">1</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="number">2</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="number">3</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><p>å¦‚æœå‚æ•°ä¼ å…¥äº† <code>MYSQLI_BOTH</code>ï¼Œè¿”å›æ•°ç»„çš„ç´¢å¼•åªåŒ…å«åç§°ã€‚ <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">array</span> (size=<span class="number">13</span>)</span><br><span class="line">  <span class="string">'id'</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="string">'name'</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="string">'email'</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="string">'phone'</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><p>å…¶å®è¿˜æœ‰ç­‰ä»·çš„æ–¹æ³• <code>fetch_row()</code>ï¼Œ<code>fetch_assoc()</code> ä»–ä»¬ä¹‹é—´çš„å…³ç³»å¦‚ä¸‹ <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   $result-&gt;fetch_row() </span><br><span class="line">=  mysql_fetch_row() </span><br><span class="line">=  $result-&gt;fetch_array(MYSQLI_NUM) </span><br><span class="line">=  mysql_fetch_array(MYSQLI_NUM)  </span><br><span class="line">è¿”å›ç´¢å¼•æ•°ç»„</span><br><span class="line"></span><br><span class="line">   $result-&gt;fetch_assoc() </span><br><span class="line">=  mysql_fetch_assoc() </span><br><span class="line">=  $result-&gt;fetch_array(MYSQLI_ASSOC) </span><br><span class="line">=  mysql_fetch_array(MYSQLI_ASSOC)  </span><br><span class="line">è¿”å›ç´¢å¼•åˆ—å</span><br></pre></td></tr></table></figure></p><h3><span id="æ’å…¥æ•°æ®">æ’å…¥æ•°æ®</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//æ’å…¥æ•°æ®</span></span><br><span class="line">$sql=<span class="string">"insert into designer(name,phone) values('hello','18352682923')"</span>;</span><br><span class="line"><span class="comment">//æ‰§è¡Œæ’å…¥è¯­å¥</span></span><br><span class="line">$result=$mysqli-&gt;query($sql);</span><br><span class="line"><span class="comment">//å¦‚æœæ‰§è¡Œé”™è¯¯</span></span><br><span class="line"><span class="keyword">if</span>(!$result)&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"SQLè¯­å¥æœ‰è¯¯&lt;br&gt;"</span>;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"ERROR:"</span>.$mysqli-&gt;errno.<span class="string">"|"</span>.$mysqli-&gt;error;</span><br><span class="line">    <span class="keyword">exit</span>;    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//å¦‚æœæ’å…¥æˆåŠŸï¼Œåˆ™è¿”å›å½±å“çš„è¡Œæ•°</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;affected_rows;</span><br></pre></td></tr></table></figure><h3><span id="æ›´æ–°æ•°æ®">æ›´æ–°æ•°æ®</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//æ›´æ–°æ•°æ®</span></span><br><span class="line">$sql=<span class="string">"update designer set name = 'hello' where id = 10062"</span>;</span><br><span class="line"><span class="comment">//æ‰§è¡Œæ’å…¥è¯­å¥</span></span><br><span class="line">$result=$mysqli-&gt;query($sql);</span><br><span class="line"><span class="comment">//å¦‚æœæ‰§è¡Œé”™è¯¯</span></span><br><span class="line"><span class="keyword">if</span>(!$result)&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"SQLè¯­å¥æœ‰è¯¯&lt;br&gt;"</span>;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"ERROR:"</span>.$mysqli-&gt;errno.<span class="string">"|"</span>.$mysqli-&gt;error;</span><br><span class="line">    <span class="keyword">exit</span>;    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//å¦‚æœæ’å…¥æˆåŠŸï¼Œåˆ™è¿”å›å½±å“çš„è¡Œæ•°</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;affected_rows;</span><br></pre></td></tr></table></figure><h3><span id="é¢„å¤„ç†è¯­å¥">é¢„å¤„ç†è¯­å¥</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//å‡†å¤‡å¥½ä¸€æ¡è¯­å¥æ”¾åˆ°æœåŠ¡å™¨ä¸­ï¼Œæ’å…¥è¯­å¥</span></span><br><span class="line">$sql = <span class="string">"insert into designer(name, email) values(?, ?)"</span>;</span><br><span class="line"><span class="comment">//ç”Ÿæˆé¢„å¤„ç†è¯­å¥</span></span><br><span class="line">$stmt = $mysqli-&gt;prepare($sql);</span><br><span class="line"><span class="comment">//ç»™å ä½ç¬¦å·æ¯ä¸ª?å·ä¼ å€¼ï¼ˆç»‘å®šå‚æ•°ï¼‰ i  d  s  bï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ ¼å¼åŒ–å­—ç¬¦ï¼Œssä»£è¡¨ä¸¤ä¸ªå­—ç¬¦ä¸²ï¼Œdä»£è¡¨æ•°å­—</span></span><br><span class="line">$stmt-&gt;bind_param(<span class="string">"ss"</span>, $name, $email);</span><br><span class="line"><span class="comment">//ä¸ºå˜é‡èµ‹å€¼</span></span><br><span class="line">$name = <span class="string">"Mike"</span>;</span><br><span class="line">$email = <span class="string">"mike@live.cn"</span>;</span><br><span class="line"><span class="comment">//æ‰§è¡Œ</span></span><br><span class="line">$stmt-&gt;execute();</span><br><span class="line"><span class="comment">//ä¸ºå˜é‡èµ‹å€¼</span></span><br><span class="line">$name = <span class="string">"Larry"</span>;</span><br><span class="line">$email = <span class="string">"larry@live.cn"</span>;</span><br><span class="line"><span class="comment">//æ‰§è¡Œ</span></span><br><span class="line">$stmt-&gt;execute();</span><br><span class="line"><span class="comment">//æœ€åè¾“å‡º</span></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"æœ€åID"</span>.$stmt-&gt;insert_id.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="keyword">echo</span> <span class="string">"å½±å“äº†"</span>.$stmt-&gt;affected_rows.<span class="string">"è¡Œ&lt;br&gt;"</span>;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GIT ç¬”è®°</title>
      <link href="/2015/12/18/GIT%20%E7%AC%94%E8%AE%B0/"/>
      <url>/2015/12/18/GIT%20%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2><span id="å®‰è£…git">å®‰è£…Git</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git</span><br><span class="line">The program &apos;git&apos; is currently not installed. You can install it by typing:</span><br><span class="line">sudo apt-get install git</span><br></pre></td></tr></table></figure><a id="more"></a><p>å®‰è£…å®Œæˆä¹‹åï¼š</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name &quot;Your Name&quot;</span><br><span class="line">$ git config --global user.email &quot;email@example.com&quot;</span><br></pre></td></tr></table></figure><h2><span id="åˆ›å»ºç‰ˆæœ¬åº“">åˆ›å»ºç‰ˆæœ¬åº“</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git init</span><br><span class="line">Initialized empty Git repository in /Users/michael/learngit/.git/</span><br></pre></td></tr></table></figure><p>å°†æ–‡ä»¶æ”¾å…¥ä»“åº“ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git add readme.md </span><br><span class="line">$ git commit -m &quot;add readme&quot;</span><br></pre></td></tr></table></figure></p><h2><span id="æ—¶å…‰ç©¿æ¢­æœº">æ—¶å…‰ç©¿æ¢­æœº</span></h2><p>æŸ¥çœ‹ä»“åº“å½“å‰çŠ¶æ€ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git status</span><br></pre></td></tr></table></figure></p><p>æŸ¥çœ‹ä¿®æ”¹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git diff</span><br></pre></td></tr></table></figure></p><h3><span id="ç‰ˆæœ¬é€€å›">ç‰ˆæœ¬é€€å›</span></h3><p>æŸ¥çœ‹æäº¤æ—¥å¿—ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git log</span><br></pre></td></tr></table></figure></p><p>ä¸€æ¡æ—¥å¿—åœ¨ä¸€è¡Œæ˜¾ç¤ºï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git log --pretty=online</span><br></pre></td></tr></table></figure></p><blockquote><p>åœ¨Gitä¸­ï¼Œç”¨<code>HEAD</code>è¡¨ç¤ºå½“å‰ç‰ˆæœ¬ï¼Œä¹Ÿå°±æ˜¯æœ€æ–°çš„æäº¤<code>3628164...882e1e0</code>ï¼ˆæ³¨æ„æˆ‘çš„æäº¤IDå’Œä½ çš„è‚¯å®šä¸ä¸€æ ·ï¼‰ï¼Œä¸Šä¸€ä¸ªç‰ˆæœ¬å°±æ˜¯<code>HEAD^</code>ï¼Œä¸Šä¸Šä¸€ä¸ªç‰ˆæœ¬å°±æ˜¯<code>HEAD^^</code>ï¼Œå½“ç„¶å¾€ä¸Š100ä¸ªç‰ˆæœ¬å†™100ä¸ª^æ¯”è¾ƒå®¹æ˜“æ•°ä¸è¿‡æ¥ï¼Œæ‰€ä»¥å†™æˆ<code>HEAD~100</code>ã€‚</p></blockquote><p>é€€å›åˆ°ä¸Šä¸€ç‰ˆæœ¬ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git reset --hard HEAD^</span><br></pre></td></tr></table></figure></p><p>è®°å½•æ¯ä¸€æ¡å‘½ä»¤ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git reflog</span><br></pre></td></tr></table></figure></p><h3><span id="å·¥ä½œåŒºå’Œæš‚å­˜åŒº">å·¥ä½œåŒºå’Œæš‚å­˜åŒº</span></h3><figure><img src="/images/1446625069461.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p><strong>å·¥ä½œåŒºæœ‰ä¸€ä¸ªéšè—ç›®å½•<code>.git</code>ï¼Œè¿™ä¸ªä¸ç®—å·¥ä½œåŒºï¼Œè€Œæ˜¯Gitçš„ç‰ˆæœ¬åº“ã€‚</strong></p><blockquote><p>Gitçš„ç‰ˆæœ¬åº“é‡Œå­˜äº†å¾ˆå¤šä¸œè¥¿ï¼Œå…¶ä¸­æœ€é‡è¦çš„å°±æ˜¯ç§°ä¸ºstageï¼ˆæˆ–è€…å«indexï¼‰çš„æš‚å­˜åŒºï¼Œè¿˜æœ‰Gitä¸ºæˆ‘ä»¬è‡ªåŠ¨åˆ›å»ºçš„ç¬¬ä¸€ä¸ªåˆ†æ”¯<code>master</code>ï¼Œä»¥åŠæŒ‡å‘<code>master</code>çš„ä¸€ä¸ªæŒ‡é’ˆå«<code>HEAD</code>ã€‚</p></blockquote><h3><span id="ç®¡ç†ä¿®æ”¹">ç®¡ç†ä¿®æ”¹</span></h3><p><strong>æ¯æ¬¡ä¿®æ”¹ï¼Œå¦‚æœä¸<code>add</code>åˆ°æš‚å­˜åŒºï¼Œé‚£å°±ä¸ä¼šåŠ å…¥åˆ°<code>commit</code>ä¸­ã€‚</strong></p><h3><span id="æ’¤é”€ä¿®æ”¹">æ’¤é”€ä¿®æ”¹</span></h3><p>ä¸¢å¼ƒå·¥ä½œåŒºçš„ä¿®æ”¹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -- file</span><br></pre></td></tr></table></figure></p><blockquote><p>å‘½ä»¤<code>git checkout -- readme.txt</code>æ„æ€å°±æ˜¯ï¼ŒæŠŠ<code>readme.txt</code>æ–‡ä»¶åœ¨å·¥ä½œåŒºçš„ä¿®æ”¹å…¨éƒ¨æ’¤é”€ï¼Œè¿™é‡Œæœ‰ä¸¤ç§æƒ…å†µï¼š * ä¸€ç§æ˜¯<code>readme.txt</code>è‡ªä¿®æ”¹åè¿˜æ²¡æœ‰è¢«æ”¾åˆ°æš‚å­˜åŒºï¼Œç°åœ¨ï¼Œæ’¤é”€ä¿®æ”¹å°±å›åˆ°å’Œç‰ˆæœ¬åº“ä¸€æ¨¡ä¸€æ ·çš„çŠ¶æ€ï¼› * ä¸€ç§æ˜¯<code>readme.txt</code>å·²ç»æ·»åŠ åˆ°æš‚å­˜åŒºåï¼Œåˆä½œäº†ä¿®æ”¹ï¼Œç°åœ¨ï¼Œæ’¤é”€ä¿®æ”¹å°±å›åˆ°æ·»åŠ åˆ°æš‚å­˜åŒºåçš„çŠ¶æ€ã€‚</p></blockquote><p><strong>åœºæ™¯1</strong>ï¼šå½“ä½ æ”¹ä¹±äº†å·¥ä½œåŒºæŸä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œæƒ³ç›´æ¥ä¸¢å¼ƒå·¥ä½œåŒºçš„ä¿®æ”¹æ—¶ï¼Œç”¨å‘½ä»¤<code>git checkout -- file</code>ã€‚</p><p><strong>åœºæ™¯2</strong>ï¼šå½“ä½ ä¸ä½†æ”¹ä¹±äº†å·¥ä½œåŒºæŸä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œè¿˜æ·»åŠ åˆ°äº†æš‚å­˜åŒºæ—¶ï¼Œæƒ³ä¸¢å¼ƒä¿®æ”¹ï¼Œåˆ†ä¸¤æ­¥ï¼Œç¬¬ä¸€æ­¥ç”¨å‘½ä»¤<code>git reset HEAD file</code>ï¼Œå°±å›åˆ°äº†åœºæ™¯1ï¼Œç¬¬äºŒæ­¥æŒ‰åœºæ™¯1æ“ä½œã€‚ <br></p><p><strong>åœºæ™¯3</strong>ï¼šå·²ç»æäº¤äº†ä¸åˆé€‚çš„ä¿®æ”¹åˆ°ç‰ˆæœ¬åº“æ—¶ï¼Œæƒ³è¦æ’¤é”€æœ¬æ¬¡æäº¤ï¼Œå‚è€ƒ<em>ç‰ˆæœ¬å›é€€</em>ä¸€èŠ‚</p><h3><span id="åˆ é™¤æ–‡ä»¶">åˆ é™¤æ–‡ä»¶</span></h3><p>ä»ç‰ˆæœ¬åº“é‡Œåˆ é™¤æ–‡ä»¶ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git rm file</span><br><span class="line">$ git commit -m &quot;remove file&quot;</span><br></pre></td></tr></table></figure></p><blockquote><p>å‘½ä»¤<code>git rm</code>ç”¨äºåˆ é™¤ä¸€ä¸ªæ–‡ä»¶ã€‚å¦‚æœä¸€ä¸ªæ–‡ä»¶å·²ç»è¢«æäº¤åˆ°ç‰ˆæœ¬åº“ï¼Œé‚£ä¹ˆä½ æ°¸è¿œä¸ç”¨æ‹…å¿ƒè¯¯åˆ ï¼Œ<strong>ä½†æ˜¯è¦å°å¿ƒï¼Œä½ åªèƒ½æ¢å¤æ–‡ä»¶åˆ°æœ€æ–°ç‰ˆæœ¬ï¼Œä½ ä¼šä¸¢å¤±æœ€è¿‘ä¸€æ¬¡æäº¤åä½ ä¿®æ”¹çš„å†…å®¹ã€‚</strong></p></blockquote><h2><span id="è¿œç¨‹ä»“åº“">è¿œç¨‹ä»“åº“</span></h2><p>åˆ›å»ºSSH Keyï¼š <code>$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot;</code></p><p>å¦‚æœä¸€åˆ‡é¡ºåˆ©çš„è¯ï¼Œå¯ä»¥åœ¨ç”¨æˆ·ä¸»ç›®å½•é‡Œæ‰¾åˆ°.sshç›®å½•ï¼Œé‡Œé¢æœ‰<code>id_rsa</code>å’Œ<code>id_rsa.pub</code>ä¸¤ä¸ªæ–‡ä»¶ï¼Œè¿™ä¸¤ä¸ªå°±æ˜¯SSH Keyçš„ç§˜é’¥å¯¹ï¼Œ<code>id_rsa</code>æ˜¯ç§é’¥ï¼Œä¸èƒ½æ³„éœ²å‡ºå»ï¼Œ<code>id_rsa.pub</code>æ˜¯å…¬é’¥ï¼Œå¯ä»¥æ”¾å¿ƒåœ°å‘Šè¯‰ä»»ä½•äººã€‚</p><h3><span id="æ·»åŠ è¿œç¨‹åº“">æ·»åŠ è¿œç¨‹åº“</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote add origin git@github.com:NeymarL/learngit.git</span><br></pre></td></tr></table></figure><blockquote><p>æ·»åŠ åï¼Œè¿œç¨‹åº“çš„åå­—å°±æ˜¯<code>origin</code>ï¼Œè¿™æ˜¯Gité»˜è®¤çš„å«æ³•ï¼Œä¹Ÿå¯ä»¥æ”¹æˆåˆ«çš„ï¼Œä½†æ˜¯<code>origin</code>è¿™ä¸ªåå­—ä¸€çœ‹å°±çŸ¥é“æ˜¯è¿œç¨‹åº“ã€‚</p></blockquote><p>æŠŠæœ¬åœ°åº“çš„æ‰€æœ‰å†…å®¹æ¨é€åˆ°è¿œç¨‹åº“ä¸Šï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push -u origin master</span><br></pre></td></tr></table></figure></p><blockquote><p>åŠ ä¸Šäº†<code>-u</code>å‚æ•°ï¼ŒGitä¸ä½†ä¼šæŠŠæœ¬åœ°çš„<code>master</code>åˆ†æ”¯å†…å®¹æ¨é€çš„è¿œç¨‹æ–°çš„<code>master</code>åˆ†æ”¯ï¼Œè¿˜ä¼šæŠŠæœ¬åœ°çš„<code>master</code>åˆ†æ”¯å’Œè¿œç¨‹çš„masteråˆ†æ”¯å…³è”èµ·æ¥</p></blockquote><h3><span id="ä»è¿œç¨‹åº“å…‹éš†">ä»è¿œç¨‹åº“å…‹éš†</span></h3><p>ä»è¿œç¨‹åº“å…‹éš†ä¸€ä¸ªæœ¬åœ°åº“ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git@github.com:NeymarL/gitskills.git</span><br></pre></td></tr></table></figure></p><h2><span id="åˆ†æ”¯ç®¡ç†">åˆ†æ”¯ç®¡ç†</span></h2><h3><span id="åˆ›å»ºä¸åˆå¹¶åˆ†æ”¯">åˆ›å»ºä¸åˆå¹¶åˆ†æ”¯</span></h3><figure><img src="/images/1446626485656.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>æ¯æ¬¡æäº¤ï¼Œ<code>master</code>åˆ†æ”¯éƒ½ä¼šå‘å‰ç§»åŠ¨ä¸€æ­¥ï¼Œè¿™æ ·ï¼Œéšç€ä½ ä¸æ–­æäº¤ï¼Œ<code>master</code>åˆ†æ”¯çš„çº¿ä¹Ÿè¶Šæ¥è¶Šé•¿ã€‚</p><p>å½“æˆ‘ä»¬åˆ›å»ºæ–°çš„åˆ†æ”¯ï¼Œä¾‹å¦‚<code>dev</code>æ—¶ï¼ŒGitæ–°å»ºäº†ä¸€ä¸ªæŒ‡é’ˆå«<code>dev</code>ï¼ŒæŒ‡å‘<code>master</code>ç›¸åŒçš„æäº¤ï¼Œå†æŠŠ<code>HEAD</code>æŒ‡å‘<code>dev</code>ï¼Œå°±è¡¨ç¤ºå½“å‰åˆ†æ”¯åœ¨<code>dev</code>ä¸Šï¼š <img src="/images/1446626525260.png" alt="Alt text"></p><p>Gitåˆ›å»ºä¸€ä¸ªåˆ†æ”¯å¾ˆå¿«ï¼Œå› ä¸ºé™¤äº†å¢åŠ ä¸€ä¸ª<code>dev</code>æŒ‡é’ˆï¼Œæ”¹æ”¹<code>HEAD</code>çš„æŒ‡å‘ï¼Œå·¥ä½œåŒºçš„æ–‡ä»¶éƒ½æ²¡æœ‰ä»»ä½•å˜åŒ–ï¼</p><p>Gitæ€ä¹ˆåˆå¹¶å‘¢ï¼Ÿæœ€ç®€å•çš„æ–¹æ³•ï¼Œå°±æ˜¯ç›´æ¥æŠŠ<code>master</code>æŒ‡å‘<code>dev</code>çš„å½“å‰æäº¤ï¼Œå°±å®Œæˆäº†åˆå¹¶ï¼š <img src="/images/1446626632797.png" alt="Alt text"></p><p>åˆå¹¶å®Œåˆ†æ”¯åï¼Œç”šè‡³å¯ä»¥åˆ é™¤<code>dev</code>åˆ†æ”¯ã€‚åˆ é™¤<code>dev</code>åˆ†æ”¯å°±æ˜¯æŠŠ<code>dev</code>æŒ‡é’ˆç»™åˆ æ‰ï¼Œåˆ æ‰åï¼Œæˆ‘ä»¬å°±å‰©ä¸‹äº†ä¸€æ¡<code>master</code>åˆ†æ”¯ï¼š <img src="/images/1446626670302.png" alt="Alt text"></p><hr><p>é¦–å…ˆï¼Œæˆ‘ä»¬åˆ›å»ºdevåˆ†æ”¯ï¼Œç„¶ååˆ‡æ¢åˆ°devåˆ†æ”¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -b dev</span><br><span class="line">Switched to a new branch &apos;dev</span><br></pre></td></tr></table></figure></p><p><code>git checkout</code>å‘½ä»¤åŠ ä¸Š<code>-b</code>å‚æ•°è¡¨ç¤ºåˆ›å»ºå¹¶åˆ‡æ¢ï¼Œç›¸å½“äºä»¥ä¸‹ä¸¤æ¡å‘½ä»¤ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git branch dev</span><br><span class="line">$ git checkout dev</span><br></pre></td></tr></table></figure></p><p>ç„¶åï¼Œç”¨<code>git branch</code>å‘½ä»¤æŸ¥çœ‹å½“å‰åˆ†æ”¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git branch</span><br><span class="line">* dev</span><br><span class="line">  master</span><br></pre></td></tr></table></figure></p><p><code>git branch</code>å‘½ä»¤ä¼šåˆ—å‡ºæ‰€æœ‰åˆ†æ”¯ï¼Œå½“å‰åˆ†æ”¯å‰é¢ä¼šæ ‡ä¸€ä¸ª<code>*</code>å·ã€‚</p><p>ç„¶åï¼Œæˆ‘ä»¬å°±å¯ä»¥åœ¨<code>dev</code>åˆ†æ”¯ä¸Šæ­£å¸¸æäº¤ã€‚</p><p><code>dev</code>åˆ†æ”¯çš„å·¥ä½œå®Œæˆï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ‡æ¢å›<code>master</code>åˆ†æ”¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &apos;master&apos;</span><br></pre></td></tr></table></figure></p><p>åˆ‡æ¢å›<code>master</code>åˆ†æ”¯åï¼Œåˆšæ‰æ·»åŠ çš„å†…å®¹ä¸è§äº†ï¼å› ä¸ºé‚£ä¸ªæäº¤æ˜¯åœ¨<code>dev</code>åˆ†æ”¯ä¸Šï¼Œè€Œ<code>master</code>åˆ†æ”¯æ­¤åˆ»çš„æäº¤ç‚¹å¹¶æ²¡æœ‰å˜ï¼š <img src="/images/1446626948887.png" alt="Alt text"></p><p>ç°åœ¨ï¼Œæˆ‘ä»¬æŠŠdevåˆ†æ”¯çš„å·¥ä½œæˆæœåˆå¹¶åˆ°masteråˆ†æ”¯ä¸Šï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git merge dev</span><br></pre></td></tr></table></figure></p><p>åˆå¹¶å®Œæˆåï¼Œå°±å¯ä»¥æ”¾å¿ƒåœ°åˆ é™¤<code>dev</code>åˆ†æ”¯äº†ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git branch -d dev</span><br><span class="line">Deleted branch dev (was fec145a).</span><br></pre></td></tr></table></figure></p><blockquote><p>å› ä¸ºåˆ›å»ºã€åˆå¹¶å’Œåˆ é™¤åˆ†æ”¯éå¸¸å¿«ï¼Œæ‰€ä»¥Gité¼“åŠ±ä½ ä½¿ç”¨åˆ†æ”¯å®ŒæˆæŸä¸ªä»»åŠ¡ï¼Œåˆå¹¶åå†åˆ æ‰åˆ†æ”¯ï¼Œè¿™å’Œç›´æ¥åœ¨<code>master</code>åˆ†æ”¯ä¸Šå·¥ä½œæ•ˆæœæ˜¯ä¸€æ ·çš„ï¼Œä½†è¿‡ç¨‹æ›´å®‰å…¨ã€‚</p></blockquote><p>Gité¼“åŠ±å¤§é‡ä½¿ç”¨åˆ†æ”¯ï¼š</p><ul><li><p>æŸ¥çœ‹åˆ†æ”¯ï¼š<code>git branch</code></p></li><li><p>åˆ›å»ºåˆ†æ”¯ï¼š<code>git branch &lt;name&gt;</code></p></li><li><p>åˆ‡æ¢åˆ†æ”¯ï¼š<code>git checkout &lt;name&gt;</code></p></li><li><p>åˆ›å»º+åˆ‡æ¢åˆ†æ”¯ï¼š<code>git checkout -b &lt;name&gt;</code></p></li><li><p>åˆå¹¶æŸåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ï¼š<code>git merge &lt;name&gt;</code></p></li><li><p>åˆ é™¤åˆ†æ”¯ï¼š<code>git branch -d &lt;name&gt;</code></p></li></ul><h3><span id="è§£å†³å†²çª">è§£å†³å†²çª</span></h3><p>å‡è®¾ï¼Œ<code>master</code>åˆ†æ”¯å’Œ<code>feature1</code>åˆ†æ”¯å„è‡ªéƒ½åˆ†åˆ«æœ‰æ–°çš„æäº¤ï¼Œå˜æˆäº†è¿™æ ·ï¼š <img src="/images/1446627386655.png" alt="Alt text"></p><p>è¿™ç§æƒ…å†µä¸‹ï¼ŒGitæ— æ³•æ‰§è¡Œâ€œå¿«é€Ÿåˆå¹¶â€ï¼Œåªèƒ½è¯•å›¾æŠŠå„è‡ªçš„ä¿®æ”¹åˆå¹¶èµ·æ¥ï¼Œä½†è¿™ç§åˆå¹¶å°±å¯èƒ½ä¼šæœ‰å†²çªï¼Œ<strong>å¿…é¡»æ‰‹åŠ¨è§£å†³å†²çªåå†æäº¤ã€‚</strong></p><p>æäº¤ä¹‹åï¼š <img src="/images/1446627526133.png" alt="Alt text"></p><p>ç”¨å¸¦å‚æ•°çš„<code>git log</code>ä¹Ÿå¯ä»¥çœ‹åˆ°åˆ†æ”¯çš„åˆå¹¶æƒ…å†µï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ git log --graph --pretty=oneline --abbrev-commit</span><br><span class="line">*   59bc1cb conflict fixed</span><br><span class="line">|\</span><br><span class="line">| * 75a857c AND simple</span><br><span class="line">* | 400b400 &amp; simple</span><br><span class="line">|/</span><br><span class="line">* fec145a branch test</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h3><span id="åˆ†æ”¯ç®¡ç†ç­–ç•¥">åˆ†æ”¯ç®¡ç†ç­–ç•¥</span></h3><p>é€šå¸¸ï¼Œåˆå¹¶åˆ†æ”¯æ—¶ï¼Œå¦‚æœå¯èƒ½ï¼ŒGitä¼šç”¨<code>Fast forward</code>æ¨¡å¼ï¼Œä½†è¿™ç§æ¨¡å¼ä¸‹ï¼Œåˆ é™¤åˆ†æ”¯åï¼Œä¼šä¸¢æ‰åˆ†æ”¯ä¿¡æ¯ã€‚</p><p>å¦‚æœè¦ç”¨<code>--no-ff</code>å¼ºåˆ¶ç¦ç”¨<code>Fast forward</code>æ¨¡å¼ï¼ŒGitå°±ä¼šåœ¨<code>merge</code>æ—¶ç”Ÿæˆä¸€ä¸ªæ–°çš„<code>commit</code>ï¼Œè¿™æ ·ï¼Œä»åˆ†æ”¯å†å²ä¸Šå°±å¯ä»¥çœ‹å‡ºåˆ†æ”¯ä¿¡æ¯ã€‚</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git merge --no-ff -m &quot;merge with no-ff&quot; dev</span><br></pre></td></tr></table></figure><p>å› ä¸ºæœ¬æ¬¡åˆå¹¶è¦åˆ›å»ºä¸€ä¸ªæ–°çš„<code>commit</code>ï¼Œæ‰€ä»¥åŠ ä¸Š-må‚æ•°ï¼ŒæŠŠ<code>commit</code>æè¿°å†™è¿›å»ã€‚</p><p>å¯ä»¥çœ‹åˆ°ï¼Œä¸ä½¿ç”¨<code>Fast forward</code>æ¨¡å¼ï¼Œ<code>merge</code>åå°±åƒè¿™æ ·ï¼š <img src="/images/1446627786918.png" alt="Alt text"></p><h4><span id="åˆ†æ”¯ç­–ç•¥">åˆ†æ”¯ç­–ç•¥</span></h4><p>åœ¨å®é™…å¼€å‘ä¸­ï¼Œæˆ‘ä»¬åº”è¯¥æŒ‰ç…§å‡ ä¸ªåŸºæœ¬åŸåˆ™è¿›è¡Œåˆ†æ”¯ç®¡ç†ï¼š</p><p>é¦–å…ˆï¼Œ<code>master</code>åˆ†æ”¯åº”è¯¥æ˜¯éå¸¸ç¨³å®šçš„ï¼Œä¹Ÿå°±æ˜¯ä»…ç”¨æ¥å‘å¸ƒæ–°ç‰ˆæœ¬ï¼Œ<strong>å¹³æ—¶ä¸èƒ½åœ¨ä¸Šé¢å¹²æ´»</strong>ï¼›</p><p>é‚£åœ¨å“ªå¹²æ´»å‘¢ï¼Ÿå¹²æ´»éƒ½åœ¨<code>dev</code>åˆ†æ”¯ä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œ<code>dev</code>åˆ†æ”¯æ˜¯ä¸ç¨³å®šçš„ï¼Œåˆ°æŸä¸ªæ—¶å€™ï¼Œæ¯”å¦‚1.0ç‰ˆæœ¬å‘å¸ƒæ—¶ï¼Œå†æŠŠ<code>dev</code>åˆ†æ”¯åˆå¹¶åˆ°<code>master</code>ä¸Šï¼Œåœ¨<code>master</code>åˆ†æ”¯å‘å¸ƒ1.0ç‰ˆæœ¬ï¼›</p><p><strong>ä½ å’Œä½ çš„å°ä¼™ä¼´ä»¬æ¯ä¸ªäººéƒ½åœ¨<code>dev</code>åˆ†æ”¯ä¸Šå¹²æ´»</strong>ï¼Œæ¯ä¸ªäººéƒ½æœ‰è‡ªå·±çš„åˆ†æ”¯ï¼Œæ—¶ä¸æ—¶åœ°å¾€<code>dev</code>åˆ†æ”¯ä¸Šåˆå¹¶å°±å¯ä»¥äº†ã€‚</p><p>æ‰€ä»¥ï¼Œå›¢é˜Ÿåˆä½œçš„åˆ†æ”¯çœ‹èµ·æ¥å°±åƒè¿™æ ·ï¼š <img src="/images/1446628189809.png" alt="Alt text"> &gt; åˆå¹¶åˆ†æ”¯æ—¶ï¼ŒåŠ ä¸Š<code>--no-ff</code>å‚æ•°å°±å¯ä»¥ç”¨æ™®é€šæ¨¡å¼åˆå¹¶ï¼Œåˆå¹¶åçš„å†å²æœ‰åˆ†æ”¯ï¼Œèƒ½çœ‹å‡ºæ¥æ›¾ç»åšè¿‡åˆå¹¶ï¼Œè€Œ<code>fast forward</code>åˆå¹¶å°±çœ‹ä¸å‡ºæ¥æ›¾ç»åšè¿‡åˆå¹¶ã€‚</p><h3><span id="bugåˆ†æ”¯">Bugåˆ†æ”¯</span></h3><p>Gitè¿˜æä¾›äº†ä¸€ä¸ª<code>stash</code>åŠŸèƒ½ï¼Œå¯ä»¥æŠŠå½“å‰å·¥ä½œç°åœºâ€œå‚¨è—â€èµ·æ¥ï¼Œç­‰ä»¥åæ¢å¤ç°åœºåç»§ç»­å·¥ä½œï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git stash</span><br><span class="line">Saved working directory and index state WIP on dev: 6224937 add merge</span><br><span class="line">HEAD is now at 6224937 add merge</span><br></pre></td></tr></table></figure></p><p>ç°åœ¨ï¼Œç”¨<code>git status</code>æŸ¥çœ‹å·¥ä½œåŒºï¼Œå°±æ˜¯å¹²å‡€çš„ï¼ˆé™¤éæœ‰æ²¡æœ‰è¢«Gitç®¡ç†çš„æ–‡ä»¶ï¼‰ï¼Œå› æ­¤å¯ä»¥æ”¾å¿ƒåœ°åˆ›å»ºåˆ†æ”¯æ¥ä¿®å¤bugã€‚</p><p>é¦–å…ˆç¡®å®šè¦åœ¨å“ªä¸ªåˆ†æ”¯ä¸Šä¿®å¤bugï¼Œå‡å®šéœ€è¦åœ¨<code>master</code>åˆ†æ”¯ä¸Šä¿®å¤ï¼Œå°±ä»<code>master</code>åˆ›å»ºä¸´æ—¶åˆ†æ”¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &apos;master&apos;</span><br><span class="line">Your branch is ahead of &apos;origin/master&apos; by 6 commits.</span><br><span class="line"></span><br><span class="line">$ git checkout -b issue-101</span><br><span class="line">Switched to a new branch &apos;issue-101&apos;</span><br></pre></td></tr></table></figure></p><p>ç°åœ¨ä¿®å¤bugï¼Œä¿®å¤å®Œæˆåï¼Œåˆ‡æ¢åˆ°masteråˆ†æ”¯ï¼Œå¹¶å®Œæˆåˆå¹¶ï¼Œæœ€ååˆ é™¤issue-101åˆ†æ”¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line"></span><br><span class="line">$ git merge --no-ff -m &quot;merged bug fix 101&quot; issue-101</span><br><span class="line"></span><br><span class="line">$ git branch -d issue-101</span><br></pre></td></tr></table></figure></p><p>ç°åœ¨ï¼Œæ˜¯æ—¶å€™æ¥ç€å›åˆ°devåˆ†æ”¯å¹²æ´»äº†ï¼ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout dev</span><br></pre></td></tr></table></figure></p><p>ç”¨<code>git stash list</code>å‘½ä»¤çœ‹çœ‹ä¹‹å‰ä¿å­˜çš„å·¥ä½œç°åœºï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git stash list</span><br><span class="line">stash@&#123;0&#125;: WIP on dev: 6224937 add merge</span><br></pre></td></tr></table></figure></p><p>å·¥ä½œç°åœºè¿˜åœ¨ï¼ŒGitæŠŠ<code>stash</code>å†…å®¹å­˜åœ¨æŸä¸ªåœ°æ–¹äº†ï¼Œä½†æ˜¯éœ€è¦æ¢å¤ä¸€ä¸‹ï¼Œæœ‰ä¸¤ä¸ªåŠæ³•ï¼š</p><ul><li><p>ä¸€æ˜¯ç”¨<code>git stash apply</code>æ¢å¤ï¼Œä½†æ˜¯æ¢å¤åï¼Œ<code>stash</code>å†…å®¹å¹¶ä¸åˆ é™¤ï¼Œä½ éœ€è¦ç”¨<code>git stash drop</code>æ¥åˆ é™¤ï¼›</p></li><li><p>å¦ä¸€ç§æ–¹å¼æ˜¯ç”¨<code>git stash pop</code>ï¼Œæ¢å¤çš„åŒæ—¶æŠŠstashå†…å®¹ä¹Ÿåˆ äº†.</p></li></ul><p>ä½ å¯ä»¥å¤šæ¬¡<code>stash</code>ï¼Œæ¢å¤çš„æ—¶å€™ï¼Œå…ˆç”¨<code>git stash list</code>æŸ¥çœ‹ï¼Œç„¶åæ¢å¤æŒ‡å®šçš„<code>stash</code>ï¼Œç”¨å‘½ä»¤ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git stash apply stash@&#123;0&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>ä¿®å¤bugæ—¶ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡åˆ›å»ºæ–°çš„bugåˆ†æ”¯è¿›è¡Œä¿®å¤ï¼Œç„¶ååˆå¹¶ï¼Œæœ€ååˆ é™¤ï¼› å½“æ‰‹å¤´å·¥ä½œæ²¡æœ‰å®Œæˆæ—¶ï¼Œå…ˆæŠŠå·¥ä½œç°åœº<code>git stash</code>ä¸€ä¸‹ï¼Œç„¶åå»ä¿®å¤bugï¼Œä¿®å¤åï¼Œå†<code>git stash pop</code>ï¼Œå›åˆ°å·¥ä½œç°åœºã€‚</p></blockquote><h3><span id="featureåˆ†æ”¯">Featureåˆ†æ”¯</span></h3><p>å¼€å‘ä¸€ä¸ªæ–°featureï¼Œæœ€å¥½æ–°å»ºä¸€ä¸ªåˆ†æ”¯ï¼›</p><p>å¦‚æœè¦ä¸¢å¼ƒä¸€ä¸ªæ²¡æœ‰è¢«åˆå¹¶è¿‡çš„åˆ†æ”¯ï¼Œå¯ä»¥é€šè¿‡<code>git branch -D &lt;name&gt;</code>å¼ºè¡Œåˆ é™¤ã€‚</p><h3><span id="å¤šäººåä½œ">å¤šäººåä½œ</span></h3><p>è¦æŸ¥çœ‹è¿œç¨‹åº“çš„ä¿¡æ¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote [-v]</span><br></pre></td></tr></table></figure></p><p>ä½†æ˜¯ï¼Œå¹¶ä¸æ˜¯ä¸€å®šè¦æŠŠæœ¬åœ°åˆ†æ”¯å¾€è¿œç¨‹æ¨é€ï¼Œé‚£ä¹ˆï¼Œå“ªäº›åˆ†æ”¯éœ€è¦æ¨é€ï¼Œå“ªäº›ä¸éœ€è¦å‘¢ï¼Ÿ</p><ul><li><code>master</code>åˆ†æ”¯æ˜¯ä¸»åˆ†æ”¯ï¼Œå› æ­¤è¦<strong>æ—¶åˆ»ä¸è¿œç¨‹åŒæ­¥</strong>ï¼›</li><li><code>dev</code>åˆ†æ”¯æ˜¯å¼€å‘åˆ†æ”¯ï¼Œå›¢é˜Ÿæ‰€æœ‰æˆå‘˜éƒ½éœ€è¦åœ¨ä¸Šé¢å·¥ä½œï¼Œæ‰€ä»¥<strong>ä¹Ÿéœ€è¦ä¸è¿œç¨‹åŒæ­¥</strong>ï¼›</li><li>bugåˆ†æ”¯åªç”¨äºåœ¨æœ¬åœ°ä¿®å¤bugï¼Œå°±<strong>æ²¡å¿…è¦æ¨åˆ°è¿œç¨‹</strong>äº†ï¼Œé™¤éè€æ¿è¦çœ‹çœ‹ä½ æ¯å‘¨åˆ°åº•ä¿®å¤äº†å‡ ä¸ªbugï¼›</li><li>featureåˆ†æ”¯æ˜¯å¦æ¨åˆ°è¿œç¨‹ï¼Œå–å†³äºä½ æ˜¯å¦å’Œä½ çš„å°ä¼™ä¼´åˆä½œåœ¨ä¸Šé¢å¼€å‘ã€‚</li></ul><p>æ€»ä¹‹ï¼Œå°±æ˜¯åœ¨Gitä¸­ï¼Œ<strong>åˆ†æ”¯å®Œå…¨å¯ä»¥åœ¨æœ¬åœ°è‡ªå·±è—ç€ç©ï¼Œæ˜¯å¦æ¨é€ï¼Œè§†ä½ çš„å¿ƒæƒ…è€Œå®šï¼</strong></p><h2><span id="æ ‡ç­¾ç®¡ç†">æ ‡ç­¾ç®¡ç†</span></h2><blockquote><p>å‘å¸ƒä¸€ä¸ªç‰ˆæœ¬æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å…ˆåœ¨ç‰ˆæœ¬åº“ä¸­æ‰“ä¸€ä¸ªæ ‡ç­¾ï¼Œè¿™æ ·ï¼Œå°±å”¯ä¸€ç¡®å®šäº†æ‰“æ ‡ç­¾æ—¶åˆ»çš„ç‰ˆæœ¬ã€‚å°†æ¥æ— è®ºä»€ä¹ˆæ—¶å€™ï¼Œå–æŸä¸ªæ ‡ç­¾çš„ç‰ˆæœ¬ï¼Œå°±æ˜¯æŠŠé‚£ä¸ªæ‰“æ ‡ç­¾çš„æ—¶åˆ»çš„å†å²ç‰ˆæœ¬å–å‡ºæ¥ã€‚æ‰€ä»¥ï¼Œæ ‡ç­¾ä¹Ÿæ˜¯ç‰ˆæœ¬åº“çš„ä¸€ä¸ªå¿«ç…§ã€‚</p></blockquote><blockquote><p>Gitçš„æ ‡ç­¾è™½ç„¶æ˜¯ç‰ˆæœ¬åº“çš„å¿«ç…§ï¼Œä½†å…¶å®å®ƒå°±æ˜¯æŒ‡å‘æŸä¸ª<code>commit</code>çš„æŒ‡é’ˆï¼ˆè·Ÿåˆ†æ”¯å¾ˆåƒå¯¹ä¸å¯¹ï¼Ÿä½†æ˜¯åˆ†æ”¯å¯ä»¥ç§»åŠ¨ï¼Œæ ‡ç­¾ä¸èƒ½ç§»åŠ¨ï¼‰ï¼Œæ‰€ä»¥ï¼Œåˆ›å»ºå’Œåˆ é™¤æ ‡ç­¾éƒ½æ˜¯ç¬é—´å®Œæˆçš„ã€‚</p></blockquote><h3><span id="åˆ›å»ºæ ‡ç­¾">åˆ›å»ºæ ‡ç­¾</span></h3><p>åœ¨Gitä¸­æ‰“æ ‡ç­¾éå¸¸ç®€å•ï¼Œé¦–å…ˆï¼Œåˆ‡æ¢åˆ°éœ€è¦æ‰“æ ‡ç­¾çš„åˆ†æ”¯ä¸Šï¼Œç„¶åï¼Œæ•²å‘½ä»¤<code>git tag &lt;name&gt;</code>å°±å¯ä»¥æ‰“ä¸€ä¸ªæ–°æ ‡ç­¾ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git tag v1.0</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥ç”¨å‘½ä»¤<code>git tag</code>æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git tag</span><br><span class="line">v1.0</span><br></pre></td></tr></table></figure></p><p>é»˜è®¤æ ‡ç­¾æ˜¯æ‰“åœ¨æœ€æ–°æäº¤çš„<code>commit</code>ä¸Šçš„ã€‚æœ‰æ—¶å€™ï¼Œå¦‚æœå¿˜äº†æ‰“æ ‡ç­¾ï¼Œæ¯”å¦‚ï¼Œç°åœ¨å·²ç»æ˜¯å‘¨äº”äº†ï¼Œä½†åº”è¯¥åœ¨å‘¨ä¸€æ‰“çš„æ ‡ç­¾æ²¡æœ‰æ‰“ï¼Œæ€ä¹ˆåŠï¼Ÿ</p><p>æ–¹æ³•æ˜¯æ‰¾åˆ°å†å²æäº¤çš„<code>commit id</code>ï¼Œç„¶åæ‰“ä¸Šå°±å¯ä»¥äº†ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ git log --pretty=oneline --abbrev-commit</span><br><span class="line">6a5819e merged bug fix 101</span><br><span class="line">cc17032 fix bug 101</span><br><span class="line">7825a50 merge with no-ff</span><br><span class="line">6224937 add merge</span><br><span class="line">59bc1cb conflict fixed</span><br><span class="line">400b400 &amp; simple</span><br><span class="line">75a857c AND simple</span><br><span class="line">fec145a branch test</span><br><span class="line">d17efd8 remove test.txt</span><br><span class="line"></span><br><span class="line">æ¯”æ–¹è¯´è¦å¯¹add mergeè¿™æ¬¡æäº¤æ‰“æ ‡ç­¾ï¼Œå®ƒå¯¹åº”çš„commit idæ˜¯6224937ï¼Œæ•²å…¥å‘½ä»¤ï¼š</span><br><span class="line"></span><br><span class="line">$ git tag v0.9 6224937</span><br></pre></td></tr></table></figure></p><p><strong>æ³¨æ„ï¼Œæ ‡ç­¾ä¸æ˜¯æŒ‰æ—¶é—´é¡ºåºåˆ—å‡ºï¼Œè€Œæ˜¯æŒ‰å­—æ¯æ’åºçš„ã€‚</strong> å¯ä»¥ç”¨<code>git show &lt;tagname&gt;</code>æŸ¥çœ‹æ ‡ç­¾ä¿¡æ¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ git show v0.9</span><br><span class="line">commit 622493706ab447b6bb37e4e2a2f276a20fed2ab4</span><br><span class="line">Author: Michael Liao &lt;askxuefeng@gmail.com&gt;</span><br><span class="line">Date:   Thu Aug 22 11:22:08 2013 +0800</span><br><span class="line"></span><br><span class="line">    add merge</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>è¿˜å¯ä»¥åˆ›å»ºå¸¦æœ‰è¯´æ˜çš„æ ‡ç­¾ï¼Œç”¨<code>-a</code>æŒ‡å®šæ ‡ç­¾åï¼Œ<code>-m</code>æŒ‡å®šè¯´æ˜æ–‡å­—ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -a v0.1 -m &quot;version 0.1 released&quot; 3628164</span><br></pre></td></tr></table></figure></p><p>è¿˜å¯ä»¥é€šè¿‡<code>-s</code>ç”¨ç§é’¥ç­¾åä¸€ä¸ªæ ‡ç­¾ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -s v0.2 -m &quot;signed version 0.2 released&quot; fec145a</span><br></pre></td></tr></table></figure></p><p>ç­¾åé‡‡ç”¨PGPç­¾åï¼Œå› æ­¤ï¼Œå¿…é¡»é¦–å…ˆå®‰è£…gpgï¼ˆGnuPGï¼‰ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°gpgï¼Œæˆ–è€…æ²¡æœ‰gpgå¯†é’¥å¯¹ï¼Œå°±ä¼šæŠ¥é”™ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpg: signing failed: secret key not available</span><br><span class="line">error: gpg failed to sign the data</span><br><span class="line">error: unable to sign the tag</span><br></pre></td></tr></table></figure></p><p>å¦‚æœæŠ¥é”™ï¼Œè¯·å‚è€ƒGnuPGå¸®åŠ©æ–‡æ¡£é…ç½®Keyã€‚</p><p><strong>å°ç»“</strong>ï¼š * å‘½ä»¤<code>git tag &lt;name&gt;</code>ç”¨äºæ–°å»ºä¸€ä¸ªæ ‡ç­¾ï¼Œé»˜è®¤ä¸º<code>HEAD</code>ï¼Œä¹Ÿå¯ä»¥æŒ‡å®šä¸€ä¸ª<code>commit id</code>ï¼›</p><ul><li><p><code>git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;</code>å¯ä»¥æŒ‡å®šæ ‡ç­¾ä¿¡æ¯ï¼›</p></li><li><p><code>git tag -s &lt;tagname&gt; -m &quot;blablabla...&quot;</code>å¯ä»¥ç”¨PGPç­¾åæ ‡ç­¾ï¼›</p></li><li><p>å‘½ä»¤<code>git tag</code>å¯ä»¥æŸ¥çœ‹æ‰€æœ‰æ ‡ç­¾ã€‚</p></li></ul><h3><span id="æ“ä½œæ ‡ç­¾">æ“ä½œæ ‡ç­¾</span></h3><p>å¦‚æœæ ‡ç­¾æ‰“é”™äº†ï¼Œä¹Ÿå¯ä»¥åˆ é™¤ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -d v0.1</span><br><span class="line">Deleted tag &apos;v0.1&apos; (was e078af9)</span><br></pre></td></tr></table></figure></p><p>å› ä¸ºåˆ›å»ºçš„æ ‡ç­¾éƒ½åªå­˜å‚¨åœ¨æœ¬åœ°ï¼Œä¸ä¼šè‡ªåŠ¨æ¨é€åˆ°è¿œç¨‹ã€‚æ‰€ä»¥ï¼Œæ‰“é”™çš„æ ‡ç­¾å¯ä»¥åœ¨æœ¬åœ°å®‰å…¨åˆ é™¤ã€‚</p><p>å¦‚æœè¦æ¨é€æŸä¸ªæ ‡ç­¾åˆ°è¿œç¨‹ï¼Œä½¿ç”¨å‘½ä»¤<code>git push origin &lt;tagname&gt;</code>ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin v1.0</span><br></pre></td></tr></table></figure></p><p>æˆ–è€…ï¼Œä¸€æ¬¡æ€§æ¨é€å…¨éƒ¨å°šæœªæ¨é€åˆ°è¿œç¨‹çš„æœ¬åœ°æ ‡ç­¾ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin --tags</span><br></pre></td></tr></table></figure></p><p>å¦‚æœæ ‡ç­¾å·²ç»æ¨é€åˆ°è¿œç¨‹ï¼Œè¦åˆ é™¤è¿œç¨‹æ ‡ç­¾å°±éº»çƒ¦ä¸€ç‚¹ï¼Œå…ˆä»æœ¬åœ°åˆ é™¤ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -d v0.9</span><br><span class="line">Deleted tag &apos;v0.9&apos; (was 6224937)</span><br></pre></td></tr></table></figure></p><p>ç„¶åï¼Œä»è¿œç¨‹åˆ é™¤ã€‚åˆ é™¤å‘½ä»¤ä¹Ÿæ˜¯pushï¼Œä½†æ˜¯æ ¼å¼å¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin :refs/tags/v0.9</span><br><span class="line">To git@github.com:michaelliao/learngit.git</span><br><span class="line"> - [deleted]         v0.9</span><br></pre></td></tr></table></figure></p><p><strong>å°ç»“</strong></p><ul><li><p>å‘½ä»¤<code>git push origin &lt;tagname&gt;</code>å¯ä»¥æ¨é€ä¸€ä¸ªæœ¬åœ°æ ‡ç­¾ï¼›</p></li><li><p>å‘½ä»¤<code>git push origin --tags</code>å¯ä»¥æ¨é€å…¨éƒ¨æœªæ¨é€è¿‡çš„æœ¬åœ°æ ‡ç­¾ï¼›</p></li><li><p>å‘½ä»¤<code>git tag -d &lt;tagname&gt;</code>å¯ä»¥åˆ é™¤ä¸€ä¸ªæœ¬åœ°æ ‡ç­¾ï¼›</p></li><li><p>å‘½ä»¤<code>git push origin :refs/tags/&lt;tagname&gt;</code>å¯ä»¥åˆ é™¤ä¸€ä¸ªè¿œç¨‹æ ‡ç­¾ã€‚</p></li></ul><h2><span id="è‡ªå®šä¹‰git">è‡ªå®šä¹‰Git</span></h2><p>è®©Gitæ˜¾ç¤ºé¢œè‰²ï¼Œä¼šè®©å‘½ä»¤è¾“å‡ºçœ‹èµ·æ¥æ›´é†’ç›®ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global color.ui true</span><br></pre></td></tr></table></figure></p><h3><span id="å¿½ç•¥ç‰¹æ®Šæ–‡ä»¶">å¿½ç•¥ç‰¹æ®Šæ–‡ä»¶</span></h3><blockquote><p>åœ¨Gitå·¥ä½œåŒºçš„æ ¹ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªç‰¹æ®Šçš„<code>.gitignore</code>æ–‡ä»¶ï¼Œç„¶åæŠŠè¦å¿½ç•¥çš„æ–‡ä»¶åå¡«è¿›å»ï¼ŒGitå°±ä¼šè‡ªåŠ¨å¿½ç•¥è¿™äº›æ–‡ä»¶ã€‚</p></blockquote><p>ä¸éœ€è¦ä»å¤´å†™<code>.gitignore</code>æ–‡ä»¶ï¼ŒGitHubå·²ç»ä¸ºæˆ‘ä»¬å‡†å¤‡äº†å„ç§é…ç½®æ–‡ä»¶ï¼Œåªéœ€è¦ç»„åˆä¸€ä¸‹å°±å¯ä»¥ä½¿ç”¨äº†ã€‚æ‰€æœ‰é…ç½®æ–‡ä»¶å¯ä»¥ç›´æ¥åœ¨çº¿æµè§ˆï¼šhttps://github.com/github/gitignore</p><p><strong>å¿½ç•¥æ–‡ä»¶çš„åŸåˆ™æ˜¯ï¼š</strong></p><ul><li>å¿½ç•¥æ“ä½œç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶ï¼Œæ¯”å¦‚ç¼©ç•¥å›¾ç­‰ï¼›</li><li>å¿½ç•¥ç¼–è¯‘ç”Ÿæˆçš„ä¸­é—´æ–‡ä»¶ã€å¯æ‰§è¡Œæ–‡ä»¶ç­‰ï¼Œä¹Ÿå°±æ˜¯å¦‚æœä¸€ä¸ªæ–‡ä»¶æ˜¯é€šè¿‡å¦ä¸€ä¸ªæ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œé‚£è‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶å°±æ²¡å¿…è¦æ”¾è¿›ç‰ˆæœ¬åº“ï¼Œæ¯”å¦‚Javaç¼–è¯‘äº§ç”Ÿçš„<code>.class</code>æ–‡ä»¶ï¼›</li><li>å¿½ç•¥ä½ è‡ªå·±çš„å¸¦æœ‰æ•æ„Ÿä¿¡æ¯çš„é…ç½®æ–‡ä»¶ï¼Œæ¯”å¦‚å­˜æ”¾å£ä»¤çš„é…ç½®æ–‡ä»¶ã€‚</li></ul><p>æœ€åè¦æŠŠ<code>.gitignore</code>æäº¤åˆ°Gitï¼Œå°±å®Œæˆäº†ã€‚ æ£€éªŒ<code>.gitignore</code>çš„æ ‡å‡†æ˜¯<code>git status</code>å‘½ä»¤æ˜¯ä¸æ˜¯è¯´<code>working directory clean</code>ã€‚</p><h3><span id="é…ç½®åˆ«å">é…ç½®åˆ«å</span></h3><p>å¦‚æœæ•²<code>git st</code>å°±è¡¨ç¤º<code>git status</code>é‚£å°±ç®€å•å¤šäº†ï¼Œå½“ç„¶è¿™ç§å·æ‡’çš„åŠæ³•æˆ‘ä»¬æ˜¯æåŠ›èµæˆçš„ã€‚</p><p>æˆ‘ä»¬åªéœ€è¦æ•²ä¸€è¡Œå‘½ä»¤ï¼Œå‘Šè¯‰Gitï¼Œä»¥å<code>st</code>å°±è¡¨ç¤º<code>status</code>ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global alias.st status</span><br></pre></td></tr></table></figure></p><p><code>--global</code>å‚æ•°æ˜¯å…¨å±€å‚æ•°ï¼Œä¹Ÿå°±æ˜¯è¿™äº›å‘½ä»¤åœ¨è¿™å°ç”µè„‘çš„æ‰€æœ‰Gitä»“åº“ä¸‹éƒ½æœ‰ç”¨ã€‚</p><p>é…ç½®ä¸€ä¸ª<code>git last</code>ï¼Œè®©å…¶æ˜¾ç¤ºæœ€åä¸€æ¬¡æäº¤ä¿¡æ¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global alias.last &apos;log -1&apos;</span><br></pre></td></tr></table></figure></p><p>ç”šè‡³è¿˜æœ‰äººä¸§å¿ƒç—…ç‹‚åœ°æŠŠlgé…ç½®æˆäº†ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global alias.lg &quot;log --color --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit&quot;</span><br></pre></td></tr></table></figure></p><p>æ¥çœ‹çœ‹git lgçš„æ•ˆæœï¼š <img src="/images/1446651004964.png" alt="Alt text"></p><h4><span id="é…ç½®æ–‡ä»¶">é…ç½®æ–‡ä»¶</span></h4><p>é…ç½®æ–‡ä»¶æ”¾å“ªäº†ï¼Ÿæ¯ä¸ªä»“åº“çš„Gité…ç½®æ–‡ä»¶éƒ½æ”¾åœ¨<code>.git/config</code>æ–‡ä»¶ä¸­ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ cat .git/config </span><br><span class="line">[core]</span><br><span class="line">    repositoryformatversion = 0</span><br><span class="line">    filemode = true</span><br><span class="line">    bare = false</span><br><span class="line">    logallrefupdates = true</span><br><span class="line">    ignorecase = true</span><br><span class="line">    precomposeunicode = true</span><br><span class="line">[remote &quot;origin&quot;]</span><br><span class="line">    url = git@github.com:michaelliao/learngit.git</span><br><span class="line">    fetch = +refs/heads/*:refs/remotes/origin/*</span><br><span class="line">[branch &quot;master&quot;]</span><br><span class="line">    remote = origin</span><br><span class="line">    merge = refs/heads/master</span><br><span class="line">[alias]</span><br><span class="line">    last = log -1</span><br></pre></td></tr></table></figure></p><p>åˆ«åå°±åœ¨<code>[alias]</code>åé¢ï¼Œè¦åˆ é™¤åˆ«åï¼Œç›´æ¥æŠŠå¯¹åº”çš„è¡Œåˆ æ‰å³å¯ã€‚</p><p>è€Œå½“å‰ç”¨æˆ·çš„Gité…ç½®æ–‡ä»¶æ”¾åœ¨ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„ä¸€ä¸ªéšè—æ–‡ä»¶<code>.gitconfig</code>ä¸­ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat .gitconfig</span><br><span class="line">[alias]</span><br><span class="line">    co = checkout</span><br><span class="line">    ci = commit</span><br><span class="line">    br = branch</span><br><span class="line">    st = status</span><br><span class="line">[user]</span><br><span class="line">    name = Your Name</span><br><span class="line">    email = your@email.com</span><br></pre></td></tr></table></figure></p><p>é…ç½®åˆ«åä¹Ÿå¯ä»¥ç›´æ¥ä¿®æ”¹è¿™ä¸ªæ–‡ä»¶ï¼Œå¦‚æœæ”¹é”™äº†ï¼Œå¯ä»¥åˆ æ‰æ–‡ä»¶é‡æ–°é€šè¿‡å‘½ä»¤é…ç½®ã€‚</p><h3><span id="æ­å»ºgitæœåŠ¡å™¨">æ­å»ºGitæœåŠ¡å™¨</span></h3><p>å‡è®¾ä½ å·²ç»æœ‰<code>sudo</code>æƒé™çš„ç”¨æˆ·è´¦å·ï¼Œä¸‹é¢ï¼Œæ­£å¼å¼€å§‹å®‰è£…ã€‚</p><p><strong>ç¬¬ä¸€æ­¥ï¼Œå®‰è£…gitï¼š</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install git</span><br></pre></td></tr></table></figure></p><p><strong>ç¬¬äºŒæ­¥ï¼Œåˆ›å»ºä¸€ä¸ªgitç”¨æˆ·ï¼Œç”¨æ¥è¿è¡ŒgitæœåŠ¡ï¼š</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo adduser git</span><br></pre></td></tr></table></figure></p><p><strong>ç¬¬ä¸‰æ­¥ï¼Œåˆ›å»ºè¯ä¹¦ç™»å½•ï¼š</strong></p><p>æ”¶é›†æ‰€æœ‰éœ€è¦ç™»å½•çš„ç”¨æˆ·çš„å…¬é’¥ï¼Œå°±æ˜¯ä»–ä»¬è‡ªå·±çš„<code>id_rsa.pub</code>æ–‡ä»¶ï¼ŒæŠŠæ‰€æœ‰å…¬é’¥å¯¼å…¥åˆ°<code>/home/git/.ssh/authorized_keys</code>æ–‡ä»¶é‡Œï¼Œä¸€è¡Œä¸€ä¸ªã€‚</p><p><strong>ç¬¬å››æ­¥ï¼Œåˆå§‹åŒ–Gitä»“åº“ï¼š</strong></p><p>å…ˆé€‰å®šä¸€ä¸ªç›®å½•ä½œä¸ºGitä»“åº“ï¼Œå‡å®šæ˜¯<code>/srv/sample.git</code>ï¼Œåœ¨<code>/srv</code>ç›®å½•ä¸‹è¾“å…¥å‘½ä»¤ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo git init --bare sample.git</span><br></pre></td></tr></table></figure></p><p>Gitå°±ä¼šåˆ›å»ºä¸€ä¸ªè£¸ä»“åº“ï¼Œè£¸ä»“åº“æ²¡æœ‰å·¥ä½œåŒºï¼Œå› ä¸ºæœåŠ¡å™¨ä¸Šçš„Gitä»“åº“çº¯ç²¹æ˜¯ä¸ºäº†å…±äº«ï¼Œæ‰€ä»¥ä¸è®©ç”¨æˆ·ç›´æ¥ç™»å½•åˆ°æœåŠ¡å™¨ä¸Šå»æ”¹å·¥ä½œåŒºï¼Œå¹¶ä¸”æœåŠ¡å™¨ä¸Šçš„Gitä»“åº“é€šå¸¸éƒ½ä»¥.gitç»“å°¾ã€‚ç„¶åï¼ŒæŠŠ<code>owner</code>æ”¹ä¸ºgitï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo chown -R git:git sample.git</span><br></pre></td></tr></table></figure></p><p><strong>ç¬¬äº”æ­¥ï¼Œç¦ç”¨shellç™»å½•ï¼š</strong></p><p>å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œç¬¬äºŒæ­¥åˆ›å»ºçš„gitç”¨æˆ·ä¸å…è®¸ç™»å½•shellï¼Œè¿™å¯ä»¥é€šè¿‡ç¼–è¾‘<code>/etc/passwd</code>æ–‡ä»¶å®Œæˆã€‚æ‰¾åˆ°ç±»ä¼¼ä¸‹é¢çš„ä¸€è¡Œï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git:x:1001:1001:,,,:/home/git:/bin/bash</span><br><span class="line">æ”¹ä¸ºï¼š</span><br><span class="line">git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell</span><br></pre></td></tr></table></figure></p><p>è¿™æ ·ï¼Œgitç”¨æˆ·å¯ä»¥æ­£å¸¸é€šè¿‡<code>ssh</code>ä½¿ç”¨gitï¼Œä½†æ— æ³•ç™»å½•<code>shell</code>ï¼Œå› ä¸ºæˆ‘ä»¬ä¸ºgitç”¨æˆ·æŒ‡å®šçš„<code>git-shell</code>æ¯æ¬¡ä¸€ç™»å½•å°±è‡ªåŠ¨é€€å‡ºã€‚</p><p><strong>ç¬¬å…­æ­¥ï¼Œå…‹éš†è¿œç¨‹ä»“åº“ï¼š</strong></p><p>ç°åœ¨ï¼Œå¯ä»¥é€šè¿‡<code>git clone</code>å‘½ä»¤å…‹éš†è¿œç¨‹ä»“åº“äº†ï¼Œåœ¨å„è‡ªçš„ç”µè„‘ä¸Šè¿è¡Œï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git@server:/srv/sample.git</span><br><span class="line">Cloning into &apos;sample&apos;...</span><br><span class="line">warning: You appear to have cloned an empty repository.</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>è®°å½•ï¼šArchlinuxæ­å»ºphpï¼Œnginxï¼Œmysqlå¼€å‘ç¯å¢ƒ</title>
      <link href="/2015/12/18/%E8%AE%B0%E5%BD%95%EF%BC%9AArchlinux%E6%90%AD%E5%BB%BAphp%EF%BC%8Cnginx%EF%BC%8Cmysql%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"/>
      <url>/2015/12/18/%E8%AE%B0%E5%BD%95%EF%BC%9AArchlinux%E6%90%AD%E5%BB%BAphp%EF%BC%8Cnginx%EF%BC%8Cmysql%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h2><span id="installation">Installation</span></h2><h3><span id="å®‰è£…php">å®‰è£…php</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S php</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="å®‰è£…php-fpm">å®‰è£…php-fpm</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S php-fpm</span><br></pre></td></tr></table></figure><h3><span id="å®‰è£…nginx">å®‰è£…nginx</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S nginx</span><br></pre></td></tr></table></figure><h3><span id="å®‰è£…mariadb">å®‰è£…Mariadb</span></h3><blockquote><p>Mariadbæ˜¯mysqlçš„ä¸€ä¸ªåˆ†æ”¯</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> sudo pacman -S mysql</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">## Configuration</span><br><span class="line"></span><br><span class="line">### é…ç½® Nginx</span><br><span class="line">é…ç½®æ–‡ä»¶ï¼š/etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><h1><span id="ä¿®æ”¹éƒ¨åˆ†">ä¿®æ”¹éƒ¨åˆ†</span></h1><h1><span id="æŠŠrootç›®å½•ç§»å‡ºloactionå¹¶åŠ ä¸Šindexphp">æŠŠrootç›®å½•ç§»å‡ºloaction,å¹¶åŠ ä¸Šindex.php</span></h1><p>root /usr/share/nginx/html; location / { index index.html index.htm index.php; }</p><h1><span id="æ³¨é‡Šæ‰rootå’Œparamä¿®æ”¹passå’Œinlude">æ³¨é‡Šæ‰rootå’Œparam,ä¿®æ”¹passå’Œinlude</span></h1><p>location ~ .php$ { #root html; fastcgi_pass unix:/run/php-fpm/php-fpm.sock; fastcgi_index index.php; #fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; include fastcgi.conf ; } <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">**webç›®å½•ä¸º `/usr/share/nginx/html` **</span><br><span class="line"></span><br><span class="line">### é…ç½® php-fpm</span><br><span class="line">é…ç½®æ–‡ä»¶ï¼š/etc/php/php-fpm.conf</span><br><span class="line"></span><br><span class="line">è®© listen çš„å€¼ä¸ä¹‹å‰ nginx é…ç½®ä¸­çš„ fastcgi_pass å€¼ä¿æŒä¸€è‡´ã€‚</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">$ listen = /run/php-fpm/php-fpm.sock</span><br></pre></td></tr></table></figure></p><h3><span id="é…ç½®php">é…ç½®php</span></h3><p>é…ç½®æ–‡ä»¶ï¼š /etc/php/php.ini</p><p><code>open_basedir</code> ä¸­åŠ ä¸Š nginx æœåŠ¡å™¨çš„æ ¹ç›®å½•ï¼ˆ /usr/share/nginx/html/ ï¼‰ã€‚å³å‘Šè¯‰ php ç¨‹åºè¦å»è§£æé‚£ä¸ªç›®å½•ä¸‹çš„ php æ–‡ä»¶</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open_basedir = /usr/share/nginx/html/:/srv/http/:/home/:/tmp/:/usr/share/pear/:/usr/share/webapps/</span><br></pre></td></tr></table></figure><p>å¯ç”¨ä»¥ä¸‹æ‰©å±•ã€‚å»æ‰é‚£è¡Œå¼€å¤´çš„åˆ†å·å³å¯ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">extension=curl.so</span><br><span class="line">extension=gd.so</span><br><span class="line">extension=gettext.so</span><br><span class="line">extension=mysql.so</span><br><span class="line">extension=mysqli.so</span><br><span class="line">extension=phar.so</span><br><span class="line">extension=pdo_mysql.so</span><br></pre></td></tr></table></figure></p><h3><span id="é…ç½®æ•°æ®åº“">é…ç½®æ•°æ®åº“</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Install mariadb</span><br><span class="line">$ mysql_install_db --user=mysql --basedir=/usr --datadir=/var/lib/mysql</span><br><span class="line"></span><br><span class="line"># starting the mysqld.service, &apos;d&apos; is important</span><br><span class="line">$ sudo systemctl start mysqld.service</span><br><span class="line"></span><br><span class="line"># è®¾ç½®rootå¯†ç </span><br><span class="line">$ mysql_secure_installation</span><br><span class="line"></span><br><span class="line"># Upgrade MariaDB</span><br><span class="line">$ mysql_upgrade -u root -p</span><br></pre></td></tr></table></figure><h2><span id="å¯åŠ¨æœåŠ¡å™¨">å¯åŠ¨æœåŠ¡å™¨</span></h2><h3><span id="è®¾ç½®ä¸ºå¼€æœºå¯åŠ¨">è®¾ç½®ä¸ºå¼€æœºå¯åŠ¨</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl enable nginx.service</span><br><span class="line">$ sudo systemctl enable mysqld.service</span><br><span class="line">$ sudo systemctl enable php-fpm.service</span><br></pre></td></tr></table></figure><h4><span id="å¯åŠ¨æœåŠ¡å™¨">å¯åŠ¨æœåŠ¡å™¨</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start nginx.service</span><br><span class="line">$ sudo systemctl start mysqld.service</span><br><span class="line">$ sudo systemctl start php-fpm.service</span><br></pre></td></tr></table></figure><p>é…ç½®å®Œæ¯•</p><hr><p>å‚è€ƒï¼š <a href="http://www.it165.net/pro/html/201410/23683.html" target="_blank" rel="noopener">Archlinux ä¸Š Nginx + PHP + Mariadb + DiscuzX2.5 å®‰è£…å°è®°</a> <a href="https://wiki.archlinux.org/index.php/MySQL" target="_blank" rel="noopener">MySQL-ArchWiki</a> <a href="https://wiki.archlinux.org/index.php/Nginx" target="_blank" rel="noopener">Nginx-ArchWiki</a></p>]]></content>
      
      
      <categories>
          
          <category> åšå®¢ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> MySQL </tag>
            
            <tag> åå°å¼€å‘ </tag>
            
            <tag> PHP </tag>
            
            <tag> Arch </tag>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>gdbåŸºæœ¬ä½¿ç”¨æ–¹æ³•</title>
      <link href="/2015/12/17/gdb%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>/2015/12/17/gdb%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>ä¸€ä¸ªé™¤é”™ç¨‹åºæ‰§è¡Œçš„æµç¨‹é€šå¸¸æ˜¯è¿™æ ·çš„ï¼š</p><ol type="1"><li>è¿›å…¥é™¤é”™ç¨‹åºå¹¶æŒ‡å®šå¯æ‰§è¡Œæ–‡ä»¶ã€‚</li><li>æŒ‡å®šç¨‹åºä»£ç æ‰€åœ¨ç›®å½•ã€‚</li><li>è®¾å®šæ–­ç‚¹åæ‰§è¡Œç¨‹åºã€‚</li><li>ç¨‹åºäºæ–­ç‚¹ä¸­æ–­åï¼Œå¯ä»¥ 1. æ£€è§†ç¨‹åºæ‰§è¡ŒçŠ¶æ€ï¼›æ£€è§†å˜é‡å€¼æˆ–å˜æ›´å˜é‡å€¼ 2. é€æ­¥æ‰§è¡Œç¨‹åºï¼Œæˆ–æ˜¯å…¨é€Ÿæ‰§è¡Œç¨‹åºåˆ°ä¸‹ä¸€ä¸ªæ–­ç‚¹æˆ–æ˜¯åˆ°ç¨‹åºç»“æŸä¸ºæ­¢ã€‚</li><li>ç¦»å¼€é™¤é”™ç¨‹åºã€‚</li></ol><a id="more"></a><h3><span id="è¿›å…¥-gdb-åŠæŒ‡å®šå¯æ‰§è¡Œæ¡£">è¿›å…¥ GDB åŠæŒ‡å®šå¯æ‰§è¡Œæ¡£ï¼š</span></h3><p>è¿›å…¥ GDB å¹¶è¯»å…¥å¯æ‰§è¡Œæ¡£ (æ¡£åä¸º <code>PROGRAM</code>)ï¼Œå‡†å¤‡è¿›è¡Œé™¤é”™ã€‚ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb PROGRAM</span><br></pre></td></tr></table></figure></p><h3><span id="æŒ‡å®šç¨‹åºä»£ç æ‰€åœ¨ç›®å½•åŠæ£€è§†ç¨‹åºä»£ç ">æŒ‡å®šç¨‹åºä»£ç æ‰€åœ¨ç›®å½•åŠæ£€è§†ç¨‹åºä»£ç </span></h3><p>å¢åŠ ç›®å½•<code>DIR</code>åˆ°æ”¶å¯»ç¨‹åºä»£ç çš„ç›®å½•åˆ—è¡¨ (å¦‚æœä½ çš„ç¨‹åºä»£ç å’Œå¯æ‰§è¡Œæ¡£æ”¾åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ï¼Œå°±ä¸é¡»æŒ‡å®šç¨‹åºä»£ç æ‰€åœ¨ç›®å½•ã€‚)ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) directory DIR</span><br></pre></td></tr></table></figure></p><h4><span id="æ£€è§†ç¨‹åºä»£ç æ ¼å¼è®¡æœ‰">æ£€è§†ç¨‹åºä»£ç ï¼Œæ ¼å¼è®¡æœ‰ï¼š</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(gdb) list // æ˜¾ç¤ºç›®å‰æ‰§è¡Œç¨‹åºä»£ç å‰åå„äº”è¡Œçš„ç¨‹åºä»£ç ï¼›æˆ–æ˜¯æ˜¾ç¤ºä»ä¸Šæ¬¡ list ä¹‹åçš„ç¨‹åºä»£ç </span><br><span class="line">(gdb) list function // æ˜¾ç¤ºè¯¥ç¨‹åºå¼€å§‹å¤„å‰åäº”è¡Œçš„ç¨‹åºä»£ç ã€‚</span><br><span class="line">(gdb) list - //ä¸Šæ¬¡æ˜¾ç¤ºç¨‹åºä»£ç çš„å‰é¢çš„åè¡Œã€‚</span><br></pre></td></tr></table></figure><h3><span id="æ–­ç‚¹çš„è®¾å®šä¸æ¸…é™¤">æ–­ç‚¹çš„è®¾å®šä¸æ¸…é™¤</span></h3><h4><span id="è®¾å®šæ–­ç‚¹æŒ‡ä»¤ä¸º-breakå¯ç®€å†™ä¸º-bæ ¼å¼è®¡æœ‰">è®¾å®šæ–­ç‚¹(æŒ‡ä»¤ä¸º <code>break</code>ï¼Œå¯ç®€å†™ä¸º (<code>b</code>)ï¼Œæ ¼å¼è®¡æœ‰ï¼š</span></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(gdb) <span class="keyword">break</span> filename.c:<span class="number">30</span> <span class="comment">// åœ¨ filename.c çš„ç¬¬ä¸‰åè¡Œå¤„åœæ­¢æ‰§è¡Œã€‚</span></span><br><span class="line">(gdb) <span class="keyword">break</span> function <span class="comment">// åœ¨è¿›å…¥ function æ—¶ä¸­æ–­ç¨‹åºçš„æ‰§è¡Œã€‚</span></span><br><span class="line">(gdb) <span class="keyword">break</span> filename.c:function <span class="comment">// åœ¨ç¨‹åºä»£ç æ¡£ filename.c ä¸­çš„å‡½æ•° function å¤„è®¾å®šæ–­ç‚¹ã€‚</span></span><br><span class="line">(gdb) <span class="keyword">break</span> <span class="comment">// åœ¨ä¸‹ä¸€ä¸ªå°†è¢«æ‰§è¡Œçš„å‘½ä»¤è®¾å®šæ–­ç‚¹ã€‚</span></span><br><span class="line">(gdb) <span class="keyword">break</span> ... <span class="keyword">if</span> cond <span class="comment">// åªæœ‰å½“ cond æˆç«‹çš„æ—¶å€™æ‰ä¸­æ–­ã€‚cond é¡»ä»¥ C è¯­è¨€çš„è¯­æ³•å†™æˆã€‚</span></span><br></pre></td></tr></table></figure><h4><span id="æ˜¾ç¤ºå„ä¸ªæ–­ç‚¹çš„ä¿¡æ¯">æ˜¾ç¤ºå„ä¸ªæ–­ç‚¹çš„ä¿¡æ¯ã€‚</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) info break</span><br></pre></td></tr></table></figure><h4><span id="æ¸…é™¤æ–­ç‚¹å‘½ä»¤ä¸º-clearæ ¼å¼åŒ-break-ä¾‹å¦‚">æ¸…é™¤æ–­ç‚¹(å‘½ä»¤ä¸º <code>clear</code>)ï¼Œæ ¼å¼åŒ <code>break</code> ã€‚ä¾‹å¦‚ :</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) clear filename.c:30</span><br></pre></td></tr></table></figure><h4><span id="æ¸…é™¤æ–­ç‚¹num-æ˜¯åœ¨-info-break-æ˜¾ç¤ºå‡ºæ¥çš„æ–­ç‚¹ç¼–å·">æ¸…é™¤æ–­ç‚¹ï¼Œ<code>NUM</code> æ˜¯åœ¨ <code>info break</code> æ˜¾ç¤ºå‡ºæ¥çš„æ–­ç‚¹ç¼–å·</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) delete NUM</span><br></pre></td></tr></table></figure><h3><span id="å…¨é€ŸåŠé€æ­¥æ‰§è¡Œç¨‹åº">å…¨é€ŸåŠé€æ­¥æ‰§è¡Œç¨‹åº</span></h3><h5><span id="ä»ç¨‹åºå¼€å¤´å…¨é€Ÿæ‰§è¡Œç¨‹åºç›´åˆ°é‡åˆ°æ–­ç‚¹æˆ–æ˜¯ç¨‹åºæ‰§è¡Œå®Œæ¯•ä¸ºæ­¢">ä»ç¨‹åºå¼€å¤´å…¨é€Ÿæ‰§è¡Œç¨‹åºï¼Œç›´åˆ°é‡åˆ°æ–­ç‚¹æˆ–æ˜¯ç¨‹åºæ‰§è¡Œå®Œæ¯•ä¸ºæ­¢</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) run</span><br></pre></td></tr></table></figure><h5><span id="åœ¨ç¨‹åºè¢«ä¸­æ–­åå…¨é€Ÿæ‰§è¡Œç¨‹åºåˆ°ä¸‹ä¸€ä¸ªæ–­ç‚¹æˆ–æ˜¯ç¨‹åºç»“æŸä¸ºæ­¢-continue-æŒ‡ä»¤å¯ç®€å†™ä¸º-c">åœ¨ç¨‹åºè¢«ä¸­æ–­åï¼Œå…¨é€Ÿæ‰§è¡Œç¨‹åºåˆ°ä¸‹ä¸€ä¸ªæ–­ç‚¹æˆ–æ˜¯ç¨‹åºç»“æŸä¸ºæ­¢ (<code>continue</code> æŒ‡ä»¤å¯ç®€å†™ä¸º <code>c</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) continue</span><br></pre></td></tr></table></figure><h5><span id="æ‰§è¡Œä¸€è¡Œç¨‹åº-è‹¥å‘¼å«å‡½æ•°-åˆ™å°†è¯¥åŒ…å«è¯¥å‡½æ•°ç¨‹åºä»£ç è§†ä¸ºä¸€è¡Œç¨‹åº-next-æŒ‡ä»¤å¯ç®€å†™ä¸º-n">æ‰§è¡Œä¸€è¡Œç¨‹åº. è‹¥å‘¼å«å‡½æ•°, åˆ™å°†è¯¥åŒ…å«è¯¥å‡½æ•°ç¨‹åºä»£ç è§†ä¸ºä¸€è¡Œç¨‹åº (<code>next</code> æŒ‡ä»¤å¯ç®€å†™ä¸º <code>n</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) next</span><br></pre></td></tr></table></figure><h5><span id="æ‰§è¡Œä¸€è¡Œç¨‹åº-è‹¥å‘¼å«å‡½æ•°-åˆ™è¿›å…¥å‡½æ•°é€è¡Œæ‰§è¡Œ-step-æŒ‡ä»¤å¯ç®€å†™ä¸º-s">æ‰§è¡Œä¸€è¡Œç¨‹åº. è‹¥å‘¼å«å‡½æ•°, åˆ™è¿›å…¥å‡½æ•°é€è¡Œæ‰§è¡Œ (<code>step</code> æŒ‡ä»¤å¯ç®€å†™ä¸º <code>s</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) step</span><br></pre></td></tr></table></figure><h5><span id="æ‰§è¡Œä¸€è¡Œç¨‹åºè‹¥æ­¤æ—¶ç¨‹åºæ˜¯åœ¨-forwhiledo-loop-å¾ªç¯çš„æœ€åä¸€è¡Œåˆ™ä¸€ç›´æ‰§è¡Œåˆ°å¾ªç¯ç»“æŸåçš„ç¬¬ä¸€è¡Œç¨‹åºååœæ­¢-until-æŒ‡ä»¤å¯ç®€å†™ä¸º-u">æ‰§è¡Œä¸€è¡Œç¨‹åºï¼Œè‹¥æ­¤æ—¶ç¨‹åºæ˜¯åœ¨ <code>for/while/do loop</code> å¾ªç¯çš„æœ€åä¸€è¡Œï¼Œåˆ™ä¸€ç›´æ‰§è¡Œåˆ°å¾ªç¯ç»“æŸåçš„ç¬¬ä¸€è¡Œç¨‹åºååœæ­¢ (<code>until</code> æŒ‡ä»¤å¯ç®€å†™ä¸º <code>u</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) until</span><br></pre></td></tr></table></figure><h4><span id="æ‰§è¡Œç°è¡Œç¨‹åºåˆ°å›åˆ°ä¸Šä¸€å±‚ç¨‹åºä¸ºæ­¢">æ‰§è¡Œç°è¡Œç¨‹åºåˆ°å›åˆ°ä¸Šä¸€å±‚ç¨‹åºä¸ºæ­¢ã€‚</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) finish</span><br></pre></td></tr></table></figure><h3><span id="æ£€è§†åŠæ›´æ”¹å˜é‡å€¼">æ£€è§†åŠæ›´æ”¹å˜é‡å€¼</span></h3><h5><span id="print-å™è¿°æ˜¾ç¤ºè¯¥å™è¿°æ‰§è¡Œçš„ç»“æœ-print-æŒ‡ä»¤å¯ç®€å†™ä¸º-på¦‚"><code>print</code> å™è¿°ï¼Œæ˜¾ç¤ºè¯¥å™è¿°æ‰§è¡Œçš„ç»“æœ (<code>print</code> æŒ‡ä»¤å¯ç®€å†™ä¸º <code>p</code>).å¦‚</span></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gdb) print a <span class="comment">// æ˜¾ç¤º a å˜é‡çš„å†…å®¹.</span></span><br><span class="line">(gdb) <span class="function">print <span class="title">sizeof</span><span class="params">(a)</span> <span class="comment">// æ˜¾ç¤º a å˜é‡çš„é•¿åº¦.</span></span></span><br></pre></td></tr></table></figure><h5><span id="display-å™è¿°åœ¨æ¯ä¸ªæ–­ç‚¹æˆ–æ˜¯æ¯æ‰§è¡Œä¸€æ­¥æ—¶æ˜¾ç¤ºè¯¥å™è¿°å€¼-å¦‚"><code>display</code> å™è¿°ï¼Œåœ¨æ¯ä¸ªæ–­ç‚¹æˆ–æ˜¯æ¯æ‰§è¡Œä¸€æ­¥æ—¶æ˜¾ç¤ºè¯¥å™è¿°å€¼ã€‚å¦‚</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) display a</span><br></pre></td></tr></table></figure><h5><span id="æ›´æ”¹å˜é‡å€¼">æ›´æ”¹å˜é‡å€¼ï¼š</span></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) print (a=<span class="number">10</span>) <span class="comment">// å°†å˜é‡ a çš„å€¼è®¾å®šä¸º 10.</span></span><br></pre></td></tr></table></figure><h3><span id="æ£€è§†ç¨‹åºæ‰§è¡ŒçŠ¶æ€">æ£€è§†ç¨‹åºæ‰§è¡ŒçŠ¶æ€</span></h3><h4><span id="æŸ¥çœ‹ç¨‹åºæ‰§è¡Œåˆ°æ­¤æ—¶æ˜¯ç»è¿‡å“ªäº›å‡½æ•°å‘¼å«çš„ç¨‹åº-backtrace-æŒ‡ä»¤å¯ç®€å†™ä¸º-btä¹Ÿå°±æ˜¯æŸ¥çœ‹å‡½æ•°å‘¼å«å †æ ˆ">æŸ¥çœ‹ç¨‹åºæ‰§è¡Œåˆ°æ­¤æ—¶ï¼Œæ˜¯ç»è¿‡å“ªäº›å‡½æ•°å‘¼å«çš„ç¨‹åº (<code>backtrace</code> æŒ‡ä»¤å¯ç®€å†™ä¸º <code>bt</code>)ï¼Œä¹Ÿå°±æ˜¯æŸ¥çœ‹å‡½æ•°å‘¼å«å †æ ˆã€‚</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) backtrace</span><br></pre></td></tr></table></figure><h3><span id="è¯»å–-core-æ–‡ä»¶ä¿¡æ¯">è¯»å– Core æ–‡ä»¶ä¿¡æ¯</span></h3><h5><span id="è¯»å…¥-program-åŠ-programcore-æ¡£å¯æ£€è§†-core-dump-æ—¶ç¨‹åºå˜é‡å€¼åŠç¨‹åºæµç¨‹çŠ¶æ€">è¯»å…¥ <code>PROGRAM</code> åŠ <code>PROGRAM.CORE</code> æ¡£ï¼Œå¯æ£€è§† Core Dump æ—¶ç¨‹åºå˜é‡å€¼åŠç¨‹åºæµç¨‹çŠ¶æ€ ã€‚</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb PROGRAM core</span><br></pre></td></tr></table></figure><blockquote><p>è¯´æ˜ï¼š<code>core</code> æ¡£æ¡ˆæ˜¯ç”± <code>PROGRAM</code> æ¡£æ‰§è¡Œåï¼Œé‡åˆ° Core Dump æ—¶äº§ç”Ÿçš„ Core æª”æª”åã€‚å¦‚æœä½ è¿˜éœ€è¦è¯¥ Core æ¡£ï¼Œæˆ‘ä»¬å»ºè®®ä½ å°†è¯¥æ¡£æ¡ˆæ¡£åæ›´æ”¹ä¸º <code>PROGRAM.core</code>ã€‚åœ¨è¾“å…¥ä¸Šè¿°å‘½ä»¤åï¼Œä½ å¯ä»¥ç”¨ GDB æä¾›çš„æ£€è§†å˜é‡å€¼ä»¥åŠæ£€è§†ç¨‹åºæ‰§è¡ŒçŠ¶æ€æ¥è¯»å–ç¨‹åº Core Dump æ—¶çš„çŠ¶æ€ã€‚</p></blockquote><h3><span id="æŸ¥çœ‹æ±‡ç¼–ä»£ç -å¯„å­˜å™¨-å†…å­˜ç­‰">æŸ¥çœ‹æ±‡ç¼–ä»£ç ã€å¯„å­˜å™¨ã€å†…å­˜ç­‰</span></h3><p><strong>æŸ¥çœ‹æ±‡ç¼–ä»£ç </strong></p><p>æŸ¥çœ‹ä»å½“å‰ä½ç½®å¾€å10è¡Œçš„ä»£ç  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x /10i $pc</span><br></pre></td></tr></table></figure></p><p><strong>æŸ¥çœ‹å¯„å­˜å™¨çš„å€¼</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">info register</span><br><span class="line">info all-registers</span><br><span class="line">info registers &lt;regname ...&gt;</span><br></pre></td></tr></table></figure><p><strong>æŸ¥çœ‹å†…å­˜çš„å€¼</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x /10x *&lt;addr&gt;</span><br><span class="line">x /10x $esp</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GDB </tag>
            
            <tag> Debug </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>åœ¨PHPè¯­è¨€ä¸­ä½¿ç”¨JSON</title>
      <link href="/2015/12/17/%E5%9C%A8PHP%E8%AF%AD%E8%A8%80%E4%B8%AD%E4%BD%BF%E7%94%A8JSON/"/>
      <url>/2015/12/17/%E5%9C%A8PHP%E8%AF%AD%E8%A8%80%E4%B8%AD%E4%BD%BF%E7%94%A8JSON/</url>
      
        <content type="html"><![CDATA[<blockquote><p>ä»5.2ç‰ˆæœ¬å¼€å§‹ï¼ŒPHPåŸç”Ÿæä¾›<code>json_encode()</code>å’Œ<code>json_decode()</code>å‡½æ•°ï¼Œå‰è€…ç”¨äºç¼–ç ï¼Œåè€…ç”¨äºè§£ç ã€‚</p></blockquote><a id="more"></a><h2><span id="json_encode">json_encode()</span></h2><p>è¯¥å‡½æ•°ä¸»è¦ç”¨æ¥å°†æ•°ç»„å’Œå¯¹è±¡ï¼Œè½¬æ¢ä¸ºjsonæ ¼å¼ã€‚å…ˆçœ‹ä¸€ä¸ªæ•°ç»„è½¬æ¢çš„ä¾‹å­ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$arr = array(&apos;a&apos;=&gt;1,&apos;b&apos;=&gt;2,&apos;c&apos;=&gt;3,&apos;d&apos;=&gt;4,&apos;e&apos;=&gt;5);</span><br><span class="line">echo json_encode($arr);</span><br></pre></td></tr></table></figure></p><p>ç»“æœä¸º <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;</span><br></pre></td></tr></table></figure></p><p>ã€€ã€€ å†çœ‹ä¸€ä¸ªå¯¹è±¡è½¬æ¢çš„ä¾‹å­ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$obj-&gt;body = &apos;another post&apos;;ã€€ã€€</span><br><span class="line">$obj-&gt;id = 21;ã€€ã€€</span><br><span class="line">$obj-&gt;approved = true;ã€€ã€€</span><br><span class="line">$obj-&gt;favorite_count = 1;ã€€</span><br><span class="line">$obj-&gt;status= NULL;</span><br><span class="line">ã€€ã€€</span><br><span class="line">echo json_encode($obj);</span><br></pre></td></tr></table></figure></p><p>ç»“æœä¸º <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€&#123;</span><br><span class="line">ã€€ã€€ã€€ã€€&quot;body&quot;:&quot;another post&quot;,</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€ã€€ã€€&quot;id&quot;:21,</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€ã€€ã€€&quot;approved&quot;:true,</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€ã€€ã€€&quot;favorite_count&quot;:1,</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€ã€€ã€€&quot;status&quot;:null</span><br><span class="line">ã€€ã€€&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>ç”±äºjsonåªæ¥å—utf-8ç¼–ç çš„å­—ç¬¦ï¼Œæ‰€ä»¥json_encode()çš„å‚æ•°å¿…é¡»æ˜¯utf-8ç¼–ç ï¼Œå¦åˆ™ä¼šå¾—åˆ°ç©ºå­—ç¬¦æˆ–è€…nullã€‚å½“ä¸­æ–‡ä½¿ç”¨GB2312ç¼–ç ï¼Œæˆ–è€…å¤–æ–‡ä½¿ç”¨ISO-8859-1ç¼–ç çš„æ—¶å€™ï¼Œè¿™ä¸€ç‚¹è¦ç‰¹åˆ«æ³¨æ„ã€‚</p></blockquote><h3><span id="ç´¢å¼•æ•°ç»„å’Œå…³è”æ•°ç»„">ç´¢å¼•æ•°ç»„å’Œå…³è”æ•°ç»„</span></h3><blockquote><p>PHPæ”¯æŒä¸¤ç§æ•°ç»„ï¼Œä¸€ç§æ˜¯åªä¿å­˜&quot;å€¼&quot;ï¼ˆvalueï¼‰çš„ç´¢å¼•æ•°ç»„ï¼ˆindexed arrayï¼‰ï¼Œå¦ä¸€ç§æ˜¯ä¿å­˜&quot;åå€¼å¯¹&quot;ï¼ˆname/valueï¼‰çš„å…³è”æ•°ç»„ï¼ˆassociative arrayï¼‰ã€‚ ç”±äºjavascriptä¸æ”¯æŒå…³è”æ•°ç»„ï¼Œæ‰€ä»¥json_encode()åªå°†ç´¢å¼•æ•°ç»„ï¼ˆindexed arrayï¼‰è½¬ä¸ºæ•°ç»„æ ¼å¼ï¼Œè€Œå°†å…³è”æ•°ç»„ï¼ˆassociative arrayï¼‰è½¬ä¸ºå¯¹è±¡æ ¼å¼ã€‚</p></blockquote><p>æ¯”å¦‚ï¼Œç°åœ¨æœ‰ä¸€ä¸ªç´¢å¼•æ•°ç»„ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$arr = Array(&apos;one&apos;, &apos;two&apos;, &apos;three&apos;);</span><br><span class="line">echo json_encode($arr);</span><br></pre></td></tr></table></figure></p><p>ç»“æœä¸ºï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€[&quot;one&quot;,&quot;two&quot;,&quot;three&quot;]</span><br></pre></td></tr></table></figure></p><p>å¦‚æœå°†å®ƒæ”¹ä¸ºå…³è”æ•°ç»„ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$arr = Array(&apos;1&apos;=&gt;&apos;one&apos;, &apos;2&apos;=&gt;&apos;two&apos;, &apos;3&apos;=&gt;&apos;three&apos;);</span><br><span class="line">echo json_encode($arr);</span><br></pre></td></tr></table></figure></p><p>ç»“æœå°±å˜äº†ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;1&quot;:&quot;one&quot;,&quot;2&quot;:&quot;two&quot;,&quot;3&quot;:&quot;three&quot;&#125;</span><br></pre></td></tr></table></figure></p><p><strong>æ³¨æ„ï¼Œæ•°æ®æ ¼å¼ä»[]ï¼ˆæ•°ç»„ï¼‰å˜æˆäº†{}ï¼ˆå¯¹è±¡ï¼‰ã€‚</strong></p><p>å¦‚æœä½ éœ€è¦å°†&quot;ç´¢å¼•æ•°ç»„&quot;å¼ºåˆ¶è½¬åŒ–æˆ&quot;å¯¹è±¡&quot;ï¼Œå¯ä»¥è¿™æ ·å†™ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€json_encode( (object)$arr );</span><br></pre></td></tr></table></figure></p><p>æˆ–è€… <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€json_encode ( $arr, JSON_FORCE_OBJECT );</span><br></pre></td></tr></table></figure></p><h3><span id="ç±»classçš„è½¬æ¢">ç±»ï¼ˆclassï¼‰çš„è½¬æ¢</span></h3><p>ä¸‹é¢æ˜¯ä¸€ä¸ªPHPçš„ç±»ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Foo &#123;</span><br><span class="line">  const     ERROR_CODE = &apos;404&apos;;</span><br><span class="line">  public    $public_ex = &apos;this is public&apos;;</span><br><span class="line">  private   $private_ex = &apos;this is private!&apos;;ã€€</span><br><span class="line">  protected $protected_ex = &apos;this should be protected&apos;; </span><br><span class="line"> ã€€ã€€</span><br><span class="line">  public function getErrorCode() &#123;</span><br><span class="line">    return self::ERROR_CODE;</span><br><span class="line">  &#125;ã€€ã€€</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>ç°åœ¨ï¼Œå¯¹è¿™ä¸ªç±»çš„å®ä¾‹è¿›è¡Œjsonè½¬æ¢ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€$foo = new Foo;</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€$foo_json = json_encode($foo);</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€echo $foo_json;</span><br></pre></td></tr></table></figure></p><p>è¾“å‡ºç»“æœæ˜¯ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€&#123;&quot;public_ex&quot;:&quot;this is public&quot;&#125;</span><br></pre></td></tr></table></figure></p><p>å¯ä»¥çœ‹åˆ°ï¼Œé™¤äº†å…¬å¼€å˜é‡ï¼ˆpublicï¼‰ï¼Œå…¶ä»–ä¸œè¥¿ï¼ˆå¸¸é‡ã€ç§æœ‰å˜é‡ã€æ–¹æ³•ç­‰ç­‰ï¼‰éƒ½é—å¤±äº†ã€‚</p><h2><span id="json_decode">json_decode()</span></h2><blockquote><p>è¯¥å‡½æ•°ç”¨äºå°†jsonæ–‡æœ¬è½¬æ¢ä¸ºç›¸åº”çš„PHPæ•°æ®ç»“æ„ã€‚</p></blockquote><p>ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€$json = &apos;&#123;&quot;foo&quot;: 12345&#125;&apos;;</span><br><span class="line">ã€€ã€€$obj = json_decode($json);</span><br><span class="line">ã€€ã€€print $obj-&gt;&#123;&apos;foo&apos;&#125;; // 12345</span><br></pre></td></tr></table></figure></p><p>é€šå¸¸æƒ…å†µä¸‹ï¼Œ<code>json_decode()</code>æ€»æ˜¯<strong>è¿”å›ä¸€ä¸ªPHPå¯¹è±¡ï¼Œè€Œä¸æ˜¯æ•°ç»„</strong>ã€‚ æ¯”å¦‚ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$json = &apos;&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;&apos;;</span><br><span class="line">var_dump(json_decode($json));</span><br></pre></td></tr></table></figure></p><p>ç»“æœå°±æ˜¯ç”Ÿæˆä¸€ä¸ªPHPå¯¹è±¡ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€object(stdClass)#1 (5) &#123;</span><br><span class="line">ã€€ã€€ã€€ã€€[&quot;a&quot;] =&gt; int(1)</span><br><span class="line">ã€€ã€€ã€€ã€€[&quot;b&quot;] =&gt; int(2)</span><br><span class="line">ã€€ã€€ã€€ã€€[&quot;c&quot;] =&gt; int(3)</span><br><span class="line">ã€€ã€€ã€€ã€€[&quot;d&quot;] =&gt; int(4)</span><br><span class="line">ã€€ã€€ã€€ã€€[&quot;e&quot;] =&gt; int(5)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>å¦‚æœæƒ³è¦å¼ºåˆ¶ç”ŸæˆPHPå…³è”æ•°ç»„ï¼Œjson_decode()éœ€è¦åŠ ä¸€ä¸ªå‚æ•°true</strong>ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$json = &apos;&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;&apos;;</span><br><span class="line">var_dump(json_decode($json,true));</span><br></pre></td></tr></table></figure></p><p>ç»“æœå°±ç”Ÿæˆäº†ä¸€ä¸ªå…³è”æ•°ç»„ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€array(5) &#123;</span><br><span class="line">ã€€ã€€ ã€€ã€€[&quot;a&quot;] =&gt; int(1)</span><br><span class="line">ã€€ã€€ ã€€ã€€[&quot;b&quot;] =&gt; int(2)</span><br><span class="line">ã€€ã€€ ã€€ã€€[&quot;c&quot;] =&gt; int(3)</span><br><span class="line">ã€€ã€€ ã€€ã€€[&quot;d&quot;] =&gt; int(4)</span><br><span class="line">ã€€ã€€ ã€€ã€€[&quot;e&quot;] =&gt; int(5)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3><span id="json_decodeçš„å¸¸è§é”™è¯¯">json_decode()çš„å¸¸è§é”™è¯¯</span></h3><p>ä¸‹é¢ä¸‰ç§jsonå†™æ³•éƒ½æ˜¯é”™çš„ï¼Œä½ èƒ½çœ‹å‡ºé”™åœ¨å“ªé‡Œå—ï¼Ÿ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ã€€ã€€$bad_json = &quot;&#123; &apos;bar&apos;: &apos;baz&apos; &#125;&quot;;</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€$bad_json = &apos;&#123; bar: &quot;baz&quot; &#125;&apos;;</span><br><span class="line">ã€€ã€€</span><br><span class="line">ã€€ã€€$bad_json = &apos;&#123; &quot;bar&quot;: &quot;baz&quot;, &#125;&apos;;</span><br></pre></td></tr></table></figure></p><p><strong>å¯¹è¿™ä¸‰ä¸ªå­—ç¬¦ä¸²æ‰§è¡Œjson_decode()éƒ½å°†è¿”å›nullï¼Œå¹¶ä¸”æŠ¥é”™</strong>ã€‚ &gt; ç¬¬ä¸€ä¸ªçš„é”™è¯¯æ˜¯ï¼Œ<strong>jsonçš„åˆ†éš”ç¬¦ï¼ˆdelimiterï¼‰åªå…è®¸ä½¿ç”¨åŒå¼•å·ï¼Œä¸èƒ½ä½¿ç”¨å•å¼•å·</strong>ã€‚ &gt; ç¬¬äºŒä¸ªçš„é”™è¯¯æ˜¯ï¼Œ<strong>jsonåå€¼å¯¹çš„&quot;å&quot;ï¼ˆå†’å·å·¦è¾¹çš„éƒ¨åˆ†ï¼‰ï¼Œä»»ä½•æƒ…å†µä¸‹éƒ½å¿…é¡»ä½¿ç”¨åŒå¼•å·</strong>ã€‚ &gt; ç¬¬ä¸‰ä¸ªçš„é”™è¯¯æ˜¯ï¼Œ<strong>æœ€åä¸€ä¸ªå€¼ä¹‹åä¸èƒ½æ·»åŠ é€—å·ï¼ˆtrailing commaï¼‰</strong>ã€‚</p><blockquote><p>å¦å¤–ï¼Œjsonåªèƒ½ç”¨æ¥è¡¨ç¤ºå¯¹è±¡<code>(object)</code>å’Œæ•°ç»„<code>(array)</code>ï¼Œå¦‚æœå¯¹ä¸€ä¸ªå­—ç¬¦ä¸²æˆ–æ•°å€¼ä½¿ç”¨<code>json_decode()</code>ï¼Œå°†ä¼šè¿”å›<code>null</code>ã€‚ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var_dump(json_decode(&quot;Hello World&quot;)); //null</span><br></pre></td></tr></table></figure></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
            <tag> JSON </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL ç¬”è®°</title>
      <link href="/2015/12/17/MySQL%20%E7%AC%94%E8%AE%B0/"/>
      <url>/2015/12/17/MySQL%20%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h3><span id="ç™»é™†">ç™»é™†</span></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mysql [-h hostname] -u username -p</span></span><br><span class="line">Enter Password:</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="æ–°å»ºæ•°æ®åº“">æ–°å»ºæ•°æ®åº“</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database dbname;</span><br></pre></td></tr></table></figure><h3><span id="åˆ›å»ºç”¨æˆ·å’Œåˆ†é…æƒé™">åˆ›å»ºç”¨æˆ·å’Œåˆ†é…æƒé™</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">privileges</span> [columes] </span><br><span class="line"><span class="keyword">ON</span> item</span><br><span class="line"><span class="keyword">TO</span> user_name [<span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'password'</span>]</span><br><span class="line">[REQUIRE ssl_options]</span><br><span class="line">[<span class="keyword">WITH</span> [<span class="keyword">GRANT</span> <span class="keyword">OPTION</span> | limit_options] ]</span><br></pre></td></tr></table></figure><h5><span id="åˆ›å»ºç”¨æˆ·">åˆ›å»ºç”¨æˆ·</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER &apos;username&apos;@&apos;host&apos; IDENTIFIED BY &apos;password&apos;;</span><br></pre></td></tr></table></figure><h5><span id="æˆæƒ">æˆæƒ</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos;</span><br></pre></td></tr></table></figure><p>è¯´æ˜: privileges â€“ ç”¨æˆ·çš„æ“ä½œæƒé™,å¦‚<code>SELECT</code> , <code>INSERT</code> , <code>UPDATE</code> ç­‰.å¦‚æœè¦æˆäºˆæ‰€ çš„æƒé™åˆ™ä½¿ç”¨<code>ALL</code>.;<code>databasename</code> â€“ æ•°æ®åº“å,<code>tablename</code>-è¡¨å,å¦‚æœè¦æˆäºˆè¯¥ç”¨æˆ·å¯¹æ‰€æœ‰æ•°æ®åº“å’Œè¡¨çš„ç›¸åº”æ“ä½œæƒé™åˆ™å¯ç”¨<code>*</code> è¡¨ç¤º, å¦‚: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GRANT SELECT, INSERT ON test.user TO &apos;pig&apos;@&apos;%&apos;;</span><br></pre></td></tr></table></figure></p><h3><span id="ä½¿ç”¨æ•°æ®åº“">ä½¿ç”¨æ•°æ®åº“</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use dbname;</span><br></pre></td></tr></table></figure><h3><span id="åˆ›å»ºæ•°æ®åº“è¡¨">åˆ›å»ºæ•°æ®åº“è¡¨</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE DATABASE dbname;</span><br><span class="line">mysql&gt; CREATE TABLE tablename (columns);</span><br><span class="line">// ä¸›æ–‡ä»¶ä¸­è½½å…¥</span><br><span class="line">mysql&gt; -h host -u username -D dbname -p &lt; bookorama.sql;</span><br></pre></td></tr></table></figure><p>ä¸¾ä¾‹ï¼š <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE books(</span><br><span class="line">isbn char(13) NOT NULL PRIMARY KEY,</span><br><span class="line">author char(50),</span><br><span class="line">title char(100),</span><br><span class="line">price float(4, 2)</span><br><span class="line">);</span><br></pre></td></tr></table></figure></p><h3><span id="æŸ¥çœ‹æ•°æ®åº“">æŸ¥çœ‹æ•°æ®åº“</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show tables;</span><br><span class="line">mysql&gt; show database;</span><br><span class="line">mysql&gt; describe tables;// æŸ¥çœ‹æŸä¸ªè¡¨çš„è¯¦ç»†ä¿¡æ¯</span><br></pre></td></tr></table></figure><h3><span id="ç´¢å¼•">ç´¢å¼•</span></h3><blockquote><p>ç´¢å¼•çš„åˆ›å»ºå¯ä»¥åœ¨<code>CREATE TABLE</code>è¯­å¥ä¸­è¿›è¡Œï¼Œä¹Ÿå¯ä»¥å•ç‹¬ç”¨<code>CREATE INDEX</code>æˆ–<code>ALTER TABLE</code>æ¥ç»™è¡¨å¢åŠ ç´¢å¼•ã€‚åˆ é™¤ç´¢å¼•å¯ä»¥åˆ©ç”¨<code>ALTER TABLE</code>æˆ–<code>DROP INDEX</code>è¯­å¥æ¥å®ç°ã€‚</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">UNIQUE</span> | FULLTEXT] <span class="keyword">INDEX</span> index_name <span class="keyword">ON</span> table_name (index_column_name [(<span class="keyword">length</span>)] [<span class="keyword">ASC</span>|<span class="keyword">DESC</span>], ...)</span><br></pre></td></tr></table></figure><h4><span id="ä½¿ç”¨alter-tableè¯­å¥åˆ›å»ºç´¢å¼•">ä½¿ç”¨<code>ALTER TABLE</code>è¯­å¥åˆ›å»ºç´¢å¼•</span></h4><p>è¯­æ³•å¦‚ä¸‹ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter table table_name add index index_name (column_list) ;</span><br><span class="line">alter table table_name add unique (column_list) ;</span><br><span class="line">alter table table_name add primary key (column_list) ;</span><br></pre></td></tr></table></figure></p><p>å…¶ä¸­åŒ…æ‹¬ * æ™®é€šç´¢å¼•ã€<code>UNIQUE</code>ç´¢å¼•å’Œ<code>PRIMARY KEY</code>ç´¢å¼•3ç§åˆ›å»ºç´¢å¼•çš„æ ¼å¼ * <code>table_name</code>æ˜¯è¦å¢åŠ ç´¢å¼•çš„è¡¨å * <code>column_list</code>æŒ‡å‡ºå¯¹å“ªäº›åˆ—è¿›è¡Œç´¢å¼•ï¼Œ<strong>å¤šåˆ—æ—¶å„åˆ—ä¹‹é—´ç”¨é€—å·åˆ†éš”</strong>ã€‚ * ç´¢å¼•å<code>index_name</code>å¯é€‰ï¼Œç¼ºçœæ—¶ï¼ŒMySQLå°†æ ¹æ®ç¬¬ä¸€ä¸ªç´¢å¼•åˆ—èµ‹ä¸€ä¸ªåç§°ã€‚ * <code>ALTER TABLE</code>å…è®¸åœ¨å•ä¸ªè¯­å¥ä¸­æ›´æ”¹å¤šä¸ªè¡¨ï¼Œå› æ­¤å¯ä»¥åŒæ—¶åˆ›å»ºå¤šä¸ªç´¢å¼•ã€‚</p><p>åˆ›å»ºç´¢å¼•çš„ç¤ºä¾‹å¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; alter table table_test add index index_test1(name) ;</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br></pre></td></tr></table></figure></p><h4><span id="ä½¿ç”¨create-indexè¯­å¥å¯¹è¡¨å¢åŠ ç´¢å¼•">ä½¿ç”¨<code>CREATE INDEX</code>è¯­å¥å¯¹è¡¨å¢åŠ ç´¢å¼•</span></h4><p>èƒ½å¤Ÿå¢åŠ æ™®é€šç´¢å¼•å’Œ<code>UNIQUE</code>ç´¢å¼•ä¸¤ç§ã€‚å…¶æ ¼å¼å¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create index index_name on table_name (column_list) ;</span><br><span class="line">create unique index index_name on table_name (column_list) ;</span><br></pre></td></tr></table></figure></p><p>åˆ›å»ºç´¢å¼•çš„ç¤ºä¾‹å¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create index index_test2 on table_test(age);</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br></pre></td></tr></table></figure></p><p>è¯´æ˜ï¼š<code>table_name</code>ã€<code>index_name</code>å’Œ<code>column_list</code>å…·æœ‰ä¸<code>ALTER TABLE</code>è¯­å¥ä¸­ç›¸åŒçš„å«ä¹‰ï¼Œç´¢å¼•åä¸å¯é€‰ã€‚å¦å¤–ï¼Œä¸èƒ½ç”¨<code>CREATE INDEX</code>è¯­å¥åˆ›å»º<code>PRIMARY KEY</code>ç´¢å¼•ã€‚</p><h4><span id="åˆ é™¤ç´¢å¼•">åˆ é™¤ç´¢å¼•</span></h4><blockquote><p>åˆ é™¤ç´¢å¼•å¯ä»¥ä½¿ç”¨<code>ALTER TABLE</code>æˆ–<code>DROP INDEX</code>è¯­å¥æ¥å®ç°ã€‚</p></blockquote><p><code>DROP INDEX</code>å¯ä»¥åœ¨<code>ALTER TABLE</code>å†…éƒ¨ä½œä¸ºä¸€æ¡è¯­å¥å¤„ç†ï¼Œå…¶æ ¼å¼å¦‚ä¸‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">drop index index_name on table_name ;</span><br><span class="line">alter table table_name drop index index_name ;</span><br><span class="line">alter table table_name drop primary key ;</span><br></pre></td></tr></table></figure></p><p>å…¶ä¸­ï¼Œåœ¨å‰é¢çš„ä¸¤æ¡è¯­å¥ä¸­ï¼Œéƒ½åˆ é™¤äº†<code>table_name</code>ä¸­çš„ç´¢å¼•<code>index_name</code>ã€‚è€Œåœ¨æœ€åä¸€æ¡è¯­å¥ä¸­ï¼Œåªåœ¨åˆ é™¤<code>PRIMARY KEY</code>ç´¢å¼•ä¸­ä½¿ç”¨ï¼Œå› ä¸ºä¸€ä¸ªè¡¨åªå¯èƒ½æœ‰ä¸€ä¸ª<code>PRIMARY KEY</code>ç´¢å¼•ï¼Œå› æ­¤ä¸éœ€è¦æŒ‡å®šç´¢å¼•åã€‚å¦‚æœæ²¡æœ‰åˆ›å»º<code>PRIMARY KEY</code>ç´¢å¼•ï¼Œä½†è¡¨å…·æœ‰ä¸€ä¸ªæˆ–å¤šä¸ª<code>UNIQUE</code>ç´¢å¼•ï¼Œåˆ™MySQLå°†åˆ é™¤ç¬¬ä¸€ä¸ª<code>UNIQUE</code>ç´¢å¼•ã€‚</p><blockquote><p>å¦‚æœä»è¡¨ä¸­åˆ é™¤æŸåˆ—ï¼Œåˆ™ç´¢å¼•ä¼šå—å½±å“ã€‚å¯¹äºå¤šåˆ—ç»„åˆçš„ç´¢å¼•ï¼Œå¦‚æœåˆ é™¤å…¶ä¸­çš„æŸåˆ—ï¼Œåˆ™è¯¥åˆ—ä¹Ÿä¼šä»ç´¢å¼•ä¸­åˆ é™¤ã€‚å¦‚æœåˆ é™¤ç»„æˆç´¢å¼•çš„æ‰€æœ‰åˆ—ï¼Œåˆ™æ•´ä¸ªç´¢å¼•å°†è¢«åˆ é™¤ã€‚</p></blockquote><p>åˆ é™¤ç´¢å¼•çš„æ“ä½œï¼Œå¦‚ä¸‹é¢çš„ä»£ç ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; drop index name on table_test ;</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br></pre></td></tr></table></figure></p><h3><span id="æ•°æ®ç±»å‹">æ•°æ®ç±»å‹</span></h3><h4><span id="æ•´æ•°ç±»å‹">æ•´æ•°ç±»å‹</span></h4><table><thead><tr class="header"><th style="text-align: left;">ç±»å‹</th><th style="text-align: left;">å–å€¼èŒƒå›´</th><th style="text-align: center;">å­˜å‚¨ç©ºé—´</th><th style="text-align: left;">æè¿°</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">TINYINT[(M)]</td><td style="text-align: left;">-127<sub>128æˆ–0</sub>255</td><td style="text-align: center;">1</td><td style="text-align: left;">éå¸¸å°çš„æ•´æ•°</td></tr><tr class="even"><td style="text-align: left;">BIT</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">TINYINTçš„åŒä¹‰è¯</td></tr><tr class="odd"><td style="text-align: left;">BOOL</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">TINYINTçš„åŒä¹‰è¯</td></tr><tr class="even"><td style="text-align: left;">SMALLINT[(M)]</td><td style="text-align: left;">-32768<sub>32767æˆ–0</sub>65535</td><td style="text-align: center;">2</td><td style="text-align: left;">å°å‹æ•´æ•°</td></tr><tr class="odd"><td style="text-align: left;">MEDIUMINT[(M)]</td><td style="text-align: left;">-8388608<sub>8883607æˆ–0</sub>16777215</td><td style="text-align: center;">3</td><td style="text-align: left;">ä¸­å‹æ•´æ•°</td></tr><tr class="even"><td style="text-align: left;">INT[(M)]</td><td style="text-align: left;"><span class="math inline">\(-2^{31}\)</span><sub><span class="math inline">\(2^{31}-1\)</span>æˆ–0</sub><span class="math inline">\(2^{32}-1\)</span></td><td style="text-align: center;">4</td><td style="text-align: left;">ä¸€èˆ¬æ•´æ•°</td></tr><tr class="odd"><td style="text-align: left;">INTEGER[(M)]</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">INTçš„åŒä¹‰è¯</td></tr><tr class="even"><td style="text-align: left;">BIGINT[(M)]</td><td style="text-align: left;"><span class="math inline">\(-2^{63}\)</span><sub><span class="math inline">\(2^{63}-1\)</span>æˆ–0</sub><span class="math inline">\(2^{64}-1\)</span></td><td style="text-align: center;">8</td><td style="text-align: left;">å¤§å‹æ•´æ•°</td></tr></tbody></table><h4><span id="æµ®ç‚¹ç±»å‹">æµ®ç‚¹ç±»å‹</span></h4><table><thead><tr class="header"><th style="text-align: left;">ç±»å‹</th><th style="text-align: left;">å–å€¼èŒƒå›´</th><th style="text-align: center;">å­˜å‚¨ç©ºé—´</th><th style="text-align: left;">æè¿°</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">FLOAT(ç²¾åº¦)</td><td style="text-align: left;">å–å†³äºç²¾åº¦</td><td style="text-align: center;">å¯å˜</td><td style="text-align: left;">å¯ç”¨äºæŒ‡å®šå•ç²¾åº¦å’ŒåŒç²¾åº¦æµ®ç‚¹æ•°</td></tr><tr class="even"><td style="text-align: left;">FLOAT[(M, D)]</td><td style="text-align: left;">+- 1.17549E-38</td><td style="text-align: center;">4</td><td style="text-align: left;">å•ç²¾åº¦æµ®ç‚¹æ•°ï¼Œç­‰åŒäºFLOAT(4)</td></tr><tr class="odd"><td style="text-align: left;">DOUBLE[(M), D]</td><td style="text-align: left;">+- 3.40282E+308</td><td style="text-align: center;">8</td><td style="text-align: left;">åŒç²¾åº¦æµ®ç‚¹æ•°ï¼Œç­‰åŒäºFLOAT(8)</td></tr><tr class="even"><td style="text-align: left;">DOUBLE</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">DOUBLE[(M, D)]çš„åŒä¹‰è¯</td></tr><tr class="odd"><td style="text-align: left;">PRECISION[(M, D)]</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">åŒä¸Š</td></tr><tr class="even"><td style="text-align: left;">REAL[(M, D)]</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">åŒä¸Š</td></tr><tr class="odd"><td style="text-align: left;">DECIMAL[(M [,D])]</td><td style="text-align: left;">å¯å˜</td><td style="text-align: center;">M + 2</td><td style="text-align: left;">æµ®ç‚¹æ•°ï¼Œä»¥charå­˜å‚¨ã€‚èŒƒå›´å–å†³äºM</td></tr><tr class="even"><td style="text-align: left;">NUMERIC[(M, D)]</td><td style="text-align: left;">åŒä¸Š</td><td style="text-align: center;"></td><td style="text-align: left;">DECIMALçš„åŒä¹‰è¯</td></tr><tr class="odd"><td style="text-align: left;">DEC[(M, D)]</td><td style="text-align: left;">åŒä¸Š</td><td style="text-align: center;"></td><td style="text-align: left;">DECIMALçš„åŒä¹‰è¯</td></tr><tr class="even"><td style="text-align: left;">FIXED[(M, D)]</td><td style="text-align: left;">åŒä¸Š</td><td style="text-align: center;"></td><td style="text-align: left;">DECIMALçš„åŒä¹‰è¯</td></tr></tbody></table><h4><span id="æ—¥æœŸå’Œæ—¶é—´ç±»å‹">æ—¥æœŸå’Œæ—¶é—´ç±»å‹</span></h4><table><thead><tr class="header"><th style="text-align: left;">ç±»å‹</th><th style="text-align: left;">å–å€¼èŒƒå›´</th><th style="text-align: left;">æè¿°</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">DATE</td><td style="text-align: left;">1000-01-01 ~ 9999-12-31</td><td style="text-align: left;">ä¸€ä¸ªæ—¥æœŸï¼Œä»¥YYYY-MM-DDæ ¼å¼æ˜¾ç¤º</td></tr><tr class="even"><td style="text-align: left;">TIME</td><td style="text-align: left;">-838:59:59 ~ 838:59:59</td><td style="text-align: left;">ä¸€ä¸ªæ—¶é—´ï¼Œä»¥HH:MM:SSå½¢å¼æ˜¾ç¤º</td></tr><tr class="odd"><td style="text-align: left;">DATETIME</td><td style="text-align: left;">1000-01-01 00:00:00 ~ 9999-12-31 23:59:59</td><td style="text-align: left;">æ—¥æœŸå’Œæ—¶é—´</td></tr><tr class="even"><td style="text-align: left;">TIMESTAMP[(M)]</td><td style="text-align: left;">1970-01-01 00:00:00 ~ 2037å¹´çš„æŸä¸ªæ—¶é—´</td><td style="text-align: left;">æ—¶é—´æ ‡ç­¾ï¼Œåœ¨å¤„ç†æŠ¥å‘Šä¸­æœ‰æ„ä¹‰ã€‚</td></tr><tr class="odd"><td style="text-align: left;">YEAR[(2/4)]</td><td style="text-align: left;">70<sub>69(1970</sub>2069)</td><td style="text-align: left;">å¹´ä»½ã€‚å¯ä»¥æŒ‡å®š2ä½æ•°å­—æˆ–4ä½æ•°å­—çš„æ ¼å¼ã€‚</td></tr></tbody></table><h4><span id="å­—ç¬¦ä¸²ç±»å‹">å­—ç¬¦ä¸²ç±»å‹</span></h4><h5><span id="å¸¸è§„å­—ç¬¦ä¸²ç±»å‹">å¸¸è§„å­—ç¬¦ä¸²ç±»å‹</span></h5><table><thead><tr class="header"><th style="text-align: left;">ç±»å‹</th><th style="text-align: left;">å–å€¼èŒƒå›´</th><th style="text-align: left;">æè¿°</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">CHAR(M)</td><td style="text-align: left;">0~255ä¸ªå­—ç¬¦</td><td style="text-align: left;">å›ºå®šé•¿åº¦ä¸ºMçš„å­—ç¬¦ä¸²ï¼ŒMçš„å–å€¼ä¸º0~255</td></tr><tr class="even"><td style="text-align: left;">CHAR</td><td style="text-align: left;"></td><td style="text-align: left;">CHAR(1)çš„åŒä¹‰è¯</td></tr><tr class="odd"><td style="text-align: left;">VARCHAR(M)</td><td style="text-align: left;">1~255ä¸ªå­—ç¬¦</td><td style="text-align: left;">å¯å˜é•¿åº¦</td></tr></tbody></table><h5><span id="textå’Œblobç±»å‹">TEXTå’ŒBLOBç±»å‹</span></h5><table><thead><tr class="header"><th style="text-align: left;">ç±»å‹</th><th style="text-align: center;">æœ€å¤§é•¿åº¦(å­—ç¬¦æ•°)</th><th style="text-align: left;">æè¿°</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">TINYBLOB</td><td style="text-align: center;">255</td><td style="text-align: left;">å°äºŒè¿›åˆ¶å¤§å¯¹è±¡(BLOB)å­—æ®µ</td></tr><tr class="even"><td style="text-align: left;">TINYTEXT</td><td style="text-align: center;">255</td><td style="text-align: left;">å°TEXTå­—æ®µ</td></tr><tr class="odd"><td style="text-align: left;">BLOB</td><td style="text-align: center;">65535</td><td style="text-align: left;">å¸¸è§„BLOBå­—æ®µ</td></tr><tr class="even"><td style="text-align: left;">TEXT</td><td style="text-align: center;">65535</td><td style="text-align: left;">å¸¸è§„TEXTå­—æ®µ</td></tr><tr class="odd"><td style="text-align: left;">MEDIUMBLOB</td><td style="text-align: center;"><span class="math inline">\(2^{24}-1\)</span></td><td style="text-align: left;">ä¸­å‹BLOBå­—æ®µ</td></tr><tr class="even"><td style="text-align: left;">MEDIUMTEXT</td><td style="text-align: center;"><span class="math inline">\(2^{24}-1\)</span></td><td style="text-align: left;">ä¸­å‹TEXTå­—æ®µ</td></tr><tr class="odd"><td style="text-align: left;">LONGBLOB</td><td style="text-align: center;"><span class="math inline">\(2^{32}-1\)</span></td><td style="text-align: left;">é•¿BLOBå­—æ®µ</td></tr><tr class="even"><td style="text-align: left;">LONGTEXT</td><td style="text-align: center;"><span class="math inline">\(2^{32}-1\)</span></td><td style="text-align: left;">é•¿TEXTå­—æ®µ</td></tr></tbody></table><h5><span id="setå’Œenumç±»å‹">SETå’ŒENUMç±»å‹</span></h5><table><thead><tr class="header"><th style="text-align: left;">ç±»å‹</th><th style="text-align: center;">é›†åˆä¸­çš„æœ€å¤§å€¼</th><th style="text-align: left;">æè¿°</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">ENUM('value1', 'value2', ...)</td><td style="text-align: center;">65535</td><td style="text-align: left;">è¯¥ç±»å‹çš„åˆ—åªå¯ä»¥å®¹çº³æ‰€åˆ—å€¼ä¹‹ä¸€æˆ–è€…ä¸ºNULL</td></tr><tr class="even"><td style="text-align: left;">SET('value1', 'value2', ...)</td><td style="text-align: center;">64</td><td style="text-align: left;">è¯¥ç±»å‹çš„åˆ—å¯ä»¥å®¹çº³ä¸€ç»„å€¼æˆ–è€…ä¸ºNULL</td></tr></tbody></table><h3><span id="æ’å…¥æ•°æ®">æ’å…¥æ•°æ®</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> [<span class="keyword">INTO</span>] table_name [(column1, column2, ...)] </span><br><span class="line"><span class="keyword">VALUES</span>(value1, value2, ...);</span><br></pre></td></tr></table></figure><h3><span id="æŸ¥è¯¢æ•°æ®">æŸ¥è¯¢æ•°æ®</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [options] items</span><br><span class="line">[<span class="keyword">INTO</span> file_details]</span><br><span class="line"><span class="keyword">FROM</span> <span class="string">`tables_name`</span></span><br><span class="line">[ <span class="keyword">WHERE</span> conditions ]</span><br><span class="line">[ <span class="keyword">GROUP</span> <span class="keyword">BY</span> group_type ]</span><br><span class="line">[ <span class="keyword">HAVING</span> where_definition ]</span><br><span class="line">[ <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_type ]</span><br><span class="line">[ <span class="keyword">LIMIT</span> limit_criteria ]</span><br><span class="line">[ <span class="keyword">PROCEDURE</span> proc_name(arguments)]</span><br><span class="line">[ lock_options ];</span><br></pre></td></tr></table></figure><p><del>æ­¤å¤„ç•¥è¿‡1000å­—</del></p><h3><span id="æ›´æ–°æ•°æ®">æ›´æ–°æ•°æ®</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> [<span class="keyword">LOW_PRIORITY</span>] [<span class="keyword">IGNORE</span>] tablename</span><br><span class="line"><span class="keyword">SET</span> column1 = expression1, ...</span><br><span class="line">[ <span class="keyword">WHERE</span> condition ]</span><br><span class="line">[ <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_criteria ]</span><br><span class="line">[ <span class="keyword">LIMIT</span> <span class="built_in">number</span> ]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> åå°å¼€å‘ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linuxå¸¸ç”¨å‘½ä»¤æ€»ç»“(ä¸‰)ï¼šç½‘ç»œä¸è¿›ç¨‹</title>
      <link href="/2015/12/17/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%89)_%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%9B%E7%A8%8B/"/>
      <url>/2015/12/17/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%89)_%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%9B%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Linuxå¸¸ç”¨å‘½ä»¤æ€»ç»“</p></blockquote><a id="more"></a><h2><span id="æŸ¥çœ‹å“ªä¸ªè¿›ç¨‹åœ¨å ç”¨ç«¯å£lsof">æŸ¥çœ‹å“ªä¸ªè¿›ç¨‹åœ¨å ç”¨ç«¯å£ï¼šlsof</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lsof -i:ï¼ˆç«¯å£å·ï¼‰</span><br></pre></td></tr></table></figure><h2><span id="ç»“æŸè¿›ç¨‹kill">ç»“æŸè¿›ç¨‹ï¼škill</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo kill è¿›ç¨‹PID</span><br></pre></td></tr></table></figure><h2><span id="ip">ip</span></h2><p><strong>show / manipulate routing, devices, policy routing and tunnels</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip link</span><br></pre></td></tr></table></figure></p><h2><span id="iwconfig">iwconfig</span></h2><p>iwconfig - configure a <strong>wireless network interface</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iwconfig</span><br></pre></td></tr></table></figure></p><h2><span id="netstat-è·Ÿè¸ªç½‘ç»œ">netstat - è·Ÿè¸ªç½‘ç»œ</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>netstat  -[atunlp]</code> <em>å‚æ•°ï¼š</em> * -a : å°†ç›®å‰ç³»ç»Ÿä¸Šæ‰€æœ‰çš„è¿æ¥ã€ç›‘å¬ã€Socketæ•°æ®éƒ½åˆ—å‡ºæ¥ * -t : åˆ—å‡ºtcpç½‘ç»œæ•°æ®åŒ…çš„æ•°æ® * -u : åˆ—å‡ºudpç½‘ç»œæ•°æ®åŒ…çš„æ•°æ® * -n : ä¸åˆ—å‡ºè¿›ç¨‹çš„æœåŠ¡åç§°ï¼Œä»¥ç«¯å£å·(port number)æ¥æ˜¾ç¤º * -l : åˆ—å‡ºç›®å‰æ­£åœ¨ç½‘ç»œç›‘å¬çš„æœåŠ¡ * -p : åˆ—å‡ºè¯¥ç½‘ç»œæœåŠ¡çš„è¿›ç¨‹PID</p><h2><span id="ps-å°†æŸä¸ªæ—¶é—´ç‚¹çš„è¿›ç¨‹è¿è¡Œæƒ…å†µé€‰å–ä¸‹æ¥">ps -å°†æŸä¸ªæ—¶é—´ç‚¹çš„è¿›ç¨‹è¿è¡Œæƒ…å†µé€‰å–ä¸‹æ¥</span></h2><p><em>ç”¨æ³•ï¼š</em> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps   aux      # æŸ¥çœ‹ç³»ç»Ÿæ‰€æœ‰çš„è¿›ç¨‹æ•°æ® </span><br><span class="line">ps   -lA      # åŒä¸Š</span><br><span class="line">ps   axjf     # è¿åŒéƒ¨åˆ†è¿›ç¨‹æ ‘çš„çŠ¶æ€</span><br></pre></td></tr></table></figure></p><p><em>å‚æ•°ï¼š</em> * -A : æ‰€æœ‰è¿›ç¨‹å‡æ˜¾ç¤ºå‡ºæ¥ï¼Œä¸-eå…·æœ‰åŒæ ·çš„ä½œç”¨ * -a : ä¸åˆ—å‡ºä¸terminalæœ‰å…³çš„æ‰€æœ‰è¿›ç¨‹ * -u : æœ‰æ•ˆç”¨æˆ·(effective user)ç›¸å…³çš„è¿›ç¨‹ * x : é€šå¸¸ä¸aè¿™ä¸ªå‚æ•°ä¸€èµ·ä½¿ç”¨ï¼Œå¯ä»¥åˆ—å‡ºè¾ƒå®Œæ•´ä¿¡æ¯ * è¾“å‡ºæ ¼å¼è§„åˆ’ï¼š * l ï¼š è¾ƒé•¿ã€è¾ƒè¯¦ç»†åœ°å°†è¯¥PIDçš„ä¿¡æ¯åˆ—å‡º * j : å·¥ä½œçš„æ ¼å¼(job format) * -f : åšä¸€ä¸ªæ›´ä¸ºå®Œæ•´çš„è¾“å‡º &gt;å¸¸ç”¨ï¼š * ps -l : åªæŸ¥çœ‹è‡ªå·±bashç¨‹åºçš„æ‰€æœ‰è¿›ç¨‹ * ps aux : æŸ¥çœ‹æ‰€æœ‰ç³»ç»Ÿè¿è¡Œçš„ç¨‹åº</p><h2><span id="top-åŠ¨æ€æŸ¥çœ‹è¿›ç¨‹å˜åŒ–">top -åŠ¨æ€æŸ¥çœ‹è¿›ç¨‹å˜åŒ–</span></h2><p><em>ç”¨æ³•ï¼š</em></p><p><code>top  [-d  æ•°å­—]  |  top  [-bnp]</code> <em>å‚æ•°ï¼š</em> * -d : åé¢å¯ä»¥æ¥ç§’æ•°ï¼Œå°±æ˜¯æ•´ä¸ªè¿›ç¨‹ç•Œé¢æ›´æ–°çš„ç§’æ•°ã€‚é»˜è®¤æ˜¯5ç§’ * -b : ä»¥æ‰¹æ¬¡çš„æ–¹å¼æ‰§è¡Œtopï¼Œé€šå¸¸ä¼šæ­é…æ•°æ®æµé‡å®šå‘æ¥å°†æ‰¹å¤„ç†çš„ç»“æœè¾“å‡ºæˆæ–‡ä»¶ * -n : ä¸-bæ­é…ï¼Œæ„ä¹‰æ˜¯ï¼Œéœ€è¦è¿›è¡Œå‡ æ¬¡topçš„è¾“å‡ºç»“æœ * -p : æŒ‡å®šæŸäº›ä¸ªPIDæ¥è¿›è¡ŒæŸ¥çœ‹æ£€æµ‹ &gt;åœ¨topæ‰§è¡Œè¿‡ç¨‹ä¸­å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æŒ‰é”®ï¼š * ? : æ˜¾ç¤ºåœ¨topä¸­å¯ä»¥è¾“å…¥çš„æŒ‰é”®å‘½ä»¤ * P : ä»¥CPUçš„ä½¿ç”¨èµ„æºæ’åºæ˜¾ç¤º * M: ä»¥å†…å­˜çš„ä½¿ç”¨èµ„æºæ’åºæ˜¾ç¤º * N : ä»¥PIDæ¥æ’åº * T : ç”±è¯¥è¿›ç¨‹ä½¿ç”¨çš„CPUæ—¶é—´ç§¯ç´¯æ’åº * k : ç»™äºˆæŸä¸ªPIDä¸€ä¸ªä¿¡å· * r : ç»™äºˆæŸä¸ªPIDé‡æ–°åˆ¶å®šä¸€ä¸ªniceå€¼ * q : ç¦»å¼€top</p><h2><span id="scp-å®‰å…¨å¤åˆ¶ç”¨äºä¸åŒçš„linuxä¹‹é—´">scp - å®‰å…¨å¤åˆ¶ï¼Œç”¨äºä¸åŒçš„linuxä¹‹é—´</span></h2><p><em>ç”¨æ³•ï¼š</em></p><p><code>scp  [-vCP46]  æ–‡ä»¶å1   è¿œç¨‹ç”¨æˆ·å@IPåœ°å€ï¼šæ–‡ä»¶å2</code> <em>å‚æ•°ï¼š</em> * -v : æ˜¾ç¤ºè¿›åº¦ã€æŸ¥çœ‹è¿æ¥ï¼Œè®¤è¯æˆ–æ˜¯åŒ¹é…é”™è¯¯ * -C : ä½¿èƒ½å‹ç¼© * -P : é€‰æ‹©ç«¯å£ * -4 : å¼ºåˆ¶ä½¿ç”¨ipv4åœ°å€ * -6 : å¼ºåˆ¶ä½¿ç”¨ipv6åœ°å€</p><h2><span id="wget-ä¸‹è½½æ–‡ä»¶å·¥å…·">wget - ä¸‹è½½æ–‡ä»¶å·¥å…·</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>wget [options]  url</code> <em>éƒ¨åˆ†å‚æ•°ï¼š</em> * -V : æ˜¾ç¤ºwgetçš„ç‰ˆæœ¬å¹¶é€€å‡º * -d : æ˜¾ç¤ºDebugä¿¡æ¯ * -x : å¼ºåˆ¶å»ºç«‹ä¸æœåŠ¡å™¨ä¸Šä¸€æ ·çš„ç›®å½• * -r : é€’å½’åœ°ä¸‹è½½æœåŠ¡å™¨ä¸Šæ‰€æœ‰çš„æ–‡ä»¶å’Œç›®å½•ï¼ˆåŒ…æ‹¬ç½‘ç«™å†…æŒ‡å‘çš„åœ°å€ï¼‰ * -l n: nä¸ºæ•°å­—ï¼Œä¸ºé€’å½’ä¸‹è½½çš„å±‚æ•° * -c : æ–­ç‚¹ç»­ä¼  * -i : æ‰¹é‡ä¸‹è½½ï¼Œåé¢æ¥txtæ–‡ä»¶ï¼ŒæŠŠæ¯ä¸ªurlå†™æˆä¸€è¡Œ * --http-user=USER, --http-passwd=PASS ï¼š è®¿é—®é™åˆ¶ç½‘ç«™æ‰€éœ€çš„è´¦å·å¯†ç  * -t : å°è¯•ä¸‹è½½é‡å¤æ¬¡æ•° * -O : æŒ‡å®šä¸‹è½½ç›®å½•å’Œæ–‡ä»¶å * -nc : ä¸è¦è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶ * -N : åªä¸‹è½½æ¯”æœ¬åœ°æ–‡ä»¶æ–°çš„æ–‡ä»¶ * -T : è®¾ç½®è¶…æ—¶æ—¶é—´ * -b : å¯åŠ¨è½¬å…¥åå°æ‰§è¡Œ</p><h2><span id="curl-urlä¸‹è½½å·¥å…·">curl - urlä¸‹è½½å·¥å…·</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>curl  [options1]   url1   [options2]  url2  â€¦.</code> <em>å‚æ•°ï¼š</em> * -o : åæ¥æ–‡ä»¶åï¼Œå°†æ–‡ä»¶ä¿å­˜ä¸ºæŒ‡å®šæ–‡ä»¶åçš„æ–‡ä»¶ä¸­ * -O : ä½¿ç”¨urlä¸­é»˜è®¤æ–‡ä»¶åä¿å­˜åˆ°æœ¬åœ° * -L : è¿›è¡Œé‡å®šå‘ * -C : æ–­ç‚¹ç»­ä¼  * --limit-rate : åé¢æ¥æ•°å­—ï¼Œé™åˆ¶æœ€å¤§ä¸‹è½½é€Ÿåº¦ * -u username[ : passwd ]: éœ€è¦æˆæƒæ—¶æä¾›è´¦å·ã€å¯†ç ã€‘ * -T : å°†æœ¬åœ°æ–‡ä»¶ä¸Šä¼ è‡³ftpæœåŠ¡å™¨ä¸Š</p><h2><span id="ifconfig-è·å–ä¿®æ”¹ç½‘ç»œæ¥å£é…ç½®ä¿¡æ¯">ifconfig - è·å–/ä¿®æ”¹ç½‘ç»œæ¥å£é…ç½®ä¿¡æ¯</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>ifconfig  [ç½‘ç»œè®¾å¤‡]   [å‚æ•°]</code> <em>å‚æ•°ï¼š</em> * up : å¯åŠ¨æŒ‡å®šç½‘ç»œè®¾å¤‡/ç½‘å¡ * down : å…³é—­æŒ‡å®šè®¾å¤‡/ç½‘å¡ * arp : è®¾ç½®ç½‘å¡æ˜¯å¦æ”¯æŒarpåè®® * -a : æ˜¾ç¤ºå…¨éƒ¨æ¥å£ä¿¡æ¯ * -s : æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯ * add : ç»™æŒ‡å®šç½‘å¡é…ç½®ipv6åœ°å€ * del : åˆ é™¤æŒ‡å®šç½‘å¡çš„ipv6åœ°å€ * address : ä¸ºç½‘å¡é…ç½®ipv4åœ°å€</p><h2><span id="ssh-sshå®¢æˆ·ç«¯">ssh - SSHå®¢æˆ·ç«¯</span></h2><blockquote><p><strong>å¸¸ç”¨æ–¹æ³•ï¼š</strong> * ssh host : ä¸åŠ ä»»ä½•é€‰é¡¹å‚æ•°ï¼Œç›´æ¥åŠ æœåŠ¡å™¨åœ°å€ * ssh -l : æŒ‡å®šç”¨æˆ· host ç”¨æŒ‡å®šç”¨æˆ·åç™»é™† * ssh host -p ç«¯å£å· : æŒ‡å®šç«¯å£ * ssh -C host : è¯·æ±‚å‹ç¼©å‘é€/æ¥æ”¶çš„æ•°æ® * ssh -v host : æ‰“å¼€è°ƒè¯•æ¨¡å¼ * ssh -b source destination: ç»‘å®šæºåœ°å€ * ssh -F é…ç½®æ–‡ä»¶ : host ä½¿ç”¨æŒ‡å®šé…ç½®æ–‡ä»¶ * ssh -X user@host : å¯ç”¨X11 Forwarding</p></blockquote><h2><span id="apt-get"><strong>apt-get</strong></span></h2><ul><li><p><code>apt-get update</code> : åœ¨ä¿®æ”¹<code>/etc/apt/sources.list</code>æˆ–<code>/etc/apt/preferences</code>ä¹‹åè¿è¡Œè¯¥å‘½ä»¤ã€‚æ­¤å¤–æ‚¨éœ€è¦å®šæœŸè¿è¡Œè¿™ä¸€å‘½ä»¤ä»¥ç¡®ä¿æ‚¨çš„è½¯ä»¶åŒ…åˆ—è¡¨æ˜¯æœ€æ–°çš„</p></li><li><p><code>apt-get install packagename</code> : å®‰è£…ä¸€ä¸ªæ–°è½¯ä»¶åŒ…</p></li><li><p><code>apt-get remove packagename</code> : å¸è½½ä¸€ä¸ªå·²å®‰è£…çš„è½¯ä»¶åŒ…ï¼ˆä¿ç•™é…ç½®æ–‡æ¡£ï¼‰</p></li><li><p><code>apt-get remove --purge packagename</code> : å¸è½½ä¸€ä¸ªå·²å®‰è£…çš„è½¯ä»¶åŒ…ï¼ˆåˆ é™¤é…ç½®æ–‡æ¡£ï¼‰</p></li><li><p><code>apt-get autoremove packagename</code> : åˆ é™¤åŒ…åŠå…¶ä¾èµ–çš„è½¯ä»¶åŒ…</p></li><li><p><code>apt-get autoremove --purge packagname</code> : åˆ é™¤åŒ…åŠå…¶ä¾èµ–çš„è½¯ä»¶åŒ…+é…ç½®æ–‡ä»¶ï¼Œæ¯”ä¸Šé¢çš„è¦åˆ é™¤çš„å½»åº•ä¸€ç‚¹</p></li><li><p><code>dpkg --force-all --purge packagename</code> : æœ‰äº›è½¯ä»¶å¾ˆéš¾å¸è½½ï¼Œè€Œä¸”è¿˜é˜»æ­¢äº†åˆ«çš„è½¯ä»¶çš„åº”ç”¨ï¼Œå°±èƒ½å¤Ÿç”¨è¿™ä¸ªï¼Œä½†æ˜¯æœ‰ç‚¹å†’é™©ã€‚</p></li><li><p><code>apt-get autoclean</code> : aptä¼šæŠŠå·²è£…æˆ–å·²å¸çš„è½¯ä»¶éƒ½å¤‡ä»½åœ¨ç¡¬ç›˜ä¸Šï¼Œæ‰€ä»¥å‡å¦‚éœ€è¦ç©ºé—´çš„è¯ï¼Œèƒ½å¤Ÿè®©è¿™ä¸ªå‘½ä»¤æ¥åˆ é™¤æ‚¨å·²å¸è½½æ‰çš„è½¯ä»¶çš„å¤‡ä»½</p></li><li><p><code>apt-get clean</code> : è¿™ä¸ªå‘½ä»¤ä¼šæŠŠå®‰è£…çš„è½¯ä»¶çš„å¤‡ä»½ä¹Ÿåˆ é™¤ï¼Œä½†æ˜¯è¿™æ ·ä¸ä¼šå½±å“è½¯ä»¶çš„ä½¿ç”¨ã€‚</p></li><li><p><code>apt-get upgrade</code> : å¯ä»¥ä½¿ç”¨è¿™æ¡å‘½ä»¤æ›´æ–°è½¯ä»¶åŒ…ï¼Œ<code>apt-get upgrade</code>ä¸ä»…å¯ä»¥ä»ç›¸åŒç‰ˆæœ¬å·çš„å‘å¸ƒç‰ˆä¸­æ›´æ–°è½¯ä»¶åŒ…ï¼Œä¹Ÿå¯ä»¥ä»æ–°ç‰ˆæœ¬å·çš„å‘å¸ƒç‰ˆä¸­æ›´æ–°è½¯ä»¶åŒ…ï¼Œå°½ç®¡å®ç°åä¸€ç§æ›´æ–°çš„æ¨èå‘½ä»¤ä¸º<code>apt-get dist-upgrade</code>ã€‚</p></li><li><p><code>apt-get -u upgrade</code> : è¿™ä¸ªé€‰é¡¹è®©APTæ˜¾ç¤ºå®Œæ•´çš„å¯æ›´æ–°è½¯ä»¶åŒ…åˆ—è¡¨ã€‚APTä¼šä¸‹è½½æ¯ä¸ªè½¯ä»¶åŒ…çš„æœ€æ–°æ›´æ–°ç‰ˆæœ¬ï¼Œç„¶åä»¥åˆç†çš„æ¬¡åºå®‰è£…å®ƒä»¬ã€‚æ³¨æ„åœ¨è¿è¡Œè¯¥å‘½ä»¤å‰åº”å…ˆè¿è¡Œ<code>apt-get update</code>æ›´æ–°æ•°æ®åº“ï¼Œæ›´æ–°ä»»ä½•å·²å®‰è£…çš„è½¯ä»¶åŒ…ã€‚</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linuxå¸¸ç”¨å‘½ä»¤æ€»ç»“(äºŒ)ï¼šæ•°æ®å¤„ç†</title>
      <link href="/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%BA%8C)_%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
      <url>/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%BA%8C)_%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Linuxå¸¸ç”¨å‘½ä»¤æ€»ç»“</p></blockquote><a id="more"></a><h2><span id="æ•°æ®æµé‡å®šå‘">æ•°æ®æµé‡å®šå‘</span></h2><ul><li><strong>æ ‡å‡†è¾“å…¥(stdin)</strong> : ä»£ç ä¸º0ï¼Œä½¿ç”¨<code>&lt;</code>æˆ–<code>&lt;&lt;</code></li><li><strong>æ ‡å‡†è¾“å‡º(stdout)</strong> : ä»£ç ä¸º1ï¼Œä½¿ç”¨<code>&gt;</code>æˆ–<code>&gt;&gt;</code></li><li><strong>æ ‡å‡†é”™è¯¯è¾“å‡º(stderr)</strong> : ä»£ç ä¸º2ï¼Œä½¿ç”¨<code>2&gt;</code>æˆ–<code>2&gt;&gt;</code></li></ul><p>èŒƒä¾‹ï¼š <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls /home &gt; ~/homefile <span class="comment"># å°†å±å¹•ä¿¡æ¯è¾“å‡ºåˆ°homefileé‡Œ</span></span><br></pre></td></tr></table></figure></p><h3><span id="devnullåƒåœ¾é»‘æ´è®¾å¤‡"><code>/dev/null</code>åƒåœ¾é»‘æ´è®¾å¤‡</span></h3><p><code>/dev/null</code>å¯ä»¥åƒæ‰ä»»ä½•å¯¼å‘è¿™ä¸ªè®¾å¤‡çš„ä¿¡æ¯</p><p>èŒƒä¾‹ï¼š <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ find /home -name .bashrc 2&gt; /dev/null</span><br><span class="line"><span class="comment"># åªæœ‰stdoutä¼šæ˜¾ç¤ºåˆ°å±å¹•ä¸Šï¼Œstderrè¢«ä¸¢å¼ƒäº†</span></span><br></pre></td></tr></table></figure></p><h3><span id="å°†æ­£ç¡®ä¸é”™è¯¯æ•°æ®å†™å…¥åŒä¸€æ–‡ä»¶">å°†æ­£ç¡®ä¸é”™è¯¯æ•°æ®å†™å…¥åŒä¸€æ–‡ä»¶</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ find /home -name .bashrc &gt; list 2&gt;&amp;1</span><br><span class="line">$ find /home -name .bashrc &amp;&gt; list</span><br></pre></td></tr></table></figure><h3><span id="ltä¸ltlt"><code>&lt;</code>ä¸<code>&lt;&lt;</code></span></h3><p>ç”¨<code>stdin</code>æ›¿ä»£é”®ç›˜è¾“å…¥ä»¥åˆ›å»ºæ–°æ–‡ä»¶çš„ç®€å•æµç¨‹ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; catdile &lt; ~/.bashrc</span><br></pre></td></tr></table></figure></p><p><code>&lt;&lt;</code>ä»£è¡¨è¾“å…¥ç»“æŸï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; catfile &lt;&lt; &quot;eof&quot;</span><br><span class="line">&gt; This is a test.</span><br><span class="line">&gt; eof  # è¾“å…¥è¿™ä¸ªå…³é”®å­—ï¼Œç«‹åˆ»ç»“æŸè€Œä¸éœ€è¦[ctrl]+d</span><br></pre></td></tr></table></figure></p><h2><span id="tee-åŒå‘é‡å®šå‘">tee -åŒå‘é‡å®šå‘</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ tee [-a] file</span><br><span class="line">å‚æ•°ï¼š-a : ä»¥ç´¯åŠ çš„æ–¹å¼è¾“å‡ºåˆ°æ–‡ä»¶</span><br></pre></td></tr></table></figure><p><strong><code>tee</code>å¯ä»¥è®©<code>standard output</code>è½¬å­˜ä¸€ä»½åˆ°æ–‡ä»¶å†…å¹¶å°†åŒæ ·çš„æ•°æ®ç»§ç»­é€åˆ°å±å¹•ä¸Šã€‚</strong></p><p>é€‰å–å‘½ä»¤ ï¼š cutã€grepsad</p><h2><span id="cut-åœ¨ä¸€è¡Œä¿¡æ¯ä¸­å–å‡ºæƒ³è¦çš„">cut -åœ¨ä¸€è¡Œä¿¡æ¯ä¸­å–å‡ºæƒ³è¦çš„</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>cut  -d  'åˆ†å‰²å­—ç¬¦'   -f  fields</code> <code>cut  -c   å­—ç¬¦èŒƒå›´</code> <em>å‚æ•°ï¼š</em> * -d : åé¢æ¥åˆ†å‰²å­—ç¬¦ï¼Œä¸ -f ä¸€èµ·ä½¿ç”¨ * -f : ä¾æ®-dçš„åˆ†å‰²å­—ç¬¦å°†ä¸€æ®µä¿¡æ¯åˆ‡å‰²æˆæ•°æ®µï¼Œç”¨-få–å‡ºç¬¬å‡ æ®µçš„æ„æ€ * -c : ä»¥å­—ç¬¦çš„å•ä½å–å‡ºå›ºå®šå­—ç¬¦åŒºé—´ <em>ä¾‹ï¼š</em> <code>echo $PATH | cut -d ':' -f 4</code> <code>export | cut -c 12-</code></p><h2><span id="sed-å·¥å…·">sed å·¥å…·</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ sed [-nefr] [åŠ¨ä½œ]</span><br><span class="line">å‚æ•°ï¼š</span><br><span class="line">-n : ä½¿ç”¨å®‰é™æ¨¡å¼ã€‚åªæœ‰ç»è¿‡sedç‰¹æ®Šå¤„ç†çš„é‚£ä¸€è¡Œæ‰ä¼šè¢«åˆ—å‡ºæ¥</span><br><span class="line">-e : ç›´æ¥åœ¨å‘½ä»¤è¡Œæ¨¡å¼ä¸Šè¿›è¡ŒsedåŠ¨ä½œç¼–è¾‘</span><br><span class="line">-f : -f filename å¯ä»¥æ‰§è¡Œfilenameé‡Œçš„sedåŠ¨ä½œ</span><br><span class="line">-r : sedçš„åŠ¨ä½œæ”¯æŒçš„æ˜¯æ‰©å±•å‹æ­£åˆ™è¡¨è¾¾å¼çš„è¯­æ³•</span><br><span class="line">-i : ç›´æ¥ä¿®æ”¹è¯»å–çš„æ–‡ä»¶å†…å®¹ï¼Œè€Œä¸æ˜¯å±å¹•è¾“å‡º</span><br><span class="line"></span><br><span class="line">åŠ¨ä½œè¯´æ˜ï¼š [n1[, n2]]funciton</span><br><span class="line">n1, n2 : ä¸è§å¾—ä¼šå­˜åœ¨ï¼Œä¸€èˆ¬ä»£è¡¨é€‰æ‹©è¿›è¡ŒåŠ¨ä½œçš„è¡Œæ•°</span><br><span class="line"></span><br><span class="line">functionæœ‰ä»¥ä¸‹ï¼š</span><br><span class="line">a : æ–°å¢, açš„åé¢å¯ä»¥æ¥å­—ç¬¦ä¸²ï¼Œè¿™äº›å­—ç¬¦ä¸²ä¼šå‡ºç°åœ¨ç›®å‰è¡Œçš„ä¸‹ä¸€è¡Œ</span><br><span class="line">c : æ›¿æ¢, cçš„åé¢å¯ä»¥æ¥å­—ç¬¦ä¸²ï¼Œè¿™äº›å­—ç¬¦ä¸²å¯ä»¥æ›¿æ¢n1-n2ä¹‹é—´çš„è¡Œ</span><br><span class="line">d : åˆ é™¤</span><br><span class="line">i : æ’å…¥, içš„åé¢å¯ä»¥æ¥å­—ç¬¦ä¸²ï¼Œè¿™äº›å­—ç¬¦ä¸²ä¼šå‡ºç°åœ¨ç›®å‰è¡Œçš„ä¸Šä¸€è¡Œ</span><br><span class="line">p : æ‰“å°, å°†æŸä¸ªé€‰æ‹©çš„æ•°æ®æ‰“å°å‡ºæ¥ï¼Œé€šå¸¸ä¸-nè¿ç”¨</span><br><span class="line">s : æ›¿æ¢, å¯ä»¥ç›´æ¥è¿›è¡Œæ›¿æ¢å·¥ä½œï¼Œå¯ä»¥æ­é…æ­£åˆ™è¡¨è¾¾å¼</span><br></pre></td></tr></table></figure><h3><span id="ä»¥è¡Œä¸ºå•ä½çš„æ–°å¢åˆ é™¤åŠŸèƒ½">ä»¥è¡Œä¸ºå•ä½çš„æ–°å¢/åˆ é™¤åŠŸèƒ½</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å°†/etc/passwd çš„å†…å®¹åˆ—å‡ºå¹¶ä¸”æ‰“å°è¡Œå·ï¼ŒåŒæ—¶å°†ç¬¬2-5è¡Œåˆ é™¤</span></span><br><span class="line">$ nl /etc/passwd | sed <span class="string">'2,5d'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åœ¨ç¬¬äºŒè¡ŒååŠ ä¸Š"drink tea?"å­—æ ·</span></span><br><span class="line">$ nl /etc/passwd | sed <span class="string">'2a drink tea'</span></span><br></pre></td></tr></table></figure><p><strong>ç”¨så‘½ä»¤æ›¿æ¢</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat pets.txt</span><br><span class="line">This is my cat</span><br><span class="line">  my cat<span class="string">'s name is betty</span></span><br><span class="line"><span class="string">This is my dog</span></span><br><span class="line"><span class="string">  my dog'</span>s name is frank</span><br><span class="line">This is my fish</span><br><span class="line">  my fish<span class="string">'s name is george</span></span><br><span class="line"><span class="string">This is my goat</span></span><br><span class="line"><span class="string">  my goat'</span>s name is adam</span><br></pre></td></tr></table></figure><p>æŠŠå…¶ä¸­çš„ <code>my</code> å­—ç¬¦ä¸²æ›¿æ¢æˆ <code>Hao Chenâ€™s</code>ï¼Œä¸‹é¢çš„è¯­å¥åº”è¯¥å¾ˆå¥½ç†è§£ï¼ˆsè¡¨ç¤ºæ›¿æ¢å‘½ä»¤ï¼Œ/my/è¡¨ç¤ºåŒ¹é…myï¼Œ/Hao Chenâ€™s/è¡¨ç¤ºæŠŠåŒ¹é…æ›¿æ¢æˆHao Chenâ€™sï¼Œ/g è¡¨ç¤ºä¸€è¡Œä¸Šçš„æ›¿æ¢æ‰€æœ‰çš„åŒ¹é…ï¼‰ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sed <span class="string">"s/my/Hao Chen's/g"</span> pets.txt</span><br><span class="line">This is Hao Chen<span class="string">'s cat</span></span><br><span class="line"><span class="string">  Hao Chen'</span>s cat<span class="string">'s name is betty</span></span><br><span class="line"><span class="string">This is Hao Chen'</span>s dog</span><br><span class="line">  Hao Chen<span class="string">'s dog'</span>s name is frank</span><br><span class="line">This is Hao Chen<span class="string">'s fish</span></span><br><span class="line"><span class="string">  Hao Chen'</span>s fish<span class="string">'s name is george</span></span><br><span class="line"><span class="string">This is Hao Chen'</span>s goat</span><br><span class="line">  Hao Chen<span class="string">'s goat'</span>s name is adam</span><br></pre></td></tr></table></figure><p>æ³¨æ„ï¼šå¦‚æœä½ è¦ä½¿ç”¨å•å¼•å·ï¼Œé‚£ä¹ˆä½ æ²¡åŠæ³•é€šè¿‡â€™è¿™æ ·æ¥è½¬ä¹‰ï¼Œå°±æœ‰åŒå¼•å·å°±å¯ä»¥äº†ï¼Œåœ¨åŒå¼•å·å†…å¯ä»¥ç”¨â€æ¥è½¬ä¹‰ã€‚</p><h2><span id="grep-åˆ†æä¸€è¡Œä¿¡æ¯è‹¥æœ‰æƒ³è¦çš„å°±æ‹¿å‡ºæ•´è¡Œ">grep -åˆ†æä¸€è¡Œä¿¡æ¯ï¼Œè‹¥æœ‰æƒ³è¦çš„å°±æ‹¿å‡ºæ•´è¡Œ</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>grep [-acinv] [-A] [-B] [--color=auto]   'æŸ¥æ‰¾å­—ç¬¦ä¸²'   filename</code> <em>å‚æ•°ï¼š</em> * -a : å°†binaryæ–‡ä»¶ä»¥textæ–‡ä»¶çš„æ–¹å¼æŸ¥æ‰¾æ•°æ® * -c : è®¡ç®—æ‰¾åˆ°'æŸ¥æ‰¾å­—ç¬¦ä¸²'çš„æ¬¡æ•° * -i : å¿½ç•¥å¤§å°å†™ * -n : è¾“å‡ºè¡Œå· * -v : åå‘é€‰æ‹© * -A : åé¢æ¥æ•°å­—ï¼Œä¸ºafterçš„æ„æ€ï¼Œåç»­çš„nè¡Œä¹Ÿåˆ—å‡ºæ¥ * -B : åé¢æ¥æ•°å­—ï¼Œä¸ºbeforeçš„æ„æ€ï¼Œå‰é¢çš„nè¡Œä¹Ÿåˆ—å‡ºæ¥ * --color=auto : å¯ä»¥å°†æ‰¾åˆ°çš„å…³é”®å­—éƒ¨åˆ†åŠ ä¸Šé¢œè‰²æ˜¾ç¤º</p><p>ä¾‹ï¼š <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ last | grep -v &apos;neymar&apos; | cut -d &apos; &apos; -f 1</span><br><span class="line">$ dmesg | grep -n -A3 -B2 --color=auto &apos;eth&apos;</span><br><span class="line"># dmesgå¯åˆ—å‡ºå†…æ ¸äº§ç”Ÿçš„ä¿¡æ¯ã€‚é€šè¿‡grepæ¥é€‰å–ç½‘å¡ç›¸å…³ä¿¡æ¯</span><br></pre></td></tr></table></figure></p><h2><span id="æ’åºå‘½ä»¤sort-wc-uniq">æ’åºå‘½ä»¤ï¼šsort, wc, uniq</span></h2><h3><span id="sort">sort</span></h3><p><em>ç”¨æ³•ï¼š</em> <code>sort   [-fbMnrtuk]   [file or stdin]</code> <em>å‚æ•°ï¼š</em> * -f : å¿½ç•¥å¤§å°å†™ * -b : å¿½ç•¥æœ€å‰é¢ç©ºæ ¼ * -M: ä»¥æœˆä»½çš„åå­—æ¥æ’åº * -n : ä½¿ç”¨çº¯æ•°å­—è¿›è¡Œæ’åºï¼ˆé»˜è®¤ä»¥æ–‡å­—ç±»å‹æ¥æ’åºï¼‰ * -r : åå‘æ’åº * -u : å°±æ˜¯uniqï¼Œç›¸åŒçš„æ•°æ®ä¸­ï¼Œä»…å‡ºç°ä¸€è¡Œä»£è¡¨ * -t : åˆ†éš”ç¬¦ï¼Œé»˜è®¤ç”¨[Tab]æ¥åˆ†å‰²ï¼Œé…åˆ-kä½¿ç”¨ * -k : åé¢åŠ æ•°å­—ï¼Œä»¥-tåˆ†å‰²å‡ºæ¥çš„å“ªä¸ªåŒºé—´è¿›è¡Œæ’åº <em>ä¾‹ï¼š</em> <code>last | cut -d '.' f 1 | sort</code></p><h3><span id="uniq-é‡å¤æ•°æ®ä»…åˆ—å‡ºä¸€ä¸ª">uniq -é‡å¤æ•°æ®ä»…åˆ—å‡ºä¸€ä¸ª</span></h3><p><em>ç”¨æ³•ï¼š</em> <code>uniq  [-ic]</code> <em>å‚æ•°ï¼š</em> * -i : å¿½ç•¥å¤§å°å†™å­—ç¬¦çš„ä¸åŒ * -c : è¿›è¡Œè®¡æ•° <em>ä¾‹ï¼š</em> <code>last | cut -d ' ' -f1 | sort | uniq -c</code></p><h3><span id="wc-è®¡ç®—è¾“å‡ºä¿¡æ¯çš„æ•´ä½“æ•°æ®">wc - è®¡ç®—è¾“å‡ºä¿¡æ¯çš„æ•´ä½“æ•°æ®</span></h3><p><em>ç”¨æ³•ï¼š</em> <code>wc   [-lwm]</code> <em>å‚æ•°ï¼š</em> * -l : ä»…åˆ—å‡ºè¡Œ * -w: ä»…åˆ—å‡ºå¤šå°‘å­— * -m : ä»…åˆ—å‡ºå¤šå°‘å­—ç¬¦ <em>ä¾‹ï¼š</em> <code>cat /etc/passwd | wc</code></p><h3><span id="awk-æ•°æ®å¤„ç†å·¥å…·">awk - æ•°æ®å¤„ç†å·¥å…·</span></h3><blockquote><p>awkä¸»è¦æ˜¯å¤„ç†æ¯ä¸€è¡Œçš„å­—æ®µå†…æ•°æ®ï¼Œè€Œé»˜è®¤çš„å­—æ®µçš„åˆ†éš”ç¬¦ä¸ºç©ºæ ¼é”®æˆ–[tab]é”®</p></blockquote><p><em>ç”¨æ³•:</em> <code>awk   'æ¡ä»¶ç±»å‹1{åŠ¨ä½œ1}  æ¡ä»¶ç±»å‹2{åŠ¨ä½œ2} â€¦  '  filename</code></p><blockquote><p>awkçš„å†…ç½®å˜é‡ä¸å«ä¹‰ï¼š * $0 ä¸€æ•´è¡Œæ•°æ® * $1, $2 â€¦ $n ç¬¬1åˆ—ï¼Œç¬¬2åˆ— â€¦. ç¬¬nåˆ— * NF æ¯ä¸€è¡Œæ‹¥æœ‰çš„å­—æ®µæ€»æ•° * NR ç›®å‰å¤„ç†çš„è¡Œæ•° * FS ç›®å‰çš„åˆ†éš”ç¬¦ï¼Œé»˜è®¤æ—¶ç©ºæ ¼é”®</p></blockquote><blockquote><p>awkçš„é€»è¾‘è¿ç®—ç¬¦ï¼š * &gt; &lt; &gt;= &lt;= == !=</p></blockquote><blockquote><p>è¯´æ˜ï¼š * æ‰€æœ‰awkåŠ¨ä½œï¼Œå³åœ¨{}å†…çš„åŠ¨ä½œï¼Œå¦‚æœæœ‰éœ€è¦å¤šä¸ªå‘½ä»¤è¾…åŠ©æ—¶ï¼Œå¯ç”¨â€;â€œé—´éš”ï¼Œæˆ–è€…ç›´æ¥ä»¥[Enter]é”®æ¥éš”å¼€æ¯ä¸ªå‘½ä»¤ * ä¸bashã€shellçš„å˜é‡ä¸åŒï¼Œåœ¨awkä¸­ï¼Œå˜é‡å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦åŠ â€$â€œ</p></blockquote><p>ä¸¾ä¾‹ï¼š * å–å‡ºè´¦å·ä¸ç™»å½•è€…IPï¼Œä¸”è´¦å·ä¸IPä¹‹é—´ä»¥[tab]éš”å¼€ï¼š <code>last -n 5 | awk '{print $1 â€œ\tâ€ $3}'</code> * åˆ—å‡ºæ¯ä¸€è¡Œçš„è´¦å·ï¼Œåˆ—å‡ºæ­£åœ¨å¤„ç†çš„è¡Œæ•°ï¼Œå¹¶è¯´æ˜è¯¥è¡Œæœ‰å¤šå°‘å­—æ®µï¼š <code>last -n 5 | awk '{print $1 â€œ\t  lines: â€œ NR â€œ\t  columes:  â€œ NF}'</code> * åœ¨/etc/passwdä¸­ä»¥â€ï¼šâ€œæ¥åˆ†éš”å­—æ®µï¼Œåˆ—å‡ºç¬¬ä¸‰åˆ—å°äº10çš„æ•°æ®ï¼Œå¹¶ä¸”ä»…åˆ—å‡ºè´¦å·ä¸ç¬¬ä¸‰åˆ— <code>cat /etc/passwd | awk 'BEGIN {FS=&quot;:&quot;} $3 &lt; 10 {print $1 &quot;\t&quot; $3}'</code></p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linuxå¸¸ç”¨å‘½ä»¤æ€»ç»“(ä¸€)ï¼šå¸¸è§„</title>
      <link href="/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%80)_%E5%B8%B8%E8%A7%84/"/>
      <url>/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%80)_%E5%B8%B8%E8%A7%84/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Linuxå¸¸ç”¨å‘½ä»¤æ€»ç»“</p></blockquote><a id="more"></a><h2><span id="man-åœ¨çº¿å‚è€ƒæ‰‹å†Œçš„æ¥å£">man - åœ¨çº¿å‚è€ƒæ‰‹å†Œçš„æ¥å£</span></h2><blockquote><p>manæ˜¯ç³»ç»Ÿçš„æ‰‹å†Œåˆ†é¡µç¨‹åºã€‚æŒ‡å®šç»™mançš„é¡µé€‰é¡¹é€šå¸¸æ˜¯ç¨‹åºã€å·¥å…·æˆ–å‡½æ•°åã€‚ç¨‹åºå°†æ˜¾ç¤ºæ‰¾åˆ°çš„ç›¸å…³æ‰‹å†Œé¡µã€‚å¦‚æœæŒ‡å®šäº†ç« èŠ‚ï¼Œmanå°†åªåœ¨æ‰‹å†Œçš„æŒ‡å®šç« èŠ‚æœç´¢ã€‚é»˜è®¤å°†æŒ‰é¢„å®šçš„é¡ºåºæŸ¥æ‰¾ã€‚</p></blockquote><p><em>å¸¸ç”¨çš„æ‰‹å†Œç« èŠ‚åŠç±»å‹ï¼š</em> * 1 å¯æ‰§è¡Œç¨‹åºæˆ–shellå‘½ä»¤ * 5 æ–‡ä»¶æ ¼å¼å’Œè§„èŒƒï¼Œå¦‚/etc/passwd * 8 ç³»ç»Ÿç®¡ç†å‘½ä»¤ï¼ˆé€šå¸¸åªé’ˆå¯¹rootç”¨æˆ·ï¼‰</p><blockquote><p>ä¸€ä¸ªæ‰‹å†Œé¡µé¢åŒ…å«è‹¥å¹²ä¸ªå°èŠ‚ã€‚ å°èŠ‚é€šå¸¸åŒ…æ‹¬ï¼šNAME, æ¦‚è¿°(SYNOPSIS), é…ç½®(CONFIGURATION), æè¿°(DESCRIPTION), é€‰é¡¹(OPTIONS), é€€å‡ºçŠ¶æ€(EXIT STATUS), è¿”å›å€¼(RETURN VALUE), é”™è¯¯(ERRORS), ç¯å¢ƒ(ENVIRONMENT), æ–‡ä»¶(FILES), ç‰ˆæœ¬(VERSIONS), ç¬¦åˆæ ‡å‡†(CONFORMING TO), æ³¨(NOTES), ç¼ºé™·(BUGS), ç¤ºä¾‹(EXAMPLE), ä½œè€…(AUTHORS), å’Œ äº¦è§(SEE ALSO).</p></blockquote><p><em>æ¦‚è¿°å°èŠ‚è§„èŒƒï¼š</em> * åŠ ç²—æ–‡æœ¬ åŸæ ·æ˜¾ç¤ºçš„æ ·å¼ã€‚ * å€¾æ–œæ–‡æœ¬ æ›¿æ¢ä¸ºç›¸åº”çš„å‚æ•°ã€‚ * [-abc] [ ] å†…çš„ä»»æ„/å…¨éƒ¨å‚æ•°éƒ½æ˜¯å¯é€‰çš„ã€‚ * -a|-b ä»¥ | åˆ†éš”çš„é€‰é¡¹å¯ä»¥ä¸€èµ·ä½¿ç”¨ã€‚ * å‚æ•° ... å‚æ•° å¯ä»¥é‡å¤ã€‚ * [è¡¨è¾¾å¼] ... [ ] å†…çš„æ•´ä¸ª è¡¨è¾¾å¼ å¯ä»¥é‡å¤ã€‚</p><p><em>æŸ¥è¯¢æ•°æ®æ–¹æ³•ï¼š</em> 1. å…ˆæŸ¥çœ‹NAMEçš„é¡¹ç›®ï¼Œçº¦ç•¥çœ‹ä¸€ä¸‹è¿™ä¸ªæ•°æ®çš„æ„æ€ã€‚ 2. å†ä»”ç»†çœ‹ä¸€ä¸‹DESCROPTIONï¼Œè¿™ä¸ªéƒ¨åˆ†ä¼šæåˆ°å¾ˆå¤šç›¸å…³çš„èµ„æ–™ä¸ç”¨æ³•ï¼Œä»è¿™ä¸ªåœ°æ–¹å¯ä»¥å­¦åˆ°å¾ˆå¤šç»†èŠ‚ã€‚ 3. è€Œå¦‚æœå¯¹è¿™ä¸ªå‘½ä»¤å…¶å®å¾ˆç†Ÿæ‚‰äº†ï¼Œé‚£ä¹ˆä¸»è¦å°±æ˜¯æŸ¥è¯¢å…³äºOPTIONSçš„éƒ¨åˆ†äº†ã€‚å¯ä»¥çŸ¥é“æ¯ä¸ªé€‰é¡¹çš„æ„ä¹‰ï¼Œè¿™æ ·å°±å¯ä»¥æ‰§è¡Œæ¯”è¾ƒç»†éƒ¨çš„å†…å®¹ã€‚ 4. æœ€åä¼šçœ‹ä¸€ä¸‹è·Ÿè¿™ä¸ªèµ„æ–™ç›¸å…³çš„è¿˜æœ‰å“ªäº›ä¸œè¥¿å¯ä»¥ä½¿ç”¨çš„ã€‚</p><p><strong>mançš„å‚æ•°</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">man -k printf #åœ¨ç³»ç»Ÿè¯´æ˜æ–‡ä»¶ä¸­ï¼Œåªè¦æœ‰printfè¿™ä¸ªå…³é”®å­—å°±å°†è¯¥è¯´æ˜åˆ—å‡ºæ¥ã€‚</span><br><span class="line">man -f smail  #æŸ¥æ‰¾smail å¼•ç”¨çš„æ‰‹å†Œé¡µå¹¶è¾“å‡ºæ‰¾åˆ°çš„ä»»ä½•æ¦‚è¿°</span><br></pre></td></tr></table></figure></p><p><strong>man page ä¸­å¸¸ç”¨æŒ‰é”®</strong> | ç©ºæ ¼é”®, [Page Down] | å‘ä¸‹ç¿»ä¸€é¡µ | | :-------- | :--------| | [Page Up] | å‘ä¸Šç¿»ä¸€é¡µ | | [Home] | å»ç¬¬ä¸€é¡µ | | [End] | å»æœ€åä¸€é¡µ | |<strong>/string</strong> |<strong>å‘ä¸‹æŸ¥è¯¢stringå­—ç¬¦ä¸²</strong> | | ?string | å‘ä¸ŠæŸ¥è¯¢stringå­—ç¬¦ä¸² | |<strong>n, N</strong>| <strong>æŸ¥è¯¢æ—¶, åˆ©ç”¨næ¥ç»§ç»­ä¸‹ä¸€ä¸ªæŸ¥è¯¢,Næ¥è¿›è¡Œåå‘æŸ¥è¯¢</strong> | | q | é€€å‡ºman page|</p><h2><span id="nano-ç®€å•çš„æ–‡æœ¬ç¼–è¾‘å™¨">nano - ç®€å•çš„æ–‡æœ¬ç¼–è¾‘å™¨</span></h2><p><em>ç”¨æ³•</em> <code>nano  æ–‡ä»¶å      æ‰“å¼€ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶</code></p><p><em>nanoçš„å‡ ä¸ªé‡è¦çš„ç»„åˆé”®</em> |[Ctrl] + G | å–å¾—åœ¨çº¿å¸®åŠ©| | :-------- | :--------| |[Ctrl] + X | ç¦»å¼€nanoï¼Œè‹¥æœ‰ä¿®æ”¹ä¼šæç¤ºæ˜¯å¦éœ€è¦ä¿å­˜| |[Ctrl] + O | ä¿å­˜æ–‡ä»¶| |[Ctrl] + R | ä»å…¶ä»–æ–‡ä»¶è¯»å…¥æ•°æ®| |[Ctrl] + W | æŸ¥è¯¢å­—ç¬¦ä¸²| |[Ctrl] + C | è¯´æ˜ç›®å‰å…‰æ ‡æ‰€åœ¨è¡Œåˆ—ç­‰ä¿¡æ¯| |[Ctrl] + è¡Œå· | å¯ä»¥è®©å…‰æ ‡ç§»åŠ¨åˆ°è¯¥è¡Œ| |[Alt] + M | å¯ä»¥æ”¯æŒé¼ æ ‡æ¥ç§»åŠ¨å…‰æ ‡åŠŸèƒ½|</p><h2><span id="ls-åˆ—å‡ºç›®å½•å†…å®¹">ls - åˆ—å‡ºç›®å½•å†…å®¹</span></h2><p><em>æè¿°ï¼š</em> <strong>åˆ—å‡ºå½“å‰ç›®å½•ï¼ˆé»˜è®¤ï¼‰æ–‡ä»¶ä¿¡æ¯ï¼Œå¦‚æœæ²¡æŒ‡å®šæ’åºè§„åˆ™çš„è¯å°±æŒ‰ç…§å­—æ¯é¡ºåºæ’åºã€‚</strong></p><p><em>ç”¨æ³•ï¼š</em> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls   [-aAdfFhilnrRSt]   ç›®å½•åç§°</span><br><span class="line">ls   [--color=&#123;never, auto, always&#125; ]  ç›®å½•åç§°</span><br><span class="line">ls   [--full-time]   ç›®å½•åç§°</span><br></pre></td></tr></table></figure></p><p><em>å‚æ•°ï¼š </em><br>|-a, -all | åˆ—å‡ºåŒ…æ‹¬éšè—æ–‡ä»¶(å³ â€œ.â€å¼€å¤´çš„æ–‡ä»¶å)| | :-------- | :--------| |-A | åˆ—å‡ºå…¨éƒ¨æ–‡ä»¶è¿åŒéšè—æ–‡ä»¶ä½†ä¸åŒ…æ‹¬ . ä¸ ..| |<strong>-d </strong>| <strong>ä»…åˆ—å‡ºç›®å½•ï¼Œè€Œä¸æ˜¯åˆ—å‡ºç›®å½•é‡Œæ–‡ä»¶æ•°æ®</strong>| | -f | ç›´æ¥åˆ—å‡ºç»“æœï¼Œä¸æ’åº| | -F | æ ¹æ®æ–‡ä»¶ã€ç›®å½•ç­‰ä¿¡æ¯ç»™äºˆé™„åŠ æ•°æ®ç»“æ„, ä¾‹å¦‚ * ä»£è¡¨å¯æ‰§è¡Œæ–‡ä»¶ï¼› / ä»£è¡¨ç›®å½•| | -h | å°†æ–‡ä»¶å®¹é‡ä»¥äººç±»è¾ƒæ˜“è¯»çš„æ–¹å¼åˆ—å‡ºæ¥(GB, KBç­‰)| | -i | åˆ—å‡ºinodeå·ç | |<strong>-l</strong> | <strong>åˆ—å‡ºé•¿æ•°æ®ä¸²ï¼Œ åŒ…å«æ–‡ä»¶çš„å±æ€§ä¸æƒé™ç­‰æ•°æ®</strong>| | -r | å°†æ’åºç»“æœååºè¾“å‡º| | -t | æŒ‰æ—¶é—´æ’åº| | -s | æ˜¾ç¤ºæ–‡ä»¶å¤§å°| | -S | æŒ‰æ–‡ä»¶å¤§å°æ’åº| | --sort=WORD|æŒ‰WORDæ–¹å¼æ’åº,WORDå–å€¼ï¼šnone (-U), extension (-X), size (-S), time (-t), version (-v)| | --full-time |ä»¥å®Œæ•´çš„æ—¶é—´æ¨¡å¼ï¼ˆåŒ…å«å¹´æœˆæ—¥æ—¶åˆ†ï¼‰è¾“å‡º|</p><p>æ³¨ï¼š<code>ll = ls -l</code></p><p><strong>ls -al æ–‡ä»¶ä¿¡æ¯è¯¦è§£</strong></p><p><strong>è¡¨ç¤ºåˆ—å‡ºæ‰€æœ‰çš„æ–‡ä»¶è¯¦ç»†çš„æƒé™ä¸å±æ€§ï¼ˆåŒ…å«éšè—æ–‡ä»¶ï¼‰</strong> ä¾‹å¦‚ï¼š <code>-rw-------  1 neymar neymar     2532 10æœˆ 13 23:42 .bash_history</code> * ç¬¬ä¸€åˆ—ä»£è¡¨è¿™ä¸ªæ–‡ä»¶çš„ç±»å‹ä¸æƒé™ * ç¬¬ä¸€ä¸ªå­—ç¬¦è‹¥æ˜¯[d]åˆ™æ˜¯ç›®å½•ï¼Œè‹¥æ˜¯[-]åˆ™æ˜¯æ–‡ä»¶æ¥ä¸‹æ¥çš„å­—ç¬¦ï¼Œä¸‰ä¸ªä¸ºä¸€ç»„ï¼Œä¸”å‡ä¸ºâ€rwxâ€çš„ç»„åˆã€‚å…¶ä¸­<strong>[r]</strong>ä»£è¡¨å¯è¯»(read)ï¼Œ<strong>[w]</strong>ä»£è¡¨å¯å†™(write), <strong>[x]</strong>ä»£è¡¨å¯æ‰§è¡Œ(execute),å¦‚æœæ²¡æœ‰æƒé™å°±ä¼šå‡ºç°<strong>[-]</strong>ã€‚ * ç¬¬ä¸€ç»„ä¸º <em>æ–‡ä»¶æ‰€æœ‰è€…</em> çš„æƒé™ * ç¬¬äºŒç»„ä¸º <em>åŒç”¨æˆ·ç»„</em> çš„æƒé™ * ç¬¬ä¸‰ç»„ä¸º <em>å…¶ä»–éæœ¬ç”¨æˆ·ç»„</em> çš„æƒé™ * ç¬¬äºŒåˆ—è¡¨ç¤ºæœ‰å¤šå°‘æ–‡ä»¶åè¿æ¥åˆ°æ­¤èŠ‚ç‚¹ * ç¬¬ä¸‰åˆ—è¡¨ç¤ºè¿™ä¸ªæ–‡ä»¶ï¼ˆç›®å½•ï¼‰çš„â€æ‰€æœ‰è€…è´¦å·â€œ * ç¬¬å››åˆ—è¡¨ç¤ºè¿™ä¸ªæ–‡ä»¶çš„æ‰€å±ç”¨æˆ·ç»„ * ç¬¬äº”åˆ—è¡¨ç¤ºè¿™ä¸ªæ–‡ä»¶çš„å®¹é‡å¤§å°ï¼Œé»˜è®¤å•ä½ä¸ºB * ç¬¬å…­åˆ—ä¸ºè¿™ä¸ªæ–‡ä»¶çš„æœ€è¿‘ä¿®æ”¹æ—¥æœŸ * ç¬¬ä¸ƒåˆ—ä¸ºæ–‡ä»¶å</p><h2><span id="chgrp-æ”¹å˜æ–‡ä»¶æ‰€å±ç”¨æˆ·ç»„-change-group">chgrp - æ”¹å˜æ–‡ä»¶æ‰€å±ç”¨æˆ·ç»„ change group</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>chgrp [-R] ç”¨æˆ·ç»„å ç›®å½•/æ–‡ä»¶å</code> <em>å‚æ•°ï¼š</em> * -R : è¿›è¡Œé€’å½’çš„æŒç»­æ›´æ”¹ï¼Œä¹Ÿå³è¿åŒå­ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶ã€ç›®å½•éƒ½æ›´æ–°æˆè¿™ä¸ªç”¨æˆ·ç»„</p><p><em>æ³¨æ„ï¼š</em>è¦æ”¹å˜çš„ç»„åå¿…é¡»å†/etc/groupæ–‡ä»¶å†…å­˜åœ¨æ‰è¡Œï¼Œå¦åˆ™å°±ä¼šæ˜¾ç¤ºé”™è¯¯</p><h2><span id="chown-æ”¹å˜æ–‡ä»¶æ‰€æœ‰è€…å’Œç”¨æˆ·ç»„-change-owner">chown - æ”¹å˜æ–‡ä»¶æ‰€æœ‰è€…å’Œç”¨æˆ·ç»„ change owner</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>chown [-R] è´¦å·åç§°:ç»„å æ–‡ä»¶æˆ–ç›®å½•</code> <em>æ³¨æ„ï¼š</em>ç”¨æˆ·å¿…é¡»æ˜¯å·²ç»å­˜åœ¨äºç³»ç»Ÿä¸­çš„è´¦å·ï¼Œä¹Ÿå°±æ˜¯åœ¨/etc/passwdè¿™ä¸ªæ–‡ä»¶ä¸­æœ‰è®°å½•çš„ç”¨æˆ·åæ‰èƒ½æ”¹å˜</p><h2><span id="chmod-æ”¹å˜æƒé™">chmod - æ”¹å˜æƒé™</span></h2><p><strong>æ•°å­—ç±»å‹æ”¹å˜æ–‡ä»¶æƒé™ï¼š</strong> * r : 4<br>* w : 2<br>* x : 1 <code>chmod [-R] xyz æ–‡ä»¶æˆ–ç›®å½•</code> <em>xyz : æ•°å­—ç±»å‹æƒé™å±æ€§ï¼Œä¸ºrwxå±æ€§å€¼ç›¸åŠ </em></p><p>ä¾‹ï¼š<code>chmod 777 .bashrc</code></p><p><strong>ç¬¦å·ç±»å‹æ”¹å˜æ–‡ä»¶æƒé™ï¼š</strong> | | | u | | | | | :-------- | :--------| :------- | :--------| | | chmod | g | +(åŠ å…¥) | r | æ–‡ä»¶æˆ–ç›®å½• | | |o | -(å‡å») | w | | |a | =(ç­‰äº) | x |</p><p><strong>user â†’ u, group â†’ g, others â†’ o, all â†’ a</strong></p><p><em>ä¾‹ï¼š</em> <code>chmod u=rwx,go=rx .bashrc</code></p><h2><span id="cd-åˆ‡æ¢ç›®å½•-change-directory">cd - åˆ‡æ¢ç›®å½• Change Directory</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>cd [ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„]</code></p><p><strong>ç‰¹æ®Šç›®å½•ï¼š</strong> * . ä»£è¡¨æ­¤å±‚ç›®å½• * .. ä»£è¡¨ä¸Šä¸€å±‚ç›®å½• * - ä»£è¡¨å‰ä¸€ä¸ªå·¥ä½œç›®å½• * ~ ä»£è¡¨ç›®å‰ç”¨æˆ·èº«ä»½æ‰€åœ¨çš„ä¸»æ–‡ä»¶å¤¹ * ~account ä»£è¡¨accountè¿™ä¸ªç”¨æˆ·çš„ä¸»æ–‡ä»¶å¤¹</p><h2><span id="pwd-æ˜¾ç¤ºç›®å‰æ‰€åœ¨çš„ç›®å½•-print-working-directory">pwd - æ˜¾ç¤ºç›®å‰æ‰€åœ¨çš„ç›®å½• print working directory</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>pwd   [-P]</code> <em>å‚æ•°ï¼š</em> * -P : æ˜¾ç¤ºå‡ºå½“å‰çš„è·¯å¾„ï¼Œè€Œéä½¿ç”¨è¿æ¥(link)è·¯å¾„</p><h2><span id="mkdir-æ–°å»ºç›®å½•-make-directory">mkdir - æ–°å»ºç›®å½• make directory</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>mkdir [-mp]  ç›®å½•åç§°</code> <em>å‚æ•°ï¼š</em> * -m : é…ç½®æ–‡ä»¶å¤¹çš„æƒé™(æ•°å­—æ–¹å¼) * -p : å¸®åŠ©ä½ ç›´æ¥å°†æ‰€éœ€è¦çš„ç›®å½•é€’å½’åˆ›å»ºèµ·æ¥(ä¸å»ºè®®ç»å¸¸ä½¿ç”¨)</p><h2><span id="rmdir-åˆ é™¤ç©ºç›®å½•-remove-directory">rmdir - åˆ é™¤ç©ºç›®å½• remove directory</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>rmdir  [-p]   ç›®å½•åç§°</code> <em>å‚æ•°ï¼š</em> * -p : è¿åŒä¸Šå±‚ç©ºç›®å½•ä¸€èµ·åˆ é™¤</p><h2><span id="echo-æ˜¾ç¤ºæ‰“å°å‡º">echo - æ˜¾ç¤º,æ‰“å°å‡º</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>echo   [-eE]  å­—ç¬¦ä¸²</code> <code>echo   $variable</code> <em>å‚æ•°ï¼š</em> * -e : æŠŠ â€ Â â€œ å½“åšè½¬ä¹‰å­—ç¬¦ * -E : ä¸æŠŠåæ–œæ‰›å½“åšè½¬ä¹‰å­—ç¬¦ï¼ˆé»˜è®¤ï¼‰</p><h2><span id="cp-å¤åˆ¶-copy">cp - å¤åˆ¶ copy</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>cp  [-adfilprsu]   æºæ–‡ä»¶  ç›®æ ‡æ–‡ä»¶</code> <code>cp  [options]    source1  source2  source3.... directory</code> <em>å‚æ•°ï¼š</em> * <strong>-a : ç›¸å½“äº -pdr çš„æ„æ€ï¼Œæ•°æ®ç‰¹æ€§å®Œå…¨å¤åˆ¶ï¼ˆæ•ˆæœä¸èº«ä»½æœ‰å…³ï¼‰</strong> * -d : è‹¥æºæ–‡ä»¶ä¸ºè¿æ¥æ–‡ä»¶çš„å±æ€§(link file),åˆ™å¤åˆ¶è¿æ¥æ–‡ä»¶å±æ€§è€Œéæ–‡ä»¶èº« * -f : forceï¼Œè‹¥ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ä¸”æ— æ³•å¼€å¯ï¼Œåˆ™åˆ é™¤åå†è¯•ä¸€æ¬¡ * <strong>-i : è‹¥ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨åˆ™ä¼šè¯¢é—®æ˜¯å¦è¦†ç›–</strong> * -l : è¿›è¡Œç¡¬è¿æ¥(hard link)çš„è¿æ¥æ–‡ä»¶åˆ›å»ºï¼Œè€Œéå¤åˆ¶æ–‡ä»¶æœ¬èº« * -p : è¿åŒæ–‡ä»¶å±æ€§ä¸€èµ·å¤åˆ¶è¿‡å»ï¼Œè€Œéä½¿ç”¨é»˜è®¤å±æ€§ï¼ˆå¤‡ä»½å¸¸ç”¨ï¼‰ * <strong>-r : é€’å½’æŒç»­å¤åˆ¶ï¼Œç”¨äºç›®å½•çš„å¤åˆ¶è¡Œä¸º</strong> * -s : å¤åˆ¶æˆä¸ºç¬¦å·é“¾æ¥æ–‡ä»¶(symbolic link)ï¼Œå³â€œå¿«æ·æ–¹å¼â€æ–‡ä»¶ * -u : è‹¥ç›®æ ‡æ–‡ä»¶æ¯”æºæ–‡ä»¶æ—§æ—¶æ‰æ›´æ–° <strong>æ³¨æ„ï¼šå¦‚æœæºæ–‡ä»¶æœ‰ä¸¤ä¸ªä»¥ä¸Šï¼Œåˆ™æœ€åä¸€ä¸ªç›®çš„æ–‡ä»¶ä¸€å®šè¦æ˜¯ç›®å½•æ‰è¡Œ</strong></p><h2><span id="rm-ç§»é™¤æ–‡ä»¶æˆ–ç›®å½•">rm - ç§»é™¤æ–‡ä»¶æˆ–ç›®å½•</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>rm  [-fir]  æ–‡ä»¶æˆ–ç›®å½•</code> <em>å‚æ•°ï¼š</em> * -f : force, å¿½ç•¥ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼Œä¸ä¼šå‡ºç°è­¦å‘Šä¿¡æ¯ * -i : äº’åŠ¨æ¨¡å¼ï¼Œåœ¨åˆ é™¤å‰ä¼šè¯¢é—®ç”¨æˆ·æ˜¯å¦æ“ä½œ * -r : é€’å½’åˆ é™¤ã€‚æœ€å¸¸ç”¨åœ¨ç›®å½•çš„åˆ é™¤äº†ã€‚<strong>è¿™æ˜¯éå¸¸å±é™©çš„å‚æ•°ã€‚</strong></p><h2><span id="mv-ç§»åŠ¨æ–‡ä»¶ä¸ç›®å½•æˆ–æ›´å">mv - ç§»åŠ¨æ–‡ä»¶ä¸ç›®å½•æˆ–æ›´å</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>mv  [-fiu]  source  destination</code> <code>mv  [option]  source1  source2  source3 â€¦  directory</code> <em>å‚æ•°ï¼š</em> * -f : forceï¼Œå¦‚æœç›®æ ‡æ–‡ä»¶å·²ç»å­˜åœ¨ï¼Œä¸ä¼šè¯¢é—®è€Œç›´æ¥è¦†ç›– * -i : è‹¥ç›®æ ‡æ–‡ä»¶å·²ç»å­˜åœ¨æ—¶ï¼Œè¯¢é—®æ˜¯å¦è¦†ç›– * -u : è‹¥ç›®æ ‡æ–‡ä»¶å­˜åœ¨ä¸”sourceæ¯”è¾ƒæ–°æ‰ä¼šæ›´æ–°</p><h2><span id="cat-æŸ¥çœ‹æ–‡ä»¶å†…å®¹-concatenate">cat - æŸ¥çœ‹æ–‡ä»¶å†…å®¹ concatenate</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>cat  [-AbEnTv]</code> <em>å‚æ•°ï¼š</em> * -A : ç›¸å½“äº-vETçš„ç»“åˆï¼Œå¯ä»¥åˆ—å‡ºä¸€äº›ç‰¹æ®Šå­—ç¬¦ï¼Œè€Œä¸æ˜¯ç©ºç™½ * -b : åˆ—å‡ºè¡Œå·ï¼Œä»…é’ˆå¯¹éç©ºç™½è¡Œ * -E : å°†ç»“å°¾çš„æ–­è¡Œå­—ç¬¦ $ æ˜¾ç¤ºå‡ºæ¥ * <strong>-n : æ˜¾ç¤ºè¡Œå·ï¼Œè¿åŒç©ºç™½ç¬¦ï¼Œä¸-bä¸åŒ</strong> * -T : å°†[Tab]æŒ‰é”®ä»¥ ^I æ˜¾ç¤ºå‡ºæ¥ * -v : åˆ—å‡ºä¸€äº›çœ‹ä¸è§çš„ç‰¹æ®Šå­—ç¬¦</p><h2><span id="nl-æ·»åŠ è¡Œå·æ‰“å°">nl - æ·»åŠ è¡Œå·æ‰“å°</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>nl  [-bnw]  æ–‡ä»¶</code> <em>å‚æ•°ï¼š</em> * -b : æŒ‡å®šè¡Œå·çš„æ˜¾ç¤ºæ–¹å¼ï¼Œä¸»è¦æœ‰ä¸¤ç§ï¼š * -b a : è¡¨ç¤ºæ— è®ºæ˜¯å¦ä¸ºç©ºè¡Œï¼Œä¹ŸåŒæ ·åˆ—å‡ºè¡Œå·ï¼ˆç±»ä¼¼ä¸ cat -nï¼‰ * -b t : ç©ºè¡Œä¸åˆ—å‡ºè¡Œå·ï¼ˆé»˜è®¤ï¼‰ * -n : åˆ—å‡ºè¡Œå·çš„è¡¨ç¤ºæ–¹æ³•ï¼Œä¸»è¦æœ‰ä¸‰ç§ï¼š * -n ln : è¡Œå·åœ¨å±å¹•æœ€å·¦æ–¹æ˜¾ç¤º * -n rn : è¡Œå·åœ¨å­—æ®µæœ€å³æ–¹æ˜¾ç¤ºï¼Œä¸”ä¸åŠ 0 * -n rz : è¡Œå·åœ¨å­—æ®µæœ€å³æ–¹æ˜¾ç¤ºï¼ŒåŠ 0 * -w : è¡Œå·å­—æ®µå ç”¨ä½æ•°</p><h2><span id="more-å¯ç¿»é¡µæŸ¥çœ‹">more - å¯ç¿»é¡µæŸ¥çœ‹</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>more  æ–‡ä»¶å</code> <em>æ“ä½œï¼š</em> | ç©ºæ ¼é”® | ä»£è¡¨å‘ä¸‹ç¿»ä¸€é¡µ| | :-------- | :--------| | Enter | ä»£è¡¨å‘ä¸‹æ»šåŠ¨ä¸€è¡Œ| | /å­—ç¬¦ä¸² | å‘ä¸‹æŸ¥è¯¢â€å­—ç¬¦ä¸²â€œå…³é”®å­—| | :f | ç«‹åˆ»æ˜¾ç¤ºå‡ºæ–‡ä»¶åä»¥åŠç›®å‰æ˜¾ç¤ºçš„è¡Œæ•°| | q | ä»£è¡¨ç«‹åˆ»ç«‹åˆ»moreï¼Œä¸å†æ˜¾ç¤ºè¯¥æ–‡ä»¶å†…å®¹| | bæˆ–[ctrl]-b | ä»£è¡¨å¾€å›ç¿»é¡µï¼Œä¸è¿‡è¿™åªå¯¹æ–‡ä»¶æœ‰ç”¨ï¼Œå¯¹ç®¡é“æ— ç”¨|</p><h2><span id="less-ä¸€é¡µä¸€é¡µç¿»åŠ¨">less - ä¸€é¡µä¸€é¡µç¿»åŠ¨</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>less    æ–‡ä»¶å</code> <em>æ“ä½œï¼š</em> | ç©ºæ ¼ | å‘ä¸‹ç¿»åŠ¨ä¸€é¡µ| | :-------- | :-------- | | [PageDown] | å‘ä¸‹ç¿»åŠ¨ä¸€é¡µ| | [PageUp] | å‘ä¸Šç¿»åŠ¨ä¸€é¡µ| | /å­—ç¬¦ä¸² | å‘ä¸‹æŸ¥è¯¢â€å­—ç¬¦ä¸²â€œ| | ? å­—ç¬¦ä¸² | å‘ä¸ŠæŸ¥è¯¢â€å­—ç¬¦ä¸²â€œ| | n | é‡å¤å‰ä¸€ä¸ªæŸ¥è¯¢| | N | åå‘é‡å¤å‰ä¸€ä¸ªæŸ¥è¯¢| | q | ç¦»å¼€less|</p><h2><span id="head-å–å‡ºå‰é¢å‡ è¡Œ">head - å–å‡ºå‰é¢å‡ è¡Œ</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>head    [-n  number]   æ–‡ä»¶</code> <em>å‚æ•°ï¼š</em> * -n : åé¢æ¥æ•°å­—ï¼Œä»£è¡¨æ˜¾ç¤ºå‡ è¡Œçš„æ„æ€ï¼ˆé»˜è®¤10è¡Œï¼‰</p><h2><span id="tail-å–å‡ºåé¢å‡ è¡Œ">tail - å–å‡ºåé¢å‡ è¡Œ</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>tail   [-n  number]   æ–‡ä»¶</code> <em>å‚æ•°ï¼š</em> * -n : åé¢æ¥æ•°å­—ï¼Œä»£è¡¨æ˜¾ç¤ºå‡ è¡Œï¼ˆé»˜è®¤10è¡Œï¼‰ * -f : è¡¨ç¤ºæŒç»­æ£€æµ‹åé¢æ‰€æ¥çš„æ–‡ä»¶åï¼Œè¦ç­‰åˆ°æŒ‰ä¸‹[ctrl]-cæ‰ä¼šç»“æŸtailçš„æ£€æµ‹</p><h2><span id="od-è¯»å–éçº¯æ–‡æœ¬æ–‡ä»¶">od - è¯»å–éçº¯æ–‡æœ¬æ–‡ä»¶</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>od  [-t  TYPE]   æ–‡ä»¶</code> <em>å‚æ•°ï¼š</em> * -t : åé¢æ¥ç±»å‹ï¼š * a : åˆ©ç”¨é»˜è®¤çš„å­—ç¬¦æ¥è¾“å‡º * c : ä½¿ç”¨ASCIIå­—ç¬¦æ¥è¾“å‡º * d[size] : åˆ©ç”¨åè¿›åˆ¶æ¥è¾“å‡ºæ•°æ®ï¼Œæ¯ä¸ªæ•´æ•°å ç”¨size bytes * f[size] : åˆ©ç”¨æµ®ç‚¹æ•°æ¥è¾“å‡ºæ•°æ®ï¼Œæ¯ä¸ªæ•°å size bytes * x[size] : åˆ©ç”¨åå…­è¿›åˆ¶æ¥è¾“å‡ºæ•°æ®ï¼Œæ¯ä¸ªæ•´æ•°å size bytes</p><h2><span id="touch-ä¿®æ”¹æ–‡ä»¶æ—¶é—´æˆ–åˆ›å»ºæ–°æ–‡ä»¶">touch - ä¿®æ”¹æ–‡ä»¶æ—¶é—´æˆ–åˆ›å»ºæ–°æ–‡ä»¶</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>touch  [-acdmt]   æ–‡ä»¶</code> <em>å‚æ•°ï¼š</em> * -a : ä»…ä¿®æ”¹è®¿é—®æ—¶é—´ * -c : ä»…ä¿®æ”¹æ–‡ä»¶æ—¶é—´ï¼Œè‹¥è¯¥æ–‡ä»¶ä¸å­˜åœ¨åˆ™ä¸åˆ›å»ºæ–°æ–‡ä»¶ * -d : åé¢å¯ä»¥æ¥æ¬²ä¿®æ”¹çš„æ—¥æœŸè€Œä¸ç”¨ç›®å‰çš„æ—¥æœŸï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ â€“date=â€æ—¥æœŸæˆ–æ—¶é—´â€ * -m : ä»…ä¿®æ”¹mtime * -t : åé¢å¯ä»¥æ¥æ¬²ä¿®æ”¹æ—¶é—´è€Œä¸æ˜¯å½“å‰æ—¶é—´ï¼Œæ ¼å¼ä¸º[YYMMDDhhmm]</p><h2><span id="whereis-å¯»æ‰¾ç‰¹å®šæ–‡ä»¶">whereis -å¯»æ‰¾ç‰¹å®šæ–‡ä»¶</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>whereis  [-bmsu]  æ–‡ä»¶æˆ–ç›®å½•å</code> <em>å‚æ•°ï¼š</em> * -b : åªæŸ¥æ‰¾äºŒè¿›åˆ¶æ–‡ä»¶ * -m : åªæŸ¥æ‰¾åœ¨manualè·¯å¾„ä¸‹çš„æ–‡ä»¶ * -s : åªæ‰¾sourceæºæ–‡ä»¶ * -u : æŸ¥æ‰¾ä¸åœ¨ä¸Šè¿°ä¸‰ä¸ªé€‰é¡¹ä¸­çš„å…¶ä»–ç‰¹æ®Šæ–‡ä»¶ <strong>æ³¨ï¼šwhereisæ˜¯åˆ©ç”¨æ•°æ®åº“æŸ¥æ‰¾æ–‡ä»¶è€Œä¸æ˜¯ç›´æ¥åœ¨ç¡¬ç›˜é‡Œæ‰¾</strong></p><h2><span id="locate-æŸ¥æ‰¾æ–‡ä»¶">locate - æŸ¥æ‰¾æ–‡ä»¶</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>locate  [-ir]   keyword</code> <em>å‚æ•°ï¼š</em> * -i : å¿½ç•¥å¤§å°å†™å·®å¼‚ * -r : åé¢å¯æ¥æ­£åˆ™è¡¨è¾¾å¼çš„æ˜¾ç¤ºæ–¹å¼ <strong>æ³¨ï¼šlocateä¹Ÿæ˜¯ç»ç”±æ•°æ®åº“æŸ¥æ‰¾ï¼Œé€Ÿåº¦è¾ƒå¿«ï¼Œæ›´æ–°æ•°æ®åº“å‘½ä»¤ï¼š<code>updatedb</code></strong></p><h2><span id="find-åœ¨ç¡¬ç›˜é‡Œå¯»æ‰¾æ–‡ä»¶">find - åœ¨ç¡¬ç›˜é‡Œå¯»æ‰¾æ–‡ä»¶</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>find   [PATH]    [option]    [action]</code> <em>å‚æ•°ï¼š</em> 1. ä¸æ—¶é—´æœ‰å…³çš„: å…±æœ‰ -atime, -ctime ä¸ -mtimeï¼Œä¸‹é¢ä»¥-mtimeè¯´æ˜ * -mtime n : nä¸ºæ•°å­—ï¼Œæ„ä¸ºæŸ¥æ‰¾åœ¨nå¤©ä¹‹å‰çš„é‚£ä¸€å¤©ä¹‹å†…è¢«æ›´æ”¹è¿‡çš„æ–‡ä»¶ * -mtime +n : åˆ—å‡ºåœ¨nå¤©ä¹‹å‰ï¼ˆä¸å«nå¤©æœ¬èº«ï¼‰è¢«æ›´æ”¹è¿‡çš„æ–‡ä»¶å * -mtine -n : åˆ—å‡ºnå¤©ä¹‹å†…ï¼ˆåŒ…å«ç¬¬nå¤©ï¼‰è¢«æ›´æ”¹è¿‡çš„æ–‡ä»¶å * -newer file : fileä¸ºä¸€ä¸ªå·²å­˜åœ¨æ–‡ä»¶ï¼Œåˆ—å‡ºæ¯”fileè¦æ–°çš„æ–‡ä»¶å</p><ol start="2" type="1"><li>ä¸ç”¨æˆ·æˆ–ç”¨æˆ·ç»„åæœ‰å…³çš„å‚æ•°ï¼š<ul><li><pre><code>   -uid   n   :  nä¸ºæ•°å­—ï¼Œè¿™ä¸ªæ•°å­—æ˜¯ç”¨æˆ·çš„è´¦å·IDï¼Œå³UIDï¼Œè®°å½•åœ¨/etc/passwdé‡Œé¢ä¸è´¦å·å                                                 ç§°å¯¹åº”çš„æ•°å­—</code></pre></li><li><pre><code>   -gid   n   :  nä¸ºæ•°å­—ï¼Œè¿™ä¸ªæ•°å­—æ˜¯ç”¨æˆ·ç»„åçš„IDï¼Œå³GIDï¼Œè¿™ä¸ªGIDè®°å½•åœ¨/etc/groupä¸­</code></pre></li><li><pre><code>     -user  name  :  æŸ¥æ‰¾ç”¨æˆ·åä¸ºnameçš„æ–‡ä»¶</code></pre></li><li><pre><code>     -group  name :  æŸ¥æ‰¾ç”¨æˆ·ç»„åä¸ºnameçš„æ–‡ä»¶</code></pre></li><li><pre><code>     -nouser          :    å¯»æ‰¾æ–‡ä»¶æ‰€æœ‰è€…ä¸åœ¨/etc/passwdçš„äºº</code></pre></li><li><pre><code>     -nogroup       :    å¯»æ‰¾ç”¨æˆ·ç»„åä¸å­˜åœ¨ä¸/etc/groupçš„äºº</code></pre></li></ul></li><li>ä¸æ–‡ä»¶æƒé™åŠåç§°æœ‰å…³çš„å‚æ•°ï¼š<ul><li><pre><code>     -name  filenname :  æŸ¥æ‰¾æ–‡ä»¶åä¸ºfilenameçš„æ–‡ä»¶</code></pre></li><li><pre><code>      -size     [+-]SIZE   :   æŸ¥æ‰¾æ¯”SIZEè¿˜è¦å¤§(+)æˆ–å°(-)çš„æ–‡ä»¶ï¼ŒSIZEè§„æ ¼ï¼šcä»£è¡¨byte,kä»£ è¡¨kb</code></pre></li><li><pre><code>      -type   TYPE  :  æŸ¥æ‰¾æ–‡ä»¶ç±»å‹ä¸ºTYPEçš„æ–‡ä»¶ã€‚ç±»å‹ä¸»è¦æœ‰ï¼šä¸€èˆ¬æ­£è§„æ–‡ä»¶(f),è®¾å¤‡æ–‡ä»¶(b,c)ç›®å½•(d)ï¼Œè¿æ¥æ–‡ä»¶(l)ï¼Œsocket(s)åŠFIFO(p)ç­‰</code></pre></li><li><pre><code>       -perm  mode :  æŸ¥æ‰¾æ–‡ä»¶æƒé™â€œåˆšå¥½ç­‰äºâ€modeçš„æ–‡ä»¶ï¼Œè¿™ä¸ªmodeç±»ä¼¼äºchmodçš„å±æ€§å€¼</code></pre></li><li><pre><code>       -perm  -mode : æŸ¥æ‰¾æ–‡ä»¶æƒé™ï¼šå¿…é¡»è¦å…¨éƒ¨åŒ…æ‹¬modeçš„æƒé™â€œçš„æ–‡ä»¶</code></pre></li><li><pre><code>      -perm +mode : æŸ¥æ‰¾æ–‡ä»¶æƒé™â€åŒ…å«ä»»ä¸€modeæƒé™â€œçš„æ–‡ä»¶</code></pre></li></ul></li><li>å…¶ä»–å¯è¿›è¡Œçš„æ“ä½œï¼š<ul><li><pre><code>     -exec command  :  commandä¸ºå…¶ä»–å‘½ä»¤  -execåé¢å¯å†æ¥å…¶ä»–å‘½ä»¤æ¥å¤„ç†æŸ¥æ‰¾åˆ°çš„ç»“æœ{}ä»£è¡¨ç”±findæ‰¾åˆ°çš„å†…å®¹ï¼Œå‘½ä»¤å€Ÿä¹¦æ ‡å¿—â€ \; â€ä¾‹ï¼š`find / -perm +7000 -exec ls -l {} \;`</code></pre></li><li><pre><code>      -print  :  å°†ç»“æœæ‰“å°åˆ°å±å¹•ä¸Šï¼ˆé»˜è®¤ï¼‰</code></pre></li></ul></li></ol><h2><span id="vi-æ–‡æœ¬ç¼–è¾‘å™¨">vi -æ–‡æœ¬ç¼–è¾‘å™¨</span></h2><p><strong>viåˆ†ä¸ºä¸‰ç§æ¨¡å¼ï¼šä¸€èˆ¬æ¨¡å¼ï¼Œç¼–è¾‘æ¨¡å¼ä¸å‘½ä»¤è¡Œæ¨¡å¼ã€‚</strong></p><blockquote><p>ä¸€èˆ¬æ¨¡å¼ï¼šå¯ä»¥ç”¨ä¸Šä¸‹å·¦å³é”®ç§»åŠ¨å…‰æ ‡ï¼Œåˆ é™¤å­—ç¬¦æˆ–æ•´è¡Œï¼Œä¹Ÿå¯ä»¥å¤åˆ¶ã€ç²˜è´´æ–‡ä»¶æ•°æ® ç¼–è¾‘æ¨¡å¼ï¼šä¸€èˆ¬æ¨¡å¼æ— æ³•ç¼–è¾‘å†…å®¹ï¼Œåœ¨ä¸€èˆ¬æ¨¡å¼ä¸­æŒ‰ä¸‹i,I,o,Oç­‰å¯ä»¥è¿›å…¥ç¼–è¾‘æ¨¡å¼ å‘½ä»¤è¡Œæ¨¡å¼ï¼šåœ¨ä¸€èˆ¬æ¨¡å¼ä¸­è¾“å…¥â€œ :, /, ? â€œä¸‰ä¸ªä¸­çš„ä»»ä¸€å­—ç¬¦å°±å¯ä»¥å°†å…‰æ ‡ç§»åŠ¨åˆ°æœ€ä¸‹é¢ä¸€è¡Œï¼Œåœ¨æ­¤æ¨¡å¼ä¸­å¯ä»¥æä¾›æŸ¥è¯¢æ•°æ®æ“ä½œï¼Œå¤§é‡æ›¿æ¢å­—ç¬¦ã€ç¦»å¼€viã€æ˜¾ç¤ºè¡Œå·ç­‰æ“ä½œ</p></blockquote><p><strong>å¸¸ç”¨æŒ‰é”®è¯´æ˜</strong> |ç§»åŠ¨å…‰æ ‡æ–¹æ³•| | | :-------- | :-------- | | hæˆ–å·¦é”®å¤´é”® |å…‰æ ‡å‘å·¦ç§»åŠ¨ä¸€ä¸ªå­—ç¬¦| | jæˆ–å‘ä¸‹ç®­å¤´ |å…‰æ ‡å‘ä¸‹ç§»åŠ¨ä¸€ä¸ªå­—ç¬¦| | kæˆ–å‘ä¸Šç®­å¤´| å…‰æ ‡å‘ä¸Šç§»åŠ¨ä¸€ä¸ªå­—ç¬¦| | læˆ–å‘å³ç®­å¤´ |å…‰æ ‡å‘å³ç§»åŠ¨ä¸€ä¸ªå­—ç¬¦| | æ•°å­—+ä¸Šä¸‹ç®­å¤´ |å‘ä¸Šä¸‹ç§»åŠ¨â€œæ•°å­—â€è¡Œ| | [Crtl]+[f]ã€[PageDown] |å‘ä¸‹ç¿»ä¸€é¡µ| | [Ctrl]+[b]ã€[PageUp] |å‘ä¸Šç¿»ä¸€é¡µ| | G |ç§»åŠ¨åˆ°è¿™ä¸ªæ–‡ä»¶çš„æœ€åä¸€è¡Œ| | nG |nä¸ºæ•°å­—ï¼Œç§»åŠ¨åˆ°è¿™ä¸ªæ–‡ä»¶çš„ç¬¬nè¡Œ| | gg | ç§»åŠ¨åˆ°è¿™ä¸ªæ–‡ä»¶çš„ç¬¬ä¸€è¡Œï¼Œç›¸å½“äº1G| | N[Enter] | nä¸ºæ•°å­—ã€‚å…‰æ ‡å‘ä¸‹ç§»åŠ¨nè¡Œ|</p><table><thead><tr class="header"><th style="text-align: left;">åˆ é™¤ã€å¤åˆ¶ä¸ç²˜è´´</th><th style="text-align: left;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">x</td><td style="text-align: left;">åœ¨ä¸€è¡Œå­—å½“ä¸­ï¼Œå‘ååˆ é™¤ä¸€ä¸ªå­—ç¬¦([Del])</td></tr><tr class="even"><td style="text-align: left;">X</td><td style="text-align: left;">å‘å‰åˆ é™¤ä¸€ä¸ªå­—ç¬¦([Backspace])</td></tr><tr class="odd"><td style="text-align: left;">dd</td><td style="text-align: left;">åˆ é™¤å…‰æ ‡æ‰€åœ¨çš„é‚£ä¸€æ•´è¡Œ</td></tr><tr class="even"><td style="text-align: left;">ndd</td><td style="text-align: left;">nä¸ºæ•°å­—ï¼Œåˆ é™¤å…‰æ ‡æ‰€åœ¨çš„ä¸‹nè¡Œ</td></tr><tr class="odd"><td style="text-align: left;">yy</td><td style="text-align: left;">å¤åˆ¶å…‰æ ‡æ‰€åœ¨é‚£ä¸€è¡Œ</td></tr><tr class="even"><td style="text-align: left;">nyy</td><td style="text-align: left;">nä¸ºæ•°å­—ï¼Œå¤åˆ¶å…‰æ ‡å‘ä¸‹çš„nè¡Œ</td></tr><tr class="odd"><td style="text-align: left;">p, P</td><td style="text-align: left;">pä¸ºå°†å·²å¤åˆ¶çš„æ•°æ®åœ¨å…‰æ ‡ä¸‹ä¸€è¡Œç²˜è´´ï¼Œ Pä¸ºç²˜è´´åœ¨å…‰æ ‡ä¸Šä¸€è¡Œ</td></tr><tr class="even"><td style="text-align: left;">u</td><td style="text-align: left;">æ’¤é”€</td></tr><tr class="odd"><td style="text-align: left;">[Ctrl]+r ã€.</td><td style="text-align: left;">é‡åš</td></tr></tbody></table><table><thead><tr class="header"><th style="text-align: left;">è¿›å…¥æ’å…¥æˆ–æ›¿æ¢çš„ç¼–è¾‘æ¨¡å¼</th><th style="text-align: left;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">i, I</td><td style="text-align: left;">iä¸ºä»ç›®å‰å…‰æ ‡æ‰€åœ¨çš„ä¸‹ä¸€ä¸ªå­—ç¬¦å¼€å§‹æ’å…¥ä¸ºæ‰€åœ¨ç›®å‰æ‰€åœ¨è¡Œç¬¬ä¸€ä¸ªéç©ºæ ¼å¤„æ’å…¥</td></tr><tr class="even"><td style="text-align: left;">a, A</td><td style="text-align: left;">aä¸ºä»ç›®å‰å…‰æ ‡æ‰€åœ¨çš„ä¸‹ä¸€ä¸ªå­—ç¬¦å¼€å§‹æ’å…¥Aä¸ºä»ç›®å‰å…‰æ ‡æ‰€åœ¨è¡Œçš„æœ€åä¸€ä¸ªå­—ç¬¦å¼€å§‹æ’å…¥</td></tr><tr class="odd"><td style="text-align: left;">o, O</td><td style="text-align: left;">oä¸ºåœ¨ç›®å‰å…‰æ ‡çš„ä¸‹ä¸€è¡Œæ’å…¥æ–°çš„ä¸€è¡ŒOä¸ºåœ¨ç›®å‰å…‰æ ‡çš„ä¸Šä¸€è¡Œæ’å…¥æ–°çš„ä¸€è¡Œ</td></tr><tr class="even"><td style="text-align: left;">r, R</td><td style="text-align: left;">råªä¼šæ›¿æ¢å…‰æ ‡æ‰€åœ¨çš„é‚£ä¸€ä¸ªå­—ç¬¦ä¸€æ¬¡ï¼›Rä¼šä¸€ç›´æ›¿æ¢å…‰æ ‡æ‰€åœ¨çš„é‚£ä¸ªæ–‡å­—,ç›´åˆ°æŒ‰ä¸‹[ESC]</td></tr></tbody></table><p><strong>å‘½ä»¤è¡Œçš„ä¿å­˜ã€ç¦»å¼€ç­‰å‘½ä»¤</strong> * :w ä¿å­˜ * :w! å¼ºåˆ¶ä¿å­˜ï¼Œä¸æ–‡ä»¶æƒé™æœ‰å…³ * :q ç¦»å¼€vi * :wq ä¿å­˜å¹¶ç¦»å¼€ï¼Œwq!ä¸ºå¼ºåˆ¶ä¿å­˜åç¦»å¼€ * :! command æš‚æ—¶ç¦»å¼€viåˆ°å‘½ä»¤è¡Œä¸‹æ‰§è¡Œcommandå‘½ä»¤ * :set nu æ˜¾ç¤ºè¡Œå· * :set nonu å–æ¶ˆæ˜¾ç¤ºè¡Œå·</p><h2><span id="paste-å°†å¤šä¸ªæ–‡ä»¶çš„åŒä¸€è¡Œè´´åœ¨ä¸€èµ·ä¸­é—´ç”¨tabéš”å¼€">paste -å°†å¤šä¸ªæ–‡ä»¶çš„åŒä¸€è¡Œè´´åœ¨ä¸€èµ·ï¼Œä¸­é—´ç”¨[tab]éš”å¼€</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>paste  [-d]  file1  file2</code> <em>å‚æ•°ï¼š</em> * -d : åé¢å¯ä»¥æ¥åˆ†éš”å­—ç¬¦ï¼Œé»˜è®¤æ˜¯ä»¥[tab]æ¥åˆ†éš”çš„ * - : å¦‚æœfileéƒ¨åˆ†å†™æˆ - ï¼Œè¡¨ç¤ºæ¥è‡ªstdinçš„æ•°æ®</p><h2><span id="passwd-è®¾ç½®ä¿®æ”¹å¯†ç ">passwd -è®¾ç½®/ä¿®æ”¹å¯†ç </span></h2><p><em>ç”¨æ³•ï¼š</em> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">passwd   [--stdin]  # æ‰€æœ‰äººå‡å¯ä½¿ç”¨æ¥æ”¹è‡ªå·±å¯†ç </span><br><span class="line">passwd   [-l] [-u] [--stdin] [-S] [-n æ—¥æ•°] [-x æ—¥æ•°] [-w æ—¥æ•°] [-i æ—¥æœŸ]   è´¦å·  # rootåŠŸèƒ½</span><br></pre></td></tr></table></figure></p><p><em>å‚æ•°ï¼š</em> * --stdin : å¯ä»¥æ¥è‡ªå‰ä¸€ä¸ªç®¡é“çš„æ•°æ®ï¼Œä½œä¸ºå¯†ç è¾“å…¥ï¼Œå¯¹shell scriptæœ‰å¸®åŠ© * -l : Lockï¼Œä¼šå°†/etc/shadowç¬¬äºŒåˆ—æœ€å‰é¢åŠ ä¸Šï¼ä½¿å¯†ç å¤±æ•ˆ * -u : ä¸-lç›¸å¯¹ï¼ŒUnlock * -S : åˆ—å‡ºå¯†ç ç›¸å…³å‚æ•°ï¼Œå³shadowæ–‡ä»¶å†…çš„å¤§éƒ¨åˆ†ä¿¡æ¯ * -n : åé¢æ¥å¤©æ•°ï¼Œshadowçš„ç¬¬4å­—æ®µï¼Œå¤šä¹…ä¸å¯ä¿®æ”¹å¯†ç çš„å¤©æ•° * -x : åé¢æ¥å¤©æ•°ï¼Œshadowçš„ç¬¬5å­—æ®µï¼Œå¤šä¹…å†…å¿…é¡»è¦æ”¹åŠ¨å¯†ç  * -w : åé¢æ¥å¤©æ•°ï¼Œshadowçš„ç¬¬6å­—æ®µï¼Œå¯†ç è¿‡æœŸå‰çš„è­¦å‘Šå¤©æ•° * -i : åé¢æ¥æ—¥æœŸï¼Œå¯†ç å¤±æ•ˆæ—¥æœŸ &gt;æ³¨ï¼š<strong>ç»™ä¸€èˆ¬è´¦å·æ–°å»ºå¯†ç éœ€è¦ä½¿ç”¨â€passwd è´¦å·â€œçš„æ ¼å¼ï¼Œä½¿ç”¨â€passwdâ€œè¡¨ç¤ºä¿®æ”¹è‡ªå·±çš„å¯†ç </strong></p><h2><span id="sudo-ä»¥å…¶ä»–ç”¨æˆ·èº«ä»½æ‰§è¡Œå‘½ä»¤">sudo - ä»¥å…¶ä»–ç”¨æˆ·èº«ä»½æ‰§è¡Œå‘½ä»¤</span></h2><p><em>ç”¨æ³•ï¼š</em> <code>sudo  [-b]  [-u  ç”¨æˆ·è´¦å·]</code> <em>å‚æ•°ï¼š</em> * -b : å°†åç»­çš„å‘½ä»¤è®©ç³»ç»Ÿè‡ªè¡Œæ‰§è¡Œï¼Œè€Œä¸ä¸ç›®å‰çš„shelläº§ç”Ÿå½±å“ * -u : åé¢æ¥æ¬²åˆ‡æ¢çš„ç”¨æˆ·ï¼Œè‹¥æ— æ­¤é¡¹åˆ™ä»£è¡¨åˆ‡æ¢èº«ä»½root &gt;æ³¨ï¼š * sudoçš„æ‰§è¡Œä»…éœ€è¦è‡ªå·±çš„å¯†ç å³å¯ * ä»…æœ‰/etc/sudoerså†…çš„ç”¨æˆ·æ‰èƒ½å¤Ÿæ‰§è¡Œsudoè¿™ä¸ªå‘½ä»¤</p>]]></content>
      
      
      <categories>
          
          <category> ç¬”è®° </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
