<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Elasticity and Its Application</title>
      <link href="/2019/02/22/Elasticity%20and%20Its%20Application/"/>
      <url>/2019/02/22/Elasticity%20and%20Its%20Application/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#the-elasticity-of-demand">The Elasticity of Demand</a><ul><li><a href="#the-price-elasticity-of-demand-and-its-determinants">The Price Elasticity of Demand and Its Determinants</a></li><li><a href="#computing-the-price-elasticity-of-demand">Computing the Price Elasticity of Demand</a></li><li><a href="#the-midpoint-method-a-better-way-to-calculate-percentage-changes-and-elasticities">The Midpoint Method: A Better Way To Calculate Percentage Changes and Elasticities</a></li><li><a href="#the-variety-of-demand-curves">The Variety of Demand Curves</a></li><li><a href="#total-revenue-and-the-price-elasticity-of-demand">Total Revenue and The Price Elasticity of Demand</a></li><li><a href="#elasticity-and-total-revenue-along-a-linear-demand-curve">Elasticity and Total Revenue Along A Linear Demand Curve</a></li><li><a href="#other-demand-elasticities">Other Demand Elasticities</a></li></ul></li><li><a href="#the-elasticity-of-supply">The Elasticity Of Supply</a><ul><li><a href="#the-price-elasticity-of-supply-and-its-determinants">The Price Elasticity of Supply And Its Determinants</a></li><li><a href="#computing-the-price-elasticity-of-supply">Computing The Price Elasticity of Supply</a></li><li><a href="#the-vary-of-supply-curves">The Vary Of Supply Curves</a></li></ul></li><li><a href="#three-applications-of-supply-demand-and-elasticity">Three Applications Of Supply, Demand, And Elasticity</a><ul><li><a href="#can-good-news-for-farming-be-bad-news-for-farmers">Can Good News For Farming Be Bad News For Farmers</a></li><li><a href="#why-did-opec-fail-to-keep-the-price-of-oil-high">Why Did OPEC Fail To Keep The Price Of Oil High?</a></li><li><a href="#does-drug-interdiction-increase-or-decrease-drug-related-crime">Does Drug Interdiction Increase Or Decrease Drug-Related Crime?</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="the-elasticity-of-demand">The Elasticity of Demand</span></h2><p>To measure how much consumers respond to changes in economic variables, economists use the concept of <strong>elasticity</strong>. Elasticity is a measure of the responsiveness of quantity demanded or quantity supplied to one of its determinants.</p><h3><span id="the-price-elasticity-of-demand-and-its-determinants">The Price Elasticity of Demand and Its Determinants</span></h3><p>The <strong>price elasticity of demand</strong> measures how much the quantity demanded responds to a change in price. Demand for a good is said to be <em>elastic</em> if the quantity demanded responds substantially to changes in the price. Demand is said to be <em>inelastic</em> if the quantity demanded responds only slightly to changes in the price.</p><p>Based on experience, however, we can state some general rules about what determines the price elasticity of demand.</p><ul><li>Availablity of Close Substitutes</li><li>Necessities versus Luxuries</li><li>Definition of the Market</li><li>Time Horizon</li></ul><h3><span id="computing-the-price-elasticity-of-demand">Computing the Price Elasticity of Demand</span></h3><p><strong>Price elasticity of demand</strong> = Percentage change in quantity demanded / Percentage change in price</p><p>For example, suppose that a 10 percent increase in the price of an ice-cream cone causes the amount of ie cream you buy to fall by 20 percent. We calculate your elasticity of demand as</p><p>Price elasticity of demand = 20 percent / 10 percent = 2.</p><p>In this example, the elasticity is 2, reflecting that the change in the quantity demanded is proportionately twice as large as the change in the price. <em>A larger price elasticity implies a greater responsiveness of quantity demanded to price.</em></p><h3><span id="the-midpoint-method-a-better-way-to-calculate-percentage-changes-and-elasticities">The Midpoint Method: A Better Way To Calculate Percentage Changes and Elasticities</span></h3><p>The elasticity from point A to point B seems different from the elasticity from point B to point A. This difference arises because the percentage changes are calculated from a different base.</p><p>One way to avoid this problem is to use the <strong>midpoint method</strong> for calculating elasticities. The midpoint method computes a percentage change by dividing the midpoint of the initial and final levels. The following formula expresses the midpoint method for calculating the price elasticity of demand between two points, denoted (Q1, P1) and (Q2, P2):</p><p><img src="/images/elastic/DraggedImage.jpg"></p><h3><span id="the-variety-of-demand-curves">The Variety of Demand Curves</span></h3><p>Demand is considered <strong>elastic</strong> when the elasticity is greater than 1. Demand is considered <strong>inelastic</strong> when the elasticity is less than 1. Because the price elasticity of demand measures how much quantity demanded responds to changes in the price, it is closely related to the slope of the demand curve. The <strong>flatter</strong> the demand curve that passes through a given point, the <strong>greater</strong> the price elasticity of demand. The <strong>steeper</strong> the demand curve that passes through a given point, the <strong>smaller</strong> the price elasticity of demand. Figure 1 shows five cases.</p><p><img src="/images/elastic/DraggedImage-1.jpg"></p><h3><span id="total-revenue-and-the-price-elasticity-of-demand">Total Revenue and The Price Elasticity of Demand</span></h3><p><strong>Toal revenue</strong> is the amount paid by buyers and received by sellers of the good. In any market, total revenue is P * Q, the price of the good times the quantity of the good sold. We can show total revenue graphically, as in Figure 2.</p><p><img src="/images/elastic/DraggedImage-2.jpg"></p><p>How does total revenue change as one moves along the demand curve? There are some examples in Figure 3.</p><p><img src="/images/elastic/DraggedImage-3.jpg"></p><p>Although the examples in this figure are extreme, they illustrate some general rules:</p><ul><li>When demand is <strong>inelastic</strong>, price and total revenue move in the <strong>same direction</strong>.</li><li>When demand is <strong>elastic</strong>, price and total revenue move in <strong>opposite directions</strong>.</li><li>If demand is <strong>unit elastic</strong> (a price elasticity exactly equal to 1), total revenue <strong>remains constant</strong> when the price changes.</li></ul><h3><span id="elasticity-and-total-revenue-along-a-linear-demand-curve">Elasticity and Total Revenue Along A Linear Demand Curve</span></h3><p><img src="/images/elastic/DraggedImage-4.jpg"></p><p>Even though the slope of a linear demand curve is constant, the elasticity is not. This is true because the slope is the ratio of <em>changes</em> in the two variables, whereas the elasticity is the ratio of <em>percentage changes</em> in the two variables. At points with a low price and high quantity, the demand curve is inelastic. At points with a high price and low quantity, the demand curve is elastic.</p><p>The linear demand curve illustrates that the price elasticity of demand need not be the same at all points on a demand curve. A constant elasticity is possible, but it is not always the case.</p><h3><span id="other-demand-elasticities">Other Demand Elasticities</span></h3><p><strong>The Income Elasticity of Demand</strong> measures how the quantity demanded changes as consumer income changes.</p><p><img src="/images/elastic/DraggedImage-5.jpg"></p><p>Most of goods are <em>normal goods</em>: Higher income raises the quantity demanded, which have positive income elasticities. A few goods, such as bus rides, are <em>inferior goods</em>: Higher income lowers the quantity demanded, which have negative income elasticities.</p><p><strong>The Cross-Price Elasticity of Demand</strong> measures how the quantity demanded of one good responds to a change in the price of another good.</p><p><img src="/images/elastic/DraggedImage-6.jpg"></p><p>Substitutes are goods that are typically used in place of one another, whose cross-price elasticity is positive. Conversely, complements are goods that are typically used together, whose cross-price elasticity is negative.</p><h2><span id="the-elasticity-of-supply">The Elasticity Of Supply</span></h2><h3><span id="the-price-elasticity-of-supply-and-its-determinants">The Price Elasticity of Supply And Its Determinants</span></h3><p>The <strong>price elasticity of supply</strong> measures how much the quantity supplied responds to changes in the price. Supply of a good is said to be <em>elastic</em> if the quantity supplied responds substantially to changes in the price.</p><p>In most markets, a key determinant of the price elasticity of supply is the <strong>time period</strong> being considered. Supply is usually <em>more elastic in the long run</em> than in the short run.</p><h3><span id="computing-the-price-elasticity-of-supply">Computing The Price Elasticity of Supply</span></h3><p>Economists compute the price elasticity of supply as the percentage change in the quantity supplied divided by the percentage change in the price. That is, <img src="/images/elastic/DraggedImage-7.jpg"></p><h3><span id="the-vary-of-supply-curves">The Vary Of Supply Curves</span></h3><p><img src="/images/elastic/DraggedImage-8.jpg"></p><p><img src="/images/elastic/DraggedImage-9.jpg"></p><h2><span id="three-applications-of-supply-demand-and-elasticity">Three Applications Of Supply, Demand, And Elasticity</span></h2><h3><span id="can-good-news-for-farming-be-bad-news-for-farmers">Can Good News For Farming Be Bad News For Farmers</span></h3><p>The raise of production provided by new farming technology could make farmers worse off. Because the new technic increase the amount of wheat that can be produced on each acre of land, farmers are willing to supply more wheat at any price. In other words, <strong>the supply curve shift to the right</strong> and the demand curve still remain the same, which cause the price of wheat falls.</p><p><img src="/images/elastic/DraggedImage-10.jpg"></p><p>Wheat being an <strong>inelastic good</strong>, the price of wheat falls doesn’t make people buy a lot more wheat. So a decrease in price causes farmers’ total revenue to fall.</p><p>You may wonder why farmers would adopt the new technology. The answer goes to the heart of <strong>how competitive markets work</strong>. Because each farmer is only a small part of the market for wheat, it’s better to use the new technic to produce and sell more wheat at any given price. Yet when all farmers do this, the supply of wheat increases, the price falls, and farmers are worse off.</p><p>It is important to keep in mind that what is good for farmers is not necessarily good for society as a whole. Improvement in farm technology can be bad for farmers because it makes farmers increasingly unnecessary, but it is surely good for consumers who pay less for food.</p><h3><span id="why-did-opec-fail-to-keep-the-price-of-oil-high">Why Did OPEC Fail To Keep The Price Of Oil High?</span></h3><p>The OPEC episode of 1970s and 1980s shows how supply and demand can behave differently in the short run and in the long run. <strong>In the short run</strong>, both the supply and demand for oil are <strong>inelastic</strong>. Supply is inelastic because the quantity of known oil reserves and the capacity for oil extraction cannot be changed quickly. Demand is inelastic because buying habits do not respond immediately to changes in price. Thus, as panel (a) of Figure 8 shows, <em>the short-run supply and demand curves are steep</em>.</p><p><img src="/images/elastic/DraggedImage-11.jpg"></p><p>The situation is very different in the long run. Over long periods of time, producers of oil outside OPEC respond to high prices by increasing oil exploration. Consumers respond with greater conservation. Thus, as panel (b) of Figure 8 shows, <em>the long-run supply and demand curves are more elastic</em>.</p><h3><span id="does-drug-interdiction-increase-or-decrease-drug-related-crime">Does Drug Interdiction Increase Or Decrease Drug-Related Crime?</span></h3><p><img src="/images/elastic/DraggedImage-12.jpg"></p><p>Suppose the government increase the number of federal agents devoted to the war on drugs. When the government stops some drugs from entering the country and arrests more smugglers, it raises the cost of selling drugs and, therefore, reduces the quantity of drugs supplied at any given price. But the <em>demand for drugs is not changed</em>, as panel (a) of Figure 9 shows.</p><p>But in terms of drug-related crime, since the demand for drugs is inelastic, then an increase in price raises total revenue in the drug market. Addicts who already had to steal to support their habits would have an even greater need for quick cash. Thus, <strong>drug interdiction could increase drug-related crime</strong>.</p><p>Rather than trying to reduce the supply of drugs, policymakers might try to reduce the demand by pursuing a policy of <strong>drug education</strong>. Successful drug education has the effects shown in panel (b) of Figure 9. Thus, in contrast to drug interdiction, <strong>drug education can reduce both drug use and drug-related crime</strong>.</p><p>However, the demand for drugs is probably inelastic over short periods, it may be more elastic elastic over longer periods because higher prices would discourage experimentation with drugs among the young and, over time, lead to fewer drug addicts. In this case, <strong>drug interdiction would increase drug-related crime in the short run while decreasing it in the long run</strong>.</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微观经济型原理 </tag>
            
            <tag> elasticity </tag>
            
            <tag> economic </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>The Market Forces of Supply and Demand</title>
      <link href="/2019/02/11/The%20Market%20Forces%20of%20Supply%20and%20Demand/"/>
      <url>/2019/02/11/The%20Market%20Forces%20of%20Supply%20and%20Demand/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#markets-and-competition">Markets and Competition</a><ul><li><a href="#what-is-a-market">What Is A Market?</a></li><li><a href="#what-is-competition">What is Competition?</a></li></ul></li><li><a href="#demand">Demand</a><ul><li><a href="#the-demand-curve-the-relationship-between-price-and-quantity-demand">The Demand Curve: The Relationship Between Price and Quantity Demand</a></li><li><a href="#market-demand-vs-individual-demand">Market Demand VS. Individual Demand</a></li><li><a href="#shifts-in-the-demand-curve">Shifts In  the Demand Curve</a></li></ul></li><li><a href="#supply">Supply</a><ul><li><a href="#the-supply-curve-the-relationship-between-price-and-quantity-supplied">The Supply Curve: The Relationship Between Price and Quantity Supplied</a></li><li><a href="#market-supply-vs-individual-supply">Market Supply VS. Individual Supply</a></li><li><a href="#shifts-in-the-supply-curve">Shifts In The Supply Curve</a></li></ul></li><li><a href="#supply-and-demand-together">Supply And Demand Together</a><ul><li><a href="#equilibrium">Equilibrium</a></li><li><a href="#three-steps-to-analyzing-changes-in-equilibrium">Three Steps To Analyzing Changes In Equilibrium</a></li></ul></li><li><a href="#conclusion-how-prices-allocate-resources">Conclusion: How prices Allocate Resources</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="markets-and-competition">Markets and Competition</span></h2><h3><span id="what-is-a-market">What Is A Market?</span></h3><p>A <strong>market</strong> is a group of buyers and sellers of a particular good or service. Buyers decide the demand for the product while sellers decide the supply of the product.</p><h3><span id="what-is-competition">What is Competition?</span></h3><p>Economists use the term <strong>competitive market</strong> to describe a market in which there are so many buyers and so many sellers that each has a negligible impact on the market price.</p><p>Competition has various degrees, from <strong>perfectly competitive</strong> to <strong>monopoly</strong>. </p><p><em>Perfectly competitive</em> requires two characteristics:</p><ol><li>the goods offered for sale are all exactly the same</li><li>the buyers and sellers are so numerous that no single buyer or seller has any influence over the market price.</li></ol><p>However, some marketplace has only one seller, such a seller is called a <em>monopoly</em>.</p><h2><span id="demand">Demand</span></h2><p>We begin our study of markets by examining the behavior of buyers. To focus our thinking, let’s keep in mind a particular good — ice cream.</p><h3><span id="the-demand-curve-the-relationship-between-price-and-quantity-demand">The Demand Curve: The Relationship Between Price and Quantity Demand</span></h3><p>The <strong>quantity demanded</strong> of any good is the amount of the good that buyers are willing and able to purchase. The relationship of price and quantity demanded follows the <strong>law of demand</strong>: Other things equal, when the price of a good rises, the quantity demanded of the good falls, and when the price falls, the quantity demanded rises. A table that shows the relationship between the price of a good and the quantity demanded is called <strong>demand schedule</strong>.</p><p><img src="/images/IMG_BD7E38AD92C1-1.jpg" alt=""></p><p>The graph in Figure 1 uses the numbers from the table to illustrate the law of demand. By convention, the quantity of ice cream demanded is on the horizontal axis. The downward-sloping line relating price and quantity demanded is called the <strong>demand curve</strong>.</p><h3><span id="market-demand-vs-individual-demand">Market Demand VS. Individual Demand</span></h3><p>Figure 1 shows the individual demand of ice-cream. However, most of the time, we want to focus on the <strong>market demand</strong> which is the sum of all individual’s demands.</p><p><img src="/images/market/DraggedImage.jpg" alt=""></p><p>Figure 2 shows the Catherine’s demand, Nicholas’s demand as well as the market demand. At each price, the total quantity demand is the sum of Catherine’s quantity demand and Nicholas’s quantity demand. The market demand curve shows how the total quantity demanded of a good varies as the price of the good varies, while all the other factors are held constant.</p><h3><span id="shifts-in-the-demand-curve">Shifts In  the Demand Curve</span></h3><p><img src="/images/market/DraggedImage-1.jpg" alt=""></p><p>Figure 3 illustrates shifts in the demand. There are many variables that can shift the demand curve. Here are the most important.</p><p><strong>Income</strong> If the demand for a good falls when income falls, the good is called a <strong>normal good</strong>. If the demand for a good rises when income falls, the good is called an <strong>inferior good</strong>, such as bus rides. As your income falls, you are less likely to buy a car or take a cab and more likely to ride a bus.</p><p><strong>Prices of Related Goods</strong> When a fall in the price of one good reduces the demand for another good, the two goods are called <strong>substitutes</strong>, such as ice cream and frozen yogurt, hot dogs and hamburgers. When a fall in the price of one good raises the demand for another good, the two goods are called <strong>complements</strong>, such as gasoline and automobiles, computers and software.</p><p><strong>Tastes</strong> If you like ice cream, you buy more of it. Economists examine what happens when tastes change.</p><p><strong>Expectations</strong> Your expectations about the future may affect your demand for a good or service today.</p><p><strong>Number of Buyers</strong> Market demand depends on the number of buyers.</p><p><strong>Summary</strong><br><img src="/images/market/DraggedImage-2.jpg" alt=""></p><h2><span id="supply">Supply</span></h2><p>We now turn to the other side of the market and examine the behavior of sellers. Once again, to focus our thinking, let’s consider the market for ice cream.</p><h3><span id="the-supply-curve-the-relationship-between-price-and-quantity-supplied">The Supply Curve: The Relationship Between Price and Quantity Supplied</span></h3><p><strong>Quantity supplied</strong> is the amount of a good that sellers are willing and able to sell. When other things equal, the quantity supplied of a good rises when the price of the good rises, which is called <strong>the law of supply</strong>.</p><p><strong>Supply schedule</strong> is a table that shows the relationship between the price of a good and the quantity supplied. The curve relating price and quantity supplied is called the <strong>supply curve</strong>.</p><p><img src="/images/market/DraggedImage-3.jpg" alt=""></p><h3><span id="market-supply-vs-individual-supply">Market Supply VS. Individual Supply</span></h3><p>Just as market demand is the sum of the demands of all buyers, market supply is the sum of the supplies of all sellers. As with demand curves, we sum the individual supply curves <em>horizontally</em> to obtain the market supply curves.<br><img src="/images/market/DraggedImage-4.jpg" alt=""></p><h3><span id="shifts-in-the-supply-curve">Shifts In The Supply Curve</span></h3><p><img src="/images/market/DraggedImage-5.jpg" alt=""></p><p>Figure 7 illustrate shifts in the supply curve. There are many variables that can shift the supply curve. Here are some of the most important.</p><p><strong>Input Prices</strong> When the price of one or more inputs rises, producing the good is less profitable, and firms supply less the good.</p><p><strong>Technology</strong> By reducing firms’ costs, the advanced technology raised the supply of goods.</p><p><strong>Expectations</strong> The amount of good a firm supplies today may depend on its expectations about the future.</p><p><strong>Number of Sellers</strong> In addition to the preceding factors, which influence the behavior of individual sellers, market supply depends on the number of these sellers.</p><p><strong>Summary</strong></p><p><img src="/images/market/DraggedImage-6.jpg" alt=""></p><h2><span id="supply-and-demand-together">Supply And Demand Together</span></h2><h3><span id="equilibrium">Equilibrium</span></h3><p>Figure 8 shows the market supply curve and market demand together. The intersection point is called <strong>equilibrium</strong>. Equilibrium is a situation in which the market price has reached the level at which quantity supplied equals quantity demanded. The price that balances quantity supplied and quantity demanded is called <strong>equilibrium</strong>.</p><p><img src="/images/market/DraggedImage-7.jpg" alt=""></p><p>At the equilibrium price, the quantity of the good that buyers are willing and able to buy exactly balances the quantity that sellers are willing and able to sell. The actions of buyers and sellers <strong>naturally move markets toward the equilibrium</strong> of supply and demand. </p><p><strong>Law of supply and demand</strong>: The price of any good adjusts to bring the quantity supplied and the quantity demanded for that good into balance.</p><p><img src="/images/market/DraggedImage-8.jpg" alt=""></p><h3><span id="three-steps-to-analyzing-changes-in-equilibrium">Three Steps To Analyzing Changes In Equilibrium</span></h3><ol><li>Decide whether the event shifts the supply or demand curve (or perhaps both).</li><li>Decide in which direction the curve shifts.</li><li>Use the supply-and-demand diagram to see how the shift changes the equilibrium price and quantity.</li></ol><p>Example 1:</p><p><img src="IMG_A9BD8FC2E549-1.jpeg" alt=""></p><p>In the ice-cream example, <strong>supply</strong> (which <em>refers to the position of the supply curve</em>) does not change because the weather does not alter firms’ desire to sell at any given price. Instead, the hot weather alters consumers’ desire to buy at any given price and thereby shifts the demand curve to the right. The increase in demand causes the equilibrium price to rise. When the price rises, the <strong>quantity supplied</strong> rises. This increase in quantity supplied is represented by the <strong>movement along the supply curve</strong>.</p><p>Example 2: Shifts in Both Supply and Demand</p><p><img src="/images/market/DraggedImage-9.jpg" alt=""></p><p><strong>Summary</strong></p><p><img src="/images/market/DraggedImage-10.jpg" alt=""></p><h2><span id="conclusion-how-prices-allocate-resources">Conclusion: How prices Allocate Resources</span></h2><p>Consider the allocation of beachfront land. Because the amount of this land is limited, not everyone can enjoy the luxury of living by the beach. Who gets this resource? The answer is whoever is <strong>willing and able to pay the price</strong>. The price of beachfront land adjusts until the quantity of land demanded exactly balances the quantity supplied. Thus, in market economies, <strong>prices are the mechanism for rationing scarce resources</strong>.</p><p>Similarly, prices determine who produces each good and how much is produced. If an invisible hand guides market economies, as Adam Smith famously suggested, then the price system is the baton that the invisible hand uses to conduct the economic orchestra.</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微观经济型原理 </tag>
            
            <tag> Supply Curve </tag>
            
            <tag> Demand Curve </tag>
            
            <tag> Equilibrium </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Vehicles</title>
      <link href="/2018/12/09/RS%20-%20Recognizing%20Vehicles/"/>
      <url>/2018/12/09/RS%20-%20Recognizing%20Vehicles/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 6. 识别系统复习笔记。</p><p>Vehicle recognition, including detection, tracking and identification, has been a research topic among automotive manufacturers, suppliers and universities for enhancing road safety.</p><p>For example, the <a href="http://www.argo.ce.unipr.it/ARGO/english/index.html" target="_blank" rel="noopener">ARGO</a> project, started in 1996 at the University of Parma and the University of Pavia, Italy, is aimed at developing a system for improving road safety by controlling and supervising the driver activity.</p><a id="more"></a><!-- toc --><ul><li><a href="#lane-detection">Lane Detection</a><ul><li><a href="#canny-edge-detector">Canny edge detector</a></li></ul></li><li><a href="#vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</a></li><li><a href="#visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</a></li><li><a href="#application-examples">Application Examples</a></li></ul><!-- tocstop --><h2><span id="lane-detection">Lane Detection</span></h2><p>For vehicle detection and tracking and intelligent transportation systems, lane marking detection is one of the key steps. Lane markings can be detected based on the camera inverse perspective mapping (IPM) and the assumption that the lane markings are represented by almost vertical bright lines of constant width, surrounded by a darker background.</p><p>The lanes can then be detected by using the camera <strong>inverse perspective mapping (IPM)</strong> and the <strong>Canny edge detector</strong>.</p><p><strong>Inverse perspective mapping</strong></p><p><img src="/images/impres.png"></p><p><img src="/images/ipmreason.png"></p><h3><span id="canny-edge-detector">Canny edge detector</span></h3><p><a href="http://en.wikipedia.org/wiki/Canny_edge_detector" target="_blank" rel="noopener">Canny edge detector</a> is one of the most popular detectors of edge pixels. The edge detection process serves to simplify the analysis of images by drastically <strong>reducing the amount of data to be processed</strong>, while at the same time <strong>preserving useful structural information</strong> about object boundaries.</p><p>There are three common criteria relevant to edge detector performance.</p><ul><li>It is important that edges that occur in the image should not be missed and that there be <em>no spurious responses</em>.</li><li>The edge points should be well localized. That is, the distance between the points marked by the detector and the true edge center should be minimized.</li><li>The last requirement is to circumvent the possibility of multiple responses to a single edge.</li></ul><p><img src="/images/cedbalala.jpg"></p><p>In the figure above, (a) is a noisy step edge; (b) is a difference of boxes operator; (c) is the output of filtering by box operator; (d) is the first derivative of Gaussian operator; and (e) is the first derivative of Gaussian applied to the edge.</p><p><img src="/images/cannysd.png"></p><p>The <strong>edge center</strong> is marked as <strong>red circle</strong> at a local maximum in the output of the filter responses. Within the region of the edge, the boxes operator exhibits more local maxima than the Gaussian operator. Therefore, <strong>the Gaussian operator is better</strong> than the boxes operator in this example.</p><p><strong>The three performance criteria</strong></p><ol type="1"><li><p>Good detection → Detection Criterion</p><p>There should be a low probability of failing to mark real edge points, and low probability of falsely marking non-edge points. This is controlled by signal-to-noise ratio: <span class="math display">\[\text{SNR}=\frac{|\int_{-w}^{+w}G(-x)f(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f(x)^2dx}}\]</span></p></li><li><p>Good localization → Localization Criterion</p><p>The points marked as edge points by the operator should be as close as possible to the true edge center. The localization is defined as the reciprocal of <span class="math inline">\(\delta x_0\)</span>: <span class="math display">\[\text{Localization}=\frac{|\int_{-w}^{+w}G(-x)f&#39;(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f&#39;(x)^2dx}}\]</span></p></li><li><p>Only one response to a single edge → Multiple Response Constraint <span class="math display">\[x_{zc}(f)=\pi\left(\frac{\int_{-\infty}^{+\infty}f&#39;(x)^2dx}{\int_{-\infty}^{+\infty}f&#39;&#39;(x)^2dx}\right)^{1/2}\]</span></p></li></ol><p>It is very difficult to find the function <span class="math inline">\(f\)</span> (filter) which maximizes the detection and localization criteria subject to the multiple response constraint. Numerical optimization is therefore used.</p><p>The solution is of the form <span class="math display">\[f(x)=a_1e^{\alpha x}\sin\omega x+a_2e^{\alpha x}\cos\omega x+a_3e^{-\alpha x}\sin\omega x\\+a_4e^{-\alpha x}\cos\omega x+c\]</span> The variables are determined by the non-linear optimization with boundary conditions.</p><p>The numerically estimated optimal edge detector can be approximated by the <strong>first derivative of a Gaussian</strong> G, where <span class="math display">\[G(x)=\exp(-\frac{x^2}{2\sigma^2})\\f(x)=G&#39;(x)=-\frac{x}{\sigma^2}\exp(-\frac{x^2}{2\sigma^2})\]</span> For 2D, the solution proposed by Canny amounts to convolving the initial image with a Gaussian function followed by computation of the derivatives in <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> of the result.</p><p><img src="/images/firstderofgaus.png"></p><p>There are three main steps in the Canny edge detection</p><ol type="1"><li><p>Gradient calculation</p><p>compute <span class="math inline">\(M\)</span>: <span class="math display">\[I_x=\frac{\partial}{\partial x}(I\ast G(x,y))\\I_y=\frac{\partial}{\partial y}(I\ast G(x,y))\\M=\sqrt{I_x^2+I_y^2}\approx |I_x|+|I_y|\]</span></p></li><li><p>Non-maximum suppression</p><p>keep local maximum, set others to zero.</p></li><li><p>Hysteresis thresholding</p><p><img src="/images/hyposisthres.png"></p></li></ol><h2><span id="vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</span></h2><p>Vehicle detection is based on the assumption that the rear or frontal views of the vehicles are generally symmetric; can be characterized by a rectangular bounding box which satisfies specific aspect ratio constraints and is placed in a specific region of the image, e.g., within lanes.</p><p>These features are used to identify vehicles in the image.</p><ol type="1"><li>Area of interest is identified on the basis of road position and perspective constraints.</li><li>This area of interest is searched for possible vertical symmetries. Not only are the gray level symmetries considered, but also vertical and horizontal edge symmetries are considered.</li><li>Step 3: Once the symmetry axis has been detected, the lower part (the two bottom corners) of a rectangular bounding box is detected.</li><li>The top horizontal limit of the vehicle is then searched according to the pre-defined aspect ratio.</li></ol><p><img src="/images/vdbasedonsys.png"></p><p>Vertical and horizontal binary edges can help solve the problems of strong reflection areas in the vehicle images. The analysis of symmetry produces symmetry maps for gray-level intensity, edge (total), horizontal edge, vertical edge and total (combined) symmetry. The symmetry axis can be found from the total symmetry map.</p><p><strong>Bounding box detection</strong></p><p>After detecting the symmetry axis, the width of the symmetrical region is checked for the presence of two corners representing the bottom of the bounding box around the vehicle.</p><p>Once the two corners are detected, the top side of the rectangle box can be detected by searching.</p><p><img src="/images/boundingboxde.png"></p><h2><span id="visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</span></h2><p><strong>Visual saliency</strong> refers to the idea that certain parts of a scene are pre-attentively distinctive (pop-out) and create some form of immediate significant visual arousal within the early stages of the <strong>Human Visual System (HVS)</strong>. The figure below is an example.</p><p>In image analysis, an <strong>edge</strong> is a pop-out region (<strong>region of saliency</strong>) since the edge is more visually significant than the other parts of the image.</p><p><img src="/images/vsexamples.png"></p><p>The salient points are literally the points on the object which are almost unique. These points maximize the discrimination between objects. The visual saliency is defined in terms of <strong>local signal complexity</strong>.</p><p><strong>Shannon entropy</strong> of local attributes (called <strong>local entropy</strong>) is <span class="math display">\[H_{D,Rx}(x)=-\sum_{i\in D}P_{D,Rx}(x,d_i)\log_2P_{D,Rx}(x,d_i)\]</span> where <span class="math inline">\(x\)</span> is point location, <span class="math inline">\(Rx\)</span> is local neighborhood at <span class="math inline">\(x\)</span>, <span class="math inline">\(D\)</span> is descriptor (e.g. intensity), and <span class="math inline">\(P_{D,Rx}(x,d_i)\)</span> is histogram value at <span class="math inline">\(x\)</span>.</p><p><img src="/images/entropylsakdjad.jpg"></p><p>Below are sample frames from the processed sequences using a <strong>fixed scale</strong> based on local entropy. Red square boxes represent the most salient icons or parts of the image. The size of the local window or scale and threshold used were selected manually to give the most satisfactory results.</p><p><img src="/images/saliegsdas.png"></p><ul><li>Problem: the scale is fixed and global. For example, the scale is inappropriate for the pedestrians and the road markings in DT sequence.</li><li>Problem: Small salient regions are not picked up. Highly textured regions, e.g., large intensity variation regions, are picked up. For example, trees and bushes in Vicky sequence.</li></ul><p>Therefore, scale is an important and implicit part of the saliency detection problem.</p><p><strong>Scale selection for salient region detection</strong></p><p>Scale is selected based on the scale-space behavior of the saliency of a given feature.</p><p>For each pixel position <span class="math inline">\(x\)</span></p><ul><li><p>For each scale <span class="math inline">\(s\)</span> inside a range between <span class="math inline">\(s_\min\)</span> and <span class="math inline">\(s_\max\)</span> :</p><ul><li><p>Measure the local descriptor values (e.g.,intensity values) within a window of scale <span class="math inline">\(s\)</span>.</p></li><li><p>Estimate the local probability density function (PDF) from this (e.g. using histogram).</p></li><li><p>Calculate the local entropy <span class="math inline">\(H_D\)</span> <span class="math display">\[H_{D}(s,x)=-\sum_{i\in D}P_{D}(s,x,d_i)\log_2P_{D}(s,x,d_i)\]</span></p></li></ul></li><li><p>Select scales for which the entropy is peaked <span class="math display">\[s:\frac{\partial^2H_D(s,x)}{\partial s^2}&lt;0\]</span></p></li><li><p>Detection performance can be further improved if change of histogram is considered.</p></li></ul><p><img src="/images/salenscaleg.png"></p><p><strong>Vehicle Detection by using AdaBoost</strong></p><p>Vehicles can be detected by using <a href="https://www.52coding.com.cn/2018/12/06/RS%20-%20Recognizing%20Faces/#adaboost">AdaBoost</a>.</p><p><img src="/images/vehildabboo.png"></p><p>By using the AdaBoost, vehicles in their lateral view can be detected in real time.</p><p><strong>Vehicle Recognition</strong></p><p>After vehicle detection, the vehicle can be recognition by using PCA and classification methods, e.g., k-NN or Bayesian methods.</p><h2><span id="application-examples">Application Examples</span></h2><p><strong>Vehicle counting in traffic surveillance</strong></p><p><img src="/images/survelleg.png"></p><p><strong>Traffic jam detection and alarming</strong></p><p><img src="/images/trafficjamsdeg.png"></p><p><strong>Abnormal vehicle behavior detection</strong></p><p><img src="/images/abnormaldetec.png"></p><p><strong>Target tracking in night</strong></p><p><img src="/images/targetrackinni.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Canny </tag>
            
            <tag> visual saliency </tag>
            
            <tag> lane detection </tag>
            
            <tag> vehicle detection </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing License Plates</title>
      <link href="/2018/12/08/RS%20-%20Recognizing%20License%20Plates/"/>
      <url>/2018/12/08/RS%20-%20Recognizing%20License%20Plates/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 5. 识别系统复习笔记。</p><p><a href="http://www.licenseplaterecognition.com/" target="_blank" rel="noopener">License Plate Recognition</a> is an image-processing technology which is used to identify vehicles by their license plates. This technology is used in various security and traffic applications, such as the access-control system, toll payment, parking fee payment, etc.</p><a id="more"></a><p>A number of license plate recognition units are installed in different locations and the passing vehicle plate numbers are matched between the points. The average speed and travel time between these points can be calculated and presented in order to monitor traffic loads. Additionally, the average speed may be used to issue a speeding ticket.</p><!-- toc --><ul><li><a href="#automatic-vehicle-identification-system">Automatic Vehicle Identification System</a></li><li><a href="#license-plate-detection">License Plate Detection</a><ul><li><a href="#global-search">Global Search</a></li><li><a href="#partial-image-analysis">Partial Image Analysis</a></li><li><a href="#sliding-concentric-windows">Sliding Concentric Windows</a></li><li><a href="#adaboost">Adaboost</a></li></ul></li><li><a href="#character-segmentation">Character Segmentation</a></li><li><a href="#character-recognition">Character Recognition</a></li></ul><!-- tocstop --><h2><span id="automatic-vehicle-identification-system">Automatic Vehicle Identification System</span></h2><p>The installation and responses of sensors help to frame a front-view/rear-view of a passing vehicle. <strong>Infra-red sensors</strong> are used for vehicle sensing.</p><p><img src="/images/infredsens.png"></p><p><strong>Anisotropic magneto-resistive (AMR) sensors</strong> for automated vehicle sensing.</p><p><img src="/images/amrsense.png"></p><p><strong>License plate recognition</strong> is generally composed of three steps.</p><ol type="1"><li>Location of the license plate region (License Plate Detection)</li><li>Segmentation of the plate characters (Character Segmentation)</li><li>Recognition of the plate characters (Character Recognition)</li></ol><p>The license plate recognition should operate fast enough to make sure that the system does not miss a single object of interest that moves through the scene.</p><p>With the growth of the computer processing power, the latest developments operate within less than 50ms for plate detection and recognition. It enables the processing of more than 20 frames per second for videos.</p><h2><span id="license-plate-detection">License Plate Detection</span></h2><p>There are several methods for detecting license plate in a vehicle image.</p><ul><li>Global search [Comelli-TVT-95$]$</li><li>Partial image analysis (vertical edge density)[Anagnostopoulos-TITS-08$]$</li><li>Sliding concentric windows [Anagnostopoulos-TITS-06$]$</li><li>AdaBoost [Dlagnekov-04$]$</li></ul><h3><span id="global-search">Global Search</span></h3><p>Comelli et al. presented a system called RITA. RITA can recognize automatically the characters written on the license plate placed on the rear-side of motor vehicles. The goal is to read only the Italian license plates and reject all the others. It is assumed that a Italian license plate is rectangular and the plate contains black characters over a white background.</p><p>The license plate detection algorithm is a <strong>global searching</strong> method because the algorithm picks within the vehicle image globally the area presenting the maximum local contrast based on <strong>gradient analysis</strong>. The picked area possibly corresponds to the rectangle that contains the license plate.</p><p>The algorithm selects the area that presents the <strong>maximum local contrast</strong> that (possibly) corresponds to the rectangle that contains the license plate.</p><p><img src="/images/globalsearch.png"></p><h3><span id="partial-image-analysis">Partial Image Analysis</span></h3><p>The vehicle image can be filtered to extract <strong>vertical edges</strong> and scanned with N-row distance. The number of the existing edges along each scan line is recorded.</p><p>If the number of the edges is greater than a threshold value, the presence of a plate can be assumed.</p><p><img src="/images/piasdsa.png"></p><p>Specifically, if the plate is not found in the first scanning processing, then the algorithm is repeated, reducing the threshold for counting edges or adjusting the threshold for finding vertical edges.</p><h3><span id="sliding-concentric-windows">Sliding Concentric Windows</span></h3><p>An adaptive image segmentation technique, called <strong>sliding concentric windows</strong> (SCW), was proposed for license plate detection. The SCW method was developed to describe the local irregularity in the vehicle image.</p><p>The method uses image statistics such as the standard deviation and the mean for finding possible plate locations.</p><p><img src="/images/slidingwc.png"></p><p>In two concentric windows A and B of different sizes (<span class="math inline">\(2X_1\times 2Y_1\)</span> and <span class="math inline">\(2X_2\times2Y_2\)</span> respectively), which scan the vehicle image from left to right and from top to bottom, the mean or the standard deviation is calculated.</p><p>If the ratio of the statistical measurements in the two windows exceeds a threshold set by the user, then the central pixel of the concentric windows is considered to belong to a license plate. <span class="math display">\[I_{output}=\begin{cases}0 &amp; \text{if }\frac{M_B}{M_A}\leq T,\\1 &amp; \text{if }\frac{M_B}{M_A}&gt; T\end{cases}\]</span> where <span class="math inline">\(M\)</span> is the statistical measurement, eigher mean or standard devation.</p><p>The result is a binary image <span class="math inline">\(I_{output}\)</span>, which eliminates all the redundant regions from the original vehicle image.</p><p>The result binary image is used as a <strong>mask for highlighting the license plate</strong> by computing the product between the binary mask and the input vehicle image. The license plate can then be found in the highlighted image based on the binary mask.</p><p><img src="/images/scwimg.png"></p><h3><span id="adaboost">Adaboost</span></h3><p>Adaptive boosting (AdaBoost) was used in conjunction with the rectangle features for training a strong classifier based on weak classifiers.</p><p>For detecting license plates, a total of 100 rectangle features can be applied to sub-regions sized 45(columns) × 15(rows) pixels being scanned as the expected license plate areas in the original vehicle image.</p><p><img src="/images/recpladaboo.png"></p><p>Within the 100 rectangle features for detection, there are 37 variance based features, 40 x-derivative features, 18 y-derivative features, and 5 mean pixel intensity features.</p><p><img src="/images/plrecoadaboo.png"></p><p>When sliding the search window across the vehicle image to be analyzed, several matches can be found. Clustering method can be used to group detected windows that are close to each other and <strong>use the mean window as the detected location</strong>.</p><h2><span id="character-segmentation">Character Segmentation</span></h2><p>In most systems with a subsequent recognition module, the vertical resolution of the plate vary from 20 to 40 pixels. Prior to character recognition, the detected license plates are enhanced for <strong>improving plate image quality</strong>, e.g., image normalization and histogram equalization.</p><p><img src="/images/characseg.png"></p><p>Given the enhanced detected license plate image, the goal is to <strong>segment each character</strong> in the image. A global threshold can be found to segment the detected license plate. <a href="http://en.wikipedia.org/wiki/Otsu&#39;s_method" target="_blank" rel="noopener">Otsu's method</a> is one of widely used methods for image binarization.</p><p><strong>Otsu's method</strong></p><p>The method is designed for finding optimum global threshold for image binarization and is optimum in the sense that it maximizes the between-class variance.</p><p>There are six steps.</p><ol type="1"><li><p>Compute the normalized histogram of the input image. Denote the components of histogram by <span class="math display">\[p_i=\frac{n_i}{MN}, i=0, 1, ..., L-1\]</span> where <span class="math inline">\(L\)</span> is the number of gray levels; <span class="math inline">\(n_i\)</span> is the number of pixels with intensity <span class="math inline">\(i\)</span>; <span class="math inline">\(M\)</span> is the number of rows; and <span class="math inline">\(N\)</span> is the number of columns.</p></li><li><p>Compute the cumulative sums (the probability that a pixel is assigned to class <span class="math inline">\(C_1\)</span>) <span class="math display">\[P_1(k)=\sum_{i=0}^kp_i\]</span> where <span class="math inline">\(k\)</span> is current threshold for thresholding the input image into two classes <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>.</p></li><li><p>Compute the cumulative means <span class="math display">\[m(k)=\sum_{i=0}^kip_i,\ k=0,1,...,L-1\]</span></p></li><li><p>Compute the global intensity mean <span class="math display">\[m_G=\sum_{i=0}^{L-1}ip_i\]</span> where <span class="math inline">\(L\)</span> is the number of gray levels.</p></li><li><p>Compute the between-class variance <span class="math display">\[\sigma^2_B(k)=\frac{[m_GP_1(k)-m(k)]^2}{P_1(k)[1-P_1(k)]},\ k=0, 1, ..., L-1\]</span></p></li><li><p>Obtain the Otsu threshold, <span class="math inline">\(k^\ast\)</span>, as the value for <span class="math inline">\(k\)</span> for which the value of <strong>between-class variance is maximum</strong>. If the maximum is not unique, obtain <span class="math inline">\(k^\ast\)</span> by averaging the values of <span class="math inline">\(k\)</span> corresponding to the various maxima detected. <span class="math display">\[\sigma^2_B(k^\ast)=\max_{0\leq k\leq L-2}\sigma^2_B(k)\]</span></p></li></ol><p><img src="/images/otsuresukt.png"></p><p>Global thresholding on the entire image may not always produce useful results due to uneven lighting environment.</p><p><img src="/images/charseg.png"></p><p>Characters can be extracted from the license plate image. Each character can then be segmented by using the thresholding method. Instead of dividing the image into regular blocks, the shape (size) of each block is defined adaptively for each character.</p><p><img src="/images/characsegggg.png"></p><p>Projections of binary edge images are performed. Rows of strings are separated based on the horizontal pixel accumulation. Same for columns of characters.</p><p>After the blocks for characters are defined adaptively, the Otsu's method is applied for each blocks adaptively.</p><p><strong>Maximally stable extremal regions</strong></p><p>Characters can be extracted and segmented by thresholding the image with a variable brightness threshold, and using the enumeration of extremal regions which are stable for a large range of the threshold <span class="math inline">\(T\)</span>.</p><p>Extremal regions are connected components of an image binarized at certain threshold. When the threshold <span class="math inline">\(T\)</span> is increasing/decreasing, the behavior of the extremal regions is used for character classification and segmentation.</p><p><a href="http://en.wikipedia.org/wiki/Maximally_stable_extremal_regions" target="_blank" rel="noopener">Maximally stable extremal regions (MSERs)</a> are usually of arbitrary shape. The MSER detector is stable and invariant to affine transformations, which is useful for handling viewpoint changes.</p><p><img src="/images/msersss.png"></p><p><img src="/images/mseralgo.png"></p><p><img src="/images/mserrrr.png"></p><p><img src="/images/mserapp.png"></p><h2><span id="character-recognition">Character Recognition</span></h2><p>After the characters are segmented, the segmented characters will be matched against a set of pre-defined characters, e.g. ten numerals (zero to nine), alphabets, etc.</p><p>The pre-defined characters usually have single font, fixed character size, and are not rotated heavily. Therefore, pattern/template matching is a suitable technique for character recognition. Templates can be generated in advance for the matching tasks.</p><p><img src="/images/charrecogpatt.png"></p><p>The matching process can be done by computing the <strong>normalized cross-correlation</strong> values for all the translational shifts of each character template over the character block (sub-image).</p><p>The normalized cross-correlation is defined as <span class="math display">\[C_{fg}=\frac{\sum_{m=1}^M\sum_{n=1}^N(f(i,j)-\bar{f})(g(i,j)-\bar{g})}{\sqrt{\sum_{m=1}^M\sum_{n=1}^N(f(i,j)-\bar{f})^2(g(i,j)-\bar{g})^2}}\]</span> where <span class="math inline">\(g\)</span> is shifted template and <span class="math inline">\(f\)</span> is character block.</p><p>More advanced techniques, e.g. <a href="http://en.wikipedia.org/wiki/Shape_context" target="_blank" rel="noopener">shape context</a>, can be used for character recognition. ([Belongie-02, Treiber-10])</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Adaboost </tag>
            
            <tag> Otsu </tag>
            
            <tag> MSER </tag>
            
            <tag> sliding concentric windows </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Fingerprints</title>
      <link href="/2018/12/07/RS%20-%20Recognizing%20Fingerprints/"/>
      <url>/2018/12/07/RS%20-%20Recognizing%20Fingerprints/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 4. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#fingerprint-image-acquisition-systems">Fingerprint image acquisition systems</a></li><li><a href="#minutiae">Minutiae</a></li><li><a href="#fingerprint-enhancement">Fingerprint Enhancement</a><ul><li><a href="#normalization">Normalization</a></li><li><a href="#orientation-image-estimation">Orientation Image Estimation</a></li><li><a href="#ridge-frequency-estimation">Ridge Frequency Estimation</a></li><li><a href="#region-mask-estimation">Region mask estimation</a></li><li><a href="#gabor-filter">Gabor Filter*</a></li></ul></li><li><a href="#fingerprint-matching">Fingerprint Matching</a></li><li><a href="#fingercode">FingerCode</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="fingerprint-image-acquisition-systems">Fingerprint image acquisition systems</span></h2><p><a href="http://en.wikipedia.org/wiki/Fingerprint" target="_blank" rel="noopener">Fingerprint</a> matching (recognition) is the most popular biometric technique used in automatic personal identification. The main reason for the popularity of fingerprints as a form of identification is that the fingerprint of a person is unique and remains invariant with his or her age.</p><p>There are three kinds of sensing devices typically: <strong>optical sensors</strong>, <strong>solid-state sensors</strong> and <strong>ultrasound sensors</strong>.</p><p><strong>Optical sensors</strong></p><p>The finger touches the top side of a glass prism. The left side of the prism is illustrated through a diffused light. The light entering the prism is reflected at the valleys, and absorbed at the ridges. The lack of reflection allows the ridges to be discriminated from the valleys. The light rays exit from the right side of the prism and are focused through a lens onto an image sensor.</p><p><img src="/images/ridgeandvall.png"></p><p><strong>Solid-state sensors</strong></p><p>All silicon-based sensors consist of an array of pixels, each pixel being a tiny sensor itself. The user directly touches the surface of the silicon. The physical information is converted into <strong>electrical signals</strong> by using the capacitive sensor (other kinds of sensor can also be used, e.g., thermal, electric field and piezoelectric).</p><p>The capacitive sensor is a 2D array of micro-capacitor plates embedded in a chip. The other plate of each micro-capacitor is the finger skin itself.</p><p><img src="/images/ssdfinger.png"></p><p>Small electrical charges are created between the surface of the finger and each of the silicon plates when a finger is placed on the chip. The magnitude of these electrical charges depends on the distance between the fingerprint surface and the capacitance plates.</p><p><strong>Ultrasound sensors</strong></p><p>An ultrasound sensor is based on sending acoustic signals toward the fingertip and capturing the echo signal. The echo signal is used to compute the range image of the fingerprint and, subsequently, the ridge structure itself.</p><p><img src="/images/ultrasound.png"></p><h2><span id="minutiae">Minutiae</span></h2><p>An <strong>automatic fingerprint identification system</strong> (AFIS) consists of various processing stages.</p><p><img src="/images/afis.png"></p><p>In AFIS, the high-level structural features (<strong>ridges and valleys</strong>) are extracted from the fingerprint image for the purpose of representation and matching. The ridges and valleys in a fingerprint alternate, flowing in a local constant direction.</p><p><img src="/images/ridandval.png"></p><p>The ridges (or the valleys) exhibit anomalies of various kinds, such as ridge bifurcations, ridge endings, short ridges, and ridge crossovers. These features are called <a href="http://en.wikipedia.org/wiki/Minutiae" target="_blank" rel="noopener">minutiae</a>.</p><p>In a good quality rolled fingerprint image, there are about 70 to 80 minutia points and in a latent fingerprint the number of minutiae is much less (approximately 20 to 30 minutia points). Commercially available fingerprint identification systems typically use <strong>ridge bifurcations</strong> and <strong>ridge endings</strong> as features.</p><p><img src="/images/bifandending.png"></p><ul><li>A ridge ending is defined as the point where a ridge ends abruptly.</li><li>A ridge bifurcation is defined as the point where a ridge diverges into branch ridges.</li></ul><p>A critical step in fingerprint matching is to automatically and reliably <strong>extract minutiae</strong> from the input fingerprint images, which is a difficult task.</p><p><img src="/images/bifandend2.png"></p><h2><span id="fingerprint-enhancement">Fingerprint Enhancement</span></h2><p>Fingerprint images can be of very poor quality. An enhancement algorithm which can improve the clarity of the ridge structure is therefore necessary.</p><p>The flowchart of the fingerprint enhancement algorithm is shown below.</p><p><img src="/images/imgnorflow.png"></p><h3><span id="normalization">Normalization</span></h3><p>A gray-level fingerprint image <span class="math inline">\(I\)</span> is defined as an <span class="math inline">\(N \times N\)</span> matrix. At the <span class="math inline">\(i\)</span> th row and <span class="math inline">\(j\)</span> th column, the intensity of the pixel is <span class="math inline">\(I(i, j)\)</span>. It is assumed that the fingerprint images are scanned at a resolution of 500 dots per inch (dpi), which is the resolution recommended by FBI.</p><p>The mean and variance of a gray-level fingerprint image are defined as</p><p><img src="/images/imgnorma.png"></p><p>An input fingerprint image is normalized so that it has a pre-specified mean <span class="math inline">\(M_0\)</span> and variance <span class="math inline">\(\text{VAR}_0\)</span>.</p><p>The normalized image <span class="math inline">\(G(i,j)\)</span> is defined as <span class="math display">\[G(i,j)=\begin{cases}M_0+\sqrt{\frac{VAR_0(I(i,j)-M)^2}{VAR}} &amp;\text{if }I(i,j)&gt;M\\M_0-\sqrt{\frac{VAR_0(I(i,j)-M)^2}{VAR}}&amp;\text{otherwise}\\\end{cases}\]</span> <img src="/images/imgnor2.png"></p><h3><span id="orientation-image-estimation">Orientation Image Estimation</span></h3><p>The orientation image (field) is estimated from the normalized input fingerprint image. By viewing a fingerprint image as an oriented image, a <strong>least-mean-square orientation estimation</strong> algorithm is used to estimate the local orientation.</p><p>The main steps are as follows.</p><p>[1] Divide the normalized image <span class="math inline">\(G\)</span> into blocks of size <span class="math inline">\(w \times w\)</span>.</p><p>[2] For each block, compute the gradients <span class="math inline">\(I_x\)</span> and <span class="math inline">\(I_y\)</span> at each pixel <span class="math inline">\((i , j)\)</span>.</p><p>[3] Estimate the local orientation of each block centered at pixel <span class="math inline">\((i, j)\)</span> using the following equations. <span class="math display">\[\theta(i,j)=90^o+\frac{1}{2}\text{atan2}\left(\frac{V_1(i,j)}{V_2(i,j)}\right)\]</span> where <span class="math display">\[V_1(i,j)=\sum_{u=i-\frac{w}2}^{i+\frac{w}2}\sum_{v=j-\frac{w}2}^{j+\frac{w}2}2I_x(u,v)I_y(i,v)\\V_2(i,j)=\sum_{u=i-\frac{w}2}^{i+\frac{w}2}\sum_{v=j-\frac{w}2}^{j+\frac{w}2}(I_x(u,v)^2-I_y(u,v)^2)\\-180^o≤\text{atan2}(x)≤180^o\]</span> [4] Due to the presence of noise, corrupted ridge and valley structures, minutiae, etc. in the input image, the estimated local ridge orientation may not always be correct. The local orientation image can be smoothed by using the low-pass smoothing filter and the concept of continuous vector field.</p><p><img src="/images/orienesti.png"></p><h3><span id="ridge-frequency-estimation">Ridge Frequency Estimation</span></h3><p>The gray levels along ridges and valleys can be modeled as a sinusoidal-shaped wave along a direction normal to the local ridge orientation.</p><p><img src="/images/ridgefreq.jpg"></p><p>Let <span class="math inline">\(G\)</span> be the normalized image and <span class="math inline">\(O\)</span> be the orientation image (field). For estimating the ridge frequency <span class="math inline">\(Ω\)</span> image,</p><ul><li><p>Step 1: divide <span class="math inline">\(G\)</span> into blocks of size <span class="math inline">\(w \times w\)</span>.</p></li><li><p>Step 2: for each block centered at pixel <span class="math inline">\((i, j)\)</span>, compute an oriented window of size <span class="math inline">\(w \times l\)</span> that is defined in the ridge coordinate system <span class="math inline">\((k, d)\)</span>. <img src="/images/ridgesys.png"></p></li><li><p>Step 3: for each block centered at pixel <span class="math inline">\((i, j)\)</span>, compute the x-signature, <span class="math inline">\(X[0], X[1], ..., X[l-1]\)</span>, of the ridges and valleys within the oriented window, where <span class="math display">\[X[k]=\frac{1}w\sum_{d=0}^{w-1}G(u,v)\\u=i+(d-\frac{w}2)\cos O(i,j)+(k+\frac{l}2)\sin O(i,j)\\v=i+(d-\frac{w}2)\sin O(i,j)+(\frac{l}2-k)\cos O(i,j)\]</span> <img src="/images/w2blabla.png"> <img src="/images/orientationdsa.png"></p></li></ul><p>The x-signature forms a discrete sinusoidal-shape wave, which has the same frequency as that of the ridges and valleys in the oriented window. Therefore, the <strong>frequency of ridges and valleys can be estimated from the x-signature</strong>.</p><p>Let <span class="math inline">\(T(i, j)\)</span> be the average number of pixels between two consecutive peaks in the x-signature, then the ridge frequency <span class="math inline">\(Ω(i, j)\)</span> is computed as <span class="math display">\[\Omega(i,j)=\frac{1}{T(i,j)}\]</span></p><h3><span id="region-mask-estimation">Region mask estimation</span></h3><p>A pixel (or a block) in an input fingerprint image can be either in a recoverable region or an unrecoverable region. Classification of pixels into recoverable and unrecoverable categories can be performed based on the assessment of the shape of the wave formed by the local ridges and valleys.</p><p><img src="/images/imgmaskest.png"></p><p>Three features are used to characterize the sinusoidal-shaped wave: amplitude, frequency, and variance.</p><p><img src="/images/imgmaskest2.png"></p><p>Typical fingerprint images where both recoverable and unrecoverable regions were manually labeled can be selected for region mask estimation. The above three features can be computed for each image.</p><p>Using the k-NN and clustering algorithms, each <span class="math inline">\(w \times w\)</span> block in an input fingerprint image can be classified into a recoverable or an unrecoverable block.</p><h3><span id="gabor-filter">Gabor Filter*</span></h3><p>The configurations of parallel ridges and valleys with well-defined frequency and orientation in a fingerprint image provide useful information which helps in removing undesired noise.</p><p>A special (bandpass) filter, namely <strong>Gabor filter</strong>, that is tuned to the corresponding frequency and orientation can efficiently remove the undesired noise and preserve the true ridge and valley structures.</p><p>Gabor filters have both frequency-selective and orientation-selective properties and are used for removing noise and preserving true ridge or valley structures.</p><p>The even-symmetric Gabor filter has the following general form:</p><p><img src="/images/gaborfilter.png"></p><p>The frequency of the filter <span class="math inline">\(f\)</span> is completely determined by the local ridge frequency and the Gabor filter orientation is determined by the local ridge orientation.</p><p><img src="/images/gabororien.png"></p><p>The ridge pixels are assigned a value '1' (white) and the remaining pixels are assigned a value '0' (black) in the resulting binary ridge image.</p><p><img src="/images/imgseg.png"></p><p>Once the ridges are located, <strong>directional smoothing</strong> is applied to smooth the ridges. A 3×7 mask is placed along the orientation field for each window. The mask containing all '1's enables us to count the number of '1's in the mask area.If the count of '1's is more than 25% of the total number of pixels, the ridge point is retained.</p><p><strong>Extracting minutiae</strong></p><p>Locating minutia points in the thinned image is relatively easy.</p><p>A count of the number of 'on' neighbors at a point of interest in a <span class="math inline">\(3\times 3\)</span> window is sufficient for this purpose.</p><ul><li>A ridge end point has only neighbor in the window.</li><li>A ridge bifurcation has at least three neighbors.</li></ul><p>Some post-processing can be performed to further improve detection quality.</p><p><img src="/images/endandbif3.jpg"></p><p><img src="/images/minuextra.png"></p><h2><span id="fingerprint-matching">Fingerprint Matching</span></h2><p>Matching a query fingerprint and a database fingerprint is equivalent to matching their minutia sets. Each database fingerprint minutia, <span class="math inline">\(p\)</span>, is examined to determine whether there is a corresponding query fingerprint minutia, <span class="math inline">\(q\)</span>.</p><p>There are three steps.</p><ol type="1"><li>Registration</li><li>Minutia paring</li><li>Matching score computation</li></ol><p><strong>Registration via Hough Transform</strong></p><p>The input to the registration algorithm consists of two sets of minutia points <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span>. <span class="math inline">\(|P|\)</span> and <span class="math inline">\(|Q|\)</span> represent the sizes of point sets <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> respectively. <span class="math display">\[P=\{(p_x^1,p_y^1,\alpha^1),...,(p_x^{|P|},p_y^{|P|},\alpha^{|P|})\}\\Q=\{(q_x^1,q_y^1,\beta^1),...,(q_x^{|Q|},q_y^{|Q|},\beta^{|Q|})\}\]</span> Each minutia has three components: x-coordinate, y-coordinate and orientation of the minutia. Each minutia in <span class="math inline">\(P\)</span> is <strong>rotated, scaled and translated</strong> for matching against a minutia in <span class="math inline">\(Q\)</span>.</p><p>The usual <strong>Hough transform</strong> for line detection can be generalized for point matching.</p><p><img src="/images/regishoughtra.png"></p><p>The transform has maximum value of <span class="math inline">\(A\)</span> means that it can match as much points as possible.</p><p><img src="/images/imgregriscomp.png"></p><p><strong>Minutia pairing and score computation</strong></p><p>After minutia registration, the minutiae need to be paired. Two minutiae are said to be paired or matched if their components <span class="math inline">\((x, y,θ)\)</span> are equal with some tolerance after registration.</p><p><img src="/images/minutiamatch.png"></p><p>The matching algorithm is based on finding the number of paired minutiae between each database fingerprint and the query fingerprint.</p><p>In order to reduce the amount of computation, the matching algorithm takes into account only those minutiae that fall within a common bounding box. The common bounding box is the intersection of the bounding box for query and reference (database) fingerprints. Once the count of matching minutiae is obtained, a matching score is computed. The matching score is used for deciding the degree of match. Finally, a set of top ten scoring reference fingerprints is obtained as a result of matching.</p><h2><span id="fingercode">FingerCode</span></h2><p><em>FingerCode</em> is a new representation for the fingerprints which yields a <strong>relatively short, fixed length code</strong> suitable for matching as well as storage on a smartcard.</p><p>The matching reduces to finding the <strong>Euclidean distance</strong> between these <em>FingerCodes</em> and hence the matching is very fast and the representation is amenable to indexing.</p><p>The FingerCode partitions the region of interest of the given fingerprint image with respect to a reference point. A feature vector is composed of an ordered enumeration of features extracted from the information contained in each sector specified by the tessellation.</p><p><img src="/images/fingercode1.png"></p><p>The feature elements capture the local information by using the <strong>Gabor filterbank</strong>. The ordered enumeration of the tessellation captures the <strong>invariant global relationships</strong> among the local patterns.</p><p>These features capture both the global pattern of ridges and valleys and the local characteristics. Matching is based on the Euclidean distance between the FingerCodes.</p><p>There are four steps for extracting the FingerCode.</p><ol type="1"><li>Determining the reference point for the fingerprint image.</li><li>Partitioning the region around the reference point.</li><li>Filtering the region of interest in eight different directions using a bank of Gabor filters.</li><li>Computing the <strong>average absolute deviation</strong> (AAD) from the mean of gray values in individual sectors in filtered images to define the <em>FingerCode</em> (the feature vector) for matching.</li></ol><p><strong>Determining the reference point</strong></p><p><img src="/images/fingercode2.png"></p><p>Given an input fingerprint image, there are seven steps for finding the reference point.</p><ol type="1"><li><p>Estimate the orientation field <span class="math inline">\(O\)</span> using a window size of <span class="math inline">\(w\times w\)</span>.</p></li><li><p>Smooth the orientation field.</p></li><li><p>Compute the sine component <span class="math inline">\(E\)</span> of the orientation field <span class="math inline">\(O\)</span>.<br><span class="math display">\[E(i,j)=\sin O(i,j)\]</span></p></li><li><p>Initialize <span class="math inline">\(A\)</span>, a label image used to indicate the reference point.</p></li><li><p>For each pixel <span class="math inline">\(E(i, j)\)</span>, integrate pixel intensities in regions <span class="math inline">\(R_I\)</span> and <span class="math inline">\(R_{II}\)</span>, and assign the corresponding pixels in <span class="math inline">\(A\)</span> according to the value of their difference. <span class="math display">\[A(i,j)=\sum_{R_I}E(i,j)-\sum_{R_{II}}E(i,j)\]</span> <img src="/images/fingercode4.png"></p></li><li><p>Find the maximum value in <span class="math inline">\(A\)</span> and assign its coordinate to the reference point.</p></li><li><p>Repeat steps 1-6 by using a window size <span class="math inline">\(w&#39;\times w&#39;\)</span>, where <span class="math inline">\(w&#39; &lt; w\)</span>, and restrict the search for the reference point in step 6 in a local neighborhood of the detected reference point.</p></li></ol><p>The geometry of regions <span class="math inline">\(R_I\)</span> and <span class="math inline">\(R_{II}\)</span> is designed to capture the maximum curvature in concave ridges.</p><p><img src="/images/fingercode3.png"></p><p><strong>Partitioning the region around the reference point</strong></p><p>Given the detected reference point, the input fingerprint image is partitioned into 80 sectors.</p><p><img src="/images/fingercode5.png"></p><p><strong>Filtering the region of interest</strong></p><p>A minutia point can be viewed as an anomaly in locally parallel ridges and it is the information that is captured by using the Gabor filters.</p><p>Before filtering the fingerprint image, <strong>image normalization</strong> is performed separately for each sector with <span class="math inline">\(M_0\)</span> and <span class="math inline">\(VAR_0\)</span>.</p><p>An even symmetric Gabor filter is given <a href="#gabor-filter*">the Gabor filer setction</a>. The filter frequency <span class="math inline">\(f\)</span> can be set to the average ridge frequency. The average ridge frequency is the reciprocal of the average inter-ridge distance, which is around 10 pixels in a 500 dpi fingerprint image. Eight different values (<span class="math inline">\(0^o\)</span>, <span class="math inline">\(22.5^o\)</span>, <span class="math inline">\(45^o\)</span>, <span class="math inline">\(67.5^o\)</span>, <span class="math inline">\(90^o\)</span>, <span class="math inline">\(112.5^o\)</span>, <span class="math inline">\(135^o\)</span> and <span class="math inline">\(157.5^o\)</span>) are used for the direction θ with respect to the x-axis.</p><p>A fingerprint convolved with a <span class="math inline">\(0^o\)</span>-oriented filter accentuates those ridges which are parallel to the x-axis and smoothes the ridges in the other directions. These eight directional-sensitive filters capture <strong>most of the global ridge directionality information</strong> as well as the <strong>local ridge characteristics</strong> present in a fingerprint.</p><p><img src="/images/fingercode6.png"></p><p><strong>Compute AAD</strong></p><p>Let <span class="math inline">\(F_{iθ}(x, y)\)</span> be the θ-direction filtered image for sector <span class="math inline">\(S_i\)</span>. The feature value <span class="math inline">\(V_{iθ}\)</span> is the average absolute deviation (AAD) from the mean which is defined as <span class="math display">\[V_{i\theta}=\frac{1}{n_i}\sum_{(x,y)\in S_i}|F_{i\theta}(x,y)-P_{i\theta}|\]</span> where <span class="math inline">\(P_{i\theta}=\frac{1}{n_i}\sum_{(x,y)\in S_i}F_{i\theta}(x,y)\)</span>; <span class="math inline">\(n_i\)</span> is the number of pixels in <span class="math inline">\(S_i\)</span>.</p><p><img src="/images/fingercode7.png"></p><p>The average absolute deviation of each sector in each of the eight filtered images defines the components of the feature vector. Fingerprint matching is based on finding the <strong>Euclidean distance</strong> between the corresponding <em>FingerCodes</em>.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> fingerprints </tag>
            
            <tag> fingercode </tag>
            
            <tag> hough transform </tag>
            
            <tag> minutiae </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Faces</title>
      <link href="/2018/12/06/RS%20-%20Recognizing%20Faces/"/>
      <url>/2018/12/06/RS%20-%20Recognizing%20Faces/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 3. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#histogram-equalization">Histogram Equalization</a></li><li><a href="#image-pyramid-and-neural-networks">Image Pyramid and Neural Networks</a></li><li><a href="#integral-image">Integral Image</a></li><li><a href="#adaboost">Adaboost</a></li><li><a href="#face-recognition-pca">Face Recognition (PCA)</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="histogram-equalization">Histogram Equalization</span></h2><p><a href="http://en.wikipedia.org/wiki/Face_detection" target="_blank" rel="noopener">Face detection</a> is the first step in automated face recognition. Its reliability has a major influence on the performance and usability of the entire face recognition system.</p><p>Due to lighting or shadow, intensity can vary significantly in an image. Normalization of pixel intensity helps correct variations in imaging parameters in cameras as well as changes in illumination conditions. One widely used technique is <a href="http://en.wikipedia.org/wiki/Histogram_equalization" target="_blank" rel="noopener">histogram equalization</a>, which is based on image histogram. It helps reduce extreme illumination.</p><p><strong>Image histogram</strong></p><p>It is assumed that there is a digital image with <span class="math inline">\(L\)</span> gray levels <span class="math inline">\(r_k\)</span>. The probability of occurrence of gray level <span class="math inline">\(r_k\)</span> is given by <span class="math display">\[p_r(r_k)=\frac{n_k}{N}\]</span> where <span class="math inline">\(n_k\)</span> is number of pixels with gray level <span class="math inline">\(r_k\)</span>; <span class="math inline">\(N\)</span> is total number of pixels in an image; <span class="math inline">\(k = 0,1,2,...,L-1\)</span>.</p><p><img src="/images/imagehis.png"></p><p>We want an image with equally many pixels at every gray level, or the output intensity approx follows <strong>uniform distribution</strong>.</p><p>That is, a flat histogram, where each gray level, <span class="math inline">\(r_k\)</span>, appears equal number of times, i.e., <span class="math inline">\(N/L\)</span> times.</p><p><img src="/images/imgequ.png"></p><p>Assume that variable <span class="math inline">\(r\)</span> has been normalized between <span class="math inline">\([0,1]\)</span>. The intensity transformation is <span class="math inline">\(s = T(r)\)</span>, such that</p><ul><li><span class="math inline">\(T(r)\)</span> is single-valued and non-decreasing in the interval <span class="math inline">\(0≤r≤1\)</span>.</li><li><span class="math inline">\(0≤T(r)≤1\)</span> for <span class="math inline">\(0≤r≤1\)</span>.</li></ul><p><strong>Histogram equalization transform</strong></p><p>The intensity transformation is the cumulative distribution function (CDF) of <span class="math inline">\(r\)</span>, which is represented by <span class="math display">\[s=T(r)=\int_0^rp_r(w)dw\]</span> The discrete implementation is given by <span class="math display">\[s_k=T(r_k)=\sum_{j=0}^k\frac{n_j}{N}=\sum_{j=0}^kp_r(r_j)\]</span> where <span class="math inline">\(s_k\)</span> is the <strong>output intensity</strong>; <span class="math inline">\(r_k\)</span> is the input intensity; <span class="math inline">\(n_j\)</span> is the number of pixels with gray level <span class="math inline">\(r_j\)</span>.</p><p>Below are some examples:</p><p><img src="/images/hisequeg.png"></p><p><img src="/images/hisequeg2.png"></p><p>Histogram equalization can significantly improve image appearance</p><ul><li>Automatic</li><li>User doesn’t have to perform windowing</li></ul><p>Nice pre-processing step before face detection</p><ul><li>Account for different lighting conditions</li><li>Account for different camera/device properties</li></ul><p>There are two methods for <strong>face detection</strong>:</p><ol type="1"><li>Method using image pyramid and neural networks [Rowley-Baluja-Kanade-98]</li><li>Method using integral image and AdaBoost learning [Viola-Jones-04]</li></ol><h2><span id="image-pyramid-and-neural-networks">Image Pyramid and Neural Networks</span></h2><p>With the neural networks, a classifier may be trained directly using preprocessed and normalized face and nonface training subwindows.</p><p><a href="http://www.cs.cmu.edu/~har/" target="_blank" rel="noopener">Rowley et al</a> use the preprocessed 20x20 subwindows as the input to a neural network. The final decision is made to classify the 20x20 subwindow into face and nonface. The architecture is shown below.</p><p><img src="/images/facepy.png"></p><p>Instead of upright, frontal faces, a <strong>router network</strong> can be trained to process each input window so that orientation can be estimated. Once the orientation is estimated, the input window can be prepared for detector neural network.</p><p><img src="/images/router.png"></p><p><strong>Rowley et al.</strong> proposed two neural networks, as presented in the previous slides. The first one is the router network which is trained to estimate the orientation of an assumed face in the 20x20 sub-window. The second one is the normal frontal, upright face detector. However, it only handles <strong>in-plane rotation</strong>.</p><p><strong>Huang et al.</strong> proposed a multi-view face tree structure for handling both in-plane and <strong>out-of-plane rotations</strong>. Every node corresponds to a strong classifier.</p><p><img src="/images/hung.png"></p><h2><span id="integral-image">Integral Image</span></h2><p><strong>Method using integral image and AdaBoost learning</strong></p><p>The <a href="http://en.wikipedia.org/wiki/Summed_area_table" target="_blank" rel="noopener">integral image</a> <span class="math inline">\(ii(x, y)\)</span> at location <span class="math inline">\((x, y)\)</span> contains the <strong>sum of the pixel intensity values above and to the left</strong> of the location <span class="math inline">\((x, y)\)</span>, inclusive.</p><p>The <span class="math inline">\(ii\)</span> is defined as <span class="math display">\[ii(x,y)=\sum_{x&#39;≤x,y&#39;≤y}i(x&#39;,y&#39;)\]</span> where <span class="math inline">\(ii(x,y)\)</span> is the integral image and <span class="math inline">\(i(x,y)\)</span> is the original input image.</p><p><img src="/images/integralimg.png"></p><p>Using the following pair of recurrences: <span class="math display">\[s(x, y)=s(x, y-1)+i(x,y)\\ii(x,y)=ii(x-1, y)+s(x,y)\]</span> where <span class="math inline">\(s(x,y)\)</span> is the cumulative row sum, <span class="math inline">\(s(x, -1) = 0\)</span>, and <span class="math inline">\(ii(-1, y)=0\)</span>, the integral image can be computed in one pass over the original image.</p><p>Using the integral image, any rectangular sum can be computed in four array references.</p><p><img src="/images/inteeg.png"></p><p><strong>Rectangle features</strong></p><p>The features for face detection are Haar-like functions. There are three kinds of features.</p><p>[1] Two-rectangle feature: The difference between the sum of the pixels within two rectangular regions.</p><p><img src="/images/recfea1.png"></p><p>[2] Three-rectangle feature: The feature is the sum within two outside rectangles subtracted from the sum in a center rectangle.</p><p><img src="/images/recfea2.png"></p><p>[3] Four-rectangle feature: The difference between diagonal pairs of rectangles.</p><p><img src="/images/recfea3.png"></p><p>The rectangle features are sensitive to the presence of edges, bars/lines, and other simple image structures in different scales and at different locations.</p><p>Given that the base resolution of the detector is 24 x 24 pixels, the exhaustive set of rectangle features is quite large, 160,000.</p><p>Given a feature set and a training set of positive and negative images, a classification function must be learned to classify a pattern into either face or non-face.</p><h2><span id="adaboost">Adaboost</span></h2><p>In this work, the classifier is designed based on the assumption that a very small number of features can be combined to form an effective classifier.</p><p>The <a href="http://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">AdaBoost</a> learning algorithm is used to boost the classification performance of a simple learning algorithm. The simple learning algorithm is applied to all rectangle features.</p><p>It does this by <strong>combining a collection of weak classification functions</strong> (weak classifiers with relatively high classification error) to form a stronger classifier. The final strong classifier takes the form of <strong>a weighted combination of weak classifiers followed by a threshold</strong>.</p><p>Weak classifier <span class="math inline">\(h_t\)</span> (each classifier compute one rectangle feature): <span class="math display">\[h_t(\vec{x})=\begin{cases}1\ \text{if }\vec{x}\text{ represents a face image }(f_t(\vec{x})&gt;\text{Threshold})\\-1\ \text{otherwise}\end{cases}\\f_t(\vec{x})=\sum_{white} x-\sum_{black} x\]</span> The strong classifier is <span class="math display">\[H(\vec{x})=\text{sgn}\left(\sum_{t=1}^T\alpha_th_t(\vec{x})\right)\]</span> where <span class="math inline">\(\alpha_t\)</span> is weight; and <span class="math inline">\(\text{sgn}(x)\)</span> is sign function: <span class="math display">\[\text{sgn}(x)=\begin{cases} -1,  &amp; \mbox{if }x≤0 \\1, &amp; \mbox{if }x&gt;0\end{cases}\]</span> <strong>Algorithm</strong></p><p>Given example images and classifications <span class="math inline">\((\vec{x}_i, y_i), i = 1, 2,..., N\)</span>, where <span class="math inline">\(N\)</span> is the total number of images.</p><p>Start with equal weights on each image <span class="math inline">\(\vec{x}_i\)</span>.</p><p>For <span class="math inline">\(t=1, ..., T\)</span>:</p><ul><li><p>Normalize all weights <span class="math inline">\(w_i = \frac{w_i}{\sum_{j=1}^Nw_j}\)</span> such that <span class="math inline">\(\sum_{i=1}^Nw_i=1\)</span>.</p></li><li><p>Select the weak classifier <span class="math inline">\(h_k\)</span> with minimum error: <span class="math display">\[e_k=\sum_{i=1}^Nw_i\left(\frac{1-h_k(\vec{x}_i)y_i}{2}\right)\]</span> where <span class="math inline">\(0≤e_k≤1\)</span>.</p></li><li><p>Set weight for selected weak classifier <span class="math display">\[\alpha_t=\frac{1}{2}\ln\left(\frac{1-e_k}{e_k}\right)\]</span></p></li><li><p>Reweight the examples (boosting) <span class="math display">\[w_i=w_i\exp(-\alpha_iy_ih_k(\vec{x}_i))\]</span></p></li></ul><p>For the last step, if the weak classifier classify example <span class="math inline">\(i\)</span> correctly, i.e. <span class="math inline">\(h_k(\vec{x}_i)=y_i\)</span>, then the example weight <span class="math inline">\(w_i=w_ie^{-\alpha_t}\)</span> will decrease; if the weak classifier classify example <span class="math inline">\(i\)</span> wrongly, the weight <span class="math inline">\(w_i=w_i^{\alpha_t}\)</span> will increase.</p><p>Values of <span class="math inline">\(T\)</span> can be 200 for <span class="math inline">\(N=10^8\)</span> images and 180,000 filters. Given the above strong classifier, a new image can classified as either face or non-face.</p><h2><span id="face-recognition-pca">Face Recognition (PCA)</span></h2><p>Images of faces often belong to a manifold of intrinsically low dimension. For example, if there are three 3x1 images (see below), then each image has three intensity values. If each intensity value is viewed as a coordinate in a 3D space, then each image can be viewed as a point in a 3D space.</p><p><img src="/images/imgspace.png"></p><p>To represent these points effectively, the number of dimensions can be reduced from three to one. It is the concept of <a href="http://en.wikipedia.org/wiki/Dimension_reduction" target="_blank" rel="noopener">dimensionality reduction</a>.</p><p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">Principal component analysis</a> (PCA) is a method for performing dimensionality reduction of high dimensional face images.</p><p><strong>Eigenfaces</strong></p><p>Let us consider a set of <span class="math inline">\(N\)</span> sample images (image vectors) with <span class="math inline">\(m\times n\)</span> dimensions:</p><p><img src="/images/eigenface1.png"></p><p>Each image is represented by a 1D vector with dimensions <span class="math inline">\((m\times n) \times 1\)</span>. The <strong>mean image vector</strong> is given by <span class="math display">\[\vec{x}=\frac{1}{N}\sum_{i=1}^N\begin{bmatrix}x_{i,1}      \\\vdots \\x_{i,mn}\end{bmatrix}\]</span> The <strong>scatter matrix</strong> is given by <span class="math display">\[\vec{S}=[\vec{x_1}-\bar{x}\ \ \vec{x_2}-\bar{x}\ \dots\ \vec{x_N}-\bar{x}]\begin{bmatrix}(\vec{x_1}-\bar{x})^T     \\(\vec{x_2}-\bar{x})^T\\\vdots \\(\vec{x_N}-\bar{x})^T\end{bmatrix}\]</span> The corresponding <span class="math inline">\(t\)</span> eigenvectors with non-zero eigenvalues <span class="math inline">\(\lambda_i\)</span> are <span class="math display">\[\vec{e}_1\ \ \vec{e}_2\ \ \dots\ \ \vec{e}_t\]</span> where <span class="math inline">\(\lambda_1≥\lambda_2≥...≥\lambda_t\)</span>.</p><p>Then the origin image vector can be approximated by <span class="math display">\[\vec{x}_j\approx\bar{x}+\sum_{i=1}^tg_{ji}\vec{e}_i\]</span> where <span class="math inline">\(g_{ji}=(\vec{x}_j-\bar{x})\cdot\vec{e}_i\)</span>.</p><p><img src="/images/egface.png"></p><p>Since the eigenvectors <span class="math inline">\(e\)</span> have the same dimension as the image vectors, the eigenvectors are referred as <a href="http://en.wikipedia.org/wiki/Eigenface" target="_blank" rel="noopener">Eigenfaces</a>. The value of <span class="math inline">\(t\)</span> is usually much smaller than the value of <span class="math inline">\(mn\)</span>. Therefore, the number of dimensions can be reduced significantly.</p><p>For each image <span class="math inline">\(\vec{x}_i\)</span>, the dimension reduced representation is <span class="math display">\[(g_{i1}, g_{i2}, ..., g_{it})\]</span> To detect if the new image <span class="math inline">\(\vec{x}\)</span> with <span class="math inline">\(t\)</span> coefficients <span class="math inline">\((g_1, g_2, ..., g_t)\)</span> is a face: <span class="math display">\[||\vec{x}-(\bar{x}+g_1\vec{e}_1+g_2\vec{e}_2+...+g_t\vec{e}_t)||&lt;\text{Threshold}\]</span> If it is a face, find the closest labeled face based on the nearest neighbor in the <span class="math inline">\(t\)</span>-dimensional space.</p><p><strong>Near-infrared images for face recognition</strong></p><p>Most current face recognition systems are based on face images captured in the visible light spectrum. The infrared imaging system is able to produce face images of good condition regardless of visible lights in the environment.</p><p><img src="/images/infared.png"></p><p><img src="/images/infeared2.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PCA </tag>
            
            <tag> Recognition System </tag>
            
            <tag> Face Recognition </tag>
            
            <tag> histogram equalization </tag>
            
            <tag> Adaboost </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Irises</title>
      <link href="/2018/12/05/RS%20-%20Recognizing%20Irises/"/>
      <url>/2018/12/05/RS%20-%20Recognizing%20Irises/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 2. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#introduction">Introduction</a></li><li><a href="#image-acquisition-systems">Image Acquisition Systems</a></li><li><a href="#iris-localization">Iris localization</a></li><li><a href="#pattern-matching">Pattern Matching</a><ul><li><a href="#alignment-registration">Alignment (Registration)</a></li><li><a href="#representation">Representation</a></li><li><a href="#goodness-of-match">Goodness of Match</a></li><li><a href="#decision-fld">Decision (FLD)</a></li></ul></li><li><a href="#hough-transform">Hough Transform</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="introduction">Introduction</span></h2><p>Face recognition and iris recognition are non-invasive method for verification and identification of people. In particular, the spatial patterns that are apparent in the human iris are highly distinctive to an individual.</p><p><img src="/images/iries.png"></p><p><strong>Schematic diagram of iris recognition</strong></p><p><img src="/images/iries_recog.png"></p><h2><span id="image-acquisition-systems">Image Acquisition Systems</span></h2><p>One of the major challenges of automated iris recognition is to capture a high-quality image of the iris while remaining non-invasive to the human operator.</p><p>There are three concerns while acquiring iris images:</p><ul><li>To support recognition, it is desirable to acquire images of the iris with sufficient resolution and sharpness.</li><li>It is important to have good contrast in the interior iris pattern without resorting to a level of illumination that annoys the operator, i.e., adequate intensity of source constrained by operator comfort with brightness.</li><li>These images must be well framed (i.e., centered) without unduly constraining the operator.</li></ul><p><strong>The Daugman system</strong></p><p>The Daugman system captures images with the iris diameter typically between 100 and 200 pixels from a distance of 15-46cm.</p><p>The system makes use of an LED-based point light source in conjunction with a standard video. By carefully positioning of the point source below the operator, reflections of the light source off eyeglasses can be avoided in the imaged iris.</p><p><img src="/images/daugman.png"></p><p>The Daugman system provides the operator with live video feedback via a tiny liquidcrystal display placed in line with the camera's optics via a beam splitter. This allows the operator to see what the camera is capturing and to adjust his position accordingly.</p><p><strong>The Wildes system</strong></p><p>The Wildes system images the iris with approximately 256 pixels across the diameter from 20cm. The system makes use of a diffused source and polarization in conjunction with a low-light level camera.</p><p>The use of matched <strong>circular polarizer</strong> at the light source and camera essentially eliminates the specular reflection of the light source.</p><p><img src="/images/wildes.png"></p><p>The coupling of a low light level camera with a diffused illumination allows for a level of illumination that is entirely unobjectionable to human operators.</p><p>The relative sizes and positions of the square contours are chosen so that when the eye is in an appropriate position, the squares overlap and appear as one to the operator.</p><h2><span id="iris-localization">Iris localization</span></h2><p><img src="/images/iries_loc.png"></p><p>Image acquisition will capture the iris as part of a larger image that also contains data derived from the immediately surrounding eye region. For example, eyelashes, upper eyelid, lower eyelid and sclera. Therefore, prior to performing iris pattern matching, it is important to <strong>localize</strong> that portion of the acquired image that corresponds to an iris.</p><p><strong>The Wildes system</strong> makes use of the <strong>first derivatives</strong> of image intensity to signal the location of edges that correspond to the borders of the iris.</p><ul><li>Step 1: The image intensity information is converted into binary edge-map.</li><li>Step 2: The edge points vote to particular contour parameter values.</li></ul><p><strong>Step 1</strong></p><p>The edge map is recovered via <strong>gradient-based edge detection</strong>. This operation consists of thresholding the magnitude of the image intensity gradient magnitude. <span class="math inline">\(I\)</span> is the intensity and (x, y) are the image coordinates. <span class="math display">\[\text{Gradient magnitude }|\triangledown G(x, y)\ast I(x, y)|\\\text{2D Gaussian function } G(x, y)=\frac{1}{2\pi\sigma^2}\exp(\frac{(x-x_0)^2+(y-y_0)^2}{2\sigma^2})\]</span> <img src="/images/iris_edge.png"></p><p><strong>Step 2</strong></p><p>The voting procedure is realized via the <a href="#hough-transform">Hough transform</a>. For circular limbic or pupillary boundaries and a set of recovered edge points, a Hough transform is defined as follows.</p><p>Edge points <span class="math inline">\((x_j, y_j)\)</span> for <span class="math inline">\(j = 1, ..., n\)</span>: <span class="math display">\[H(x_c, y_c, r)=\sum_{j=1}^nh(x_j,y_j,x_c,y_c,r)\]</span> where <span class="math display">\[h(x_j, y_j, x_c, y_c, r)=\begin{cases}1, \text{ if }\ g(x_j, y_j, x_c, y_c, r)=0\\0, \text{ otherwise}\end{cases}\\g(x_j, y_j, x_c, y_c, r)=(x_j-x_c)^2+(y_j-y_c)^2-r^2\]</span> For every parameter triple <span class="math inline">\((x_c, y_c, r)\)</span> that represents a circle through the edge point <span class="math inline">\((x_j, y_j)\)</span>, <span class="math display">\[g(x_j, y_j, x_c, y_c, r)=0\]</span> <img src="/images/wildescir.png"></p><p>The parameter triple that <strong>maximizes</strong> the Hough space <span class="math inline">\(H\)</span> is common to the largest number of edge points and is a reasonable choice to represent the contour of interest.</p><hr><p>The limbus and pupil are modeled with <strong>circular contour models</strong>.</p><p><strong>The Daugman system</strong> fits the <strong>circular contours</strong> via gradient ascent on the parameters so as to maximize <span class="math display">\[\left|\frac{\partial}{\partial r}G(r)\ast\oint_{x_c,y_c,r}\frac{I(x,y)}{2\pi r}ds\right|\]</span> where <span class="math inline">\(G(r)=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(r-r_0)^2}{2\sigma^2})\)</span>; <span class="math inline">\(r_0\)</span> is the center.</p><p>The first part of the equation is to perform Gaussian smoothing; while the second part is computing the average intensity along the circle.</p><p><img src="/images/IMG_66247EE67551-1.jpg"></p><p>In order to incorporate directional tuning of the image derivative, the arc of integration <span class="math inline">\(ds\)</span> is restricted to the left and right quadrants (i.e., near vertical edges) when fitting the <em>limbic boundary</em>.</p><p>This arc is considered over a fuller range when fitting the <em>pupillary boundary</em>.</p><h2><span id="pattern-matching">Pattern Matching</span></h2><p>Having localized the region of an acquired image that corresponds to the iris, the final task is to decide if this pattern matches a previously stored iris pattern.</p><p>There are four steps:</p><ol type="1"><li>Alignment: bringing the newly acquired iris pattern into spatial alignment with a candidate data base entry.</li><li>Representation: choosing a representation of the aligned iris patterns that makes their distinctive patterns apparent.</li><li>Goodness of Match: evaluating the goodness of match between the newly acquired and data base representations.</li><li>Decision: deciding if the newly acquired data and the data base entry were derived from the same iris based on the goodness of match.</li></ol><h3><span id="alignment-registration">Alignment (Registration)</span></h3><p>To make a detailed comparison between two images, it is advantageous to establish a precise correspondence (or matching) between characteristic structures across the pair.</p><p>Both systems (Daugman and Wildes systems) compensate for image shift, scaling and rotation.</p><p><strong>The Daugman system for alignment</strong></p><p>The Daugman system uses <strong>radial scaling</strong> to compensate for overall size as well as a simple model pupil variation based on <strong>linear stretching</strong>.</p><p>The system maps the Cartesian image coordinates <span class="math inline">\((x, y)\)</span> to dimensionless polar image coordinates <span class="math inline">\((r, θ)\)</span> according to <span class="math display">\[x(r,\theta)=(1-r)x_p(0,\theta)+rx_l(1,\theta)\\y(r,\theta)=(1-r)y_p(0,\theta)+ry_l(1,\theta)\]</span> <img src="/images/daugalign.png"></p><p><img src="/images/daugali.png"></p><p><strong>The Wildes system for alignment</strong></p><p>The Wildes system uses an <strong>image-registration</strong> technique to compensate for both scaling and rotation.</p><p>This approach geometrically warps a newly acquired image <span class="math inline">\(I_a (x, y)\)</span> into alignment with a selected data base image <span class="math inline">\(I_d (x, y)\)</span> according to a mapping function <span class="math inline">\((u(x, y), v(x, y))\)</span> such that for all <span class="math inline">\((x, y)\)</span>, the image intensity value at <span class="math inline">\((x, y) – (u(x, y), v(x, y))\)</span> is close to that at <span class="math inline">\((x, y)\)</span> at <span class="math inline">\(I_d\)</span>.</p><p>The mapping function is taken to minimize <span class="math display">\[\int_x\int_y\left(I_d(x,y)-I_a(x-u, y-v)\right)^2dxdy\]</span> under the constrains to capture similarity transformation of image coordinates <span class="math inline">\((x,y)\)</span> to <span class="math inline">\((x&#39;=x-u, y&#39;=y-v)\)</span>.</p><p><img src="/images/imgreg.jpg"></p><p><strong>Translation</strong> <span class="math display">\[\vec{x}&#39;=\vec{x}+\vec{d}\]</span> <img src="/images/imgtrans.png"></p><p><strong>Rotation</strong> <span class="math display">\[\vec{x}&#39;=R_\theta\vec{x}\\R_\theta=\begin{pmatrix}\cos\theta &amp; -\sin\theta \\\sin\theta &amp; \cos\theta\end{pmatrix}\]</span> <img src="/images/imgrot.png"></p><p><strong>Rotation + Translation</strong> <span class="math display">\[\vec{x}&#39;=R\vec{x}+\vec{d}\]</span> <strong>Scaling + Translation</strong> <span class="math display">\[\vec{x}&#39;=S\vec{x}+\vec{d}\]</span> <img src="/images/scatra.png"></p><p><strong>Shearing</strong> <span class="math display">\[\vec{x}&#39;=K\vec{x}\\K=\begin{bmatrix}1      &amp; k_{xy}     \\k_{yx}     &amp; 1\end{bmatrix}\]</span> <img src="/images/shearing.png"></p><p><strong>Affine</strong>: translation + rotation + scaling + shearing <span class="math display">\[\vec{x}&#39;=R_\theta S K\vec{x}+\vec{d}\]</span> Example: <span class="math display">\[\begin{bmatrix}x&#39; \\y&#39;\end{bmatrix}=\begin{bmatrix}\cos\theta &amp; -\sin\theta \\\sin\theta &amp; \cos\theta\end{bmatrix}\begin{bmatrix}s_x &amp; 0 \\0 &amp; s_y\end{bmatrix}\begin{bmatrix}1 &amp; k_{xy} \\k_{yx} &amp; 1\end{bmatrix}\begin{bmatrix}x \\y\end{bmatrix}+\begin{bmatrix}d_x \\d_y\end{bmatrix}\]</span></p><h3><span id="representation">Representation</span></h3><p>To represent the iris image for matching, both the Daugman and Wildes systems capture the multiscale information extracted from the image.</p><p>The Wildes system makes use of the Laplacian of Gaussian filters to construct a <strong>Laplacian pyramid</strong>.</p><p>The Laplacian of Gaussian (LoG) filter is given by <span class="math display">\[-\frac{1}{\pi\sigma^4}\left(1-\frac{\rho^2}{2\sigma^2}\right)\exp(-\frac{\rho^2}{2\sigma^2})\]</span> where <span class="math inline">\(\rho\)</span> is radial distance of a point from the filter's center; <span class="math inline">\(\sigma\)</span> is standard deviation.</p><p>A Laplacian pyramid is formed by collecting the LoG filtered images.</p><p><img src="/images/logpra.png"></p><h3><span id="goodness-of-match">Goodness of Match</span></h3><p>The Wildes system uses the <strong>normalized correlation</strong> between the acquired representation and data base representation. In discrete form, the normalized correlation can be defined as follows.</p><p>Let <span class="math inline">\(p_1[i, j]\)</span> and <span class="math inline">\(p_2[i, j]\)</span> be two image arrays of size <span class="math inline">\(n \times m\)</span>.</p><p><img src="/images/gom.png"></p><p>The normal correlation is <span class="math display">\[NC=\frac{\sum_{i=1}^n\sum_{j=1}^m(p_1[i,j]-\mu_1)(p_2[i,j]-\mu_2)}{nm\sigma_1\sigma_2}\]</span> <img src="/images/gompy.png"></p><h3><span id="decision-fld">Decision (FLD)</span></h3><p>The Wildes system combines four estimated normalized correlation values into a single <strong>accept/reject</strong> judgment.</p><p>In this application, the concept of <a href="http://en.wikipedia.org/wiki/Linear_discriminant_analysis" target="_blank" rel="noopener">Fisher's linear discriminant</a> is used for making binary decision. A <strong>weight vector</strong> is found such that <strong>the variance within a class of iris data is minimized</strong> while <strong>the variance between different classes of iris data is maximized</strong> for the transformed samples.</p><p>In iris recognition application, usually there are two classes: <strong>Authentic class (A)</strong> and <strong>Imposter class (I)</strong>.</p><p>To make a binary decision on a line, all points are projected onto the weight vector (or samples are transformed by using the weight vector).</p><p><img src="/images/fld1.png"></p><p>In iris recognition using the Wildes system, all samples are 4-dimensional vectors. Let there be n 4-dimensional samples.</p><p><img src="/images/fld2.png"></p><p>The total within class variance is <span class="math display">\[\vec{S}_w=\vec{S}_i+\vec{S}_a\]</span> Between class variance is <span class="math display">\[\vec{S}_b=(\vec{\mu}_a-\vec{\mu}_i)(\vec{\mu}_a-\vec{\mu}_i)^T\]</span> If all samples are transformed, the ratio of between class variance to total within class variance is <span class="math display">\[\frac{\vec{w}^T\vec{S}_b\vec{w}}{\vec{w}^T\vec{S}_w\vec{w}}\]</span> The ratio is maximized when <span class="math display">\[\vec{w}=\vec{S}_w^{-1}(\vec{\mu}_a-\vec{\mu}_i)\]</span> And the separation point for decision making is <span class="math display">\[\frac{1}{2}\vec{w}^T(\vec{\mu}_a+\vec{\mu}_i)\]</span> Therefore, values above this point will be taken as derived from class <span class="math inline">\(A\)</span>; values below this point will be taken as derived from class <span class="math inline">\(I\)</span>.</p><p><img src="/images/fld3.png"></p><h2><span id="hough-transform">Hough Transform</span></h2><p><strong>Detecting Lines</strong></p><p>Idea: if two edge points <span class="math inline">\((x_i, y_i)\)</span> and <span class="math inline">\((x_j, y_j)\)</span> lie on the same straight line, then they should have the same values of slope and y-intercepts on the xy-plane.</p><p><img src="/images/houghline.png"></p><p><strong>[1]</strong> For a point <span class="math inline">\((x_i,y_i)\)</span>, we set up a straight line equation: <span class="math display">\[y_i=ax_i+b\Leftrightarrow b=(-x_i)a+y_i\]</span> where <span class="math inline">\(a\)</span> = slope, <span class="math inline">\(b\)</span> = y-intercept, <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> are known and fixed.</p><p><strong>[2]</strong> We subdivide the a axis into <span class="math inline">\(K\)</span> increments between <span class="math inline">\([a_\min,a_\max]\)</span>. For each increment of <span class="math inline">\(a\)</span>, we evaluate the value of <span class="math inline">\(b\)</span>.</p><p><strong>[3]</strong> A relationship between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> can be plotted in a parameter space, i.e., ab-plane.</p><p><strong>[4]</strong> We partition the parameter space into a number of bins (accumulator cells), and increment the corresponding bin <span class="math inline">\(A(a,b)\)</span> by 1 (<span class="math inline">\(b\)</span> is rounded into the nearest integer).</p><p><img src="/images/houghbin.png"></p><p><strong>[5]</strong> For another point <span class="math inline">\((x_j,y_j)\)</span>, we set up another straight line equation: <span class="math display">\[y_j=ax_j+b\Leftrightarrow b=(-x_j)a+y_j\]</span> <strong>[6]</strong> Similarly, we subdivide the a axis into K increments between <span class="math inline">\([a_\min,a_\max]\)</span>. For each increment of <span class="math inline">\(a\)</span>, we evaluate the value of <span class="math inline">\(b\)</span>. We plot the relationship between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> in the same parameter space, and update bin values in the discrete parameter space.</p><p><strong>[7]</strong> The bin <span class="math inline">\(A(a,b)\)</span> having the highest count corresponds to the straight line passing through the points <span class="math inline">\((x_i,y_i)\)</span> and <span class="math inline">\((x_j,y_j)\)</span>.</p><p><img src="/images/hough2.png"></p><p><strong>[8]</strong> The same procedure can be applied to all points. The bin <span class="math inline">\(A(a,b)\)</span> having the <strong>highest count</strong> corresponds to the straight line passing through (or passing near) the largest number of points.</p><p>Problem: Values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> run from negative infinity to positive infinity. We need infinite number of bins!</p><p>Solution: use normal representation of a line: <span class="math display">\[x\cos(\theta)+y\sin(\theta)=\rho\]</span> <img src="/images/houghnormal.png"></p><p><span class="math inline">\(\theta\)</span> runs from <span class="math inline">\(–90^o\)</span> to <span class="math inline">\(90^o\)</span>. <span class="math inline">\(\rho\)</span> runs from <span class="math inline">\(-\sqrt{2}D\)</span> to <span class="math inline">\(\sqrt{2}D\)</span>, where <span class="math inline">\(D\)</span> is the distance between corners in the image (length and width).</p><p><strong>Circle Hough Transform (CHT)</strong></p><p>The Hough transform can be used to determine the parameters of a circle when a number of points that fall on the perimeter are known. A circle with radius <span class="math inline">\(R\)</span> and center <span class="math inline">\((a, b)\)</span> can be described with the parametric equations: <span class="math display">\[x=a+R\cos(\theta)\\y=b+R\sin(\theta)\]</span> When the angle <span class="math inline">\(θ\)</span> sweeps through the full 360 degree range the points <span class="math inline">\((x, y)\)</span> trace the perimeter of a circle.</p><p>If the circles in an image are of <strong>known radius</strong> <span class="math inline">\(R\)</span>, then the search can be reduced to 2D. The objective is to find the <span class="math inline">\((a, b)\)</span> coordinates of the centers.</p><p><img src="/images/cht1.png"></p><p>If the <strong>radius is not known</strong>, then the locus of points in parameter space will fall on the surface of a <strong>cone</strong>. Each point <span class="math inline">\((x, y)\)</span> on the perimeter of a circle will produce a cone surface in parameter space. The triplet <span class="math inline">\((a, b, R)\)</span> will correspond to the accumulation cell where the largest number of cone surfaces intersect.</p><p><img src="/images/cone.png">The drawing above illustrates the generation of a conical surface in parameter space for one <span class="math inline">\((x, y)\)</span> point. A circle with a different radius will be constructed at each level, <span class="math inline">\(r\)</span>.</p><p>The search for circles with unknown radius can be conducted by using a three dimensional accumulation matrix.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Iris </tag>
            
            <tag> FLD </tag>
            
            <tag> Daugman </tag>
            
            <tag> Wildes </tag>
            
            <tag> Hough Transform </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recognizing Image Features and Patterns</title>
      <link href="/2018/12/04/RS%20-%20Recognizing%20Image%20Features%20and%20Patterns/"/>
      <url>/2018/12/04/RS%20-%20Recognizing%20Image%20Features%20and%20Patterns/</url>
      
        <content type="html"><![CDATA[<p>HKUST CSIT5401 Recognition System lecture notes 1. 识别系统复习笔记。</p><!-- toc --><ul><li><a href="#laplacian-point-detector">Laplacian Point Detector</a></li><li><a href="#line-detector">Line Detector</a></li><li><a href="#edge-detectors">Edge Detectors</a><ul><li><a href="#gradient-operator">Gradient Operator</a></li><li><a href="#marr-hildreth-edge-detector">Marr-Hildreth Edge Detector</a></li></ul></li><li><a href="#scale-invariant-feature-transform-sift">Scale Invariant Feature Transform (SIFT)</a></li><li><a href="#harris-corner-detector">Harris Corner Detector</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="laplacian-point-detector">Laplacian Point Detector</span></h2><p>There are three different types of intensity discontinuities in a digital image:</p><ul><li>Point (Isolated Point)</li><li>Line</li><li>Edge (Ideal, Ramp and Roof)</li></ul><p>Intensity discountinuity is detected based on the mask response <span class="math inline">\(R\)</span> within a pre-defined window, e.g. <span class="math inline">\(3\times3\)</span>: <span class="math display">\[R=\sum_{i=1}^9w_iz_i\]</span> where <span class="math inline">\(w_i\)</span> represent weights within a pre-defined window; <span class="math inline">\(z_i\)</span> represent intensity values.</p><p>If <span class="math inline">\(|R|≥T\)</span> , then a point has been detected. This point is the location on which the mask is <strong>centred</strong>, where <span class="math inline">\(T\)</span> is a non-negative threshold.</p><p>The mask below is the <strong>Laplacian mask</strong> for detecting point. Sum of all weights is zero to make sure that there is no response at a flat region (constant intensity region).</p><table><thead><tr class="header"><th style="text-align: center;">1</th><th style="text-align: center;">1</th><th style="text-align: center;">1</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">1</td><td style="text-align: center;">-8</td><td style="text-align: center;">1</td></tr><tr class="even"><td style="text-align: center;">1</td><td style="text-align: center;">1</td><td style="text-align: center;">1</td></tr></tbody></table><p>The Laplacian is given as (<span class="math inline">\(f\)</span> is input image): <span class="math display">\[\triangledown^2f(x,y)=\frac{\partial^2f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}\]</span> where <span class="math display">\[\frac{\partial^2f}{\partial x^2}=f(x+1,y)-2f(x,y)+f(x-1,y)\\\frac{\partial^2 f}{\partial y^2}=f(x,y+1)-2f(x,y)+f(x,y-1)\]</span> The discrete implementation of the Laplacian operator is given as: <span class="math display">\[\triangledown^2f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)\]</span> Below are several Laplacian masks:</p><p><img src="/images/pd.png"></p><h2><span id="line-detector">Line Detector</span></h2><p>A line is detected when more than one aligned, connected points are detected or, the <strong>response</strong> of line mask <strong>is greater than some threshold</strong>. The below are line masks for detecting lines (1 pixel thick) in 4 different specific directions:</p><p><img src="/images/ld.png"></p><p>If we want to detect a line in a specified direction, then we should use the mask associated with that direction and threshold its output responses.</p><p>If 4 line masks are used, then the final response is equal to the <strong>largest</strong> response among the masks: <span class="math display">\[R = \max\left(|R_{horizontal}|, |R_{45}|, |R_{vertical}|, |R_{-45}|\right)\]</span> Example code (Matlab):</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">f = imread(<span class="string">'xxx.png'</span>); <span class="comment">% read image</span></span><br><span class="line">w = [<span class="number">2</span> <span class="number">-1</span> <span class="number">-1</span>; <span class="number">-1</span> <span class="number">2</span> <span class="number">-1</span>; <span class="number">-1</span> <span class="number">-1</span> <span class="number">2</span>]; <span class="comment">% mask</span></span><br><span class="line">g = <span class="built_in">abs</span>(imfilter(double(f),w)); <span class="comment">% mask responses</span></span><br></pre></td></tr></table></figure><h2><span id="edge-detectors">Edge Detectors</span></h2><p>Edge is the boundary of regions. The boundary has meaningful discontinuities in grey intensity level. There are three types of edges: ideal edge (left), ramp edge (middle) and roof edge (right).</p><p><img src="/images/3t.png"></p><p>For an <strong>ideal edge</strong> (step edge, left), an edge is a collection of connected pixels on the region boundary. Ideal edges can occur over the distance of 1 pixel.</p><p><strong>Roof edges</strong> (right) are models of lines through a region, with the base (width) of a roof edge being determined by the thickness and sharpness of the line. In the limit, when its base is 1 pixel wide, a roof edge becomes a 1 pixel thick line running through a region in an image. Roof edges can represent thin features, e.g., roads, line drawings, etc.</p><p>For a <strong>ramp edge</strong> (middle):</p><ul><li>edge point is any point contained in the ramp</li><li>edge length is determined by the length of the ramp</li><li>the slope of the ramp is inversely proportional to the degree of blurring in the edge</li><li>the <strong>first derivative</strong> of the intensity profile is positive at the points of transition into and out of the ramp (we move from left to right)</li><li>the <strong>second derivative</strong> of the intensity profile is positive at the transition associated with the dark side of the edge, and negative at the transition associated with the light side of the edge</li></ul><p><img src="/images/ramp.png"></p><p>The <strong>magnitude of the first derivative</strong> can be used to detect the presence of an edge. The <strong>sign of the second derivative</strong> can be used to determine whether an edge pixel lies on the dark or light side of an edge. The <strong>zero-crossing property</strong> of the second derivative is very useful for <strong>locating</strong> the centres of thick edge.</p><p>However, fairly little noise can have a significant impact on the first and second derivatives used for edge detection in images. <strong>Image smoothing</strong> is commonly used prior to the edge detection so that the estimations of the two derivatives can be more accurate.</p><h3><span id="gradient-operator">Gradient Operator</span></h3><p>The computation of the gradient of an image is based on obtaining the partial derivatives <span class="math inline">\(G_x = \partial f/\partial x\)</span> and <span class="math inline">\(G_y = \partial f/\partial y\)</span> at every pixel location (x,y). The gradient direction and gradient magnitude are <span class="math display">\[\tan^{-1}\left(\frac{G_y}{G_x}\right)\\|\triangledown f|\approx|G_x|+|G_y|\]</span> <img src="/images/z.png"></p><p>The are several ways to approximate the partial derivatives:</p><ul><li>Roberts cross-gradient operators<ul><li><span class="math inline">\(G_x = (z_9-z_5)\)</span></li><li><span class="math inline">\(G_y=(z_8-z_6)\)</span></li></ul></li><li>Prewitt operators<ul><li><span class="math inline">\(G_x=(z_7+z_8+z_9)-(z_1+z_2+z_3)\)</span></li><li><span class="math inline">\(G_y=(z_3+z_6+z_9)-(z_1+z_4+z_7)\)</span></li></ul></li><li>Sobel operators<ul><li><span class="math inline">\(G_x=(z_7+2z_8+z_9)-(z_1+2z_2+z_3)\)</span></li><li><span class="math inline">\(G_y=(z_3+2z_6+z_9)-(z_1+2z_4+z_7)\)</span></li></ul></li></ul><p><img src="/images/ed.png"></p><p>Below are diagonal edge masks for detecting discontinuities in the <strong>diagonal directions</strong>.</p><p><img src="/images/diag.png"></p><h3><span id="marr-hildreth-edge-detector">Marr-Hildreth Edge Detector</span></h3><p>The Laplacian of an image f(x,y) at location (x,y) is defined as <span class="math display">\[\triangledown^2f(x,y)=\frac{\partial^2f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}\]</span> There are two approximations: <span class="math display">\[\triangledown^2f=4z_5-(z_2+z_4+z_6+z_8)\\\triangledown^2f=8z_5-(z_1+z_2+z_3+z_4+z_6+z_7+z_8+z_9)\]</span> The Laplacian generally is <strong>not</strong> used in its original form for edge detection (based on zero-crossing property) because it is <strong>unacceptably sensitive to noise</strong>. We smooth the image by using a Gaussian blurring function <span class="math inline">\(G(r)\)</span>, where <span class="math inline">\(r\)</span> = radius, before we apply the Laplacian operator: <span class="math display">\[G(r)=\exp(\frac{-r^2}{2\sigma^2})\]</span> The <strong>Laplacian of a Gaussian (LoG)</strong> operator is defined by <span class="math display">\[\text{LoG}(f)=\triangledown^2(f\ast G)=f\ast(\triangledown^2G)\]</span> Using the LoG, the location of edges can be detected reliably based on the zero-crossing values because image noise level is reduced by the Gaussian function.</p><p><strong>Marr-Hildreth algorithm</strong></p><ol type="1"><li><p>Filter the input with an n-by-n Gaussian blurring filter <span class="math inline">\(G(r)\)</span>.</p></li><li><p>Compute the Laplacian of the image resulting from Step 1 using one of the following 3-by-3 masks.</p><p><img src="/images/mha.png"></p></li><li><p>Find the <strong>zero crossings</strong> of the image from Step 2.</p><ol type="1"><li>A zero crossing at a pixel implies that the signs of at least two of its opposing neighboring pixels must be different.</li><li>There are four cases to test: left/right, up/down, and the two diagonals.</li><li>For testing, the signs of the two opposing neighboring pixels must be different and their absolute Laplacian values must be larger than or equal to some threshold.</li><li>If yes, we call the current pixel a zero-crossing pixel.</li></ol></li></ol><p><img src="/images/mhed.png"></p><h2><span id="scale-invariant-feature-transform-sift">Scale Invariant Feature Transform (SIFT)</span></h2><p>SIFT is useful for finding distinctive patches (<strong>keypoints</strong>) in images and transforming keypoints (locations) into <strong>features vectors</strong> for recognition tasks.</p><p>SIFT consists of four steps:</p><ol type="1"><li>Scale-space extrema detection</li><li>Keypoint localization</li><li>Orientation assignment</li><li>Keypoint descriptor</li></ol><p>SIFT feature is</p><ul><li>invariant to image rotation and scale</li><li>partially invariant to change in illumination and 3D camera viewpoint</li></ul><p>The method is a cascade (one step followed by the other step) filtering approach, in which more computationally expensive operations are applied only at locations that pass an initial test.</p><p><strong>[1] Scale-space extrema detection</strong></p><p>Candidate locations are identified by searching for stable features across all scales in the scale space. The <strong>scale space</strong> of an image is defined as <span class="math display">\[L(x,y,\sigma)=G(x,y,\sigma)\ast I(x,y)\\G(x,y,\sigma)=\frac{1}{2\pi\sigma^2}\exp(-\frac{x^2+y^2}{2\sigma^2})\]</span> , where <span class="math inline">\(\ast\)</span> is the convolution operator (filtering operation), the variable-scale Gaussian is <span class="math inline">\(G(x, y, \sigma)\)</span> and the image is <span class="math inline">\(I(s, y)\)</span>.</p><p>The difference between two nearby scales separated by a constant multiplicative factor <span class="math inline">\(k\)</span> is <span class="math display">\[\begin{align}D(x,y,\sigma)&amp;=L(x,y,k\sigma)-L(x,y,\sigma)\\&amp;=\left(G(x,y,k\sigma)-G(x,y,\sigma)\right)\ast I(x,y)\end{align}\]</span> The DoG function provides a close and efficient approximation to the scale-normalized Laplacian of Gaussian (LoG).</p><p><img src="/images/dog.jpg"></p><p>Local <strong>extrema</strong> (maxima and minima) of <span class="math inline">\(D( x, y, σ)\)</span> are detected by comparing the values of its 26 neighbors, including 9 from the above image, 9 from bottom image and 8 from the current image.It is selected only if the center pixel is larger than <strong>all</strong> of these neighbors (26 neighbors) or smaller than all of them.</p><p><img src="/images/extra.png"></p><p><img src="/images/exdet.png"></p><p><strong>[2] Keypoint localization</strong></p><p>Once a keypoint candidate has been found by comparing a pixel to its neighbors, the next step is to determine whether the keypoint is selected based on <strong>local contrast and localization along edge</strong>. Therefore, the keypoints will be rejected if these points have low contrast.</p><p>All extrema are discarded if <span class="math inline">\(|D(x)|&lt;0.03\)</span> (minimum contrast), where <span class="math inline">\(x\)</span> represents a relative image position with maximum value of <span class="math inline">\(D\)</span>. The keypoints will be rejected if these points are poorly localized along an edge (determined based on the <strong>ratio of principle curvatures</strong>).</p><p><img src="/images/kl.png"></p><p><strong>[3] Orientation assignment</strong></p><p>Each corresponding keypoint in <span class="math inline">\(L\)</span> is assigned a dominant orientation. The keypoint descriptor can be represented relative to this orientation and therefore achieve invariance to image rotation.</p><p>The gradient magnitude and orientation are <span class="math display">\[m(x,y)=\sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2}\\\theta(x,y)=\tan^{-1}\left(\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}\right)\]</span> An <strong>orientation histogram</strong> is formed from the gradient orientations within a region around the keypoint. The orientation histogram has 36 bins covering the 360 degree range of orientations, 10 degrees per bin. Each sample added to the histogram is weighted by its gradient magnitude and by a Gaussian-weighted circular window (with σ that is 1.5 times that of the scale of the keypoint, and it is related to effective window size). Peak in the orientation histogram corresponds to dominant direction of the local gradients.</p><p><img src="/images/IMG_2E4DF1ED416A-1.jpg"></p><p><strong>[4] Descriptor for local image region</strong></p><p><img src="/images/kd.png"></p><p>For each detected keypoint, a local image descriptor is computed. It is partially invariant to change in illumination and 3D viewpoint.</p><p>In order to achieve orientation invariance, the coordinates and the gradient orientations are rotated relative to the keypoint orientation. A Gaussian weighting function with σ equal to one half the width of the descriptor window is used to assign a weight to the magnitude of each sample point.</p><p>Each subregion generates an orientation histogram with 8 orientation bins. Therefore, for each keypoint, if <span class="math inline">\(2\times2\)</span> descriptor is used, a feature vector can be formed with <span class="math inline">\(2\times2\times8 = 32\)</span> elements; if <span class="math inline">\(4\times4\)</span> descriptor is used, there will be <span class="math inline">\(4\times4\times8 = 128\)</span> elements in a feature vector. The <strong>optimal</strong> setting is 4x4 subregions and 8 orientation bins (the above picture).</p><p><strong>Feature matching</strong></p><p><img src="/images/IMG_043BB8EF0160-1.jpg"></p><p>Matlab Implementation</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% num = match(image1, image2)</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% This function reads two images, finds their SIFT features, and</span></span><br><span class="line"><span class="comment">%   displays lines connecting the matched keypoints.  A match is accepted</span></span><br><span class="line"><span class="comment">%   only if its distance is less than distRatio times the distance to the</span></span><br><span class="line"><span class="comment">%   second closest match.</span></span><br><span class="line"><span class="comment">% It returns the number of matches displayed.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% Example: match('scene.pgm','book.pgm');</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">num</span> = <span class="title">match</span><span class="params">(image1, image2)</span></span></span><br><span class="line"><span class="comment">% Find SIFT keypoints for each image</span></span><br><span class="line">[im1, des1, loc1] = sift(image1);</span><br><span class="line">[im2, des2, loc2] = sift(image2);</span><br><span class="line"><span class="comment">% For efficiency in Matlab, it is cheaper to compute dot products between</span></span><br><span class="line"><span class="comment">%  unit vectors rather than Euclidean distances.  Note that the ratio of</span></span><br><span class="line"><span class="comment">%  angles (acos of dot products of unit vectors) is a close approximation</span></span><br><span class="line"><span class="comment">%  to the ratio of Euclidean distances for small angles.</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% distRatio: Only keep matches in which the ratio of vector angles from the</span></span><br><span class="line"><span class="comment">%   nearest to second nearest neighbor is less than distRatio.</span></span><br><span class="line">distRatio = <span class="number">0.6</span>;</span><br><span class="line"><span class="comment">% For each descriptor in the first image, select its match to second image.</span></span><br><span class="line">des2t = des2';</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span> : <span class="built_in">size</span>(des1,<span class="number">1</span>)</span><br><span class="line">    dotprods = des1(<span class="built_in">i</span>,:) * des2t; <span class="comment">% compute orientation of des1[i] and des2[j] for all j</span></span><br><span class="line">    [vals, indx] = <span class="built_in">sort</span>(<span class="built_in">acos</span>(dotprods)); <span class="comment">% Take inverse cosine and sort results</span></span><br><span class="line">    <span class="comment">% Check if nearest neighbor has angle less than distRatio times 2nd.</span></span><br><span class="line">    <span class="keyword">if</span> (vals(<span class="number">1</span>) &lt; distRatio * vals(<span class="number">2</span>))</span><br><span class="line">      match(<span class="built_in">i</span>) = indx(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      match(<span class="built_in">i</span>) = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><img src="/images/IMG_DAD55EC9C383-1.jpg"></p><h2><span id="harris-corner-detector">Harris Corner Detector</span></h2><p><strong>Basic Idea</strong></p><p>We should easily recognize the point by looking at intensity values within a small window. hifting the window in any direction should yield a large change in appearance.</p><p><img src="/images/cornersad1.png"></p><p>Harris corner detector gives a mathematical approach for determining which case holds.</p><p>Change of intensity for the shift <span class="math inline">\([u, v]\)</span>: <span class="math display">\[E(u,v)=\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]\]</span> where <span class="math inline">\(w(x,y)\)</span> is window function.</p><p>For nearly constant patches, this will be near 0. For very distinctive patches, this will be larger. Hence... we want patches where <span class="math inline">\(E(u,v)\)</span> is LARGE.</p><p><img src="/images/harriasequ.png"></p><p>For small shifts <span class="math inline">\([u, v]\)</span>, we have a bilinear approximation: <span class="math display">\[E(u,v)\approx [u,v]M[u,v]^T\]</span> where <span class="math inline">\(M\)</span> is a 2x2 matrix computed from image derivatives: <span class="math display">\[M=\sum_{x,y}w(x,y)\begin{bmatrix}I_x^2      &amp; I_xI_y      \\I_xI_y      &amp; I_y^2\end{bmatrix}\]</span> Treat gradient vectors as a set of <span class="math inline">\((dx,dy)\)</span> points with a center of mass defined as being at <span class="math inline">\((0,0)\)</span>. Fit an ellipse to that set of points via scatter matrix.</p><p><img src="/images/harrianaly.png"></p><p><img src="/images/harrrieclips.png"></p><p>Measure of corner response: <span class="math display">\[R=Det(M)-k(Trace(M))^2\]</span> where <span class="math display">\[Det(M)=\lambda_1\lambda_2\\Trace(M)=\lambda_1+\lambda_2\]</span> According to <span class="math inline">\(R\)</span>, we can detect corner:</p><p><img src="/images/harrieres.png"></p><p><span class="math inline">\(R\)</span> depends only on eigenvalues of <span class="math inline">\(M\)</span>. As we can see from figure above,</p><ul><li><span class="math inline">\(R\)</span> is large for a corner.</li><li><span class="math inline">\(R\)</span> is negative with large magnitude for an edge</li><li><span class="math inline">\(|R|\)</span> is small for a flat region</li></ul><p><strong>Harris Corner Detection Algorithm</strong></p><ol type="1"><li><p>Compute <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> derivatives of image: <span class="math display">\[I_x=G_\sigma^x\ast I\\I_y=G_\sigma^y\ast I\]</span></p></li><li><p>Compute products of derivatives at every pixel: <span class="math display">\[I_x^2=I_x\cdot I_x\\I_y^2=I_y\cdot I_y\\I_{xy}=I_x\cdot I_y\]</span></p></li><li><p>Compute the sums of the products of derrivatives at each pixel: <span class="math display">\[S_x^2=G_\sigma&#39;\ast I_x^2\\S_y^2=G_\sigma&#39;\ast I_y^2\\S_{xy}=G_\sigma&#39;\ast I_{xy}\]</span></p></li><li><p>Define at each pixel <span class="math inline">\((x,y)\)</span> the matrix: <span class="math display">\[M(x,y)=\begin{bmatrix}S_x^2(x,y)      &amp; S_{xy}(x,y)      \\S_{xy}(x,y)     &amp; S_y^2(x,y)\end{bmatrix}\]</span></p></li><li><p>Compute the response of the detector at each pixel: <span class="math display">\[R=Det(M)-k(Trace(M))^2\]</span></p></li><li><p>Threshold of value of <span class="math inline">\(R\)</span>. Compute nonmax suppression.</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Recognition System </tag>
            
            <tag> Prewitt </tag>
            
            <tag> Sobel </tag>
            
            <tag> Marr-Hildreth Edge Detector </tag>
            
            <tag> SIFT </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Deep Deterministic Policy Gradient (DDPG)</title>
      <link href="/2018/11/30/RL%20-%20Deep%20Deterministic%20Policy%20Gradient/"/>
      <url>/2018/11/30/RL%20-%20Deep%20Deterministic%20Policy%20Gradient/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1509.02971" target="_blank" rel="noopener">Deep Deterministic Policy Gradient (DDPG)</a> 是由 DeepMind 的 Lillicrap 等人于2015年提出的算法，发表在ICLR 2016上。DDPG 是基于 <a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener">DPG</a> 算法的改进，可以看作是 Actor-critic 和 <a href="https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/">DQN</a> 的结合，它同时学习一个 Q-function 和一个策略（policy）：用 Q-learning 的方法学习 Q-function，然后用 Q-function 更新策略。</p><a id="more"></a><h2><span id="dpg">DPG</span></h2><p><a href="http://proceedings.mlr.press/v32/silver14.pdf" target="_blank" rel="noopener">Deterministic Policy Gradient (DPG)</a> 是把策略梯度（policy gradient）算法扩展到确定性策略（deterministic policy）上。事实上，DPG 被证明是随机策略梯度（stochastic policy gradient）的一种特殊情况。</p><blockquote><p>随机策略梯度： <span class="math display">\[\triangledown_\theta J(\pi_\theta)=\mathbb{E}_{s\sim\rho^\pi, a\sim\pi_\theta}[\triangledown_\theta\log\pi_\theta(a|s)Q^\pi(s,a)]\]</span> 其中，<span class="math inline">\(\pi_\theta\)</span> 是由参数为 <span class="math inline">\(\theta\)</span> 的函数近似的策略，<span class="math inline">\(\rho^\pi\)</span> 为策略 <span class="math inline">\(\pi_\theta\)</span> 的状态分布（state distribution）。</p></blockquote><p>大部分 model-free 的增强学习算法属于泛化的<a href="https://www.52coding.com.cn/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/">策略迭代（policy iteration）</a>算法，一般分为两步：策略评估（policy evaluation） 和策略改进（ policy improvement）。策略评估通常使用 <a href="https://www.52coding.com.cn/2017/12/16/RL%20-%20Model-Free%20Prediction/#monte-carlo-learning">Monte-Carlo evaluation</a> 或 <a href="https://www.52coding.com.cn/2017/12/16/RL%20-%20Model-Free%20Prediction/#temporal-difference-learning">temporal difference learning</a> 来近似 <span class="math inline">\(Q^\pi(s, a)\)</span>。策略改进则通常通过最大化评估的 action-value 来得到：<span class="math inline">\(\mu^{k+1}(s) = \arg\max_aQ^{\mu^k}(s, a)\)</span>。</p><p>然而，在连续的动作空间（continuous action spaces）里这种最大化却是不可行的。在离散的动作空间里，我们可以为每个action计算相应 Q-value 然后进行比较；但是在连续的动作空间中，我们不可能把每个action的 Q-value 都计算出来再比较，而通过对 Q-function 求导求的方式计算最大值开销又很大。所以，取而代之的是单独用一个函数近似策略，然后<strong>用 Q-function 的梯度来改进该策略</strong>。具体来说，对于每个访问过的状态 <span class="math inline">\(s\)</span>，策略函数的参数 <span class="math inline">\(\theta^{k+1}\)</span> 根据 <span class="math inline">\(\triangledown_\theta Q^{\mu_k}(s, \mu_\theta(s))\)</span> 来更新： <span class="math display">\[\begin{align}\theta^{k+1}&amp;=\theta^k+\alpha\mathbb{E}_{s\sim\rho^{\mu^k}}[\triangledown_\theta Q^{\mu^k}(s, \mu_\theta(s))]\\&amp;= \theta^k + \alpha\mathbb{E}_{s\sim\rho^{\mu^k}}[\triangledown_\theta \mu_\theta(s)\triangledown_aQ^{\mu^k}(s, a)|_{a=\mu_\theta(s)}]\end{align}\]</span></p><p>可以证明，上述更新也属于策略梯度算法，这就是DPG算法的策略更新公式。</p><h2><span id="ddpg">DDPG</span></h2><p>DDPG改进了 Q-function 的学习方式，而策略端的更新方式和DPG相同，即如式(1)所示。在 DPG 中，Q-function 是通过 Q-learning 的方式来学习的，而当使用神经网络来近似 Q-function 的时候会导致训练不稳定，DDPG 应用了 <a href="https://www.52coding.com.cn/2018/11/16/RL%20-%20DQN%20and%20A3C/#deep-q-network">DQN</a> 中的两个trick来解决不稳定的问题，也就是<strong>经验池（replay buffer）</strong>和<strong>目标网络（target network）</strong>。</p><p>具体来说，经验池 <span class="math inline">\(D\)</span> 每次探索都会存储元组 <span class="math inline">\((s, a, r, s&#39;, d)\)</span>，其中 <span class="math inline">\(d\)</span> 为一个布尔变量，如果 <code>d == True</code>，就表明 <span class="math inline">\(s&#39;\)</span> 是终止状态（terminal state）。 每次更新时都会从经验池随机采样一批数据进行更新。经验池的大小是一个需要微调的超参数：如果经验池过小的话，会导致对池内数据过拟合；如果经验池存储所有数据的话，又会放慢学习的速度。</p><p>目标网络是指用单独的网络参数来生成目标（q-target），设策略函数的参数为 <span class="math inline">\(\theta\)</span>，Q-function 的参数为 <span class="math inline">\(\phi\)</span>，则对应的目标网络参数为 <span class="math inline">\(\theta_{tag}\)</span> 和 <span class="math inline">\(\phi_{tag}\)</span>，生成的目标为： <span class="math display">\[r + \gamma(1-d)Q_{\phi_{tag}}(s&#39;, \mu_{\theta_{tag}}(s&#39;))\]</span> 所以 Q-value 端的更新公式为： <span class="math display">\[\triangledown_\phi \mathbb{E}_{s,a,r,s&#39;,d\sim D}\left[\left(Q(s,a)-(r + \gamma(1-d)Q_{\phi_{tag}}(s&#39;, \mu_{\theta_{tag}}(s&#39;)))\right)^2\right]\]</span> 与DQN不同的是，DDPG中的目标网络使用“软更新”的方式，即目标网络并不是隔一定时间后与主网络同步，而是朝着主网络缓慢移动： <span class="math display">\[\theta_{tag}\leftarrow\tau\theta+(1-\tau)\theta_{tag}\\\phi_{tag}\leftarrow\tau\phi+(1-\tau)\phi_{tag}\]</span> 其中，<span class="math inline">\(\tau \in (0, 1)\)</span> 是一个超参数，通常取值接近 1。</p><p>为了增加探索能力，训练时在选择每个动作的时候都会加上随机噪声 <span class="math inline">\(\mathcal{N}\)</span>，论文作者建议使用时间相关的 <a href="https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process" target="_blank" rel="noopener">OU噪声</a>，但是最近的研究结果表明使用不相关的、zero-mean的高斯噪声效果会更好。同时为了取得更高质量的训练数据，噪声可以随着训练过程逐步减小。另外，在评测时应去掉噪声。</p><p><strong>DDPG算法</strong></p><p><img src="/images/ddpg_algo.svg"></p><h2><span id="总结">总结</span></h2><p><strong>特点</strong></p><ul><li>off-policy算法</li><li>只能用于连续的动作空间</li><li>可以看作是把DQN应用到连续动作空间</li></ul><h2><span id="references">References</span></h2><p>[1] http://proceedings.mlr.press/v32/silver14.pdf</p><p>[2] https://arxiv.org/abs/1509.02971</p><p>[3] https://spinningup.openai.com/en/latest/algorithms/ddpg.html</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> DQN </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> DPG </tag>
            
            <tag> DDPG </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Proximal Policy Optimization (PPO)</title>
      <link href="/2018/11/25/RL%20-%20PPO/"/>
      <url>/2018/11/25/RL%20-%20PPO/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1707.06347" target="_blank" rel="noopener">Proximal Policy Optimization (PPO, PPO-Clip, PPO-Penalty)</a> 是由<a href="https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/">TRPO</a>的作者Schulman等人于2017年提出的策略梯度类算法。PPO算法的思路和TRPO一致，都是想在优化时采取尽可能大的步幅但又不能太大以至于产生崩坏。相比于比TRPO，PPO实现起来更简单，泛化能力更强，可以使用随机梯度下降（SGD）进行优化。</p><a id="more"></a><h2><span id="背景">背景</span></h2><p>PPO的背景与<a href="https://www.52coding.com.cn/2018/11/22/RL%20-%20TRPO/#背景">TRPO的背景</a>一致，最终TRPO推导出如下的带约束优化问题： <span class="math display">\[\max_{\theta}\mathbb{E}_t[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t]\\\text{subject to }\mathbb{E}_t[\text{KL}[\pi_{\theta_{old}}(\cdot|s_t), \pi_\theta(\cdot|s_t)]]\]</span> 令 <span class="math inline">\(r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\)</span> 为新旧策略的概率比（易知 <span class="math inline">\(r_t(\theta_{old}) = 1\)</span>）。TRPO最大化的替代目标（surrogate objective）可以写为如下形式： <span class="math display">\[L^{CPI}(\theta)=\mathbb{E}_t[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t]=\mathbb{E}_t[r_t(\theta)A_t]\]</span> 如果不加约束的话，直接优化该目标会产生巨大的更新，导致更新不稳定甚至崩溃。所以需要考虑一种惩罚方法，使 <span class="math inline">\(r_t(\theta)\)</span> 接近 <span class="math inline">\(1\)</span>。</p><h2><span id="ppo-clip">PPO-Clip</span></h2><p>PPO-Clip的目标函数为： <span class="math display">\[L^{CLIP}(\theta)=\mathbb{E}_t[\min(r_t(\theta)A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)A_t)]\]</span> 其中 <span class="math inline">\(\epsilon\)</span> 为超参数控制截断率，取值通常比较小（0.2左右）。</p><p>上述目标函数的第一项与 <span class="math inline">\(L^{CPI}\)</span> 一致，第二项则是为了限制更新幅度（施加惩罚），控制 <span class="math inline">\(r_t(\theta) \in [1-\epsilon, 1+\epsilon]\)</span>。可见 <span class="math inline">\(L^{CLIP}(\theta)\)</span> 是 <span class="math inline">\(L^{CPI}(\theta)\)</span> 的一个下界。</p><p><img src="/images/lclip.png"></p><p>上图显示了 <span class="math inline">\(\text{clip}\)</span> 函数的工作方式：</p><ul><li>当 <span class="math inline">\(A &gt; 0\)</span> 时，如果想使目标函数取得更大的值，就需要增大 <span class="math inline">\(\pi_\theta(a_t|s_t)\)</span> 的值，也就是增大 <span class="math inline">\(r_t(\theta)\)</span> 。但是式中的 <span class="math inline">\(\min\)</span> 函数限制了 <span class="math inline">\(r_t(\theta)\)</span> 最大取到 <span class="math inline">\(1+\epsilon\)</span>，所以新策略再远离旧策略（<span class="math inline">\(r_t(\theta)\)</span> 继续增大）并不会带来更多地好处。</li><li>当 <span class="math inline">\(A &lt; 0\)</span> 时，如果想使目标函数取得更大的值，就需要减小 <span class="math inline">\(\pi_\theta(a_t|s_t)\)</span> 的值，也就是减小 <span class="math inline">\(r_t(\theta)\)</span> 。但是式中的 <span class="math inline">\(\min\)</span> 函数限制了 <span class="math inline">\(r_t(\theta)\)</span> 最小取到 <span class="math inline">\(1-\epsilon\)</span>，所以新策略再远离旧策略（<span class="math inline">\(r_t(\theta)\)</span> 继续减小）并不会带来更多地好处。</li></ul><p>在实现中，目标函数通常使用更简单的形式： <span class="math display">\[L^{CLIP}(s, a, \theta_k, \theta)=\min(\frac{\pi_\theta(a|s)}{\pi_{\theta_{k}}(a|s)}A^{\pi_{\theta_k}}(s, a), g(\epsilon, A^{\pi_{\theta_k}}(s, a)))\]</span> 其中， <span class="math display">\[g(\epsilon, A^{\pi_{\theta_k}}(s, a))=\begin{cases} (1+\epsilon)A,  &amp; \mbox{if }A ≥0 \\(1-\epsilon)A, &amp; \mbox{if }A&lt;0\end{cases}\]</span></p><blockquote><p>注：即便对 <span class="math inline">\(r_t(\theta)\)</span> 加上截断，新策略仍染有可能偏离旧策略很远，不过有很多trick来处理这个问题。其中一个特别简单的处理方式就是：如果新策略和旧策略的平均KL距离大于某个阈值，则停止进行更新（<strong>early stopping</strong>）。</p></blockquote><p>相比于TRPO，由于没有了KL约束，PPO可以用SGD来进行优化，实现简单很多。</p><p><strong>PPO-Clip算法</strong></p><p><img src="/images/ppo_algo.svg"></p><h2><span id="ppo-penalty">PPO-Penalty</span></h2><p>这种方法使用KL距离作为惩罚项，关键在于求出能够自适应多种任务的惩罚因子 <span class="math inline">\(\beta\)</span>。算法的逻辑为，在每次策略进行更新时：</p><ul><li><p>使用SGD优化目标函数： <span class="math display">\[L^{KLPEN}(\theta)=\mathbb{E}_t\left[\frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}A_t-\beta\cdot\text{KL}[\pi_{old}(a_t|s_t), \pi_\theta(a_t|s_t)]\right]\]</span></p></li><li><p>计算 <span class="math inline">\(d = \mathbb{E}\left[\text{KL}[\pi_{\theta_{old}}(\cdot|s_t), \pi_\theta(\cdot|s_t)]\right]\)</span></p><ul><li>如果 <span class="math inline">\(d &lt; d_{targ}/1.5\)</span>，则 <span class="math inline">\(\beta \leftarrow \beta/2\)</span></li><li>如果 <span class="math inline">\(d &gt; d_{targ} \times 1.5\)</span>，则 <span class="math inline">\(\beta \leftarrow\beta \times 2\)</span></li></ul><p>其中，<span class="math inline">\(d_{targ}\)</span> 为超参数。</p></li></ul><blockquote><p>注：PPO-Penalty 没有 PPO-Clip 效果好。</p></blockquote><h2><span id="实验和总结">实验和总结</span></h2><p><strong>特点</strong></p><ul><li>训练稳定</li><li>通过限制 <span class="math inline">\(r_t(\theta)\)</span> 来找到尽可能大的并且合理的步长</li><li>on-policy 算法</li><li>可用于离散和连续的动作空间</li><li>相比于TRPO，PPO实现简单，效果更好</li></ul><p><strong>实验性能</strong></p><p>在大部分 MuJoCo 环境中强于其他策略梯度类算法，在Atari环境中，表现仅次于ACER，但是学习速度优于ACER。</p><p><img src="/images/ppo_mujoco.png"></p><p><img src="/images/ppo_atari.png"></p><h3><span id="代码">代码</span></h3><p>自己也实现了一下PPO-Clip算法，代码在<a href="https://github.com/NeymarL/Pacman-RL/blob/master/src/ppo.py" target="_blank" rel="noopener">这里</a>。下图显示了在 OpenAI <a href="https://gym.openai.com/" target="_blank" rel="noopener">Gym</a> 上的 <code>MsPacman-ram-v0</code> 环境上的测试结果：</p><p><img src="/images/ppo_pacman.png"></p><p><img src="/images/sample1.gif"></p><p><img src="/images/sample2.gif"></p><h2><span id="references">References</span></h2><p>[1] https://arxiv.org/abs/1707.06347</p><p>[2] https://spinningup.openai.com/en/latest/algorithms/ppo.html</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> PPO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Trust Region Policy Optimization (TRPO)</title>
      <link href="/2018/11/22/RL%20-%20TRPO/"/>
      <url>/2018/11/22/RL%20-%20TRPO/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1502.05477" target="_blank" rel="noopener">Trust Region Policy Optimization (TRPO)</a>算法是由伯克利大学的Schulman等人于2015年提出的策略梯度（Policy Gradients）算法。TRPO通过最大化新策略相对于当前策略的优势来保证每次更新都是单调递增的（稳定），同时找到尽可能大的更新步幅。算法推导出的最终结果是在KL约束下最大化替代优势函数。</p><a id="more"></a><h2><span id="背景">背景</span></h2><p>考虑经典的 MDP<span class="math inline">\(&lt;S, A, P, r, \rho_0, \gamma&gt;\)</span>，其中 <span class="math inline">\(S\)</span> 是所有状态（state）的集合，<span class="math inline">\(A\)</span> 是所有动作（action）的集合，<span class="math inline">\(P: S\times A\times S \rightarrow \mathbb{R}\)</span> 是转移概率分布，<span class="math inline">\(r\)</span> 是奖励（reward）函数，<span class="math inline">\(\rho_0\)</span> 是初始状态（<span class="math inline">\(s_0\)</span>）分布，<span class="math inline">\(\gamma\)</span> 是折扣因子（ discount factor）。</p><p>定义 <span class="math inline">\(\pi\)</span> 为一个随机策略：<span class="math inline">\(\pi: S\times A\rightarrow [0, 1]\)</span>，定义 <span class="math inline">\(\eta(\pi)\)</span> 来衡量策略 <span class="math inline">\(\pi\)</span> 的好坏： <span class="math display">\[\eta(\pi)=\mathbb{E}_{s_0, a_0, ...\sim\pi}[\sum_{t=0}^\infty\gamma^tr(s_t)]\]</span> 接着定义 state-action value function <span class="math inline">\(Q_\pi\)</span>, value function <span class="math inline">\(V_\pi\)</span>, 优势函数（advantage function）<span class="math inline">\(A_\pi\)</span>: <span class="math display">\[Q_\pi(s_t, a_t) = \mathbb{E}_{s_{t+1}, a_{t+1}, ...\sim\pi}[\sum_{l=0}^\infty\gamma^lr_{s_{t+l}}]\]</span></p><p><span class="math display">\[V_\pi(s_t) =\mathbb{E}_{a_t, s_{t+1}, ...\sim\pi}[\sum_{l=0}^\infty\gamma^lr_{s_{t+l}}]\]</span></p><p><span class="math display">\[A_\pi(s, a) = Q_\pi(s, a) - V_\pi(s)\]</span></p><p>然后可以通过下式来衡量策略 <span class="math inline">\(\tilde{\pi}\)</span> 相对于策略 <span class="math inline">\(\pi\)</span> 的优势（证明详见论文）： <span class="math display">\[\begin{align}\eta(\tilde{\pi})&amp;=\eta(\pi)+\mathbb{E}_{s_0, a_0, ...\sim\color{red}{\tilde{\pi}}}[\sum_{t=0}^\infty\gamma^tA_\pi(s_t,a_t)]\\&amp;= \eta(\pi)+\sum_s\color{red}{\rho_\tilde{\pi}(s)}\sum_a\tilde{\pi}(a|s)A_\pi(s, a)\end{align}\]</span> 其中 <span class="math inline">\(\rho_\pi\)</span> 为策略 <span class="math inline">\(\pi\)</span> 的折扣访问频率（discounted visitation frequency）： <span class="math display">\[\rho_\pi(s) = P(s_0=s)+\gamma P(s_1=s) + \gamma^2 P(s_2=s)+...\]</span> 通过上式可知，只要每个状态 <span class="math inline">\(s\)</span> 的期望优势非负，即 <span class="math inline">\(\sum_a\tilde{\pi}(a|s)A_\pi(s, a)&gt;0\)</span>，就可以保证更新是单调非递减的，这其实就是经典的<a href="https://www.52coding.com.cn/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/">策略迭代（policy iteration）</a>的更新方式。然而，由于 <span class="math inline">\(\rho_\tilde{\pi}(s)\)</span> 的存在，导致直接优化上式很困难，所以引入一个<strong>替代优势</strong>（surrogate advantage）： <span class="math display">\[\begin{align}L_\pi(\tilde{\pi})&amp;=\eta(\pi)+\sum_s\color{red}{\rho_\pi(s)}\sum_a\tilde{\pi}(a|s)A_\pi(s, a)\\\end{align}\]</span> 经过一系列推导，可以得到策略 <span class="math inline">\(\tilde{\pi}\)</span> 的优势下界： <span class="math display">\[\eta(\tilde{\pi})≥L_\pi(\tilde{\pi})-C\cdot D_{KL}^\max(\pi, \tilde{\pi})\]</span> 其中，<span class="math inline">\(C=\frac{4\epsilon\gamma}{(1-\gamma)^2}\)</span>，<span class="math inline">\(D_{KL}^\max\)</span> 是最大的KL散度。</p><p>这里相当于对优化目标 <span class="math inline">\(L_\pi(\tilde{\pi})\)</span> 进行了惩罚，惩罚因子为 <span class="math inline">\(C\)</span>，惩罚项为KL散度，目的是限制新旧策略的差距。通过最大化上述公式，就能最大化新策略 <span class="math inline">\(\tilde{\pi}\)</span> 所得到的奖励，同时又不会离旧策略 <span class="math inline">\(\pi\)</span> 太远（导致对当前数据过拟合），算法如下：</p><p><img src="/images/IMG_1925FD469BD9-1.jpeg"></p><h2><span id="trpo">TRPO</span></h2><p>由于Deep RL都是使用参数为 <span class="math inline">\(\theta\)</span> 的神经网络来拟合策略 <span class="math inline">\(\pi_\theta\)</span>，为了使公式更简洁，把算法1中公式的 <span class="math inline">\(\pi\)</span> 替换成 <span class="math inline">\(\theta\)</span>: <span class="math display">\[\theta = \arg\max_{\theta}[L(\theta_{old}, \theta)-C\cdot D_{KL}^\max(\theta_{old}|| \theta)]\]</span> 其中， <span class="math display">\[\begin{align}L(\theta_{old}, \theta) &amp;= \sum_s\rho_{\theta_{old}}(s)\sum_a\pi_\theta(a|s)A_{\theta_{old}}(s,a) \\&amp;= \mathbb{E}_{s,a\sim\pi_{\theta_{old}}}[\frac{\pi_\theta(a|s)}{\pi_{\theta_{old}}(a|s)}A_{\theta_{old}}(s,a)]\end{align}\]</span> TRPO是算法1的近似，区别在于：TRPO没有使用惩罚项 <span class="math inline">\(C\)</span>，而是使用 KL散度约束（i.e. trust region constraint）： <span class="math display">\[\theta = \arg\max_\theta L(\theta_{old}, \theta)\\\text{ s.t. }\bar{D}_{KL}(\theta||\theta_{old})≤\delta\]</span> 其中，<span class="math inline">\(\bar{D}_{KL}\)</span> 是平均KL散度： <span class="math display">\[\bar{D}_{KL}(\theta||\theta_{old})=\mathbb{E}_{s\sim\pi_{\theta_{old}}}[D_{KL}(\pi_{\theta}(\cdot|s)||\pi_{\theta_{old}}(\cdot|s))]\]</span> 然而上面的带约束优化也并非容易，所以TRPO对上式进行了一些近似，对目标函数和约束进行泰勒展开可以得到： <span class="math display">\[L(\theta_{old}, \theta) \approx g^T(\theta-\theta_{old})\]</span></p><p><span class="math display">\[\bar{D}_{KL}(\theta||\theta_{old})\approx \frac{1}{2}(\theta-\theta_{old})^TH(\theta-\theta_{old})\]</span></p><p>其中，<span class="math inline">\(g\)</span> 是替代函数的梯度在 <span class="math inline">\(\theta=\theta_{old}\)</span> 处的值，凑巧的是，它和策略梯度的值正好相等：<span class="math inline">\(g = \triangledown_\theta J(\pi_\theta)|_{\theta_{old}}\)</span>；<span class="math inline">\(H\)</span> 是对于 <span class="math inline">\(\theta\)</span> 的海森矩阵（Hessian matrix）。</p><p>于是得到如下的近似优化问题： <span class="math display">\[\theta_{k+1}=\arg\max_\theta g^T(\theta-\theta_k)\\\text{s.t. }\frac{1}{2}(\theta-\theta_k)^TH(\theta-\theta_k)≤\delta\]</span> 通过拉格朗日法求解上述约束优化问题得： <span class="math display">\[\theta_{k+1}=\theta_k+\sqrt{\frac{2\delta}{g^TH^{-1}g}}H^{-1}g\]</span> 这个就是 <a href="https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf" target="_blank" rel="noopener">Natural Policy Gradient</a> 的更新公式。不过，由于泰勒近似引入了误差，上式的解可能不满足 KL 约束，所以 TRPO 增加了一个线性搜索（backtracking line search）： <span class="math display">\[\theta_{k+1}=\theta_k+\alpha^j\sqrt{\frac{2\delta}{g^TH^{-1}g}}H^{-1}g\]</span> 其中，<span class="math inline">\(\alpha\in(0,1)\)</span> 是回溯系数（backtracking coefficient），<span class="math inline">\(j\)</span> 是最小的非负整数使得 <span class="math inline">\(\pi_{\theta_{k+1}}\)</span> 满足 KL 约束并且产生<strong>正</strong>的替代优势，这样就可以保证训练进步是单调的。</p><p>最后，计算和存储 <span class="math inline">\(H^{-1}\)</span> 的开销是很大的，尤其是神经网络的参数动不动就几M。TRPO 使用<a href="https://www.wikiwand.com/en/Conjugate_gradient_method" target="_blank" rel="noopener">共轭梯度法（conjugate gradient）</a>来解 <span class="math inline">\(Hx = g\)</span>，这样就不用直接计算和存储 <span class="math inline">\(H\)</span>。</p><p>最终的更新公式为： <span class="math display">\[\theta_{k+1}=\theta_k+\alpha^j\sqrt{\frac{2\delta}{\hat{x}^TH\hat{x}}}\hat{x}\]</span> 其中， <span class="math display">\[\begin{align}\hat{x}&amp;\approx H^{-1}g &amp; \text{(using conjugate gradient)}\end{align}\]</span></p><p><span class="math display">\[H\hat{x} = \triangledown_\theta((\triangledown_\theta\bar{D}_{KL}(\theta||\theta_k))^T\hat{x})\]</span></p><p><strong>TRPO算法</strong></p><p><img src="/images/trpo.svg"></p><h2><span id="performance">Performance</span></h2><p><strong>TRPO的一些特点</strong></p><ul><li>保证每次更新在当前训练数据上都是进步的，训练过程更加稳定</li><li>通过满足KL约束来找尽可能大的步长</li><li>on-policy 算法</li><li>可用于离散和连续的动作空间</li><li>算法较为复杂</li></ul><p><strong>实验性能</strong></p><p>在模拟机器人走路、游泳等任务中取得了在当时不错的效果；在通过视频输入玩Atari游戏的任务中表现不如DQN等方法。</p><p><img src="/images/trpo_per.jpg"></p><p>下图是我在 OpenAI <a href="https://gym.openai.com/" target="_blank" rel="noopener">Gym</a> 的 <code>Walker2d-v2</code> 和 <code>MsPacman-ram-v0</code> 中测试的结果。</p><p><img src="/images/walker.png"></p><p><img src="/images/pacman.png"></p><h2><span id="references">References</span></h2><p>[1] https://arxiv.org/abs/1502.05477</p><p>[2] https://spinningup.openai.com/en/latest/algorithms/trpo.html</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> TRPO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - DQN &amp; A3C &amp; GAE</title>
      <link href="/2018/11/16/RL%20-%20DQN%20and%20A3C/"/>
      <url>/2018/11/16/RL%20-%20DQN%20and%20A3C/</url>
      
        <content type="html"><![CDATA[<h2><span id="deep-q-network">Deep Q-Network</span></h2><p>Deep Q-Network (<a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf" target="_blank" rel="noopener">DQN</a>) 是由DeepMind的Mnih等人于2013年提出的算法，该算法成功把深度学习应用到了RL领域，并（一定程度上）解决了训练不稳定的问题，在玩Atari游戏中取得了非常好的结果。</p><p>文章指出使用非线性函数拟合 Q-value 的RL算法不稳定主要因为：</p><ol type="1"><li>同一个观测序列中的数据相关性较大</li><li>当 Q-value 发生了很小的改变，可能导致整个策略（policy）发生较大变化，从而导致 Q-value 和目标 <span class="math inline">\(r + \gamma * \max_{a&#39;}Q(s&#39; ,a&#39;)\)</span> 的差距不稳定</li></ol><a id="more"></a><p>DQN使用了两个trick来解决上述问题：</p><ul><li>Experience replay<ul><li>使用经验池缓存数据，每次训练时从经验池里sample数据，从而降低训练数据之间的相关性</li></ul></li><li>Two Q networks<ul><li>一个网络用来生成 Q-target，另一个网络进行探索；每隔一定时间两个网络进行同步</li><li>这样使得 Q-target 相对稳定</li></ul></li></ul><p><strong>整体算法</strong></p><p><img src="/images/dqn.jpg"></p><hr><h2><span id="asynchronous-actor-critic">Asynchronous Actor Critic</span></h2><p>Asynchronous Actor Critic (<a href="https://arxiv.org/abs/1602.01783" target="_blank" rel="noopener">A3C</a>) 也是由DeepMind的Mnih等人提出的算法，于2016年发表在ICML上。不同于DQN的是，A3C属于策略梯度（Policy Gradient）类算法，而DQN是基于value的；相同的是，A3C也在Atari游戏上取得了非常好的结果（强于DQN）。</p><p>使用上述经验池有以下问题：</p><ol type="1"><li>使用更多的内存和计算资源</li><li>只能使用 <strong>off-policy</strong> 的RL算法（学习 old policy 产生的数据）</li></ol><p>为了使用 on-policy 算法，文章提出了使用异步学习代替经验池的方法，同时也能保持算法的稳定性，其中使用最广泛的是A3C算法，它具有以下特点：</p><ul><li>并行地使用多个 agent 在各自的环境里探索，每个 agent 在同一时刻探索的内容各不相同，从而降低了数据相关性</li><li>在CPU上训练更加高效</li></ul><p><strong>整体算法</strong></p><ol type="1"><li>同步线程专属网络（<span class="math inline">\(\theta&#39;, \theta_v&#39;\)</span>）和全局网络（<span class="math inline">\(\theta, theta_v\)</span>）</li><li>每个 agent 使用线程专属网络各自进行探索</li><li>根据线程专属网络计算梯度：<span class="math inline">\(d\theta, d\theta_v\)</span></li><li>使用 <span class="math inline">\(d\theta, d\theta_v\)</span> 更新全局网络（<span class="math inline">\(\theta, theta_v\)</span>）</li><li>回到第一步</li></ol><p><img src="/images/IMG_25EB14880DD1-1.jpeg"></p><p><strong>其他细节</strong></p><ul><li><strong>主线程向子线程传参数，子线程向主线程传梯度</strong></li><li>agent 和 critic 共用一个网络，输出分为两头</li><li>增加了熵正则化（鼓励探索）<ul><li><span class="math inline">\(\triangledown_{\theta&#39;}\log\pi(a_t|s_t;\theta&#39;)(R_t-V(s_t;\theta_v))+\beta\triangledown_{\theta&#39;}H(\pi(s_t; \theta&#39;))\)</span></li><li><span class="math inline">\(H(X) = E[-\log P(X)]\)</span></li></ul></li><li>代码参考：https://github.com/NeymarL/Pacman-RL/blob/master/src/a3c.py<ul><li><strong>注</strong>：计算 policy loss 中的 advantage 的时候不能保留其梯度，否则 policy 的梯度会流入 value network 中，产生bug</li></ul></li></ul><hr><h2><span id="generalized-advantage-estimator">Generalized Advantage Estimator</span></h2><p>Generalized Advantage Estimator (<a href="https://arxiv.org/abs/1506.02438" target="_blank" rel="noopener">GAE</a>) 是由伯克利大学的Schulman等人于2016年提出的一种新的估计优势函数（Advantage function）的方法。</p><p>我们的目标是定义优势函数 <span class="math inline">\(A^\pi(s_t, a_t)\)</span> 使其用来计算策略梯度： <span class="math display">\[\hat{g}=\mathbb{E}_{s_0, a_0...\sim\pi_\theta}[\sum_{t=0}^\infty A^\pi_t(s_t,a_t)\triangledown_\theta\pi_\theta(a_t|s_t)]\]</span> 优势函数的定义为： <span class="math display">\[A^\pi(s_t, a_t) = Q^\pi(s_t, a_t) - V^\pi(s_t)\]</span> 我们使用 <span class="math inline">\(V\)</span> 来近似价值函数（value function），那么 TD(0) error <span class="math inline">\(\delta_t^V = r_t +\gamma V(s_{t+1}-V(s_t))\)</span> 就是优势函数的一个估计，并且如果 <span class="math inline">\(V = V^\pi\)</span>，则 <span class="math inline">\(\delta_t^V\)</span> 是 <span class="math inline">\(A^\pi\)</span> 的一个无偏估计： <span class="math display">\[\begin{align}\mathbb{E}_{s_{t+1}}[\delta_t^{V^\pi}]&amp;=\mathbb{E}_{s_{t+1}}[r_t+\gamma V^\pi(s_{t+1})-V^\pi(s_t)]\\&amp;= \mathbb{E}_{s_{t+1}}[Q^\pi(s_t,a_t)-V^\pi(s_t)]\\&amp;= A^\pi(s_t,a_t)\end{align}\]</span> 只要 <span class="math inline">\(V\)</span> 是近似的，TD(0) error就是优势函数的一个有偏估计，那么TD(<span class="math inline">\(\lambda\)</span>) error又如何呢？</p><p>顺着这个思路，我们可以多往后看几步： <span class="math display">\[\begin{array}{lcl}\hat{A}_t^{(1)}&amp;:=\delta_t^V&amp;=-V(s_t)+r_t+\gamma V(s_{t+1})\\\hat{A}_t^{(2)}&amp;:=\delta_t^V + \gamma\delta_{t+1}^V&amp;=-V(s_t)+r_t+\gamma r_{t+1}+\gamma^2 V(s_{t+2})\\\hat{A}_t^{(3)}&amp;:=\delta_t^V + \gamma\delta_{t+1}^V+\gamma^2\delta_{t+2}^V &amp;=-V(s_t)+r_t+\gamma r_{t+1}+\gamma^2 r_{t+2} +\gamma^2 V(s_{t+3}) \\\end{array}\]</span></p><p><span class="math display">\[\hat{A}_t^{k}:=\sum_{l=0}^{k-1}\gamma^l\delta_{t+l}^V=-V(s_t)+r_t+\gamma r_{t+1}+...+\gamma^{k-1}r_{t+k-1}+\gamma^kV(s_{t+k})\]</span></p><p>可以看到，虽然 <span class="math inline">\(\hat{A}_t^{(k)}\)</span> 依旧是有偏估计，但是偏差随着 <span class="math inline">\(k\)</span> 的增大在逐渐减小，因为 <span class="math inline">\(\gamma^kV(s_{t+k})\)</span> 这一项衰减的越来越厉害。当 <span class="math inline">\(k\rightarrow\infty\)</span> 时： <span class="math display">\[\hat{A}_t^{(\infty)}=\sum_{l=0}^\infty\gamma^l\delta_{t+l}^V=-V(s_t)+\sum_{l=0}^\infty\gamma^lr_{t+l}\]</span> 可以看到就是 return 减去 baseline。</p><p><span class="math inline">\(\text{GAE}(\lambda)\)</span> 的定义为这些 <span class="math inline">\(k\)</span> 步估计的指数平均，即 TD(<span class="math inline">\(\lambda\)</span>) error： <span class="math display">\[\begin{align}\text{GAE}_t(\lambda)&amp;:=(1-\lambda)(\hat{A}_t^{(1)}+\lambda\hat{A}_t^{(2)}+\lambda^2\hat{A}_t^{(3)}+...)\\&amp;=(1-\lambda)(\delta_t^V+\lambda(\delta_t^V-\gamma\delta_{t+1}^V)+...)\\&amp;=\sum_{l=0}^\infty(\gamma\lambda)^l\delta_{t+l}^V\end{align}\]</span> 代码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rews : rewards, vals: values, lam: lambda</span></span><br><span class="line">deltas = rews[:<span class="number">-1</span>] + gamma * vals[<span class="number">1</span>:] - vals[:<span class="number">-1</span>]</span><br><span class="line">adv_buf = discount_cumsum(deltas, gamma * lam)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discount_cumsum</span><span class="params">(x, discount)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    magic from rllab for computing discounted cumulative sums of vectors.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    input: </span></span><br><span class="line"><span class="string">        vector x, </span></span><br><span class="line"><span class="string">        [x0, </span></span><br><span class="line"><span class="string">         x1, </span></span><br><span class="line"><span class="string">         x2]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    output:</span></span><br><span class="line"><span class="string">        [x0 + discount * x1 + discount^2 * x2,  </span></span><br><span class="line"><span class="string">         x1 + discount * x2,</span></span><br><span class="line"><span class="string">         x2]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> scipy.signal.lfilter([<span class="number">1</span>], [<span class="number">1</span>, float(-discount)], x[::<span class="number">-1</span>], axis=<span class="number">0</span>)[::<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><hr><h2><span id="其他">其他</span></h2><h3><span id="batch-normalization">Batch-Normalization</span></h3><p>解决网络层数变多梯度<strong>消失</strong>/爆炸问题</p><ul><li>梯度截断</li><li>初始化</li><li>RELU</li></ul><p>对每层神经元处理结果进行归一化，但又不能破坏上一层提取的特征（变换重构，引入了可学习参数<span class="math inline">\(\gamma, \beta\)</span>）</p><figure><img src="/images/bn.png" alt="bn"><figcaption>bn</figcaption></figure><p>Inference时 <span class="math inline">\(\mu_B\)</span> 和 <span class="math inline">\(\sigma^2_B\)</span> 固定。</p><p>为什么不用白化？</p><ul><li>在模型训练过程中进行白化操作会带来过高的计算代价和运算时间</li></ul><p>在BN中，是通过将activation规范为均值和方差一致的手段使得原本会减小的activation的scale变大。 <span class="math display">\[\frac{\partial h_l}{\partial h_{l-1}} = \frac{\partial BN(w_l h_{l-1})}{\partial h_{l-1}} = \frac{\partial \alpha w_l h_{l-1}}{\partial h_{l-1}}\]</span> 其中 <span class="math inline">\(\alpha\)</span> 指缩放。可以看到此时反向传播乘以的数不再和 <span class="math inline">\(w\)</span> 的尺度相关，也就是说尽管我们在更新过程中改变 <span class="math inline">\(w\)</span> 的值，但是反向传播的梯度却不受影响。</p><h3><span id="activation-layers">Activation Layers</span></h3><h4><span id="relu">ReLU</span></h4><figure><img src="/images/relu.png" alt="relu"><figcaption>relu</figcaption></figure><p>整流线性单元易于优化，因为它们和线性单元非常类似。线性单元和整流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为零。这使得只要整流线性单元处于激活状态，它的导数都能保持较大。它的梯度不仅大而且一致。整流操作的二阶导数几乎处处为 0，并且在整流线性单元处于激活状态时，它的一阶导数处处为 1。这意味着相比于引入二阶效应的激活函数来说，它的梯度方向对于学习来说更加有用。</p><p>ReLU 的过程更接近生物神经元的作用过程</p><p><strong>Leaky ReLU</strong></p><p>ReLU 及其扩展都是基于一个原则，那就是如果它们的行为更接近线性，那么模型更容易优化。 <span class="math display">\[g(z; \alpha) = \max(0, z) + \alpha \min(0, z)\]</span> <span class="math inline">\(\alpha\)</span> 为固定值或可学习参数。</p><h4><span id="sigmoid-amp-tanh">Sigmoid &amp; Tanh</span></h4><p><img src="/images/sigmoid.png" alt="sigmoid"> <span class="math display">\[g(z) = \frac{1}{1 + e^{-z}}\]</span></p><ul><li>sigmoid 常作为输出单元用来预测二值型变量取值为 1 的概率</li><li>sigmoid 函数在输入取绝对值非常大的正值或负值时会出现<strong>饱和</strong>（saturate）现象，在图像上表现为开始变得很平，此时函数会对输入的微小改变会变得不敏感。仅当输入接近 0 时才会变得敏感。从而使得学习变困难。</li><li>如果要使用 sigmoid 作为激活函数时（浅层网络），tanh 通常要比 sigmoid 函数表现更好。</li></ul><h3><span id="bagging">Bagging</span></h3><p>思想：多个模型平均效果好于单个模型</p><p><strong>Bagging（bootstrap aggregating）</strong>是通过结合几个模型降低泛化误差的技术 (Breiman, 1994)。</p><p>具体来说，Bagging 涉及构造 k 个<strong>不同的数据集</strong>。每个数据集从原始数据集中<strong>重复采样</strong>构成，和原始数据集具有<strong>相同数量</strong>的样例。这意味着，每个数据集以高概率缺少一些来自原始数据集的例子，还包含若干重复的例子（更具体的，如果采样所得的训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 <strong>2/3</strong> 的实例）</p><figure><img src="/images/bagging.png" alt="bagging"><figcaption>bagging</figcaption></figure><p>第一个分类器学到上面的圆圈就会认为数字是8，第二个分类器检测到下面的圈就会认为数字是8，把两个结合起来就知道只有当上下都有圈（置信概率最大）的时候数字才是8。</p><h3><span id="dropout">Dropout</span></h3><p>简单来说，Dropout (Srivastava et al., 2014) 通过<strong>参数共享</strong>提供了一种廉价的 <strong>Bagging</strong> 集成近似，能够训练和评估<strong>指数级数量</strong>的神经网络。</p><figure><img src="/images/dropout.png" alt="dropout"><figcaption>dropout</figcaption></figure><p><strong>Dropout与Bagging的不同点</strong>：</p><ul><li>Bagging 为串行策略；Dropout 为并行策略</li><li>在 Bagging 的情况下，所有模型都是独立的；而在 Dropout 的情况下，所有模型<strong>共享参数</strong>，其中每个模型继承父神经网络参数的不同子集。</li><li>在 Bagging 的情况下，每一个模型都会在其相应训练集上训练到收敛。而在 Dropout 的情况下，通常大部分模型都没有显式地被训练；取而代之的是，在单个步骤中我们训练一小部分的子网络，参数共享会使得剩余的子网络也能有好的参数设定。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Q-learning </tag>
            
            <tag> DQN </tag>
            
            <tag> A3C </tag>
            
            <tag> GAE </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>中国象棋Zero技术详解</title>
      <link href="/2018/11/07/CCZero/"/>
      <url>/2018/11/07/CCZero/</url>
      
        <content type="html"><![CDATA[<p><a href="https://cczero.org/" target="_blank" rel="noopener">中国象棋Zero（CCZero）</a>是一个开源项目，把<a href="https://arxiv.org/abs/1712.01815" target="_blank" rel="noopener">AlphaZero</a>的算法应用到了中国象棋上，旨在借助广大象棋爱好者之力一起训练出一个可以打败旋风名手的“象棋之神”。因为种种原因吧，这个目标到目前（2018/11/07）为止未能实现，或者说还差得远，而跑谱的人也越来越少了，很可能坚持不了多久了。</p><p>虽然未能实现目标，但在技术上还是有一定意义的，<a href="https://github.com/NeymarL/ChineseChess-AlphaZero" target="_blank" rel="noopener">GitHub</a>上也时不时有人询问技术细节，在此总结一下，记录一些坑以后不要再踩。</p><a id="more"></a><h2><span id="模块">模块</span></h2><p>程序主要分为三大模块（每个模块对应一个目录）：</p><ul><li><code>agents</code>：核心模块，决定如何下棋<ul><li><code>model.py</code>：神经网络模型</li><li><code>player.py</code>：MCTS，输出走法</li><li><code>api.py</code>：供外界调用model</li></ul></li><li><code>envrionment</code>：象棋规则<ul><li>训练（跑谱）使用<code>static_env.py</code>，速度快一些</li><li>用自带GUI下棋时使用的是<code>env.py</code>, <code>chessboard.py</code>这些，可以输出PNG格式的棋谱</li></ul></li><li><code>worker</code>：把agent和envrionment串联起来的脚本<ul><li><code>self_play.py</code>：自我博弈</li><li><code>compute_elo.py</code>：评测并上传结果到官网</li><li><code>optimize.py</code>：训练棋谱</li><li><code>_windows</code>后缀表示是在Windows平台上运行的相应功能，之所以分开是因为两个多进程的启动方式不同，导致代码结构也要发生一些变化，详见<a href="#自我博弈">自我博弈</a>。</li></ul></li></ul><h3><span id="神经网络模型">神经网络模型</span></h3><p><strong>网络输入</strong>：<span class="math inline">\(14\times10\times9\)</span></p><ul><li><span class="math inline">\(10 \times 9\)</span> 是中国象棋棋盘的大小</li><li><span class="math inline">\(14\)</span> 是所有棋子种类（红/黑算不同种类）</li><li>整体的输入就是14个棋盘堆叠在一起，每个棋盘表示一种棋子的位置：棋子所在的位置为1，其余位置为0。</li></ul><p><strong>网络输出</strong></p><ul><li>策略头（policy head）输出：<span class="math inline">\(2086\)</span><ul><li><span class="math inline">\(2086\)</span> 是行动空间的大小。行动空间就是说根据中国象棋的规则，任意棋子在任意位置的走法集合。</li></ul></li><li>价值头（value head）输出：<span class="math inline">\(1\)</span><ul><li>价值头输出一个标量衡量当前局势 <span class="math inline">\(v\in[-1, 1]\)</span>：当 <span class="math inline">\(v\)</span> 接近1时，局势大好；接近0为均势；接近-1为败势。</li></ul></li></ul><p>附：棋子编号表</p><table><thead><tr class="header"><th>棋子</th><th>编号</th></tr></thead><tbody><tr class="odd"><td>兵/卒</td><td>0</td></tr><tr class="even"><td>炮</td><td>1</td></tr><tr class="odd"><td>车</td><td>2</td></tr><tr class="even"><td>马</td><td>3</td></tr><tr class="odd"><td>相/象</td><td>4</td></tr><tr class="even"><td>仕/士</td><td>5</td></tr><tr class="odd"><td>帅/将</td><td>6</td></tr></tbody></table><p><strong>网络结构</strong></p><p>网络主体是 ResNet，输出部分分出两个头，分别输出 policy 和 value。现在的架构是中间有10个残叉块（Residual Block），每个块里面有两个CNN：卷积核大小为 <span class="math inline">\(3 \times 3\)</span>，过滤器个数为192。</p><h3><span id="蒙特卡洛树搜索">蒙特卡洛树搜索</span></h3><p><img src="/images/mcts0.png"></p><p>搜索树中的每个节点都包含所有合法移动 a ∈ A(s) 的边(s，a)。 每条边存储一组统计数据， <span class="math display">\[\{N(s,a) ,W(s,a) ,Q(s,a) ,P(s,a)\}\]</span> 其中 <span class="math inline">\(N(s,a)\)</span> 是访问计数，<span class="math inline">\(W(s,a)\)</span> 是总动作价值，<span class="math inline">\(Q(s,a)\)</span> 是平均动作价值，<span class="math inline">\(P(s,a)\)</span> 是选择该边的先验概率。 多个模拟在单独的搜索线程上并行执行。</p><ol type="1"><li><p>选择</p><p>每个模拟的第一个 in-tree 阶段开始于搜索树的根节点 <span class="math inline">\(s_0\)</span>，并且在模拟时刻 L 处到达叶节点 <span class="math inline">\(s_L\)</span> 时结束。在每个这些时刻 <span class="math inline">\(t &lt; L\)</span> 处，根据搜索树中的统计量选择一个移动: <span class="math inline">\(a_t = \arg\max_a(Q(s_t,a) + U(s_t,a))\)</span>，其中 <span class="math inline">\(U(s_t,a)\)</span> 使用PUCT算法的变体得到 <span class="math display">\[U(s,a)=c_{puct}P(s,a)\frac{\sqrt{\sum_bN(s,b)}}{1+N(s,a)}\]</span> 其中 <span class="math inline">\(c_{puct}​\)</span> 是一个决定探索程度的常数; 这种搜索控制策略最初倾向于具有高先验概率和低访问次数的行为，但后期倾向于具有高动作价值的行为。</p></li><li><p>扩展和评估</p><p>叶子结点 <span class="math inline">\(s_L\)</span> 被加入到等待评估队列进行评估: <span class="math inline">\((d_i(p),v)=f_\theta(d_i(s_L))\)</span>，其中 <span class="math inline">\(d_i\)</span>是旋转或反射操作。神经网络一次评估队列里的 8 个结点;搜索进程直到评估完毕才能继续工作。每个叶子结点和每条边 <span class="math inline">\((s_L,a)\)</span> 的统计值被初始化为 <span class="math inline">\(\{N(s_L,a) = 0,W(s_L,a) = 0,Q(s_L,a) =0, P(s_L, a) = p_a\}\)</span>，然后价值 v 开始回溯。</p></li><li><p>回溯</p><p>每条边的统计值延路径反向更新：访问计数递增 <span class="math inline">\(N(s_t,𝑎_t) = N(s_t,𝑎_t) +1\)</span>，移动价值更新为平均值 <span class="math inline">\(W(s_t,a_t)=W(s_t,a_t)+v\)</span>, <span class="math inline">\(Q(s_t,a_t)=\frac{W(s_t,a_t)}{N(s_t,a_t)}\)</span>。</p></li><li><p>下棋</p><p>在搜索结束时，AlphaGo Zero 在根位置 <span class="math inline">\(s_0\)</span> 选择移动 a，与其指数访问计数成比例，<span class="math inline">\(\pi(a|s_0) = \frac{N(s_0,a)^{1/\tau}}{\sum_bN(s,b)^{1/\tau}}\)</span>，其中 <span class="math inline">\(τ\)</span> 是控制探索水平的参数。搜索树可以在后面的时刻重用：与所选择的移动对应的子节点成为新的根节点; 在这个节点下面的子树被保留以及它的所有统计数据，而树的其余部分被丢弃。</p></li></ol><h4><span id="实现细节">实现细节</span></h4><p><strong>在选择的过程中，发现当前state在history中出现过（形成循环）怎么办？</strong></p><ul><li>根据比赛规则：闲着循环3次判和；违规（长捉、长将等）判负；对方违规判胜。</li></ul><p><strong>Virtual Loss</strong></p><ul><li><p>多线程搜索时，当某一线程选择了某个action时，为了鼓励其他线程选择其他action，应该降低该action的价值（施加virtual loss）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">self.tree[state].sum_n += <span class="number">1</span></span><br><span class="line">action_state = self.tree[state].a[sel_action]</span><br><span class="line">action_state.n += virtual_loss</span><br><span class="line">action_state.w -= virtual_loss</span><br><span class="line">action_state.q = action_state.w / action_state.n</span><br></pre></td></tr></table></figure></li><li><p>在回溯时，更新value要考虑到virtual loss的影响</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">node = self.tree[state]</span><br><span class="line">action_state = node.a[action]</span><br><span class="line">action_state.n += <span class="number">1</span> - virtual_loss</span><br><span class="line">action_state.w += v + virtual_loss</span><br><span class="line">action_state.q = action_state.w / action_state.n</span><br></pre></td></tr></table></figure></li></ul><p><strong>state表示</strong></p><p>虽然对于神经网络来说state就是<span class="math inline">\(14\times10\times9\)</span>的tensor，但是对于搜索树来说，显然不能用它来表示每个局面。</p><p>在初始版本中，象棋环境（<code>environment/chessboard.py</code>）里是用数组来表示棋盘的，所以在搜索中也使用相应的数组表示state，这样做虽然没什么问题，但是在搜索的过程中需要大量的深拷贝操作（因为需要回溯），增加了许多开销。</p><p>后来版本进行了改进，使用<a href="https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation" target="_blank" rel="noopener">FEN string</a>作为state的表示，降低了拷贝操作的开销；同时也优化了象棋环境（<code>environment/static_env.py</code>），可以直接对FEN进行操作，无需记录复杂的数组。</p><blockquote><p><strong>Forsyth–Edwards Notation</strong> (<strong>FEN</strong>) is a standard <a href="https://www.wikiwand.com/en/Chess_notation" target="_blank" rel="noopener">notation</a> for describing a particular board position of a <a href="https://www.wikiwand.com/en/Chess" target="_blank" rel="noopener">chess</a> game. The purpose of FEN is to provide all the necessary information to restart a game from a particular position.</p></blockquote><h3><span id="自我博弈">自我博弈</span></h3><p>为了提高CPU/GPU利用率，这里使用了多进程，每个进程各自进行自我博弈。Python的多进程有三个实现方式：<code>fork</code>, <code>spawn</code>, <code>forkserver</code>。</p><blockquote><p>On Windows only <code>'spawn'</code> is available. On Unix <code>'fork'</code> and <code>'spawn'</code> are always supported, with <code>'fork'</code> being the default.</p></blockquote><p>由于我自己在macOS/Linux上开发和测试，所以首先实现的是基于<code>fork</code>的多进程，而当我在程序加了<code>mp.set_start_method('spawn')</code>的时候，程序就跑不了了，会报pickling error（貌似是因为传给子进程的参数里不能出现queue的数据结构），于是只能换种方式实现来绕过这个问题。</p><h2><span id="分布式">分布式</span></h2><p>起初我是没打算做成分布式的，实现完上面说述模块之后我用实验室的K80进行训练，练了几天之后发现进步并不明显，几乎还是随机下，很弱智，这是我才意识到即使把它训练到一个业余玩家的水平也需要巨大的算力。</p><p><img src="/images/issueouashd.png"></p><p>后来有一天有人在GitHub上提了一个issue说你可以把它做成分布式的，像LeelaZero那样，我们可以帮你一起训练。<a href="https://zero.sjeng.org/" target="_blank" rel="noopener">LeelaZero</a>是国外一个开发者复现AlphaGo论文搞的围棋AI，因为DeepMind并没有公开程序或代码，所以他想训练出一个公开的围棋之神，然后就邀请网友帮他一起训练，具体的方法就是：网友们在自己的机器上进行自我博弈，然后把博弈的棋谱上传到他的服务器上，然后他攒够一定棋谱之后进行训练神经网络，训练好之后分发新的权重。</p><p>在国内也有很多人帮他训练（跑谱），给我提issue的那个人也是帮LeelaZero训练中的一员。当时正好程序写完了没什么事做，每天就只能等训练结果，然后就决定尝试一下这个模式。因为之前有过Web开发的经验，所以服务器很快就搭好了，测试基本没问题之后就开始运行。</p><p><strong>架构</strong></p><p><img src="/images/architecture.png"></p><p>在维护这个项目正常运行的过程中遇到很多<strong>坑</strong>，程序也做了很多改进：</p><ol type="1"><li>首先是帮忙跑谱的大多都是象棋爱好者，并非开发者，所以我要把Python代码打包成exe文件分发给他们一键执行，最终使用<a href="https://www.pyinstaller.org/" target="_blank" rel="noopener">PyInstaller</a>打包成功，这其中遇到了很多坑：<ul><li>卸载cytoolz；pandas的版本必须为0.20.3</li><li>代码里加上<code>mp.freeze_support()</code>，否则多进程不会正常工作</li></ul></li><li>服务器带宽有限，客户端下载权重太慢，解决办法：把权重放到云存储服务中，如腾讯云/七牛云的对象存储服务。</li><li>中国象棋棋规的完善。并不是说基础的马走日象走田这种规则，而是像长将、长捉等这种比赛规则，这个算是坑最大的一个，直到现在规则还存在少许问题。</li><li>部分支持了UCI协议。这样就可以使用其他的象棋界面加载这个引擎，并且能和其他引擎对弈。</li><li>因为“同行竞争”，我的服务器在今年暑假期间我的服务器经常遭受DDos攻击，由于买不起腾讯云的高防服务，只能尝试其他办法，包括配置弹性IP、配置防火墙、Cloudfare CDN等，但都不好用。最终把服务转移到<a href="https://www.ovh.com/" target="_blank" rel="noopener">OVH</a>提供的VPS上才解决了问题（OVH提供免费的DDos防护）。</li></ol><hr><h2><span id="alphazero-and-exit">AlphaZero and ExIt</span></h2><p><a href="https://arxiv.org/abs/1705.08439" target="_blank" rel="noopener">Expert Iteration（ExIt）</a>是一种模仿学习（Imitation Learning, IL）算法，普通的 IL 算法中，徒弟模仿专家的策略只能提高自己的策略，专家是不会有任何提高的，而 ExIt 算法就是想让师傅教徒弟的时候自己也有提高。</p><p><strong>ExIt 算法</strong> 师傅根据徒弟的策略进行前向搜索（例如MCTS，alpha-beta，贪心搜索等），得出比徒弟更好的策略，然后徒弟再学习师傅的策略，如此循环，随着徒弟的增强，师傅也会越来越强。</p><p><img src="/images/exit.png"></p><p>可见，AlphaZero也属于 ExIt 算法，师傅为 MCTS，徒弟就是神经网络。</p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaZero </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> CCZero </tag>
            
            <tag> MCTS </tag>
            
            <tag> 中国象棋 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hexo 搭建博客踩坑记录</title>
      <link href="/2018/11/06/%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E8%AE%B0%E5%BD%95/"/>
      <url>/2018/11/06/%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<p>博客迁移这个事早就想做了，但到现在才有时间和精力来完成。以前太年轻，写的博客系统并不方便维护，迁移的动力主要有以下几个：</p><ol type="1"><li>原博客更新、维护较麻烦。以前的博客是用<a href="https://www.52coding.com.cn/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/">PHP</a>写的，之前的写作方式是用Markdown写好导出HTML，再修改HTML代码使得静态资源（图片等）加载正确，这就使得修改博客很麻烦；更换主题也很麻烦，博客的主题和Markdown的主题通常会有冲突，所以想换个样式就要改半天CSS。</li><li>觉得UI有些难看，想要简洁一些；</li><li>安全问题。</li></ol><p>现在的解决方案是<a href="https://pages.github.com/" target="_blank" rel="noopener">Github Pages</a> + <a href="https://hexo.io/zh-cn/index.html" target="_blank" rel="noopener">Hexo</a>，主题选的是<a href="https://github.com/CodeDaraW/Hacker" target="_blank" rel="noopener">Hacker</a>，迁移了两天终于搞完了，在此简单记录一下遇到的坑。</p><a id="more"></a><h3><span id="数学公式渲染">数学公式渲染</span></h3><p>由于这款主题并不是原生支持数学公式的，所以要添加些代码来使其支持Mathjax，参考http://searene.me/2016/10/01/Let-hexo-support-mathjax/。</p><p>首先在主题的<code>layout</code>目录下新建<code>mathjax.ejs</code>，文件内容如下：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">%</span> <span class="attr">if</span> (<span class="attr">theme.mathjax.enable</span>)&#123; %&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Config(&#123;</span></span><br><span class="line"><span class="undefined">      tex2jax: &#123;</span></span><br><span class="line"><span class="undefined">        inlineMath: [ ['$','$'], ["\\(","\\)"] ],</span></span><br><span class="line"><span class="undefined">        processEscapes: true</span></span><br><span class="line"><span class="undefined">      &#125;</span></span><br><span class="line"><span class="undefined">    &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Config(&#123;</span></span><br><span class="line"><span class="undefined">        tex2jax: &#123;</span></span><br><span class="line"><span class="undefined">          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined">      &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/x-mathjax-config"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  MathJax.Hub.Queue(function() &#123;</span></span><br><span class="line"><span class="undefined">          var all = MathJax.Hub.getAllJax(), i;</span></span><br><span class="line"><span class="xml">          for(i=0; i <span class="tag">&lt; <span class="attr">all.length</span>; <span class="attr">i</span> += <span class="string">1)</span> &#123;</span></span></span><br><span class="line"><span class="undefined">              all[i].SourceElement().parentNode.className += ' has-jax';</span></span><br><span class="line"><span class="undefined">          &#125;</span></span><br><span class="line"><span class="undefined">      &#125;);</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%</span> &#125; %&gt;</span></span><br></pre></td></tr></table></figure><p><strong>坑1</strong>：之前在网上查到的代码给的MathJax.js的链接多是过期的，如<code>https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML</code>，然后就被坑了。</p><p>然后在<code>layout.ejs</code>中加上<code>&lt;%- partial('mathjax') %&gt;</code>，文件整体内容为：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE HTML&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">head</span>') %&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"blog"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"content"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">header</span>') %&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">main</span> <span class="attr">class</span>=<span class="string">"site-main posts-loop"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">%-</span> <span class="attr">body</span> %&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">main</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">footer</span>') %&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">components</span>/<span class="attr">googleanalytics</span>') %&gt;</span></span><br><span class="line">      <span class="comment">&lt;!-- 新加的 --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">%-</span> <span class="attr">partial</span>('<span class="attr">mathjax</span>') %&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>最后在主题的<code>_config.yml</code>中加上： <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mathjax:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>如果没有安装MathJax插件的话需要安装一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-math --save</span><br></pre></td></tr></table></figure><p>重新生成一下应该就可以渲染数学公式了。</p><p>不过还有些问题，就是你写在数学公式里的下划线(<code>_</code>)、反斜杠(<code>\</code>)、和星号(<code>*</code>)会被当作普通Markdown来处理，比如把下划线(<code>_</code>)和星号(<code>*</code>)替换成<code>&lt;em&gt;</code>标签等导致公式渲染错误。</p><p>解决方案来自https://zhuanlan.zhihu.com/p/33857596，打开<code>nodes_modules/marked/lib/marked.js</code>:</p><ol type="1"><li><p>找到下面的代码:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([\\`*&#123;&#125;\[\]()# +\-.!_&gt;])/</span>,</span><br></pre></td></tr></table></figure><p>改为：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">escape</span>: <span class="regexp">/^\\([`*&#123;&#125;\[\]()# +\-.!_&gt;])/</span>,</span><br></pre></td></tr></table></figure></li><li><p>找到em的符号:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">em: <span class="regexp">/^\b((?:[^]|_)+?)\b|^*((?:**|[\s\S])+?)*(?!*)/</span>,</span><br></pre></td></tr></table></figure><p>改为：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">em:<span class="regexp">/^\*((?:\*\*|[\s\S])+?)\*(?!\*)/</span>,</span><br></pre></td></tr></table></figure></li></ol><p>这样就去掉了<code>_</code>的斜体含义，在公式里使用<code>_</code>就没有问题了，不过要使用<code>*</code>的话要用<code>\ast</code>替代。</p><h3><span id="评论">评论</span></h3><p>Hacker这款主题支持两种评论方式，分别是<a href="https://github.com/imsun/gitment" target="_blank" rel="noopener">Gitment</a>和<a href="https://disqus.com/" target="_blank" rel="noopener">Disqus</a>。一开始试了试Gitment，配置好之后发现不能用，其原因是有一个服务过期了而作者也弃坑了没人管，我也懒得折腾就转向了Disqus，注册了之后就可以直接使用，十分方便，<strong>但是</strong>国内要翻墙才能访问。</p><p>最后换成了<a href="https://www.livere.com/" target="_blank" rel="noopener">来必力</a>评论，国内可以正常访问，虽然主题没有内置支持，但是操作很简单，只需把安装代码放到 <code>layout/components/comment.ejs</code> 里即可。</p><h3><span id="搜索">搜索</span></h3><p>主题内置不支持搜索，需要自己动手，丰衣足食。</p><p>首先安装生成搜索内容的插件： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure></p><p>然后在<code>_config.yml</code>进行如下配置： <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">search:</span></span><br><span class="line"><span class="attr">  path:</span> <span class="string">search.xml</span></span><br><span class="line"><span class="attr">  field:</span> <span class="string">post</span></span><br><span class="line"><span class="attr">  content:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p>配置项具体含义参考<a href="https://www.npmjs.com/package/hexo-generator-search" target="_blank" rel="noopener">这里</a>，这个网站还说了应该怎么用这个插件来在博客中支持搜索并且给了demo，分为三步：</p><ol type="1"><li><a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/layout/_widget/search.ejs#L8" target="_blank" rel="noopener">创建搜索框</a></li><li>编写<a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/source/js/search.js" target="_blank" rel="noopener">搜索脚本</a></li><li>在 Hexo 主题中把两部分<a href="https://github.com/wzpan/hexo-theme-freemind/blob/master/layout/_partial/after_footer.ejs#L22" target="_blank" rel="noopener">结合起来</a></li></ol><h4><span id="创建搜索框">创建搜索框</span></h4><p>我的打算是把“搜索”放在顶部，和“主页”、“目录”等一排，是一个单独的页面。所以要先创建新界面：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page &quot;search&quot;</span><br></pre></td></tr></table></figure><p>修改 <code>search</code> 目录下的 <code>index.md</code>：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: 搜索</span><br><span class="line">date: 2018-11-23 14:42:39</span><br><span class="line">layout: "search"</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>在主题的 <code>_config.yml</code> 中加上：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">menu:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="string">搜索:</span> <span class="string">/search</span></span><br></pre></td></tr></table></figure><p>在主题的 <code>layout</code> 目录下创建 <code>search.ejs</code>：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">article</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">h2</span> <span class="attr">class</span>=<span class="string">"article-title &lt;% if (page.category)&#123; %&gt; category&lt;% &#125; else if (page.category)&#123; %&gt; category&lt;% &#125; %&gt;"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">%=</span> <span class="attr">page.title</span> || <span class="attr">config.title</span> %&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"site_search"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"form-group"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">id</span>=<span class="string">"local-search-input"</span> <span class="attr">name</span>=<span class="string">"q"</span> <span class="attr">results</span>=<span class="string">"0"</span> <span class="attr">placeholder</span>=<span class="string">"输入关键词"</span> <span class="attr">class</span>=<span class="string">"st-search-input st-default-search-input form-control"</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"archive"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"local-search-result"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">article</span>&gt;</span></span><br></pre></td></tr></table></figure><p>重新build就应该可以看到“搜索”标签和搜索框了。</p><h4><span id="编写搜索脚本">编写搜索脚本</span></h4><p>在主题目录下创建<code>source/js/search.js</code>，源码照 https://github.com/wzpan/hexo-theme-freemind/blob/master/source/js/search.js 稍作修改。同时也下载jquery到<code>js</code>文件夹。</p><p>然后在 <code>layout/components/head.ejs</code>中添加：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"&lt;%- config.root %&gt;js/search.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"&lt;%- config.root %&gt;js/jquery.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><h4><span id="结合">结合</span></h4><p>在 <code>layout/search.ejs</code>里添加</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=<span class="string">"text/javascript"</span>&gt;</span><br><span class="line">    <span class="keyword">var</span> search_path = <span class="string">"&lt;%= config.search.path %&gt;"</span>;</span><br><span class="line">    <span class="keyword">if</span> (search_path.length == <span class="number">0</span>) &#123;</span><br><span class="line">        search_path = <span class="string">"search.xml"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">var</span> path = <span class="string">"&lt;%= config.root %&gt;"</span> + search_path;</span><br><span class="line">    searchFunc(path, <span class="string">'local-search-input'</span>, <span class="string">'local-search-result'</span>);</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure><p>这样就完全实现了搜索功能！</p><h3><span id="其他">其他</span></h3><p><strong>分割线</strong></p><p>Hexo中写作不能使用<code>___</code>（三个下划线）来实现分割线，用了的话会generate失败，而且提示的错误很迷，曾经困扰了我很久。如果要用分割线的话需要四个下划线。</p><p><strong>修改网站Icon</strong></p><p>在主题中找到<code>head.ejs</code>文件，其中有一行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link href=&quot;&lt;%- config.root %&gt;favicon.ico&quot; rel=&quot;icon&quot;&gt;;</span><br></pre></td></tr></table></figure><p>按理来说只要往根目录（<code>source</code>）下放一个<code>favicon.ico</code>的文件即可。</p><p>可是我的就不行，不知道什么原因，把文件名换了就可以了，所以我改成了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;link href=&quot;&lt;%- config.root %&gt;icon.png&quot; type=&quot;image/png&quot; rel=&quot;icon&quot;&gt;</span><br></pre></td></tr></table></figure><p>然后往根目录下放一个<code>icon.png</code>，解决。</p><p><strong>分享</strong></p><p>分享接口使用<a href="https://github.com/overtrue/share.js" target="_blank" rel="noopener">Share.js</a>，只需引入相应的css和js文件，照文档使用即可。</p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mathjax </tag>
            
            <tag> Hexo </tag>
            
            <tag> Disqus </tag>
            
            <tag> Gitment </tag>
            
            <tag> Github Pages </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Interdependence and the Gains from Trade</title>
      <link href="/2018/11/03/Interdependence%20and%20the%20Gains%20from%20Trade/"/>
      <url>/2018/11/03/Interdependence%20and%20the%20Gains%20from%20Trade/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#a-parable-for-the-modern-economy">A Parable for the Modern Economy</a><ul><li><a href="#production-possibilities">Production Possibilities</a></li><li><a href="#specialization-and-trade">Specialization and Trade</a></li></ul></li><li><a href="#comparative-advance-the-driving-force-of-specialization">Comparative Advance: The Driving Force of Specialization</a><ul><li><a href="#absolute-advantage">Absolute Advantage</a></li><li><a href="#opportunity-cost-and-comparative-advantage">Opportunity Cost and Comparative Advantage</a></li><li><a href="#comparative-advantage-and-trade">Comparative Advantage and Trade</a></li><li><a href="#the-price-and-the-trade">The Price and The Trade</a></li></ul></li><li><a href="#applications-of-comparative-advantage">Applications of Comparative Advantage</a><ul><li><a href="#should-tiger-woods-mow-his-own-lawn">Should Tiger Woods Mow His Own Lawn?</a></li><li><a href="#should-the-united-states-trade-with-other-countries">Should the United States Trade With Other Countries?</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="a-parable-for-the-modern-economy">A Parable for the Modern Economy</span></h2><h3><span id="production-possibilities">Production Possibilities</span></h3><p>The graph shows the various mixes of output that an economy can produce and illustrate that people face trade-offs.</p><p><img src="/images/IMG_CBD807794C2B-1.png"> If the farmer and rancher do not trade, the production possibilities frontier is also the consumption possibilities frontier. However, the frontier shows trade-offs but do not show what they will choose to do. So let’s suppose the choose the combinations identified in the graph by points A and B.</p><h3><span id="specialization-and-trade">Specialization and Trade</span></h3><p><img src="/images/IMG_FA9EF67DD902-1.png"> The farmer and rancher can both benefit because trade allows each of them to specialize in doing what they do best. The farmer will spend more time growing potatoes and less time raising cattle. The rancher will spend more time raising cattle and less time growing potatoes. As a result of specialization and trade, each of them can consume more meat and more potatoes without working any more hours.</p><h2><span id="comparative-advance-the-driving-force-of-specialization">Comparative Advance: The Driving Force of Specialization</span></h2><p>The puzzle is why the rancher does better in both fields, he still gain from trade? To solve this puzzle, we should answer first who has a lower cost to produce potatoes?</p><h3><span id="absolute-advantage">Absolute Advantage</span></h3><p>We can measure the cost through <em>absolute advantage</em> which is the ability to produce a good using fewer inputs than another producer. In our example, the only input is time. Because the rancher need fewer time to produce both items, he has the absolute advantage in producing both goods. Base on this the rancher has a lower cost to produce potatoes.</p><h3><span id="opportunity-cost-and-comparative-advantage">Opportunity Cost and Comparative Advantage</span></h3><p>Recall the <em>opportunity cost</em> is whatever must be given up to obtain some item. In our example, the opportunity cost of the rancher to produce 1 ounce potatoes is 1/2 ounce meat and the opportunity cost of him to produce 1 ounce meat is 2 ounce potatoes. Similarly, we can compute the opportunity cost for farmer which summarize in table 1. <img src="/images/IMG_857CB49E31D3-1.png"></p><p>We can also measure the cost through <em>comparative advantage</em>, which is the ability to produce a good at a lower opportunity cost than another producer. Through table 1 we can find out that farmer has comparative advantage in producing potatoes and rancher has comparative advantage in producing meat. That’s why the rancher can gain from trade.</p><p>Although it is possible for one person to have an absolute advantage in both goods, it is impossible for one to have a comparative advantage in both goods. Because the opportunity cost of one good is inverse of the opportunity cost of the other.</p><h3><span id="comparative-advantage-and-trade">Comparative Advantage and Trade</span></h3><p>The gains from specialization and trade based on comparative advantage. By specialization in what he has a comparative advantage, the total production of the society raises which means increase the size of economic pie.</p><p>Also, the price of the goods should lower than their opportunity cost of producing it. For example, the farmer exchange 15 ounce potatoes for 5 ounce meat. The price of meat for the farmer is 3 ounce potatoes which is lower than his opportunity cost of producing meat (4 ounce potatoes). Similarly, for the rancher, the price of 1 ounce potatoes is 1/3 ounce meat which is also lower than his opportunity cost of producing potatoes (1/2 ounce meat).</p><p>Conclude: <strong>Trade can benefit everyone in society because it allows people to specialize in activities in which they have a comparative advantage</strong>.</p><h3><span id="the-price-and-the-trade">The Price and The Trade</span></h3><p><strong>For both parties to gain from trade, the price at which they trade must lie between the two opportunity costs</strong>.</p><h2><span id="applications-of-comparative-advantage">Applications of Comparative Advantage</span></h2><h3><span id="should-tiger-woods-mow-his-own-lawn">Should Tiger Woods Mow His Own Lawn?</span></h3><p>Say Tiger Woods can mow his own lawn in 2 hours while, Forrest, the boy next door, can mow the lawn in 4 hours. Should Tiger Woods mow his own lawn?</p><p>Clearly, Tiger Woods has an absolute advantage in mowing the lawn but he has a higher opportunity cost in doing it because he could spend 2 hours filming a commercial advertisement earning $10000 while Forrest can only earn $20 in 4 hours. So Tiger should hire Forrest to mow the lawn and both of them will better off as long as the payment is between $20 and $10000.</p><h3><span id="should-the-united-states-trade-with-other-countries">Should the United States Trade With Other Countries?</span></h3><p>International trade can make some individuals worse off, even as it makes the country as a whole better off. When the US exports food and imports cars, the impact on an American farmer is not the same as the impact on an American autoworker. Yet, international trade is not like war, in which some countries win and others lose. <em>Trade allows all countries to achieve greater prosperity</em>.</p><h2><span id="summary">Summary</span></h2><ul><li>Each person consumes goods and services produced by many other people both in the United States and around the world. Interdependence and trade are desirable because they allow everyone to enjoy a greater <strong>quantity and variety</strong> of goods and services.</li><li>There are two ways to compare the ability of two people in producing a good. The person who can produce the good with the smaller quantity of inputs is said to have an <em>absolute advantage</em> in producing the good. The person who has the smaller <em>opportunity cost</em> of producing the good is said to have a <em>comparative advantage</em>. The gains from trade are based on comparative advantage, not absolute advantage.</li><li>Trade makes everyone better off because it allows people to specialize in those activities in which they have a comparative advantage.</li><li>The principle of comparative advantage applies to countries as well as to people. Economists use the principle of comparative advantage to advocate free trade among countries.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微观经济型原理 </tag>
            
            <tag> trade </tag>
            
            <tag> comparative advantage </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Unity学习笔记</title>
      <link href="/2018/11/01/Unity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2018/11/01/Unity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p><strong>记录一些小功能的实现</strong></p><!-- toc --><ul><li><a href="#实现相机跟随">实现相机跟随</a></li><li><a href="#拖动图标在场景生成物体">拖动图标在场景生成物体</a></li><li><a href="#技能冷却效果">技能冷却效果</a></li><li><a href="#鼠标点击选中场景中的物体">鼠标点击选中场景中的物体</a></li><li><a href="#2d人物朝左朝右">2D人物朝左朝右</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="实现相机跟随">实现相机跟随</span></h2><ul><li>方法一<ul><li>把相机设置为目标的Child</li></ul></li><li>方法二<ul><li>设置好距目标的距离和角度，根据数学关系计算出相机位置</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">float distance = 15;// 距离</span><br><span class="line">float rot = 0;// 横向角度</span><br><span class="line">GameObject target;// 目标物体</span><br><span class="line">float roll = 30f * Mathf.PI * 2 / 360; // 纵向角度</span><br><span class="line"></span><br><span class="line">void LateUpdate () &#123;</span><br><span class="line">Vector3 targetPos = target.transform.position;</span><br><span class="line">Vector3 cameraPos;</span><br><span class="line">float d = distance * Mathf.Cos (roll);</span><br><span class="line">float height = distance * Mathf.Sin (roll);</span><br><span class="line">cameraPos.x = targetPos.x + d * Mathf.Cos (rot);</span><br><span class="line">cameraPos.z = targetPos.z + d * Mathf.Sin (rot);</span><br><span class="line">cameraPos.y = targetPos.y + height;</span><br><span class="line">Camera.main.transform.position = cameraPos;</span><br><span class="line">Camera.main.transform.LookAt (target.transform);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>相机随鼠标旋转</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">void Rotate()</span><br><span class="line">&#123;</span><br><span class="line"> float w = Input.GetAxis (&quot;Mouse X&quot;) * rotSpeed;</span><br><span class="line">rot -= w;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Roll()</span><br><span class="line">&#123;</span><br><span class="line">float w = Input.GetAxis (&quot;Mouse Y&quot;) * rollSpeed * 0.5f;</span><br><span class="line">roll -= w;</span><br><span class="line">if (roll &gt; maxRoll) &#123;</span><br><span class="line">roll = maxRoll;</span><br><span class="line">&#125;</span><br><span class="line">if (roll &lt; minRoll) &#123;</span><br><span class="line">roll = minRoll;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void LateUpdate () &#123;</span><br><span class="line">Rotate();</span><br><span class="line">  Roll();</span><br><span class="line">....</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="拖动图标在场景生成物体">拖动图标在场景生成物体</span></h2><p><strong>拖动UI</strong></p><p>新建<code>Drag</code>类，继承<code>IBeginDragHandler, IDragHandler, IEndDragHandler</code>，实现拖动UI功能有三个接口：</p><ul><li><code>public void OnBeginDrag (PointerEventData eventData)</code></li><li><code>public void OnDrag (PointerEventData eventData)</code></li><li><code>public void OnEndDrag (PointerEventData eventData)</code></li></ul><p>在<code>Drag</code>类里实现这三个接口即可实现想要的拖动效果，最后不用忘了把<code>Drag</code>脚本添加到想要被拖动的UI物体上。</p><p><strong>在场景中生成物体</strong></p><p>要实现这个功能:</p><ul><li>首先在<code>OnBeginDrag</code>中生成新的<code>GameObject</code>；</li><li>然后在<code>OnDrag</code>中，根据鼠标在场景里的位置调整<code>GameObject</code>的位置，再检测<code>GameObject</code>的collider有无和其他物体碰撞；</li><li>最后在<code>OnEndDrag</code>中，如果<code>GameObject</code>的最终位置合法，则不再移动；否则销毁物体，生成失败。</li></ul><h2><span id="技能冷却效果">技能冷却效果</span></h2><p><strong>定时器</strong></p><p>实现冷却效果计时器必不可少，实现方法也很简单，只需两个变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bool timerStarted = false;</span><br><span class="line">float remain = 10f;</span><br></pre></td></tr></table></figure><p>然后在<code>Update</code>中作如下更新：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">void Update ()</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    if (timerStarted) &#123;</span><br><span class="line">remain -= Time.deltaTime;</span><br><span class="line">        if (remain &lt;= 0) &#123;</span><br><span class="line">            CloseTimer();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>UI效果</strong></p><p>Button的层次如下：</p><ul><li><p><code>Button</code></p><ul><li><p><code>Image</code>：按钮显示的图标</p></li><li><p><code>Mask</code>：可以用按钮的默认背景；调整颜色和透明度；ImageType为filled；通过调整Fill Amount来实现转动效果</p><p><img src="/images/Screen%20Shot%202018-10-30%20at%204.09.00%20PM.png"></p></li><li><p><code>CD Text</code>：显示剩余冷却时间</p></li></ul></li></ul><p><strong>Note</strong>：在开始冷却的同时，应把设置<code>btn.interactable = false;</code>，否则按钮可以在冷却过程中再次被点击。</p><p>这里Button的<code>OnClick</code>绑定了两个函数，分别给<code>CharacterController</code>实现技能效果，和给<code>UIManager</code>实现UI动效：</p><p><img src="/images/btnclick.png"></p><h2><span id="鼠标点击选中场景中的物体">鼠标点击选中场景中的物体</span></h2><p>思路：从点击位置向场景发射射线，检测是否击中物体</p><p>实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">void MousePick () &#123;</span><br><span class="line">    if (Input.GetMouseButtonUp (0)) &#123;</span><br><span class="line">        // 发射射线</span><br><span class="line">        Ray myRay = Camera.main.ScreenPointToRay (Input.mousePosition);</span><br><span class="line">        // 选择想被选中的layer</span><br><span class="line">        int layerMask = LayerMask.GetMask (&quot;Building&quot;);</span><br><span class="line">        // 检测碰撞</span><br><span class="line">        RaycastHit2D hit = Physics2D.Raycast (new Vector2 (myRay.origin.x, myRay.origin.y),</span><br><span class="line">            Vector2.down, Mathf.Infinity, layerMask);</span><br><span class="line">        if (hit.collider) &#123;</span><br><span class="line">            // 检测到碰撞，选中该物体</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2><span id="2d人物朝左朝右">2D人物朝左朝右</span></h2><p>思路：如果原sprite朝右，那么只要把transform的<code>scale.x</code>变成<code>-1</code>就是朝左了。</p><p><img src="/images/facingside.png"></p><p>实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">void LateUpdate () &#123;</span><br><span class="line">    Vector3 localScale = _transform.localScale;</span><br><span class="line"></span><br><span class="line">    if (_vx &gt; 0) &#123; // moving right so face right</span><br><span class="line">        _facingRight = true;</span><br><span class="line">    &#125; else if (_vx &lt; 0) &#123; // moving left so face left</span><br><span class="line">        _facingRight = false;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // check to see if scale x is right for the player</span><br><span class="line">    // if not, multiple by -1 which is an easy way to flip a sprite</span><br><span class="line">    if ((_facingRight) &amp;&amp; (localScale.x &lt; 0) || </span><br><span class="line">        ((localScale.x &gt; 0)) &#123;</span><br><span class="line">        localScale.x *= -1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // update the scale</span><br><span class="line">    _transform.localScale = localScale;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>未完待续</strong></p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Unity </tag>
            
            <tag> C# </tag>
            
            <tag> Game Dev </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Thinking Like an Economist</title>
      <link href="/2018/10/03/Thinking%20Like%20an%20Economist/"/>
      <url>/2018/10/03/Thinking%20Like%20an%20Economist/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#the-economist-as-scientist">The Economist as Scientist</a><ul><li><a href="#the-scientific-method-observation-theory-and-more-observation">The Scientific Method: Observation, Theory, and More Observation</a></li><li><a href="#the-role-of-assumptions">The Role of Assumptions</a></li><li><a href="#economic-models">Economic Models</a></li><li><a href="#our-first-model-the-circular-flow-diagram">Our First Model: The Circular-Flow Diagram</a></li><li><a href="#our-second-model-the-production-possibilities-frontier">Our Second Model: The Production Possibilities Frontier</a></li><li><a href="#microeconomics-and-macroeconomics">Microeconomics and Macroeconomics</a></li></ul></li><li><a href="#the-economist-as-policy-adviser">The Economist as Policy Adviser</a><ul><li><a href="#positive-versus-normative-analysis">Positive versus Normative Analysis</a></li><li><a href="#economists-in-washington">Economists in Washington</a></li><li><a href="#why-economists-advice-is-not-always-followed">Why Economists’ Advice Is Not Always Followed</a></li></ul></li><li><a href="#why-economists-disagree">Why Economists Disagree</a><ul><li><a href="#differences-in-scientific-judgments">Differences in Scientific Judgments</a></li><li><a href="#difference-in-values">Difference in Values</a></li><li><a href="#perception-versus-reality">Perception versus Reality</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="the-economist-as-scientist">The Economist as Scientist</span></h2><h3><span id="the-scientific-method-observation-theory-and-more-observation">The Scientific Method: Observation, Theory, and More Observation</span></h3><p>Invention an economic theory is just like in other scientific fields, which is <em>observation, summary to a theory and then collect data to test it</em>. However, it is often <em>difficult or impossible</em> for economists to <em>collect data</em> because you cannot change policies just for experiments. <strong>Therefore, economists often pay attention to the natural experiments offered by history</strong> which can not only give insight into the economy of the past, but also allow to illustrate and evaluate economic theories of the present.</p><h3><span id="the-role-of-assumptions">The Role of Assumptions</span></h3><p><strong>Make assumptions can simplify the question.</strong> e.g. once we understood the international trade in the simplified imaginary world, we are in a better position to understand international trader in the more complex world.</p><p>Also, the art in scientific thinking is <strong>deciding which assumptions to make</strong>. e.g. study short-run effect or long-run effect make different assumptions.</p><h3><span id="economic-models">Economic Models</span></h3><p>Economic models composed with graphs and equations which omit a lot of details to emphases the essence of economy. Each economic models make assumptions to simplify reality so as to improve our understanding of it.</p><h3><span id="our-first-model-the-circular-flow-diagram">Our First Model: The Circular-Flow Diagram</span></h3><p><img src="/images/IMG_9A38B6F35EC5-1.jpeg.jpg"></p><p>e.g. money in your wallet -&gt; buy coffee in markets for goods and services (local Starbucks) -&gt; revenue of the company -&gt; pay rental or wage -&gt; someone’s wallet</p><p>Because of its simplicity, this circular-flow diagram is useful to keep in mind when thinking about <strong>how the pieces of the economy fit together</strong>.</p><h3><span id="our-second-model-the-production-possibilities-frontier">Our Second Model: The Production Possibilities Frontier</span></h3><p><img src="/images/IMG_2122EF5B828A-1.jpeg.jpg"> The production possibilities frontier shows the <em>efficiency</em> of the society. Because resources are <em>scarce</em>, not every conceivable outcome is feasible. Points <strong>on</strong> the production possibilities frontier represent <em>efficient levels</em> of production.</p><p>It also reveals <em>trade-off</em> and <em>opportunity costs</em>: if produce more computers, means have to produce less cars. The <em>opportunity cost</em> is measured by the <strong>slope</strong> of the production possibilities frontier, which means point F’s opportunity cost of a car is lower and point E’ opportunity cost of producing a car is higher. That’s because when at point E, the society has let all of car engineers to produce cars. Producing one more car means moving some of the best computer technicians out of the computer industry and making them autoworkers.</p><p>The production possibilities frontier also change with time, which shows <em>economic growth</em>. <img src="/images/IMG_0EA219852402-1.jpeg.jpg"></p><h3><span id="microeconomics-and-macroeconomics">Microeconomics and Macroeconomics</span></h3><p>Economics is studied on various levels, which is traditionally divided into two broad subfields:</p><ul><li><strong>Microeconomics</strong> is the study of how households and firms make decisions and how they interact in specific markets.</li><li><strong>Macroeconomics</strong> is the study of economy-wide phenomena, including inflation, unemployment, and economic growth.</li></ul><h2><span id="the-economist-as-policy-adviser">The Economist as Policy Adviser</span></h2><h3><span id="positive-versus-normative-analysis">Positive versus Normative Analysis</span></h3><p><strong>positive statements</strong>: claims that attempt to describe the world as it is <strong>normative statements</strong>: claims that attempt to prescribe how the world should be</p><p>Normative statements comes from positive statements as well as value judgements. Deciding what is good or bad policy is not just a matter of science. It also involves our views on ethics, religion, and political philosophy.</p><h3><span id="economists-in-washington">Economists in Washington</span></h3><p>Economists in Whitehouse also face trade-offs. The influence of economists on policy goes beyond their role as advisers: Their research and writings often affect policy indirectly.</p><h3><span id="why-economists-advice-is-not-always-followed">Why Economists’ Advice Is Not Always Followed</span></h3><p>Economists offer crucial input into the policy process, but their advice is only one ingredient of a complex recipe.</p><h2><span id="why-economists-disagree">Why Economists Disagree</span></h2><h3><span id="differences-in-scientific-judgments">Differences in Scientific Judgments</span></h3><p><strong>Economic is a young science and there is still much to be learned.</strong> They disagree because they have different hunches about the validity of alternative theories or about the size of important parameters that measure how economic variables are related.</p><h3><span id="difference-in-values">Difference in Values</span></h3><p>Economists give conflicting advice sometimes because they have different values.</p><h3><span id="perception-versus-reality">Perception versus Reality</span></h3><p>Why do policies such as rent control persist if the experts are united in their opposition? It may be that the realities of the <strong>political process</strong> stand as immovable obstacles. But it also may be that economists have <strong>not yet convinced</strong> enough of the public that these policies are undesirable.</p>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微观经济型原理 </tag>
            
            <tag> Production Possibilities Frontier </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Ten Principles of Economics</title>
      <link href="/2018/09/16/Chapter%201-%20Ten%20Principles%20of%20Economics/"/>
      <url>/2018/09/16/Chapter%201-%20Ten%20Principles%20of%20Economics/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#how-people-make-decisions">How People Make Decisions</a><ul><li><a href="#principle-1-people-face-trade-offs">Principle 1: People Face Trade-offs</a></li><li><a href="#principle-2-the-cost-of-something-is-what-you-give-up-to-get-it">Principle 2: The Cost of Something Is What You Give Up to Get It</a></li><li><a href="#principle-3-rational-people-think-at-the-margin">Principle 3: Rational People Think at the Margin</a></li><li><a href="#principle-4-people-respond-to-incentives">Principle 4: People Respond to Incentives</a></li></ul></li><li><a href="#how-people-interact">How People Interact</a><ul><li><a href="#principle-5-trade-can-make-everyone-better-off">Principle 5: Trade Can Make Everyone Better Off</a></li><li><a href="#principle-6-markets-are-usually-a-good-way-to-organize-economic-activity">Principle 6: Markets Are Usually a Good Way to Organize Economic Activity</a></li><li><a href="#principle-7-governments-can-sometimes-improve-market-outcomes">Principle 7: Governments Can Sometimes Improve Market Outcomes</a></li></ul></li><li><a href="#how-the-economy-as-a-whole-works">How the Economy as a Whole Works</a><ul><li><a href="#principle-8-a-countrys-standard-of-living-depends-on-its-ability-to-produce-goods-and-services">Principle 8: A Country’s Standard of Living Depends on Its Ability to Produce Goods and Services</a></li><li><a href="#principle-9-prices-rise-when-the-government-prints-too-much-money">Principle 9: Prices Rise When the Government Prints Too Much Money</a></li><li><a href="#principle-10-society-faces-a-short-run-trade-off-between-inflation-and-unemployment">Principle 10: Society Faces a Short-Run Trade-off between Inflation and Unemployment</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="how-people-make-decisions">How People Make Decisions</span></h2><p><strong>scarcity</strong>: the limited nature of society’s resources <strong>economics</strong>: the study of how society manages its <em>scarce</em> resources</p><h3><span id="principle-1-people-face-trade-offs">Principle 1: People Face Trade-offs</span></h3><p>To get one thing we like, we usually have to give up another thing that we like. <strong>Making decisions</strong> requires trading-off one goal against another.</p><ul><li>student cannot learn two or more things at the same time</li><li>how to spend family income</li><li>guns (defense) and butter (living conditions)</li></ul><p><strong>Efficiency</strong> and <strong> Equality</strong></p><ul><li><em>Efficiency</em> means the property of society getting the most it can from its scarce resources.</li><li><em>Equality</em> means the property of distributing economic prosperity uniformly among the members of society.</li><li>In other words, <em>efficiency</em> refers to the size of the economic pie, and <em>equality</em> refers to how the pie is divided into individual slices.</li><li>When government tries to cut the economic pie into more equal slices, the pie get smaller.</li></ul><p>Nonetheless, people are likely to make good decisions only if they understand the options they have available. Our study of economics, therefore, starts by acknowledging life’s trade-offs.</p><h3><span id="principle-2-the-cost-of-something-is-what-you-give-up-to-get-it">Principle 2: The Cost of Something Is What You Give Up to Get It</span></h3><p><strong>Opportunity cost</strong>: whatever must be given up to obtain some item. When making any decision, decision makers should be aware of the opportunity costs that accompany each possible action.</p><h3><span id="principle-3-rational-people-think-at-the-margin">Principle 3: Rational People Think at the Margin</span></h3><p><strong>Rational people</strong> systematically and purposefully do the best they can to achieve their objectives, given the available opportunities. <strong> Marginal change</strong>: a small incremental adjustment to a plan of action. e.g. when exam around, study one more hour instead of playing games.</p><p>Rational people often make decisions by comparing <em>marginal benefits</em> and <em>marginal costs</em>.</p><ul><li>airline ticket</li><li>why is water so cheap, while diamonds are so expensive?<ul><li>water is plentiful -&gt; margin benefit is small</li><li>diamonds are so rare -&gt; margin benefit is large A rational decision maker takes an action if and only if the <em>marginal benefit</em> of the action <strong>exceeds</strong> the <em>marginal cost</em>.</li></ul></li></ul><h3><span id="principle-4-people-respond-to-incentives">Principle 4: People Respond to Incentives</span></h3><p>An <strong>incentive</strong> is something that induces a person to act, such as the prospect of a punishment or a reward. <em>People respond to incentives, the rest is commentary.</em></p><p>Auto safety</p><ul><li>1950s, no seat belt, accident is costly -&gt; seat belt law -&gt; accident is not that costly -&gt; people drive faster (cost less time) -&gt; few deaths per accident but more accidents -&gt; little change in driver deaths and an increase in the number of pedestrian deaths.</li></ul><p>When analyzing any policy, we must consider not only the direct effects but also the less obvious indirect effects that work through incentives. If the policy changes incentives, it will cause people to alter their behavior.</p><p><em>Incentive Pay</em> Chicago buses do not take the shortcut when around congestion, because they have no incentive to do so. If they are paid by passengers like taxi rather than by bus company, they will choose the shortcuts to get more passengers like other cars do. It will increase the bus driver’s productivity but also increase the risk of having accidents.</p><h2><span id="how-people-interact">How People Interact</span></h2><h3><span id="principle-5-trade-can-make-everyone-better-off">Principle 5: Trade Can Make Everyone Better Off</span></h3><p><strong>Trade</strong> between two countries is not like a sports contest in which one side wins and the other side loses. In fact, the opposite is true: <em>Trade between two countries can make each country better off</em>.</p><p>Trade allows countries to specialize in what they do best and to enjoy a greater variety of goods and services.</p><h3><span id="principle-6-markets-are-usually-a-good-way-to-organize-economic-activity">Principle 6: Markets Are Usually a Good Way to Organize Economic Activity</span></h3><p><em>Communist</em> countries worked on the premise that government officials were in the best position to allocate the economy’s scarce resources. The theory behind <em>central planning</em> was that only the government could organize economic activity in a way that promoted <em>economic well-being for the country as a whole</em>. <em>Central planners</em> failed because they tried to run the economy with one hand tied behind their backs — the invisible hand of the marketplace.</p><p>In a <strong>market economy</strong>, the decisions of a central planner are replaced by the decisions of millions of firms and households.</p><blockquote><p>Households and firms interacting in markets act as if they are guided by an “invisible hand” that leads them to desirable market outcomes. — Adam Smith</p></blockquote><p>In any market, buyers look at the price when determining how much to demand, and sellers look at the price when deciding how much to supply. As a result of the decisions that buyers and sellers make, <em>market prices</em> reflect both <em>the value of a good to society</em> and <em>the cost to society of making the good</em>. Smith’s great insight was that <strong>prices</strong> adjust to <strong>guide</strong> these individual buyers and sellers to reach outcomes that, in many cases, <em>maximize the well-being of society as a whole</em>.</p><h3><span id="principle-7-governments-can-sometimes-improve-market-outcomes">Principle 7: Governments Can Sometimes Improve Market Outcomes</span></h3><p><strong>property right</strong>: the ability of an individual to own and exercise control over scarce resources. <strong>market failure</strong>: a situation in which a market left on its own fails to allocate resources efficiently. <strong>externality</strong>: the impact of one person’s actions on the well-being of a bystander. <strong>market power</strong>: the ability of a single economic actor (or a small group of actors) to have a substantial influence on market prices.</p><p><em>The invisible hand is powerful, but it is not omnipotent.</em> The economy needs the government to</p><ul><li>enforce the rules and maintain the institutions that are key to a market economy</li><li>enforce <strong>property right</strong><ul><li>We all rely on government-provided police and courts to enforce our rights over the things we produce — and the <em>invisible hand</em> counts on our ability to enforce our rights.</li></ul></li><li>promote <strong>efficiency</strong><ul><li><em>market failure</em> because <strong>externality</strong> (e.g. pollution) and <strong>market power</strong> (e.g. monopoly)</li></ul></li><li>promote <strong>equality</strong></li></ul><h2><span id="how-the-economy-as-a-whole-works">How the Economy as a Whole Works</span></h2><h3><span id="principle-8-a-countrys-standard-of-living-depends-on-its-ability-to-produce-goods-and-services">Principle 8: A Country’s Standard of Living Depends on Its Ability to Produce Goods and Services</span></h3><p>Why the differences in living standards among countries and over time are so large? Almost all variation in living standards is attributable to differences in countries’ <strong>productivity</strong> — that is, the amount of goods and services produced from each unit of labor input. When thinking about how any policy will affect our living standards, the key question is <em>how it will affect our ability to produce goods and services</em>.</p><h3><span id="principle-9-prices-rise-when-the-government-prints-too-much-money">Principle 9: Prices Rise When the Government Prints Too Much Money</span></h3><p><strong>inflation</strong>: an increase in the overall level of prices in the economy</p><p>What cause inflation? In almost all cases of large or persistent inflation, the culprit is <em>growth in the quantity of money</em>.</p><blockquote><p>The broken window fallacy Some teenagers, being the little beasts that they are, toss a brick through a bakery window. A crown gathers and laments, “What a shame”. But before you know it, someone suggests a silver lining to the situation: Now the baker will have to spend money to have the window repaired. This will add to the income of the repairman, who will spend his additional income, which will add to another seller’s income, and so on. The chain of spending will multiply and generate higher income and employment. If the broken window is large enough, it might produce an economic boom! But if the baker hadn’t spent his money on window repair, he would have spent it on the new suit he was saving to buy. Then the tailor would have the new income to spend, and so on. <em>The broken window didn’t create new spending; it just diverted spending from somewhere else.</em></p></blockquote><h3><span id="principle-10-society-faces-a-short-run-trade-off-between-inflation-and-unemployment">Principle 10: Society Faces a Short-Run Trade-off between Inflation and Unemployment</span></h3><p>Short-run effects of monetary injections as follows:</p><ul><li>Increasing the amount of money in the economy stimulates the overall level of spending and thus the demand for goods and services</li><li>Higher demand many over time cause firms to raise their prices, but in the meantime, it also encourage them to hire more workers and produce a larger quantity of goods and services.</li><li>More hiring means lower unemployment.</li></ul><p><strong>business cycle</strong>: fluctuations in economic activity, such as employment and production.</p><p>Case: 2008 deep economic downturn -&gt; Barack Obama: <em>stimulus package of reduced taxes and increased government spending</em> -&gt; Federal Reserve: <em>increased the supply of money</em> -&gt; <strong>reduce unemployment</strong> -&gt; might over time lead to an <strong>excessive level of inflation</strong>.</p><h2><span id="summary">Summary</span></h2><ol type="1"><li>The fundamental lessons about individual decision making are that people face trade-offs among alternative goals, that the cost of any action is measured in terms of forgone opportunities, that rational people make decisions by comparing marginal costs and marginal benefits, and that people change their behavior in response to the incentives they face.</li><li>The fundamental lessons about interactions among people are that trade and interdependence can be mutually beneficial, that markets are usually a good way of coordinating economic activity among people, and that the government can potentially improve market outcomes by remedying a market failure or by promoting greater economic equality.</li><li>The fundamental lessons about the economy as a whole are that productivity is the ultimate source of living standards, that growth in the quantity of money is the ultimate source of inflation, and that society faces a short-run trade-off between inflation and unemployment.</li></ol>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微观经济型原理 </tag>
            
            <tag> inflation </tag>
            
            <tag> marginal benefit </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>AlphaGo, AlphaGo Zero and AlphaZero</title>
      <link href="/2018/05/15/AlphaGo%20and%20AlphaGo%20Zero/"/>
      <url>/2018/05/15/AlphaGo%20and%20AlphaGo%20Zero/</url>
      
        <content type="html"><![CDATA[<h2><span id="go">Go</span></h2><p>围棋起源于古代中国，是世界上最古老的棋类运动之一。在宋代的《梦溪笔谈》中探讨了围棋的局数变化数目，作者沈括称“大约连书万字四十三个，即是局之大数”，意思是说变化数目要写43个万字。根据围棋规则，没有气的子不能存活，扣除这些状态后的合法状态约有 <span class="math inline">\(2.08×10^{170}\)</span> 种。Robertson 与 Munro 在1978年证得围棋是一种 PSPACE-hard 的问题，其必胜法之记忆计算量在<span class="math inline">\(10^{600}\)</span> 以上，这远远超过可观测宇宙的原子总数 <span class="math inline">\(10^{75}\)</span>，可见围棋对传统的搜索方法是非常有挑战的。 <a id="more"></a></p><p><img src="/images/go1.png"></p><h2><span id="alphago">AlphaGo</span></h2><p><img src="/images/alphago_ori.png"></p><p>AlphaGo是第一个打败人类冠军的电脑程序。</p><p><strong>网络结构</strong></p><p>它由两个卷积神经网络组成，分别是策略网络和价值网络。</p><p><img src="/images/policynet.png"></p><p>策略网络 P 推荐下一步怎么走；它的输入就是棋盘的矩阵：白棋和黑棋的位置。这个网络由许多卷积层组成，逐渐学习围棋知识，最终输出行动（action）的概率分布，来推荐下一步怎么走。</p><p><img src="/images/valuenet.png"></p><p>价值网络也由卷积神经网络组成，它是用来预测这盘棋的胜者。它的输入也是棋盘矩阵，输出是一个属于 <span class="math inline">\([-1, +1]\)</span> 的标量，-1代表AlphaGo一定会输，+1代表一定会赢。</p><p><strong>训练流程</strong></p><p><img src="/images/alphago_train.png"></p><p>首先是监督学习，让策略网络学习人类专家的数据集：每一个棋面都有一个标签，对应人类专家的下法，让AlphaGo首先学习专家的走法。然后使用策略网络进行自我博弈，由于每局都会产生胜者，用这些数据来训练价值网络。</p><p><strong>搜索算法</strong></p><p><img src="/images/rebredth.png"></p><p>使用策略网络减少搜索宽度，只考虑网络推荐的下法。</p><p><img src="/images/red_val.png"></p><p>还可以使用价值网络来降低搜索树的深度，可以把搜索子树替换为一个值来表明这个局面赢的概率。</p><p><img src="/images/mcts_go.png"></p><p>不过实际上还是用的蒙特卡洛搜索树。它分为三步：</p><ol type="1"><li><p>选择</p><p>首先从树根向下遍历，每次选择置信度最高的走法，直到叶节点。置信度是由每个节点中存储的 Q-value 和策略网络给的先验概率 P 组成。</p></li><li><p>扩展和评估</p><p>到了叶节点之后就要扩展这颗树，用策略网络和价值网络分别评估当前局面，把概率最大的节点加入搜索树。</p></li><li><p>回溯</p><p>把新加入节点的价值 v 回溯到路径上的每一个节点的 Q-value 上。</p></li></ol><p>这就是初始版本的AlphaGo，这个版本赢了世界冠军李世石。</p><p><img src="/images/leesd.png"></p><h2><span id="alphago-zero">AlphaGo Zero</span></h2><p>AlphaGo Zero 除了围棋规则本身以外完全移除了人类的围棋知识，它与AlphaGo的主要区别如下：</p><ul><li>无人类数据<ul><li>完全从自我博弈中学习</li></ul></li><li>无手动编码的特征<ul><li>输入只是棋盘本身</li></ul></li><li>单一的神经网络<ul><li>策略网络和价值网络合二为一，并且结构改进为ResNet</li><li>输出部分分为两头，分别输出 policy 和 value</li></ul></li><li>更简单的搜索<ul><li>更简单的MCTS，无随机的快速走子，只用神经网络进行评估</li></ul></li></ul><p><strong>增强学习算法</strong></p><p><img src="/images/rl_zero.png"></p><p>目标：使用高质量（really really high quality）数据来训练神经网络，而最好的数据来源就是AlphaGo自我博弈。</p><p>所以流程就是这样的：</p><ol type="1"><li>输入当前的棋局，使用当前的神经网络来指导进行蒙特卡洛搜索，然后下搜索出的那步棋，接着输入后面的棋局、搜索….直到一盘棋结束。</li></ol><p><img src="/images/train_zero.png"></p><ol start="2" type="1"><li>下一步就是训练神经网络，使用之前自我对局的数据，训练策略的数据的特征就是任一棋局，标签就是蒙特卡洛搜索的结果，即策略更贴近于AlphaGo实际下的策略（MCTS的搜索结果）</li></ol><p><img src="/images/train_zero_val.png"></p><ol start="3" type="1"><li>与此同时，使用每盘对局的胜者训练价值网络部分。</li></ol><p><img src="/images/zero_iterate.png"></p><ol start="4" type="1"><li>最后，经过训练的神经网络又可以继续进行自我博弈，产生更高质量的数据，然后用这个数据继续训练…. 循环往复，循环的关键在于，经过每个循环，我们都会得到更强的棋手（神经网络），所以继续会得到更高质量的数据。最后就产生了非常强的棋手。</li></ol><p><img src="/images/rl_policy_ite.png"></p><p>这个算法可以被看作是增强学习里的策略迭代（Policy Iteration）算法：</p><ul><li>Search-Based Policy Improvement （策略增强）<ul><li>用当前的网络进行MCTS</li><li>MCTS搜索出来的结果 &gt; 神经网络直接选择的结果（因为搜索的结果结合了前瞻）</li></ul></li><li>Search-Based Policy Evaluation （策略评估）<ul><li>使用搜索算法和神经网络进行自我博弈</li><li>评估改进后的策略</li></ul></li></ul><p><strong>学习曲线</strong></p><p><img src="/images/gozero_curve.png"></p><p><strong>实力</strong></p><p><img src="/images/gozero_rating.png"></p><h2><span id="alphazero">AlphaZero</span></h2><p><img src="/images/alphazero.png"></p><p>AlphaZero使用同一种算法学习三种不同的棋类，并都取得了超人的水平。</p><p>棋类AI研究情况总结</p><ul><li>在AI的历史上很早就开始研究棋类，如图灵、香农、冯诺伊曼等</li><li>专一系统曾在国际象棋上成功过<ul><li>深蓝在1997年击败卡氏</li><li>现在的象棋程序人类已无法击败</li></ul></li><li>将棋（日本象棋）比国际象棋更难<ul><li>更大的棋盘和行动空间</li><li>只有最近的程序才达到了龙王的水平</li></ul></li><li>最前沿的引擎都是根据 alpha-beta 搜索<ul><li>人类大师手工优化的评估函数</li><li>搜索域针对不同棋类疯狂优化</li></ul></li></ul><p><img src="/images/gochess.png"></p><p>由上图可见围棋与将棋和象棋还是有很大不同的，但是AlphaZero的主要算法和AlphaGo Zero一样，都是自我博弈的增强学习，只是把一些只针对围棋的细节去掉了（比如通过旋转进行数据增强，因为围棋是对称的）和输入输出维度进行了改变。</p><p>它的学习曲线如下，均达到了顶尖水平：</p><p><img src="/images/zero_curve2.png"></p><h2><span id="alphazero-and-exit">AlphaZero and ExIt</span></h2><p><a href="https://arxiv.org/abs/1705.08439" target="_blank" rel="noopener">Expert Iteration（ExIt）</a>是一种模仿学习（Imitation Learning, IL）算法，普通的 IL 算法中，徒弟模仿专家的策略只能提高自己的策略，专家是不会有任何提高的，而 ExIt 算法就是想让师傅教徒弟的时候自己也有提高。</p><p><strong>ExIt 算法</strong> 师傅根据徒弟的策略进行前向搜索（例如MCTS，alpha-beta，贪心搜索等），得出比徒弟更好的策略，然后徒弟再学习师傅的策略，如此循环，随着徒弟的增强，师傅也会越来越强。</p><p><img src="/images/exit.png"></p><p>可见，AlphaZero也属于 ExIt 算法，师傅为 MCTS，徒弟就是神经网络。</p><h2><span id="summary">Summary</span></h2><p>现在棋类人工智能算法的发展趋势是越来越泛化，趋向于多功能。从 AlphaGo 的学习人类专家的棋谱到 AlphaGo Zero 的从零开始无需人类知识的自我博弈学习再到 AlphaZero 的同一算法适应不同棋类并且都取得超人水平。可见人工智能越来越向通用智能发展，虽然长路漫漫，现在的算法远不够泛化，但是很多东西，比如神经网络结构都是可以用到不同领域的。AlphaGo 系列的作者之一 David Silver 曾说:“每次你专门化一些东西都会伤害你的泛化能力” (Every time you specialize something you hurt your generalization ability.)。事实也的确如此，AlphaGo 系列架构越来越简单，而其性能和泛化能力却越来越强大。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> AlphaZero </tag>
            
            <tag> 增强学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>论文翻译：在没有人类知识的情况下掌握围棋</title>
      <link href="/2018/03/10/%E5%9C%A8%E6%B2%A1%E6%9C%89%E4%BA%BA%E7%B1%BB%E7%9F%A5%E8%AF%86%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E6%8E%8C%E6%8F%A1%E5%9B%B4%E6%A3%8B/"/>
      <url>/2018/03/10/%E5%9C%A8%E6%B2%A1%E6%9C%89%E4%BA%BA%E7%B1%BB%E7%9F%A5%E8%AF%86%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E6%8E%8C%E6%8F%A1%E5%9B%B4%E6%A3%8B/</url>
      
        <content type="html"><![CDATA[<h4><span id="1-前言">1. 前言</span></h4><p>​ 人工智能的一个长期目标是在一些有挑战的领域中从零开始学习出超人熟练程度的算法。最近，AlphaGo成为第一个在围棋比赛中击败世界冠军的程序。 AlphaGo中的树搜索使用深度神经网络评估位置和选定的移动。这些神经网络是通过监督学习来自人类专家的走法以及通过强化自我学习来进行训练的。这里我们只介绍一种基于强化学习的算法，没有超出游戏规则的人类数据，指导或领域知识。AlphaGo成为自己的老师：一个神经网络训练预测AlphaGo的移动选择和游戏的胜者。这个神经网络提高了树搜索的强度，在下一次迭代中拥有更高质量的移动选择和更强的自我学习。我们的新程序AlphaGo Zero从零开始学习，实现了超人的表现，与之前发布的夺冠冠军AlphaGo相比以100-0取胜。</p><a id="more"></a><h4><span id="2-概述">2. 概述</span></h4><p>​ 围棋程序在人工智能方面已经取得了很大的进展，使用经过训练的监督学习系统来复制人类专家的决定。但是，专家数据集通常很昂贵，不可靠或根本无法使用。即使有可靠的数据集，它们也可能会对以这种方式培训的系统的性能施加上限。相比之下，强化学习系统是根据他们自己的经验进行学习的，原则上允许他们超越人类能力，并在缺乏人力专业知识的领域运作。最近，通过强化学习训练的深度神经网络，朝着这个目标快速发展。这些系统在计算机游戏中胜过人类，如Atari游戏和3D虚拟环境。然而，在人类智力方面最具挑战性的领域 - 比如被广泛认为是人工智能的巨大挑战的围棋游戏 - 在广阔的搜索空间中需要精确和复杂的搜索。以前的方法没有在这些领域实现达到人类水平的表现。</p><p>​ AlphaGo 是第一个在围棋中实现超人表现的程序。之前发布的版本，我们称之为AlphaGo Fan，于2015年10月击败了欧洲冠军范辉。AlphaGo Fan 使用了两个深度神经网络：输出移动概率的策略网络和输出位置评估的价值网络。策略网络最初是通过监督学习来准确地预测人类专家的行为，随后通过策略升级强化学习进行了改进。价值网络经过训练，可以预测游戏的胜者。一旦开始训练，这些网络就会与蒙特卡洛树搜索（MCTS）结合使用，从而提供先行搜索，使用策略网络将搜索范围缩小为高概率移动，并使用价值网络来评估树中的位置。我们称之为 AlphaGo Lee 的后续版本使用了类似的方法，并于2016年3月击败了获得18个国际冠军的Lee Sedol。</p><p>​ AlphaGo Zero 与 AlphaGo Fan 和 AlphaGo Lee 在几个重要方面不同。首先，它只是通过自我增强强化学习进行训练，从随机比赛开始，没有任何监督或使用人类数据。其次，它只使用黑白棋位置作为输入。第三，它使用单一的神经网络，而不是单独的策略和价值网络。最后，它使用更简单的搜索树，该搜索依赖于这个单一的神经网络来评估位置和移动，而无需执行任何 Monte Carlo 回溯。为了实现这些结果，我们引入了一种新的强化学习算法，该算法在训练环内部结合了前瞻搜索，从而实现了快速改进和精确而稳定的学习。在方法一栏中中描述了搜索算法，训练过程和网络体系结构中的其他技术差异。</p><h4><span id="3-alphago-zero-中的增强学习">3. AlphaGo Zero 中的增强学习</span></h4><p>​ 我们的新方法使用参数为 <span class="math inline">\(\theta\)</span> 的深度神经网络 <span class="math inline">\(f(\theta)\)</span>。该神经网络将位置及其历史的原始平面表示 s 作为输入，并输出移动概率和价值 <span class="math inline">\((p,v)=f_\theta(s)\)</span>。 移动概率 p 的向量表示选择每个移动 a 的概率，<span class="math inline">\(P_a=Pr(a|s)\)</span> 。价值 v 是一个标量评估，用于估计当前玩家从位置 s 获胜的概率。这个神经网络将策略网络和价值网络结合到一个网络中。神经网络由卷积层，许多残差块组成，批量归一化和非线性整流器（参见方法）组成。</p><p>​ AlphaGo Zero 中的神经网络是通过一种新型的强化学习算法从自我博弈的游戏中训练出来的。在每个位置 <span class="math inline">\(s\)</span>，执行 MCTS 搜索，由神经网络 <span class="math inline">\(f(\theta)\)</span> 指导。MCTS 搜索输出每次移动的概率 <span class="math inline">\(π\)</span>。这些搜索概率通常选择比神经网络的原始移动概率 <span class="math inline">\(p\)</span> 更加强大;因此，MCTS 可被视为策略改进的操作。使用搜索进行自我博弈 - 使用改进的基于 MCTS 的策略来选择每个动作，然后使用游戏获胜者 <span class="math inline">\(z\)</span> 作为价值的样本 - 可以被视为一个强大的策略评估操作。我们的强化学习算法的主要思想是在策略迭代过程中重复使用这些操作：更新神经网络的参数以使移动概率和值 <span class="math inline">\((p,v)=f_\theta(s)\)</span> 更紧密匹配改进的搜索概率和获胜者 <span class="math inline">\((\pi,z)\)</span>；这些新参数将用于下一次自我博弈，以使搜索更加强大。图 1说明了自我博弈训练流程。</p><p><img src="/images/selfplay.png"></p><p>​ <em>图1 AlphaGo Zero中的自我博弈与增强学习训练流程</em></p><p>​ MCTS 使用神经网络 <span class="math inline">\(f(\theta)\)</span> 来指导其模拟（见图 2）。搜索树中的每个边 <span class="math inline">\((s,a)\)</span> 存储先验概率 <span class="math inline">\(P(s,a)\)</span>，访问计数 <span class="math inline">\(N(s,a)\)</span> 和动作价值 <span class="math inline">\(Q(s,a)\)</span> 。每个模拟从根状态开始，并且迭代地选择使置信上限 <span class="math inline">\(Q(s,a)+U(s,a)\)</span> 最大化的移动，其中<span class="math inline">\(U\propto \frac{P(s,a)}{1+N(s,a)}\)</span>，直到遇到叶节点 <span class="math inline">\(s&#39;\)</span>。该叶子位置被网络扩展和评估一次，以产生先验概率和评估，<span class="math inline">\((P(s&#39;, \cdot), v(s&#39;))=f_\theta(s&#39;)\)</span>。在模拟中遍历的每个边 <span class="math inline">\((s,a)\)</span> 被更新以增加其访问计数 <span class="math inline">\(N(s,a)\)</span>，并且将其动作价值更新为在这些模拟上的平均评估 <span class="math inline">\(Q(s,a) = \frac{1}{N(s,a)}\sum_{s&#39;|s,a\rightarrow s&#39;}V(s&#39;)\)</span>， 其中 <span class="math inline">\(s,a\rightarrow s&#39;\)</span> 表示在从位置 <span class="math inline">\(s\)</span> 执行行动 <span class="math inline">\(a\)</span> 后模拟最终达到位置 <span class="math inline">\(s&#39;\)</span>。</p><p><img src="/images/mcts0.png"></p><p>​ <em>图2 AlphaGo Zero中的蒙特卡洛搜索树</em></p><p>​ MCTS 可以被看作是一种自我博弈算法，在给定神经网络参数 <span class="math inline">\(θ\)</span> 和根位置 <span class="math inline">\(s\)</span> 的情况下，计算推荐移动的搜索概率矢量，<span class="math inline">\(\pi = a_\theta(s)\)</span>，与每次移动的访问计数的指数成比例，<span class="math inline">\(\pi_a\propto N(s,a)^{1/\tau}\)</span>，其中 <span class="math inline">\(τ\)</span> 是温度参数。</p><p>​ 神经网络通过使用 MCTS 选择每个动作的自我博弈增强化学习算法进行训练。首先，神经网络被初始化为随机权重 <span class="math inline">\(\theta_0\)</span>。在随后的每次迭代 <span class="math inline">\(i≥1\)</span> 时，产生自我博弈的数据（图 1）。在每个时刻 <span class="math inline">\(t\)</span>，使用先前的神经网络迭代 <span class="math inline">\(f_{\theta_{i-1}}\)</span> 执行 MCTS 搜索，并且通过对搜索概率 <span class="math inline">\(\pi_t\)</span> 进行采样来执行移动。当两个玩家都无路可走时或者当搜索值下降到低于阈值或当游戏超过最大长度时，游戏在时刻 <span class="math inline">\(T\)</span> 终止;然后对游戏进行评分以给出 <span class="math inline">\(r_T\in\{-1,+1\}\)</span> 的最终奖励（详见方法）。每个时刻 <span class="math inline">\(t\)</span> 的数据存储为 <span class="math inline">\((s_t,\pi_t,z_t)\)</span>，其中 <span class="math inline">\(z_t = \pm r_T\)</span> 是时刻 <span class="math inline">\(t\)</span> 从当前玩家角度出发的游戏获胜者。同时（如图 1），新的网络参数 <span class="math inline">\(\theta_i\)</span> 从最后一次自我博弈的所有时间中统一采样的数据 <span class="math inline">\((s,\pi,t)\)</span> 进行训练。调整神经网络 <span class="math inline">\((p,v)=f_{\theta_i}(s)\)</span> 以最小化预测值 <span class="math inline">\(v\)</span> 与实际赢得者 <span class="math inline">\(z\)</span>之间的误差，并使神经网络移动概率 <span class="math inline">\(p\)</span> 与搜索概率 <span class="math inline">\(π\)</span> 的相似性最大化。具体而言，参数 <span class="math inline">\(θ\)</span> 通过梯度下降在损失函数 <span class="math inline">\(l\)</span> 上进行调整，所述损失函数 <span class="math inline">\(l\)</span> 分别对均方误差和交叉熵误差进行求和： <span class="math display">\[(p,v)=f_\theta(s) \mbox{ and }l=(z-v)^2-\pi^T\log p+c||\theta||^2\]</span> 其中 <span class="math inline">\(c\)</span> 是控制 L2 正则化程度的超参数（为了防止过拟合）。</p><h4><span id="4-alphago-zero-的实验分析">4. AlphaGo Zero 的实验分析</span></h4><p>​ 我们使用上述强化学习流程来训练 AlphaGo Zero。训练从完全随机的行为开始，持续约三天且无人为干预。在训练过程中，每个 MCTS 使用 1,600 次模拟，每次移动的思考时间大约为 0.4s，从而产生了 490 万局自我博弈。 参数从 700,000 个包含 2048 个状态的批量中更新。神经网络包含 20 个残余块。</p><p>​ 图 3 显示了 AlphaGo Zero 在自我博弈过程中的表现，横坐标为训练时间，纵坐标为 Elo 量。整个训练过程进展顺利，并且没有遭受先前文献中提出的振荡或灾难性遗忘。令人惊讶的是，AlphaGo Zero 仅仅 36 小时就赢了AlphaGo Lee。相比之下，AlphaGo Lee 训练了几个月。在 72 小时后，我们根据在首尔人机比赛中使用的相同的 2 小时时间控制和匹配条件，对 AlphaGo Zero 与 AlphaGo Lee 的确切版本进行了评估，该版本击败了 Lee Sedol。AlphaGo Zero 使用带有4个张量处理单元（TPU）的单台机器，而 AlphaGo Lee 分布在多台机器上并使用 48 个TPU。AlphaGo Zero 将 AlphaGo Lee 以 100 比 0 击败。</p><p>​ 为了评估自我强化学习的优点，与从人类数据中学习相比，我们训练了第二个神经网络（使用相同的体系结构）来预测 KGS 服务器数据集中的专家动作; 与之前的工作相比，这实现了预测的准确性。 监督式学习的初始表现更好，并且更好地预测人类职业动作（图 3）。 值得注意的是，尽管监督学习获得了更高的移动预测准确度，但自学者的整体表现更好，在训练的前 24 小时内击败了训练有素的选手。这表明 AlphaGo Zero 可能正在学习一种与人类下棋不同的策略。</p><p><img src="/images/ag0em.png"></p><p>​ <em>图3 AlphaGo Zero的实验评估</em></p><p>​ 为了分离架构和算法的贡献，我们将 AlphaGo Zero 中的神经网络架构的性能与 AlphaGo Lee 中使用的以前的神经网络架构进行了比较（见图 4）。 新训练的AlphaGo Zero 有四个版本的神经网络，分别是：使用 AlphaGo Lee 的卷积网络架构；AlphaGo Zero 的剩余网络架构；使用 AlphaGo Zero 的卷积网络架构；使用AlphaGo Lee 的剩余网络架构。每个网络都经过训练，以最小化相同的损失函数，使用由 AlphaGo Zero 在自我训练 72 小时后产生的固定数据集。使用剩余网络更准确，实现了更低的误差，AlphaGo 的性能提高了 600 多 Elo。将策略和价值组合在一起成为一个网络，略微降低了移动预测的准确性，但是将降低了 AlphaGo 的价值误差和提高了博弈性能约 600 个 Elo。部分原因在于提高了计算效率，但更重要的是，双重目标将网络正则化为支持多种用例的表示。</p><p><img src="/images/ag02.png"></p><p>​ <em>图4 AlphaGo Zero和AlphaGo Lee的神经网络结构比较</em></p><h4><span id="5-alphago-zero-学习到的围棋知识">5. AlphaGo Zero 学习到的围棋知识</span></h4><p>​ AlphaGoZero在其自我博弈训练过程中发现了非凡的围棋知识水平。这不仅包括人类围棋知识的基本要素，还包括超出传统围棋知识范围的非标准策略。</p><p>​ 图 5显示了一个时间线，表明何时发现了专业 joseki（角点序列）;最终AlphaGo Zero 更喜欢先前未知的新的 joseki 变体（图5b ）。图5c 显示了几种在不同训练阶段进行的快速自我博弈。在整个训练中定期进行的锦标赛长度比赛在补充信息中显示。 AlphaGo Zero 从完全随机的移动过渡到对围棋概念的复杂理解，包括fuseki（开场），tesuji（战术），生与死，ko（重复棋局），yose（终局），捕捉比赛，sente（倡议），形状，影响力和领土，都是从最初的原则发现的。令人惊讶的是，Shocho - 人类学习的围棋知识的第一要素之一 - 只有在 AlphaGo Zero 的训练中才能被理解。</p><p><img src="/images/ag05.png"></p><p>​ <em>图5 AlphaGo Zero学到的围棋知识</em></p><h4><span id="6-alphago-zero-的最终水平">6. AlphaGo Zero 的最终水平</span></h4><p>​ 随后我们使用更大的神经网络和更长的持续时间将我们的强化学习管道应用于AlphaGo Zero的第二个实例。再次训练从完全随机行为开始并持续大约40天。</p><p>​ 在训练过程中，产生了 2900 万次自我博弈。参数从每个 2,048 个位置的 310 万个小型批量中更新。神经网络包含 40 个残余块。学习曲线如图 6a 所示。在整个训练过程中定期进行的比赛显示在补充信息中。</p><p><img src="/images/ag06.png"></p><p>​ <em>图6 AlphaGo Zero的评估</em></p><p>​ 我们使用 AlphaGo Fan，AlphaGo Lee 和之前的几个围棋程序的内部比赛评估了训练有素的 AlphaGo Zero。我们还与最强大的现有程序 AlphaGo Master 进行了游戏，该程序基于本文提供的算法和体系结构，但使用了人类数据和特征（请参阅方法） - 它在 60-0 在线游戏中击败了最强的人类职业玩家。在我们的评估中，所有程序都允许每个动作有5秒的思考时间; AlphaGo Zero 和 AlphaGo Master 每台在带有 4 个 TPU 的单台机器上博弈; AlphaGo Fan 和 AlphaGo Lee 分别分布有 176 个GPU和 48 个TPU。我们还包括一个完全基于 AlphaGo Zero 原始神经网络的选手; 该选手只是以最大的概率选择移动（不进行 MCTS 搜索）。</p><p>​ 图 6b显示了每个程序在Elo规模上的表现。未使用任何预测的原始神经网络实现了3,055的Elo评级。 AlphaGo Zero 获得了5,185的评分，而 AlphaGo Master 的4,858，AlphaGo Lee 的 3,739和 AlphaGo Fan 的3,144。</p><p>​ 最后，我们评估了 AlphaGo Zero 对阵 AlphaGo Master，在每场2小时的时间限定内进行了100场比赛，AlphaGo Zero 赢得了其中的89场。</p><h4><span id="7-结论">7. 结论</span></h4><p>​ 我们的研究结果全面证明，即使在最具挑战性的领域中，纯粹的强化学习方法也是完全可行的：在不超出基本规则的情况下，没有关于领域的知识，就可以训练到超人的水平，没有人类的例子或指导。此外，与用人类专家数据训练的程序相比，纯粹的强化学习方法只需要几个小时的训练时间就能达到更好的性能。使用这种方法，AlphaGo Zero 大幅度击败了使用人工数据训练的 AlphaGo 最强大的先前版本。</p><p>​ 人类已经积累了几千年来的围棋知识，发展成固定的模式，总结成谚语和书籍。在几天的时间里，AlphaGo Zero 从零学起，就能够重新发现许多的围棋知识，并能为这个古老的游戏提供新见解、新策略。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> AlphaZero </tag>
            
            <tag> 增强学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Integrating Learning and Planning</title>
      <link href="/2018/01/09/RL%20-%20Integrating%20Learning%20and%20Planning/"/>
      <url>/2018/01/09/RL%20-%20Integrating%20Learning%20and%20Planning/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>In last lecture, we learn <strong>policy</strong> directly from experience. In previous lectures, we learn <strong>value function</strong> directly from experience. In this lecture, we will learn <strong>model</strong> directly from experience and use <strong>planning</strong> to construct a value function or policy. Integrate learning and planning into a single architecture.</p><p>Model-Based RL</p><ul><li>Learn a model from experience</li><li><strong>Plan</strong> value function (and/or policy) from model</li></ul><a id="more"></a><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#model-based-reinforcement-learning">Model-Based Reinforcement Learning</a></li><li><a href="#integrated-architectures">Integrated Architectures</a></li><li><a href="#simulation-based-search">Simulation-Based Search</a></li></ul><!-- tocstop --><h2><span id="model-based-reinforcement-learning">Model-Based Reinforcement Learning</span></h2><p><img src="/images/mbrl.png"></p><p>Advantages of Model-Based RL</p><ul><li>Can efficiently learn model by supervised learning methods</li><li>Can reason about model uncertainty</li></ul><p>Disadvantages</p><ul><li>First learn a model, then construct a value function -&gt; two source of approximation error</li></ul><p><strong>What is a Model?</strong></p><p>A model <span class="math inline">\(\mathcal{M}\)</span> is a representation of an MDP <span class="math inline">\(&lt;\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}&gt;\)</span> parametrized by <span class="math inline">\(\eta\)</span>.</p><p>We will assume state space <span class="math inline">\(\mathcal{S}\)</span> and action space <span class="math inline">\(\mathcal{A}\)</span> are known. So a model <span class="math inline">\(\mathcal{M}=&lt;\mathcal{P}_, \eta\mathcal{R}_\eta&gt;\)</span> represents state transitions <span class="math inline">\(\mathcal{P}_\eta \approx \mathcal{P}\)</span> and rewards <span class="math inline">\(\mathcal{R}_\eta\approx \mathcal{R}\)</span>. <span class="math display">\[S_{t+1}\sim\mathcal{P}_\eta(S_{t+1}|S_t, A_t)\\R_{t+1}=\mathcal{R}_\eta(R_{t+1}|S_t, A_t)\]</span> Typically assume conditional independence between state transitions and rewards.</p><p>Goal: estimate model <span class="math inline">\(\mathcal{M}_\eta\)</span> from experience <span class="math inline">\(\{S_1, A_1, R_2, …, S_T\}\)</span>.</p><p>This is a supervised learning problem: <span class="math display">\[S_1, A_1 \rightarrow R_2, S_2 \\S_2, A_2 \rightarrow R_3, S_3 \\...\\S_{T-1}, A_{T-1} \rightarrow R_T, S_T \\\]</span> Learning <span class="math inline">\(s, a\rightarrow r\)</span> is a <em>regression</em> problem; learning <span class="math inline">\(s, a\rightarrow s&#39;\)</span> is a <em>density</em> estimation problem. Pick loss function, e.g. mean-squared error, KL divergence, … Find parameters <span class="math inline">\(\eta\)</span> that minimise empirical loss.</p><p>Examples of Models</p><ul><li>Table Lookup Model</li><li>Linear Expectation Model</li><li>Linear Gaussian Model</li><li>Gaussian Process Model</li><li>Deep Belief Network Model</li></ul><p><strong>Table Lookup Model</strong></p><p>Model is an explicit MDP. Count visits <span class="math inline">\(N(s, a)\)</span> to each state action pair: <span class="math display">\[\hat{\mathcal{P}}^a_{s,s&#39;}=\frac{1}{N(s,a)}\sum^T_{t=1}1(S_t,A_t,S_{t+1}=s, a, s&#39;)\\\hat{\mathcal{R}}^a_{s,s&#39;}=\frac{1}{N(s,a)}\sum^T_{t=1}1(S_t,A_t=s, a)R_t\]</span> Alternatively, at each time-step <span class="math inline">\(t\)</span>, record experience tuple <span class="math inline">\(&lt;S_t, A_t, R_{t+1}, S_{t+1}&gt;\)</span>. To sample model, randomly pick tuple matching <span class="math inline">\(&lt;s, a, \cdot, \cdot&gt;\)</span>.</p><p><strong>AB Example</strong></p><p><img src="/images/ab2.png"></p><p>We have contrusted a <strong>table lookup model</strong> from the experience. Next step, we will planning with a model.</p><p><strong>Planning with a model</strong></p><p>Given a model <span class="math inline">\(\mathcal{M}_\eta=&lt;\mathcal{P}_\eta, \mathcal{R}_\eta&gt;\)</span>, solve the MDP <span class="math inline">\(&lt;\mathcal{S}, \mathcal{A}, \mathcal{P}_\eta, \mathcal{R}_\eta&gt;\)</span> using favorite planning algorithms</p><ul><li>Value iteration</li><li>Policy iteration</li><li>Tree search</li><li>….</li></ul><p><strong>Sample-Based Planning</strong></p><p>A simple but powerful approach to planning is to use the model <strong>only</strong> to generate samples.</p><p><strong>Sample</strong> experience from model <span class="math display">\[S_{t+1}\sim\mathcal{P}_\eta(S_{t+1}|S_t,A_t)\\R_{t+1}=\mathcal{R}_\eta(R_{t+1}|S_t,A_t)\]</span> Apply <strong>model-free</strong> RL to samples, e.g.:</p><ul><li>Monte-Carlo control</li><li>Sarsa</li><li>Q-learning</li></ul><p>Sample-based planning methods are often more efficient.</p><p><strong>Back to AB Example</strong></p><p><img src="/images/ab3.png"></p><p>We can use our model to sample more experience and apply model-free RL to them.</p><p><strong>Planning with an Inaccurate Model</strong></p><p>Given an imperfect model <span class="math inline">\(&lt;\mathcal{P}_\eta, \mathcal{R}_\eta&gt; ≠ &lt;\mathcal{P}, \mathcal{R}&gt;\)</span>. Performance of model-based RL is limited to optimal policy for approximate MDP <span class="math inline">\(&lt;\mathcal{S}, \mathcal{A}, \mathcal{P}_\eta, \mathcal{R}_\eta&gt;\)</span> i.e. Model-based RL is only as good as the estimated model.</p><p>When the model is inaccurate, planning process will compute a suboptimal policy.</p><ul><li>Solution1: when model is wrong, use model-free RL</li><li>Solution2: reason explicitly about model uncertainty</li></ul><h2><span id="integrated-architectures">Integrated Architectures</span></h2><p>We consider two sources of experience:</p><ul><li><p>Real experience: Sampled from environment (true MDP) <span class="math display">\[S&#39;\sim \mathcal{P}^a_{s,s&#39;}\\R=\mathcal{R}^a_s\]</span></p></li><li><p>Simulated experience: Sampled from model (approximate MDP) <span class="math display">\[S&#39;\sim \mathcal{P}_\eta(S&#39;|S, A)\\R=\mathcal{R}_\eta(R|S, A)\]</span></p></li></ul><p><strong>Integrating Learning and Planning</strong></p><p>Dyna Architecture</p><ul><li>Learn a model from real experience</li><li>Learn and plan value function (and/or policy) from real and simulated experience</li></ul><p><img src="/images/dyna.png"></p><p>The simplest dyna algorithm is <em>Dyna-Q Algorithm</em>:</p><p><img src="/images/dynaq.png"></p><p><img src="/images/dynaqres.png"></p><p>From the experiments, we can see that using planning is more efficient than direct RL only.</p><p><strong>Dyna-Q with an Inaccurate Model</strong></p><p>The changed envrionment is <strong>harder</strong>:</p><p><img src="/images/dynaqhard.png"></p><p>There is a <strong>easier</strong> change:</p><p><img src="/images/dynaqeasy.png"></p><h2><span id="simulation-based-search">Simulation-Based Search</span></h2><p>Let's back to planning problems. Simulation-based search is another approach to solve MDP.</p><p><strong>Forward Search</strong></p><p>Forward search algorithms select the best action by <strong>lookahead</strong>. They build a <strong>search tree</strong> with the current state <span class="math inline">\(s_t\)</span> at the root using a model of the MDP to look ahead.</p><p><img src="/images/ftree.png"></p><p>We don't need to solve the whole MDP, just sub-MDP starting from <strong>now</strong>.</p><p><strong>Simulation-Based Search</strong></p><p>Simulation-based search is forward search paradigm using sample-based planning. Simulate episodes of experience from <strong>now</strong> with the model. Apply <strong>model-free</strong> RL to simulated episodes.</p><p><img src="/images/sbsearch.png"></p><p>Simulate episodes of experience from <strong>now</strong> with the model: <span class="math display">\[\{s_t^k, A^k_t,R^k_{t+1}, ..., S^k_T\}^K_{k=1}\sim\mathcal{M}_v\]</span> Apply <strong>model-free</strong> RL to simulated episodes</p><ul><li>Monte-Carlo control <span class="math inline">\(\rightarrow\)</span> Monte-Carlo search</li><li>Sarsa <span class="math inline">\(\rightarrow\)</span> TD search</li></ul><p><strong>Simple Monte-Carlo Search</strong></p><p>Given a model <span class="math inline">\(\mathcal{M}_v\)</span> and a simulation policy <span class="math inline">\(\pi\)</span>.</p><p>For each action <span class="math inline">\(a\in\mathcal{A}\)</span></p><ul><li><p>Simulate <span class="math inline">\(K\)</span> episodes from current (real) state <span class="math inline">\(s_t\)</span> <span class="math display">\[\{s_t, a, R^k_{t+1},S^k_{t+1},A^k_{t+1}, ..., S^k_T \}^K_{k=1}\sim \mathcal{M}_v, \pi\]</span></p></li><li><p>Evaluate actions by mean return (<strong>Monte-Carlo evaluation</strong>) <span class="math display">\[Q(s_t, a)=\frac{1}{K}\sum^k_{k=1}G_t\rightarrow q_\pi(s_t, a)\]</span></p></li></ul><p>Select current (real) action with maximum value <span class="math display">\[a_t=\arg\max_{a\in\mathcal{A}}Q(s_t, a)\]</span> <strong>Monte-Carlo Tree Search</strong></p><p>Given a model <span class="math inline">\(\mathcal{M}_v\)</span>. Simulate <span class="math inline">\(K\)</span> episodes from current state <span class="math inline">\(s_t\)</span> using current simulation policy <span class="math inline">\(\pi\)</span>. <span class="math display">\[\{s_t, A_t^k, R^k_{t+1},S^k_{t+1},A^k_{t+1}, ..., S^k_T \}^K_{k=1}\sim \mathcal{M}_v, \pi\]</span> Build a search tree containing visited states and actions. <strong>Evaluate</strong> states <span class="math inline">\(Q(s, a)\)</span> by mean return of episodes from <span class="math inline">\(s, a\)</span>: <span class="math display">\[Q(s, a)=\frac{1}{N(s,a)}\sum^K_{k=1}\sum^T_{u=t}1(S_u, A_u=s,a)G_u \to q_\pi(s,a)\]</span> After search is finished, select current (real) action with maximum value in search tree: <span class="math display">\[a_t=\arg\max_{a\in\mathcal{A}}Q(s_t, a)\]</span> In MCTS, the simulation policy <span class="math inline">\(\pi\)</span> <strong>improves</strong>.</p><p>Each simulation consists of two phases (in-tree, out-of-tree)</p><ul><li><strong>Tree policy</strong> (improves): pick actions to maximise <span class="math inline">\(Q(S,A)\)</span></li><li><strong>Default policy</strong> (fixed): pick actions randomly</li></ul><p>Repeat (each simulation)</p><ul><li><span class="math inline">\(\color{red}{\mbox{Evaluate}}\)</span> states <span class="math inline">\(Q(S,A)\)</span> by Monte-Carlo evaluation</li><li><span class="math inline">\(\color{red}{\mbox{Improve}}\)</span> tree policy, e.g. by <span class="math inline">\(\epsilon\)</span>-greedy(Q)</li></ul><p>MCTS is <strong>Monte-Carlo control</strong> applied to <strong>simulated experience</strong>.</p><p>Converges on the optimal search tree, <span class="math inline">\(Q(S, A) \to q_*(S, A)\)</span>.</p><p><strong>Case Study: the Game of Go</strong></p><p><img src="/images/go_2.png"></p><p><em>Rules of Go</em></p><ul><li>Usually played on 19$<span class="math inline">\(19, also 13\)</span><span class="math inline">\(13 or 9\)</span>$9 board</li><li>Black and white place down stones alternately</li><li>Surrounded stones are captured and removed</li><li>The player with more territory wins the game</li></ul><p><img src="/images/ruleofgo.png"></p><p><em>Position Evaluation in Go</em></p><p>The key problem is how good is a position <span class="math inline">\(s\)</span>?</p><p>So the reward function is if Black wins, the reward of the final position is 1, otherwise 0: <span class="math display">\[R_t = 0 \mbox{ for all non-terminal steps } t&lt;T\\R_T=\begin{cases} 1,  &amp; \mbox{if }\mbox{ Black wins} \\0, &amp; \mbox{if }\mbox{ White wins}\end{cases}\]</span> Policy <span class="math inline">\(\pi=&lt;\pi_B,\pi_W&gt;\)</span> selects moves for both players.</p><p>Value function (how good is position <span class="math inline">\(s\)</span>): <span class="math display">\[v_\pi(s)=\mathbb{E}_\pi[R_T|S=s]=\mathbb{P}[Black wins|S=s]\\v_*(s)=\max_{\pi_B}\min_{\pi_w}v_\pi(s)\]</span> <em>Monte Carlo Evaluation in Go</em></p><p><img src="/images/mcego.png"></p><p><img src="/images/amcts1.png"></p><p><img src="/images/amcts2.png"></p><p><img src="/images/amcts3.png"></p><p><img src="/images/amcts4.png"></p><p><img src="/images/amcts5.png"></p><p>So, MCTS will expand the tree towards the node that is most promising and ignore the useless parts.</p><p><strong>Advantages of MC Tree Search</strong></p><ul><li>Highly selective best-first search</li><li>Evaluates states <em>dynamically</em></li><li>Uses sampling to break curse of dimensionality</li><li>Works for &quot;black-box&quot; models (only requires samples)</li><li>Computationally efficient, anytime, parallelisable</li></ul><p><strong>Temporal-Difference Search</strong></p><ul><li>Simulation-based search</li><li>Using TD instead of MC (bootstrapping)</li><li>MC tree search applies MC control to sub-MDP from now</li><li>TD search applies Sarsa to sub-MDP from now</li></ul><p><strong>MC vs. TD search</strong></p><p>For model-free reinforcement learning, bootstrapping is helpful</p><ul><li>TD learning reduces variance but increase bias</li><li>TD learning is usually more efficient than MC</li><li>TD(<span class="math inline">\(\lambda\)</span>) can be much more efficient than MC</li></ul><p>For simulation-based search, bootstrapping is also helpful</p><ul><li>TD search reduces variance but increase bias</li><li>TD search is usually more efficient than MC search</li><li>TD(<span class="math inline">\(\lambda\)</span>) search can be much more efficient than MC search</li></ul><p><strong>TD Search</strong></p><p>Simulate episodes from the current (real) state <span class="math inline">\(s_t\)</span>. Estimate action-value function <span class="math inline">\(Q(s, a)\)</span>. For each step of simulation, update action-values by Sarsa: <span class="math display">\[\triangle Q(S,A)=\alpha (R+\gamma Q(S&#39;,A&#39;)-Q(S,A))\]</span> Select actions based on action-value <span class="math inline">\(Q(s,a)\)</span>, e.g. <span class="math inline">\(\epsilon\)</span>-greedy. May also use function approximation for <span class="math inline">\(Q\)</span>.</p><p><strong>Dyna-2</strong></p><p>In Dyna-2, the agent stores two sets of feature weights:</p><ul><li><strong>Long-term</strong> memory</li><li><strong>Short-term</strong> (working) memory</li></ul><p>Long-term memory is updated from <strong>real experience</strong> using TD learning</p><ul><li>General domain knowledge that applies to any episode</li></ul><p>Short-term memory is updated from <strong>simulated experience</strong> using TD search</p><ul><li>Specific local knowledge about the current situation</li></ul><p>Over value function is sum of long and short-term memories.</p><p>End.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> MCTS </tag>
            
            <tag> TD Search </tag>
            
            <tag> Dyna </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Policy Gradient</title>
      <link href="/2018/01/06/RL%20-%20Policy%20Gradient/"/>
      <url>/2018/01/06/RL%20-%20Policy%20Gradient/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>This lecture talks about methods that optimise policy directly. Instead of working with value function as we consider so far, we seek experience and use the experience to update our policy in the direction that makes it better.</p><p>In the last lecture, we approximated the value or action-value function using parameters <span class="math inline">\(\theta\)</span>, <span class="math display">\[V_\theta(s)\approx V^\pi(s)\\Q_\theta(s, a)\approx Q^\pi(s, a)\]</span> A policy was generated directly from the value function using <span class="math inline">\(\epsilon\)</span>-greedy.</p><p>In this lecture we will directly parametrise the policy <span class="math display">\[\pi_\theta(s, a)=\mathbb{P}[a|s, \theta]\]</span> We will focus again on <span class="math inline">\(\color{red}{\mbox{model-free}}\)</span> reinforcement learning.</p><a id="more"></a><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#finite-difference-policy-gradient">Finite Difference Policy Gradient</a></li><li><a href="#monte-carlo-policy-gradient">Monte-Carlo Policy Gradient</a></li><li><a href="#actor-critic-policy-gradient">Actor-Critic Policy Gradient</a></li><li><a href="#summary-of-policy-gradient-algorithms">Summary of Policy Gradient Algorithms</a></li></ul><!-- tocstop --><p><strong>Value-Based and Policy-Based RL</strong></p><ul><li>Value Based<ul><li>Learnt Value Function</li><li>Implicit policy (e.g. <span class="math inline">\(\epsilon\)</span>-greedy)</li></ul></li><li>Policy Based<ul><li>No Value Function</li><li>Learnt Policy</li></ul></li><li>Actor-Critic<ul><li>Learnt Value Function</li><li>Learnt Policy</li></ul></li></ul><p><img src="/images/vfp.png"></p><p><strong>Advantages of Policy-Based RL</strong></p><p>Advantages:</p><ul><li>Better convergence properties</li><li>Effective in high-dimensional or contimuous action spaces (<em>without computing max</em>)</li><li>Can learn stochastic policies</li></ul><p>Disadvantages:</p><ul><li>Typically converge to a local rather than global optimum</li><li>Evaluating a policy is typically inefficient and high variance</li></ul><p>Deterministic policy or taking max is not also the best. Take the rock-paper-scissors game for example.</p><p><img src="/images/rps.png"></p><p>Consider policies <em>iterated</em> rock-paper-scissors</p><ul><li>A deterministic policy is easily exploited</li><li>A uniform random policy is optimal (according to Nash equilibrium)</li></ul><p><strong>Aliased Gridworld Example</strong></p><p><img src="/images/agw.png"></p><p>The agent cannot differentiate the grey states.</p><p>Consider features of the following form (for all N, E, S, W) <span class="math display">\[\phi(s, a)=1(\mbox{wall to N, a = move E})\]</span> Compare value-based RL, using an approximate value function <span class="math display">\[Q_\theta(s, a)=f(\phi(s, a), \theta)\]</span> To policy-based RL, using a parametrised policy <span class="math display">\[\pi_\theta(s, a)=g(\phi(s, a), \theta)\]</span> Since the agent cannot differentiate the grey states given the feature, if you take a <strong>deterministic</strong> policy, you must pick the same action at two grey states.</p><p><img src="/images/deagw.png"></p><p>Under aliasing, an optimal <span class="math inline">\(\color{red}{\mbox{deterministic}}\)</span> policy will either</p><ul><li>move W in both grey states (as shown by red arrows)</li><li>move E in both grey states</li></ul><p>Either way, it can get stuck and never reach the money.</p><p>Value-based RL learns a near-deterministic policy, so it will traverse the corridor for a long time.</p><p><img src="/images/ranagw.png"></p><p>An optimal <span class="math inline">\(\color{red}{\mbox{stochastic}}\)</span> policy will randomly move E or W in grey states: <span class="math display">\[\pi_\theta(\mbox{wall to N and S, move E}) = 0.5\\\pi_\theta(\mbox{wall to N and S, move W}) = 0.5\\\]</span> It will reach the goal state in a few steps with high probability. Policy-based RL can learn the optimal stochastic policy.</p><p>These examples show that a stochastic policy can be better than the deterministic policy, especially in the case that the MDP is <strong>partialy observed</strong> or cannot fully represent the state.</p><p><strong>Policy Objective Functions</strong></p><p>Goal: given policy <span class="math inline">\(\pi_\theta(s, a)\)</span> with parameters <span class="math inline">\(\theta\)</span>, find best <span class="math inline">\(\theta\)</span>. But how do we measure the quality of a policy <span class="math inline">\(\pi_\theta\)</span>?</p><ul><li><p>In episodic environments we can use the <strong>start value</strong> <span class="math display">\[J_1(\theta)=V^{\pi_\theta}(s_1)=\mathbb{E}_{\pi_\theta}[v_1]\]</span></p></li><li><p>In continuing environments we can use the <strong>average value</strong> <span class="math display">\[J_{av}v(\theta)=\sum_s d^{\pi_\theta}(s)V^{\pi_\theta}(s)\]</span></p></li><li><p>Or the <strong>average reward per time-step</strong></p><p>​ <span class="math display">\[J_{av}R(\theta)=\sum_s d^{\pi_\theta}(s)\sum_a\pi_\theta(s, a)\mathcal{R}^a_s\]</span></p></li><li><p>where <span class="math inline">\(d^{\pi_\theta}(s)\)</span> is <strong>stationary distribution</strong> of Markov chain for <span class="math inline">\(\pi_\theta\)</span>.</p></li></ul><p><strong>Policy Optimisation</strong></p><p>Policy based reinforcement learning is an <strong>optimisation</strong> problem. Find <span class="math inline">\(\theta\)</span> that maximises <span class="math inline">\(J(\theta)\)</span>.</p><p>Some approaches do not use gradient</p><ul><li>Hill climbing</li><li>Simplex / amoeba / Nelder Mead</li><li>Genetic algorithms</li></ul><p>However, greater efficiency often possible using gradient</p><ul><li>Gradient descent</li><li>Conjugate gradient</li><li>Quasi-newton</li></ul><p>We focus on gradient descent, many extensions possible. And on methods that exploit sequential structure.</p><h2><span id="finite-difference-policy-gradient">Finite Difference Policy Gradient</span></h2><p><strong>Policy Gradient</strong></p><p>Let <span class="math inline">\(J(\theta)\)</span> be any policy objective function. Policy gradient algorithms search for a local maximum in <span class="math inline">\(J(\theta)\)</span> by ascending the gradient of the policy, w.r.t. parameters <span class="math inline">\(\theta\)</span> <span class="math display">\[\triangle\theta = \alpha\nabla_\theta J(\theta)\]</span> Where <span class="math inline">\(\bigtriangledown_\theta J(\theta)\)</span> is the <span class="math inline">\(\color{red}{\mbox{policy gradient}}\)</span>, <span class="math display">\[\nabla_\theta J(\theta)=\begin{pmatrix}\frac{\partial J(\theta)}{\partial \theta_1}  \\\vdots\\\frac{\partial J(\theta)}{\partial \theta_n}\end{pmatrix}\]</span> and <span class="math inline">\(\alpha\)</span> is a step-size parameter.</p><p><strong>Computing Gradients By Finite Differences (Numerical)</strong></p><p>To evaluate policy gradient of <span class="math inline">\(\pi_\theta(s, a)\)</span>.</p><ul><li>For each dimension <span class="math inline">\(k\in[1, n]\)</span>:<ul><li><p>Estimate <span class="math inline">\(k\)</span>th partial derivative of objective function w.r.t. <span class="math inline">\(\theta\)</span></p></li><li><p>By perturbing <span class="math inline">\(\theta\)</span> by small amount <span class="math inline">\(\epsilon\)</span> in <span class="math inline">\(k\)</span>th dimension <span class="math display">\[\frac{\partial J(\theta)}{\partial \theta_k}\approx \frac{J(\theta+\epsilon u_k)-J(\theta)}{\epsilon}\]</span> where <span class="math inline">\(u_k\)</span> is unit vector with 1 in <span class="math inline">\(k\)</span>th component, 0 elsewhere</p></li></ul></li><li>Uses <span class="math inline">\(n\)</span> evaluations to compute policy gradient in <span class="math inline">\(n\)</span> dimensions</li></ul><p>This is a simple, noisy, inefficient, but sometimes effective method. It works for <strong>arbitrary</strong> policies, even if policy is <strong>not</strong> differentiable.</p><p>The algorithm is efficient when the dimension of <span class="math inline">\(\theta\)</span> is low.</p><h2><span id="monte-carlo-policy-gradient">Monte-Carlo Policy Gradient</span></h2><p><strong>Score Function</strong></p><p>We now compute the policy gradient <em>analytically</em>.</p><p>Assume policy <span class="math inline">\(\pi_\theta\)</span> is differentiable whenever it is non-zero and we know the gradient <span class="math inline">\(\nabla_\theta\pi_\theta(s, a)\)</span>.</p><p><span class="math inline">\(\color{red}{\mbox{Likelihood ratios}}\)</span> exploit the following identity <span class="math display">\[\begin{align}\nabla_\theta\pi_\theta(s, a) &amp; =\pi_\theta(s, a) \frac{\nabla_\theta\pi_\theta(s, a) }{\pi_\theta(s, a) } \\&amp; = \pi_\theta(s, a) \nabla_\theta\log \pi_\theta(s, a)  \\\end{align}\]</span> The <span class="math inline">\(\color{red}{\mbox{score function}}\)</span> is $<em></em>(s, a) $. Let's take two examples to see what the score function looks like.</p><p><em>Softmax Policy</em></p><p>We will use a softmax policy as a running example. Weight actions using linear combination of features <span class="math inline">\(\phi(s, a)^T\theta\)</span>. Probability of action is proportional to exponentiated weight: <span class="math display">\[\pi_\theta(s, a)\varpropto e^{\phi(s, a)^T\theta}\]</span> The score function is <span class="math display">\[\nabla_\theta\log\pi_\theta(s, a)=\phi(s, a)-\mathbb{E}_{\pi_\theta}[\phi(s, \cdot)]\]</span> (Intuition: log gradient = the feature for the action that we actually took minus the average feature for all actions.)</p><p><em>Gaussian Policy</em></p><p>In continuous action spaces, a Gaussian policy is natural.</p><ul><li>Mean is a linear combination of state features <span class="math inline">\(\mu(s) = \phi(s)^T\theta\)</span>.</li><li>Variance may be fixed <span class="math inline">\(\sigma^2\)</span>, or can also parametrised</li></ul><p>Policy is Gaussian, <span class="math inline">\(a\sim \mathcal{N}(\mu(s), \sigma^2)\)</span>. The score function is <span class="math display">\[\nabla_\theta\log\pi_\theta(s, a)=\frac{(a-\mu(s))\phi(s)}{\sigma^2}\]</span> So far we just have a sense of what does the score function look like. Now we step into policy gradient theorem.</p><p><strong>One-Step MDPs</strong></p><p>Consider a simple class of one-step MDPs:</p><ul><li>Starting in state <span class="math inline">\(s\sim d(s)\)</span></li><li>Terminating after one time-step with reward <span class="math inline">\(r=\mathcal{R}_{s,a}\)</span></li></ul><p>Use likelihood ratios to compute the policy gradient <span class="math display">\[\begin{align}J(\theta) &amp;=\mathbb{E}_{\pi_\theta}[r]\\&amp;=\sum_{s\in\mathcal{S}}d(s)\sum_{a\in\mathcal{A}}\pi_\theta(s, a)\mathcal{R}_{s,a}\end{align}\]</span></p><p><span class="math display">\[\begin{align}\nabla_\theta J(\theta) &amp;=\sum_{s\in\mathcal{S}}d(s)\sum_{a\in\mathcal{A}}\pi_\theta(s, a)\nabla_\theta\log\pi_\theta(s, a)\mathcal{R}_{s,a}\\&amp;=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s, a)r]\end{align}\]</span></p><p>The policy gradient theorem generalises the likelihood ratio approach to multi-step MDPs.</p><ul><li>Replaces instantaneous reward <span class="math inline">\(r\)</span> with long-term value <span class="math inline">\(Q^\pi(s, a)\)</span></li></ul><p>Policy gradient theorem applies to start state objective, average reward, and average value objective.</p><blockquote><p>Theorem</p><p>For any differentiable policy <span class="math inline">\(\pi_\theta(s,a)\)</span>, for any of the policy objective functions mentioned earlier, the policy gradient is <span class="math display">\[\nabla_\theta J(\theta)=\color{red}{\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s, a)Q^{\pi_\theta}(s, a)]}\]</span></p></blockquote><p><strong>Demonstration</strong></p><blockquote><p>Settings: The initial state <span class="math inline">\(s_0\)</span> is sampled from distribution <span class="math inline">\(\rho_0\)</span>. A trajectory <span class="math inline">\(\tau = (s_0, a_0, s_1, a_1, ..., s_{t+1})\)</span> is sampled from policy <span class="math inline">\(\pi_\theta\)</span>.</p><p>The target function would be <span class="math display">\[J(\theta) = E_{\tau\sim\pi}[R(\tau)]\]</span> The probability of trajectory <span class="math inline">\(\tau\)</span> is sampled from <span class="math inline">\(\pi\)</span> is <span class="math display">\[P(\tau|\theta) = \rho_0(s_0)+\prod_{t=0}^TP(s_{t+1}|s_t, a_t)\pi_\theta(a_t|s_t)\]</span> Using the log prob trick: <span class="math display">\[\triangledown_\theta P(\tau|\theta) = P(\tau|\theta)\triangledown_\theta\log P(\tau|\theta)\]</span> Expand the trajectory: <span class="math display">\[\begin{align}\require{cancel}\triangledown_\theta \log P(\tau|\theta) &amp;= \cancel{\triangledown_\theta \log\rho_0(s_0)}+\sum_{t=0}^T\cancel{\triangledown_\theta \log P(s_{t+1}|s_t,a_t)}+ \triangledown_\theta\log\pi_\theta(a_t|s_t)\\&amp;= \sum_{t=0}^T\triangledown_\theta\log\pi_\theta(a_t|s_t)\end{align}\]</span> The gradient of target function <span class="math display">\[\begin{align}\triangledown_\theta J(\theta) &amp;= \triangledown_\theta E_{\tau\sim\pi}[R(\tau)]\\&amp;= \int_\tau \triangledown_\theta P(\tau|\theta)R(\tau)\\&amp;= \int_\tau P(\tau|\theta)\triangledown_\theta \log P(\tau|\theta)R(\tau)\\&amp;= E_{\tau\sim\pi}[\triangledown_\theta \log P(\tau|\theta)R(\tau)]\\&amp;= E_{\tau\sim\pi}[\sum_{t=0}^T\triangledown_\theta\log\pi_\theta(a_t|s_t)R(\tau)]\\&amp;= E_{\tau\sim\pi}[\sum_{t=0}^T \color{red}{\Phi_t}\triangledown_\theta\log\pi_\theta(a_t|s_t)]\end{align}\]</span></p></blockquote><p><strong>Monte-Carlo Policy Gradient (REINFORCE)</strong></p><p>Update parameters by stochastic gradient ascent using policy gradient theorem. And using return <span class="math inline">\(v_t\)</span> as an <strong>unbiased sample</strong> of <span class="math inline">\(Q^{\pi_\theta}(s_t,a_t)\)</span>: <span class="math display">\[\triangle\theta_t=\alpha\nabla_\theta\log\pi_\theta(s_t, a_t)v_t\]</span> <img src="/images/mcpseudo.png"></p><p>(Note: MCPG is slow.)</p><h2><span id="actor-critic-policy-gradient">Actor-Critic Policy Gradient</span></h2><p><strong>Reducing Variance Using a Critic</strong></p><p>Monte-Carlo policy gradient still has high variance, we use a <span class="math inline">\(\color{red}{critic}\)</span> to estimate the action-value function: <span class="math display">\[Q_w(s, a)\approx Q^{\pi_\theta}(s, a)\]</span> Actor-critic algorithms maintain two sets of parameters:</p><ul><li>Critic: Updates action-value function parameters <span class="math inline">\(w\)</span></li><li>Actor: Updates policy parameters <span class="math inline">\(\theta\)</span>, in direction suggested by critic</li></ul><p>Actor-critic algorithms follow an <em>approximate</em> policy gradient: <span class="math display">\[\nabla_\theta J(\theta)\approx \mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s, a)Q_w(s, a)]\\\triangle\theta= \alpha\nabla_\theta\log\pi_\theta(s, a)Q_w(s, a)\]</span> The critic is solving a familiar problem: policy evaluation. This problem was explored in previous lectures:</p><ul><li>Monte-Carlo policy evaluation</li><li>Temporal-Difference learning</li><li>TD(<span class="math inline">\(\lambda\)</span>)</li><li>Least Squares policy evaluation</li></ul><p>Simple actor-critic algorithm based on action-value critic using linear value function approximation. <span class="math inline">\(Q_w(s, a)=\phi(s,a)^Tw\)</span></p><ul><li>Critic: Updates <span class="math inline">\(w\)</span> by linear TD(0)</li><li>Actor: Updates <span class="math inline">\(\theta\)</span> by policy gradient</li></ul><p><img src="/images/qacpseudo.png"></p><p><strong>Bias in Actor-Critic Algorithms</strong></p><p>Approximating the policy gradient introduces bias. A biased policy gradient may not find the right solution. Luckily, if we choose value function approximation carefully, then we can avoid introducing any bias. That is we can still follow the exact policy gradient.</p><blockquote><p><strong>Compatible Function Approximation Theorem</strong></p><p>If the following two conditions are satisdied:</p><ol type="1"><li><p>Value function approximator is <strong>compatible</strong> to the policy <span class="math display">\[\nabla_w Q_w(s, a)=\nabla_\theta \log\pi_\theta(s, a)\]</span></p></li><li><p>Value function parameters <span class="math inline">\(w\)</span> minimise the mean-squared error <span class="math display">\[\epsilon=\mathbb{E}_{\pi_\theta}[(Q^{\pi_\theta}(s, a)-Q_w(s, a))^2]\]</span></p></li></ol><p>Then the policy gradient is exact, <span class="math display">\[\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)Q_w(s,a)]\]</span></p></blockquote><p><strong>Trick: Reducing Variance Using a Baseline</strong></p><p>We substract a baseline function <span class="math inline">\(B(s)\)</span> from the policy gradient. This can <strong>reduce variance, without changing expectation</strong>: <span class="math display">\[\begin{align}\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)B(s)]&amp;=\sum_{s\in\mathcal{S}}d^{\pi_\theta}(s)\sum_a\nabla_\theta\pi_\theta(s,a)B(s)\\&amp;= \sum_{s\in\mathcal{S}}d^{\pi_\theta}B(s)\nabla_\theta\sum_{a\in\mathcal{A}}\pi_\theta(s,a)\\&amp;=  \sum_{s\in\mathcal{S}}d^{\pi_\theta}B(s)\nabla_\theta 1 \\&amp;=0\end{align}\]</span> A good baseline is the state value function <span class="math inline">\(B(s)=V^{\pi_\theta}(s)\)</span>. So we can rewrite the policy gradient using the <span class="math inline">\(\color{red}{\mbox{advantage function}}\ A^{\pi_\theta}(s,a)\)</span>. <span class="math display">\[A^{\pi_\theta}(s,a)=Q^{\pi_\theta}(s,a)-V^{\pi_\theta}(s)\\\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)\color{red}{A^{\pi_\theta}(s,a)}]\]</span> where <span class="math inline">\(V^{\pi_\theta}(s)​\)</span> is the state value function of <span class="math inline">\(s​\)</span>.</p><p><strong>Intuition</strong>: The advantage function <span class="math inline">\(A^{\pi_\theta}(s,a)\)</span> tells us how much better than usual is it to take action <span class="math inline">\(a\)</span>.</p><p><strong>Estimating the Advantage Function</strong></p><p>How do we know the state value function <span class="math inline">\(V\)</span>?</p><p>One way to do that is to estimate both <span class="math inline">\(V^{\pi_\theta}(s)\)</span> and <span class="math inline">\(Q^{\pi_\theta}(s,a)\)</span>. Using two function approximators and two parameter vectors, <span class="math display">\[V_v(s)\approx V^{\pi_\theta}(s)\\Q_w(s,a)\approx Q^{\pi_\theta}(s,a)\\A(s,a)=Q_w(s,a)-V_v(s)\]</span> And updating both value functions by e.g. TD learning.</p><p>Another way is to use the TD error to compute the policy gradient. For the true value function <span class="math inline">\(V^{\pi_\theta}(s)\)</span>, the TD error <span class="math inline">\(\delta^{\pi_\theta}\)</span> <span class="math display">\[\delta^{\pi_\theta}=r+\gamma V^{\pi_\theta}(s&#39;)-V^{\pi_\theta}(s)\]</span> is an unbiased estimate of the advantage function: <span class="math display">\[\begin{align}\mathbb{E}_{\pi_\theta}[\delta^{\pi_\theta}|s, a] &amp;= \mathbb{E}_{\pi_\theta}[r+\gamma V^{\pi_\theta}(s&#39;)|s, a]-V^{\pi_\theta}(s)\\&amp;= Q^{\pi_\theta}(s, a) - V^{\pi_\theta}(s)\\&amp;= \color{red}{A^{\pi_\theta}(s,a)}\end{align}\]</span> So we can use the TD error to compute the policy gradient <span class="math display">\[\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)\color{red}{\delta^{\pi_\theta}}]\]</span> In practice we can use an approximate TD error: <span class="math display">\[\delta_v=r+\gamma V_v(s&#39;)-V_v(s)\]</span> This approach only requires one set of critic parameters <span class="math inline">\(v\)</span>.</p><p><strong>Critics and Actors at Different Time-Scales</strong></p><p>Critic can estimate value function <span class="math inline">\(V_\theta(s)\)</span> from many targets at different time-scales</p><ul><li><p>For MC, the target is return <span class="math inline">\(v_t\)</span> <span class="math display">\[\triangle \theta=\alpha(\color{red}{v_t}-V_\theta(s))\phi(s)\]</span></p></li><li><p>For TD(0), the target is the TD target <span class="math inline">\(r+\gamma V(s&#39;)\)</span> <span class="math display">\[\triangle \theta=\alpha(\color{red}{r+\gamma V(s&#39;)}-V_\theta(s))\phi(s)\]</span></p></li><li><p>For forward-view TD(<span class="math inline">\(\lambda\)</span>), the target is the return <span class="math inline">\(_vt^\lambda\)</span> <span class="math display">\[\triangle \theta=\alpha(\color{red}{v_t^\lambda}-V_\theta(s))\phi(s)\]</span></p></li><li><p>For backward-view TD(<span class="math inline">\(\lambda\)</span>), we use eligibility traces <span class="math display">\[\begin{align}\delta_t &amp;= r_{t+1}+\gamma V(s_{t+1})-V(s_t) \\e_t&amp; = \gamma\lambda e_{t-1} +\phi(s_t) \\\triangle\theta&amp;=\alpha\delta_te_t\end{align}\]</span></p></li></ul><p>The policy gradient can also be estimated at many time-scales <span class="math display">\[\nabla_\theta J(\theta)=\mathbb{E}_{\pi_\theta}[\nabla_\theta\log\pi_\theta(s,a)\color{red}{A^{\pi_\theta}(s,a)}]\]</span></p><ul><li><p>MC policy gradient uses error from complete return <span class="math display">\[\triangle\theta=\alpha(\color{red}{v_t}-V_v(s_t))\nabla_\theta\log\pi_\theta(s_t,a_t)\]</span></p></li><li><p>Actor-critic policy gradient uses the one-step TD error <span class="math display">\[\triangle\theta=\alpha(\color{red}{r+\gamma V_v(s_{t+1})}-V_v(s_t))\nabla_\theta\log\pi_\theta(s_t,a_t)\]</span></p></li><li><p>Just like forward-view TD(<span class="math inline">\(\lambda\)</span>), we can mix over time-scale <span class="math display">\[\triangle \theta=\alpha(\color{red}{v_t^\lambda}-V_v(s_t))\nabla_\theta\log\pi_\theta(s_t,a_t)\]</span> where <span class="math inline">\(v_t^\lambda-V_v(s_t)\)</span> is a biased estimate of advantage function.</p></li><li><p>Like backward-view TD(<span class="math inline">\(\lambda\)</span>), we can also use eligibility traces by substituting <span class="math inline">\(\phi(s)=\nabla_\theta\log\pi_\theta(s,a)\)</span> <span class="math display">\[\begin{align}\delta_t &amp;= r_{t+1}+\gamma V_v(s_{t+1})-V_v(s_t) \\e_{t+1}&amp; = \gamma\lambda e_{t} +\nabla_\theta\log\pi_\theta(s,a) \\\triangle\theta&amp;=\alpha\delta_te_t\end{align}\]</span></p></li></ul><h2><span id="summary-of-policy-gradient-algorithms">Summary of Policy Gradient Algorithms</span></h2><p>The policy gradient has many equivalent forms</p><p><img src="/images/sumpg.png"></p><p>Each leads a stochastic gradient ascent algorithm. Critic uses policy evaluation to estimate <span class="math inline">\(Q^\pi(s, a)\)</span>, <span class="math inline">\(A^\pi(s, a)\)</span> or <span class="math inline">\(V^\pi(s)\)</span>.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> Policy Gradient </tag>
            
            <tag> REINFORCE </tag>
            
            <tag> Actor-Critic </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Value Function Approximation</title>
      <link href="/2018/01/03/RL%20-%20Value%20Function%20Approximation/"/>
      <url>/2018/01/03/RL%20-%20Value%20Function%20Approximation/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>This lecture will introduce how to scale up our algorithm to real practical RL problems by value function approximation.</p><p>Reinforcement learning can be used to solve <em>large</em> problems, e.g.</p><ul><li>Backgammon: <span class="math inline">\(10^{20}\)</span> states</li><li>Computer Go: <span class="math inline">\(10^{170}\)</span> states</li><li>Helicopter: continuous state space</li></ul><a id="more"></a><p>How can we scale up the model-free methods for prediction and control from the last two lectures?</p><p>So far we have represented value function by a <strong>lookup</strong> table:</p><ul><li>Every state <span class="math inline">\(s\)</span> has an entry <span class="math inline">\(V(s)\)</span></li><li>Or every state-action pair <span class="math inline">\(s, a\)</span> has an entry <span class="math inline">\(Q(s, a)\)</span></li></ul><p>Problems with large MDPs:</p><ul><li>There are too many states and/or actions to store in memory</li><li>It is too slow to learn the value of each state individually</li></ul><p>Solution for large MDPs: Estimate value function with <em>function approximation</em> <span class="math display">\[\hat{v}(s, \mathbb{w})\approx v_\pi(s)\\\mbox{or }\hat{q}(s, a, \mathbb{w})\approx q_\pi(s, a)\]</span> where <span class="math inline">\(\hat{v}\)</span> or <span class="math inline">\(\hat{q}\)</span> are function approximations of real <span class="math inline">\(v_\pi\)</span> or <span class="math inline">\(q_\pi\)</span>, and <span class="math inline">\(\mathbb{w}\)</span> are the parameters. This apporach has a major advantage:</p><ul><li><strong>Generalise</strong> from seen state to unseen states</li></ul><p>We can fit the <span class="math inline">\(\hat{v}\)</span> or <span class="math inline">\(\hat{q}\)</span> to <span class="math inline">\(v_\pi\)</span> or <span class="math inline">\(q_\pi\)</span> by MC or TD learning.</p><p><strong>Types of Value Function Approximation</strong></p><p><img src="/images/vftypes.png"></p><p>We consider <span class="math inline">\(\color{red}{\mbox{differentiable}}\)</span> function approximators, e.g.</p><ul><li>Linear combinations of features</li><li>Neural network</li></ul><p>Futhermore, we require a training method that is suitable for <span class="math inline">\(\color{red}{\mbox{non-stationary}}\)</span>, <span class="math inline">\(\color{red}{\mbox{non-idd}}\)</span> (idd = independent and identical distributed) data.</p><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#incremental-methods">Incremental Methods</a><ul><li><a href="#value-function-approximation">Value Function Approximation</a></li><li><a href="#action-value-function-approximation">Action-Value Function Approximation</a></li></ul></li><li><a href="#batch-methods">Batch Methods</a><ul><li><a href="#least-square-prediction">Least Square Prediction</a></li><li><a href="#least-squares-control">Least Squares Control</a></li></ul></li></ul><!-- tocstop --><h2><span id="incremental-methods">Incremental Methods</span></h2><h3><span id="value-function-approximation">Value Function Approximation</span></h3><p><strong>Gradient Descent</strong></p><p>Let <span class="math inline">\(J(\mathbb{w})\)</span> be a differentiable function of parameter vector <span class="math inline">\(\mathbb{w}\)</span>.</p><p>Define the gradient of <span class="math inline">\(J(\mathbb{w})\)</span> to be <span class="math display">\[\bigtriangledown_wJ(\mathbb{w})=\begin{pmatrix}\frac{\partial J(\mathbb{w})}{\partial \mathbb{w}_1} \\\vdots\\\frac{\partial J(\mathbb{w})}{\partial \mathbb{w}_n} \end{pmatrix}\]</span> To find a local minimum of <span class="math inline">\(J(\mathbb{w})\)</span>, adjust <span class="math inline">\(\mathbb{w}\)</span> in direction of -ve gradient <span class="math display">\[\triangle \mathbb{w}=-\frac{1}{2}\alpha \bigtriangledown_\mathbb{w}J(\mathbb{w})\]</span> where <span class="math inline">\(\alpha\)</span> is a step-size parameter.</p><p>So let's apply the <em>stochastic gradient descent</em> to <strong>value fucntion approximation</strong>.</p><p>Goal: find parameter vector <span class="math inline">\(\mathbb{w}\)</span> minimising mean-squared error between approximate value function <span class="math inline">\(\hat{v}(s, \mathbb{w})\)</span> and true value function <span class="math inline">\(v_\pi(s)\)</span>. <span class="math display">\[J(\mathbb{w})=\mathbb{E}_\pi[(v_\pi(S)-\hat{v}(S, \mathbb{w}))^2]\]</span> Gradient descent finds a local minimum <span class="math display">\[\begin{align}\triangle\mathbb{w}&amp;=-\frac{1}{2}\alpha \bigtriangledown_\mathbb{w}J(\mathbb{w})\\&amp; = \alpha\mathbb{E}_\pi[(v_\pi(S)-\hat{v}(S, \mathbb{w}))\bigtriangledown_\mathbb{w}\hat{v}(S, \mathbb{w})] \\\end{align}\]</span> Stochastic gradient descent <em>samples</em> the gradient <span class="math display">\[\triangle\mathbb{w}=\alpha(v_\pi(S)-\hat{v}(S, \mathbb{w}))\bigtriangledown_\mathbb{w}\hat{v}(S, \mathbb{w})\]</span> Expected update is equal to full gradient update.</p><p><strong>Feature Vectors</strong></p><p>Let's make this idea more concrete.</p><p>Represent state by a <em>feature vector</em>: <span class="math display">\[x(S) =\begin{pmatrix}x_1(S) \\\vdots\\x_n(S)\end{pmatrix}\]</span> For example:</p><ul><li>Distance of robot from landmarks</li><li>Trend in the stock market</li><li>Piece and pawn configurations in chess</li></ul><p><strong>Linear Value Function Approximation</strong></p><p>Represent value function by a linear combination of features <span class="math display">\[\hat{v}(S, \mathbb{w})=x(S)^T\mathbb{w}=\sum^n_{j=1}x_j(S)\mathbb{w}_j\]</span> Objective function is quadratic in parameters <span class="math inline">\(\mathbb{w}\)</span> <span class="math display">\[J(\mathbb{w})=\mathbb{E}_\pi[(v_\pi(S)-x(S)^T\mathbb{w})^2]\]</span> Stochastic gradient descent converges on global optimum.</p><p>Update rule is particularly simple <span class="math display">\[\bigtriangledown_\mathbb{w}\hat{v}(S, \mathbb{w})=x(S)\\\triangle \mathbb{w}=\alpha(v_\pi(S)-\hat{v}(S, \mathbb{w}))x(S)\]</span> Update = step-size <span class="math inline">\(\times\)</span> prediction error <span class="math inline">\(\times\)</span> feature value.</p><p>So far we have assumed true value function <span class="math inline">\(v_\pi(s)\)</span> given by supervisor. But in RL there is <strong>no supervisor, only rewards</strong>.</p><p>In practice, we substitute a <em>target</em> for <span class="math inline">\(v_\pi(s)\)</span>:</p><ul><li><p>For MC, the target is return <span class="math inline">\(G_t​\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{G_t}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w})\]</span></p></li><li><p>For TD(0), the target is the TD target <span class="math inline">\(R_{t+1}+\gamma\hat{v}(S_{t+1}, \mathbb{w})\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{R_{t+1}+\gamma\hat{v}(S_{t+1}, \mathbb{w})}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w})\]</span></p></li><li><p>For TD(<span class="math inline">\(\lambda\)</span>), the target is the return <span class="math inline">\(G_t^\lambda\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{G_t^\lambda}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w})\]</span></p></li></ul><p><strong>Monte-Carlo with Value Function Approximation</strong></p><p>Return <span class="math inline">\(G_t\)</span> is unbiased, noisy sample of true value <span class="math inline">\(v_\pi(S_t)\)</span>. We can build our &quot;training data&quot; to apply supervised learning: <span class="math display">\[&lt;S_1, G_1&gt;, &lt;S_2, G_2&gt;, ..., &lt;S_T, G_T&gt;\]</span> For example, using <em>linear Monte-Carlo policy evaluation</em> <span class="math display">\[\begin{align}\triangle \mathbb{w}&amp;=\alpha(\color{red}{G_t}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w}) \\&amp; = \alpha(G_t-\hat{v}(S_t, \mathbb{w}))x(S_t)\\\end{align}\]</span> Monte-Carlo evaluation converges to a local optimum even when using non-linear value function approximation.</p><p><strong>TD Learning with Value Function Approximation</strong></p><p>The TD-target <span class="math inline">\(R_{t+1}+\gamma \hat{v}(S_{t+1}, \mathbb{w})\)</span> is a biased sample of true value <span class="math inline">\(v_\pi(S_t)\)</span>. We can still apply supervised learning to &quot;traning data&quot;: <span class="math display">\[&lt;S_1, R_2 +\gamma\hat{v}(S_2, \mathbb{w})&gt;,&lt;S_2, R_3 +\gamma\hat{v}(S_3, \mathbb{w})&gt;,...,&lt;S_{T-1}, R_T&gt;\]</span> For example, using <em>linear TD(0)</em> <span class="math display">\[\begin{align}\triangle \mathbb{w}&amp;=\alpha(\color{red}{R+\gamma\hat{v}(S&#39;, \mathbb{w})}-\hat{v}(S, \mathbb{w}))\bigtriangledown_w \hat{v}(S, \mathbb{w}) \\&amp; = \alpha\delta x(S)\\\end{align}\]</span> Linear TD(0) converges (close) to global optimum.</p><p><strong>TD(<span class="math inline">\(\lambda\)</span>) with Value Function Approximation</strong></p><p>The <span class="math inline">\(\lambda\)</span>-return <span class="math inline">\(G_t^\lambda\)</span> is also a biased sample of true value <span class="math inline">\(v_\pi(s)\)</span>. We can also apply supervised learning to &quot;training data&quot;: <span class="math display">\[&lt;S_1, G_1^\lambda&gt;, &lt;S_2, G_2^\lambda&gt;, ..., &lt;S_{T-1}, G_{T-1}^\lambda&gt;\]</span> Can use either forward view linear TD(<span class="math inline">\(\lambda\)</span>): <span class="math display">\[\begin{align}\triangle \mathbb{w}&amp;=\alpha(\color{red}{G_t^\lambda}-\hat{v}(S_t, \mathbb{w}))\bigtriangledown_w \hat{v}(S_t, \mathbb{w}) \\&amp; = \alpha(G_t-\hat{v}(S_t, \mathbb{w}))x(S_t)\\\end{align}\]</span> or backward view linear TD(<span class="math inline">\(\lambda\)</span>): <span class="math display">\[\begin{align}\delta_t &amp;= R_{t+1}+\gamma \hat{v}(S_{t+1}, \mathbb{w})-\hat{v}(S_t, \mathbb{w}) \\E_t&amp; = \gamma\lambda E_{t-1} +x(S_t) \\\triangle\mathbb{w}&amp;=\alpha\delta_tE_t\end{align}\]</span></p><h3><span id="action-value-function-approximation">Action-Value Function Approximation</span></h3><p><img src="/images/avfa.png"></p><p>Approximate the action-value function: <span class="math display">\[\hat{q}(S, A, \mathbb{w}) \approx q_\pi(S, A)\]</span> Minimise mean-squared error between approximate action-value function <span class="math inline">\(\hat{q}(S, A, \mathbb{w})\)</span> and true action-value function <span class="math inline">\(q_\pi(S, A)\)</span>: <span class="math display">\[J(\mathbb{w})=\mathbb{E}_\pi[(q_\pi(S, A)-\hat{q}(S, A, \mathbb{w}))^2]\]</span> Use stochastic gradient descent to find a local minimum: <span class="math display">\[-\frac{1}{2}\bigtriangledown_w J(\mathbb{w})=(q_\pi(S, A)-\hat{q}(S, A, \mathbb{w}))\bigtriangledown_w\hat{q}(S, A, \mathbb{w})\\\triangle\mathbb{w}=\alpha (q_\pi(S, A)-\hat{q}(S, A, \mathbb{w}))\bigtriangledown_w\hat{q}(S, A, \mathbb{w})\]</span> Represent state and action by a feature vector: <span class="math display">\[\mathbb{x}(S, A)=\begin{pmatrix}x_1(S, A) \\\vdots\\x_n(S, A)\end{pmatrix}\]</span> Represent action-value function by linear combination of features: <span class="math display">\[\hat{q}(S, A, \mathbb{w})=\mathbb{x}(S, A)^T\mathbb{w}=\sum^n_{j=1}x_j (S, A)\mathbb{w}_j\]</span> Stochastic gradient descent update: <span class="math display">\[\bigtriangledown_w\hat{q}(S, A, \mathbb{w})=\mathbb{x}(S, A)\\\triangle \mathbb{w}=\alpha(q_\pi(S, A)-\hat{q}(S,  A, \mathbb{w}))\mathbb{x}(S, A)\]</span> Like prediction, we must subsitute a target for <span class="math inline">\(q_\pi(S, A)\)</span>:</p><ul><li><p>For MC, the target is the return <span class="math inline">\(G_t\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{G_t}-\hat{q}(S_t,  A_t, \mathbb{w}))\bigtriangledown_w\hat{q}(S_t, A_t, \mathbb{w})\]</span></p></li><li><p>For TD(0), the target is the TD target <span class="math inline">\(R_{t+1}+\gamma Q(S_{t+1}, A_{t+1})​\)</span> <span class="math display">\[\triangle \mathbb{w}=\alpha(\color{red}{R_{t+1}+\gamma \hat{q}(S_{t+1},  A_{t+1}, \mathbb{w})}-\hat{q}(S_t,  A_t, \mathbb{w}))\bigtriangledown_w\hat{q}(S_t, A_t, \mathbb{w})\]</span></p></li><li><p>For forward-view TD(<span class="math inline">\(\lambda\)</span>), target is the action-value <span class="math inline">\(\lambda\)</span>-return <span class="math display">\[\triangle\mathbb{w}=\alpha(\color{red}{q_t^\lambda}-\hat{q}(S_t, A_t,\mathbb{w}))\bigtriangledown\hat{q}(S_t, A_t, \mathbb{w})\]</span></p></li><li><p>For backward-view TD(<span class="math inline">\(\lambda\)</span>), equivalent update is <span class="math display">\[\begin{align}\delta_t&amp; =R_{t+1}+\gamma\hat{q}(S_{t+1}, A_{t+1}, \mathbb{w})-\hat{q}(S_t, A_t, \mathbb{w}) \\E_t&amp; = \gamma\lambda E_{t-1}+\bigtriangledown_w\hat{q}(S_t, A_t, \mathbb{w}) \\\triangle\mathbb{w}&amp;= \alpha\delta_t E_t\end{align}\]</span></p></li></ul><p><strong>Linear Sarsa with Coarse Coding in Mountain Car</strong></p><p><img src="/images/linsarsa.png"></p><p>The goal is to control our car to reach the top of the mountain. We represent state by the car's position and velocity. The height of the diagram shows the value of each state. Finally, the value function is like:</p><p><img src="/images/linsarfin.png"></p><p><strong>Study of <span class="math inline">\(\lambda\)</span>: Should We Bootstrap?</strong></p><p><img src="/images/lambdastudy.png"></p><p>The answer is <strong>yes</strong>. We can see from above picture, choose some approprite <span class="math inline">\(\lambda\)</span> can certainly reduce the training steps as well as the cost.</p><p>However, temporal-difference learning in many cases doesn't guarantee to converge. It may also diverge.</p><p><strong>Convergence of Prediction Algorithms</strong></p><p><img src="/images/converge.png"></p><p>TD dose not follow the gradient of <em>any</em> objective function. This is why TD can diverge when off-policy or using non-linear function approximation. <strong>Gradient TD</strong> follows true gradient of projected Bellman error.</p><p><img src="/images/gtd.png"></p><p><strong>Convergence of Control Algorithms</strong></p><p><img src="/images/convca.png"></p><h2><span id="batch-methods">Batch Methods</span></h2><p>Gradient descent is simple and appealing. But it is not <strong>sample efficient</strong>. Batch methods seek to find the best fitting value function given the agent's experience.</p><h3><span id="least-square-prediction">Least Square Prediction</span></h3><p>Give value function approximation <span class="math inline">\(\hat{v}(s, \mathbb{w})\approx v_\pi(s)\)</span> and experience <span class="math inline">\(\mathcal{D}\)</span> consisting of <em>&lt;state, value&gt;</em> pairs: <span class="math display">\[\mathcal{D} = \{&lt;s_1, v_1^\pi&gt;, &lt;s_2, v_2^\pi&gt;, ..., &lt;s_T, v_T^\pi&gt; \}\]</span> Which parameters <span class="math inline">\(\mathbb{w}\)</span> give the best fitting value function <span class="math inline">\(\hat{v}(s, \mathbb{w})\)</span> ?</p><p><span class="math inline">\(\color{red}{\mbox{Least squares}}\)</span> algorithms find parameter vector <span class="math inline">\(\mathbb{w}\)</span> minimising sum-squared error between <span class="math inline">\(\hat{v}(s_t, \mathbb{w})\)</span> and target values <span class="math inline">\(v_t^\pi\)</span>, <span class="math display">\[\begin{align}LS(\mathbb{w}) &amp; = \sum^T_{t=1}(v_t^\pi-\hat{v}(s_t, \mathbb{w}))^2 \\&amp; = \mathbb{E}_\mathcal{D}[(v^\pi-\hat{v}(s, \mathbb{w}))^2] \\\end{align}\]</span> Given experience consisting of <em>&lt;state, value&gt;</em> pairs <span class="math display">\[\mathcal{D}=\{&lt;s_1, v_1^\pi&gt;, &lt;s_2, v_2^\pi&gt;, ..., &lt;s_T, v_T^\pi&gt;\}\]</span> Repeat:</p><ol type="1"><li><p>Sample state, value from experience <span class="math display">\[&lt;s, v^\pi&gt; \sim \mathcal{D}\]</span></p></li><li><p>Apply stochastic gradient descent update <span class="math display">\[\triangle \mathbb{w}=\alpha(v^\pi-\hat{v}(s, \mathbb{w}))\bigtriangledown_w\hat{v}(s, w)\]</span></p></li></ol><p>Converges to least squares solution <span class="math display">\[\mathbb{w}^\pi=\arg\min_w LS(w)\]</span> <strong>Deep Q-Networks (DQN)</strong></p><p>DQN uses <span class="math inline">\(\color{red}{\mbox{experience replay}}\)</span> and <span class="math inline">\(\color{red}{\mbox{fixed Q-targets}}\)</span>:</p><ul><li><p>Take action <span class="math inline">\(a_t\)</span> according to <span class="math inline">\(\epsilon\)</span>-greedy policy</p></li><li><p>Store transition <span class="math inline">\((s_t, a_t, r_{t+1}, s_{t+1})\)</span> in replay memory <span class="math inline">\(\mathcal{D}\)</span></p></li><li><p>Sample random mini-batch of transitions <span class="math inline">\((s, a, r, s&#39;)\)</span> from <span class="math inline">\(\mathcal{D}\)</span></p></li><li><p>Compute Q-learning targets w.r.t. old, fixed parameters <span class="math inline">\(w^-\)</span></p></li><li><p>Optimise MSE between Q-network and Q-learning target <span class="math display">\[\mathcal{L}(w_i)=\mathbb{E}_{s,a,r,s&#39;\sim\mathcal{D}_i}[(r+\gamma\max_{a&#39;}Q(s&#39;,a&#39;;w^-_i)-Q(s, a;w_i))^2]\]</span></p></li><li><p>Using variant of stochastic gradient descent</p></li></ul><p>Note: <span class="math inline">\(\color{red}{\mbox{fixed Q-targets}}\)</span> means we use two Q-networks. One of it using fixed old parameters to generate the Q-target to update the fresh Q-network, which can keep the update <strong>stable</strong>. Otherwise, when you update the Q-network, you also update the Q-target, which can cause diverge.</p><p>DQN in Atari</p><ul><li>End-to-end learning of values <span class="math inline">\(Q(s, a)\)</span> from pixels <span class="math inline">\(s\)</span></li><li>Input state <span class="math inline">\(s\)</span> is stack of raw pixels from last 4 frames</li><li>Output is <span class="math inline">\(Q(s, a)\)</span> for 18 joystick/button positions</li><li>Rewards is change in score for that step</li></ul><p><img src="/images/ataridqn.png"></p><p>Results</p><p><img src="/images/dqnres.png"></p><p>How much does DQN help?</p><p><img src="/images/dqnhelp.png"></p><p><strong>Linear Least Squares Prediction - Normal Equation</strong></p><p>Experience replay finds least squares solution but it may take many iterations. Using <em>linear value function approximation</em> <span class="math inline">\(\hat{v}(s, w) = x(s)^Tw\)</span>, we can solve squares soluton directly.</p><p>At minimum of <span class="math inline">\(LS(w)\)</span>, the expected update must be zero:</p><p><img src="/images/llsp.png"></p><p>For <span class="math inline">\(N\)</span> features, direct solution time is <span class="math inline">\(O(N^3)\)</span>. Incremental solution time is <span class="math inline">\(O(N^2)\)</span> using Shermann-Morrison.</p><p>We do not know true values <span class="math inline">\(v_t^\pi\)</span>. In practice, our &quot;training data&quot; must be noisy or biased samples of <span class="math inline">\(v_t^\pi\)</span>:</p><p><img src="/images/llspa.png"></p><p>In each case solve directly for fixed point of MC / TD / TD(<span class="math inline">\(\lambda\)</span>).</p><p><strong>Convergence of Linear Least Squares Prediction Algorithms</strong></p><p><img src="/images/cllspa.png"></p><h3><span id="least-squares-control">Least Squares Control</span></h3><p><strong>Least Squares Policy Iteration</strong></p><p><img src="/images/lspi.png"></p><p><strong>Least Squares Action-Value Function Approximation</strong></p><p>Approximate action-value function <span class="math inline">\(q_\pi(s, a)\)</span> using linear combination of features <span class="math inline">\(\mathbb{x}(s, a)\)</span>: <span class="math display">\[\hat{q}(s, a, \mathbb{w})=\mathbb{x}(s, a)^T\mathbb{w}\approx q_\pi(s, a)\]</span> Minimise least squares error between <span class="math inline">\(\hat{q}(s, a, \mathbb{w})\)</span> and <span class="math inline">\(q_\pi(s, a)\)</span> from experience generated using policy <span class="math inline">\(\pi\)</span> consisting of <em>&lt;(state, action), value&gt;</em> pairs: <span class="math display">\[\mathcal{D}=\{&lt;(s_1,a_1),v_1^\pi&gt;,&lt;(s_2,a_2),v_2^\pi&gt;,...,&lt;(s_T,a_T),v_T^\pi&gt;\}\]</span> <strong>Least Squares Control</strong></p><p>For policy evaluation, we want to efficiently use all experience. For control, we also want to improve the policy. This experience is generated from many policies. So to evaluate <span class="math inline">\(q_\pi(S, A)\)</span> we must learn <span class="math inline">\(\color{red}{\mbox{off-policy}}\)</span>.</p><p>We use the same idea as Q-learning:</p><ul><li>Use experience generated by old policy <span class="math inline">\(S_t, A_t, R_{t+1}, S_{t+1} \sim \pi_{old}\)</span></li><li>Consider alternative successor action <span class="math inline">\(A&#39;=\pi_{new}(S_{t+1})\)</span></li><li>Update <span class="math inline">\(\hat{q}(S_t, A_t,\mathbb{w})\)</span> towards value of alternative action <span class="math inline">\(R_{t+1}+\gamma \hat{q}(S_{t+1}, A&#39;, \mathbb{w})\)</span></li></ul><p>Consider the following linear Q-learning update <span class="math display">\[\delta=R_{t+1}+\gamma \hat{q}(S_{t+1}, \color{red}{\pi(S_{t+1})}, \mathbb{w})-\hat{q}(S_t, A_t, \mathbb{w})\\\triangle \mathbb{w}=\alpha\delta\mathbb{x}(S_t, A_t)\]</span> LSTDQ algorithm: solve for total update = zero:</p><p><img src="/images/lstdq.png"></p><p>The following pseudocode uses LSTDQ for policy evaluation. It repeatedly re-evaluates experience <span class="math inline">\(\mathcal{D}\)</span> with different policies.</p><p><img src="/images/lspipseudo.png"></p><p><strong>Convergence of Control Algorithms</strong></p><p><img src="/images/ccal.png"></p><p>End.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> DQN </tag>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Model-Free Control</title>
      <link href="/2017/12/21/RL%20-%20Model-Free%20Control/"/>
      <url>/2017/12/21/RL%20-%20Model-Free%20Control/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>Last lecture:</p><ul><li>Model-free prediction</li><li><em>Estimate</em> the value function of an <em>unknown</em> MDP</li></ul><p>This lecture:</p><ul><li>Model-free control</li><li><strong>Optimise</strong> the value function of an unknown MDP</li></ul><a id="more"></a><p>Why we care about model-free control? So, let's see some example problems that can be modelled as MDPs:</p><ul><li>Helicopter, Robocup Soccer, Quake</li><li>Portfolio management, Game of Go...</li></ul><p>For most of these problems, either:</p><ul><li>MDP model is <strong>unknown</strong>, but experience can be sampled</li><li>MDP model is known, but is <strong>too big to use</strong>, except by samples</li></ul><p><span class="math inline">\(\color{red}{\mbox{Model-free control}}\)</span> can sovlve these problems.</p><p>There are two branches of model-free control:</p><ul><li><span class="math inline">\(\color{red}{\mbox{On-policy}}\)</span> learning<ul><li>&quot;Learn on the job&quot;</li><li>Learn about policy <span class="math inline">\(\pi\)</span> from experience sampled from <span class="math inline">\(\pi\)</span></li></ul></li><li><span class="math inline">\(\color{red}{\mbox{Off-policy}}\)</span> learning<ul><li>&quot;Look over someone's shoulder&quot;</li><li>Learn about policy <span class="math inline">\(\pi\)</span> from experience sampled from <span class="math inline">\(\mu\)</span></li></ul></li></ul><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#on-policy-monte-carlo-control">On-Policy Monte-Carlo Control</a></li><li><a href="#on-policy-temporal-difference-learning">On-Policy Temporal-Difference Learning</a><ul><li><a href="#sarsalambda">Sarsa(<span class="math inline">\(\lambda\)</span>)</a></li></ul></li><li><a href="#off-policy-learning">Off-Policy Learning</a><ul><li><a href="#q-learning">Q-Learning</a></li></ul></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><h2><span id="on-policy-monte-carlo-control">On-Policy Monte-Carlo Control</span></h2><p>In previous lectures, we have seen that using policy iteration to find the best policy. Today, we also use this central idea plugging in MC or TD algorithm.</p><p><img src="/images/pi.png"></p><p><strong>Generalised Policy Iteration With Monte-Carlo Evaluation</strong></p><p>A simple idea is</p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(V = v_\pi\)</span>?</li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: Greedy policy improvement?</li></ul><p>Well, this idea has two major problems:</p><ul><li><p>Greedy policy improvement over <span class="math inline">\(V(s)\)</span> requires <strong>model of MDP</strong> <span class="math display">\[\pi^\prime(s) = \arg\max_{a\in\mathcal{A}}\mathcal{R}^a_s+\mathcal{P}^a_{ss&#39;}V(s&#39;)\]</span> since, we do not know the state transition probability matrix <span class="math inline">\(\mathcal{P}\)</span>.</p></li><li><p>Exploration issue: cannot guarantee to explore all states</p></li></ul><p>So, the alternative is to use action-value function <span class="math inline">\(Q\)</span>:</p><ul><li>Greedy policy improvement over <span class="math inline">\(Q(s, a)\)</span> is model-free <span class="math display">\[\pi^\prime=\arg\max_{a\in\mathcal{A}}Q(s,a)\]</span></li></ul><p>Let's replace it in the algorithm:</p><p><img src="/images/avf.png"></p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(\color{red}{Q = q_\pi}\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: Greedy policy improvement?</li></ul><p>We still have one problems about the algorithm, which is exploration issue. Here is a example of greedy action selection:</p><p><img src="/images/gaseg.png"></p><p>The reward of the two doors are stochastic. However, because of the greedy action selection, we always choose the right door without exploring the value of the left one.</p><p>One simple algorithm to ensure keeping exploration is <strong><span class="math inline">\(\epsilon\)</span>-greedy exploration</strong>.</p><p><strong><span class="math inline">\(\epsilon\)</span>-Greedy Exploration</strong></p><p>All <span class="math inline">\(m\)</span> actions are tried with non-zero probalility,</p><ul><li>With probability <span class="math inline">\(1-\epsilon\)</span> choose the greedy action</li><li>With probability <span class="math inline">\(\epsilon\)</span> choose an action at <strong>random</strong></li></ul><p><span class="math display">\[\pi(a|s)=\begin{cases} \epsilon/m+1-\epsilon,  &amp; \mbox{if } a^* = \arg\max_{a\in\mathcal{A}}Q(s,a) \\\epsilon/m, &amp; \mbox{otherwise }\end{cases}\]</span></p><blockquote><p>Theorem</p><p>For any <span class="math inline">\(\epsilon\)</span>-greedy policy <span class="math inline">\(\pi\)</span>, the <span class="math inline">\(\epsilon\)</span>-greedy policy <span class="math inline">\(\pi^\prime\)</span> with respect to <span class="math inline">\(q_\pi\)</span> is an improvement, <span class="math inline">\(v_{\pi^\prime}≥v_\pi(s)\)</span>.</p></blockquote><p><img src="/images/egpi.png"></p><p>Therefore from policy improvement theorem, <span class="math inline">\(v_{\pi^\prime}(s) ≥ v_\pi(s)\)</span>.</p><p><strong>Monte-Carlo Policy Iteration</strong></p><p><img src="/images/mcpi.png"></p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(Q = q_\pi\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: <span class="math inline">\(\color{red}{\epsilon}\)</span>-greedy policy improvement</li></ul><p><strong>Monte-Carlo Control</strong></p><p><img src="/images/mcc.png"></p><p><span class="math inline">\(\color{red}{\mbox{Every episode}}\)</span>:</p><ul><li><span class="math inline">\(\color{Blue}{\mbox{Policy evaluation}}\)</span>: Monte-Carlo policy evaluation, <span class="math inline">\(\color{red}{Q \approx q_\pi}\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span>: <span class="math inline">\(\epsilon\)</span>-greedy policy improvement</li></ul><p>The method is once evaluate over an episode, immediately improve the policy. The idea is since we already have a better evaluation, why waiting to update the policy after numerous episodes. That is improving the policy right after evaluating one episode.</p><p><strong>GLIE</strong></p><blockquote><p>Definition</p><p><strong>Greedy in the Limit with Infinite Exploration</strong> (GLIE)</p><ul><li><p>All state-action pairs are explored infinitely many times, <span class="math display">\[\lim_{k\rightarrow\infty}N_k(s,a)=\infty\]</span></p></li><li><p>The policy converges on a greedy policy, <span class="math display">\[\lim_{k\rightarrow\infty}\pi_k(a|s)=1(a=\arg\max_{a^\prime \in\mathcal{A}}Q_k(s, a^\prime))\]</span></p></li></ul></blockquote><p>For example, <span class="math inline">\(\epsilon\)</span>-greedy is GLIE if <span class="math inline">\(\epsilon\)</span> reduces to zero at <span class="math inline">\(\epsilon_k=\frac{1}{k}\)</span>.</p><p><strong>GLIE Monte-Carlo Control</strong></p><p>Sample <span class="math inline">\(k\)</span>th episode using <span class="math inline">\(\pi\)</span>: <span class="math inline">\(\{S_1, A_1, R_2, …, S_T\} \sim \pi\)</span></p><ul><li><p><span class="math inline">\(\color{red}{\mbox{Evaluation}}\)</span></p><ul><li>For each state <span class="math inline">\(S_t\)</span> and action <span class="math inline">\(A_t\)</span> in the episode, <span class="math display">\[\begin{array}{lcl}N(S_t, A_t) \leftarrow N(S_t, A_t)+1 \\Q(S_t, A_t) \leftarrow Q(S_t, A_t)+\frac{1}{N(S_t, A_t)}(G_t-Q(S_t, A_t))\end{array}\]</span></li></ul></li><li><p><span class="math inline">\(\color{red}{\mbox{Improvement}}\)</span></p><ul><li>Improve policy based on new action-value function <span class="math display">\[\begin{array}{lcl}\epsilon\leftarrow \frac{1}{k} \\\pi \leftarrow \epsilon\mbox{-greedy}(Q)\end{array}\]</span></li></ul></li></ul><p>GLIE Monte-Carlo control converges to the optimal action-value function, <span class="math inline">\(Q(s,a) \rightarrow q_*(s,a)\)</span>.</p><p><strong>Blackjack Example</strong></p><p><img src="/images/mccb.png"></p><p>Using Monte-Carlo control, we can get the optimal policy above.</p><h2><span id="on-policy-temporal-difference-learning">On-Policy Temporal-Difference Learning</span></h2><p>Temporal-difference (TD) learning has several advantages over Monte-Carlo (MC):</p><ul><li>low variance</li><li>Online</li><li>Incomplete sequences</li></ul><p>A natural idea is using TD instead of MC in our control loop:</p><ul><li>Apply TD to <span class="math inline">\(Q(S, A)\)</span></li><li>Use <span class="math inline">\(\epsilon\)</span>-greedy policy improvement</li><li>Update every <em>time-step</em></li></ul><p><strong>Sarsa Update</strong></p><p><img src="/images/sarsa.png"></p><p>Updating action-value functions with Sarsa: <span class="math display">\[Q(S,A) \leftarrow Q(S, A) + \alpha(R+\gamma Q(S^\prime, A^\prime)-Q(S, A))\]</span> <img src="/images/mcc.png"></p><p>So, the full algorithm is:</p><ul><li>Every <span class="math inline">\(\color{red}{\mbox{time-step}}\)</span>:<ul><li><span class="math inline">\(\color{blue}{\mbox{Policy evaluation}}\)</span> <span class="math inline">\(\color{red}{\mbox{Sarsa}}\)</span>, <span class="math inline">\(Q\approx q_\pi\)</span></li><li><span class="math inline">\(\color{blue}{\mbox{Policy improvement}}\)</span> <span class="math inline">\(\epsilon\)</span>-greedy policy improvement</li></ul></li></ul><p><img src="/images/pesedotd.png"></p><p><strong>Windy Gridworld Example</strong></p><p><img src="/images/wweg.png"></p><p>The 'S' represents start location and 'G' marks the goal. There is a number at the bottom of each column which represents the wind will blow the agent up how many grids if the agent stays at that column.</p><p>The result of apply Sarsa to the problem is</p><p><img src="/images/wwegres.png"></p><h3><span id="sarsalambda">Sarsa(<span class="math inline">\(\lambda\)</span>)</span></h3><p><strong>n-Step Sarsa</strong></p><p>Consider the following <span class="math inline">\(n\)</span>-step returns for <span class="math inline">\(n=1,2,..\infty\)</span>:</p><p><img src="/images/nsarsa.png"></p><p>Define the <span class="math inline">\(n\)</span>-step <span class="math inline">\(Q\)</span>-return <span class="math display">\[q_t^{(n)}=R_{t+1}+\gamma R_{t+2}+...+\gamma^{n-1}R_{t+n}+\gamma^n Q(S_{t+n})\]</span> <span class="math inline">\(n\)</span>-step Sarsa updates <span class="math inline">\(Q(s, a)\)</span> towards the <span class="math inline">\(n\)</span>-step <span class="math inline">\(Q\)</span>-return <span class="math display">\[Q(S_t, A_t)\leftarrow Q(S_t, A_t)+\alpha(q_t^{(n)}-Q(S_t,A_t))\]</span> <strong>Forward View Sarsa(<span class="math inline">\(\lambda\)</span>)</strong></p><p><img src="/images/sarsalam.png"></p><p>The <span class="math inline">\(q^\lambda\)</span> return combines all <span class="math inline">\(n\)</span>-step Q-returns <span class="math inline">\(q_t^{(n)}\)</span> using weight <span class="math inline">\((1-\lambda)\lambda^{n-1}\)</span>: <span class="math display">\[q_t^\lambda = (1-\lambda)\sum^\infty_{n=1}\lambda^{n-1}q_t^{(n)}\]</span> Forward-view Sarsa(<span class="math inline">\(\lambda\)</span>): <span class="math display">\[Q(S_t, A_t)\leftarrow Q(S_t, A_t)+\alpha(q_t^\lambda-Q(S_t, A_t))\]</span> <strong>Backward View Sarsa(<span class="math inline">\(\lambda\)</span>)</strong></p><p>Just like TD(<span class="math inline">\(\lambda\)</span>), we use <span class="math inline">\(\color{red}{\mbox{eligibility traces}}\)</span> in an online algorithm, but Sarsa(<span class="math inline">\(\lambda\)</span>) has one eligibility trace for each state-action pair: <span class="math display">\[E_0(s, a) = 0\]</span></p><p><span class="math display">\[E_t(s, a) = \gamma\lambda E_{t-1}(s,a)+1(S_t=s, A_t=a)\]</span></p><p><span class="math inline">\(Q(s, a)\)</span> is updated for every state <span class="math inline">\(s\)</span> and action <span class="math inline">\(a\)</span> in proportion to TD-error <span class="math inline">\(\delta_t\)</span> and eligibility trace <span class="math inline">\(E_t(s, a)\)</span>: <span class="math display">\[\delta_t=R_{t+1}+\gamma Q(S_{t+1}, A_{t+1})-Q(S_t, A_t)\]</span></p><p><span class="math display">\[Q(s, a) \leftarrow Q(s, a) +\alpha \delta_t E_t(s, a)\]</span></p><p><img src="/images/sarcode.png"></p><p>The difference between Sarsa and Sarsa(<span class="math inline">\(\lambda\)</span>):</p><p><img src="/images/sarsadiff.png"></p><p>If we initial all <span class="math inline">\(Q(s, a) = 0\)</span>, then we first do a random walk and reach the goal. Using Sarsa, we can only update the Q-value of the previous state before reaching the goal since all other <span class="math inline">\(Q\)</span> are zero. So the reward can only propagate one state. On the contrary, if we using Sarsa(<span class="math inline">\(\lambda\)</span>), the reward can propagate from the last state to the first state with a exponential decay.</p><h2><span id="off-policy-learning">Off-Policy Learning</span></h2><p>Evaluate target policy <span class="math inline">\(\pi(a|s)\)</span> to compute <span class="math inline">\(v_\pi(s)\)</span> or <span class="math inline">\(q_\pi(s, a)\)</span> while following behaviour policy <span class="math inline">\(\mu(a|s)\)</span> <span class="math display">\[\{S_1, A_1, R_2, ..., S_T\}\sim \mu\]</span> So, why is this important? There are several reasons:</p><ul><li>Learn from observing hunman or other agents</li><li>Re-use experience generated from old policies <span class="math inline">\(\pi_1, \pi_2, …, \pi_{t-1}\)</span></li><li>Learn about <strong>optimal</strong> policy while following <span class="math inline">\(\color{red}{\mbox{exploratory policy}}\)</span></li><li>Learn about <strong>multiple</strong> policies while following one policy</li></ul><p><strong>Importance Sampling</strong></p><p>Estimate the expectation of a different distribution <span class="math display">\[\mathbb{E}_{X\sim P}[f(X)] = \sum P(X)f(X)=\sum Q(X)\frac{P(X)}{Q(X)}f(X)=\mathbb{E}_{X\sim Q}[\frac{P(X)}{Q(X)}f(X)]\]</span> <strong>Off-Policy Monte-Carlo</strong></p><p>Use returns generated from <span class="math inline">\(\mu\)</span> to evaluate <span class="math inline">\(\pi\)</span>. Weight return <span class="math inline">\(G_t\)</span> according to <strong>similarity</strong> between policies. Multiply importance sampling corrections along whole episode: <span class="math display">\[G_t^{\pi/\mu}=\frac{\pi(A_t|S_t)}{\mu(A_t|S_t)}\frac{\pi(A_{t+1}|S_{t+1})}{\mu(A_{t+1}|S_{t+1})}...\frac{\pi(A_T|S_T)}{\mu(A_T|S_T)}G_t\]</span> Update value towards <em>corrected</em> return: <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha (\color{red}{G_t^{\pi/\mu}}-V(S_t))\]</span> But it has two major problems:</p><ul><li>Cannot use if <span class="math inline">\(\mu\)</span> is zero when <span class="math inline">\(\pi\)</span> is non-zero</li><li>Importance sampling can dramatically increase variance, so it is useless in practice</li></ul><p><strong>Off-Policy TD</strong></p><p>Use TD targets generated from <span class="math inline">\(\mu\)</span> to evaluate <span class="math inline">\(\pi\)</span>. Weight TD target <span class="math inline">\(R+\gamma V(S&#39;)\)</span> by importance sampling. Only need a single importance sampling correction: <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha \left(\color{red}{\frac{\pi(A_t|S_t)}{\mu(A_t|S_t)}(R_{t+1}+\gamma V(S_{t+1}))}-V(S_t)\right)\]</span> This algorithm has much lower variance than Monte-Carlo importance sampling because policies only need to be similar over a single step.</p><h3><span id="q-learning">Q-Learning</span></h3><p>We now consider off-policy learning of action-values <span class="math inline">\(Q(s, a)\)</span>. The benefit of it is no importance sampling is required.</p><p>The next action is chosen using <strong>behaviour</strong> policy <span class="math inline">\(A_{t+1}\sim\mu(\cdot|S_t)\)</span>. But we consider <strong>alternative</strong> successor action <span class="math inline">\(A&#39;\sim \pi(\cdot|S_t)\)</span>. And update <span class="math inline">\(Q(S_t, A_t)\)</span> towards value of alternative action <span class="math display">\[Q(S_t, A_t) \leftarrow Q(S_t, A_t) + \alpha (R_{t+1}+\gamma Q(S_{t+1}, \color{red}{A&#39;})-Q(S_t, A_t))\]</span> We now allow both behaviour and target policies to <strong>improve</strong>.</p><p>The <strong>target</strong> policy <span class="math inline">\(\pi\)</span> is <span class="math inline">\(\color{red}{\mbox{greedy}}\)</span> w.r.t <span class="math inline">\(Q(s, a)\)</span>: <span class="math display">\[\pi(S_{t+1})=\arg\max_{a&#39;}Q(S_{t+1}, a&#39;)\]</span> The <strong>behaviour</strong> policy <span class="math inline">\(\mu\)</span> is e.g. <span class="math inline">\(\color{red}{\epsilon \mbox{-greedy}}\)</span> w.r.t. <span class="math inline">\(Q(s,a)\)</span>.</p><p>The <strong>Q-learning</strong> target then simplifies: <span class="math display">\[\begin{align}\mbox{Q-learning Target} &amp;= R_{t+1}+\gamma Q(S_{t+1}, A&#39;) \\&amp; = R_{t+1}+\gamma Q(S_{t+1}, \arg\max_{a&#39;}Q(S_{t+1}, a&#39;)) \\&amp;= R_{t+1}+\max_{a&#39;}\gamma Q(S_{t+1}, a&#39;)\end{align}\]</span> So the Q-learning control algorithm is</p><p><img src="/images/qlalg.png"></p><p>Of course, the Q-learning control still converges to the optimal action-value function, <span class="math inline">\(Q(s, a)\rightarrow q_*(s,a)\)</span>.</p><p><img src="/images/qlcode.png"></p><h2><span id="summary">Summary</span></h2><p><strong>Relationship Between DP and TD</strong></p><p><img src="/images/rbtddp.png"></p><p><img src="/images/rbtddp2.png"></p><p>In a word, TD backup can be seen as the sample of corresponding DP backup. This lecture introduces model-free control which is optimise the value function of an unknown MDP with on-policy and off-policy methods. Next lecture will introduce function approximation which is easy to scale up and can be applied into big MDPs.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> Q-learning </tag>
            
            <tag> Monte-Carlo Control </tag>
            
            <tag> Sarsa </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Model-Free Prediction</title>
      <link href="/2017/12/16/RL%20-%20Model-Free%20Prediction/"/>
      <url>/2017/12/16/RL%20-%20Model-Free%20Prediction/</url>
      
        <content type="html"><![CDATA[<h2><span id="introduction">Introduction</span></h2><p>Last lecture, David taught us how to solve a <em>known</em> MDP, which is <em>planning by dynamic programming</em>. In this lecture, we will learn how to estimate the value function of an <strong>unknown</strong> MDP, which is <em>model-free prediction</em>. And in the next lecture, we will <em>optimise</em> the value function of an unknown MDP.</p><a id="more"></a><p>In summary:</p><ul><li>Planning by dynamic programming<ul><li>Solve a <em>known MDP</em></li></ul></li><li><strong>Model-Free prediction</strong><ul><li>Estimate the value function of an <em>unknown</em> MDP</li></ul></li><li>Model-Free control<ul><li>Optimise the value function of an <em>unknown</em> MDP</li></ul></li></ul><p>We have two major methods to estimate the value function of an unknown MDP:</p><ul><li>Monte-Carlo Learning</li><li>Temporal-Difference Learning</li></ul><p>We will introduce the two methods and combine them to a general method.</p><p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#monte-carlo-learning">Monte-Carlo Learning</a></li><li><a href="#temporal-difference-learning">Temporal-Difference Learning</a><ul><li><a href="#unified-view">Unified View</a></li></ul></li><li><a href="#tdlambda">TD(<span class="math inline">\(\lambda\)</span>)</a><ul><li><a href="#forward-view-tdlambda">Forward View TD(<span class="math inline">\(\lambda\)</span>)</a></li><li><a href="#backward-view-tdlambda">Backward View TD(<span class="math inline">\(\lambda\)</span>)</a></li><li><a href="#relationship-between-forward-and-backward-td">Relationship Between Forward and Backward TD</a></li></ul></li></ul><!-- tocstop --><h2><span id="monte-carlo-learning">Monte-Carlo Learning</span></h2><p>MC (Monte-Carlo) methods learn directly from <strong>episodes of experience</strong>, which means:</p><ul><li>MC is <em>model-free</em>: no knowledge of MDP transitions / rewards</li><li>MC learns from complete episodes: no bootstrapping</li><li>MC uses the simplest possible idea: value = mean return</li><li>Can only apply MC to <em>episodic</em> MDPs: all episodes must terminate</li></ul><p><strong>Goal</strong>: learn <span class="math inline">\(v_\pi\)</span> from episodes of experience under policy <span class="math inline">\(\pi\)</span> <span class="math display">\[S_1, A_1, R_2, ..., S_k \sim \pi\]</span> Recall that the <strong>return</strong> is the total discounted reward: <span class="math display">\[G_t = R_{t+1}+\gamma R_{t+2} + ... + \gamma^{T-1}R_T\]</span> Recall that the <strong>value function</strong> is the expected return: <span class="math display">\[v_\pi(s) = \mathbb{E}_\pi[G_t|S_t=s]\]</span> Monte-Carlo policy evaluation uses <em>empirical mean</em> return instead of <em>expected</em> return.</p><p><strong>First-Visit Monte-Carlo Policy Evaluation</strong></p><p>To evaluate state <span class="math inline">\(s\)</span>, the <strong>first</strong> time-step <span class="math inline">\(t\)</span> that state <span class="math inline">\(s\)</span> is visited in <strong>an episode</strong>:</p><ul><li>Increment counter <span class="math inline">\(N(s) \leftarrow N(s) + 1\)</span></li><li>Increment total return <span class="math inline">\(S(s) \leftarrow S(s) + G_t\)</span></li></ul><p>Value is estimated by mean return <span class="math inline">\(V(s) = S(s) / N(s)\)</span>, by <em>law of large numbers</em>, <span class="math inline">\(V(s) \rightarrow v_\pi(s)\)</span> as <span class="math inline">\(N(s) \rightarrow \infty\)</span>.</p><p><strong>Every-Visit Monte-Carlo Policy Evaluation</strong></p><p>To evaluate state <span class="math inline">\(s\)</span>, <strong>every</strong> time-step <span class="math inline">\(t\)</span> that state <span class="math inline">\(s\)</span> is visited in <strong>an episode</strong>:</p><ul><li>Increment counter <span class="math inline">\(N(s) \leftarrow N(s) + 1\)</span></li><li>Increment total return <span class="math inline">\(S(s) \leftarrow S(s) + G_t\)</span></li></ul><p>Value is estimated by mean return <span class="math inline">\(V(s) = S(s) / N(s)\)</span>. Again, by <em>law of large numbers</em>, <span class="math inline">\(V(s) \rightarrow v_\pi(s)\)</span> as <span class="math inline">\(N(s) \rightarrow \infty\)</span>.</p><p><strong>Blackjack Example</strong></p><p>Please refer to https://www.wikiwand.com/en/Blackjack to learn the rule of <em>Blackjack</em>.</p><p>If we build an RL agent to play blackjack, the <strong>states</strong> would have 3-dimension:</p><ul><li>Current sum (12 - 21)<ul><li>We just consider this range because if the current sum is lower than 12, we will always take another card.</li></ul></li><li>Dealer's showing card (ace - 10)</li><li>Do I have a &quot;useable&quot; ace? (yes - no)</li></ul><p>So there would be 200 different states.</p><p>The actions are:</p><ul><li><strong>Stick</strong>: stop receiving cards and terminate</li><li><strong>Twist</strong>: take another card (no replacement)</li></ul><p>And <em>reward</em> for action</p><ul><li><strong>Stick</strong><ul><li><span class="math inline">\(+1\)</span> if sum of cards <span class="math inline">\(&gt;\)</span> sum of dealer cards</li><li><span class="math inline">\(0\)</span> if sum of cards <span class="math inline">\(=\)</span> sum of dealer cards</li><li><span class="math inline">\(-1\)</span> if sum of cards <span class="math inline">\(&lt;\)</span> sum of dealer cards</li></ul></li><li><strong>Twist</strong><ul><li><span class="math inline">\(-1\)</span> if sum of cards <span class="math inline">\(&gt; 21\)</span> and terminate</li><li><span class="math inline">\(0\)</span> otherwise</li></ul></li></ul><p>Transitions: automatically <em>twist</em> if sum of cards &lt; 12.</p><p>Policy: <strong>stick</strong> if sum of cards <span class="math inline">\(≥ 20\)</span>, otherwise <strong>twist</strong>.</p><p><img src="/images/backjack.png"></p><p>In the above diagrams, the height represents the value function of that point. Since it's a simple policy, the value funtion achieves high value only if player sum is higher than 20.</p><p><strong>Incremental Mean</strong></p><p>The mean <span class="math inline">\(\mu_1, \mu_2, …\)</span> of a sequence <span class="math inline">\(x_1, x_2, …\)</span> can be computed incrementally, <span class="math display">\[\begin{align}\mu_k &amp; = \frac{1}{k}\sum^k_{j=1}x_j \\&amp; = \frac{1}{k}(x_k+\sum^{k-1}_{j=1}x_j) \\&amp;= \frac{1}{k}(x_k+(k-1)\mu_{k-1}) \\&amp;= \mu_{k-1}+\frac{1}{k}(x_k-\mu_{k-1}) \\\end{align}\]</span> which means the current mean equals to previous mean plus some error. The error is <span class="math inline">\(x_k - \mu_{k-1}\)</span> and the step-size is <span class="math inline">\(\frac{1}{k}\)</span>, which is dynamic.</p><p><strong>Incremental Monte-Carlo Updates</strong></p><p>Update <span class="math inline">\(V(s)\)</span> incrementally after episode <span class="math inline">\(S_1, A_1, R_2, …, S_T\)</span>, for each state <span class="math inline">\(S_t\)</span> with return <span class="math inline">\(G_t\)</span>, <span class="math display">\[N(S_t) \leftarrow N(S_t) + 1\]</span></p><p><span class="math display">\[V(S_t)\leftarrow V(S_t)+\frac{1}{N(S_t)}(G_t-V(S_t))\]</span></p><p>In non-stationary problems, it can be useful to track a running mean, i.e. forget old episodes, <span class="math display">\[V(S_t)\leftarrow V(S_t) + \alpha(G_t-V(S_t))\]</span> So, that's the part for Monte-Carlo learning. It's a very simple idea: you run out an episode, look the complete return and update the mean value of the sample return for each state you have visited.</p><h2><span id="temporal-difference-learning">Temporal-Difference Learning</span></h2><p>Temporal-Difference (TD) methods learn directly from episodes of experiences, which means</p><ul><li>TD is <em>model-free</em>: no knowledge of MDP transitions / rewards</li><li>TD learns from <strong>incomplete</strong> episodes, by <em>bootstrapping</em>. (A major difference from MC method)</li><li>TD updates a guess towards a guess.</li></ul><p>Goal: learn <span class="math inline">\(v_\pi\)</span> online from experience under policy <span class="math inline">\(\pi\)</span>.</p><p><em>Incremental every-visit Monte-Carlo</em></p><ul><li>Update value <span class="math inline">\(V(S_t)\)</span> toward actual return <span class="math inline">\(\color{Red}{G_t}\)</span> <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha (\color{Red}{G_t}-V(S_t))\]</span></li></ul><p>Simplest temporal-difference learning algorithm: <strong>TD(0)</strong></p><ul><li><p>Update value <span class="math inline">\(V(S_t)\)</span> towards <em>estimated</em> return <span class="math inline">\({\color{Red}{R_{t+1}+\gamma V(S_{t+1})}}\)</span> <span class="math display">\[V(S_t)\leftarrow V(S_t)+ \alpha ({\color{Red}{R_{t+1}+\gamma V(S_{t+1})}}-V(S_t))\]</span></p></li><li><p><span class="math inline">\(R_{t+1}+\gamma V(S_{t+1})​\)</span> is called the <em>TD target</em>;</p></li><li><p><span class="math inline">\(\delta = R_{t+1}+\gamma V(S_{t+1})-V(S_t)\)</span> is called the <em>TD error</em>.</p></li></ul><p>Let's see a concret <strong>driving home example</strong>.</p><p><img src="/images/dheg.png"></p><p>The <em>Elapsed Time</em> shows the actual time that has spent, the <em>Predicted Time to Go</em> represents the predicted time to arrive home from current state, and the <em>Predicted Total Time</em> means the predicted time to arrive home from leaving office.</p><p><strong>Advantages and Disadvantages of MC vs. TD</strong></p><p>TD can learn <em>before</em> knowing the final outcome</p><ul><li>TD can learn online after every step</li><li>MC must wait until end of episode before return is known</li></ul><p>TD can learn <em>without</em> the final outcome</p><ul><li>TD can learn from incomplete sequences</li><li>MC can only learn from complete sequences</li><li>TD works in continuing (non-terminating) environments</li><li>MC only works for episodic (terminating) environments</li></ul><p>MC has high variance, zero bias</p><ul><li>Good convergence properties (even with function approximation)</li><li>Not very sensitive to initial value</li><li>Very simple to understand and use</li></ul><p>TD has low variance, some bias</p><ul><li>Usually more efficient than MC</li><li>TD(0) converges to <span class="math inline">\(v_\pi(s)\)</span> (but not always with function approximation)</li><li>More sensitive to initial value</li></ul><p><strong>Bias/Variance Trade-Off</strong></p><p>Return <span class="math inline">\(G_t = R_{t+1} + \gamma R_{t+2}+…+\gamma^{T-1}R_T\)</span> is <strong>unbiased</strong> estimate of <span class="math inline">\(v_\pi(S_t)\)</span>.</p><p>True TD target <span class="math inline">\(R_{t+1}+\gamma v_\pi(S_{t+1})\)</span> is <strong>unbiased</strong> estimate of <span class="math inline">\(v_\pi(S_t)\)</span></p><blockquote><p>Explanation of bias and variance:</p><ul><li>The <a href="https://www.wikiwand.com/en/Bias_of_an_estimator" target="_blank" rel="noopener">bias of an estimator</a> is the difference between an estimator's expected value and the true value of the parameter being estimated.</li><li>A <strong>variance</strong> value of zero indicates that all values within a set of numbers are identical; all variances that are non-zero will be positive numbers. A large variance indicates that numbers in the set are far from the mean and each other, while a small variance indicates the opposite. Read more: <a href="https://www.investopedia.com/terms/v/variance.asp#ixzz51J8RTueh" target="_blank" rel="noopener">Variance</a></li></ul></blockquote><p>While TD target <span class="math inline">\(R_{t+1}+\gamma V(S_{t+1})\)</span> is <strong>biased</strong> estimate of <span class="math inline">\(v_\pi(S_t)\)</span>.</p><p>However, TD target is much lower <em>variance</em> than the return, since</p><ul><li>Return depends on <em>many</em> random actions, transitions, rewards</li><li>TD target depends on <em>one</em> random actions, transition, reward</li></ul><p><strong>Random Walk Example</strong></p><p><img src="/images/rweg.png"></p><p>There are several states on a street, the black rectangles are terminate states. Each transition has 0.5 probability and the reward is marked on the line. The question is what is the value function of each state?</p><p>Using <em>TD</em> to solve the problem:</p><p><img src="/images/rwtd.png"></p><p>The x-axis represents each state, y-axis represent the estimated value. Each line represents the result of TD algorithm that run different episodes. We can see, at the begining, all states have initial value <span class="math inline">\(0.5\)</span>. After 100 episodes, the line converges to diagonal, which is the true values.</p><p>Using <em>MC</em> to solve the problem:</p><p><img src="/images/rwmc.png"></p><p>The x-axis represents the number of episodes that algorithm takes. The y-axis shows the error of the algorithm. The black lines shows using MC methods with different step-size, while the grey lines below represents using TD methods with different step-size. We can see TD methods are more efficient than MC methods.</p><p><strong>Batch MC and TD</strong></p><p>We know that MC and TD converge: <span class="math inline">\(V(s) \rightarrow v_\pi(s)\)</span> as experience <span class="math inline">\(\rightarrow \infty\)</span>. But what about batch solution for finite experience? If we <strong>repeatly</strong> train some <em>finite</em> sample episodes with MC and TD respectively, do the two algorithms give <strong>same</strong> result?</p><p><em>AB Example</em></p><p>To get more intuition, let's see the <em>AB</em> example.</p><p>There are two states in a MDP, <span class="math inline">\(A, B\)</span> with no discounting. And we have 8 episodes of experience:</p><ul><li>A, 0, B, 0</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 1</li><li>B, 0</li></ul><p>For example, the first episode means we in state <span class="math inline">\(A\)</span> and get <span class="math inline">\(0\)</span> reward, then transit to state <span class="math inline">\(B\)</span> getting <span class="math inline">\(0\)</span> reward, and then terminate.</p><p>So, What is <span class="math inline">\(V(A), V(B)\)</span> ?</p><p>First, let's consider <span class="math inline">\(V(B)\)</span>. <span class="math inline">\(B\)</span> state shows 8 times and 6 of them get reward <span class="math inline">\(1\)</span>, 2 of them get reward <span class="math inline">\(0\)</span>. So <span class="math inline">\(V(B) = \frac{6}{8} = 0.75\)</span> according to TD and MC.</p><p>However, if we consider <span class="math inline">\(V(A)\)</span>, MC method will give <span class="math inline">\(V(A) = 0\)</span>, since <span class="math inline">\(A\)</span> just shows in one episode and the reward of that episode is <span class="math inline">\(0\)</span>. TD method will give <span class="math inline">\(V(A) = 0 + V(B) = 0.75\)</span>.</p><p>The MDP of these experiences can be illustrated as</p><p><img src="/images/abmdp.png"></p><p><strong>Certainty Equivalence</strong></p><p>As we show above,</p><ul><li><p><strong>MC</strong> converges to solution with <strong>minimum mean-squared error</strong></p><ul><li><p>Best fit to the <strong>observed returns</strong> <span class="math display">\[\sum^K_{k=1}\sum^{T_k}_{t=1}(G^k_t-V(s^k_t))^2\]</span></p></li><li><p>In the AB example, <span class="math inline">\(V(A) = 0\)</span></p></li></ul></li><li><p><strong>TD(0)</strong> converges to solution of <strong>max likelihood Markov model</strong></p><ul><li><p>Solution to the <strong>MDP <span class="math inline">\(&lt;\mathcal{S, A, P, R, }\gamma&gt;\)</span> that best fits the data</strong></p><p><img src="/images/cemath.png"></p><p>(First, count the transitions. Then compute rewards.)</p></li><li><p>In the AB example, <span class="math inline">\(V(A) = 0.75\)</span></p></li></ul></li></ul><p><strong>Advantages and Disadvantages of MC vs. TD (2)</strong></p><ul><li>TD exploits <strong>Markov property</strong><ul><li>Usually more efficient in Markov environments</li></ul></li><li>MC does <strong>not</strong> exploit Markov property<ul><li>Usually more effective in non-Markov environments</li></ul></li></ul><h3><span id="unified-view">Unified View</span></h3><p><strong>Monte-Carlo Backup</strong></p><p><img src="/images/mcbackup.png"></p><p>We start from <span class="math inline">\(S_t\)</span> to look-ahead and build a look-ahead tree. What Monte-Carlo do is to sample a episode until it terminates and use the episode to update the value of state <span class="math inline">\(S_t\)</span>.</p><p><strong>Temporal-Difference Backup</strong></p><p><img src="/images/tdbackup.png"></p><p>On the contrary, TD backup just sample one-step ahead and use the value of <span class="math inline">\(S_{t+1}\)</span> to update <span class="math inline">\(S_t\)</span>.</p><p><strong>Dynamic Programming Backup</strong></p><p><img src="/images/dpbackup.png"></p><p>In dynamic programming backup, we do not sample. Since we know the environment, we look all possible one-step ahead and weighted them to update the value of <span class="math inline">\(S_t\)</span>.</p><p><strong>Bootstrapping and Sampling</strong></p><ul><li><strong>Bootstrapping</strong>: update involves an estimate<ul><li>MC does not bootstrap</li><li>DP bootstraps</li><li>TD bootstraps</li></ul></li><li><strong>Sampling</strong>: update samples an expectation<ul><li>MC samples</li><li>DP does not sample</li><li>TD samples</li></ul></li></ul><p><strong>Unified View of Reinforcement Learning</strong></p><p><img src="/images/uvrl.png"></p><h2><span id="tdlambda">TD(<span class="math inline">\(\lambda\)</span>)</span></h2><p>Let TD target look <span class="math inline">\(n\)</span> steps into the future,</p><figure><img src="/images/tdlam.png" alt="ds"><figcaption>ds</figcaption></figure><p>Consider the following <span class="math inline">\(n\)</span>-step returns for <span class="math inline">\(n = 1, 2, …, \infty\)</span>:</p><p><img src="/images/tdlamret.png"></p><p>Define the <span class="math inline">\(n\)</span>-step return <span class="math display">\[G_t^{(n)} = R_{t+1}+\gamma R_{t+2}+...+\gamma^{n-1}R_{t+n}+\gamma^n V(S_{t+n})\]</span> <span class="math inline">\(n\)</span>-step temporal-difference learning: <span class="math display">\[V(S_t)\leftarrow V(S_t)+\alpha (G_t^{(n)}-V(S_t))\]</span> We know that <span class="math inline">\(n \in [1, \infty)\)</span>, but which <span class="math inline">\(n\)</span> is the best?</p><p>There are some experiments about that:</p><p><img src="/images/rmn.png"></p><p>So, you can see that the optimal <span class="math inline">\(n\)</span> changes with on-line learning and off-line leanring. If the MDP changes, the best <span class="math inline">\(n\)</span> also changes. Is there a robust algorithm to fit any different situation?</p><h3><span id="forward-view-tdlambda">Forward View TD(<span class="math inline">\(\lambda\)</span>)</span></h3><p><strong>Averaging n-step Returns</strong></p><p>We can average n-step returns over different <span class="math inline">\(n\)</span>, e.g. average the 2-step and 4-step returns: <span class="math display">\[\frac{1}{2}G^{(2)}+\frac{1}{2}G^{(4)}\]</span> But can we efficiently combine information from all time-steps?</p><p>The answer is yes.</p><p><strong><span class="math inline">\(\lambda\)</span>-return</strong></p><p><img src="/images/tdlambda.png"></p><p>The <span class="math inline">\(\lambda\)</span>-return <span class="math inline">\(G_t^{\lambda}\)</span> combines all n-step returns <span class="math inline">\(G_t^{(n)}\)</span> using weight <span class="math inline">\((1-\lambda)\lambda^{n-1}\)</span>: <span class="math display">\[G_t^\lambda = (1-\lambda)\sum^\infty_{n=1}\lambda^{n-1}G_t^{(n)}\]</span> <strong>Forward-view</strong> <span class="math inline">\(TD(\lambda)\)</span>, <span class="math display">\[V(S_t) \leftarrow V(S_t) + \alpha (G_t^\lambda-V(S_t))\]</span> <img src="/images/tdgeo.png"></p><p>We can see the weight decay geometrically and the weights sum to 1.</p><p>The reason we use geometrical decay rather than other weight because it's efficient to compute, we can compute TD(<span class="math inline">\(\lambda\)</span>) as efficient as TD(0).</p><p><img src="/images/forwardtd.png"></p><p><strong>Forward-view</strong> <span class="math inline">\(TD(\lambda)\)</span></p><ul><li>Updates value function towards the <span class="math inline">\(\lambda\)</span>-return</li><li>Looks into the future to compute <span class="math inline">\(G_t^\lambda\)</span></li><li>Like MC, can only be computed from <strong>complete episodes</strong></li></ul><p><img src="/images/fortdlam.png"></p><h3><span id="backward-view-tdlambda">Backward View TD(<span class="math inline">\(\lambda\)</span>)</span></h3><p><strong>Eligibility Traces</strong></p><p><img src="/images/bellexe.png"></p><p>Recall the <a href="https://www.52coding.com.cn/index.php?/Articles/single/69#header-n50">rat example</a> in lecture 1, credit assignment problem: did bell or light cause shock?</p><ul><li><strong>Frequency heuristic</strong>: assign credit to most frequent states</li><li><strong>Recency heuristic</strong>: assign credit to most recent states</li></ul><p><em>Eligibility traces</em> combine both heuristics.</p><p><img src="/images/egt.png"></p><p>If visit state <span class="math inline">\(s\)</span>, <span class="math inline">\(E_t(s)\)</span> plus <span class="math inline">\(1\)</span>; otherwise <span class="math inline">\(E_t(s)\)</span> decay exponentially.</p><p><strong>Backward View TD(<span class="math inline">\(\lambda\)</span>)</strong></p><ul><li>Keep an eligibility trace for every state <span class="math inline">\(s\)</span></li><li>Update value <span class="math inline">\(V(s)\)</span> for every state <span class="math inline">\(s\)</span> in proportion to TD-error <span class="math inline">\(\delta_t\)</span> and eligibility trace <span class="math inline">\(E_t(s)\)</span></li></ul><p><span class="math display">\[\delta_t=R_{t+1}+\gamma V(S_{t+1})-V(S_t)\]</span></p><p><span class="math display">\[V(s)\leftarrow V(s)+\alpha \delta_tE_t(s)\]</span></p><p><img src="/images/bvtdlam.png"></p><p>When <span class="math inline">\(\lambda = 0\)</span>, only current state is updated, which is exactly equivalent to TD(0) update: <span class="math display">\[E_t(s) = 1(S_t = s)\]</span></p><p><span class="math display">\[V(s)\leftarrow V(s)+\alpha\delta_tE_t(s) = V(S_t)+\alpha\delta_t\]</span></p><p>When <span class="math inline">\(\lambda = 1\)</span>, credit is deferred until end of episode, total update for TD(1) is the same as total update for MC.</p><h3><span id="relationship-between-forward-and-backward-td">Relationship Between Forward and Backward TD</span></h3><blockquote><p><strong>Theorem</strong></p><p>The sum of offline updates is identical for forward-view and backward-view TD(<span class="math inline">\(\lambda\)</span>) <span class="math display">\[\sum^T_{t=1}\alpha\delta_tE_t(s)=\sum^T_{t=1}\alpha(G_t^\lambda-V(S_t))1(S_t=s)\]</span></p></blockquote><p><strong>MC and TD(1)</strong></p><p>Consider an episode where <span class="math inline">\(s\)</span> is visited once at time-step <span class="math inline">\(k\)</span>, TD(1) eligiblity trace discounts time since visit, <span class="math display">\[E_t(s) = \gamma E_{t-1}(s)+1(S_t = s) = \begin{cases} 0,  &amp; \mbox{if }t&lt;k \\\gamma^{t-k}, &amp; \mbox{if }t≥k\end{cases}\]</span> TD(1) updates accumulate error <em>online</em> <span class="math display">\[\sum^{T-1}_{t=1}\alpha\delta_tE_t(s)=\alpha\sum^{T-1}_{t=k}\gamma^{t-k}\delta_t\]</span> By end of episode it accumulates total error <span class="math display">\[\begin{align}\mbox{TD(1) Error}&amp;= \delta_k+\gamma\delta_{k+1}+\gamma^2\delta_{k+2}+...+\gamma^{T-1-k}\delta_{T-1} \\&amp; = R_{t+1}+\gamma V(S_{t+1}) -V(S_t) \\&amp;+ \gamma R_{t+2}+\gamma^2V(S_{t+2}) - \gamma V(S_{t+1})\\&amp;+ \gamma^2 R_{t+3}+\gamma^3V(S_{t+3}) - \gamma^2 V(S_{t+2})\\&amp;+\ ... \\&amp;+ \gamma^{T-1-t}R_T+\gamma^{T-t}V(S_T)-\gamma^{T-1-t}V(S_{T-1})\\&amp;= R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3} ... + \gamma^{T-1-t}R_T-V(S_t)\\&amp;= G_t-V(S_t)\\&amp;= \mbox{MC Error}\end{align}\]</span> TD(1) is roughly equivalent to every-visit Monte-Carlo, error is accumulated online, step-by-step.</p><p>If value function is only updated offline at end of episode, then total update is exactly the same as MC.</p><p><strong>Forward and Backward Equivalence</strong></p><p>For general <span class="math inline">\(\lambda\)</span>, TD errors also telescope to <span class="math inline">\(\lambda\)</span>-error, <span class="math inline">\(G_t^\lambda-V(S_t)\)</span></p><p><img src="/images/teltdlam.png"></p><p>Consider an episode where <span class="math inline">\(s\)</span> is visited once at time-step <span class="math inline">\(k\)</span>, TD(<span class="math inline">\(\lambda\)</span>) eligibility trace discounts time since visit, <span class="math display">\[E_t(s) = \gamma\lambda E_{t-1}(s)+1(S_t = s) = \begin{cases} 0,  &amp; \mbox{if }t&lt;k \\(\gamma\lambda)^{t-k}, &amp; \mbox{if }t≥k\end{cases}\]</span> Backward TD(<span class="math inline">\(\lambda\)</span>) updates accumulate error <em>online</em> <span class="math display">\[\sum^{T-1}_{t=1}\alpha\delta_tE_t(s)=\alpha\sum^{T-1}_{t=k}(\gamma\lambda)^{t-k}\delta_t = \alpha(G_k^\lambda-V(S_k))\]</span> By end of episode it accumulates total error for <span class="math inline">\(\lambda\)</span>-return.</p><p>For multiple visits to <span class="math inline">\(s\)</span>, <span class="math inline">\(E_t(s)\)</span> accumulates many errors.</p><p><strong>Offline</strong> Updates</p><ul><li>Updates are accumulated within episode but applied in batch at the end of episode</li></ul><p><strong>Online</strong> Updates</p><ul><li>TD(<span class="math inline">\(\lambda\)</span>) updates are applied online at each step within episode, forward and backward view TD(<span class="math inline">\(\lambda\)</span>) are slightly different.</li></ul><p>In summary,</p><p><img src="/images/tdsum.png"></p><ul><li>Forward view provides <strong>theory</strong></li><li>Backward view provids <strong>mechanism</strong><ul><li>update online, every step, from incomplete sequences</li></ul></li></ul><p>This lecture just talks about how to evaluate a policy given an unknown MDP. Next lecture will introduce Model-free Control.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> Model-Free </tag>
            
            <tag> Monte-Carlo Learning </tag>
            
            <tag> TD </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Planning by Dynamic Programming</title>
      <link href="/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/"/>
      <url>/2017/12/07/RL%20-%20Planning%20by%20Dynamic%20Programming/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#introduction">Introduction</a></li><li><a href="#policy-evaluation">Policy Evaluation</a></li><li><a href="#policy-iteration">Policy Iteration</a></li><li><a href="#value-iteration">Value Iteration</a></li><li><a href="#extentions-to-dynamic-programming">Extentions to Dynamic Programming</a></li><li><a href="#contraction-mapping">Contraction Mapping</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="introduction">Introduction</span></h2><p><strong>What is Dynamic Programming?</strong></p><p><strong>Dynamic</strong>: sequential or temporal component to the problem <strong>Programming</strong>: optimising a &quot;program&quot;, i.e. a policy</p><ul><li>c.f. linear programming</li></ul><p>So, Dynamic Programming is a method for solving complex problems by breaking them down into <strong>subproblems</strong>.</p><ul><li>Solve the subproblems</li><li>Combine solutions to subproblems</li></ul><p>Dynamic Programming is a very general solution method for problems which have two properties:</p><ul><li><strong>Optimal substructure</strong><ul><li><em>Principle of optimality applies</em></li><li>Optimal solution can be decomposed into subproblems</li></ul></li><li><strong>Overlapping subproblems</strong><ul><li>Subproblems recur many times</li><li>Solution can be cached and reused</li></ul></li></ul><p><strong>Markov decision processes</strong> satisfy both properties:</p><ul><li><strong>Bellman euqtion</strong> gives recursive decomposition</li><li><strong>Value function</strong> stores and reuses solutions</li></ul><p><strong>Planning by Dynamic Programming</strong></p><p><strong>Planning</strong> means dynamic programming assumes full knowledge of the MDP.</p><ul><li>For prediction (Policy Evaluation):<ul><li>Input: MDP<span class="math inline">\(&lt;S,A,P,R,\gamma&gt;\)</span> and policy <span class="math inline">\(\pi\)</span></li><li>Output: value function <span class="math inline">\(v_{\pi}\)</span></li></ul></li><li>For <strong>control</strong>:<ul><li>Input: MDP<span class="math inline">\(&lt;S,A,P,R,\gamma&gt;\)</span></li><li>Output: optimal value function <span class="math inline">\(v_*\)</span> and optimal policy <span class="math inline">\(\pi_*\)</span></li></ul></li></ul><p>We first learn how to evaluate a policy and then put it into a loop to find the optimal policy.</p><h2><span id="policy-evaluation">Policy Evaluation</span></h2><ul><li><p>Problem: evaluate a given policy <span class="math inline">\(\pi\)</span></p></li><li><p>Solution: iterative application of <strong>Bellman expectation equation</strong></p></li><li><p><span class="math inline">\(v_1\)</span> -&gt; <span class="math inline">\(v_2\)</span> -&gt; <span class="math inline">\(v_3\)</span> -&gt; … -&gt; <span class="math inline">\(v_\pi\)</span></p></li><li><p><em>Synchronous</em> backups</p><ul><li><p>At each iteration <span class="math inline">\(k+1\)</span></p></li><li><p>For all states <span class="math inline">\(s \in S\)</span></p></li><li><p>Update <span class="math inline">\(v_{k+1}(s)\)</span> from <span class="math inline">\(v_k(s&#39;)\)</span>, where <span class="math inline">\(s&#39;\)</span> is a successor state of <span class="math inline">\(s\)</span></p><p><img src="/images/vpi2.png"> <span class="math display">\[v_{k+1}(s)=\sum_{a\in\mathcal{A}}\pi(a|s)(\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}v_k(s&#39;))\]</span></p><p><span class="math display">\[v^{k+1}=\mathcal{R}^\pi+\gamma \mathcal{P}^\pi v^k\]</span></p></li></ul></li></ul><p><em>Example</em>: Evaluating a Random Policy in the Small Gridworld</p><p><img src="/images/grid.png"></p><ul><li><p>Actions are move North/East/South/West for one grid.</p></li><li><p>Undiscounted episodic MDP (<span class="math inline">\(\gamma = 1\)</span>)</p></li><li><p>Nontermial states <span class="math inline">\(1, …, 14\)</span></p></li><li><p>One terminal State (shown twice as shaded squares)</p></li><li><p>Reward is <span class="math inline">\(-1\)</span> until the terminal state is reahed</p></li><li><p>Agent follows uniform random policy <span class="math display">\[\pi(n|\cdot)=\pi(e|\cdot)=\pi(s|\cdot)=\pi(w|\cdot) = 0.25\]</span></p></li></ul><p>Let's use dynamic programming to solve the MDP.</p><p><img src="/images/ipe1.png"></p><p><img src="/images/ipe2.png"></p><p>The grids on the left show the value function of each state, the update rule shown by the illustration. Finally, it converges to the true value function of the policy. It basically tell us <em>if we take the random walk under the policy, how much reward on average we will get when we reach the terminal state</em>.</p><p>The right-hand column shows how to find better policy with respect to the value funtions.</p><h2><span id="policy-iteration">Policy Iteration</span></h2><p>How to improve a Policy</p><ul><li><p>Given a policy <span class="math inline">\(\pi\)</span></p><ul><li><p><strong>Evaluate</strong> the policy <span class="math inline">\(\pi\)</span> <span class="math display">\[v_\pi(s) = E[R_{t+1}+\gamma R_{t+2} + ... | S_t = s]\]</span></p></li><li><p><strong>Improve</strong> the policy by acting <em>greedily</em> with respect to <span class="math inline">\(v_\pi\)</span> <span class="math display">\[\pi&#39;=greddy(v_\pi)\]</span></p></li></ul></li><li><p>In general, need more iterations of improvement / evaluation</p></li><li><p>But this process of <em>policy iteration</em> always converges to <span class="math inline">\(\pi_*\)</span></p></li></ul><p><img src="/images/pi.png"></p><p><strong>Demonstration</strong></p><p>Consider a deterministic policy <span class="math inline">\(a = \pi(s)\)</span>, we can improve the policy by acting greedily <span class="math display">\[\pi&#39;(s) = \arg\max_{a\in\mathcal{A}}q_\pi(s, a)\]</span> (Note: <span class="math inline">\(q_\pi\)</span> is the action value function following policy <span class="math inline">\(\pi\)</span>)</p><p>This improves the value from any state <span class="math inline">\(s\)</span> over one step, <span class="math display">\[q_\pi(s, \pi&#39;(s)) = \max_{a\in\mathcal{A}}q_\pi(s,a)≥q_\pi(s, \pi(s))=v_\pi(s)\]</span> (Note: <span class="math inline">\(q_\pi(s, \pi&#39;(s))\)</span> means the action value of taking one step following policy <span class="math inline">\(\pi&#39;\)</span> then following policy <span class="math inline">\(\pi\)</span> forever.)</p><p>If therefore improves the value function, <span class="math inline">\(v_{\pi&#39;}(s) ≥ v_\pi (s)\)</span> <span class="math display">\[\begin{align}v_\pi(s) &amp; ≤ q_\pi(s, \pi&#39;(s))=E_{\pi&#39;}[R_{t+1}+\gamma v_\pi(S_{t+1})|S_t = s]  \\&amp; ≤ E_{\pi&#39;}[R_{t+1} + \gamma q_\pi(S_{t+1}, \pi&#39;(S_{t+1}))|S_t=s] \\&amp;≤ E_{\pi&#39;}[R_{t+1} + \gamma R_{t+2} + \gamma^2q_\pi(S_{t+2}, \pi&#39;(S_{t+2}))|S_t = s]\\&amp;≤ E_{\pi&#39;}[R_{t+1} + \gamma R_{t+2} + ..... | S_t = s] = v_{\pi&#39;}(s)\end{align}\]</span> (Unroll the equation to the second, third … step by taking the Bellman euqation into it.)</p><p>If improvements stop, <span class="math display">\[q_\pi(s, \pi&#39;(s)) = \max_{a\in\mathcal{A}}q_\pi(s,a) = q_\pi(s, \pi(s)) = v_\pi(s)\]</span> Then the <strong>Bellman optimality</strong> equation has been satisfied <span class="math display">\[v_\pi(s) = \max_{a\in\mathcal{A}}q_\pi(s, a)\]</span> Therefore <span class="math inline">\(v_\pi(s) = v_*(s)\)</span> for all <span class="math inline">\(s \in \mathcal{S}\)</span>, so <span class="math inline">\(\pi\)</span> is an optimal policy.</p><p><strong>Early Stopping</strong></p><p>Question: Does policy evaluation need to converge to <span class="math inline">\(v_\pi\)</span> ?</p><ul><li>e.g. in the small gridworld <span class="math inline">\(k = 3\)</span> was sufficient to acheive optimal policy</li></ul><p>Or shoule we introduce a stopping condition</p><ul><li>e.g. <span class="math inline">\(\epsilon\)</span>-convergence of value function</li></ul><p>Or simply stop after <span class="math inline">\(k\)</span> iterations of iterative policy evaluation?</p><h2><span id="value-iteration">Value Iteration</span></h2><p><strong>Principle of Optimality</strong></p><p>Any optimal policy can be subdivided into two components:</p><ul><li>An optimal first action <span class="math inline">\(A_*\)</span></li><li>Followed by an optimal policy from successor state <span class="math inline">\(S&#39;\)</span></li></ul><blockquote><p>Theorem: Principle of Optimality</p><p>A policy <span class="math inline">\(\pi(a|s)\)</span> achieves the optimal value from state <span class="math inline">\(s\)</span>, <span class="math inline">\(v_\pi(s) = v_*(s)\)</span> if and only if</p><ul><li>For any state <span class="math inline">\(s&#39;\)</span> reachable from <span class="math inline">\(s\)</span>, <span class="math inline">\(\pi\)</span> achieves the optimal value from state <span class="math inline">\(s&#39;\)</span></li></ul></blockquote><p>If we know the solution to subproblems <span class="math inline">\(v_\ast(s&#39;)\)</span>, then solution <span class="math inline">\(v_\ast(s)\)</span> can be found by one-step look ahead: <span class="math display">\[v_\ast(s) \leftarrow \max_{a\in\mathcal{A}}\mathcal{R}^a_s+\gamma \sum_{s&#39;\in \mathcal{S}}P^a_{ss&#39;}v_\ast(s&#39;)\]</span> The idea of value iteration is to apply these updates iteratively.</p><ul><li>Intuition: start with final rewards and work backwards</li><li>Still works with loopy, stochatis MDPs</li></ul><p><strong>Example: Shortest Path</strong></p><p><img src="/images/grid2.png"></p><ul><li>The goal state is on the left-up corner</li><li>Each step get -1 reward</li><li>The number showed in each grid is the value of that state</li><li>At each iteration, update all states</li></ul><p><strong>Value Iteration</strong></p><ul><li>Problem: find optimal policy <span class="math inline">\(\pi\)</span></li><li>Solution: iterative application of Bellman optimality backup</li><li><span class="math inline">\(v_1 \rightarrow v_2 \rightarrow … \rightarrow v_*\)</span></li><li><em>Synchronous</em> backups<ul><li>At each iteration <span class="math inline">\(k+1\)</span></li><li>For all states <span class="math inline">\(s\in \mathcal{S}\)</span></li><li>Update <span class="math inline">\(v_{k+1}(s)\)</span> from <span class="math inline">\(v_k(s&#39;)\)</span></li></ul></li><li>Convergence to <span class="math inline">\(v_*\)</span> will be proven later</li><li>Unlike policy iteration, there is no explicit policy</li><li>Intermediate value functions may not correspond to any policy</li></ul><p><strong>Synchronous Dynamic Programming Algorithms</strong></p><table><colgroup><col style="width: 12%"><col style="width: 51%"><col style="width: 35%"></colgroup><thead><tr class="header"><th>problem</th><th>bellman equation</th><th>algorithm</th></tr></thead><tbody><tr class="odd"><td>Prediction</td><td>Bellman Expectation Equation</td><td>Iterative Policy Evaluation</td></tr><tr class="even"><td>Control</td><td>Bellman Expectation Equation + Greedy Policy Improvement</td><td>Policy Iteration</td></tr><tr class="odd"><td>Control</td><td>Bellman Optimatility Equation</td><td>Value Iteration</td></tr></tbody></table><p>Algorithms are based on state-value function <span class="math inline">\(v_\pi(s)\)</span> or <span class="math inline">\(v_*(s)\)</span></p><ul><li><span class="math inline">\(O(mn^2)\)</span> per iteration, for <span class="math inline">\(m\)</span> actions and <span class="math inline">\(n\)</span> states</li></ul><p>Could also apply to action-value function <span class="math inline">\(q_\pi(s, a)\)</span> or <span class="math inline">\(q_*(s, a)\)</span></p><ul><li><span class="math inline">\(O(m^2n^2)\)</span> per iteration</li></ul><h2><span id="extentions-to-dynamic-programming">Extentions to Dynamic Programming</span></h2><p><strong>Asynchronous Dynamic Programming</strong></p><p><em>Asynchronous DP</em> backs up states individually, in any order. For each selected state, apply the appropriate backup, which can significantly reduce computation. It also guaranteed to converge if all states continue to be selected.</p><p>Three simple ideas for asynchronous dynamic programming:</p><ul><li><p><em>In-place</em> dynamic programming</p><p><img src="/images/in-place.png"></p></li><li><p><em>Prioritised sweeping</em></p><p><img src="/images/ps.png"></p></li><li><p><em>Real-time</em> dynamic programming</p><p><img src="/images/real-time.png"></p></li></ul><p><strong>Full-Width Backups</strong></p><p>DP uses <em>full-width</em> backups</p><ul><li><em>full-width</em> means when we look aheah, we consider all branches(actions) that could happen</li><li>For each backup (sync or async)<ul><li>Every successor state and action is considered</li><li>Using knowledge of the MDP transitions and reward function</li></ul></li></ul><p><img src="/images/fw.png"></p><h2><span id="contraction-mapping">Contraction Mapping</span></h2><p>Information about <em>contraction mapping theorem</em>, please refer to http://www.math.uconn.edu/~kconrad/blurbs/analysis/contraction.pdf</p><p>Consider the vector space <span class="math inline">\(\mathcal{V}\)</span> over value functions. There are <span class="math inline">\(|\mathcal{S}|\)</span> dimensions.</p><ul><li>Each point in this space fully specifies a value function <span class="math inline">\(v(s)\)</span></li></ul><p>We will measure distance between state-value functions <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> by the <span class="math inline">\(\infty\)</span>-norm. <span class="math display">\[||u-v||_\infty = \max_{s\in\mathcal{S}}|u(s)-v(s)|\]</span> <em>Bellman Expectation Backup is a Contraction</em></p><p>Define the <em>Bellman expectation backup operator</em> <span class="math inline">\(T^\pi\)</span>, <span class="math display">\[T^\pi(v) = \mathcal{R}^\pi + \gamma\mathcal{P}^\pi v\]</span> This operator is a <span class="math inline">\(\gamma\)</span>-contraction, it makes value functions closer bt at least <span class="math inline">\(\gamma\)</span>, <span class="math display">\[\begin{align}||T^\pi(u)-T^\pi(v)||_\infty &amp;= ||(\mathcal{R}^\pi + \gamma\mathcal{P}^\pi v) - (\mathcal{R}^\pi + \gamma\mathcal{P}^\pi u)||_\infty \\&amp;= ||\gamma P^\pi(u-v)||_\infty\\&amp;≤||\gamma P^\pi||u-v||_\infty||_\infty\\&amp;≤\gamma||u-v||_\infty\end{align}\]</span></p><blockquote><p>Theorem: <strong>Contraction Mapping Theorem</strong></p><p>For any metric space <span class="math inline">\(\mathcal{V}\)</span> that is complete (closed) under an operator <span class="math inline">\(T(v)\)</span>, where <span class="math inline">\(T\)</span> is a <span class="math inline">\(\gamma\)</span>-contraction,</p><ul><li><span class="math inline">\(T\)</span> converges to a unique fixed point</li><li>At a linear convergence rate of <span class="math inline">\(\gamma\)</span></li></ul></blockquote><p><strong>Convergence of Iterative Policy Evaluation and Policy Iteration</strong></p><p>The Bellman expectation operator <span class="math inline">\(T^\pi\)</span> has a unique fixed point <span class="math inline">\(v_\pi\)</span>.</p><p>By contraction mapping theorem,</p><ul><li>Iterative policy evaluation converges on <span class="math inline">\(v_\pi\)</span>;</li><li>Policy iteration converges on <span class="math inline">\(v_*\)</span>.</li></ul><p><em>Bellman Optimality Backup is a Contraction</em></p><p>Define the <em>Bellman Optimality backup operator</em> <span class="math inline">\(T^\ast\)</span>, <span class="math display">\[T^\ast(v) = \max_{a\in\mathcal{A}}\mathcal{R}^a+\gamma \mathcal{P}^av\]</span> This operator is a <span class="math inline">\(\gamma\)</span>-contraction, it makes value functions closer by at least <span class="math inline">\(\gamma\)</span>, <span class="math display">\[||T^\ast(u)-T\ast(v)||_\infty≤\gamma ||u-v||_\infty\]</span> <strong>Convergence of Value Iteration</strong></p><p>The Bellman optimality operator <span class="math inline">\(T^∗\)</span> has a unique fixed point <span class="math inline">\(v_*\)</span>.</p><p>By contraction mapping theorem, value iteration converges on <span class="math inline">\(v_*\)</span>.</p><p>In summary, what does a Bellman backup do to points in value function space is to bring value functions <em>closer</em> to a unique fixed point. And therefore the backups must converge on a unique solution.</p><p>This lecture (note) introduces how to use dynamic programming to solve <em>planning</em> problems. Next lecture will introduce model-free prediction, which is a really RL problem.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> MDP </tag>
            
            <tag> Dynamic Programming </tag>
            
            <tag> Policy Iteration </tag>
            
            <tag> Value Iteration </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Markov Decision Processes</title>
      <link href="/2017/08/18/RL%20-%20Markov%20Decision%20Processes/"/>
      <url>/2017/08/18/RL%20-%20Markov%20Decision%20Processes/</url>
      
        <content type="html"><![CDATA[<p><strong>Table of Contents</strong></p><!-- toc --><ul><li><a href="#markov-processes">Markov Processes</a></li><li><a href="#markov-reward-process">Markov Reward Process</a></li><li><a href="#markov-decision-process">Markov Decision Process</a></li></ul><!-- tocstop --><h2><span id="markov-processes">Markov Processes</span></h2><p>Basically, <strong>Markov decision processes</strong> formally describe an environment for reinforcement learning, where the environment is <strong>fully observable</strong>, which means the current state completely characterises the process.</p><a id="more"></a><p>Almost all RL problems can be formalised as MDPs, e.g.</p><ul><li>Optimal control primarily deals with continuous MDPs</li><li>Partially observable problems can be converted into MDPs</li><li>Bandits are MDPs with one state</li></ul><p>So, if we solve MDP, we can solve all above RL problems.</p><p><strong>Markov Property</strong></p><p>Markov Property is &quot;The future is independent of the past given the present&quot;, like <a href="https://www.52coding.com.cn/index.php?/Articles/single/69">last note</a> said. The formal definition is: <span class="math display">\[P[S_{t+1}|S_t]=P[S_{t+1}|S_1, ..., S_t]\]</span> where <span class="math inline">\(S\)</span> represents a state.</p><p>The formula means the current can capture all relevant information from the history. Once the state is known, the history may be thrown away, i.e. the state is a sufficient statistic of the future.</p><p><strong>State Transition Matrix</strong></p><p>We know that given the current state, we can use its information to reach the next state, but how? — It is characterized by the <em>state transition probability</em>.</p><p>For a Markov state <span class="math inline">\(s\)</span> and successor state <span class="math inline">\(s&#39;\)</span> , the state transition probability is deﬁned by <span class="math display">\[P_{ss&#39;}=P[S_{t+1}=s&#39;|S_t=s]\]</span> We can put all of the probabities into a matrix called transition matrix, denoted by <span class="math inline">\(P\)</span> : <span class="math display">\[P = \begin{bmatrix}P_{11}     &amp; \cdots &amp; P_{1n}      \\\vdots &amp; \ddots &amp; \vdots \\P_{n1}     &amp; \cdots &amp; P_{nn}\end{bmatrix}\]</span> where each row of the matrix sums to 1.</p><p><strong>Markov Process</strong></p><p>Formally, a Markov process is a <strong>memoryless</strong> random process, i.e. a sequence of random states <span class="math inline">\(S_1, S_2, …\)</span> with the <strong>Markov property</strong>.</p><blockquote><p>Definition</p><p><strong>A Markov Process (or Markov Chain) is tuple</strong> <span class="math inline">\(&lt;S, P&gt;\)</span></p><ul><li><strong><span class="math inline">\(S\)</span> is a (finite) set of states</strong></li><li><strong><span class="math inline">\(P\)</span> is a state transition probability matrix, <span class="math inline">\(P_{ss&#39;} = P[S_{t+1}=s&#39;|S_t=s]\)</span></strong></li></ul></blockquote><p><em>Example</em></p><p><img src="/images/markov.png"></p><p>The above figure show a markov chains of a student's life. Process starts from <em>Class 1</em>, taking class 1 may be boring, so he have either 50% probability to look <em>Facebook</em> or to move to <em>Class 2</em>. …. And finally, he reach the final state <em>Sleep</em>. It's a final state just because it is a self-loop with probability 1 which is nothing special.</p><p>We can sample sequences from such process. Sample <strong>episodes</strong> for Student Markov Chain starting from <span class="math inline">\(S_1 = C_1\)</span>: <span class="math display">\[S_1, S_2, ..., S_T\]</span></p><ul><li>C1 C2 C3 Pass Sleep</li><li>C1 FB FB C1 C2 Sleep</li><li>C1 C2 C3 Pub C2 C3 Pass Sleep</li><li>C1 FB FB C1 C2 C3 Pub C1 FB FB FB C1 C2 C3 Pub C2 Sleep</li></ul><p>Also, we can make the transition matrix from such markov chain:</p><p><img src="/images/trans_mat.png"></p><p>If we have this matrix, we can fully describe the Markov process.</p><h2><span id="markov-reward-process">Markov Reward Process</span></h2><p>So far, we have never talked about Reinforcement Learning, there is no reward at all. So, let's talk about the <em>Markov Reward Process</em>.</p><p>The most important is adding reward to Markov process, so a Markov reward process is a Markov chain with values.</p><blockquote><p>Definition</p><p>A Markov Reward Process is tuple <span class="math inline">\(&lt;S, P, R, \gamma&gt;\)</span></p><ul><li><span class="math inline">\(S\)</span> is a (finite) set of states</li><li><span class="math inline">\(P\)</span> is a state transition probability matrix, <span class="math inline">\(P_{ss&#39;} = P[S_{t+1}=s&#39;|S_t=s]\)</span></li><li><strong><span class="math inline">\(R\)</span> is a reward function, <span class="math inline">\(R_s=E[R_{t+1}|S_t=s]\)</span></strong></li><li><strong><span class="math inline">\(\gamma\)</span> is a discount factor, <span class="math inline">\(\gamma \in [0, 1]\)</span></strong></li></ul></blockquote><p>Note that <span class="math inline">\(R\)</span> is the <strong>immediate reward</strong>, it characterize the reward you will get if you currently stay on state <span class="math inline">\(s\)</span>.</p><p><em>Example</em></p><p>Let's back to the student example:</p><p><img src="/images/mrp.png"></p><p>At each state, we have corresponding reward represents the goodness/badness of that state.</p><p><strong>Return</strong></p><p>We don't actually care about the immediate reward, we care about the whole random sequence's total reward. So we define the term <em>return</em>:</p><blockquote><p>Definition</p><p><strong>The return <span class="math inline">\(G_t\)</span> is the total dicounted reward from time-step <span class="math inline">\(t\)</span>.</strong> <span class="math display">\[G_t=R_{t+1}+\gamma R_{t+2}+...=\sum_{k=0}^\infty \gamma^kR_{t+k+1}\]</span></p></blockquote><p>The discount <span class="math inline">\(\gamma \in [0,1]\)</span> is the present value of future rewards. So the value of receiving reward <span class="math inline">\(R\)</span> after <span class="math inline">\(k+1\)</span> time-steps is <span class="math inline">\(\gamma^k R\)</span>.</p><p><strong>Note</strong>: <span class="math inline">\(R_{t+1}\)</span> is the immediate reward of state <span class="math inline">\(S_t\)</span>.</p><p>This values <strong>immediate reward</strong> above <strong>delayed reward</strong>:</p><ul><li><span class="math inline">\(\gamma\)</span> closes to <span class="math inline">\(0\)</span> leads to &quot;myopic&quot; evaluation</li><li><span class="math inline">\(\gamma\)</span> closes to <span class="math inline">\(1\)</span> leads to &quot;far-sighted&quot; evaluation</li></ul><p>Most Markov reward and decision processes are discounted. <strong>Why?</strong></p><ul><li><strong>Mathematically convenient</strong> to discount rewards</li><li><strong>Avoids inﬁnite returns</strong> in cyclic Markov processes</li><li><strong>Uncertainty</strong> about the future may not be fully represented</li><li>If the reward is ﬁnancial, immediate rewards may earn more interest than delayed rewards</li><li><strong>Animal/human behaviour</strong> shows preference for immediate reward</li><li>It is sometimes possible to use undiscounted Markov reward processes (i.e. γ = 1), e.g. if all sequences terminate.</li></ul><p><strong>Value Function</strong></p><p>The value function <span class="math inline">\(v(s)\)</span> gives the long-term value of state <span class="math inline">\(s\)</span>.</p><blockquote><p>Definition</p><p><strong>The state value funtion <span class="math inline">\(v(s)\)</span> of an MRP is the expected return starting from state <span class="math inline">\(s\)</span></strong> <span class="math display">\[v(s) = E[G_t|S_t=s]\]</span></p></blockquote><p>We use expectation because it is a random process, we want to figure out the expected value of a state, not such a sequence sampled starts it.</p><p><em>Example</em></p><p>Sample <strong>returns</strong> from Student MRP, starting from <span class="math inline">\(S_1 = C1\)</span> with <span class="math inline">\(\gamma = \frac{1}{2}\)</span>: <span class="math display">\[G_1=R_2+\gamma R_3+...+\gamma^{T-2}R_T\]</span> <img src="/images/samret.png"></p><p>The <em>return</em> is random, but the <em>value function</em> is not random, rather, it is expectation of all samples' return.</p><p>Let's see the example of state <em>value function</em>:</p><p><img src="/images/svf.png"></p><p>When <span class="math inline">\(\gamma = 0\)</span>, the value function just consider the reward of current state no matter how it changes future.</p><p><img src="/images/gamma0.9.png"></p><p><img src="/images/gamma1.png"></p><p><strong>Bellman Equation for MRPs</strong></p><p>The value function can be decomposed into two parts:</p><ul><li>immediate reward <span class="math inline">\(R_{t+1}\)</span></li><li>discounted value of successor state <span class="math inline">\(\gamma v(S_{t+1})\)</span></li></ul><p>So as to we can apply dynamic programming to solve the value function.</p><p>Here is the demonstration: <span class="math display">\[\begin{align}v(s) &amp; = \mathbb{E}[G_t|S_t=s] \\&amp; = \mathbb{E}[R_{t+1}+\gamma R_{t+2}+\gamma^2 R_{t+3}+...|S_t=s] \\&amp;= \mathbb{E}[R_{t+1}+\gamma(R_{t+2}+\gamma R_{t+3}+...)|S_t=s]\\&amp;= \mathbb{E}[R_{t+1}+\gamma G_{t+1}|S_t=s]\\&amp;= \mathbb{E}[R_{t+1}+\gamma v(S_{t+1})|S_t=s]\end{align}\]</span> Here we get: <span class="math display">\[v(s) =\mathbb{E}[R_{t+1}+\gamma v(S_{t+1})|S_t=s]=R_{t+1}+\gamma\mathbb{E}[ v(S_{t+1})|S_t=s]\]</span> We look ahead one-step, and averaging all value function of next possible state:</p><p><img src="/images/bf2.png"> <span class="math display">\[v(s) = R_s+\gamma\sum_{s&#39;\in S}P_{ss&#39;}v(s&#39;)\]</span> We can use the Bellman equation to vertify a MRP:</p><p><img src="/images/verMRP.png"></p><p><em>Bellman Equation in Matrix Form</em></p><p>The Bellman equation can be expressed concisely using matrices, <span class="math display">\[v = R + \gamma Pv\]</span> where <span class="math inline">\(v\)</span> is a column vector with one entry per state: <span class="math display">\[\begin{bmatrix}v(1)         \\\vdots  \\v(n)    \end{bmatrix}=\begin{bmatrix}R_1         \\\vdots  \\R_n   \end{bmatrix}+\gamma \begin{bmatrix}P_{11}     &amp; \cdots &amp; P_{1n}      \\\vdots &amp; \ddots &amp; \vdots \\P_{n1}     &amp; \cdots &amp; P_{nn}\end{bmatrix}\begin{bmatrix}v(1)         \\\vdots  \\v(n)    \end{bmatrix}\]</span> Because the Bellman equation is a linear equation, it can be solved directly: <span class="math display">\[\begin{align}v &amp; = R+\gamma Pv \\(I-\gamma P)v&amp; =R \\v &amp;= (I-\gamma P)^{-1}R\end{align}\]</span> However, the Computational complexity is <span class="math inline">\(O(n^3)\)</span> for <span class="math inline">\(n\)</span> states, because of the inverse operation. This method can be applied to solve small MRPs.</p><p>There are many iterative methods for large MRPs, e.g.</p><ul><li>Dynamic programming</li><li>Monte-Carlo evaluation</li><li>Temporal-Diﬀerence learning</li></ul><p>So far with MRP, all we want to do is to make decisions, so let's move on <em>Markov Decision Process</em>, which we actually using in RL.</p><h2><span id="markov-decision-process">Markov Decision Process</span></h2><p>A <strong>Markov decision process (MDP)</strong> is a Markov reward process with decisions. It is an <em>environment</em> in which all states are Markov.</p><blockquote><p>Definition</p><p><strong>A Markov Decision Process is a tuple</strong> <span class="math inline">\(&lt;S, A,P,R,\gamma&gt;\)</span></p><ul><li><span class="math inline">\(S\)</span> is a finite set of states</li><li><span class="math inline">\(A\)</span> <strong>is a finite set of actions</strong></li><li><span class="math inline">\(P\)</span> is a state transition probability matrix, <span class="math inline">\(P^a_{ss&#39;}=\mathbb{P}[S_{t+1}=s&#39;|S_t=s, A_t=a]\)</span></li><li><span class="math inline">\(R\)</span> is a reward function, <span class="math inline">\(R^a_s=\mathbb{E}[R_{t+1}|S_t=s,A_t=t]\)</span></li><li><span class="math inline">\(\gamma\)</span> is a discount factor <span class="math inline">\(\gamma \in[0,1]\)</span></li></ul></blockquote><p><em>Example</em></p><p><img src="/images/mdpstu.png"></p><p>Red marks represents the actions or decisions, what we want to do is to find the best path that maximize the value function.</p><p><strong>Policy</strong></p><p>Formally, the decision can be defined as <em>policy</em>:</p><blockquote><p>Definition</p><p><strong>A policy π is a distribution over actions given states,</strong> <span class="math display">\[\pi(a|s)=\mathbb{P}[A_t=a|S_t=s]\]</span></p></blockquote><p>A policy fully deﬁnes the behaviour of an agent.</p><p>Note that MDP policies depend on the current state (not the history), i.e. policies are stationary (time-independent), <span class="math inline">\(A_t~\pi(\cdot|S_t), \forall t&gt;0\)</span>.</p><p>An MDP can transform into a Markov process or an MRP:</p><ul><li><p>Given an MDP <span class="math inline">\(\mathcal{M}=&lt;\mathcal{S,A,P,R}, \gamma&gt;\)</span> and a policy <span class="math inline">\(\pi\)</span></p></li><li><p>The state sequence <span class="math inline">\(&lt;S_1 , S_2 , ... &gt;\)</span> is a Markov process <span class="math inline">\(&lt;\mathcal{S, P}^π&gt;\)</span></p></li><li><p>The state and reward sequence <span class="math inline">\(&lt;S_1 , R_2 , S_2 , …&gt;\)</span> is a Markov reward process <span class="math inline">\(&lt;\mathcal{S,P}^\pi,\mathcal{R}^\pi,\gamma&gt;\)</span> where, <span class="math display">\[\mathcal{P}^\pi_{s,s&#39;}=\sum_{a\in\mathcal{A}}\pi(a|s)P^a_{ss&#39;}\]</span></p><p><span class="math display">\[\mathcal{R}^\pi_s=\sum_{a\in\mathcal{A}}\pi(a|s)\mathcal{R}^a_s\]</span></p></li></ul><p><strong>Value Function</strong></p><p>There are two value functions: the first one is called <em>state-value function</em> which represents the expected return following policy <span class="math inline">\(\pi\)</span>, the other is called <em>action-value function</em> which measures the goodness/badness of an action following policy <span class="math inline">\(\pi\)</span>.</p><blockquote><p>Definition</p><p>The <strong>state-value function</strong> <span class="math inline">\(v_π (s)\)</span> of an MDP is the expected return starting from state <span class="math inline">\(s\)</span>, and then following policy π <span class="math display">\[v_\pi(s)=\mathbb{E}_\pi[G_t|S_t=s]\]</span></p></blockquote><blockquote><p>Definition</p><p>The <strong>action-value function</strong> <span class="math inline">\(q_π (s, a)\)</span> is the expected return starting from state <span class="math inline">\(s\)</span>, taking action <span class="math inline">\(a\)</span>, and then following policy <span class="math inline">\(π\)</span> <span class="math display">\[q_\pi(s,a)=\mathbb{E}_\pi[G_t|S_t=s,A_t=a]\]</span></p></blockquote><p><em>Example</em></p><p><img src="/images/svformdp.png"></p><p><strong>Bellman Expectation Equation</strong></p><p>The <strong>state-value function</strong> can again be decomposed into immediate reward plus discounted value of successor state, <span class="math display">\[v_\pi(s)=\mathbb{E}_\pi[R_{t+1}+\gamma v_\pi(S_{t+1})|S_t=s]\]</span> The <strong>action-value function</strong> can similarly be decomposed, <span class="math display">\[q_\pi(s,a)=\mathbb{E}_\pi[R_{t+1}+\gamma q_\pi (S_{t+1},A_{t+1})|S_t=s,A_t=a]\]</span> <em>Bellman Expectation Equation for <span class="math inline">\(V_π\)</span></em></p><p><img src="/images/vpi.png"> <span class="math display">\[v_\pi(s)=\sum_{a\in\mathcal{A}}\pi(a|s)q_\pi(s,a)\]</span> The look-ahead approach is taking an action and computing its reward, all we need to do is to averaging all possible actions' rewards, which is equal to current state-value.</p><p><em>Bellman Expectation Equation for <span class="math inline">\(Q_π\)</span></em></p><p><img src="/images/qpi.png"> <span class="math display">\[q_\pi(s,a)=\mathcal{R}_s^a + \gamma \sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}v_\pi(s&#39;)\]</span> It is identical to the immediate reward of taking action <span class="math inline">\(a\)</span> plus the average of the reward/value of all possible states which the action could lead to.</p><p><em>Bellman Expectation Equation for <span class="math inline">\(V_π\)</span></em></p><p><img src="/images/vpi2.png"> <span class="math display">\[v_\pi(s)=\sum_{a\in\mathcal{A}}\pi(a|s)(\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}v_\pi(s&#39;))\]</span> This is a two-step look-ahead approach, just combining the last two equations.</p><p><img src="/images/qpi2.png"> <span class="math display">\[q_\pi(s,a)=\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}\sum_{a&#39;\in\mathcal{A}}\pi(a&#39;|s&#39;)q_\pi(s&#39;,a&#39;)\]</span> <em>Example</em>: State-value function</p><p><img src="/images/qgbee.png"></p><p><em>Bellman Expectation Equation (Matrix Form)</em></p><p>The Bellman expectation equation can be expressed concisely using the induced MRP, <span class="math display">\[v_\pi=R^\pi+\gamma P^\pi v_\pi\]</span> with direct solution <span class="math display">\[v_\pi=(I-\gamma P^{\pi-1})^{-1}R^\pi\]</span> <strong>Optimal Value Function</strong></p><blockquote><p>Definition</p><p><strong>The optimal state-value function <span class="math inline">\(v_∗(s)\)</span> is the maximum value function over all policies</strong> <span class="math display">\[v_\ast(s)=\max_{\pi}v_\pi(s)\]</span> <strong>The optimal action-value function <span class="math inline">\(q_∗ (s, a)\)</span> is the maximum action-value function over all policies</strong> <span class="math display">\[q_\ast(s,a)=\max_\pi q_\pi(s,a)\]</span></p></blockquote><p>The optimal value function speciﬁes the best possible performance in the MDP.</p><p>If we know the <span class="math inline">\(q_*(s,a)\)</span>, we &quot;solve&quot; MDP because we know what actions should take at each state to maximize the reward.</p><p><em>Example</em></p><p><img src="/images/egvalue.png"></p><p><img src="/images/egstar.png"></p><p><strong>Optimal Policy</strong></p><p>Deﬁne a partial ordering over policies <span class="math display">\[\pi≥\pi&#39;\ if\ v_\pi(s)≥v_{\pi&#39;}, \forall s\]</span></p><blockquote><p>Theorem</p><ul><li><strong>There exists an optimal policy <span class="math inline">\(π_∗\)</span> that is better than or equal to all other policies,</strong>, <span class="math inline">\(\pi_* ≥ \pi, \forall \pi\)</span></li><li><strong>All optimal policies achieve the optimal value function,</strong> <span class="math inline">\(v_{pi_*}=v_*(s)\)</span></li><li><strong>All optimal policies achieve the optimal action-value function,</strong> <span class="math inline">\(q_{\pi_*}(s,a)=q_*(s,a)\)</span></li></ul></blockquote><p><em>Finding an Optimal Policy</em></p><p>An optimal policy can be found by maximising over <span class="math inline">\(q_∗ (s, a)\)</span>,</p><p><span class="math display">\[\pi_\ast(a|s)=\begin{cases}1\ if\ a=\arg\max_{a\in\mathcal{A}}q_\ast(s,a) \\0 \ otherwise\end{cases}\]</span></p><p>There is always a deterministic optimal policy for any MDP. So if we know <span class="math inline">\(q_∗ (s, a)\)</span>, we immediately have the optimal policy.</p><p><img src="/images/optpol.png"></p><p>The optimal policy is highlight in red.</p><p><strong>Bellman Optimality Equation</strong></p><p>The optimal value functions are recursively related by the Bellman optimality equations:</p><p><img src="/images/boev.png"></p><p><span class="math display">\[v_\ast(s)=\max_aq_\ast(s,a)\]</span></p><p><img src="/images/boeq.png"></p><p><span class="math display">\[q_\ast(s,a)=\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}\mathcal{P}^a_{ss&#39;}v_\ast(s&#39;)\]</span></p><p><img src="/images/boev2.png"></p><p><span class="math display">\[v_\ast(s)=\max_a\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}\mathcal{P}^a_{ss&#39;}v_\ast(s&#39;)\]</span></p><p><img src="/images/boeq2.png"></p><p><span class="math display">\[q_\ast(s,a)=\mathcal{R}^a_s+\gamma\sum_{s&#39;\in\mathcal{S}}P^a_{ss&#39;}\max_{a&#39;}q_\ast(s&#39;,s)\]</span></p><p><em>Example</em></p><p><img src="/images/boe_in_stu_mdp.png"></p><p><em>Solving the Bellman Optimality Equation</em></p><p>Bellman Optimality Equation is non-linear, so it is not able to be sovle as solving linear equation. And there is no closed from solution (in general).</p><p>Many <strong>iterative</strong> solution methods</p><ul><li>Value Iteration</li><li>Policy Iteration</li><li>Q-learning</li><li>Sarsa</li></ul><p>End. Next note will introduce how to solve the Bellman Optimality Equation by dynamic programming.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> MDP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RL - Introduction to Reinforcement Learning</title>
      <link href="/2017/08/15/RL%20-%20Introduction%20to%20Reinforcement%20Learning/"/>
      <url>/2017/08/15/RL%20-%20Introduction%20to%20Reinforcement%20Learning/</url>
      
        <content type="html"><![CDATA[<p>RL, especially DRL (Deep Reinforcement Learning) has been an fervent research area during these years. One of the most famous RL work would be AlphaGo, who has beat <a href="https://www.wikiwand.com/en/Lee_Sedol" target="_blank" rel="noopener">Lee Sedol</a>, one of the best players at Go, last year. And in this year (2017), AlphaGo won three games with Ke Jie, the world No.1 ranked player. Not only in Go, AI has defeated best human play in many games, which illustrates the powerful of the combination of Deep Learning and Reinfocement Learning. However, despite AI plays better games than human, AI takes more time, data and energy to train which cannot be said to be very intelligent. Still, there are numerous unexplored and unsolved problems in RL research, that's also why we want to learn RL.</p><p>This is the first note of David Silver's <a href="http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html" target="_blank" rel="noopener">RL course</a>.</p><a id="more"></a><!-- toc --><ul><li><a href="#about-reinforcement-learning">About Reinforcement Learning</a></li><li><a href="#the-reinforcement-learning-problem">The Reinforcement Learning Problem</a></li><li><a href="#inside-an-rl-agent">Inside An RL Agent</a></li><li><a href="#problems-within-reinforcement-learning">Problems within Reinforcement Learning</a></li></ul><!-- tocstop --><h2><span id="about-reinforcement-learning">About Reinforcement Learning</span></h2><p>Reinforcement Learning is one of the three major branches of Machine Learning, and is also the intersect of many different disciplines, as the following two figure illustrated.</p><p><img src="/images/branches.png"></p><p><img src="/images/faces.png"></p><p>There are several reasons that makes reinforcement learning different from other machine learning paradigms:</p><ul><li>There is no supervisor, only a <em>reward</em> signal</li><li>Feedback is delayed, not instantaneous</li><li>Time really matters (sequential, non i.i.d data)</li><li>Agent's actions affect the subsequent data it receives</li></ul><p>There are some examples of Reinforcement Learning:</p><ul><li>Fly stunt manoeuvres in a helicopter</li><li>Defeat the world champion at Backgammon</li><li>Manage an investment portfolio</li><li>Control a power station</li><li>Make a humanoid robot walk</li><li>Play many diﬀerent Atari games better than humans</li></ul><h2><span id="the-reinforcement-learning-problem">The Reinforcement Learning Problem</span></h2><p><strong>Rewards</strong></p><p>We say RL do not have a supervisor, just a <em>reward</em> signal. Then what is <em>reward</em> ?</p><ul><li>A <strong>reward</strong> <span class="math inline">\(R_t\)</span> is a scalar feedback signal</li><li>Indicates how well agent is doing at step <span class="math inline">\(t\)</span></li><li>The agent's job is to maximise cumulative reward</li></ul><p>Reinforcement Learning is based on the <strong>reward hypothesis</strong>, which is</p><blockquote><p>Definition of reward hypothesis</p><p><strong>All goals can be described by the maximisation of expected cumulative reward.</strong></p></blockquote><p>There are some examples of <em>rewards</em> :</p><ul><li>Fly stunt manoeuvres in a helicopter<ul><li>+ve reward for following desired trajectory</li><li>−ve reward for crashing</li></ul></li><li>Defeat the world champion at Backgammon<ul><li>+/−ve reward for winning/losing a game</li></ul></li><li>Manage an investment portfolio<ul><li>+ve reward for each $ in bank</li></ul></li><li>Control a power station<ul><li>+ve reward for producing power</li><li>−ve reward for exceeding safety thresholds</li></ul></li><li>Make a humanoid robot walk<ul><li>+ve reward for forward motion</li><li>−ve reward for falling over</li></ul></li><li>Play many diﬀerent Atari games better than humans<ul><li>+/−ve reward for increasing/decreasing score</li></ul></li></ul><p><strong>Sequential Decision Making</strong></p><p>So, according to the <em>reward hypothesis</em>, our goal is to <strong>select actions to maximise total future reward</strong>. Actions may have long term consequences as well as reward may be delayed. It may be better to sacrifice immediate reward to gain more long-term reward. For instance, a ﬁnancial investment may take months to mature and a helicopter might prevent a crash in several hours.</p><p><strong>Agent and Environment</strong></p><p><img src="/images/aae.png"></p><p>Agents and envrionments are big concepts in RL. They have following relationships:</p><ul><li>At each step <span class="math inline">\(t\)</span> the agent:<ul><li>Excutes action <span class="math inline">\(A_t\)</span></li><li>Receives observation <span class="math inline">\(O_t\)</span></li><li>Receives scalar reward <span class="math inline">\(R_t\)</span></li></ul></li><li>The environment:<ul><li>Receives action <span class="math inline">\(A_t\)</span></li><li>Emits observation <span class="math inline">\(O_{t+1}\)</span></li><li>Emits scalar reward <span class="math inline">\(R_{t+1}\)</span></li></ul></li><li><span class="math inline">\(t\)</span> increments at env. step</li></ul><p><strong>State</strong></p><p><em>History and State</em></p><p>The <strong>history</strong> is the sequence of observations, actions, rewards: <span class="math display">\[H_t = O_1, R_1, A_1, ..., A_{t-1}, O_t, R_t\]</span> which means all observable variables up to time <span class="math inline">\(t\)</span>, i.e. the sensorimotor stream of a robot or embodied agent.</p><p>What happens next depends on the history:</p><ul><li>The agent selects actions</li><li>The environments select observations/rewards</li></ul><p><strong>State</strong> is the information used to determine what happens next. Formally, state is a function of the history: <span class="math display">\[S_t = f(H_t)\]</span> <em>Environment State</em></p><p>The <strong>environment state</strong> <span class="math inline">\(S^e_t\)</span> is the environment's private representation, i.e. whatever data the environment uses to pick the next observation /reward. The environment state is not usually visible to the agent. Even if <span class="math inline">\(S^e_t\)</span> is visible, it may contain irrelevant information.</p><p><em>Agent State</em></p><p>The <strong>agent state</strong> <span class="math inline">\(S^a_t\)</span> is the agent's internal representation, i.e. whatever information the agent uses to pick the next action. It is the information used by reinforcement learning algotithms. It can be any function of history: <span class="math display">\[S^a_t=f(H_t)\]</span> <em>Information State</em></p><p>An <strong>information state</strong> (a.k.a. <strong>Markov state</strong>) contains all useful information from the history.</p><blockquote><p>Definition</p><p><strong>A state <span class="math inline">\(S_t\)</span> is Markov if and only if</strong> <span class="math display">\[P[S_{t+1}|S_t]=P[S_{t+1}|S_1,...,S_t]\]</span></p></blockquote><p>The above formular means:</p><ul><li><p>&quot;The future is independent of the past given the present&quot; <span class="math display">\[H_{1:t}\rightarrow S_t\rightarrow H_{t+1:\infty}\]</span></p></li><li><p>Once the state is known, the history may be thrown away.</p></li><li><p>The state is a sufficient statistic of the future</p></li><li><p>The environment state <span class="math inline">\(S^e_t\)</span> is Markov</p></li><li><p>The history <span class="math inline">\(H_t\)</span> is Markov</p></li></ul><p><em>Rat Example</em></p><p>Here is an example to explain what is state, imagine you are a rat and your master would decide whether to excuted you or give you a pice of cheese. The master makes decisions according to a sequence of signals, the first two sequence and the result are shown in the figure below:</p><p><img src="/images/firsttwo.png"></p><p>The question is, what would you get if the sequence is like below:</p><p><img src="/images/que.png"></p><p>Well, the answer you may give is decided by what is your agent state：</p><ul><li>If agent state = last 3 items in sequence, then the answer would be being excuted.</li><li>If agent state = counters for lights, bells and levers, then the answer would be given a piece of cheese.</li><li>What if agent state = complete sequence?</li></ul><p><em>Fully Observable Environments</em></p><p><strong>Full observability</strong>: agent <strong>directly</strong> observes environment state: <span class="math display">\[O_t = S^a_t=S^e_t\]</span></p><ul><li>Agent state = environment state = information state</li><li>Formally, this is a <strong>Markov decision process</strong> (MDP)</li></ul><p><em>Partially Observable Environments</em></p><p><strong>Partial observability</strong>: agent <strong>indirectly</strong> observes environment:</p><ul><li>A robot with camera vision isn't told its absolute location</li><li>A trading agent only observes current prices</li><li>A poker playing agent only observes public cards</li></ul><p>With partial observability, agent state ≠ environment state, formally this is a <strong>partially observable Markov decision process</strong> (POMDP).</p><p>In this situation, agent must construct its own state representation <span class="math inline">\(S^a_t\)</span>, e.g.</p><ul><li>Complete history: <span class="math inline">\(S^a_t = H_t\)</span></li><li><strong>Beliefs</strong> of environment state: <span class="math inline">\(S_t^a = (P[S^e_t=s^1], …, P[S^e_t=s^n])\)</span></li><li>Recurrent neural network: <span class="math inline">\(S^a_t=\sigma(S^a_{t-1}W_s+O_tW_o)\)</span></li></ul><h2><span id="inside-an-rl-agent">Inside An RL Agent</span></h2><p>There are three major components of an RL agent, actually, an agent may include one or more of these:</p><ul><li>Policy: agent's behaviour function</li><li>Value function：how good is each state and/or action</li><li>Model：agent's representation of the environment</li></ul><p><strong>Policy</strong></p><p>A <strong>Policy</strong> is the agent's behaviour, it is a map from state to action, e.g.</p><ul><li>Deterministic policy：<span class="math inline">\(a = \pi(s)\)</span></li><li>Stochastic policy: <span class="math inline">\(\pi(a|s)=P[A_t=a|S_t=s]\)</span></li></ul><p><strong>Value Function</strong></p><p>Value function is a prediction of future reward, it is used to evaluate the goodness/badness of states. And therefore to select between actions: <span class="math display">\[v_\pi(s)=E_\pi[R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+...|S_t=s]\]</span> <strong>Model</strong></p><p>A <strong>model</strong> predicts what the environment will do next, denoted by <span class="math inline">\(P\)</span> which predicts the next state and by <span class="math inline">\(R\)</span> predicts the next (immediate) reward: <span class="math display">\[P^a_{ss&#39;}=P[S_{t+1}=s&#39;|S_t=s,A_t=a]\]</span></p><p><span class="math display">\[R^a_s=E[R_{t+1}|S_t=s, A_t=a]\]</span></p><p><em>Maze Example</em></p><p><img src="/images/maze.png"></p><p>Let an RL agent to solve the maze, the parameters are:</p><ul><li>Rewards: -1 per time-step</li><li>Actions: N, E, S, W</li><li>States: Agent's location</li></ul><p>Then the policy map would be (arrows represent policy <span class="math inline">\(\pi(s)\)</span> for each state <span class="math inline">\(s\)</span>):</p><p><img src="/images/mpolicy.png"></p><p>And the value function at each state would be (numbers represent value <span class="math inline">\(v_\pi(s)\)</span> of each state <span class="math inline">\(s\)</span>):</p><p><img src="/images/mvf.png"></p><p>Model could be visualize as following:</p><ul><li>Grid layout represents transition model <span class="math inline">\(P^a_{ss&#39;}\)</span></li><li>Numbers represent immediate reward <span class="math inline">\(R^a_s\)</span> from each state <span class="math inline">\(s\)</span> (same for all <span class="math inline">\(a\)</span>)</li></ul><p><img src="/images/mm.png"></p><ul><li>Agent may have an internal model of the environment</li><li>Dynamics: how actions change the state</li><li>Rewards: how much reward from each state</li><li>The model may be imperfect</li></ul><p><strong>Categorizing RL agents</strong></p><p>RL agents could be categorized into several categories:</p><ul><li>Value Based<ul><li>No Policy (Implicit)</li><li>Value Function</li></ul></li><li>Policy Based<ul><li>Policy</li><li>No Value Function</li></ul></li><li>Actor Critic<ul><li>Policy</li><li>Value Function</li></ul></li><li>Model Free<ul><li>Policy and/or Value Function</li><li>No Model</li></ul></li><li>Model Based<ul><li>Policy and/or Value Function</li><li>Model</li></ul></li></ul><p><img src="/images/agcat.png"></p><h2><span id="problems-within-reinforcement-learning">Problems within Reinforcement Learning</span></h2><p>This section only proposes questions without providing the solutions.</p><p><strong>Learning and Planning</strong></p><p>Two fundamental problems in sequential decision making:</p><ul><li>Reinforcement Learning<ul><li>The environment is initially unknown</li><li>The agent interacts with the environment</li><li>The agent improves its policy</li></ul></li><li>Planning:<ul><li>A model of the environment is known</li><li>The agent performs computations with its model (without any external interaction)</li><li>The agent improves its policy a.k.a. deliberation, reasoning, introspection, pondering, thought, search</li></ul></li></ul><p><em>Atari Example: Reinforcement Learning</em></p><p><img src="/images/atari.png"></p><p>In atari games, rules of the game are unknown, the agent learns directly from interactive game-play by picking actions on joystick and seeing pixels and scores.</p><p><em>Atari Example: Planning</em></p><p><img src="/images/plan.png"></p><p>In such case, rules of the game are known, which means the agent could query the emulator as known as a perfect model inside agent's brain. Agents need plan ahead to ﬁnd optimal policy, e.g. tree search.</p><p><strong>Exploration and Exploitation</strong></p><ul><li>Reinforcement learning is like trial-and-error learning</li><li>The agent should discover a good policy</li><li>From its experiences of the environment</li><li>Without losing too much reward along the way</li><li><strong>Exploration</strong> ﬁnds more information about the environment</li><li><strong>Exploitation</strong> exploits known information to maximise reward</li><li>It is usually important to explore as well as exploit</li></ul><p><em>Examples</em></p><ul><li>Restaurant Selection<ul><li>Exploitation Go to your favourite restaurant</li><li>Exploration Try a new restaurant</li></ul></li><li>Online Banner Advertisements<ul><li>Exploitation Show the most successful advert</li><li>Exploration Show a diﬀerent advert</li></ul></li><li>Game Playing<ul><li>Exploitation Play the move you believe is best</li><li>Exploration Play an experimental move</li></ul></li></ul><p><strong>Prediction and Control</strong></p><p><strong>Prediction</strong>: evaluate the future</p><ul><li>Given a policy</li></ul><p><strong>Control</strong>: optimise the future</p><ul><li>Find the best policy</li></ul><p>End. Next note will introduce the Markov Decision Processes.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> 增强学习 </tag>
            
            <tag> DRL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Stacked Attention Networks for Image QA</title>
      <link href="/2017/08/15/SAN%20for%20Image%20QA/"/>
      <url>/2017/08/15/SAN%20for%20Image%20QA/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Zichao Yang, Xiaodong He, Jianfeng Gao , Li Deng , Alex Smola <a href="https://arxiv.org/abs/1511.02274" target="_blank" rel="noopener">Stacked Attention Networks for Image Question Answering</a></p></blockquote><p>这篇文章发表在CVPR2016，作者把 attention 机制应用在 Visual QA，不但能理解神经网络生成答案的 multiple resoning，而且获得了当时最好的效果。</p><p>SAN总共由三部分组成：</p><ul><li>Image Model：用来编码图片信息</li><li>Question Moel：用来编码问题信息</li><li>Stacked Attention Networks：通过多层 attention layer 不断优化对问题的编码</li></ul><a id="more"></a><p><img src="/images/san.png"></p><h2><span id="image-model">Image Model</span></h2><p>Image model 使用 VGGNet 处理源图片，用最后一个池化层作为提取的图片特征: <span class="math display">\[f_I = CNN_{vgg}(I)\]</span> 把输入图片转化为 <span class="math inline">\(448 \times 448\)</span> 大小， 输出的特征即为 <span class="math inline">\(512 \times 14 \times 14\)</span>，其中 <span class="math inline">\(512\)</span> 为特征向量（feature vector） <span class="math inline">\(f_i\)</span> 的维度，<span class="math inline">\(14 \times 14\)</span> 是区域（特征向量）的个数，每个特征向量 <span class="math inline">\(f_i\)</span> 代表源图片中 <span class="math inline">\(32 \times 32\)</span> 大小的区域。</p><p><img src="/images/vgg.png"></p><p>为了后面方便处理，通过一个线性层把图片特征转化为和问题特征一样的维度： <span class="math display">\[v_I = \tanh(W_If_I + b_I)\]</span> 其中，<span class="math inline">\(v_I\)</span> 是个矩阵，它的第 <span class="math inline">\(i\)</span> 列 <span class="math inline">\(v_i\)</span> 是区域 <span class="math inline">\(i\)</span> 的特征向量（feature vector）。</p><h2><span id="question-model">Question Model</span></h2><p>作者采用了两种模型对问题进行编码，分别基于 LSTM 和 CNN。</p><h3><span id="lstm-based-question-model">LSTM based question model</span></h3><p>基于 LSTM 的模型很简单，就是用一个普通的 LSTM 对问题进行编码（没准扩展成bi-LSTM效果会更好一些），每个时刻处理一个词，把最后一个词对应的 hidden state 作为编码结果: <span class="math display">\[\begin{alignat}{3}x_t &amp;= W_eq_t, \ t\in\{1, 2, ... T\} \\h_t &amp;= LSTM(x_t), \ t\in\{1, 2, ... T\}\\v_Q &amp;= h_T\end{alignat}\]</span> 其中， <span class="math inline">\(q_t\)</span> 为词的 one-hot encoding，<span class="math inline">\(W_e\)</span> 为 embedding 矩阵，<span class="math inline">\(x_t\)</span> 就为词的 word embedding（总觉得这样的词编码太简单了），<span class="math inline">\(v_Q\)</span> 为对问题的编码。</p><p><img src="/images/lstmq.png"></p><h3><span id="cnn-based-question-model">CNN based question model</span></h3><p><img src="/images/cnn_basedq.png"></p><p>这应该算是CNN的一个变种，它的 filter 有三种，分别为 unigram, bigram, trigram，分别对应窗口大小 <span class="math inline">\(c = 1, 2, 3\)</span>。定义符号 <span class="math inline">\(x_{i:j}\)</span> 为 <span class="math inline">\(x_i, x_{i+1}, …, x_j\)</span> 的连接，所以问题向量可表示为: <span class="math display">\[x_{1:T} = [x1, x2, ..., x_T]\]</span></p><p>然后对每一个 filter 分别在 <span class="math inline">\(x_{1:T}\)</span> 上进行卷积操作，第 <span class="math inline">\(t\)</span> 次卷积操作的输出为： <span class="math display">\[h_{c,t} = \tanh(W_cx_{t:t+c-1}+b_c)\]</span> 窗口大小为 <span class="math inline">\(c\)</span> 的 feature map 为： <span class="math display">\[h_c = [h_{c,1}, h_{c,2}, ..., h_{c,T-c+1}]\]</span> 然后对每个 feature map 进行 max pooling，得到最终的问题特征： <span class="math display">\[\hat{h}_c = \max_t(h_{c,1}, h_{c, 2} ..., h_{c,T-c+1})\]</span></p><p><span class="math display">\[v_Q = h = [\hat{h}_1,\hat{h}_2,\hat{h}_3]\]</span></p><h2><span id="stacked-attention-networks">Stacked Attention Networks</span></h2><p><strong>第一层 attention network</strong></p><p><img src="/images/san1st.png"></p><p>首先根据图像特征矩阵 <span class="math inline">\(v_I\)</span> 和问题特征向量 <span class="math inline">\(v_Q\)</span> 计算 attention map： <span class="math display">\[\begin{alignat}{3}h_A &amp;= \tanh(W_{I,A}v_I\oplus (W_{Q,A}v_Q+b_A))\\p_I &amp;= softmax(W_Ph_A+b_P)\end{alignat}\]</span> 其中，<span class="math inline">\(v_I\in R^{d\times m}\)</span>, <span class="math inline">\(d\)</span> 是图像特征的维度，<span class="math inline">\(m\)</span> 是图像区域个数；<span class="math inline">\(v_Q \in R^d\)</span>；<span class="math inline">\(W_{I, A}, W_{Q,A} \in R^{k \times d}\)</span>，<span class="math inline">\(b_A \in R^{k}\)</span>；定义 <span class="math inline">\(\oplus\)</span> 为矩阵和向量的加法，其运算规则为矩阵的每一列分别和该向量相加，所以 <span class="math inline">\(h_A \in R^{k\times m}\)</span>。<span class="math inline">\(W_P \in R^{1\times k}, b_P\in R^{1\times m}\)</span>，<span class="math inline">\(p_I \in R^{1\times m}\)</span> 为 attention vector，它每一项都是一个概率，表示该问题的答案所在某个区域的概率，或者说问了回答这个问题，注意力应该集中在哪里。</p><p>之后用 attention vector 计算 图像特征的加权和，然后与问题特征相加，得到<strong>优化的问题特征</strong>： <span class="math display">\[\begin{alignat}{3}\widehat{v}_I &amp;= \sum_ip_iv_i \\u &amp;= \hat{v}_I+v_Q\end{alignat}\]</span> 后面的每层 attention network 结构都是一样的，区别在于不再使用原始的问题特征 <span class="math inline">\(v_Q\)</span>，而是用优化后的 <span class="math inline">\(u\)</span>:</p><p><img src="/images/san2nd.png"></p><p><strong>第 k 层 attention network</strong> <span class="math display">\[\begin{alignat}{3}h_A^k &amp;= \tanh(W_{I,A}^kv_I\oplus (W_{Q,A}^ku_{k-1}+b_A^k))\\p_I^k &amp;= softmax(W_P^kh_A^k+b_P^k)\\\widehat{v}_I^k &amp;= \sum_ip_i^kv_i \\u^k &amp;= \hat{v}_I^k+u^{k-1}\end{alignat}\]</span> 作者通过实验发现，第一层 attention 可以识别问题中出现的实体，第二层则可以消除无关的，只关心与答案相关的实体，多加几层对识别效果没有明显提升。</p><p><strong>输出层</strong></p><p><img src="/images/vqa_out.png"></p><p>由于输出只是一个词，所以可以转化为分类问题，在所有候选答案里挑一个词出来： <span class="math display">\[p_{ans} = softmax(W_uu^K+b_u)\]</span> 其中 <span class="math inline">\(K\)</span> 为 attention 的层数。</p><h2><span id="可视化-attention-layer">可视化 Attention Layer</span></h2><ul><li>正确结果</li></ul><p><img src="/images/true_vqa.png"></p><ul><li>错误结果</li></ul><p><img src="/images/false_vqa.png"></p><h2><span id="总结">总结</span></h2><p>这篇文章的主要工作在于把 attention 机制应用在 Visual QA 问题中，效果卓群，可解释性强。但也有可改进的地方，如图片编码选择 ResNet 而不是 VGGNet；问题的 word embedding 采用 word2vec；对问题的编码采用 bi-LSTM 等，也许会进一步提高整体的表现。</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Attention </tag>
            
            <tag> CV </tag>
            
            <tag> CNN </tag>
            
            <tag> VQA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Neural Machine Translation In Linear Time (ByteNet)</title>
      <link href="/2017/08/14/Neural%20Machine%20Translation%20In%20Linear%20Time%20(ByteNet)/"/>
      <url>/2017/08/14/Neural%20Machine%20Translation%20In%20Linear%20Time%20(ByteNet)/</url>
      
        <content type="html"><![CDATA[<p>ByteNet 可用于<strong>字符级</strong>的机器翻译模型并且有着很好的表现，它的特点在于可以在线性时间 (linear time) 完成翻译而且能够处理长距离依赖。它也采用编码器-解码器架构，并且编码器和解码器都由CNN组成。</p><p>ByteNet 之所以有上述的这些特性，是因为使用了如下一些技术：</p><ul><li>Dynamic Unfolding<ul><li>解决了生成不同长度翻译的问题</li></ul></li><li>Dilated Convolution<ul><li>缩短了依赖传播的距离</li></ul></li><li>Masked 1D Convolution<ul><li>保证训练时只用过去的信息生成当前字符</li></ul></li><li>Residual Blocks<ul><li>解决梯度消失问题</li></ul></li></ul><a id="more"></a><p><img src="/images/byte.png"></p><h2><span id="dynamic-unfolding">Dynamic Unfolding</span></h2><p><img src="/images/dy_unfold.png"></p><p>Encoder 的输出的句子编码的长度固定为 <span class="math inline">\(|\hat{t}|\)</span> (不够会补零)，是目标句子长度 <span class="math inline">\(|t|\)</span> 的上界，可以通过下式得到： <span class="math display">\[|\hat{t}| = a|s| + b\]</span> 其中，<span class="math inline">\(|s|\)</span> 表示源句子长度，通过选择适当的参数 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(b\)</span>，使得 <span class="math inline">\(|\hat{t}|\)</span> 基本都大于实际长度 <span class="math inline">\(|t|\)</span>，并且没有太多冗余。</p><p>在每一步，decoder 根据当前输入字符和句子特征输出下一个字符，直到生成EOS。至于 decoder 怎么接收输入并 conditioned on 编码器的输出，论文在并没有提及，不过从一个<a href="https://github.com/paarthneekhara/byteNet-tensorflow/blob/master/ByteNet/model.py" target="_blank" rel="noopener">开源实现</a>中看出是直接把输入和编码器在对应位置的输出连接起来，如上图所示。</p><h2><span id="dilated-convolution">Dilated Convolution</span></h2><p>一维离散卷积的定义为： <span class="math display">\[(f*g)[n] = \sum_{m=-\infty}^{\infty}f[m]g[n-m] = \sum_{m=-M}^Mf[n - m]g[m]\]</span> 例：如果 <span class="math inline">\(f = [0, 1, 2, -1, 1, -3, 0]\)</span>, <span class="math inline">\(g = [1, 0, -1]\)</span>，则按照上式，卷积计算如下所示： <span class="math display">\[\begin{array}{lcl}(f*g)[2]        &amp; = &amp; f[2]g[0] + f[1]g[1] + f[0]g[2] = -2 \\(f*g)[3]  &amp; = &amp; f[3]g[0] + f[2]g[1] + f[1]g[2] = 2 \\...\\(f*g)[6]  &amp; = &amp; f[6]g[0] + f[5]g[1] + f[4]g[2] = 1 \\\end{array}\]</span> 和 stride = 1 的普通卷积网络计算一致。</p><p><img src="/images/stride.jpeg"></p><p><strong>Dilated Convolution</strong>的定义为： <span class="math display">\[(f*_lg)[n] = \sum_{m=-\infty}^{\infty}f[m]g[n-lm] = \sum_{m=-M}^Mf[n - lm]g[m]\]</span> 其中，<span class="math inline">\(l\)</span> 为 dilation factor，控制扩张大小，这样 <span class="math inline">\(l = 2\)</span> 时上面例子中的卷积就变成了： <span class="math display">\[\begin{array}{lcl}(f*_2g)[4]        &amp; = &amp; f[4]g[0] + f[2]g[1] + f[0]g[2]  \\(f*_2g)[5]  &amp; = &amp; f[5]g[0] + f[3]g[1] + f[1]g[2] \\(f*_2g)[6]  &amp; = &amp; f[6]g[0] + f[4]g[1] + f[2]g[2]  \\\end{array}\]</span> 当 <span class="math inline">\(l = 3\)</span> 时，相应卷积就为: <span class="math display">\[(f*_3g)[6] = f[6]g[0] + f[3]g[1] + f[0]g[2]\]</span> 这样虽然卷积核都为3，但 receptive field 的大小却大了很多，所以使用 dialted conv 能使 <strong>receptive field</strong> 的大小呈<strong>指数增长</strong>，而相应<strong>参数</strong>却是<strong>线性增长</strong>的，如下图所示。使用 dilated conv 就可以有效地缩短依赖传播的距离。</p><p><img src="/images/dilated.png"></p><p>参考：<a href="https://arxiv.org/abs/1511.07122" target="_blank" rel="noopener">MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS</a></p><h2><span id="residual-block">Residual Block</span></h2><p><img src="/images/residual.png"></p><p>每一层（包括 Encoder 和 Decoder）都封装了一个 residual block（上图），其中每个黄色的格子代表一个卷积层，里面的数字是相应的 filter size。中间的 Masked 1 x K 是这层的主力，其他都是为了使他发挥更大效果的陪衬。</p><h2><span id="linear-time">Linear Time</span></h2><p><img src="/images/lt.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> NMT </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> CNN </tag>
            
            <tag> ByteBet </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Attention Is All You Need</title>
      <link href="/2017/08/13/Attention%20Is%20All%20You%20Need/"/>
      <url>/2017/08/13/Attention%20Is%20All%20You%20Need/</url>
      
        <content type="html"><![CDATA[<p>Google的<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">这篇论文</a>提出了一个只使用Attention机制的神经翻译模型，该模型依旧采用编码器-解码器（Encoder-Decoder）架构，但未使用RNN和CNN。文章的主要目的是在减少计算量和提高并行效率的同时不损害最终的实验结果，创新之处在于提出了两个新的Attention机制，分别叫做 Scaled Dot-Product Attention 和 Multi-Head Attention.</p><a id="more"></a><h2><span id="整体框架">整体框架</span></h2><figure><img src="/images/at_all.png" alt="整体框架"><figcaption>整体框架</figcaption></figure><ul><li>输入：一个句子 <span class="math inline">\(z = (z_1, …, z_n)\)</span>，它是原始句子 <span class="math inline">\(x = (x_1, …, x_n)\)</span> 的 Embedding，其中 <span class="math inline">\(n\)</span> 是句子长度。</li><li>输出：翻译好的句子 <span class="math inline">\((y_1, …, y_m)\)</span></li></ul><h3><span id="encoder">Encoder</span></h3><ul><li>输入 <span class="math inline">\(z \in R^{n \times d_{model}}\)</span></li><li>输出大小不变</li><li>Positional Encoding</li><li>6个Block<ul><li>Multi-Head Self-Attention</li><li>Position-wise Feed Forward</li><li>Residual connection<ul><li>LayerNorm(x + Sublayer(x))</li><li>引入了残差，尽可能保留原始输入x的信息</li></ul></li><li><span class="math inline">\(d_{model} = 512\)</span></li></ul></li></ul><h3><span id="decoder">Decoder</span></h3><ul><li>Positional Encoding</li><li>6个Block<ul><li>Multi-Head Self Attention (with mask)<ul><li>采用 0-1mask 消除右侧单词对当前单词 attention 的影响</li></ul></li><li>Multi-Head Self Attention (with encoder)<ul><li>使用Encoder的输出作为一部分输入</li></ul></li><li>Position-wise Feed Forward</li><li>Residual connection</li></ul></li></ul><h3><span id="multi-head-self-attention">Multi-Head Self Attention</span></h3><p><img src="/images/at_attention.png"></p><p><strong>Multi-Head Attention</strong></p><p>输入 <span class="math inline">\(Q \in R^{n \times d_{model}}\)</span>、<span class="math inline">\(K \in R^{n \times d_{model}}\)</span>、<span class="math inline">\(V \in R^{n \times d_{model}}\)</span>，分别代表query、key-value pair。这里的 key, value, 和 query 需要解释一下，这里把 attention 抽象为对 value (<span class="math inline">\(V\)</span>) 的每个 token 进行加权，而加权的 weight就是 attention weight，而 attention weight 就是根据 query 和 key 计算得到，其意义为：<strong>为了用 value 求出 query 的结果, 根据 query 和 key 来决定注意力应该放在 value 的哪部分</strong>。以前的 attention 是用 LSTM 做 encoder，也就是用它来生成 key 和 value ，然后由 decoder 来生成 query。具体到 Bahdanau 的论文 Neural machine translation by jointly learning to align and translate，key 和 value 是一样的，都是文中的 <span class="math inline">\(h\)</span>，而 query 是文中的 <span class="math inline">\(s\)</span>。而在这篇论文中：</p><ul><li>在encoder块中，key, value, query 同为<code>encoder_input</code>（上一层的输出），因为是<a href="https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/self_attention_embedding.md" target="_blank" rel="noopener">self-attention</a>，可以理解为生成对这个句子的编码，可以全面获取输入序列中positions之间依赖关系。</li><li>在decoder块中，第一层Multi-Head Attention的输入都为<code>decoder_input</code>；第二层的 <span class="math inline">\(Q\)</span> 为前一层的输出，<span class="math inline">\(K, V\)</span> 为encoder的输出。可以理解为，比如刚翻译完主语，接下来想要找谓语，【找谓语】这个信息就是 query，然后 key 是源句子的编码，通过 query 和 key 计算出 attention weight （应该关注的谓语的位置），最后和 value （源句子编码）计算加权和。</li></ul><p>然后把 <span class="math inline">\(Q, K, V\)</span> 线性映射 <span class="math inline">\(h\)</span> 次，分别映射到 <span class="math inline">\(d_k, d_k, d_v\)</span> 维度，总的attention为每个映射的attention连接起来（这 <span class="math inline">\(h\)</span> 个attention可以并行计算），即：</p><p><img src="/images/at_multi.png"></p><p>其中，投影的参数矩阵 <span class="math inline">\(W^Q_i \in R^{d_{model} \times d_k}\)</span>, <span class="math inline">\(W^K_i \in R^{d_{model} \times d_k}\)</span>, <span class="math inline">\(W^V_i \in R^{d_{model} \times d_v}\)</span>. 在论文中 <span class="math inline">\(h = 8\)</span>，<span class="math inline">\(d_k = d_v = \frac{d_{model}}{h} = 64\)</span>，所以这层的输出和输入大小相同。</p><p>这些线性映射使得模型可以从不同的子空间的不同位置中学习注意力！</p><p><strong>Scaled Dot-Product Attention</strong></p><p>上式中的attention正是Scaled Dot-Product Attention，它也接收 <span class="math inline">\(Q, K, V\)</span> 三个参数，计算方法如下： <span class="math display">\[Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span> Dot-Product指的是 <span class="math inline">\(QK^T\)</span>，scaled是指除以了 <span class="math inline">\(\sqrt{d_k}\)</span> （因为假设两个 <span class="math inline">\(d_k\)</span> 维向量每个分量都是一个相互独立的服从标准正态分布的随机变量，那么他们的点乘的方差就是 <span class="math inline">\(d_k\)</span>，每一个分量除以 <span class="math inline">\(\sqrt{d_k}\)</span> 可以让点乘的方差变成 1）。</p><p>总共有两种流行的attention计算方法：</p><ul><li>additive attention<ul><li>通过一个小型神经网络计算注意力</li></ul></li><li>dot-product attention<ul><li>上面的方法</li></ul></li></ul><p>其中第二种方法比第一种方法快很多，第一种方法在 <span class="math inline">\(d_k\)</span> 较大时比第二种方法表现好，论文作者觉得可能是因为dot-product使梯度变得很大以至于失去作用，所以进行了scale。</p><p><strong>可视化 self-attention</strong></p><p><img src="/images/attn_vis.png"></p><p><img src="/images/attn_vis2.png"></p><h3><span id="position-wise-feed-forward-networks">Position-wise Feed-Forward Networks</span></h3><p><span class="math display">\[FFN(x) = \max(0, xW_1 + b_1)W_2 + b_2\]</span></p><p>这是一个 MLP （多层）网络，上层的输出中，每个 <span class="math inline">\(d_{model}\)</span> 维向量 <span class="math inline">\(x\)</span> 在此先由 <span class="math inline">\(xW_1+b_1\)</span> 变为 <span class="math inline">\(d_{ff}\)</span> 维的 <span class="math inline">\(x&#39;\)</span>，再经过 <span class="math inline">\(\max(0, x&#39;)W_2+b_2\)</span> 回归 <span class="math inline">\(d_{model}\)</span> 维。之后再是一个 residual connection。输出大小和输入大小一样，都 <span class="math inline">\(\in R^{n \times d_{model}}\)</span>.</p><h3><span id="positional-encoding">Positional Encoding</span></h3><p>因为这个网络没有 recurrence（因为decoder在训练时给ground truth做为输入，这样生成不同位置的词是可以并行的）和 convolution，为了表示词在序列中的位置信息，要用一种特殊的位置编码。</p><p>本篇论文中使用 <span class="math inline">\(\sin\)</span> 和 <span class="math inline">\(\cos\)</span> 来编码： <span class="math display">\[\begin{array}{lcl}PE_{(pos, 2i)}        &amp; = &amp; \sin(\frac{pos}{10000^{2i/d_{model}}})\\PE_{(pos, 2i+1)}        &amp; = &amp; \cos(\frac{pos}{10000^{2i/d_{model}}})\end{array}\]</span> 其中，<span class="math inline">\(pos\)</span> 代表位置，<span class="math inline">\(i\)</span> 代表维度（<span class="math inline">\([0, d_{model}-1]\)</span>）。</p><p>这样做的目的是因为正弦和余弦函数具有周期性，对于固定长度偏差 <span class="math inline">\(k\)</span>（类似于周期），<span class="math inline">\(pos+k\)</span> 位置的 PE 可以表示成关于 <span class="math inline">\(pos\)</span> 位置 PE 的一个线性变换（<span class="math inline">\(\sin(pos + k) =\sin(pos)\cos(k)+\sin(k)\cos(pos)\)</span>），这样可以方便模型学习词与词之间的一个相对位置关系。</p><p>另一种解释，来自 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650728452&amp;idx=4&amp;sn=fcc845a7ff15e6ceb331161d71899402&amp;chksm=871b2c7ab06ca56c9d746a2c2977578ec391ed526ec05d7b1da1910d1987597b5801ac6f98d1&amp;mpshare=1&amp;scene=23&amp;srcid=0701ZtSHzIyPmVKwYJdpsdvM%23rd" target="_blank" rel="noopener">WarBean</a> ：</p><blockquote><p>每两个维度构成一个二维的单位向量，总共有 <span class="math inline">\(d_{model} / 2\)</span> 组。每一组单位向量会随着 <span class="math inline">\(pos\)</span> 的增大而旋转，但是旋转周期不同，按照论文里面的设置，最小的旋转周期是 <span class="math inline">\(2\pi\)</span>，最大的旋转周期是 <span class="math inline">\(10000 \times 2\pi\)</span>。至于为什么说相邻 <span class="math inline">\(k\)</span> 步的 position embedding 可以用一个线性变换对应上，是因为上述每组单位向量的旋转操作可以用表示为乘以一个 2 x 2 的旋转矩阵。</p></blockquote><h3><span id="特点">特点</span></h3><ol type="1"><li><p>训练阶段完全可并行（因为decoder在训练时给ground truth做为输入，这样生成不同位置的词是可以并行的，而encoder一次处理一整个句子）</p></li><li><p>解决 long dependency 的问题</p><blockquote><p>传统的用RNN建模语言的时序特征，前面的单词信息都依次feed到后面一个单词，这种信息的堆叠感觉有点浪费，而且反而把信息糅杂在一起不好区分，虽然decoder阶段对每个单词对应的encoder输出位置做attention，但每个encoder输出已经夹杂了前面单词的信息。同时前面单词信息往后传，走的路径比较长，也就是long dependency的问题，虽然LSTM/GRU这种结构能一定程度上解决，但是毕竟不能完全去掉 long dependency。而conv在处理dependency问题时，利用卷积的感受野receptive field，通过堆叠卷积层来扩大每个encoder输出位置所覆盖单词的范围，每个单词走的路径大致是logk(n)步，缩短了dependency的长度。而这篇论文的做法是直接用encoder或者decoder的层与层之间直接用attention，句子中的单词dependency长度最多只有1，减少了信息传输路径。而且这种attention的方式直接可以挖掘句子内部单词与单词的语义组合关系，将它作为一个语义整体，使得翻译时更好地利用单词组合甚至是短语的信息，更好地decode出语义匹配的目标语言单词（转自<a href="https://www.zhihu.com/question/61077555/answer/183884003" target="_blank" rel="noopener">谭旭</a>）</p></blockquote></li></ol><p><img src="/images/path_table.png"></p><h3><span id="开源代码分析">开源代码分析</span></h3><p>代码来自：https://github.com/jadore801120/attention-is-all-you-need-pytorch</p><p>使用 PyTorch 框架</p><p><strong>Encoder</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' A encoder model with self attention mechanism. '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_src_vocab, n_max_seq, n_layers=<span class="number">6</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 n_head=<span class="number">8</span>, d_k=<span class="number">64</span>, d_v=<span class="number">64</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">         d_word_vec=<span class="number">512</span>, d_model=<span class="number">512</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">                 d_inner_hid=<span class="number">1024</span>, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># .....</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src_seq, src_pos)</span>:</span></span><br><span class="line">        <span class="comment"># Word embedding look up</span></span><br><span class="line">        enc_input = self.src_word_emb(src_seq)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Position Encoding addition</span></span><br><span class="line">        enc_input += self.position_enc(src_pos)</span><br><span class="line">        enc_outputs, enc_slf_attns = [], []</span><br><span class="line"></span><br><span class="line">        enc_output = enc_input</span><br><span class="line">        enc_slf_attn_mask = </span><br><span class="line">        get_attn_padding_mask(src_seq, src_seq)</span><br><span class="line">        <span class="comment"># 对每一层计算 encoder output 和 self-attention</span></span><br><span class="line">        <span class="keyword">for</span> enc_layer <span class="keyword">in</span> self.layer_stack:</span><br><span class="line">            enc_output, enc_slf_attn = enc_layer(</span><br><span class="line">                enc_output, slf_attn_mask=enc_slf_attn_mask)</span><br><span class="line">            <span class="comment"># 把每层的输出添加到总输出列表</span></span><br><span class="line">            enc_outputs += [enc_output]</span><br><span class="line">            enc_slf_attns += [enc_slf_attn]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> enc_outputs, enc_slf_attns</span><br></pre></td></tr></table></figure><p><strong>Positional Encoding</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">position_encoding_init</span><span class="params">(n_position, d_pos_vec)</span>:</span></span><br><span class="line">    <span class="string">''' Init the sinusoid position encoding table '''</span></span><br><span class="line"><span class="comment"># 对每个位置进行编码，位置0为全0，其他位置按照相应公式计算</span></span><br><span class="line">    position_enc = np.array([</span><br><span class="line">        [pos / np.power(<span class="number">10000</span>, <span class="number">2</span>*i/d_pos_vec) </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(d_pos_vec)]</span><br><span class="line">        <span class="keyword">if</span> pos != <span class="number">0</span> <span class="keyword">else</span> np.zeros(d_pos_vec) </span><br><span class="line">        <span class="keyword">for</span> pos <span class="keyword">in</span> range(n_position)])</span><br><span class="line"><span class="comment"># dim 2i</span></span><br><span class="line">    position_enc[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(position_enc[<span class="number">1</span>:, <span class="number">0</span>::<span class="number">2</span>]) </span><br><span class="line">    <span class="comment"># dim 2i+1</span></span><br><span class="line">    position_enc[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(position_enc[<span class="number">1</span>:, <span class="number">1</span>::<span class="number">2</span>]) </span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(position_enc)</span><br></pre></td></tr></table></figure><p><strong>Scaled Dot-Product Attention</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScaledDotProductAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' Scaled Dot-Product Attention '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, attn_dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(ScaledDotProductAttention, self).__init__()</span><br><span class="line">        self.temper = np.power(d_model, <span class="number">0.5</span>)</span><br><span class="line">        self.dropout = nn.Dropout(attn_dropout)</span><br><span class="line">        self.softmax = BottleSoftmax()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, q, k, v, attn_mask=None)</span>:</span></span><br><span class="line">        attn = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>)) / self.temper</span><br><span class="line">        ...</span><br><span class="line">        attn = self.softmax(attn)</span><br><span class="line">        attn = self.dropout(attn)</span><br><span class="line">        output = torch.bmm(attn, v)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attn</span><br></pre></td></tr></table></figure><p>从中可见，self-attention 指 softmax 操作之后的部分，层输出是 <span class="math inline">\(attention \times V\)</span>。</p><p><strong>Encoder layer</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' Compose with two layers '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_inner_hid, n_head, d_k, d_v,</span></span></span><br><span class="line"><span class="function"><span class="params">                 dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(EncoderLayer, self).__init__()</span><br><span class="line">        self.slf_attn = MultiHeadAttention(</span><br><span class="line">            n_head, d_model, d_k, d_v, dropout=dropout)</span><br><span class="line">        self.pos_ffn = PositionwiseFeedForward(d_model, </span><br><span class="line">                                              d_inner_hid, </span><br><span class="line">                                              dropout=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, enc_input, slf_attn_mask=None)</span>:</span></span><br><span class="line">        <span class="comment"># Q, K, V 都是 enc_input</span></span><br><span class="line">        enc_output, enc_slf_attn = self.slf_attn(</span><br><span class="line">            enc_input, enc_input, enc_input,</span><br><span class="line">            attn_mask=slf_attn_mask)</span><br><span class="line">        enc_output = self.pos_ffn(enc_output)</span><br><span class="line">        <span class="keyword">return</span> enc_output, enc_slf_attn</span><br></pre></td></tr></table></figure><p>可见，传给 <code>MultiHeadAttention</code> 的<span class="math inline">\(Q, K, V\)</span> 都是 <code>enc_input</code>。</p><p><strong>Decoder Layer</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' Compose with three layers '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># ....</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, dec_input, enc_output, </span></span></span><br><span class="line"><span class="function"><span class="params">                slf_attn_mask=None, dec_enc_attn_mask=None)</span>:</span></span><br><span class="line">        <span class="comment"># 第一个attention层接收的 Q, K, V 都是 dec_input</span></span><br><span class="line">        dec_output, dec_slf_attn = self.slf_attn(</span><br><span class="line">            dec_input, dec_input, dec_input, </span><br><span class="line">            attn_mask=slf_attn_mask)</span><br><span class="line">        <span class="comment"># 第二个attention层接收的 Q 是 dec_output，</span></span><br><span class="line">        <span class="comment"># K 和 V 是 enc_output</span></span><br><span class="line">        dec_output, dec_enc_attn = self.enc_attn(</span><br><span class="line">            dec_output, enc_output, enc_output, </span><br><span class="line">            attn_mask=dec_enc_attn_mask)</span><br><span class="line">        dec_output = self.pos_ffn(dec_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dec_output, dec_slf_attn, dec_enc_attn</span><br></pre></td></tr></table></figure><p><strong>Transformer</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Transformer</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">''' 完整的 transformer '''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            self, n_src_vocab, n_tgt_vocab, n_max_seq,</span></span></span><br><span class="line"><span class="function"><span class="params">        n_layers=<span class="number">6</span>, n_head=<span class="number">8</span>, d_word_vec=<span class="number">512</span>, d_model=<span class="number">512</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        d_inner_hid=<span class="number">1024</span>, d_k=<span class="number">64</span>, d_v=<span class="number">64</span>, dropout=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        proj_share_weight=True, embs_share_weight=True)</span>:</span></span><br><span class="line"></span><br><span class="line">        super(Transformer, self).__init__()</span><br><span class="line">        <span class="comment"># 初始化 encoder</span></span><br><span class="line">        self.encoder = Encoder(</span><br><span class="line">            n_src_vocab, n_max_seq, n_layers=n_layers,</span><br><span class="line">            n_head=n_head, d_word_vec=d_word_vec, </span><br><span class="line">            d_model=d_model, d_inner_hid=d_inner_hid,</span><br><span class="line">            dropout=dropout)</span><br><span class="line">        <span class="comment"># 初始化 decoder</span></span><br><span class="line">        self.decoder = Decoder(</span><br><span class="line">            n_tgt_vocab, n_max_seq, n_layers=n_layers,</span><br><span class="line">            n_head=n_head, d_word_vec=d_word_vec, </span><br><span class="line">            d_model=d_model, d_inner_hid=d_inner_hid,</span><br><span class="line">            dropout=dropout)</span><br><span class="line">      <span class="comment"># ....</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src, tgt)</span>:</span></span><br><span class="line">        src_seq, src_pos = src</span><br><span class="line">        tgt_seq, tgt_pos = tgt</span><br><span class="line"></span><br><span class="line">        tgt_seq = tgt_seq[:, :<span class="number">-1</span>]</span><br><span class="line">        tgt_pos = tgt_pos[:, :<span class="number">-1</span>]</span><br><span class="line"><span class="comment"># 编码</span></span><br><span class="line">        enc_outputs, enc_slf_attns = self.encoder(src_seq,</span><br><span class="line">                                                  src_pos)</span><br><span class="line">        <span class="comment"># 解码</span></span><br><span class="line">        dec_outputs, dec_slf_attns, dec_enc_attns =</span><br><span class="line">        self.decoder( tgt_seq, tgt_pos, src_seq,</span><br><span class="line">                         enc_outputs)</span><br><span class="line">        dec_output = dec_outputs[<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">        seq_logit = self.tgt_word_proj(dec_output)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> seq_logit.view(<span class="number">-1</span>, seq_logit.size(<span class="number">2</span>))</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> NMT </tag>
            
            <tag> Attention </tag>
            
            <tag> Deep NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Question Answering</title>
      <link href="/2017/08/12/Deep%20NLP%20-%20Question%20Answering/"/>
      <url>/2017/08/12/Deep%20NLP%20-%20Question%20Answering/</url>
      
        <content type="html"><![CDATA[<p>Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.</p><a id="more"></a><!-- toc --><ul><li><a href="#semantic-parsing">Semantic Parsing</a></li><li><a href="#reading-comprehension">Reading Comprehension</a></li><li><a href="#answer-sentence-selection">Answer Sentence Selection</a></li><li><a href="#visual-question-answering">Visual Question Answering</a></li><li><a href="#summary">Summary</a></li></ul><!-- tocstop --><p><strong>Questions</strong></p><table><colgroup><col style="width: 46%"><col style="width: 53%"></colgroup><thead><tr class="header"><th style="text-align: left;">Question</th><th style="text-align: left;">answer</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">When were the ﬁrst pyramids built?</td><td style="text-align: left;">2630 BC</td></tr><tr class="even"><td style="text-align: left;">Jean-Claude Juncker</td><td style="text-align: left;">Jean-Claude Juncker is a Luxembourgish politician. Since 2014, Juncker has been President of the European Commission.</td></tr><tr class="odd"><td style="text-align: left;">How old is Keir Starmer?</td><td style="text-align: left;">54 years</td></tr><tr class="even"><td style="text-align: left;">What is the current price for AAPL?</td><td style="text-align: left;">136.50 USD</td></tr><tr class="odd"><td style="text-align: left;">What’s the weather like in London?</td><td style="text-align: left;">7 degrees Celsius. Clear with some clouds.</td></tr><tr class="even"><td style="text-align: left;">Whom did Juncker meet with?</td><td style="text-align: left;">The European Commission president was speaking after meeting with Irish Taoiseach Enda Kenny in Brussels.</td></tr><tr class="odd"><td style="text-align: left;">When did you get to this lecture?</td><td style="text-align: left;">Five minutes after it started.</td></tr><tr class="even"><td style="text-align: left;">Why do we yawn?</td><td style="text-align: left;">When we’re bored or tired we don’t breathe as deeply as we normally do. This causes a drop in our blood-oxygen levels and yawning helps us counter-balance that.</td></tr></tbody></table><p><strong>Why do we care about QA ?</strong></p><p>Because <strong>QA is awesome</strong></p><ol type="1"><li><p><strong>QA is an AI-complete problem.</strong></p><p>If we solve QA, we have solved every other problem, too.</p></li><li><p>Many immediate and obvious applications</p><p>Search, dialogue, information extraction, summarisation, ...</p></li><li><p>Some pretty nice results already</p><p>IBM Watson and Jeopardy!, Siri, Google Search ...</p></li><li><p>Lots left to do!</p><p>Plenty of interesting research and hard problems as well as low-hanging fruit.</p></li></ol><p><strong>Data</strong></p><table><colgroup><col style="width: 25%"><col style="width: 37%"><col style="width: 37%"></colgroup><thead><tr class="header"><th>question</th><th>context/source</th><th>answer</th></tr></thead><tbody><tr class="odd"><td>Factual questions</td><td>Sets of documents (corpus)</td><td>A single fact</td></tr><tr class="even"><td>Complex/narrative questions</td><td>A single document</td><td>An explanation</td></tr><tr class="odd"><td>Information Retrieval</td><td>Knowledge Base</td><td>A document</td></tr><tr class="even"><td>Library Reference</td><td>Non-linguistic types of data (GPS, images, sensors, ...)</td><td>A sentence or paragraph extracted from somewhere</td></tr><tr class="odd"><td></td><td></td><td>An image or other type of object</td></tr><tr class="even"><td></td><td></td><td>Another question</td></tr></tbody></table><p><strong>Question Taxonomy</strong></p><p>Many possible taxonomies for questions:</p><ul><li>Wh- words</li><li>Subject of question</li><li>The form of expected answers</li><li>Types of sources from which answers may be drawn</li></ul><p>For the purposes of building QA systems it is useful to start by considering the sources an answer may be drawn from. <strong>Focus on the answer</strong> rather than the question.</p><p><em>Three Questions for building a QA System</em></p><ul><li>What do the answers look like?</li><li>Where can I get the answers from?</li><li>What does my training data look like?</li></ul><p><strong>Areas in Question Answering</strong></p><ul><li>Reading Comprehension<ul><li>Answer based on a document</li><li>Context is a speciﬁc document</li></ul></li><li>Semantic Parsing<ul><li>Answer is a logical form, possible executed against a KB</li><li>Context is a Knowledge Base</li></ul></li><li>Visual QA<ul><li>Answer is simple and factual</li><li>Context is one/multiple image(s)</li></ul></li><li>Information Retrieval<ul><li>Answer is a document/paragraph/sentence</li><li>Context is a corpus of documents</li></ul></li><li>Library Reference<ul><li>Answer is another question</li><li>Context is the structured knowledge available in the library and the librarians view of it.</li></ul></li></ul><h2><span id="semantic-parsing">Semantic Parsing</span></h2><p>Semantic Parsing is the process of mapping natural language into a formal representation of its meaning. Depending on the chosen formalism this <strong>logical representation</strong> can be used to query a <strong>structured knowledge base</strong>.</p><p><img src="/images/NLP/se_par.png"></p><p><em>Semantic Parsing</em> is <strong>Question→Logical Form.</strong></p><p>We (often mistakenly) then assume that <strong>LF→Answer</strong> is trivial.</p><p><strong>Knowledge Bases for QA with Semantic Parsing</strong></p><p>Knowledge bases typically represent their data as triples：</p><ul><li>Generally: <em>(relation, entity1, entity2)</em></li><li>(married-to, Michelle Obama, Barack Obama)</li><li>(member-of, United Kingdom, European Union)</li></ul><p>There are several (large) databases freely available to use, e.g.:</p><ul><li><strong>Freebase</strong>: 1.9 billion triples on general knowledge. Defunct as of 2016 and replaced by Google Knowledge Graph</li><li><strong>WikiData</strong>: Information on 25 million entities</li><li><strong>OpenStreetMap</strong>: 3 billion triples on geography</li><li><strong>GeoQuery</strong>: 700 facts about US geography. Tiny dataset, but frequently used in semantic parsing work.</li></ul><p><strong>Supervised Data is expensive!</strong></p><ul><li><strong>Free917</strong>: 917 freebase annotated questions</li><li><strong>GeoQuery</strong>: 880 questions on US geography</li><li><strong>NLMaps</strong>: 2,380 natural language queries on the OSM data</li></ul><p>These kinds of datasets are incredibly expensive to create as they require experts for the manual annotation process, who are trained in using a given database schema:</p><ul><li><p>“<em>Where are kindergartens in Hamburg?</em>”</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query(area(keyval(name,Hamburg)), nwr(keyval(amenity,kindergarten)), qtype(latlong))</span><br></pre></td></tr></table></figure></li></ul><p><strong>A Deep Learning Approach to Semantic Parsing</strong></p><p>Semantic parsing can be viewed as a sequence to sequence model, not unlike <strong>machine translation</strong>.</p><p><img src="/images/NLP/dl_sen.png"></p><p>Details</p><ul><li>✅ Encode sentence with sequence models</li><li>✅ Decode with standard mechanisms from MT</li><li>❌ Supervised training data hard to come by</li><li>❌ Depending on formalism used, highly complex target side</li><li>❌ How to deal with proper nouns and numbers?</li></ul><p><strong>One Solution to Sparsity: Avoid Logical Forms</strong></p><p>Semantic parsing frequently reduce the reliance on supervised data (language-logical form) by exploiting other types of data such as <strong>question-answer pairs</strong> or corpora of <strong>questions only</strong>.</p><blockquote><p>Berant et al. (2013): Semantic Parsing on Freebase from QA Pairs Reddy et al. (2014): Large-scale Semantic Parsing without QA Pairs</p></blockquote><p><img src="/images/NLP/graph.png"></p><p><strong>Improved Neural Semantic Parsing</strong></p><p>We can apply the same idea to neural semantic parsing, and further take mechanisms from <strong>machine translation</strong> to improve performance and data eﬃciency:</p><ul><li>Like in MT, using attention can be helpful<ul><li>Dong and Lapata (2016): Language to Logical Form with Neural Attention</li></ul></li><li>Exploit the highly rigid structure in the target side to constrain generation<ul><li>Liang et al. (2016): Neural Symbolic Machines</li><li>Ling et al. (2016): Latent predictor networks for code generation</li></ul></li><li>Make use of semi-supervised training to counter sparsity<ul><li>Kocisky et al. (2016): Semantic Parsing with Semi-Supervised Sequential Autoencoders</li></ul></li></ul><p><em>Generation with multiple sources</em></p><blockquote><p>Ling et al. (2016): Latent predictor networks for code generation</p></blockquote><p><img src="/images/NLP/multi_src.png"></p><p><strong>Semantic Parsing Summary</strong></p><ul><li>✅ LF instead of answer makes system robust</li><li>✅ Answer independent of question and parsing mechanism</li><li>✅ Can deal with rapidly changing information</li><li>❌ Constrained to queriable questions in DB schema</li><li>❌ No database is large enough</li><li>❌ Training data hard to ﬁnd</li></ul><p><em>Questions</em></p><ul><li>✅ When were the pyramids built?</li><li>❓ Jean-Claude Juncker</li><li>✅ How old is Keir Starmer?</li><li>✅ What is the price for AAPL?</li><li>✅ What’s the weather in London?</li><li>❌ Whom did Juncker meet with?</li><li>❌ When did you get here?</li><li>❌ Why do we yawn?</li></ul><p>Caveat: Each of these examples requires a <strong>diﬀerent</strong> underlying KB!</p><h2><span id="reading-comprehension">Reading Comprehension</span></h2><p>Answer a question related to a given document.</p><p><strong>Corpora for Reading Comprehension</strong></p><ul><li><strong>CNN/DailyMail</strong>: Over 1 million cloze form QA pairs with articles from CNN and Mail online for context. Pick an anonymised entity.</li><li><strong>CBT</strong>: 700k QA pairs, children’s books as context. Pick one of 10 candidates.</li><li><strong>SQuAD</strong>: 100k manual QA pairs with 500 Wikipedia articles for context. Answer is a span.</li></ul><p>Assumptions made in all of the above tasks</p><ul><li>Context is read on the ﬂy and unknown during training phase</li><li>Answer is contained in the context as a single word or span</li><li>This constraint does not hold for reading comprehension in general!</li></ul><p><em>CNN article Example</em></p><ul><li>Document<ul><li>The BBC producer allegedly struck by Jeremy Clarkson will not press charges against the “Top Gear” host, his lawyer said Friday. Clarkson, who hosted one of the most-watched television shows in the world, was dropped by the BBC Wednesday after an internal investigation by the British broadcaster found he had subjected producer Oisin Tymon “to an unprovoked physical and verbal attack.” . . .</li></ul></li><li>Query<ul><li>Producer X will not press charges against Jeremy Clarkson, his lawyer says.</li></ul></li><li>Answer<ul><li>Oisin Tymon</li></ul></li></ul><p>We formulate <em>Cloze style</em> queries from the story paraphrases.</p><p>Out of vocabulary (OOV) and proper nouns are dealt with by <strong>replacing all entities with anonymised markers</strong>. This greatly reduces the vocabulary size.</p><ul><li><p>Document</p><ul><li><p>the ent381 producer allegedly struck by ent212 will not press</p><p>charges against the “ ent153 ” host , his lawyer said friday . ent212 , who hosted one of the most - watched television shows in the world , was dropped by the ent381 wednesday after an internal investigation by the ent180 broadcaster found he had subjected producer ent193 “ to an unprovoked physical and verbal attack . ” . . .</p></li></ul></li><li><p>Query</p><ul><li>Producer X will not press charges against ent212 , his lawyer says .</li></ul></li><li><p>Answer</p><ul><li>ent193</li></ul></li></ul><p><strong>A Generic Neural Model for Reading Comprehension</strong></p><p>Given context <span class="math inline">\(d\)</span> and question <span class="math inline">\(q\)</span>, the probability of an answer <span class="math inline">\(a\)</span> can be represented as: <span class="math display">\[p(a|q, d) \varpropto \exp(W(a)g(q, d)), \ \ s.t.a \in V\]</span> Details</p><ul><li>✅ Encode question and context with sequence models</li><li>✅ Combine <span class="math inline">\(q\)</span> and <span class="math inline">\(d\)</span> with an MLP or attention <span class="math inline">\(g\)</span></li><li>✅ Select answer from attention map, by using a classiﬁer, or with generative setup</li><li>❌ How to deal with out of vocabulary (OOV) terms?</li><li>❌ How to deal with proper nouns and numbers?</li></ul><p><img src="/images/NLP/rc_attn.png"></p><ul><li>Read (encode) context document and question</li><li>Use question to attend to context</li><li>Use joint representation to generate answer<ul><li>Predict based on attention map</li><li>Generate conditioned on joint representation</li><li>Classify over set of candidate answers</li></ul></li></ul><p>Denote the outputs of a bidirectional LSTM as <span class="math inline">\(\overrightarrow{y(t)}\)</span> and <span class="math inline">\(\overleftarrow{y(t)}\)</span>. Form two encodings, one for the query and one for each token in the document, <span class="math display">\[u = \overrightarrow{y_q}(|q|)\ ||\ \overleftarrow{y_q}(1),\ \ y_d(t) = \overrightarrow{y_d}(t)\ ||\ \overleftarrow{y_d}(t)\]</span> The representation <span class="math inline">\(r\)</span> of the document <span class="math inline">\(d\)</span> is formed by a weighted sum of the token vectors. The weights are interpreted as the model’s attention, <span class="math display">\[\begin{alignat}{3}m(t) &amp;= \tanh(W_{ym}y_d(t)+W_{um}u) \\s(t) &amp;\varpropto \exp(w_{ms}^Tm(t)) \\r &amp;= y_ds \\\end{alignat}\]</span> Deﬁne the joint document and query embedding via a non-linear combination: <span class="math display">\[g^{AR}(d, q) = \tanh(W_{rg}r+W_{ug}u)\]</span> Training</p><p><img src="/images/NLP/traing.png"></p><p>Models were trained using asynchronous minibatch stochastic gradient descent (RMSProp) on approximately 25 GPUs.</p><p><em>Attention Sum Reader</em></p><blockquote><p>Kadlec et al. (2016), Text Understanding with the Attention Sum Reader Network</p></blockquote><p>The model can be modiﬁed to make use of the fact that <strong>the answer is a word from the context document</strong>. Now we calculate the probability of the answer being in position <span class="math inline">\(i\)</span> of the context: <span class="math display">\[p(i|q, d)  \varpropto \exp(f_i(d)\cdot g(q))\]</span> Positional probabilities can then be summed to form token-based probabilities: <span class="math display">\[P(w|q, d) \varpropto \sum_{i(w,d)}P(i|q,d)\]</span> The rest of the model is equivalent to the attentive reader model presented before.</p><p><strong>Reading Comprehension Summary</strong></p><ul><li>✅ Ask questions in context</li><li>✅ Easily used in discriminative and generative fashion</li><li>✅ Large datasets available</li><li>❌ Constraint on context often artiﬁcial</li><li>❌ Many types of questions unanswerable</li></ul><p><em>Questions</em></p><ul><li>❓ When were the pyramids built?</li><li>❓ Jean-Claude Juncker</li><li>❓ How old is Keir Starmer?</li><li>❓ What is the price for AAPL?</li><li>❓ What’s the weather in London?</li><li>✅ Whom did Juncker meet with?</li><li>❌ When did you get here?</li><li>❌ Why do we yawn?</li></ul><p>Caveat: Need context for any of these, and incredibly up-to-date context for some of these.</p><h2><span id="answer-sentence-selection">Answer Sentence Selection</span></h2><p><img src="/images/NLP/trump.jpg"></p><p><strong>Answer Sentence Selection</strong> describes the task of picking a suitable sentence from a corpus that can be used to answer a question.</p><ul><li><strong>Questions</strong>: Factual questions, possibly with context</li><li><strong>Data Source</strong>: “The Web” or the output of some IR system</li><li><strong>Answer</strong>: One or several excerpts pertinent to the answer</li></ul><p>The answer is <strong>guaranteed to be extracted</strong>, while in reading comprehension it could be either generated or extracted.</p><p><strong>Data Corpora</strong></p><ul><li><strong>TREC QA track (8-13)</strong>: Several hundred manually-annotated question answer pairs with around 20 candidates per instance.</li><li><strong>MS MARCO</strong>: 100k question-answer pairs with 10 contextual passages each. Can also be used as a QA dataset for reading comprehension.</li></ul><p>Likewise, answer sentence selection plays a role in any information retrieval setup, and datasets from IR and other QA tasks can easily be converted into answer selection style datasets.</p><p><em>A Neural Model for Answer Sentence Selection</em></p><blockquote><p>Yu et al., 2014</p></blockquote><p>We need to compute the probability of an answer candidate <span class="math inline">\(a\)</span> and a question <span class="math inline">\(q\)</span> matching. Note that this is diﬀerent from the previous task as we now calculate that score independently of all other candidates: <span class="math display">\[p(y=1|q, a) = \sigma(q^TMa + b)\]</span> <img src="/images/NLP/ass.png"></p><p><strong>Evaluation</strong></p><p>Unlike single entity style QA where we can use a simple accuracy measure, tasks such as answer sentence selection require more specialised metrics for evaluating model performance.</p><table><colgroup><col style="width: 20%"><col style="width: 40%"><col style="width: 40%"></colgroup><thead><tr class="header"><th>measure</th><th>description</th><th>formula</th></tr></thead><tbody><tr class="odd"><td>Accuracy</td><td>Binary measure</td><td>#true/#toal</td></tr><tr class="even"><td>Mean Reciprocal Rank</td><td>Measures position of ﬁrst relevant document in return set.</td><td><span class="math inline">\(\frac{1}{\|Q\|}\sum_{i=1}^{\|Q\|}\frac{1}{rank_i}\)</span></td></tr><tr class="odd"><td>BLEU Score</td><td>Machine Translation measure for translation accuracy</td><td>complicated</td></tr></tbody></table><p><strong>Answer Selection Summary</strong></p><ul><li>✅ Designed to deal with large amounts of context</li><li>✅ More robust than ‘true’ QA systems as it turns provides context with its answers</li><li>✅ Obvious pipeline step between IR and QA</li><li>❌ Does not provide answers, provides context only</li><li>❌ Real-world use depends on underlying IR pipeline</li></ul><p><em>Questions</em></p><ul><li>✅ When were the pyramids built?</li><li>✅ Jean-Claude Juncker</li><li>✅ How old is Keir Starmer?</li><li>❌ What is the price for AAPL?</li><li>❌ What’s the weather in London?</li><li>❓ Whom did Juncker meet with?</li><li>❌ When did you get here?</li><li>✅ Why do we yawn?</li></ul><p>Note: Things like age or stock price may produce answers, but with no guarantee of accuracy (any mention of any AAPL price might be a good ﬁt).</p><h2><span id="visual-question-answering">Visual Question Answering</span></h2><p>Sometimes questions require context outside of pure language.</p><p><img src="/images/NLP/visual.jpg"></p><p><strong>Task and Corpora</strong></p><p>In recent years a number of visual QA datasets have sprung up. Some of the more popular ones include:</p><ul><li><strong>VisualQA</strong>: Agrawal et al. (2015)</li><li><strong>VQA 2.0</strong> Goyal et al. (2016)</li><li><strong>COCO-QA</strong> Ren et al. (2015)</li></ul><p>Details between these datasets vary, but the basic organisation remains the same of images paired with simple questions and answers (either free form or from a list of options).</p><p>All of these are reasonably large (100ks of images, over 1M questions).</p><p><strong>Visual QA</strong></p><ul><li>Question is language → some encoder</li><li>Context is a single picture → convolutional network</li><li>Answer is a single word → classiﬁer function</li></ul><p>We have covered all the components already:</p><p><img src="/images/NLP/visualQA.jpg"></p><p><strong>Blind Model</strong></p><blockquote><p>Goyal et al. (2016)</p></blockquote><p><em>Ignoring the images is a good baseline!</em></p><ul><li>What colour is the cat?</li><li>How many chairs are around the table?</li><li>What furniture is in the bedroom?</li><li>Where is the person sleeping?</li></ul><p>We can get reasonably good guesses in at many of these questions without seeing an image for context.</p><p><strong>Attention Methods for Visual QA</strong></p><blockquote><p>Yang et al. (2015): Stacked Attention Networks for Image Question Answering</p></blockquote><p>Viewing VQA from the perspective of our default QA paradigm, there is signiﬁcant overlap with reading comprehension style models. We use similar techniques to improve performance.</p><p>We can use attention on visual representations:</p><p><img src="/images/NLP/attn_vqa.png"></p><p><img src="/images/NLP/vqa_eg.jpg"></p><p><strong>VIisual Question Answering Summary</strong></p><ul><li>✅ Extra modality ‘for free’</li><li>✅ Plenty of training data available as of recently</li><li>❌ Currently quite gimmicky</li><li>❌ Still a long way to go</li></ul><p><em>Questions</em></p><ul><li>❌ When were the pyramids built?</li><li>❌ Jean-Claude Juncker</li><li>❌ How old is Keir Starmer?</li><li>❌ What is the price for AAPL?</li><li>❓ What’s the weather in London?</li><li>❌ Whom did Juncker meet with?</li><li>❌ When did you get here?</li><li>❌ Why do we yawn?</li></ul><h2><span id="summary">Summary</span></h2><p><strong>How to build your own QA system ?</strong></p><p>Build a QA model in seven questions</p><ul><li>What is the task?</li><li>What do question, answer and context look like?</li><li>Where does the data come from?</li><li>Can you augment the data?</li><li>How to encode question and context?</li><li>How to combine question and context?</li><li>How to predict or generate an answer?</li></ul><p>There are plenty of open questions left in QA. Just remember to <strong>start with the data</strong>!</p><p><em>Sources and Further Reading</em></p><ul><li><strong>Question Answering Theory and Datasets</strong><ul><li>Pomerantz (2005), A Linguistic Analysis of Question Taxonomies</li><li>Nguyen et al. (2016), MS MARCO: A Human Generated Machine Reading Comprehension Dataset</li><li>Haas and Riezler (2016), A Corpus and Semantic Parser for Multilingual Natural Language Querying of OpenStreetMap</li></ul></li><li><strong>Semantic Parsing</strong><ul><li>Artzi et al. (2013), Semantic Parsing with CCG</li><li>Berant et al. (2013), Semantic Parsing on Freebase from Question-Answer Pairs</li><li>http://nlp.stanford.edu/software/sempre/</li></ul></li><li><strong>Reading Comprehension</strong><ul><li>Hermann et al. (2015), Teaching Machines to Read and Comprehend</li><li>Kadlec et al. (2016), Text Understanding with the Attention Sum Reader Network</li></ul></li><li><strong>Visual QA</strong><ul><li>Yang et al. (2015), Stacked Attention Networks for Image Question Answering</li><li>Ren et al. (2015), Exploring Models and Data for Image Question Answering</li><li>Goyal et al. (2016), Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering.</li><li>https://avisingh599.github.io/deeplearning/visual-qa/</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> Attention </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> QA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Speech Recognition</title>
      <link href="/2017/08/10/Deep%20NLP%20-%20Speech%20Recognition/"/>
      <url>/2017/08/10/Deep%20NLP%20-%20Speech%20Recognition/</url>
      
        <content type="html"><![CDATA[<p>Speech recognition (SR) is the inter-disciplinary sub-field of computational linguistics that develops methodologies and technologies that enables the recognition and translation of spoken language into text by computers. <a id="more"></a></p><!-- toc --><ul><li><a href="#speech-recognition">Speech recognition</a><ul><li><a href="#acoustic-representation">Acoustic representation</a></li><li><a href="#phonetic-representation">Phonetic representation</a></li><li><a href="#history">History</a></li><li><a href="#probabilistic-speech-recognition">Probabilistic speech recognition</a></li></ul></li><li><a href="#neural-network-speech-recognition">Neural network speech recognition</a><ul><li><a href="#hybrid-neural-networks">Hybrid neural networks</a></li><li><a href="#traning-losses">Traning losses</a></li><li><a href="#sequence-discriminative-training">Sequence discriminative training</a></li><li><a href="#new-architectures">New architectures</a></li></ul></li></ul><!-- tocstop --><h2><span id="speech-recognition">Speech recognition</span></h2><p>Speech problems</p><ul><li><strong>Automatic speech recognition</strong><ul><li>Spontaneous vs read speech</li><li>Large vocabulary</li><li>In noise</li><li>Low resource</li><li>Far-field</li><li>Accent-independent</li><li>Speaker-adaptive</li></ul></li><li>Text to speech<ul><li>Low resource</li><li>Realistic prosody</li></ul></li><li>Speaker identification</li><li>Speech enhancement</li><li>Speech separation</li></ul><h3><span id="acoustic-representation">Acoustic representation</span></h3><p><strong>Speech physical realization</strong></p><ul><li>Waves of changing air pressure.</li><li>Realised through excitation from the vocal cords</li><li>Modulated by the vocal tract.</li><li>Modulated by the articulators (tongue, teeth, lips)</li><li>Converted to Voltage with a microphone</li><li>Sampled with an <em>Analogue to Digital Converter</em></li><li>Human hearing is 50Hz-20kHz</li><li>Human speech is 85Hz–8kHz</li><li>Contemporary speech processing mostly around 16kHz 16bits/sample</li></ul><p>We want a <strong>low-dimensionality</strong> representation, invariant to speaker, background noise, rate of speaking etc.</p><ul><li>Fourier analysis shows energy in diﬀerent frequency bands</li><li>windowed short-term fast Fourier transform (FFT)</li><li>e.g. FFT on overlapping 25ms windows (400 samples) taken every 10ms<ul><li>Energy vs frequency [discrete] vs time [discrete]</li><li>can hadle it as images</li></ul></li></ul><p><img src="/images/NLP/fft.png"></p><p><strong>Mel frequency representation</strong></p><ul><li><p>FFT is still too high-dimensional for conventional ASR system</p></li><li><p>Downsample by local weighted averages on <a href="https://www.wikiwand.com/zh-hans/%E6%A2%85%E5%B0%94%E5%88%BB%E5%BA%A6" target="_blank" rel="noopener">mel scale</a> non-linear spacing, and take a log. <span class="math display">\[m = 1127\ln(1+\frac{f}{700})\]</span></p></li><li><p>Result in log-mel features (default for neural network speech modelling.)</p></li><li><p>40+ dimensional features per frame</p><p><img src="/images/NLP/freq.png"></p></li></ul><p><strong>MFCC</strong></p><p><strong>Mel Frequency Cepstral Coeﬃcients</strong> - MFCCs are the <a href="https://www.wikiwand.com/zh-hans/%E9%9B%A2%E6%95%A3%E9%A4%98%E5%BC%A6%E8%BD%89%E6%8F%9B" target="_blank" rel="noopener">discrete cosine transformation</a> of the mel ﬁlterbank energies. Whitened and low-dimensional.</p><ul><li>Similar to Principal Components of log spectra</li><li>GMM speech recognition systems may use 13 MFCCs</li></ul><p><strong>Perceptual Linear Prediction</strong> – a common alternative representation.</p><p><strong>Frame stacking</strong>- it’s common to concatenate several consecutive frames.</p><ul><li>e.g. 26 for fully-connected DNN. 8 for LSTM.</li></ul><p>GMMs used local diﬀerences (deltas) and second-order diﬀerences (delta-deltas) to capture dynamics. (13 + 13 + 13 dimensional). Ultimately use <strong>39 dimensional</strong> <a href="https://www.wikiwand.com/zh-hans/%E7%B7%9A%E6%80%A7%E5%88%A4%E5%88%A5%E5%88%86%E6%9E%90" target="_blank" rel="noopener">linear discriminant analysis</a> ( class-aware PCA) projection of 9 stacked MFCC vectors.</p><h3><span id="phonetic-representation">Phonetic representation</span></h3><p>Speech evolved as communication to convey information, consists of sentences (in ASR we usually talk about “utterances”). Sentences composed of words.</p><p>Minimal unit is a “<strong>phoneme</strong>”</p><ul><li>Minimal unit that distinguishes one word from another</li><li>Set of 40-60 distinct sounds</li><li>Vary per language</li><li>Universal representations<ul><li>IPA: international phonetic alphabet</li><li>X-SAMPA (ASCII)</li></ul></li></ul><p>Homophones</p><ul><li>distinct words with the same pronunciation: “there” vs “their”</li></ul><p>Prosody</p><ul><li>How something is said can convey meaning.</li></ul><p><strong>Datasets</strong></p><ul><li>TIMIT<ul><li>Hand-marked phone boundaries given</li><li>630 speakers × 10 utterances</li></ul></li><li>Wall Street Journal (WSJ) 1986 Read speech. WSJ0 1991, 30k vocab</li><li>Broadcast News (BN) 1996 104 hours</li><li>Switchboard (SWB) 1992. 2000 hours spontaneous telephone speech 500 speakers</li><li>Google voice search<ul><li>anonymized live traﬃc 3M utterances 2000 hours</li><li>hand-transcribed 4M vocabulary.</li><li>Constantly refreshed, synthetic reverberation + additive noise</li></ul></li><li>DeepSpeech 5000h read (Lombard) speech + SWB with additive noise.</li><li>YouTube 125,000 hours aligned captions (Soltau et al., 2016)</li></ul><h3><span id="history">History</span></h3><ul><li>1960s Dynamic Time Warping</li><li>1970s Hidden Markov Models</li><li>Multi-layer perceptron 1986</li><li>Speech recognition with neural networks 1987–1995</li><li>Superseded by GMMs 1995–2009</li><li>Neural network features 2002–</li><li>Deep networks 2006– (Hinton, 2002)</li><li>Deep networks for speech recognition<ul><li>Good results on TIMIT (Mohamed et al., 2009)</li><li>Results on large vocabulary systems 2010 (Dahl et al., 2011)</li><li>Google lunches DNN ASR product 2011</li><li>Dominant paradigm for ASR 2012 (Hinton et al., 2012)</li></ul></li><li>Recurrent networks for speech recognition 1990, 2012-<ul><li>New models (attention, LAS, neural transducer)</li></ul></li></ul><h3><span id="probabilistic-speech-recognition">Probabilistic speech recognition</span></h3><p>Speech signal represented as an observation sequence <span class="math inline">\(o = \{o_t\}\)</span>, we want to ﬁnd the <strong>most likely</strong> word sequence <span class="math inline">\(\hat{w}\)</span>.</p><p>We model this with a <strong>Hidden Markov Model</strong>.</p><ul><li><p>The system has a set of discrete states, transitions from state to state according to <strong>transition probabilities</strong> (Markovian: memoryless)</p></li><li><p>Acoustic observation when making a transition is conditioned on state alone. <span class="math inline">\(P(o_t|c_t)\)</span></p></li><li><p>We seek to recover the <strong>state sequence</strong> and consequently the phoneme sequence and consequently the word sequence.</p><p><img src="/images/NLP/hmm.png"></p></li></ul><p>We choose the decoder output as the most likely sequence <span class="math inline">\(\hat{w}\)</span> from all possible sequences, <span class="math inline">\(Σ∗\)</span>, for an observation sequence <span class="math inline">\(o\)</span>: <span class="math display">\[\begin{align}\hat{w} &amp; = \arg\max_{w\in\sum*}P(w|o) \\&amp; = \arg\max_{w\in\sum*}P(o|w)P(w) \\\end{align}\]</span> A product of <em>Acoustic model</em> and <em>Language model</em> scores. <span class="math display">\[P(o|w) = \sum_{d,c,p}P(o|c)P(c|p)P(p|w)\]</span> Where <span class="math inline">\(p\)</span> is the phone sequence and <span class="math inline">\(c\)</span> is the state sequence.</p><p>We can model word sequences with a language model: <span class="math display">\[P(w_1, w_2, ..., w_N) = P(w_0)\prod P(w_i|w_0, ..., w_{i-1})\]</span> <strong>Speech recognition as transduction</strong></p><p><img src="/images/NLP/tranduction.png"></p><p><strong>Lexicon</strong>: phoneme to word</p><p>Construct graph using <strong>Weighted Finite State Transducers (WFST)</strong>.</p><p><img src="/images/NLP/lexicon.png"></p><p>Compose Lexicon FST with Grammar FST <span class="math inline">\(L \circ G\)</span>.</p><p><img src="/images/NLP/FST.png"></p><p><em>Phonetic Unites</em></p><ul><li>Phonemes: “cat” → /K/, /AE/, /T/</li><li>Context independent HMM states <span class="math inline">\(k1, k2...\)</span></li><li>Context dependent states</li><li>Context dependent phones</li><li>Diphones (pairs of half-phones)</li><li>Syllables</li><li>Word-parts cf Machine translation (Wu et al., 2016)</li><li>Characters (graphemes)</li><li>Whole words Sak et al. (2014a, 2015); Soltau et al. (2016)<ul><li>Hard to generalize to rare words</li></ul></li></ul><p>Choice depends on language, size of dataset, task, resources available.</p><p><strong>The difference between Phone and Phoneme</strong></p><blockquote><p>A <a href="http://en.wikipedia.org/wiki/Phoneme" target="_blank" rel="noopener"><strong>phoneme</strong></a> is the <strong>smallest structural unit</strong> that distinguishes <strong>meaning in a language</strong>. Phonemes are not the physical segments themselves, but are cognitive abstractions or categorizations of them.</p><p>On the other hand, <a href="http://en.wikipedia.org/wiki/Phone_(phonetics)" target="_blank" rel="noopener"><strong>phones</strong></a> refer to the instances of phonemes in the actual <strong>utterances</strong> - i.e. the physical segments.</p><p>For example:</p><blockquote><p>the words &quot;madder&quot; and &quot;matter&quot; obviously are composed of distinct <em>phonemes</em>; however, in american english, both words are pronounced almost identically, which means that their <em>phones</em> are the same, or at least very close in the acoustic domain.</p></blockquote></blockquote><p><strong>Context dependent phonetic clustering</strong></p><p>A phone’s realization depends on the preceding and following context, could improve discrimination if we model diﬀerent contextual realizations separately:</p><ul><li>AE preceded by K, followed by T: AE+T-K</li></ul><p>But, if we have 42 phones, and 3 states per phone, there are <span class="math inline">\(3 × 42^3\)</span> context-dependent phones, But most of these won't be observed.</p><p>So <em>cluster</em> – group together similar distributions and train a joint model. Have a “back-oﬀ” rule to determine which model to use for unobserved contexts. Usually a decision tree.</p><p><strong>Gaussian Mixture Models (GMM)</strong></p><ul><li>Dominant paradigm for ASR from 1990 to 2010</li></ul><p>Model the probability distribution of the acoustic features for each state: <span class="math display">\[P(o_t|c_i) = \sum_j w_{ij}N(o_t;\mu_{ij}, \sigma_{ij})\]</span> Often use <strong>diagonal covariance Gaussians</strong> to keep number of parameters under control.</p><p>Train by the E-M algorithm (Dempster et al., 1977) alternating:</p><ul><li>M: <em>forced alignment</em> computing the maximum-likelihood state sequence for each utterance</li><li>E: parameter <span class="math inline">\((µ, σ)\)</span> estimation</li></ul><p>Complex training procedures to incrementally ﬁt increasing numbers of components per mixture.</p><ul><li>More components, better ﬁt. 79 parameters / component.</li></ul><p>Given an alignment mapping audio frames to states, this is parallelizable by state. But hard to share parameters / data across states.</p><p><em>Forced alignment</em></p><p>Forced alignment uses a model to compute the <strong>maximum likelihood alignment</strong> between speech features and phonetic states. For each training utterance, construct the set of phonetic states for the ground truth transcription. Use Viterbi algorithm to ﬁnd ML monotonic state sequence under constraints such as at least one frame per state. Results in a phonetic label for each frame, which can give hard or soft segmentation.</p><p><img src="/images/NLP/force.png"></p><p>With a transducer with states <span class="math inline">\(ci\)</span>:</p><p><img src="/images/NLP/HMM.png"></p><p>Compute state likelihoods at time <span class="math inline">\(t\)</span>: <span class="math display">\[P(o_{1, ...., t}|c_i) = \sum_j P(o_t|c_j)P(o_{1, ..., t}|c_j)P(c_j|c_i)\]</span> With transition probabilities: <span class="math inline">\(P(c_i|c_j)\)</span>, find the best path: <span class="math display">\[P(o_{1, ..., t}|c_i) = \max_j P(o_t|c_j)P(o_{1, ..., t}|c_j)P(c_i|c_j)\]</span> I do not quite understand the image below actually:</p><p><img src="/images/NLP/fa.png"></p><p><strong>Decoding</strong></p><p>Speech recognition <strong>unfolds</strong> in much the same way. Now we have a graph instead of a straight-through path.</p><ul><li>Optional silences between words</li><li>Alternative pronunciation paths.</li></ul><p>Typically use max probability, and work in the log domain. Hypothesis space is huge, so we only keep a “beam” of the best paths, and can lose what would end up being the true best path.</p><p><img src="/images/NLP/unfolds.png"></p><h2><span id="neural-network-speech-recognition">Neural network speech recognition</span></h2><p><strong>Two main paradigms</strong></p><ul><li>Use neural networks to compute nonlinear feature representations.<ul><li>“Bottleneck” or “tandem” features (Hermansky et al., 2000)</li><li>Low-dimensional representation is modelled conventionally with GMMs.</li><li>Allows all the GMM machinery and tricks to be exploited.</li></ul></li><li>Use neural networks to estimate phonetic unit probabilities.</li></ul><p><strong>Neural network features</strong></p><p>Train a neural network to <strong>discriminate classes</strong>. Use output or a low-dimensional <em>bottleneck layer</em> representation as features.</p><p><img src="/images/NLP/bottn.png"></p><ul><li>TRAP: Concatenate PLP-HLDA features and NN features.</li><li>Bottleneck outperforms posterior features (Grezl et al., 2007)</li><li>Generally DNN features + GMMs reach about the same performance as hybrid DNN-HMM systems, but are much more complex.</li></ul><h3><span id="hybrid-neural-networks">Hybrid neural networks</span></h3><p>Train the network as a classiﬁer with a softmax across the phonetic units. Train with cross-entropy. Softmax will converge to posterior across phonetic states: <span class="math inline">\(P(c_i|o_i)\)</span>.</p><p>Now we model <span class="math inline">\(P(o|c)\)</span> with a Neural network instead of a Gaussian Mixture model. Everything else stays the same. <span class="math display">\[P(o|c) = \prod_{t}P(o_t|c_t)\]</span></p><p><span class="math display">\[\begin{align}P(o_t|c_t) &amp; = \frac{P(c_t|o_t)P(o_t)}{P(c_t)} \\&amp; \varpropto  \frac{P(c_t|o_t)}{P(c_t)} \\\end{align}\]</span></p><p>For observations <span class="math inline">\(o_t\)</span> at time <span class="math inline">\(t\)</span> and a CD state sequence <span class="math inline">\(c_t\)</span>. We can ignore <span class="math inline">\(P(o_t)\)</span> since it is the same for all decoding paths.</p><p>The last term is called the “<strong>scaled posterior</strong>”: <span class="math display">\[\log P(o_t|c_t) = \log P(c_t|o_t) - \alpha \log P(c_t)\]</span> Empirically (by cross validation) we actually ﬁnd better results with a “<strong>prior smoothing</strong>” term <span class="math inline">\(α ≈ 0.8\)</span>.</p><p><strong>Input features</strong></p><p>Neural networks can handle high-dimensional features with correlated features. Use (26) stacked ﬁlterbank inputs. (40-dimensional mel-spaced ﬁlterbanks).</p><p>Example ﬁlters learned in the ﬁrst layer of a fully-connected network:</p><p><img src="/images/NLP/eg_inp.png"></p><ul><li>(33 x 8 ﬁlters. Each subimage 40 frequency vs 26 time.)</li></ul><p><strong>Network architectures</strong></p><ul><li>Fully connected</li><li>CNN<ul><li>Time delay neural networks<ul><li>Waibel et al. (1989)</li><li>Dilated convolutions</li></ul></li><li>CNNs in time or frequency domain. Abdel-Hamid et al. (2014); Sainath et al. (2013)</li><li>Wavenet (van den Oord et al., 2016)</li></ul></li><li>RNN<ul><li>RNN (Robinson and Fallside, 1991)</li><li>LSTM Graves et al. (2013)</li><li>Deep LSTM-P Sak et al. (2014b)</li><li>CLDNN (right) (Sainath et al., 2015a)</li><li>GRU. DeepSpeech 1/2 (Amodei et al., 2015)</li><li>Bidirectional (Schuster and Paliwal, 1997) helps, but introduces latency.</li><li>Dependencies not long at speech frame rates (100Hz).</li><li>Frame stacking and down-sampling help.</li></ul></li></ul><p><em>Human parity in speech recognition (Xiong et al., 2016)</em></p><ul><li>Ensemble of BLSTMs</li><li>i-vectors for speaker normalization<ul><li>i-vector is an embedding of audio trained to discriminate between speakers. (Speaker ID)</li></ul></li><li>Interpolated n-gram + LSTM language model.</li><li>5.8% WER on SWB (vs 5.9% for human).</li></ul><h3><span id="traning-losses">Traning losses</span></h3><p><em>Cross Entropy Training</em></p><ul><li><p>GMMs were trained with <em>Maximum Likelihood</em></p></li><li><p>Conventional training uses Cross-Entropy loss. <span class="math display">\[L_{X\ ENT}(o_t, \theta) = \sum_{i=1}^Ny_t(i)\log\frac{y_t(i)}{\hat{y_t}(i)}\]</span></p></li><li><p>With large data we can use Viterbi (binary) targets: <span class="math inline">\(y_t ∈ {0, 1}\)</span></p><ul><li>− i.e. a hard alignment.</li></ul></li><li><p>Can also use a soft (Baum-Welch) alignment (Senior and Robinson, 1994)</p></li></ul><p><em>Connectionist Temporal Classiﬁcation (Graves et al., 2006)</em></p><p>CTC is a bundle of alternatives to conventional system:</p><ul><li><p>CTC introduces an optional <strong>blank symbol</strong> between the ”real” labels.</p></li><li><p>Simple to implement in the FST framework</p><p><img src="/images/NLP/ctc.png"></p></li><li><p>Continuous realignment — no need for a bootstrap model</p></li><li><p>Always use soft targets.</p></li><li><p>Don’t scale by posterior.</p></li><li><p>Similar results to conventional training.</p></li></ul><p><img src="/images/NLP/ctc_align.png"></p><h3><span id="sequence-discriminative-training">Sequence discriminative training</span></h3><p>Conventional training uses <em>Cross-Entropy</em> loss</p><ul><li>Tries to <strong>maximize probability of the true state sequence</strong> given the data.</li></ul><p>We care about Word Error Rate of the complete system. Design a loss that’s diﬀerentiable and closer to what we care about.</p><ul><li>Applied to neural networks (Kingsbury, 2009).</li><li>Posterior scaling gets learnt by the network.</li><li>Improves conventional training and CTC by 15% relative.</li><li>bMMI, sMBR(Povey et al., 2008)</li></ul><p><span class="math display">\[P(S_r|X_r) = \frac{p(X_r, S_r)}{\sum_S p(X_r, S)} = \frac{p(X_r|S_r)P(S_r)}{\sum_Sp(X_r|S)P(S)}\]</span></p><p><span class="math display">\[L_{mmi}(\theta) = -\sum_{r=1}^R\log P(S_r|X_r)\]</span></p><p><img src="/images/NLP/new_loss.png"></p><h3><span id="new-architectures">New architectures</span></h3><p><strong>Seq2seq</strong></p><p>Basic sequence2sequence not that good for speech</p><ul><li>Utterances are too long to memorize</li><li>Monotonicity of audio (vs Machine Translation)</li></ul><p>Models</p><ul><li>Attention + seq2seq for speech (Chorowski et al., 2015)</li><li>Listen, Attend and Spell (Chan et al., 2015)</li></ul><p>Output characters until EOS, incorporates language model of training set. Harder to incorporate a separately-trained language model. (e.g. trained on trillions of tokens)</p><p><em>Watch, Listen, Attend and Spell (Chung et al., 2016)</em></p><p>Apply LAS to audio and video streams simultaneously.</p><p><img src="/images/NLP/wlas.png"></p><p>Train with scheduled sampling (Bengio et al., 2015)</p><p><img src="/images/NLP/sche_sam.png"></p><p><em>Neural transducer (Jaitly et al., 2015)</em></p><p>Seq2seq models require the whole sequence to be available. Introduce latency compared to unidirectional.</p><p>Solution: Transcribe monotonic chunks at a time with attention.</p><p><img src="/images/NLP/chunk.png"></p><p><img src="/images/NLP/transducer.png"></p><p><strong>Raw waveform speech recognition</strong></p><p>We typically train on a much-reduced dimensional signal.</p><ul><li>Would like to train end-to-end.</li><li>Learn ﬁlterbanks, instead of hand-crafting.</li></ul><p>A conventional RNN at audio sample rate can’t learn long-enough dependencies.</p><ul><li>Add a convolutional ﬁlter to a conventional system e.g. CLDNN (Sainath et al., 2015b)</li><li>WaveNet-style architecture</li><li>Clockwork RNN (Koutn´ık et al., 2014)<ul><li>Run a hierarchical RNN at multiple rates.</li></ul></li></ul><p>Frequency distribution of learned ﬁlters diﬀers from hand-initialization:</p><p><img src="/images/NLP/raw_wave.png"></p><p><strong>Speech recognition in noise</strong></p><ul><li>Multi-style training (“MTS”)<ul><li>Collect noisy data.</li><li>Or, add realistic but randomized noise to utterances during training.</li><li>e.g. Through a “room simulator” to add reverberation.</li><li>Optionally add a clean-reconstruction loss in training.</li></ul></li><li>Train a denoiser</li><li>NB <em>Lombard</em> eﬀect – voice changes in noise.</li></ul><p><strong>Multi-microphone speech recognition</strong></p><p>Multiple microphones give a richer representation, “closest to the speaker” has better SNR.</p><p>Beamforming</p><ul><li>Given geometry of microphone array and speed of sound</li><li>Compute Time Delay of Arrival at each microphone</li><li>Delay-and-sum: Constructive interference of signal in chosen direction.</li><li>Destructive interference depends on direction / frequency of noise.</li></ul><p>More features for a neural network to exploit.</p><ul><li>Important to preserve phase information to enable beam-forming</li></ul><p><em>Factored multichannel raw waveform CLDNN (Sainath et al., 2016)</em></p><p><img src="/images/NLP/factor.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> Speech Recognition </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Conditional Language Model with Attention</title>
      <link href="/2017/08/09/Deep%20NLP%20-%20Conditional%20Language%20Model%20with%20Attention/"/>
      <url>/2017/08/09/Deep%20NLP%20-%20Conditional%20Language%20Model%20with%20Attention/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#machine-translation-with-attention">Machine translation with attention</a><ul><li><a href="#with-concatenation">With Concatenation</a></li><li><a href="#with-convolutional-nets">With Convolutional Nets</a></li><li><a href="#with-bidirectional-rnns">With Bidirectional RNNS</a></li><li><a href="#attention">Attention</a></li></ul></li><li><a href="#image-caption-generation-with-attention">Image caption generation with attention</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="machine-translation-with-attention">Machine translation with attention</span></h2><p><strong>Problems about conditioning with vectors</strong></p><ul><li>We are compressing a lot of information in a finite-sized vector.</li><li>Gradients have a long way to travel. Even LSTMs forget!</li></ul><p><strong>Solution</strong></p><ul><li>Represent a source sentence as a matrix<ul><li>Solve the capacity problem</li></ul></li><li>Generate a target sentence from a matrix<ul><li>Solve the gradient flow problem</li></ul></li></ul><p><strong>Sentences as Matrices</strong></p><p><img src="/images/NLP/sentence_mat.png"></p><p>Question: <strong>How do we build these matrices?</strong></p><h3><span id="with-concatenation">With Concatenation</span></h3><ul><li>Each word type is represented by an n-dimensional vector</li><li>Take all of the vectors for the sentence and concatenate them into a matrix</li><li>Simplest possible model<ul><li>So simple that no one publish how well/badly it works!</li></ul></li></ul><p><img src="/images/NLP/With_Concatenation.png"></p><h3><span id="with-convolutional-nets">With Convolutional Nets</span></h3><ul><li>Apply convolutional networks to transform the naive concatenated matrix to obtain a context-dependent matrix</li><li>Note: convnets usually have a &quot;pooling&quot; operation at the top level that results in a fixed-sized representation. For sentences, leave this out.</li><li>Papers<ul><li><strong>Gehring et al., ICLR 2016</strong></li><li><strong>Kalchbrenner and Blunsom, 2013</strong></li></ul></li></ul><p><img src="/images/NLP/With%20CNN.png"></p><h3><span id="with-bidirectional-rnns">With Bidirectional RNNS</span></h3><ul><li>By far the most widely used matrix representation, due to <strong>Bahdanau et al (2015)</strong></li><li>One column per word</li><li>Each column (word) has two halves concatenated together:<ul><li>a “forward representation”, i.e., a word and its left context</li><li>a “reverse representation”, i.e., a word and its right context</li></ul></li><li>Implementation: bidirectional RNNs (GRUs or LSTMs) to read f from left to right and right to left, concatenate representations</li></ul><p><img src="/images/NLP/With_BiRNN.png"></p><p><strong>Where are we in 2017?</strong></p><p>There are lots of ways to construct <span class="math inline">\(F\)</span></p><ul><li><p>Very little systematic work comparing them</p></li><li><p>There are many more undiscovered things out there</p><ul><li>convolutions are particularly interesting and under-explored</li><li><strong>syntactic</strong> information can help (<strong>Sennrich &amp; Haddow, 2016</strong>; <strong>Nadejde et al., 2017</strong>), but many more integration stregration strategies are possible</li></ul></li><li><p>try something with phrase types instead of word types?</p><p>Multi-word expressions are a pain in the neck .</p></li></ul><h3><span id="attention">Attention</span></h3><p>Bahdanau et al. (2015) were the ﬁrst to propose using <strong>attention</strong> for translating from matrix-encoded sentences.</p><p><strong>High-Level Idea</strong></p><ul><li>Generate the output sentence word by word using an RNN</li><li>At each output position <span class="math inline">\(t\)</span>, the RNN receives two inputs (in addition to any recurrent inputs)<ul><li>a ﬁxed-size vector embedding of the previously generated output symbol <span class="math inline">\(e_{t-1}\)</span></li><li>a ﬁxed-size vector encoding a “view” of the input matrix</li></ul></li><li>How do we get a ﬁxed-size vector from a matrix that changes over time?<ul><li>Bahdanau et al: do <strong>a weighted sum of the columns</strong> of <span class="math inline">\(F\)</span> (i.e., words) based on how important they are at the current time step. (i.e., just a matrix-vector product <span class="math inline">\(Fa_t\)</span> )</li><li>The weighting of the input columns at each time-step (<span class="math inline">\(a_t\)</span>) is called <strong>attention</strong></li></ul></li></ul><p><img src="/images/NLP/BA.png"></p><p><strong>Compute Attention</strong></p><p>At each time step (one time step = one output word), we want to be able to “attend” to different words in the source sentence</p><ul><li>We need a weight for every column: this is an |<span class="math inline">\(f\)</span>|-length vector a <span class="math inline">\(a_t\)</span></li><li>Here is Bahdanau et al.’s solution<ul><li>Use an RNN to predict model output, call the hidden states <span class="math inline">\(s_t\)</span></li><li>At time <span class="math inline">\(t\)</span> compute the <strong>expected input embedding</strong> <span class="math inline">\(r_t = Vs_{t-1}\)</span></li><li>Take the dot product with every column in the source matrix to compute the <strong>nonlinear attention energy</strong>. <span class="math inline">\(e_t = v^T\tanh(WF+r_t)\)</span></li><li>Exponentiate and normalize to 1: <span class="math inline">\(a_t = softmax(u_t)\)</span></li><li>Finally, the input source vector for time t is <span class="math inline">\(c_t = Fa_t\)</span></li></ul></li></ul><p>The overall algorithm:</p><p><img src="/images/NLP/algorithm.png"></p><p>Add attention to seq2seq translation: <strong>+11 BLEU</strong></p><p><em>Model Variant</em></p><p><img src="/images/NLP/variant.png"></p><p><strong>Summary</strong></p><ul><li>Attention is closely related to “pooling” operations in convnets (and other architectures)</li><li>Bahdanau’s attention model seems to only cares about “content”<ul><li>No obvious bias in favor of diagonals, short jumps, fertility, etc.</li><li>Some work has begun to add other “structural” biases (Luong et al., 2015; Cohn et al., 2016), but there are lots more opportunities</li></ul></li><li>Attention weights provide interpretation you can look at</li></ul><h2><span id="image-caption-generation-with-attention">Image caption generation with attention</span></h2><p><img src="/images/NLP/imggen.png"></p><p><strong>Regions in ConvNets</strong></p><p>Each point in a “higher” level of a convnet deﬁnes spatially localised feature vectors(/matrices).</p><p>Xu et al. calls these “<em>annotation vectors</em>”, <span class="math inline">\(a_i\)</span> , <span class="math inline">\(i\in \{1, . . . , L\}\)</span></p><p><img src="/images/NLP/a1.png"></p><p><img src="/images/NLP/a2.png"></p><p>Attention “weights” ( <span class="math inline">\(a_t\)</span> ) are computed using exactly the <strong>same</strong> technique as discussed above.</p><ul><li><p>Deterministic <strong>soft</strong> attention (Bahdanau et al., 2014)</p><p><span class="math inline">\(c_t = Fa_t\)</span></p></li><li><p>Stochastic <strong>hard</strong> attention (Xu et al., 2015)</p><p><span class="math inline">\(s_t \sim Categorical(a_t)\)</span></p><p><span class="math inline">\(c_t = F_{:,s_t}\)</span></p></li></ul><p><em>Learning Hard Attention</em></p><p>The loss is computed by following equation: <span class="math display">\[\begin{align}L &amp; = -\log p(w|x) \\&amp; = -\log\sum_s p(w,s|x) \\&amp;= -\log\sum_sp(s|x)p(w|x, s)\end{align}\]</span> where <span class="math inline">\(x\)</span> is the input image, <span class="math inline">\(s\)</span> is the generated context, and <span class="math inline">\(w\)</span> is the caption.</p><p>According to <em>Jensen's inequality</em>, <span class="math display">\[\begin{align}L &amp;= -\log\sum_sp(s|x)p(w|x, s)\\&amp;≤-\sum_s p(s|x)\log p(w|x, s)\\&amp;\approx -\frac{1}{N}\sum_{i=1}^Np(s^{(i)}|x)\log p(w|x, s)\end{align}\]</span> Sample <span class="math inline">\(N\)</span> sequences of attention decisions from the model, the gradient is the probability of this sequence scaled by the log probability of generating the target words using that sequence of attention decisions.</p><p>This is equivalent to using the <strong>REINFORCE</strong> algorithm (Williams, 1992) using the log probability of the observed words as a “<strong>reward function</strong>”. REINFORCE a <em>policy gradient</em> algorithm used for reinforcement learning.</p><p><img src="/images/NLP/imgeg.png"></p><p><strong>Summary</strong></p><ul><li>Signiﬁcant performance improvements<ul><li>Better performance over vector-based encodings</li><li>Better performance with smaller training data sets</li></ul></li><li>Model interpretability</li><li>Better gradient ﬂow</li><li>Better capacity (especially obvious for translation)</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> NMT </tag>
            
            <tag> Attention </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> Machine Translation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Conditional Language Model</title>
      <link href="/2017/08/08/Deep%20NLP%20-%20Conditional%20Language%20Modeling/"/>
      <url>/2017/08/08/Deep%20NLP%20-%20Conditional%20Language%20Modeling/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#kalchbrenner-and-blunsom-2013">Kalchbrenner and Blunsom 2013</a></li><li><a href="#sutskever-et-al-2014">Sutskever et al. (2014)</a></li><li><a href="#kiros-et-al2013">Kiros et al.(2013)</a></li></ul><!-- tocstop --><a id="more"></a><p>A <strong>conditional language model</strong> assigns probabilities to sequences of words, <span class="math inline">\(w = (w_1, w_2, …, w_l)\)</span>, given some conditioning context, <strong>x</strong>.</p><p>As with unconditional models, it is again helpful to use the chain rule to decompose this probability: <span class="math display">\[p(w|x) = \prod_{t=1}^lp(w_t|x, w_1, w_2, ..., w_{t-1})\]</span></p><table><thead><tr class="header"><th>x &quot;input&quot;</th><th>w &quot;text output&quot;</th></tr></thead><tbody><tr class="odd"><td>An author</td><td>A document written by that author</td></tr><tr class="even"><td>A topic label</td><td>An article about that topic</td></tr><tr class="odd"><td>{SPAM, NOT_SPAM}</td><td>An email</td></tr><tr class="even"><td>A sentence in French</td><td>Its English translation</td></tr><tr class="odd"><td>A sentence in English</td><td>Its French translation</td></tr><tr class="even"><td>A sentence in English</td><td>Its Chinese translation</td></tr><tr class="odd"><td>An image</td><td>A text description of the image</td></tr><tr class="even"><td>A question + a document</td><td>Its answer</td></tr><tr class="odd"><td>A question + an image</td><td>Its answer</td></tr></tbody></table><p>To <strong>train</strong> contitional language models, we need paired samples, <span class="math inline">\(\{(x_i, w_i)\}\)</span>.</p><p><strong>Algorighmic challenges</strong></p><p>We often want to find the most likely <span class="math inline">\(w\)</span> given some <span class="math inline">\(x\)</span>. This is unfortunately generally and <em>intractable problem</em>. <span class="math display">\[w^* = \arg \max_wp(w|x)\]</span> We therefore approximate it using a <strong>beam search</strong> or with Monte Carlo methods since <span class="math inline">\(w^{(i)} \approx p(w|x)\)</span> is often computationally easy.</p><p><strong>Evaluating conditional LMs</strong></p><p>We can use <strong>cross entropy</strong> or <strong>preplexity</strong>, it's okay to implement, but hard to interpret.</p><p><strong>Task-specific evaluation</strong>. Compare the model's most likely output to human-generated expected output using a task-specific evaluation metric <span class="math inline">\(L\)</span>. <span class="math display">\[w^* = \arg \max_wp(w|x)\ \ \ \ \ L(w^*, w_{ref})\]</span> Examples of <span class="math inline">\(L\)</span>: BLUE, METEOR, WER, ROUGE, easy to implement, okay to interpret.</p><p><strong>Encoder-Decoder</strong></p><p><img src="/images/NLP/ed1.png"></p><p><img src="/images/NLP/ed2.png"></p><p>Two questions</p><ul><li>How do we encode <span class="math inline">\(x\)</span> as a fixed-size vector, <span class="math inline">\(c\)</span> ?</li><li>How do we condition on <span class="math inline">\(c\)</span> in the decoing model?</li></ul><h2><span id="kalchbrenner-and-blunsom-2013">Kalchbrenner and Blunsom 2013</span></h2><p>Encoder <span class="math display">\[c = embed(x)\]</span></p><p><span class="math display">\[s = Vc\]</span></p><p>Recurrent decoder <span class="math display">\[h_t = g(W[h_{t-1}; w_{t-1}] + s + b)\]</span></p><p><span class="math display">\[u_t = Ph_t + b&#39;\]</span></p><p><span class="math display">\[p(W_t|x, w&lt;t) = softmax(u_t)\]</span></p><p><strong>CSM Encoder</strong></p><p>How should we define <span class="math inline">\(c = embed(x)\)</span> ?</p><p>Convolutional sentence model(CSM)</p><p><img src="/images/NLP/CSM.png"></p><p>Good</p><ul><li>By stacking them, longer range dependencies can be learnt</li><li>Convolutions learn interactions among features in a local context</li><li>Deep ConvNets have a branching structure similar to trees, but no parser is required</li></ul><p>Bad</p><ul><li>Sentences have different lengths, need different depth trees; convnets are not usually so dynamic, but see Kalchbrenner et al. (2014). A convolutional neural network for modelling sentences. In Proc. ACL.</li></ul><p><img src="/images/NLP/RNNdecoder.png"></p><h2><span id="sutskever-et-al-2014">Sutskever et al. (2014)</span></h2><p>LSTM encoder</p><ul><li><span class="math inline">\((c_0, h_0)\)</span> are parameters</li><li><span class="math inline">\((c_i, h_i)\)</span> = LSTM(<span class="math inline">\(x_i, c_{i-1}, h_{i-1}\)</span>)</li></ul><p>The encoding is <span class="math inline">\((c_l, h_l)\)</span> where <span class="math inline">\(l = |x|\)</span></p><p>LSTM decoder</p><ul><li><span class="math inline">\(w_0 = &lt;s&gt;\)</span></li><li><span class="math inline">\((c_{t+l}, h_{t+l}) = LSTM(w_{t-1}, c_{t+l-1}, h_{t+l-1})\)</span></li><li><span class="math inline">\(u_t = Ph_{t+l} + b\)</span></li><li><span class="math inline">\(P(W_t|x, w&lt;t) = softmax(u_t)\)</span></li></ul><p><img src="/images/NLP/sea.png"></p><p>Good</p><ul><li>RNNs deal naturally with sequences of various lengths</li><li>LSTMs in principle can propagate gradients a long</li><li>Very simple architecture</li></ul><p>Bad</p><ul><li>The hidden state has to remember a lot of information!</li></ul><p><strong>Tricks</strong></p><p>Read the input sequence &quot;backwards&quot; : <strong>+4 BLEU</strong></p><p><img src="/images/NLP/backsea.png"></p><p>Use an ensemble of J <strong>independently trained</strong> models.</p><ul><li>Ensemble of 2 models: <strong>+3 BLEU</strong></li><li>Ensemble of 5 models; <strong>+4.5 BLEU</strong></li></ul><p><strong>A word about decoding</strong></p><p>In general, we want to find the most probable (MAP) output given the input, i.e. <span class="math display">\[\begin{align}w^* = \arg\max_{w}p(w|x) = \arg \max_w\sum_{t=1}^{|w|}\log p(w_t|x, w_{&lt;t})\end{align}\]</span> This is, for general RNNs, a hard problem. We therefore approximate it with a <strong>greedy search</strong>： <span class="math display">\[\begin{array}{lcl}w_1^* = \arg\max_{w_1}p(w_1|x)\\w_2^* = \arg\max_{w_2}p(w_2|x, w_1^*)\\...\\w^*_t = \arg\max_{w_t}p(w_t|x, w^*_{&lt;t})\end{array}\]</span> A slightly better approximation is to use a <strong>beam search</strong> with beam size <span class="math inline">\(b\)</span>. Key idea: <strong>keep track of top b hypothesis</strong>. Use beam search: <strong>+1 BLEU</strong></p><p><img src="/images/NLP/beam.png"></p><h2><span id="kiros-et-al2013">Kiros et al.(2013)</span></h2><p><strong>Image caption generation</strong></p><ul><li>Neural networks are great for working with multiple modalities - <strong>Everything is a vector!</strong></li><li>Image caption generation can therefore use the same techniques as translation modeling</li><li>A word about data<ul><li>Relatively few captioned images are avaliable</li><li>Pre-train image embedding model using another task, like image identification (e.g., ImageNet)</li></ul></li></ul><p>Look a lot like Kalchbrenner and Blunsom(2013)</p><ul><li>convolutional network on the input</li><li>n-gram language model on the output</li></ul><p>Innovation: <strong>multiplicative interactions</strong> in the decoder n-gram model</p><p>Encoder <strong>x</strong> = enbed(<span class="math inline">\(x\)</span>)</p><p>Simple conditional n-gram LM: <span class="math display">\[\begin{array}{lcl}h_t = W[w_{t-n+1}; w_{t-n+2};...; w_{t-1}] + Cx\\u_t = Ph_t+b\\p(W_t|x, w_{t-n+1}^{t-1}) = softmax(u_t)\end{array}\]</span> Multiplicative n-gram LM:</p><ul><li><span class="math inline">\(w_i = r_{i,j,w}x_j\)</span></li><li><span class="math inline">\(w_i = u_{w,i}v_{i,j}\ \ \ \ \ \ \ \ (U\in R^{|V|*d}, V \in R^{d*k})\)</span></li><li><span class="math inline">\(r_t = W[w_{t-n+1}; w_{t-n+2};...; w_{t-1}] + Cx\)</span></li><li><span class="math inline">\(h_t = (W^{fr}r_t)\odot (W^{fx}x)\)</span></li><li><span class="math inline">\(u_t = Ph_t + b\)</span></li><li><span class="math inline">\(p(W_t|x, w_{&lt;t}) = softmax(u_t)\)</span></li></ul><p>Two messages:</p><ul><li>Feed-forward n-gram models can be used in place of RNNs in conditional models</li><li>Modeling interactions between input modalities holds a lot of promise<ul><li>Although MLP-type models can approximate higher order tensors, multiplicative models appear to make learning interactions easier</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> NMT </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> Machine Translation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Text Classification</title>
      <link href="/2017/08/07/Deep%20NLP%20-%20Text%20Classification/"/>
      <url>/2017/08/07/Deep%20NLP%20-%20Text%20Classification/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#generative-and-discriminative-models">Generative and discriminative models</a></li><li><a href="#naive-bayes-classifier">Naive Bayes classifier</a></li><li><a href="#feature-representations">Feature Representations</a></li><li><a href="#logistic-regression">Logistic Regression</a></li><li><a href="#representing-text-with-a-rnn">Representing Text with a RNN</a></li><li><a href="#convolutional-neural-network">Convolutional Neural Network</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="generative-and-discriminative-models">Generative and discriminative models</span></h2><p><strong>Generative (joint) models</strong> <span class="math inline">\(P(c, d)\)</span></p><ul><li>Model the distribution of individual classes and place probabilities over both observed data and hidden variables (such as labels)</li><li>E.g. n-gram models, hidden Markov models, probabilistic context-free grammars, IBM machine translation models, Naive Bayes...</li></ul><p><strong>Discriminative (conditional) models</strong> <span class="math inline">\(P(c|d)\)</span></p><ul><li>Learn <strong>boundaries</strong> between classes. Take data as given and put probability over the hidden structure give the data.</li><li>E.g. logistic regression, maximum entropy models, conditional random fields, support-vector machines...</li></ul><h2><span id="naive-bayes-classifier">Naive Bayes classifier</span></h2><p>Bayes' Rule: <span class="math display">\[P(c|d) = \frac{P(c)P(d|c)}{P(d)}\]</span> This estimates the probility of document <span class="math inline">\(d\)</span> being in class <span class="math inline">\(c\)</span>, assuming document length <span class="math inline">\(n_d\)</span> and tokens <span class="math inline">\(t\)</span>: <span class="math display">\[P(c|d)  = P(c)P(d|c) = P(c)\prod_{1 ≤i≤n_d}P(t_i|c)\]</span> <strong>Independence Assumptions</strong></p><p>Note that we assume <span class="math inline">\(P(t_i|c) = P(t_j|c)\)</span> independent of token position. This is the <strong>naive</strong> part of Naive Bayes.</p><p>The best class is the <strong>maximum a posteriori (MAP)</strong> clss: <span class="math display">\[c_{map} = \arg\max_{c\in C}P(c|d) = \arg\max_{c\in C}P(c)\prod_{1≤i≤n_d}P(t_i|c)\]</span> Multiplying tons of small probabilities is tricky, so <strong>log space</strong> it: <span class="math display">\[c_{map} = \arg\max_{c\in C}(\log P(c) + \sum_{1≤i≤n_d}\log P(t_i|c))\]</span> Finally: zero probabilities are bad. Add <strong>smoothing</strong>: <span class="math display">\[P(t|c) = \frac{T_{ct}}{\sum_{t&#39;\in V}T_{ct&#39;}} =&gt; P(t|c) = \frac{T_{ct} + 1}{\sum_{t&#39;\in V}T_{ct&#39;}+|V|}\]</span> This is Laplace or add-1 smoothing.</p><p><strong>Advantages</strong></p><ul><li>Simple</li><li>Interpretable</li><li>Fast (linear in size of training set and test document)</li><li>Text representation trivial (bag of words)</li></ul><p><strong>Drawbacks</strong></p><ul><li>Independence assumptions often too strong</li><li>Sentence/document structure not taken into account</li><li>Naive classifier has zero probabilities; smoothing is awkward</li></ul><p><strong>Naive Bayes is a generative model!!!</strong> <span class="math display">\[P(c|d)P(d) = P(d|c)P(c) = P(d, c)\]</span> While we are using a conditional probability <span class="math inline">\(P(c|d)\)</span> for classification, we model the joint probability of <span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>.</p><p>This meas it is trivial to invert the process and generate new text given a class label.</p><h2><span id="feature-representations">Feature Representations</span></h2><p>A feature representation (of text) can be viewed as a vector where each element indicates the presence or absence of a given feature in a document.</p><p>Note: features can be binary (presence/absence), multinomial (count) or continuous (eg. TF-IDF weighted).</p><h2><span id="logistic-regression">Logistic Regression</span></h2><p>A general framework for learning <span class="math inline">\(P(c|d)\)</span> is <strong>logistic regression</strong></p><ul><li>logistic : because is uses a logistic function</li><li>regression : combines a feature vector (<span class="math inline">\(d\)</span>) with weights (<span class="math inline">\(\beta\)</span>) to compute an answer</li></ul><p>Binary case: <span class="math display">\[P(true|d) = \frac{1}{1 + \exp(\beta_0 + \sum_i\beta_iX_i)}\]</span></p><p><span class="math display">\[P(false|d) = \frac{\exp(\beta_0 + \sum_i\beta_iX_i)}{1 + \exp(\beta_0+\sum_i\beta_iX_i)}\]</span></p><p>Multinomial case: <span class="math display">\[P(c|d) = \frac{\exp(\beta_{c,0} + \sum_i\beta_{c,i}X_i)}{\sum_{c&#39;}\exp(\beta_{c&#39;,0} +  \sum_i\beta_{c&#39;,i}X_i)}\]</span> The binary and general functions for the logistic regression can be simplified as follows: <span class="math display">\[P(c|d) = \frac{1}{1+\exp(-z)}\]</span></p><p><span class="math display">\[P(c|d) = \frac{\exp(z_c)}{\sum_{c&#39;}\exp(z_{c&#39;})}\]</span></p><p>which are referred to as the <strong>logistic</strong> and <strong>softmax</strong> function.</p><p>Given this model formulation, we want to learn parameters <span class="math inline">\(β\)</span> that maximise the conditional likelihood of the data according to the model.</p><p>Due to the softmax function we not only construct a classifier, but learn <strong>probability distributions</strong> over classifications.</p><p>There are many ways to chose weights <span class="math inline">\(β\)</span>:</p><ul><li>Perceptron Find misclassified examples and move weights in the direction of their correct class</li><li>Margin-Based Methods such as Support Vector Machines can be used for learning weights</li><li>Logistic Regression Directly maximise the conditional log-likelihood via gradient descent.</li></ul><p><strong>Advantages</strong></p><ul><li>Still reasonably simple</li><li>Results are very interpretable</li><li>Do not assume statistical independence between features!</li></ul><p><strong>Drawbacks</strong></p><ul><li>Harder to learn than Naive Bayes</li><li>Manually designing features can be expensive</li><li>Will not necessarily generalise well due to hand-craftedfeatures</li></ul><h2><span id="representing-text-with-a-rnn">Representing Text with a RNN</span></h2><p><img src="/images/NLP/RNNre.png"></p><ul><li><span class="math inline">\(h_i\)</span> is a function of <span class="math inline">\(x\{0:i\}\)</span> and <span class="math inline">\(h\{0:i−1\}\)</span></li><li>It contains information about all text read up to point <span class="math inline">\(i\)</span>.</li><li>The first half of this lecture was focused on learning a representation <span class="math inline">\(X\)</span> for a given text</li></ul><p>So in order to classify text we can simply take a trained language model and extract text representations from the final hidden state <span class="math inline">\(c_n\)</span>.</p><p>Classification as before using a logistic regression: <span class="math display">\[P(c|d) = \frac{\exp(\beta_{c,0} + \sum_i\beta_{c,i}h_{ni})}{\sum_{c&#39;}\exp(\beta_{c&#39;,0} +  \sum_i\beta_{c&#39;,i}h_{ni})}\]</span> ✅ Can use RNN + Logistic Regression out of the box ✅ Can in fact use any other classifier on top of <span class="math inline">\(h\)</span> ! ❌ How to ensure that <span class="math inline">\(h\)</span> pays attention to relevant aspects of data?</p><p><strong>Move the classification function inside the network</strong></p><p><img src="/images/NLP/RNNtext.png"></p><p>This is a simple <strong>Multilayer Perceptron (MLP)</strong>. We can train the model using the cross-entropy loss: <span class="math display">\[L_i = -\sum_c y_c \log P(c|d_i) = -\log (\frac{\exp(m_c)}{\sum_j\exp(m_j)})\]</span></p><ul><li>Cross-entropy is designed to deal with errors on <strong>probabilities</strong>.</li><li>Optimizing means minimizing the cross-entropy between the estiated class probabilities (<span class="math inline">\(P(c|d)\)</span>) and the ture distribution.</li><li>There are many alternative losses (hinge-loss, square error, L1 loss).</li></ul><p><strong>Dual Objective RNN</strong></p><p>In practice it may make sense to combine an LM objective with classifier training and to optimise the two losses jointly.</p><p><img src="/images/NLP/DualRNN.png"> <span class="math display">\[J = \alpha J_{class} + (1-\alpha)J_{lm}\]</span> Such a joint loss enables making use of text beyond labelled data.</p><p><strong>Bi-Directional RNNs</strong></p><p>Another way to add signal is to process the input text both in a forward and in a backward sequence.</p><p><img src="/images/NLP/BiRNN.png"></p><p>The update rules for this directly follow the regular forward-facing RNN arhitecture. In practice, bidirectional networks have shown to be more robust than unidirectional networks.</p><p>A bidirectional network can be used as a classifier simply by redefining <span class="math inline">\(d\)</span> to be the <strong>concatenation</strong> of both final hidden states: <span class="math display">\[d = (\rightarrow{h_n}||h_0\leftarrow)\]</span> <strong>RNN Classifier can be either a generative or a discriminative model</strong></p><p><img src="/images/NLP/seq2seq.png"></p><p>Encoder: discriminative (it does not model the probability of the text) Joint-model: generative (learns both <span class="math inline">\(P(c)\)</span> and <span class="math inline">\(P(d)\)</span>).</p><h2><span id="convolutional-neural-network">Convolutional Neural Network</span></h2><p>Reasons to consider CNNs for Text:</p><ul><li>✅ Really fast (GPU)</li><li>✅ BOW is often sufficient</li><li>✅ Actually can take some structure into account</li><li>❌ Not sequential in its processing of input data</li><li>❌ Easier to discriminate than to generate variably sized data</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> LSTM </tag>
            
            <tag> Naive Bayes </tag>
            
            <tag> Text Classification </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Recurrent Neural Networks and Language Modelling</title>
      <link href="/2017/08/06/Deep%20NLP%20-%20RNNs%20and%20Language%20Modelling/"/>
      <url>/2017/08/06/Deep%20NLP%20-%20RNNs%20and%20Language%20Modelling/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#count-based-n-gram-language-models">Count based N-Gram Language Models</a></li><li><a href="#neural-n-gram-language-models">Neural N-Gram Language Models</a></li><li><a href="#recurrent-neural-network-language-models">Recurrent Neural Network Language Models</a><ul><li><a href="#long-short-term-memory-lstm">Long Short Term Memory (LSTM)</a></li><li><a href="#deep-rnn-lms">Deep RNN LMs</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><p>A language model assigns a <strong>probability</strong> to a sequence of words, given the observed training text, how probable is this new utterance?</p><p>Most language models employ the chain rule to decompose the joint probability into a sequence of conditional probabilities: <span class="math display">\[p(w_1, w_2, w_3, ..., w_N) = p(w_1)p(w_2|w_1)p(w_3|w_1,w_2)*...*p(w_N|w_1,..w_{N-1})\]</span> <strong>Evaluating a Language Model</strong></p><p>A good model assigns real utterances <span class="math inline">\(w_1^N\)</span> from a language a high probability. This can be measured with <em>cross entropy</em>: <span class="math display">\[H(w_1^N) = -\frac{1}{N}\log_2p(w_1^N)\]</span> <em>Intuition</em> : Cross entropy is a measure of how many bits are needed to encode text with our model.</p><p><strong>Data</strong></p><p>Language modelling is a time series prediction problem in which we must be careful to <strong>train on the past</strong> and <strong>test on the future</strong>.</p><p>If the corpus is composed of articles, it is best to ensure the <strong>test data</strong> is drawn from <strong>a disjoint set of articles</strong> to the training data.</p><h2><span id="count-based-n-gram-language-models">Count based N-Gram Language Models</span></h2><p><strong>Markov assumption</strong></p><ul><li>only previous history matters</li><li>limited memory: only last <span class="math inline">\(k - 1\)</span> words are included in history(older words less relevant)</li><li><span class="math inline">\(k\)</span>-th order Markov model</li></ul><p>e.g. 2-gram language model: <span class="math display">\[p(w_1, w_2, ..., w_n) \approx p(w_1)p(w_2|w_1)p(w_3|w_2)...p(w_n|w_{n-1})\]</span> <strong>Estimating Probabilities</strong></p><p>Maximum likelihood estimation for 3-grams: <span class="math display">\[p(w_3|w_1, w_2) = \frac{count(w_1,w_2,w_3)}{count(w_1,w_2)}\]</span> In our training corpus we may never observe this trigrams:</p><ul><li>Oxford Pimm's eater</li><li>Oxford Pimm's drinker</li></ul><p>If both have count 0 our smoothing methods will assign the same probability to them.</p><p>A better solution is to interpolate with the bigram probability.</p><ul><li>Pimm's eater</li><li>Pimm's drinker</li></ul><p>A simple approach is linear interpolation: <span class="math display">\[p_l(w_n|w_{n-1}, w_{n-2}) = \lambda_3p(w_n|w_{n-1}, w_{n-2})+\lambda_2p(w_n|w_{n-1})+\lambda_1p(w_n)\]</span> where <span class="math inline">\(\lambda_3 + \lambda_2 + \lambda_1 = 1\)</span>.</p><p><strong>Summary</strong></p><p>Good</p><ul><li>Count based n-gram models are exceptionally scalable and able to be trained on trillions of words of data</li><li>fast constant time evaluation of probabilities at best time</li><li>sophisticated smoothing techniques match the empirical distribution of language</li></ul><p>Bad</p><ul><li>Large ngrams are sparse, so hard to capture long dependencies</li><li>symbolic nature does not capture correlations between semantically similary word distributions, e.g. cat &lt;-&gt; dog.</li><li>similarly morphological regularities, running &lt;-&gt; jumping, or gender.</li></ul><h2><span id="neural-n-gram-language-models">Neural N-Gram Language Models</span></h2><p>Trigram NN language model <span class="math display">\[h_n = g(V[w_{n-1};w_{n-2}] + c) \]</span></p><p><span class="math display">\[\hat{p_n} = softmax(Wh_n + b)\]</span></p><p><span class="math display">\[softmax(u)_i = \frac{\exp(u_i)}{\sum_j\exp u_j}\]</span></p><p>where</p><ul><li><span class="math inline">\(w_i\)</span> are one hot vetors and <span class="math inline">\(\hat{p_i}\)</span> are distributions</li><li><span class="math inline">\(|w_i| = |\hat{p_i}| = V\)</span> (words in the vocabulary)</li><li><span class="math inline">\(V\)</span> is usually very large <span class="math inline">\(&gt; 1e5\)</span></li></ul><p><img src="/images/NLP/NLM1.png"></p><p><strong>Training</strong></p><p>The usual training objective is the cross entropy of the data given the model (MLE): <span class="math display">\[F = -\frac{1}{N}\sum_ncost_n(w_n,\hat{p_n})\]</span> The cost function is simply the model's estimated log-probability of <span class="math inline">\(w_n\)</span>: <span class="math display">\[cost(a, b) = a^T\log b\]</span> <img src="/images/NLP/NLM1T.png"></p><p>Calculating the gradients is straightforward with back propagation: <span class="math display">\[\frac{\partial F}{\partial W} = -\frac{1}{N}\sum_n \frac{\partial cost_n}{\partial \hat{p_n}}\frac{\partial \hat{p_n}}{\partial W}\]</span></p><p><span class="math display">\[\frac{\partial F}{\partial W} = -\frac{1}{N} \sum_n\frac{\partial cost_n}{\partial \hat{p_n}}\frac{\partial\hat{p_n}}{\partial h_n}\frac{\partial h_n}{\partial V}\]</span></p><p><strong>Comparison with Count Based N-Gram LMs</strong></p><p>Good</p><ul><li><p>Better generalisation on unseen n-grams, poorer on seen n-grams.</p><p>Solution: direct (linear) ngram features</p></li><li><p>Simple NLMs are often an order magnitude smaller in memory footprint than their vanilla n-gram cousins (though not if you use the linear features suggested above!)</p></li></ul><p>Bad</p><ul><li>The number of parameters in the model scales with the n-gram size and thus the length of the history captured.</li><li>The n-gram history is finite and thus there is limit on the longest dependencies that an be captured.</li><li>Mostly trained with Maximum Likelihood based objectives which do not encode the expected frequencies of words a priori.</li></ul><h2><span id="recurrent-neural-network-language-models">Recurrent Neural Network Language Models</span></h2><p>The major difference between RNN and Neural N-Gram model is RNN not only forward propagate the previous input (<span class="math inline">\(y_{n-1}\)</span>) to next layer but also forward propagate the previous <strong>state</strong> (<span class="math inline">\(h_{n-1}\)</span>).</p><p><img src="/images/NLP/RNN.png"></p><p><strong>BPTT</strong></p><p><strong>Back Propagation Through Time</strong> (BPTT) note the dependence of derivatives at time <span class="math inline">\(n\)</span> with those at time <span class="math inline">\(n + \alpha\)</span>.</p><p><img src="/images/NLP/BPTT.png"></p><p><strong>TBPTT</strong></p><p>If we break these dependencies after a fixed number of time steps we get <strong>Truncated Back Propagation Through Time</strong> (TBPTT).</p><p>![(/images/NLP/TBPTT.png)</p><p><strong>Comparison with N-Gram LMs</strong></p><p>Good</p><ul><li>RNNs can represent unbounded dependencies, unlike models with a fixed n-gram order.</li><li>RNNs compress history of words into a fixed size hidden vector.</li><li>The number of parameters does not grow with the length of dependencies captured, but they do grow with the amount of information stored in the hidden layer.</li></ul><p>Bad</p><ul><li>RNNs are hard to learn and often will not discover long range dependencies present in the data.</li><li>Increasing the size of the hidden layer, and thus memory, increases the computation and memory quadratically.</li><li>Mostly trained with Maximum Likelihood based objectives which do not encode the expected frequencies of words a priori.</li></ul><p><strong>Exploding and Vanishing Gradients</strong></p><p>Consider the path of partial derivatives linking a change in <span class="math inline">\(cost_N\)</span> to changes in <span class="math inline">\(h_1\)</span>:</p><p><img src="/images/eqq.png"></p><p>where</p><p><span class="math display">\[h_n  = g(V_xx_n + V_hh_{n-1} + c) = g(z_n)\]</span></p><p><span class="math display">\[\frac{\partial h_n}{\partial z_n} = diag(g&#39;(z_n))\]</span></p><p>The core of the recurrent product is the repeated multiplication of <span class="math inline">\(V_h\)</span>. If the <strong>largest eigenvalue</strong> of <span class="math inline">\(V_h\)</span> is:</p><ul><li><span class="math inline">\(1\)</span>, then gradient will <strong>propagate</strong>,</li><li><span class="math inline">\(&gt;1\)</span>, the product will grow exponentially (<strong>explode</strong>),</li><li><span class="math inline">\(&lt;1\)</span>, the prodcut shrinks exponentially (<strong>vanishes</strong>).</li></ul><p>Most of the time the spectral radius of <span class="math inline">\(V_h\)</span> is <strong>small</strong>. The result is that the gradient vanishes and <strong>long range dependencies</strong> are <strong>not</strong> learnt.</p><h3><span id="long-short-term-memory-lstm">Long Short Term Memory (LSTM)</span></h3><p>The original RNN is:</p><p><img src="/images/NLP/origin.png"></p><p>Then adding a linear layer of current input and previous state and then going through a tanh non-linearity before passing to the current state:</p><p><img src="/images/NLP/2nd.png"></p><p>The next step is to introduce an extra hidden layer called cell-state (<span class="math inline">\(c\)</span>), and think it as our memory. The really cool thing is that propagation is <strong>additive</strong>. The <strong>key innovation</strong> of LSTM is replacing the <strong>multiplication</strong> with <strong>sum</strong>.</p><p><img src="/images/NLP/3rd.png"></p><p>How to balance the grow of addition?</p><p>The method is called <strong>Gating</strong>. So we are going to do is gating the input of the hidden layer, which is called <em>input gate</em>, represented by <span class="math inline">\(i\)</span>. The gate in neural network, is to compute a non-linearity, which is bound between 0 and 1. We think it like a <strong>switch</strong>, if 1, we turn on the connection and if 0, we shut off the connection. The key thing is the gate is <strong>not</strong> a <strong>decret binary</strong> function <strong>but</strong> a <strong>continuous</strong> function, thus we can differentiate and back propagation through it.</p><p>If the gate is 1, the input would contribute to the current state, if the gate is 0, the input would not affect the current state, so the gate gives <strong>state</strong> ability to <strong>ignore the input</strong>.</p><p><img src="/images/NLP/4th.png"></p><p>We already have the ability to include or ignore the input, but we can't forget things. So next we are going to add a <strong>forget gate</strong>, represented by <span class="math inline">\(f\)</span>.</p><p><img src="/images/NLP/5th.png"></p><p>So given the <span class="math inline">\(i\)</span> and <span class="math inline">\(f\)</span>, our network has the ability to include something new and decide what to remember depend on the input to the next cell state.</p><p>The final step is to add a <em>output gate</em>, represented by <span class="math inline">\(o\)</span>, between the cell state to the current state.</p><p><img src="/images/NLP/6th.png"></p><p><img src="/images/NLP/LSTM.png"></p><p>The LSTM cell : <span class="math display">\[c_n = f_n \circ c_{n-1} + i_n \circ \hat{c_n}\]</span></p><p><span class="math display">\[\begin{align}\hat{c_n} &amp;= \tanh (W_c[w_{n-1};h_{t-1}] + b_c)\\h_n &amp;= o_n \circ \tanh (W_h c_n + b_h)\\i_n &amp;= \sigma (W_i[w_{n-1}; h_{t-1}] + b_i)\\f_n &amp;= \sigma (W_f[w_{n-1}; h_{t-1}] + b_f)\\o_n &amp;= \sigma (W_o[w_{n-1}; h_{t-1}] + b_o)\end{align}\]</span></p><p><strong>Gated Recurrent Unit (GRU)</strong></p><p><img src="/images/NLP/GRU.png"></p><p><strong>LSTMs and GRUs</strong></p><p>Good</p><ul><li>Careful initialisation and optimisation of vanilla RNNs can enable then to learn long(ish) dependencies, but gated additive cells, like the LSTM and GRU, often just work.</li><li>The (re)introduction of LSTMs has been key to many recent developments, e.g. Neural Machine Translation, Speech Recognition, TTS, etc.</li></ul><p>Bad</p><ul><li>LSTMs and GRUs have considerably more parameters and computation per memory cell than a vanilla RNN, as such they have less memory capacity per parameter.</li></ul><h3><span id="deep-rnn-lms">Deep RNN LMs</span></h3><p>The memory capacity of an RNN can be increased by employing a larger hidden layer <span class="math inline">\(h_n\)</span>, but a linear increase in <span class="math inline">\(h_n\)</span> results in quadratic increase in model size and compution:</p><p><img src="/images/NLP/DRNN11.png"></p><p>Alternatively we can increase depth in the time dimension. This improves the representational ability, but not the memory capacity.</p><p><img src="/images/NLP/DRNN2.png"></p><p><strong>Regularisation : Dropout</strong></p><p>Large recurrent networks often overfit their training data by memorising the sequences observed. Such models generalise poorly to novel sequences.</p><p>A common approach in Deep Learning is to overparametrise a model, such that it could easily memorise the training data, and then heavily regularise it to facilitate generalisation.</p><p>The regularisation method of choice is often Dropout.</p><p>Dropout is ineffective when applied to recurrent connections, as repeated random masks zero all hidden units in the limit. The most common solution is to only apply dropout to <strong>non-recurrent</strong> connections.</p><p><img src="/images/NLP/Dropout.png"></p><p><strong>Summary</strong></p><p>Long Range Dependencies</p><ul><li>The repeated multiplication of the recurrent weights <span class="math inline">\(V\)</span> lead to vanishing (or exploding) gradients,</li><li>additive gated architectures, such as LSTMs, significantly reduce this issue.</li></ul><p>Deep RNNs</p><ul><li>Increasing the size of the recurrent layer increases memory capacity with a quadratic slow down,</li><li>deepening networks in both dimensions can improve their representational efficiency and memory capacity with a linear complexity cost.</li></ul><p>Large Vocabularies</p><ul><li>Large vocabularies, <span class="math inline">\(V &gt; 10^4\)</span>, lead to slow softmax calculations,</li><li>reducing the number of vector matrix products evaluated,by factorising the softmax or sampling, reduces the training overhead significantly.</li><li>Different optimisations have different training and evaluation complexities which should be considered.</li></ul><p><strong>Readings</strong></p><p>Textbook</p><ul><li>Deep Learning, Chapter 10</li></ul><p>Blog Posts</p><ul><li>Andrej Karpathy: <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li><li>Yoav Goldberg: <a href="http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139" target="_blank" rel="noopener">The unreasonable effectiveness of Character-level Language Models</a></li><li>Stephen Merity: <a href="http://smerity.com/articles/2016/orthogonal_init.html" target="_blank" rel="noopener">Explaining and illustrating orthogonal initialization for recurrent neural networks</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> RNN </tag>
            
            <tag> LSTM </tag>
            
            <tag> Language Model </tag>
            
            <tag> N-Gram </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep NLP - Word Level Semantics</title>
      <link href="/2017/08/05/DeepNLP-Word%20Level%20Semantics/"/>
      <url>/2017/08/05/DeepNLP-Word%20Level%20Semantics/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#word-level-semantics">Word Level Semantics</a><ul><li><a href="#count-based-methods">Count-based methods</a></li><li><a href="#neural-embedding-models">Neural Embedding Models</a><ul><li><a href="#cw">C&amp;W</a></li><li><a href="#cbow">CBoW</a></li><li><a href="#skip-gram">Skip-gram</a></li></ul></li><li><a href="#task-based-embedding-learning">Task-based Embedding Learning</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="word-level-semantics">Word Level Semantics</span></h2><h3><span id="count-based-methods">Count-based methods</span></h3><ul><li>Define a <strong>basis vocabulary</strong> <span class="math inline">\(C\)</span> of context words</li><li>Define a <strong>word window</strong> size <span class="math inline">\(w\)</span></li><li><strong>Count the basis vocabulary words</strong> occurring <span class="math inline">\(w\)</span> words to the left or right of each instance of a <strong>target</strong> word in the corpus.</li><li>Form a <strong>vector representation</strong> of the target word based on these counts.</li></ul><p><strong>Example</strong>:</p><ul><li>... and the cute kitten purred and then ...</li><li>... the cute furry cat purred and miaowed ...</li><li>... that the small kitten miaowed and she ...</li><li>... the loud furry dog ran and bit ...</li></ul><p>Example <strong>basis vocabulary</strong>: {bit, cute, furry, loud, miaowed, purred, ran, small}.</p><ul><li><strong>kitten</strong> context words: {cute, purred, small, miaowed}.</li><li><strong>cat</strong> context words: {cute, furry, miaowed}.</li><li><strong>dog</strong> context words: {loud, furry, ran, bit}.</li></ul><p>Therefore</p><ul><li><span class="math inline">\(kitten = [0, 1, 0, 0, 1, 1, 0, 1]^T\)</span></li><li><span class="math inline">\(cat = [0, 1, 1, 0, 1, 0, 0, 0]^T\)</span></li><li><span class="math inline">\(dog = [1, 0, 1, 1, 0, 0, 1, 0]^T\)</span></li></ul><h3><span id="neural-embedding-models">Neural Embedding Models</span></h3><ul><li><p>Learning count based vetors produces an <strong>embedding matrix</strong> <span class="math inline">\(E\)</span> in <span class="math inline">\(R^{|vocab|*|context|}\)</span>.</p><p><img src="/images/NLP/embed.png"></p></li><li><p>Rows are word vectors = <strong>one hot vector</strong></p><ul><li><span class="math inline">\(cat = onehot^T_{cat}E\)</span></li></ul></li></ul><p>General idea behind embedding learning:</p><ol type="1"><li>Collect instances <span class="math inline">\(t_i \in inst(t)\)</span> of a word <span class="math inline">\(t\)</span> of vocab <span class="math inline">\(V\)</span></li><li>For each instance, collect its context words <span class="math inline">\(c(t_i)\)</span> (e.g. k-word window)</li><li>Define some score function <span class="math inline">\(socre(t_i, c(t_i); \theta, E)\)</span> with upper bound on output</li><li>Define a loss</li><li>Estimate</li><li>Use the estimated <span class="math inline">\(E\)</span> as your embedding matrix</li></ol><h4><span id="campw">C&amp;W</span></h4><p><img src="/images/NLP/C&amp;W.png"></p><h4><span id="cbow">CBoW</span></h4><p><img src="/images/NLP/CBoW.png"></p><p>word2vec详解：http://blog.csdn.net/itplus/article/details/37969979</p><h4><span id="skip-gram">Skip-gram</span></h4><p><img src="/images/NLP/Skip-Gram.png"></p><h3><span id="task-based-embedding-learning">Task-based Embedding Learning</span></h3><p>Neural network parameters are updated using gradients on loss <span class="math inline">\(L(x, y, \theta)\)</span> <span class="math display">\[\theta_{t+1} = update(\theta_t, \triangledown_\theta L(x, y, \theta_t))\]</span> If <span class="math inline">\(E \in \theta\)</span> then this update can modify <span class="math inline">\(E\)</span> : <span class="math display">\[E_{t+1} = update(E_t, \triangledown_E L(x, y, \theta_t))\]</span> General intuition: learn to classify/predict/generate based on features, but also the <strong>features themselves</strong>.</p><ul><li>Bow Classifiers</li><li>Bilingual Features</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> NLP </tag>
            
            <tag> Deep NLP </tag>
            
            <tag> Word2Vec </tag>
            
            <tag> CBoW </tag>
            
            <tag> Skip-gram </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Regularization for Deep Learning</title>
      <link href="/2017/07/13/Regularization%20for%20Deep%20Learning/"/>
      <url>/2017/07/13/Regularization%20for%20Deep%20Learning/</url>
      
        <content type="html"><![CDATA[<p>定义：Any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.</p><!-- toc --><ul><li><a href="#parameter-norm-penalties">Parameter Norm Penalties</a><ul><li><a href="#l2-parameter-regularzation"><span class="math inline">\(L^2\)</span> Parameter Regularzation</a></li><li><a href="#l1-regularization"><span class="math inline">\(L^1\)</span> Regularization</a></li></ul></li><li><a href="#regularization-and-under-constrained-problems">Regularization and Under-Constrained Problems</a></li><li><a href="#dataset-augmentation">Dataset Augmentation</a></li><li><a href="#noise-robustness">Noise Robustness</a></li><li><a href="#multi-task-learning">Multi-Task Learning</a></li><li><a href="#early-stopping">Early Stopping</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="parameter-norm-penalties">Parameter Norm Penalties</span></h2><p>通过限制模型的能力来正则化，通常在目标函数中加入惩罚项 <span class="math inline">\(\Omega(\theta)\)</span>: <span class="math display">\[\hat{J}(\theta; X, y) = J(\theta; X, y) + \alpha \Omega(\theta)\]</span> 这样模型在训练的时候不但会减小原来的 <span class="math inline">\(J\)</span> ，也会尽量减小惩罚项 <span class="math inline">\(\Omega\)</span>，从而达到防止过拟合的效果。</p><p>需要注意的是，在神经网络中只需要正则化网络中的<strong>权重（weights）</strong>，而偏置不需要正则化，一方面是因为相对于权重，偏置很容易被拟合（使用较少的数据），也没有权重重要，权重需要观察两个变量在各种条件下的情况来进行拟合，而偏置只需考虑一个变量，所以不惩罚偏置也不会对过拟合造成多大影响；另一方面是因为如果对偏置业也进行惩罚则容易造成欠拟合。所以之后用 <span class="math inline">\(w\)</span> 表示所有权重，而 <span class="math inline">\(\theta\)</span> 表示全部参数。</p><h3><span id="l2-parameter-regularzation"><span class="math inline">\(L^2\)</span> Parameter Regularzation</span></h3><p><span class="math inline">\(L^2\)</span> 正则化又叫 weight decay，岭回归（ridge regression）和 Tikhonov regularization。它在目标函数后加上惩罚项 <span class="math inline">\(\Omega(\theta) = \frac{1}{2}||w||^2_2\)</span>，这使得权重趋近于向原点方向更新。</p><p>我们可以从梯度更新的角度来理解正则化是怎么工作的，为了简化，假设模型里无偏置参数，即 <span class="math inline">\(\theta = w\)</span>，所以目标函数如下： <span class="math display">\[\hat{J}(w;X,y) = \frac{\alpha}{2}w^Tw + J(w;X,y)\]</span> 对 <span class="math inline">\(w\)</span> 求梯度： <span class="math display">\[\bigtriangledown_w\hat{J}(w; X, y) = \alpha w+\bigtriangledown_wJ(w; X,y)\]</span> 所以梯度更新公式为： <span class="math display">\[\begin{align}w &amp;\leftarrow w - \epsilon(\alpha w + \bigtriangledown_wJ(w;X,y)) \\w&amp; \leftarrow (1-\epsilon\alpha)w - \epsilon\bigtriangledown_wJ(w;X,y)\end{align}\]</span> 可以见得，每次更新梯度时都先会按照一定的因子缩小 <span class="math inline">\(w\)</span>，然后在执行正常的梯度下降。</p><p>这是执行一步梯度下降发生的事情，若在整个 training 期间都执行此规则会发生什么呢？</p><blockquote><p>线性逼近（Linear approximation）</p><blockquote><p>函数 <span class="math inline">\(f(x)\)</span> 在点 <span class="math inline">\(a\)</span> 处的最佳线性逼近 <span class="math inline">\(L_a(x)\)</span> 要满足: <span class="math inline">\(L_a(a) = f(a)\)</span> 且 <span class="math inline">\(L_a&#39;(a) = f&#39;(a)\)</span>，这样可以构造出 <span class="math inline">\(L_a(x) = f(a) + f&#39;(a)(x-a)\)</span>。</p></blockquote><p>二次逼近（Quadratic approximation）</p><blockquote><p>函数 <span class="math inline">\(f(x)\)</span> 在点 <span class="math inline">\(a\)</span> 处的最佳二次逼近 <span class="math inline">\(Q_a(x)\)</span> 要满足：</p><ul><li><span class="math inline">\(Q_a(a) = f(a)\)</span></li><li><span class="math inline">\(Q_a&#39;(a) = f&#39;(a)\)</span></li><li><span class="math inline">\(Q_a&#39;&#39;(a) = f&#39;&#39;(a)\)</span></li></ul><p>通过这三个条件可以构造出 <span class="math inline">\(Q_a(x) = f(a) + f&#39;(a)(x-a)+\frac{1}{2}f&#39;&#39;(a)(x-a)^2\)</span></p><p>也可以根据泰勒公式理解，把 <span class="math inline">\(f(x)\)</span> 在 <span class="math inline">\(a\)</span> 点进行泰勒展开，只保留到二阶导。</p></blockquote></blockquote><p>为了简化问题，我们在最优点 <span class="math inline">\(w^* = \arg\min_wJ(w)\)</span> 用二次逼近（quadratic approximation）拟合原目标函数，得到新的近似目标函数： <span class="math display">\[\hat{J}(w) = J(w^*)+\frac{1}{2}(w-w^*)^TH(w-w*)\]</span> 其中 <span class="math inline">\(H​\)</span> 为 <span class="math inline">\(J​\)</span> 对 <span class="math inline">\(w​\)</span> 的海森矩阵（Hessian matrix），它是由二阶偏导数组成的方阵，若 <span class="math inline">\(w = [w_1, w_2, …, w_n]​\)</span>，则： <span class="math display">\[H = \begin{bmatrix}\frac{\partial^2J}{\partial w_1^2}    &amp; \frac{\partial^2J}{\partial w_1\partial w_2}  &amp; \cdots &amp; \frac{\partial^2J}{\partial w_1\partial w_n}      \\\vdots &amp; \ddots &amp; \vdots \\\frac{\partial^2J}{\partial w_n\partial w_1} &amp; \frac{\partial^2J}{\partial w_n\partial w_2}      &amp; \cdots &amp; \frac{\partial^2J}{\partial w_n^2}\end{bmatrix}\]</span> 我们发现上式中没有一阶偏导数，那是因为 <span class="math inline">\(J\)</span> 的一阶导数在最优点 <span class="math inline">\(w^*\)</span> 的值为 <span class="math inline">\(0\)</span>，即 <span class="math inline">\(J&#39;(w^*) = 0\)</span>。</p><p>当 <span class="math inline">\(\hat{J}\)</span> 取得最小值时，它的梯度 <span class="math display">\[\bigtriangledown_w\hat{J}(w) = H(w - w^*)\]</span> 等于 <span class="math inline">\(0​\)</span>。</p><p>为了研究正则化的影响，我们修改上式，加入 weight decay gradient，我们用 <span class="math inline">\(\hat{w}\)</span> 表示正则化后的 <span class="math inline">\(\hat{J}\)</span> 的最小值的位置，可以解得： <span class="math display">\[\alpha\hat{w} + H(\hat{w}-w^*) = 0\]</span></p><p><span class="math display">\[(H+\alpha I)\hat{w} = Hw^*\]</span></p><p><span class="math display">\[\hat{w} = (H+\alpha I)^{-1}Hw^*\]</span></p><p>可以看出，当 <span class="math inline">\(\alpha\)</span> 趋近于 <span class="math inline">\(0\)</span> 时，<span class="math inline">\(\hat{w} \approx w^*\)</span>，那当 <span class="math inline">\(\alpha\)</span> 较大时会发生什么呢？</p><p>因为 <span class="math inline">\(H\)</span> 由实数组成且对称，所以 <span class="math inline">\(H\)</span> 可以分解为一个对角阵 <span class="math inline">\(\Lambda\)</span> 和正交矩阵 <span class="math inline">\(Q\)</span> 的乘积： <span class="math display">\[H = Q\Lambda Q^T\]</span> 其中，<span class="math inline">\(\Lambda\)</span> 中对角线的元素为 <span class="math inline">\(H\)</span> 的特征值，<span class="math inline">\(Q\)</span> 的每一列为对应的特征向量。</p><p>由此可以进一步化简： <span class="math display">\[\begin{align}\hat{w} &amp; = (Q\Lambda Q^T+\alpha I)^{-1}Q\Lambda Q^Tw^* \\&amp; = [Q(\Lambda+\alpha I)Q^T]^{-1}Q\Lambda Q^T w^* \\&amp; = (Q^{T})^{-1}(\Lambda+\alpha I)^{-1}Q^{-1}Q\Lambda Q^T w^* \\&amp; = Q(\Lambda+\alpha I)^{-1}\Lambda Q^T w^* \\\end{align}\]</span> 令 $ =Q(+I)<sup>{-1}Q</sup>T $，则 <span class="math inline">\(\hat{H}\)</span> 的任意特征值 <span class="math inline">\(\hat{\lambda_i}\)</span> 与 <span class="math inline">\(H\)</span> 里对应的特征值 <span class="math inline">\(\lambda_i\)</span> 有如下关系： <span class="math display">\[\hat{\lambda_i} = \frac{\lambda_i}{\lambda_i+\alpha}\]</span> 所以 <span class="math inline">\(L^2\)</span> 正则化的效果就是把 <span class="math inline">\(w^*\)</span> 沿着 <span class="math inline">\(H\)</span> (或 <span class="math inline">\(\hat{H}\)</span>) 的特征向量所定义的方向重新调整大小（rescale）。其中，<span class="math inline">\(w^*\)</span> 中沿着 <span class="math inline">\(H\)</span> 的第 <span class="math inline">\(i\)</span> 个特征向量方向的成分被扩大了 <span class="math inline">\(\frac{\lambda_i}{\lambda_i+\alpha}\)</span> 倍。</p><blockquote><p><img src="/images/f2.3.png"></p></blockquote><p>那些大特征值对应的特征向量的方向，<span class="math inline">\(\lambda_i\gg \alpha\)</span>，正则化的效果很小；而那些小特征值对应的方向，<span class="math inline">\(\lambda_i \ll \alpha\)</span>，<span class="math inline">\(w^*\)</span> 相应方向的成分就很容易缩小到 <span class="math inline">\(0\)</span>，正则化效果很明显。</p><p>得出后面的结论还有一个前提，就是梯度大的方向对应的 <span class="math inline">\(H\)</span> 的特征值也大，由此可得：<strong>只有那些对减小目标函数梯度影响很大的方向的成分才不受正则化影响；那些对梯度下降影响不大的方向，会得到一个较小的特征值，从而使那些不重要方向的成分在训练中一直在缩小</strong>。</p><p><img src="/images/f7.1.png"></p><p>上面我们讨论了泛化的、通用的情况下 <span class="math inline">\(L^2\)</span> 正则化的作用，下面来看一个线性回归的具体实例。线性回归的均方误差目标函数为： <span class="math display">\[(Xw-y)^T(Xw-y)\]</span> 增加 <span class="math inline">\(L^2\)</span> 正则化之后变成： <span class="math display">\[(Xw-y)^T(Xw-y)+\frac{1}{2}\alpha w^Tw\]</span> 解出 <span class="math inline">\(w\)</span> 的正规方程也从 <span class="math display">\[w = (X^TX)^{-1}X^Ty\]</span> 变为： <span class="math display">\[w=(X^TX+\alpha I)^{-1}X^Ty\]</span> 可见，下面的式子只是把 <span class="math inline">\((X^TX)^{-1}\)</span> 换成了 <span class="math inline">\((X^TX+\alpha I)^{-1}\)</span>， 在 <span class="math inline">\(X^TX\)</span> 的对角线上多加了 <span class="math inline">\(\alpha\)</span> 。但是 <span class="math inline">\(X^TX\)</span> 对角线上的元素对应的就是输入特征的方差，也就是<span class="math inline">\(L^2\)</span>正则化增加了输入特征的方差，从而迫使模型去降低那些没有用（与输出目标的协方差很低）的特征的权重。</p><h3><span id="l1-regularization"><span class="math inline">\(L^1\)</span> Regularization</span></h3><p>对于 <span class="math inline">\(L^1\)</span> 正则化，它的惩罚项就是权重 <span class="math inline">\(w\)</span> 的1范数： <span class="math display">\[\Omega(\theta) = ||w||_1 = \sum_i|w_i|\]</span> 还像上面一样不考虑偏置参数，<span class="math inline">\(\alpha\)</span> 为正则化因子，则使用 <span class="math inline">\(L^1\)</span> 正则化的目标函数为： <span class="math display">\[\hat{J}(w;X,y) = \alpha||w||_1 + J(w;X,y)\]</span> 相应的梯度为： <span class="math display">\[\bigtriangledown_w\hat{J}(w;X,y) = \alpha sign(w) + \bigtriangledown_wJ(w;X,y)\]</span> 其中 <span class="math inline">\(sign\)</span> 为符号函数，大于 <span class="math inline">\(0\)</span> 值为 <span class="math inline">\(1\)</span>，小于 <span class="math inline">\(0\)</span> 值为 <span class="math inline">\(-1\)</span>，等于 <span class="math inline">\(0\)</span> 值为 <span class="math inline">\(0\)</span> 。</p><p>这里可以看出，<span class="math inline">\(L^1\)</span> 正则化不是在按照一定比例来缩小参数 <span class="math inline">\(w\)</span>，而是每步增加或减少一个常量。</p><p>为了观察整体训练过程中正则化的影响，我们继续用在最优点 <span class="math inline">\(w^*\)</span> 的二次逼近来拟合目标函数： <span class="math display">\[\hat{J}(w) = J(w^*)+\frac{1}{2}(w-w^*)^TH(w-w*)\]</span> 相应的梯度为： <span class="math display">\[\bigtriangledown_w\hat{J}(w) = H(w - w^*)\]</span> 这里的 <span class="math inline">\(H\)</span> 依旧是海森矩阵，由于 <span class="math inline">\(L^1\)</span> 惩罚相不保证可以用一个代数式表示（clean algebraic expression），所以假设 <span class="math inline">\(H\)</span> 是个对角阵，<span class="math inline">\(H = diag([H_{1,1}, …, H_{n,n}])\)</span>，并且每个 <span class="math inline">\(H_{i,i} &gt; 0\)</span>。只要 Linear Regression 的输入特征直接没有关联（correlation）就可以保证上述假设成立，而这一点可以通过PCA做到。</p><p>加上 <span class="math inline">\(L^1\)</span> 正则化的目标函数为： <span class="math display">\[\hat{J}(w;X,y) = J(w^*; X,y) + \sum_i\left[ \frac{1}{2}H_{i,i}(w_i-w^*_i)^2+\alpha|w_i| \right]\]</span> 最小化该目标函数可得： <span class="math display">\[w_i = sign(w^*_i)\max\left\{|w^*_i| - \frac{\alpha}{H_{i,i}}, 0\right\}\]</span> 考虑所有 <span class="math inline">\(w_i^* &gt; 0\)</span>，有两种可能结果：</p><ol type="1"><li>当 <span class="math inline">\(w_i^*≤\frac{\alpha}{H_{i,i}}\)</span> 时，<span class="math inline">\(w_i\)</span> 的最优解为 <span class="math inline">\(0\)</span>。This occurs because the contribution of <span class="math inline">\(J(w;X,y)\)</span> to the regularized objective <span class="math inline">\(\hat{J}(w;X,y)\)</span> is overwhelmed—in direction <span class="math inline">\(i\)</span> —by the <span class="math inline">\(L^1\)</span> regularization which pushes the value of <span class="math inline">\(w_i\)</span> to zero.</li><li>当 <span class="math inline">\(w_i^*≥\frac{\alpha}{H_{i,i}}\)</span> 时，这是最优的 <span class="math inline">\(w_i\)</span> 不会为 <span class="math inline">\(0\)</span>，而是会向 <span class="math inline">\(0\)</span> 的方向移动 <span class="math inline">\(\frac{\alpha}{H_{i,i}}\)</span> 的距离。</li></ol><p>当所有 <span class="math inline">\(w^*_1 &lt; 0\)</span> 时也有类似的结果。</p><p>和 <span class="math inline">\(L^2\)</span> 正则化相比，<span class="math inline">\(L^1\)</span> 正则化趋向于使权重变的稀疏（sparse），也就是说一部分参数的最优值为 <span class="math inline">\(0\)</span>。如果我们用同样的假设分析 <span class="math inline">\(L^2\)</span> 正则化，则会得到 <span class="math inline">\(\hat{w}_i = \frac{H_{i,i}}{H_{i,i}+\alpha}w^*_i\)</span>，只要 <span class="math inline">\(w_i^*\)</span> 非零，<span class="math inline">\(\hat{w}_i\)</span> 一定也非零。所以 <span class="math inline">\(L^2\)</span> 正则化不会使参数变稀疏，而 <span class="math inline">\(L^1\)</span> 正则化在 <span class="math inline">\(\alpha\)</span> 很大的情况下会。</p><p><span class="math inline">\(L^1\)</span> 正则化的这个性质可以用来做<strong>特征选择（feature selection）</strong>，如果某个特征对模型收敛帮助不大，则它对应的权重会收缩到 <span class="math inline">\(0\)</span>，我们就可以去掉那些用处不大的特征。</p><blockquote><p>Maximum A Posteriori (MAP) Estimation <span class="math display">\[\theta_{MAP} = \arg\max_\theta p(\theta|x) = \arg\max_\theta \log p(x|\theta)+\log p(\theta)\]</span> Maximum Likelihood Estimator (MLE) <span class="math display">\[\theta_{ML} = \arg\max_\theta p(X;\theta)\]</span></p></blockquote><p><strong>正则化与参数估计之间的关系</strong></p><p>使用均方误差的线性回归可以看作是对参数 <span class="math inline">\(w\)</span> （如果 <span class="math inline">\(w\)</span> 的先验服从 <span class="math inline">\(N(w;0,\frac{1}{\lambda}I^2)\)</span>）的最大似然估计（MLE），如果加上 <span class="math inline">\(L^2\)</span> 正则化项 <span class="math inline">\(\lambda w^T w\)</span> 的话，则变成了对参数 <span class="math inline">\(w\)</span> 的最大后验估计（MAP），因为： <span class="math display">\[\log p(w) = \log N(w;0,\frac{1}{\lambda}I^2)=\log\frac{\lambda}{\sqrt{2\pi}} - \frac{1}{2}\lambda w^Tw\]</span> 而 <span class="math inline">\(L^1​\)</span> 正则化则相当于 <span class="math inline">\(w​\)</span> 的先验估计服从各向同性拉普拉斯分布（isotropic Laplace distribution）： <span class="math display">\[\log p(w) = \sum_i\log Laplace(w_i; 0, \frac{1}{\alpha}) = -\alpha ||w||_1 + n\log\alpha -n\log2\]</span> 我们可以忽略 <span class="math inline">\(n\log\alpha -n\log2\)</span> 因为它们不依赖于 <span class="math inline">\(w\)</span>。</p><h2><span id="regularization-and-under-constrained-problems">Regularization and Under-Constrained Problems</span></h2><p>正则化不光可以解决过拟合问题，还可以解决其他很多问题。</p><p>比如求解线性回归中，正规方程为 <span class="math inline">\(w = (X^TX)^{-1}X^Ty\)</span>，但 <span class="math inline">\(X^TX\)</span> 有可能是不可逆的，比如特征多但样本少的时候， <span class="math inline">\(X^TX\)</span> 就不可逆，这时候如果加上 <span class="math inline">\(L^2\)</span> 正则项，变成 <span class="math inline">\(X^TX+\alpha I\)</span>，这可以保证一定是可逆的。</p><p>还有一种情况，在 Logistic 回归中，假设数据集是线形可分的，如果参数 <span class="math inline">\(w\)</span> 可以完美的进行分类，那么 <span class="math inline">\(2w\)</span> 一定也可以，而且会有更大的似然。这样循环更新的算法（梯度下降）就会使 <span class="math inline">\(w\)</span> 不断增大，直到发生溢出。而加上正则化可以防止这种情况的发生，比如加上 <span class="math inline">\(L^2\)</span> 正则项，当权重衰减的指数和似然的坡度持平时，就会停止增大参数。（For example, weight decay will cause gradient descent to quit increasing the magnitude of the weights when the slope of the likelihood is equal to the weight decay coeﬃcient.）</p><p>再比如求 Moore-Penrose 伪逆： <span class="math display">\[X^+ = \lim_{\alpha\rightarrow0}(X^TX+\alpha I)^{-1}X^T\]</span> 我们现在可以认为上式是在求带 <span class="math inline">\(L2\)</span> 正则项的线性回归，也就可以把它解释为用正则化解决欠问题（underdetermined problems）。</p><h2><span id="dataset-augmentation">Dataset Augmentation</span></h2><p>数据集增强是提高机器学习模型泛化能力的一种方法，主要应用于分类算法中，操作通常包括对输入添加白噪声、对输入进行变换、对神经网络中间添加噪声等，但注意对输入变换时不要改变标签值。这种数据集增强的方法被证明在物体识别和语音识别方面很有作用。</p><p>但在比较两个机器学习模型好坏时，一定要在相同的数据集和数据集增强操作的情况下进行比较。</p><h2><span id="noise-robustness">Noise Robustness</span></h2><p><strong>Injecting Noise at the Output Targets</strong></p><p>因为大多数数据集都包含错误标签，若 <span class="math inline">\(y\)</span> 是错误的则最大化 <span class="math inline">\(\log p(y|x)\)</span> 将会带来很大危害。一个解决办法是给标签添加噪声，比如假设一个小常量 <span class="math inline">\(\epsilon\)</span> ，训练集中 <span class="math inline">\(1-\epsilon\)</span> 的概率的标签是正确的，剩下 <span class="math inline">\(\epsilon\)</span> 概率的标签则不一定。我们不用实际在样本中加入噪声，而是直接把 <span class="math inline">\(\epsilon\)</span> 嵌入到目标函数中。比如 <strong>label smoothing</strong> 技术把hard target <span class="math inline">\(0\)</span> 和 <span class="math inline">\(1\)</span> 替换成 <span class="math inline">\(\frac{\epsilon}{k-1}\)</span> 和 <span class="math inline">\(1-\epsilon\)</span>，标准的交叉熵损失就是为了处理这种 soft target。而事实上，最大似然学习 + softmax + hard target 根本不会收敛，因为 softmax 肯定不会输出绝对地 <span class="math inline">\(0\)</span> 或 <span class="math inline">\(1\)</span>。</p><h2><span id="multi-task-learning">Multi-Task Learning</span></h2><p>多任务学习也是一种提高模型泛化能力的方法，多个任务使用相同的输入，但输出不同，整个模型的参数分为两部分：</p><ol type="1"><li>任务相关的参数，只从任务相关的样本中优化参数，在下图中的上层</li><li>一般的参数，不与任务相关，可以从所有样本中更新参数，在下图中的底层（<span class="math inline">\(h^{(shared)}\)</span>）。</li></ol><p><img src="/images/f7.2.png"></p><p>从深度学习的角度来说：<em>among the factors that explain the variations observed in the data associated with the diﬀerent tasks, some are shared across two or more tasks</em>.</p><h2><span id="early-stopping">Early Stopping</span></h2><p>如果我们的机器学习模型拟合能力过强的话，就会发生这种情况，训练误差一直减小，但交叉验证的误差先减小，然后在某个值达到最小，后来又增大，如下图所示。</p><p><img src="/images/f7.3.png"></p><p>这时我们可以使用 <strong>early stopping 策略</strong>，在每次计算 validation loss 之后，把该 loss 与达到的最小值比较，若它小于最小值，则更新最小值并拷贝一份当前的参数；否则继续下一轮训练。训练结束返回拷贝的参数而不是最后一轮训练的参数。</p><p>Early stopping 策略是一种很常用正则化方法，因为它既有效又简单。它也可以看做是超参数选择的方法，因为训练的轮数也是个超参数，而应用 early stopping 策略就可以自动选择这个值，而不需要大量猜测。</p><p><strong>How early stopping acts as a regularizer</strong></p><p>Early stopping 会限制权重更新次数，即限制了权重（参数）远离初始权重的距离，如果最佳采取 <span class="math inline">\(\tau\)</span> 轮迭代，学习速率为 <span class="math inline">\(\epsilon\)</span> ，那么它俩的乘积 <span class="math inline">\(\epsilon\tau\)</span> 就类似于 <span class="math inline">\(L^2\)</span> 正则化中的系数！</p><p><img src="/images/f7.4.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Regularization </tag>
            
            <tag> L1 Norm </tag>
            
            <tag> L2 Norm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>物联网安全概论</title>
      <link href="/2017/07/06/%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%89%E5%85%A8%E6%A6%82%E8%AE%BA/"/>
      <url>/2017/07/06/%E7%89%A9%E8%81%94%E7%BD%91%E5%AE%89%E5%85%A8%E6%A6%82%E8%AE%BA/</url>
      
        <content type="html"><![CDATA[<p><strong>目录</strong></p><!-- toc --><ul><li><a href="#概论">概论</a></li><li><a href="#密码学基础">密码学基础</a></li><li><a href="#现代常规对称加密技术">现代常规对称加密技术</a><ul><li><a href="#des">DES</a></li><li><a href="#triple-des">Triple DES</a></li><li><a href="#aes">AES</a></li></ul></li><li><a href="#公钥密码">公钥密码</a><ul><li><a href="#随机数产生">随机数产生</a></li><li><a href="#公钥密码算法">公钥密码算法</a><ul><li><a href="#diffie-hellman密钥交换">Diffie-Hellman密钥交换</a></li><li><a href="#背包算法">背包算法</a></li><li><a href="#rsa算法">RSA算法</a></li></ul></li></ul></li><li><a href="#hash函数-数字签名与身份认证">Hash函数、数字签名与身份认证</a><ul><li><a href="#hash函数">Hash函数</a></li><li><a href="#数字签名">数字签名</a></li><li><a href="#身份认证">身份认证</a></li></ul></li><li><a href="#pki">PKI</a></li><li><a href="#基于身份加密体制">基于身份加密体制</a></li><li><a href="#物联网安全">物联网安全</a><ul><li><a href="#密码学在分布式传感器网络dsn中的应用">密码学在分布式传感器网络（DSN）中的应用</a></li><li><a href="#基于密码学的rfid认证">基于密码学的RFID认证</a></li><li><a href="#基于pke的rfid认证">基于PKE的RFID认证</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="概论">概论</span></h2><p><em>信息安全的含义</em></p><blockquote><p>信息安全是一门涉及计算机科学、网络技术、通信技术、密码技术、信息安全技术、应用数学、数论、信息论等多种学科的综合性科学。</p></blockquote><p>信息安全的整体目标</p><ul><li>物理安全<ul><li>防盗、防火、防静电、防雷击、防电磁泄漏</li></ul></li><li><em>逻辑安全</em><ul><li>计算机的逻辑安全需要用口令字、文件许可、查账等方法来实现</li></ul></li><li>操作系统安全</li><li>联网安全</li></ul><p><strong>安全四要素</strong></p><ul><li>保密性<ul><li>保证信息为授权者享用而不泄漏给未经授权者</li></ul></li><li>完整性<ul><li>数据完整性，未被未授权篡改或者损坏</li><li>系统完整性，系统未被非授权操纵，按既定的功能运行</li></ul></li><li><em>可用性</em><ul><li>保证信息和信息系统随时为授权者提供服务;不要出现由于非授权者的滥用，却对授权者拒绝服务的情况</li></ul></li><li><em>可靠性</em><ul><li>特定行为和结果的一致性</li><li>可靠性是指系统在规定条件下和规定时间内、完成规定功能的概率。可靠性是⽹网络安全最基本的要求之一，网络不可靠，事故不断，也就谈不上网络的安全。目前，对于⽹络可靠性的研究基本上偏重于硬件可靠性⽅面。研制⾼高可靠性元器件设备，采取合理的冗余备份措施仍是最基 本的可靠性对策，然而，有许多故障和事故，则与软件可靠性、⼈员可靠性和环境可靠性有关。</li><li>区分</li></ul></li></ul><p><em>威胁来源</em></p><ul><li><em>物理威胁</em><ul><li>偷窃、废物搜索、间谍行为、身份识别错误</li></ul></li><li><em>系统漏洞造成的威胁</em><ul><li>乘虚而入、不安全服务、配置和初始化</li></ul></li><li><em>身份鉴别威胁</em><ul><li>口令圈套（钓鱼）</li><li>口令破解</li><li>算法考虑不周</li><li>编辑口令</li><li>线缆连接威胁<ul><li>窃听</li><li>拨号进入</li><li>冒名顶替</li></ul></li></ul></li><li><em>有害程序威胁</em><ul><li>病毒</li><li>代码炸弹</li><li>特洛伊木马</li><li>更新或下载</li></ul></li></ul><p><em>安全威胁的分类</em></p><ul><li><em>中断</em>：系统的软、硬件资源由于各种各样的原因遭到破坏，使得程序的正常运⾏行行被中断或通信线路路 上数据的传送被中断。</li><li><em>窃取</em>：未经允许的⽤用户⾮非法获得了了对系统资源的访问权，从中窃取了了对他有⽤用的数据，或者骗取计 算机为他供了了某种服务。</li><li><em>篡改</em>：⾮非法⽤用户在获得了了对某项信息的访问权后，可以对它进⾏行行篡改，例例如修改程序使它完成⾮非法 操作者特定的功能，或者更更改数据，使⾃自⼰己获利利。在⽹网络上传送的信息也可能遭到篡改、添加，使 其结果对攻击者有利利，⽽而合法⽤用户⽆无法获得准确有⽤用的信息。</li><li><em>伪造</em>：攻击者在未经许可的情形下，在系统中产⽣生出虚假的数据或虚假的服务，例例如在电⼦子商务中，攻击者可能希望在⽹网络通信系统上加上⼀一些假的交易易，或在数据库中增加⼀一此伪造的记录，另 外在⽹网络通信中重放以前过时的信息等，使⽹网络使⽤用者落⼊入攻击者的陷井。</li><li><em>冒充</em>：假冒⽤用户身份是⼀一种常⻅见的⽹网络攻击⼿手段，例例如在甲、⼄乙双⽅方通信时，可能是丙在冒充⼄乙的 身份与甲通信，此时甲受到了了欺骗，由此引起甲受到经济甚⾄至政治上的损失。</li><li><em>抵赖</em>：某些⽤用户为了了⾃自⼰己的利利益，否认⾃自⼰己曾经发出的信息(如否认他发出的转帐信息)或者否认他 ⾃自⼰己收到了了信息。</li></ul><p><em>威胁原因</em></p><ul><li><em>薄弱的认证环节</em>：网络上的认证通常是使⽤用口令来实现的，但口令有公认的薄弱性。网上口令可以通过许多方法破译，其中最常用的两种方法是把加密的口令解密和通过信道窃取口令。</li><li><em>系统的易易被监视性</em>：⽤户使⽤Telnet或FTP连接他在远程 主机上的账户，在网上传的口令是没有加密的。入侵者可以通过监视携带用户名和口令的IP包获取它们，然后使⽤这些用户名和⼝令通过正常渠道登录到系统。如果被截获的是管理员的⼝令，那么获取特权级访问就变得更容易了。成千上万的系统就是被这种⽅方式侵⼊入的。</li><li><em>易欺骗性</em>：TCP或UDP服务相信主机的地址。如果使⽤“IP Source Routing”，那么攻击者的主机就可以冒充一个被信任的主机或客户。</li><li><em>有缺陷的网络服务和相互信任的主机</em>：主机的安全管理既困难有费时。为了降低管理要求并增强局域网，一些站点使⽤了诸如NIS和NFS之类的服务。这些服务通过允许一些数据库(如⼝令文件)以分布式⽅式管理以及允许系统共享⽂件和数据，在很⼤程度上减轻了过多的管理工作量。但这些服务带来了不不安全因素，可以被有经验闯入者利用以获得访问权。</li><li><em>复杂的设置和控制</em>：主机系统的访问控制配置复杂且难于验证。因此偶然的配置错误会使闯入者获取访问权。一些主要的Unix经销商仍然把Unix配置成具有最大访问权的系统，这将导致未经许可的访问。</li><li><em>无法估计主机的安全性</em>：主机系统的安全性⽆法很好的估计:随着一个站点的主机数量量的增加，确保每台主机的安全性都处在⾼⽔平的能力却在下降。只⽤管理⼀台系统的能力来管理理如此多的系统就容易犯错误。另一因素是系统管理的作⽤经常变换并行动迟缓。这导致⼀些系统的安全性⽐另一些要低。这些系统将成为薄弱环节，最终将破坏这个安全链。</li></ul><p><em>安全机制</em></p><ul><li>加密机制<ul><li>加密是提供信息保密的核⼼方法</li></ul></li><li><em>访问控制机制</em><ul><li>访问控制可以防止未经授权的用户非法使用系统资源，这种服务不仅可以供给单个用户，也可以供给用户组的所有用户。</li><li>分类<ul><li>自主访问控制<ul><li>⾃自主访问控制是指数据的拥有者有权决定系统中的哪些⽤用户对他的数据具有访问权，以及具有什么样的访问权。</li></ul></li><li>强制访问控制<ul><li>计算机系统根据事先确定的安全策略，对⽤用户的访问权限进⾏强制性的控制</li></ul></li><li>基于角色的访问控制<ul><li>为了反映实际工作中的需要，<em>可根据用户的工作职责设置若干角色</em>，不同的用户可以具有相同的角色，在系统中享有相同的权力，同一个用户又可以同时具有多个不同的角色，在系统中行使多个角色的权力。</li></ul></li></ul></li></ul></li><li><em>数据完整性机制</em><ul><li>数据单元的完整性<ul><li>是指组成一个单元的一段数据不被破坏和增删篡改</li></ul></li><li>数据序列的完整性<ul><li>是指发出的数据分割为按序列号编排的许多单元时，在接收时还能按原来的序列把数据串联起来，而不要发生数据单元的丢失、重复、乱序、假冒等情况。</li></ul></li></ul></li><li>数字签名机制<ul><li>解决：否认、伪造、冒充、篡改</li></ul></li><li>交换鉴别机制<ul><li>口令、密码技术、特征实物</li></ul></li><li>公证机制<ul><li>为了免得事后说不清，可以找一个大家都信任的公证机构，各方的交换的信息都通过公证机构来中转。公证机构从中转的信息里 取必要的证据，日后一旦发生纠纷，就可以据此做出仲裁</li></ul></li><li>流量填充机制<ul><li>流量填充机制能够保持流量基本恒定，因此观测者不能获取任何信息。流量填充的实现方法是:随机生成数据并对其加密，再通过网络发送</li></ul></li><li>路由控制机制<ul><li>路由控制机制使得可以指定通过网络发送数据的路径</li></ul></li><li>审计<ul><li>审计是模拟社会监察机构在计算机系统中用来监视、 记录和控制用户活动的一种机制，它使影响系统安全 的访问和访问企图留下线索，以便事后分析和追查。 现代安全计算机系统，除了要求有身份鉴别、访问控制、加密等安全措施外，还要求系统能对用户的行为进行有效的监控和记录，即要求有审计功能</li></ul></li></ul><h2><span id="密码学基础">密码学基础</span></h2><p><em>密码学背景</em></p><ul><li><em>通信保密</em>：60-70年代<ul><li>信息保密</li></ul></li><li><em>信息安全</em>：80-90年代<ul><li>机密性、完整性、可用性、不可否认性</li></ul></li><li><em>信息保障</em>：90年代-2004<ul><li>全生命周期的保护</li><li>信息保障是一种保证信息和信息系统能够安全运行的防护性行为，是信息安全在当前信息时代的新发展</li><li>目的是采取技术、管理等综合性手段，使信息和信息系统具备机密性、完整性、可用性、可认证性、不可否认性，以及在遭受攻击后的可恢复性</li><li><strong>可恢复性</strong>（热回滚）</li></ul></li><li><strong>密码学与访问控制的统一</strong>：2005-<ul><li>基础成功：<strong>基于身份密码学</strong></li><li>核心成果<ul><li>基于属性密码学(具有特定属性可解密)</li><li>代理重加密(数据拥有者可指定的解密)</li><li>可搜索加密(数据拥有者可委托的密文检索)</li><li>函数加密(满足特定函数可解密)</li><li>同态加密/签名(可计算的密文/签名)</li></ul></li><li>重要应用<ul><li>云存储安全</li><li>基于密码学的访问控制</li></ul></li></ul></li></ul><p><em>密码学基本概念</em></p><ul><li>矛：密码编码学</li><li>盾：密码分析学</li></ul><p><strong>密码算法分类</strong></p><ul><li>古典：受限制的算法<ul><li>算法的保密性基于<em>保持算法的秘密</em></li></ul></li><li>现代：基于密钥（key-based）的算法<ul><li>算法的保密性基于<em>对密钥的保密</em></li><li>对称加密<ul><li>发送方和接收方有相同的密钥<ul><li>面对面协商-&gt;小范围</li><li><strong>使用公钥密码协商</strong></li></ul></li></ul></li><li>非对称加密<ul><li>公钥密码算法<ul><li>加密密钥（公钥）和解密密钥（私钥）不同</li></ul></li></ul></li></ul></li><li>分组密码：一次加密一块 * 实际应用</li><li>流密码；一次一位或一子节 * 多用于研究<ul><li>为什么？<ul><li><strong>研究很难一步到位提出分组的新型公钥密码算法</strong>，为了简化难度，先做流式的，再扩展到分组式</li></ul></li></ul></li></ul><p><em>发展</em></p><ul><li>1949前：艺术🎨 * <strong>密码算法的安全性没有理论依据</strong>，无法回答到底有多安全</li><li>1949-1975：科学🔬 * 信息论的出现-&gt;理论依据 * 实用性？ * <strong>没有办法有效生成足够多的随机数</strong></li><li><strong>1976后：公钥密码学</strong> * 基于<strong>计算复杂性理论</strong>的密码算法 * 理论上可被破解，但计算代价巨大<ul><li>1976：<em>Diffie &amp; Hellman</em>提出公钥密码，以公钥密码实现会话密钥的协商</li><li>1977：Rivest,Shamir &amp; Adleman提出了<em>RSA</em>公钥算法，因此获得图灵奖</li><li>90年代逐步出现了<em>基于椭圆曲线</em>的公钥算法：比RSA更安全更高效，但实际应用依然较少</li><li>2000年左右出现了<em>基于双线性映射</em>的公钥算法：<strong>基于身份密码学</strong>的重要数学基础</li><li>2000年左右出现了<em>基于格代数</em>的公钥算法：后量子时代的利器</li><li>2005年以后<em>公钥密码与访问控制的融合</em>：实现了基于不可信存储第三方的加密数据共享</li><li>2005年以后出现了<em>全同态加密</em>：实现了密文的同态加法和乘法运算</li><li>安全通讯-&gt;安全控制-&gt;安全计算</li></ul></li></ul><p>密码分析</p><ol type="1"><li>唯密：攻击者被动地(窃听)具有密⽂串y，但没有相应的明文x</li><li>已知明文：攻击者被动地(窃听)具有明⽂x和相应的密文y.</li><li>选择明文：：攻击者可获得对加密机的暂时访问，因此可主动选择明文x，并得到相应的密文y</li><li>选择密文：攻击者可获得对解密机的暂时访问，因此可主动选择密⽂串y，并得到相应的明文x</li></ol><p>现代密码学要求：</p><ol type="1"><li>不能破解密钥</li><li>不能破解明文</li><li>不能破解明文的语义</li></ol><p><strong>密码算法的安全性度量</strong></p><ul><li>无条件安全<ul><li>无论破译者有多少密文，他也无法解出对应的明文，即使他解出了，他也无法验证结果的正确性</li><li>常用于评估<em>基于信息论</em>的密码学算法</li></ul></li><li><em>计算上安全</em><ul><li>破译的代价超出信息本身的价值；<em>破译的时间超出了信息的有效期</em></li><li>常用于<em>基于计算复杂性</em>的密码学算法</li></ul></li></ul><p><em>古典密码（计算题）</em></p><ul><li>代替密码 * 明文空间换为密文空间<ul><li><em>简单代替密码／单字母密码</em><ul><li>明文的一个字符用相对固定的一个密文字符代替</li></ul></li><li><em>多字母密码</em><ul><li>明文中的字符映射到密文空间的字符<em>还依赖于它在上下文中的位置</em></li></ul></li></ul></li><li>同余：若整数a和b有<code>(a mod q) = (b mod q)</code>，则称a与b在mod q下同余<ul><li><strong>移位密码</strong><ul><li>密钥<code>k in Z26</code></li><li>加密算法：<code>e(x) = x + k mod 26</code></li><li>解密算法：<code>d(y) = y - k mod 26</code></li><li>注：26个英文字母与模26剩余类集合<code>{0, ..., 25}</code>一一对应</li></ul></li><li><strong>乘数密码</strong>（对称加密）<ul><li>密钥<code>k</code>与26互素，即<code>K={1,3,5,7,9,11,15,17,19,21,23,25}</code></li><li>加密算法：<code>e(x) = kx mod 26</code></li><li>解密算法：<code>d(y) = k-1 y mod 26</code></li><li>为什么K要与26互素？<ul><li>保证加密变换是一一映射的</li><li>保证K有逆元，使解密算法成立</li></ul></li><li><em>K逆计算</em><ul><li>对于整数a、p，如果存在整数b，满足<code>ab mod p =1</code>，则说，b是a的模p乘法逆元</li></ul></li><li>更容易受唯密文攻击</li></ul></li><li><strong>仿射密码</strong><ul><li>密钥<code>a,b in {0, 25}</code>并且<code>a</code>与26互素</li><li>加密算法：<code>e(x) = ax + b mod 26</code></li><li>解密算法：<code>d(y) = a-1 (y - b) mod 26</code></li></ul></li><li>多名代替密码<ul><li>映射是一对多的，掩盖明文的频率差异</li><li><strong>重要：加上了抛币的随机数！</strong></li></ul></li><li>多表代替密码<ul><li>是以一系列代换表依此对明文消息的字母进行代换的方法</li><li>非周期：所有明文字符，每个明文字符有一个不同的单表加密</li><li>周期：用一定数量的单表循环加密<ul><li>依然保留一定频率</li><li>重码分析法</li></ul></li><li><strong>Vigenére密码</strong> <img src="/images/物联网安全概论/DraggedImage.png"></li><li><strong>Vernam密码</strong><ul><li>加密：<code>Ci = Pi ^ Ki</code></li><li>解密：<code>Pi = Ci ^ Ki</code></li></ul></li><li><strong>Playfair密码</strong> <img src="/images/物联网安全概论/DraggedImage-1.png"></li><li><strong>Hill密码</strong> <img src="/images/物联网安全概论/DraggedImage-2.png"></li></ul></li></ul></li><li><strong>古典密码的安全性缺陷</strong><ul><li>频率攻击</li><li>无随机</li></ul></li></ul><p><strong>由《风语者》看密码无处不在</strong></p><ul><li>语言本身也是一种密码，受限的密码算法</li><li><em>加密：协商出一种只有发送方和接收方看得懂的语言</em></li></ul><p><strong>由“信任”看如何说明密码算法的安全性</strong></p><ul><li>到底什么是安全？<ul><li>水的安全性？<ul><li>为什么认为没毒？<ul><li>因为喝过</li><li>正规厂商</li><li>正规渠道</li><li>相信给你说的人不会害你</li><li>相信厂家不会害你</li><li>….</li></ul></li><li>因为相信了xxx，所以相信这瓶水是安全的</li></ul></li><li>不能保证绝对安全<ul><li>如果保证绝对安全，一定要试一下</li></ul></li><li><strong>安全在绝大多数情况下无法实证</strong></li><li>安全来源于<strong>信任</strong>，依托于已知<strong>信任源</strong>，使得某一个场景是安全的</li><li><strong>信任源有信任程度的差异</strong><ul><li>对安全造成影响</li></ul></li><li>直观感觉同一瓶水安全性是常量，但通过给水的方式变了，导致水的安全性的改变。<ul><li>因为信任源变了！</li></ul></li><li><strong>信任源是动态的</strong></li><li>如果希望产品达到很好的安全性，则<em>信任源要信任程度高而且稳健</em></li><li><em>现代密码学信任源</em>：数学公理（<strong>公认的数学难题</strong>）</li><li>密码建立过程？<ul><li>假设-证明</li><li>证明如果存在攻击者能够破解我的加密算法，那么我能用它解决公认的数学难题</li><li>逆否-&gt;不成立</li></ul></li><li>什么是求解数学问题？<ul><li>前提：有解</li><li>数学问题：解在问题中，关键在于能不能展示出来</li><li>数学难题：解在问题本身，但没办法有效展示出来<ul><li>但有时额外增加一个量，就很好解</li><li>增加的量-&gt;解密密钥</li><li>原始问题-&gt;加密密钥</li></ul></li></ul></li></ul></li></ul><h2><span id="现代常规对称加密技术">现代常规对称加密技术</span></h2><ul><li>DES</li><li>Triple DES</li><li>AES</li></ul><p><em>分组密码</em></p><ul><li>基本思想：密文的统计特性与密钥独立</li><li><strong>设计原则</strong><ul><li><em>扩散（Diffusion）</em><ul><li>明文中的单个数字影响密文中的多个数字，从⽽使明文的统计特征在密文中消失，相当于明文的统计结构被扩散</li><li><em>使破解明文变得困难</em></li></ul></li><li><em>混乱（Confusion）</em><ul><li>密钥与密文之间的统计信息的关系变得复杂，从⽽增加通过统计⽅法进⾏攻击的难度</li><li><em>使破解密钥变得困难</em></li></ul></li></ul></li><li>软件要求<ul><li>使用子块（8, 16, 32bit）和简单（CPU直接支持的）的操作</li></ul></li><li>硬件要求<ul><li>加密算法和解密算法尽可能一样-&gt;成本降低</li></ul></li></ul><h3><span id="des">DES</span></h3><p><strong>如何保障加解密正确性</strong></p><ul><li>依赖于<strong>Feistel结构</strong>实现加解密的正确性</li></ul><p><em>密钥长度</em></p><ul><li>48bit：子密钥长度</li><li>56bit：真正用加密和解密的密钥长度</li><li>64bit：其中有8比特不用做加解密，是用来做奇偶校验的</li></ul><p><em>Feistel</em>结构</p><ul><li>不管F函数怎么设计，一定可以保证<strong>加密过程和解密过程一模一样</strong></li><li>结构 <img src="/images/物联网安全概论/DraggedImage-3.png"></li></ul><p><strong>S-Box</strong></p><ul><li>S盒无法求逆</li><li>只依赖于<strong>Feistel结构</strong>实现加解密的正确性</li><li><em>最⼤保障安全性</em></li></ul><p><em>DES缺陷</em></p><ul><li>弱密钥<ul><li>导致每一轮使用相同的子密钥</li></ul></li><li>半弱密钥<ul><li>使用不同密钥加密相同明文时会得到相同密文</li></ul></li></ul><p><strong>分组密码的操作模式</strong></p><ol type="1"><li>电子密码本（ECB） <img src="/images/物联网安全概论/DraggedImage-4.png"><ul><li>分块，单独对每一块进行DES加解密</li><li>优点<ul><li>可并行</li></ul></li><li>缺点<ul><li>安全性不够高</li><li>篡改密文块位置</li><li>无随机-&gt;相同明文一定得到相同密文-&gt;存在频率分析的可能性</li></ul></li><li><em>最直观，就是⽤用DES加密长文件，把⻓文件切块，但安全性很差</em></li></ul></li><li>密码分组链接（CBC） <img src="/images/物联网安全概论/DraggedImage-5.png"><ul><li>引入随机数-&gt;初始向量-&gt;解决频率分析</li><li>前一块对后一块有影响-&gt;解决篡改密文</li><li>优点<ul><li>无法篡改密文块位置</li></ul></li><li>缺点<ul><li>无法并行</li></ul></li><li><em>引⼊入随机数，引⼊入前后块的关联关系，但不不能实现流式</em></li></ul></li><li>密码反馈模式（CFB） <img src="/images/物联网安全概论/DraggedImage-6.png"><ul><li>流式加密-&gt;加密最小单位自定义</li><li>优点<ul><li>加密最小单位自定义</li><li>防篡改（链接模式）</li></ul></li><li>缺点<ul><li>加密速度没准达不到流失数据产生的速度</li><li>无法并行</li></ul></li><li><em>流式加密过程，但⽆无法应对⼤大量量流式数据短时间到达</em></li></ul></li><li>输出反馈（OFB） <img src="/images/物联网安全概论/DraggedImage-7.png"><ul><li>把中间结果反馈回去-&gt;<strong>可以预处理</strong>-&gt;加快速度，解决并行问题 <strong>进化原因</strong>：克服缺点</li></ul></li></ol><h3><span id="triple-des">Triple DES</span></h3><p><strong>为什么出现</strong></p><ul><li>因为DES的56bit的秘钥长度不足以抵御穷举攻击</li><li>问题：DES安全性不高-&gt; 再现有基础上改进 or 完全做一个新的</li></ul><p>高安全性的必要性：<strong>多次DES加密与单次DES加密不等价</strong></p><p><strong>Triple DES</strong></p><ol type="1"><li>DES-EEE3：三个不同的密钥加密</li><li>DES-EDE3：加密-解密-加密</li><li>DES-EEE2：K1 = K3</li><li>DES-EDE2: K1 = K3<ul><li>兼容常规DES：若K1=K2，相当于一次DES<ul><li>为什么要兼容：有很多已用单次DES加密的数据</li></ul></li><li>没有有效攻击方法</li></ul></li></ol><h3><span id="aes">AES</span></h3><p><em>（为什么会有AES）提出全新的密码算法</em> * 比三重DES快 * 至少一样安全 * 数据分组长度为128比特 * <strong>密钥长度为128/192/256比特</strong></p><p><strong>Rijindeal</strong></p><ul><li>不属于Feistel结构-&gt;加解密算法不同</li><li>有较好的数学理论作为基础</li><li>结果简单、速度快</li><li><em>AES需要多少轮密钥：11个</em></li><li><em>AES第10轮没有列列混操作</em></li></ul><p><strong>AES如何保证加解密的正确性</strong></p><ul><li>解密是加密的<em>逆变换</em>，加密过程中不存在不可逆变换</li></ul><p><em>与DES的S盒比较</em></p><ul><li>相同点<ul><li>非线性替代</li><li>提供<em>混乱作用</em></li></ul></li><li>不同点<ul><li>可逆</li><li>不会丢失信息</li></ul></li></ul><p><strong>列混合变换</strong>（具有数学特征）</p><ul><li>矩阵乘法，其中加法变成异或，乘法变为<strong>多项式乘法</strong></li><li>代替操作，将状态的列看作有限域GF上的4维向量并被有限域GF上的一个固定可逆方阵A乘 <img src="/images/物联网安全概论/DraggedImage-8.png"> <img src="/images/物联网安全概论/DraggedImage-9.png"> <img src="/images/物联网安全概论/DraggedImage-10.png"> <img src="/images/物联网安全概论/DraggedImage-11.png"></li><li>举例 <img src="/images/物联网安全概论/DraggedImage-12.png"> <img src="/images/物联网安全概论/DraggedImage-13.png"> <img src="/images/物联网安全概论/DraggedImage-14.png"></li></ul><p>Rijndael安全性</p><ul><li>没有发现弱密钥或补密钥</li><li>能有效抵抗目前已知的攻击算法<ul><li>线性攻击</li><li>差分攻击</li></ul></li></ul><h2><span id="公钥密码">公钥密码</span></h2><h3><span id="随机数产生">随机数产生</span></h3><p><em>随机数的基本特点</em></p><ul><li><em>随机性</em><ul><li>均匀分布</li><li>独立性</li></ul></li><li><em>不可预测性</em></li></ul><p><em>伪随机数</em>：攻击者在有效时间内分辨不出是真随机的还是伪随机的</p><p>把循环加密换成DES，在现代有啥问题？</p><ul><li>秘钥⻓度不够，易被暴力破解从而丧失不可预测性</li></ul><p>BBS产生器 <img src="/images/物联网安全概论/DraggedImage-15.png"></p><ul><li>基于大数分解</li><li><em>最后一步去掉有什么问题？</em><ul><li><em>可预测</em>，根据前一个可预测下一个</li></ul></li><li><em>为什么选最后1比特？</em><ul><li>Xi的每个比特的随机性有差异，而<em>随机性最强的比特是最低位</em>，所以Bi取最低比特</li></ul></li></ul><h3><span id="公钥密码算法">公钥密码算法</span></h3><p><em>起源（为什么会出现公钥加密算法？）</em></p><ul><li>在广域网情况下，发送方如何让接收方提前知道对称密码的密钥是什么？<ul><li><em>解决了对称加密的密钥的协商、发送问题</em></li></ul></li></ul><p>公钥密码特征</p><ul><li>公钥：加密（公开的）</li><li>私钥：解密</li><li>不能从公钥推导出私钥</li></ul><p>加密过程</p><ul><li>发送方用<strong>接收方的公钥</strong>来加密（对称密钥）</li><li>为什么不直接加密文件？<ul><li>公钥密码开销大，速度慢</li></ul></li><li>发送方如何知道发送接收方的公钥？</li></ul><p><strong>数学定理</strong></p><ul><li>引理1：若<code>ac = bc mod m</code>, 且c和m互素，则<code>a = b mod m</code></li><li>引理2：若a和m互素，则 <code>a, 2a, 3a, ..., (m-1)a</code>的最小剩余（<code>mod m</code>）按照某种次序排列后为：<code>1, 2, 3, ...., m-1</code></li><li><em>Fermat定理</em>：<code>p</code>为素数，<code>a</code>是整数且不能被<code>p</code>整除，则 <img src="/images/物联网安全概论/DraggedImage-16.png"> <img src="/images/物联网安全概论/DraggedImage-17.png"> <img src="/images/物联网安全概论/DraggedImage-18.png"></li><li><em>Euler数</em>：<code>o|o(n)</code>小于<code>n</code>且与<code>n</code>互素的正整数<em>个数</em><ul><li>若<code>p</code>是素数，<code>o|o(p) = p - 1</code> <img src="/images/物联网安全概论/DraggedImage-19.png"> <img src="/images/物联网安全概论/DraggedImage-20.png"></li></ul></li><li><em>Euler定理</em>：若<code>a</code>与<code>n</code>为互素的正整数，则： <img src="/images/物联网安全概论/DraggedImage-21.png"><ul><li>举例 <img src="/images/物联网安全概论/DraggedImage-22.png"></li><li>证明 <img src="/images/物联网安全概论/DraggedImage-23.png"> <img src="/images/物联网安全概论/DraggedImage-24.png"><ul><li><strong>注</strong>：如果有<code>m | (a - b)</code>，即<code>m</code>是<code>a - b</code>的因子</li></ul></li><li>推论：若<code>n = pq, p≠q</code>都是素数，<code>k</code>是任意整数，则： <img src="/images/物联网安全概论/DraggedImage-25.png"></li></ul></li><li><em>原根</em> <img src="/images/物联网安全概论/DraggedImage-26.png"></li><li><em>离散对数</em> <img src="/images/物联网安全概论/DraggedImage-27.png"></li><li><strong>离散对数问题</strong> <img src="/images/物联网安全概论/DraggedImage-28.png"><ul><li>给定上式，已知<code>g, y, p</code>，计算<code>x</code>！</li></ul></li></ul><h4><span id="diffie-hellman密钥交换">Diffie-Hellman密钥交换</span></h4><ul><li>基于离散对数问题 <em>目的</em>：允许两个用户可以<em>安全地交换一个秘密信息</em>，用于后续的通讯过程</li></ul><p>算法 <img src="/images/物联网安全概论/DraggedImage-29.png"></p><p><em>安全性保障</em>：“直观上”依赖于计算<em>离散对数</em>的难度</p><p><em>中间人攻击</em></p><ul><li>攻击者必须实时截获并冒充转发 <img src="/images/物联网安全概论/DraggedImage-30.png"></li></ul><p>为什么选取a是<strong>原根</strong>？</p><ul><li>为了保证两两不相等，如果不选原根，对于攻击者破解难度降低</li></ul><h4><span id="背包算法">背包算法</span></h4><p>MH公钥算法 <img src="/images/物联网安全概论/DraggedImage-31.png"> 公钥 = 私钥 * w mod m</p><ul><li>举例<ul><li>计算公钥 <img src="/images/物联网安全概论/DraggedImage-32.png"></li><li>加密 <img src="/images/物联网安全概论/DraggedImage-33.png"></li><li>解密 <img src="/images/物联网安全概论/DraggedImage-34.png"></li></ul></li></ul><p><em>背包算法问题</em></p><ul><li><strong>加密无随机</strong>-&gt;容易破解</li><li>实际中不采用</li></ul><h4><span id="rsa算法">RSA算法</span></h4><p>实际用的RSA算法为<em>RSA-OAEP</em> 为什么实际用的与理论用的不一样？</p><ul><li>教科书中讲的加密过程<em>没有用到随机数</em></li></ul><p>RSA安全性依据</p><ul><li>x的e次方mod n 是一个单向函数 -&gt; 无法求出x</li><li>攻击者无法分解：n = pq</li></ul><p><em>RSA算法</em> <img src="/images/物联网安全概论/DraggedImage-35.png"></p><p>举例 <img src="/images/物联网安全概论/DraggedImage-36.png"></p><p>密钥长度</p><ul><li>95：512bit</li><li>99：1024bit</li><li>现在：2048bit</li><li>趋势：使用基于椭圆曲线的加密算法<ul><li>因为基于比大数分解难题更难的难题</li></ul></li><li>为什么选1024⽐比特？<ul><li>计算复杂度<strong> 达到2^80 </strong></li><li>因为现在密码学认为超过2^80就是安全的</li></ul></li></ul><p><strong>对RSA的选择密文攻击</strong></p><ul><li>攻击者可以自己选择一些密文，并获得对应的明文</li><li><em>选密攻击从不考虑不直接解密？</em><ul><li>等同于用户把自己私钥暴露出去</li><li>这样所有密码体制都无法保证安全性</li></ul></li><li>怎么保证用户一定会提供解密服务？<ul><li>用户如果不解密，密文也看不懂；解密完发现看不懂，就什么也不做-&gt;间接提供给攻击者明文信息</li><li>这么假设<em>为了保证加密算法的安全性</em></li></ul></li></ul><p><em>公共模攻击</em></p><ul><li><strong>能不能去相同的模数？</strong><ul><li>不可以 <em>小加密指数攻击</em> <em>小解密指数攻击</em></li></ul></li></ul><p><strong>加密指数选择，能不能用小指数，为什么？</strong></p><ul><li><em>可以</em>，因为实际应用中都是RSA-OAEP，加密前将消息与随机值混合，并保证m与n有相同的长度。小加密指数攻击无法实施。实际上为了提高加密速度，通常取e为特定的整数，ISO/IEC9796中甚至允许取e=3</li></ul><h2><span id="hash函数-数字签名与身份认证">Hash函数、数字签名与身份认证</span></h2><h3><span id="hash函数">Hash函数</span></h3><p><em>Hash函数能不能直接用作数据完整性校验？</em></p><ul><li>不能，因为hash函数结果也易被篡改</li></ul><p><em>MAC</em></p><ul><li>如果要在不安全的信道中保证消息的完整性，可以在Hash函数中引入一个密钥，其结果被称为<em>消息验证码(MAC)</em> <img src="/images/物联网安全概论/DraggedImage-37.png"> <img src="/images/物联网安全概论/DraggedImage-38.png"></li><li>Hash函数基本要求<ul><li>快速<ul><li>因为输入长度不固定</li></ul></li><li>单向<ul><li>根据H(M)=h无法计算出M</li><li>在MAC中防止解出密钥</li></ul></li><li>防碰撞</li></ul></li><li><em>安全性</em><ul><li><em>原像稳固</em>：给定消息摘要y，能否找到x使得<code>h(x)=y</code><ul><li>单向性</li></ul></li><li><em>第二原像稳固</em>：给定一个消息x，能否找到x’ ≠x ，使得<code>h(x)=h(x’)</code><ul><li>防碰撞</li></ul></li><li><em>碰撞稳固</em>：寻找任意x’ ≠x，使得<code>h(x)=h(x’) </code><ul><li>任意寻找两个不同的x，使得哈希结果相同的可能性为0</li></ul></li></ul></li></ul><h3><span id="数字签名">数字签名</span></h3><p><em>数字签名是传统签名的数字化</em>,基本要求: </p><ul><li>能与所签文件“绑定” </li><li>签名者不能否认自己的签名</li><li>签名不能被伪造</li><li>容易被自动验证</li></ul><p>与MAC的区别：<em>MAC不能保证双方自身的相互欺骗</em></p><p>必须保证的性质</p><ul><li><em>可验证</em>:签字是可以被确认的</li><li><em>防抵赖</em>:发送者事后不承认发送报文并签名;</li><li><em>防假冒</em>:攻击者冒充发送者向收方发送文件;</li><li><em>防篡改</em>:收方对收到的文件进行篡改;</li><li><em>防伪造</em>:收方伪造对报文的签名</li></ul><p>三个过程</p><ul><li>系统的初始化过程<ul><li>在系统的初始化过程中要产生的数字签名方案中用到的一切参数，有公开的，也有秘密的</li></ul></li><li>签名产生过程<ul><li>在签名产生的过程中用户利用给定的算法对消息产生签名，这种签名过程可以公开也可以不公开</li></ul></li><li>签名验证过程<ul><li>在签名验证过程中，验证者利用公开验证方法对给定消息的签名进行验证，得出签名的有效性</li></ul></li></ul><p><em>数字签名问题</em></p><ul><li>签名后文件可能被重复利用<ul><li>签字后的文件可能被B重复使用。如果签字 后的文件是一张支票，B很容易多次用该电子支 票兑换现金，为此A需要在文件中加上一些该支票的特有的凭证，如timestamp等，以防止上述情况发生</li></ul></li><li>公钥算法效率低</li></ul><p><em>RSA数字签名</em> <img src="/images/物联网安全概论/DraggedImage-39.png"></p><ul><li><strong>与加解密的异同？</strong><ul><li><em>利用私钥签名，公钥验证</em>，而RSA加密是⽤公钥加密，私钥解密</li></ul></li></ul><h3><span id="身份认证">身份认证</span></h3><p><em>身份认证是对网络中的主体进行验证的过程</em>，用户必须提供他是谁的证明，他是某个雇员，某个组织的代理、某个软件过程(如交易过程) 。</p><p><em>主要方法</em></p><ul><li>口令认证<ul><li>含义：用户名/口令认证</li><li>优点<ul><li>最简单、最普遍的身份识别技术</li></ul></li><li>缺点<ul><li>大多数系统的口令是明文传送到验证服务器的， 容易被截获</li><li>口令维护的成本较高，难于记忆</li><li>口令容易在输入的时候被攻击者偷窥，而且用户无法及时发现</li></ul></li><li>安全性要求<ul><li>位数&gt;6位</li><li>大小写字母混合</li><li>字母与数字混合</li><li>口令有字母、数字以外的符号</li><li>禁止使用缺省口令</li><li>定期更换口令</li><li>保持口令历史记录，使用户不能循环使用旧口令</li><li>用口令破解程序测试口令</li></ul></li><li>攻击种类<ul><li>字典攻击</li><li>穷举尝试</li><li>窥探</li><li>社交工程</li><li>垃圾搜索</li><li>重放攻击</li></ul></li></ul></li><li>智能卡认证<ul><li>含义：<em>网络通过用户拥有什么东西来识别的方法，一般是用智能卡或其它特殊形式的标志</em>，这类标志可以从连接到计算机上的读出器读出来。访问不但需要口令，也需要使用物理智能卡（<em>询问／应答模式</em>）</li><li>优点<ul><li>存储容量大 、体积小而轻、保密性强、网络要求低、 数据可靠性高 、防磁、防静电、防潮、耐温、抗干扰能力强，一张IC卡片可重复读写十万次，卡中数据可 保存几十年，对计算机的实时性、敏感性要求降低。内部数据保密性、可靠性好，读写稳定可脱机工作，易于安装维护</li></ul></li><li>缺点<ul><li><em>丢失后短时间内不好补回</em></li></ul></li><li>安全性要求</li><li>攻击种类</li></ul></li><li>基于生物特征的认证<ul><li>含义：目前已有的设备包括:视网膜扫描仪、声音验证设备、手型识别器等</li><li>优点<ul><li>安全性高</li></ul></li><li>缺点<ul><li>一旦泄露，<em>生物信息不可更改！</em></li></ul></li><li>安全性要求</li><li>攻击种类</li></ul></li><li>双因素认证<ul><li>含义：所知道的内容+所拥有的物品</li><li>优点</li><li>缺点</li><li>安全性要求</li><li>攻击种类</li></ul></li></ul><p><em>身份认证协议</em></p><ul><li>NSSK：通信双方A和B通过可信第三方协商会话密钥<ul><li>基于对称密码的双向认证协议 <img src="/images/物联网安全概论/DraggedImage-40.png"></li></ul><ol type="1"><li>A向可信第三方T发送要和B勾搭的请求，加上随机数Na</li><li>T给A回复相应的Na，B的信息，AB之间的密钥，和用Kbt的密钥加密的Kab与A的信息</li><li>A解密之后，验证Na，然后把用Kbt的密钥加密的Kab与A的信息发给B</li><li>B用Kbt解密，获取Kab，并生成随机数，用Kab加密发给A</li><li>A解密后，把随机数+1，在用Kab加密发回B <strong>信任建立</strong></li></ol><ul><li><em>A认证B</em>：第四步，因为只有真正的B才能解出BT通讯的对称密钥</li><li><em>B认证A</em>：第五步，因为只有真正的A才能解出AB通讯的对称密钥</li></ul></li><li>NSPK：通信双方A和B通过可信第三方协商会话密钥<ul><li>基于非对称密码的双向认证协议 <img src="/images/物联网安全概论/DraggedImage-41.png"></li></ul><ol type="1"><li>A向可信第三方T发送要和B勾搭的请求</li><li>T臭不要脸的同意了，给了B的联系方式（B的公钥），怕A不相信，还在上面改了一个戳（用自己的私钥签名）</li><li>A拿到B的公钥，随便选了个数，作为定情信数，然后附上自己的名片，用B的公钥加密，发送给B</li><li>B收到这封信，用自己的私钥解密，知道是A这个小彪子要勾搭自己，精虫上脑，然后也向T去申请</li><li>同样的T也给了B一个自己盖过章的A的公钥</li><li>B拿到A的公钥，又选了一个定情信数Nb，俩数一块用A的公钥加密发给A</li><li>A解密出Nb的值，再用Kb加密发回给B <strong>信任建立</strong>：</li></ol><ul><li><em>B认证A</em>：(6)里面B发给A的是用A的公钥加密的，只有A能解开，所以，(7)里面A把正确的Nb发回给B，证明他真的是A</li><li><em>A认证B</em>：(6)里面B能把A随便选的定情信数解密出来（之前是用Kb加密的），再发回给A，就证明自己是真的B</li></ul></li><li>基于非对称密码的单向认证协议 <img src="/images/物联网安全概论/DraggedImage-42.png"></li></ul><h2><span id="pki">PKI</span></h2><p>概念：PKI-Public Key Infrastructure公钥基础设施。<em>是一个用公钥技术来实施和提供安全服务的具有普适性的安全基础设施</em>。</p><p>功能</p><ul><li>签发证书</li><li>签发证书撤销列列表</li><li>密钥备份与恢复功能</li><li>证书、密钥对的⾃自动更更新</li><li>加密、签名密钥的分割 密钥历史的管理理</li><li>交叉认证</li></ul><p><em>本质任务</em>：<strong>绑定用户和公钥</strong> <em>为什么需要PKI</em>：公钥和用户没有天然的绑定关系，所以需要KPI来完成这种绑定。 <em>密钥备份及恢复系统</em>：密钥的备份与恢复<em>只能针对解密密钥</em>，<strong>签名私钥不能备份</strong></p><ul><li>为什么？<em>防⽌发生发送方抵赖，说签名不是⾃己签的，因为PKI也有自⼰的私钥</em></li></ul><p><em>撤销方法</em>：把证书列入证书撤销列表中（CRL）来实现</p><ul><li>到期</li><li>临时<ul><li>用户身份改变</li><li>对密钥的怀疑（丢失或泄露）</li><li>用户工作的变动</li><li>认为CA证书已泄露</li></ul></li></ul><p><em>交叉认证</em></p><ul><li>为什么：在以前没有联系的PKI之间建立信任关系，就需要交叉认证。它能够让一个PKI团体的用户验证另一个PKI团体的用户证书，从而实现通信。</li><li>分类<ul><li>域内／间交叉认证</li><li>单向／双向</li><li>正／反向交叉验证</li></ul></li><li>验证步骤<ol type="1"><li>验证真实性（基于证书链机制）。证书是否为可信任的CA认证中心颁发？</li><li>验证有效性。证书是否在有效期之内？</li><li>验证可用性（基于证书撤销机制）。证书是否已废除？</li></ol></li></ul><h2><span id="基于身份加密体制">基于身份加密体制</span></h2><p>为什么会出现？</p><ul><li><strong>CA成为了PKI的性能瓶颈</strong></li><li>公钥和用户没有天然的绑定关系，所以需要KPI来完成这种绑定</li><li>如果不用KPI，那么公钥和用户要有天然的绑定关系</li></ul><p><em>概念</em>：一种能够让用户及其公钥有天然的绑定关系的加密体制 天然的绑定关系？</p><ul><li>属性</li><li>身份</li><li>需要从不同的角度考虑</li></ul><p>算法含义</p><ul><li><em>Setup</em><ul><li>系统初始化算法用于生成系统公开参数和系统秘密参数</li></ul></li><li><em>Extract</em><ul><li>根据系统秘密参数和用户的身份信息（公钥），根据系统秘密参数和用户的身份信息（公钥） 生成用户的私钥</li></ul></li><li><em>Enc</em><ul><li>发送方根据系统公开参数、接收方身份信息 （公钥），加密明文，并生成密文</li></ul></li><li><em>Dec</em><ul><li>接收方用自己的私钥解密收到的密文</li></ul></li></ul><h2><span id="物联网安全">物联网安全</span></h2><p><em>RFID威胁</em></p><ul><li><em>物理攻击</em><ul><li>针对节点本身进行<em>物理上的破坏行为</em>，导致信息泄露、恶意追踪等。</li></ul></li><li><em>信道堵塞</em><ul><li>攻击者长期占据信道导致通信<em>无法传输</em>。</li></ul></li><li><em>伪造攻击</em><ul><li><em>伪造电子标签</em>生成系统认可的“合法用户标签”（实现代价较高）。 </li></ul></li><li><em>假冒攻击</em><ul><li>截获合法用户身份信息后，截获合法用户身份信息后使用该信息<em>假冒合法用户</em>入网。使用该信息假冒合法用户入网 </li></ul></li><li><em>重放攻击</em><ul><li>利用某次合法用户的身份登陆信息或者窃听到的有效信息过一段时间后<em>重发送给接收者</em>，骗取信任，达到攻击的目的。 </li></ul></li><li><em>中间人攻击</em><ul><li>攻击者将窃听到的信息进行<em>修改之后再将信息传给</em>接收者。</li></ul></li></ul><p><em>无线传感网络的威胁</em></p><ul><li><em>网关节点俘获</em><ul><li>控制<em>节点被俘获</em>之后，可能导致通信密钥、广播密钥、配对密钥等全部 泄露，泄露 进而威胁到整个网络的通信安全。进而威胁到<em>整个网络的通信安全</em></li></ul></li><li><em>普通节点俘获</em><ul><li>导致<em>部分通信密钥泄露</em>，对局部网络通信安全造成威胁。 </li></ul></li><li><em>传感信息窃听</em><ul><li>攻击者对通信链路间传输的信息进行窃听，从而分析并得出其中的敏感信息。</li></ul></li><li><em>DoS攻击（拒绝服务攻击）</em><ul><li>网关节点容易受到DoS攻击，耗尽节点资源，使得节点丧失运行能力。</li></ul></li><li><em>虚假路由信息</em><ul><li>通过欺骗，纂改或重发路由信息，攻击者可以创建循环路由，延长或者 屏蔽路径，屏蔽路径，增加端到端延迟，增加端到端延迟从而<em>消耗节点能源</em>。</li></ul></li></ul><p><em>传输层安全威胁</em></p><ul><li>异构网络跨网认证</li><li>异步攻击（传输层的重放攻击等等）</li><li>合谋攻击</li></ul><p><em>传输层相关措施</em></p><ul><li><strong>点到点加密机制</strong>：在路由节点解密后再加密传输：好多密钥</li><li><strong>端到端加密机制</strong>：传输过程始终保持密文传输：单一密钥</li></ul><p><em>应用层安全威胁</em></p><ul><li>在满足数据智能化处理基础之上，<em>加强数据库访问控制策略</em>。 </li><li>加强不同应用场景的<em>认证机制和加密机制</em>。 </li><li>加强<em>数据溯源能力和网络取证能力</em>，完善网络犯罪取证机制。</li></ul><h3><span id="密码学在分布式传感器网络dsn中的应用">密码学在分布式传感器网络（DSN）中的应用</span></h3><p><strong>密钥分发问题</strong></p><ol type="1"><li><em>单一密钥</em><ul><li>优点<ul><li>存储少</li><li>效率高</li><li>增加／删除新节点容易，不会对现有节点产生问题</li></ul></li><li>缺点<ul><li>单一节点被俘获，危害整个系统的安全</li></ul></li></ul></li><li><em>每两个传感器采用不同密钥</em><ul><li>优点<ul><li>安全性高</li></ul></li><li>缺点<ul><li>每个传感器需要存储N-1个密钥</li><li>增加／删除传感器会对现有传感器产生影响</li></ul></li></ul></li><li><em>折中</em>方法<ul><li>分组</li></ul></li></ol><p>安全性 VS 效率</p><ol type="1"><li>追求极致的效率而不考虑安全性<ul><li>看此问题有没有有效的解决方法-&gt;如果没有，则不必向下探究</li></ul></li><li>追求极致的安全性而不考虑效率的开销<ul><li>最大能达到的安全性</li></ul></li><li>平衡安全性和效率<ul><li>弱化第二种方案的安全性-&gt;减少步骤</li></ul></li></ol><h3><span id="基于密码学的rfid认证">基于密码学的RFID认证</span></h3><p>安全性需求</p><ul><li><em>保密性</em>：即信息在Tag与Reader之间传输时需要进行保护，例如加密</li><li><em>不可伪造性</em>：攻击者不能够伪装成一个合法的攻击者不能够伪装成个合法的Tag或者Reader</li><li><em>位置隐私</em>：攻击者不能够获知Tag的位置信息， 即不可追踪</li></ul><p><em>Hash-Lock协议（最简单）</em> <img src="/images/物联网安全概论/DraggedImage-43.png"></p><ul><li>实现Tag与Reader的<em>互认证</em><ul><li>第五步，Tag认证读写器</li><li>第六步，读写器认证Tag</li></ul></li><li>优点<ul><li>简单</li></ul></li><li>问题：攻击者可以<em>劫持传输的metaID和ID</em><ul><li><strong>伪造RFID标签</strong></li><li><strong>重放攻击</strong>（需要截获并记录以前的通讯）</li></ul></li></ul><p><em>随机化Hash-Lock协议</em> <img src="/images/物联网安全概论/DraggedImage-44.png"></p><ul><li>认证<ul><li>第五步，Tag验证读写器</li><li>第四步，读写器验证Tag，因为解出一个正确的标签ID</li></ul></li><li>但Tag标识仍以明文形式传 输，很容易对Tag进行跟踪，且<strong>易受伪造攻击和重传攻击 </strong><ul><li>截获合法的IDk，放到伪造的标签里</li><li>第四步传回所有的ID，通信开销很大，读取器存储开销大</li></ul></li></ul><p><em>Hash链协议</em> <img src="/images/物联网安全概论/DraggedImage-45.png"> <img src="/images/物联网安全概论/DraggedImage-46.png"></p><ul><li><em>单向认证</em><ul><li>读写器认证Tag：第四步，因为解出一个正确的标签ID</li></ul></li><li>合法RFID标签的ID值是动态变化的</li><li>优点<ul><li>可防追逐</li><li>可防伪造</li><li>可重传攻击</li></ul></li><li>G、H不能相同<ul><li>若相同则a变成下一次的状态信息</li></ul></li></ul><h3><span id="基于pke的rfid认证">基于PKE的RFID认证</span></h3><p><img src="/images/物联网安全概论/DraggedImage-47.png"></p><p><em>方案1</em> <img src="/images/物联网安全概论/DraggedImage-48.png"></p><ul><li>安全性：引入了随机数，因此可以抵抗消息重放攻击</li><li><em>读写器对Tag的单向认证</em><ul><li>因为只有真正的Tag才会有正确的（ID, K）和刚发的随机数 <em>方案2</em> <img src="/images/物联网安全概论/DraggedImage-49.png"></li></ul></li><li>安全性</li><li><em>读写去和Tag的双向认证</em><ul><li>第三步，读写器验证Tag</li><li>第四步，Tag验证读写器</li></ul></li></ul><p>实际应⽤用中缺点：复杂、效率低、成本⾼高</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 本科课程 </tag>
            
            <tag> 物联网 </tag>
            
            <tag> 信息安全 </tag>
            
            <tag> RSA </tag>
            
            <tag> DES </tag>
            
            <tag> AES </tag>
            
            <tag> PKI </tag>
            
            <tag> HASH </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>计算机网络</title>
      <link href="/2017/06/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
      <url>/2017/06/30/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p><strong>目录</strong></p><!-- toc --><ul><li><a href="#计算机网络概论">计算机网络概论</a><ul><li><a href="#计算机网络的定义">计算机网络的定义</a></li><li><a href="#因特网的结构">因特网的结构</a></li><li><a href="#协议分层与服务模型">协议分层与服务模型</a></li><li><a href="#分组交换网的性能指标">分组交换网的性能指标</a></li></ul></li><li><a href="#数据通信基础">数据通信基础</a><ul><li><a href="#交换技术">交换技术</a></li><li><a href="#接入网">接入网</a></li><li><a href="#物理层概述">物理层概述</a></li></ul></li><li><a href="#直接连接的网络">直接连接的网络</a><ul><li><a href="#链路层概述">链路层概述</a></li><li><a href="#成桢">成桢</a></li><li><a href="#差错检测和纠错技术">差错检测和纠错技术</a></li><li><a href="#可靠传输原理">可靠传输原理</a></li><li><a href="#多路访问协议">多路访问协议</a></li><li><a href="#以太网">以太网</a></li><li><a href="#链路层交换机">链路层交换机</a></li></ul></li><li><a href="#网络互联">网络互联</a><ul><li><a href="#网络层概述">网络层概述</a></li><li><a href="#网络服务模型">网络服务模型</a></li><li><a href="#网际协议ip">网际协议（IP）</a></li><li><a href="#路由选择协议及其算法">路由选择协议及其算法</a></li><li><a href="#路由器的工作原理">路由器的工作原理</a></li></ul></li><li><a href="#端到端协议">端到端协议</a><ul><li><a href="#运输层协议概述">运输层协议概述</a></li><li><a href="#多路复用与多路分解">多路复用与多路分解</a></li><li><a href="#udp">UDP</a></li><li><a href="#tcp">TCP</a></li><li><a href="#tcp拥塞控制">TCP拥塞控制</a></li></ul></li><li><a href="#网络应用协议">网络应用协议</a><ul><li><a href="#域名系统dns">域名系统DNS</a></li><li><a href="#http">HTTP</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="计算机网络概论">计算机网络概论</span></h2><h3><span id="计算机网络的定义">计算机网络的定义</span></h3><p>网络实体可抽象为两种基本构件:</p><ul><li><em>结点(node)</em>(亦称节点):计算设备</li><li><em>链路(link)</em>:物理媒体</li></ul><p>构成网络的方式</p><ol type="1"><li>直接相连<ul><li>由某种物理媒体直接相连所有主机组成</li><li>分类<ul><li>物理链路与一对结点相连: <em>点到点链路(point-to-point link) </em></li><li>多结点共享同一物理链路: <em>多路访问链路(multiple access) </em></li><li><img src="/images/计算机网络/DraggedImage.png"></li></ul></li></ul></li><li>网络云<ul><li>网络云表示任何类型的</li><li>网络通常采用<em>分组交换</em>技术</li><li>主机间接连通的第一种方法</li><li><img src="/images/计算机网络/DraggedImage-1.png"></li></ul></li><li>网络云互联<ul><li><em>递归地连接网络云</em>形成更大规模的网络，有很好的扩展性由网络云构建成网络称为互联网</li><li>连接两个或多个网络云的结点称<strong>路由器</strong></li><li>主机间接连通的第二种方法</li><li><img src="/images/计算机网络/DraggedImage-2.png"></li></ul></li></ol><p>两种数据传递方法</p><ul><li>电路交换(circuit switching)<ul><li>主要用于电话网，在发送方和接收方之间通过多台交换机建立一条连接(电路circuit)</li></ul></li><li>分组交换(packet switching)<ul><li>主要用于计算机网络分组(packets) 长报文(message)划分为等长的短段，并为每个段加上首部</li></ul></li></ul><p>网络服务</p><ul><li>网络服务是向用户所提供的有用网络功能，由运行在网络中不同主机上的网络应用程序协作提供。</li><li><strong>应用程序运行在端系统上</strong>，而不运行在交换机和路由器上</li></ul><h3><span id="因特网的结构">因特网的结构</span></h3><ul><li>网络边缘(edge):<ul><li>应用与主机</li></ul></li><li>网络核心(core):<ul><li>路由器(网络的网络)</li></ul></li><li>接入网(access network):<ul><li>连接两者的通信链路</li><li>将端系统连接到其<em>边缘路由器(edge router)</em>的物理链路及设备的集合</li></ul></li><li><strong>端到端原则</strong><ul><li><strong>边缘智能，核心简单</strong></li><li>将复杂的网络功能置于边缘（如差错控制、流量控制和应用等）</li><li>相对简单的分组交付功能置于核心（如分组的选路和转发功能）</li></ul></li></ul><p><img src="/images/计算机网络/DraggedImage-3.png"></p><ul><li>因特网的核心<ul><li>在中心: “第一层”ISP (如UUNet, BBN/Genuity, Sprint, AT&amp;T), 覆盖国家/国际</li><li>第二层” ISP: 较小的(常为区域的) ISP(如中国电信、中国 网通、中国移动)</li><li>第三层” ISP和本地ISP</li></ul></li></ul><p><img src="/images/计算机网络/DraggedImage-4.png"></p><h3><span id="协议分层与服务模型">协议分层与服务模型</span></h3><p>网络协议</p><ul><li>为进行网络中的数据交换而建立的规则、标准或约定即称为<em>网络协议(network protocol) </em></li><li>网络协议3要素:<ul><li>语法 :数据与控制信息的结构或格式</li><li>语义:发出何种控制信息，完成何种动作以及做出何种响应</li><li>定时:事件实现顺序的详细说明</li></ul></li></ul><p>作业</p><ol type="1"><li>网络有哪些构件?主机之间互联有哪几种方式? 端系统上的现代操作系统通常定义了哪些编程开发接口?</li><li>参见图1-11，因特网具有大致分层的ISP等级结构。由此回答:为何说因特网是网络的网络?每层ISP是否大致与地理范围对应?内容提供商正在以何种方式改变因特网 的结构?</li><li>什么叫做网络协议?构成协议的几个要素是什么?是否可以缺失其中的某个要素?请举例说明原因。</li></ol><p><img src="/images/计算机网络/DraggedImage-5.png" title="网络结构"></p><p>网络分层</p><ul><li><strong>分而治之</strong></li><li><strong>协议是</strong>“<em>水平的</em>”，<strong>服务是</strong>“<em>垂直的</em>”</li><li>体系结构 <img src="/images/计算机网络/DraggedImage-6.png"></li></ul><p><strong>端到端原则</strong></p><ul><li>如果在较高层能够完善地实现某种功能，就无需再由较低层提供这种功能</li></ul><h3><span id="分组交换网的性能指标">分组交换网的性能指标</span></h3><p>时延和丢包的产生 <img src="/images/计算机网络/DraggedImage-7.png"></p><p><em>流量强度</em></p><ul><li>R = 链路带宽 (bps)</li><li>L = 分组长度 (比特)</li><li>a = 平均分组到达速率</li><li>流量强度 = <span class="math inline">\(La / R\)</span><ul><li>La/R -&gt; 0: 平均排队时延小</li><li>La/R -&gt; 1: 时延急剧变大</li><li>La/R &gt; 1: 更多“工作”到达，超出了服务能 力，平均时延无穷大!</li><li><img src="/images/计算机网络/DraggedImage-8.png"></li></ul></li></ul><p><em>节点时延</em></p><ul><li><img src="/images/计算机网络/DraggedImage-9.png"></li><li>dproc = 处理时延<ul><li>通常几个微秒或更少</li></ul></li><li>dqueue = 排队时延<ul><li>取决于拥塞</li></ul></li><li>dtrans = 传输时延(发送时延)= <em>L/R</em><ul><li>对低速链路很大</li></ul></li><li>dprop = 传播时延<ul><li>几微秒到几百毫秒</li></ul></li><li><img src="/images/计算机网络/DraggedImage-10.png"></li></ul><p>丢包率</p><ul><li>在一定的时段内在两结点间传输过程<em>丢失分组数量</em>与<em>总的分组发送数量</em>的比率</li><li>IP网丢包主要原因<ul><li>路由器无法容纳到达的分组，只能丢弃(drop) 到达的分组</li></ul></li></ul><p>带宽和吞吐量</p><ul><li>网络带宽<ul><li>链路在<em>一段特定的时间</em>内所能<em>传送的比特数</em>的额定值</li></ul></li><li>吞吐量<ul><li>网络在单位时间内无差错地传输数据的能力</li></ul></li><li>瓶颈链路<ul><li>路径中可用带宽最小的链路</li></ul></li><li>可用带宽<ul><li>带宽与干扰流量之差</li></ul></li></ul><p>跳与路径</p><ul><li>路径可以定义为形式为 <span class="math inline">\([h_0, l_1, h_1, ..., l_n，h_n]\)</span> 的序列，是单向的</li><li>对于端到端路径而言，h0和hn是端系统，而 h1...hn-1 是路由器。每个&lt;li，hi&gt;二元组被称为一“跳”</li><li><img src="/images/计算机网络/DraggedImage-11.png"></li></ul><p>时延与带宽乘积</p><ul><li>物理意义<ul><li><strong>管道能够容纳的比特数</strong></li></ul></li></ul><p>作业</p><ol type="1"><li>数据在各层之间的传递过程中，各层协议的首部起着什么作 用?“水平的”协议和“垂直的”服务之间有什么关系?</li><li>TCP/IP体系结构具有哪些层次?该体系结构的主要特点是什 么?</li><li>考虑一个长度为L的分组从端系统A开始，经一段链路传送到一 台分组交换机，并从该分组交换机经第二段链路传送到目的端 系统。令di、si和Ri表示链路i的长度、传播速度和传输速率 (i=1,2)。该分组交换机对每个分组的时延为dproc。假定没有 排队时延，根据di、si、Ri (i=1,2)和L，该分组总的端到端时延 是什么?现在假定该分组是1,000字节，分组交换机的处理时延 是1 ms，第一段链路的长度是4,000km，并且最后一段链路的 长度是1,000km。对于这些值，该端到端时延为多少?</li></ol><h2><span id="数据通信基础">数据通信基础</span></h2><h3><span id="交换技术">交换技术</span></h3><p>电路交换</p><ul><li>具有“<em>连接建立-数据传输-连接释放</em>”三个步骤，以<em>分时</em>的方式共享通信资源</li><li>优点<ul><li>独占资源，通信质量有保证</li><li>传输时延小，通信中无拥塞</li></ul></li><li>缺点:<ul><li>建连时间较长，工作过程复杂</li><li>有时工作效率较低:计算机通信</li></ul></li><li><img src="/images/计算机网络/DraggedImage-12.png"></li></ul><p>报文交换</p><ul><li>优点:<ul><li><em>无连接</em>，报文发给相邻结点，报文存储后再选择合适出口向后转发，直至目的结点</li><li>以“<em>存储转发</em>”为特征</li></ul></li><li>缺点<ul><li>对报文长度不加限制，中间结点<em>存储空间很大</em></li><li>长时间占用某段线路，导致报文在中间结点<em>时延非常大</em></li></ul></li><li><img src="/images/计算机网络/DraggedImage-13.png"></li></ul><p>分组交换</p><ul><li>“存储转发”能逐段并行利用线路，而长报文降低了系统效率</li><li>改进措施:<ul><li>长报文分为较短数据块(分组)</li><li>仅引入较小时延</li><li><img src="/images/计算机网络/DraggedImage-14.png"></li></ul></li><li>统计复用<ul><li>按需使用链路带宽资源</li><li>链路传输能力逐分组地被共享，以链路的最大传输速率传输</li><li>每段链路传输速率不一定相同</li></ul></li></ul><h3><span id="接入网">接入网</span></h3><p>点对点接入</p><ul><li>经调制解调器拨号<ul><li>最高达56Kbps直接接入到路由器(经常较少)</li><li><em>不能同时上网和打电话</em></li></ul></li><li><em>ADSL: 不对称数字用户线</em><ul><li>最高达1Mbps上行(典型&lt;256kbps)</li><li>最高达8Mbps下行(典型&lt;1Mbps)</li></ul></li></ul><p>电缆调制解调器</p><ul><li><em>HFC: 混合光纤同轴</em><ul><li><em>不对称</em>:最高达30Mbps下行, 2 Mbps上行</li></ul></li><li>电缆和光缆的网络将家庭连到ISP的路由器<ul><li>家庭共享到路由器的接入</li></ul></li></ul><p>公司/大学局域网 (LAN)</p><ul><li>将端系统连接到边缘路由器</li></ul><p>以太网</p><ul><li>共享或专用链路连接端系统和路由器</li><li>10 Mbs, 100Mbps, 千兆以 太网</li></ul><h3><span id="物理层概述">物理层概述</span></h3><p>物理层作用</p><ul><li>定义在连接各种计算机的传输媒体上原始比特的交互方式及其接口，<em>不关心具体的物理设备或具体的传输媒体</em></li><li><em>屏蔽</em>掉种类繁多的物理设备和传输媒体的<em>差异</em>，使这些差异对上面的数据链路层透明</li></ul><p>物理层协议</p><ul><li>机械特性</li><li>电气特性</li><li>功能特性</li><li>规程特性</li><li>使用相同的物理层标准，互联设备之间能够交互比特</li></ul><p>作业</p><ol type="1"><li>假定用户共享一条2 Mbps链路。同时假定当每个用户传输 时连续以1 Mbps传输，但每个用户仅传输20%的时间。<ol type="a"><li>当使用电路交换时，能够支持多少用户?</li><li>对于该问题的遗留问题，假定使用分组交换。为什么如果两个或更少的用户同时传输的话，在链路前面基本上没有排队时延?为什么如果3个用户同时传输的话，将有排队时延? c.求出某指定用户正在传输的概率。d. 假定现在有3个用户。求出在任何给定的时间，所有3个用户在同时传输的概率。求出排队增长的时间比率。 <em>答</em>：</li><li>当使用电路交换时，信道带宽需要用户独占，最多智能支持2个用户;</li><li>因为2Mbps链路仅能容纳两个或更少的用户同时以1Mbps连续传输时， 这时统计上会有资源富余，而当 3 个用户同时传输时，统计上便会出现供不应求 的现象，导致排队时延。</li></ol></li><li>ADSL的上下行带宽为何设计为不对称?</li><li>当前无线接入所使用的WiFi技术基于何种标准?为何3G技术经常要与WiFi技术配合使用?</li></ol><h2><span id="直接连接的网络">直接连接的网络</span></h2><p>机制</p><ul><li>成桢</li><li>查错检测和纠错</li><li>可靠数据传输</li><li>多路访问</li></ul><p>设备</p><ul><li>以太网</li><li>局域网交换机</li></ul><h3><span id="链路层概述">链路层概述</span></h3><p>链路层协议</p><ul><li>通过<em>单段链路</em>，<em>点到点</em>传送上层数据报</li><li>链路两端结点间交互的帧格式，发送和接收帧时的操作</li></ul><p>两种网络链路类型</p><ul><li>点对点链路和广播链路 链路层环境重要特点</li><li>一条路径上的不同链路可运行不同的链路层协议</li><li>链路层协议提供的服务可以不同</li><li>通信环境较为简单</li></ul><p>链路层服务的设计问题</p><ol type="1"><li><em>帧访问链路</em><ul><li>用<strong>媒体访问控制(MAC)</strong>地址标识源、目的地</li></ul></li><li>相连节点间的<em>可靠交付</em></li><li>流量控制</li><li>查错检测</li><li>纠错</li></ol><h3><span id="成桢">成桢</span></h3><p><em>面向比特的协议</em></p><ul><li>面向比特的协议把帧看成比特的集合</li><li><img src="/images/计算机网络/DraggedImage-15.png"></li><li>帧的开始和结束：<code>01111110</code></li><li><em>比特填充 (bit stuffing)法</em>(用于发送前/接收后)<ul><li>发送方：若报文中5个连续1，则插入一个0</li><li>接收方：收到5个连续1：<ul><li>如果后面为0 ，去掉；</li><li>如果后面为1，再后为0，则帧结束;否则出错</li></ul></li></ul></li></ul><p><em>PPP协议</em></p><ul><li>点对点协议</li><li>家庭主机点对点链路的链路层协议</li><li><img src="/images/计算机网络/DraggedImage-16.png"></li></ul><p><em>面向字节的协议</em></p><ul><li>每帧都看成是字节的集合</li><li>保留一组字符为控制字符</li><li><em>效率较低，目前已很少使用</em></li><li>DLE字符的“转义”作用</li></ul><h3><span id="差错检测和纠错技术">差错检测和纠错技术</span></h3><p>处理帧差错的两种方法</p><ol type="1"><li>检错重发<ul><li>差错率低效果好</li><li>适合<em>链路差错率</em>很<em>低</em>的场合，如有线通信</li></ul></li><li>前向纠错（Forward Error Correction, FEC ）<ul><li>纠错通过额外信息“预先”进行</li><li>时效性好</li><li>适合<em>对时间要求</em>很<em>高</em>的场合，如航天和实时控制</li></ul></li></ol><p><strong>差错检测</strong></p><ul><li>EDC= 差错检测和纠错比特 (冗余)</li><li>D = 数据由差错校验保护，可能包括首部字段</li><li>奇偶校验<ul><li>单比特奇偶校验<ul><li>检测单个比特差错</li></ul></li><li>二维比特奇偶校验<ul><li>检测和<em>纠正</em>单个比特差错</li></ul></li></ul></li><li><strong>互联网校验和</strong><ul><li>目标:检测传输段中的“差错”(如比特翻转) (注意: 仅用于运输层)</li><li>发送方：<ul><li>将段内容作为16比特整数序列来处理</li><li>检验和: <em>段内容相加(补码和) </em></li><li>发送方将检验和的值取反放入 UDP 检验和字段</li></ul></li><li>接收方：<ul><li>计算接收到段的检验和</li><li>检查是否计算的检验和等于检验和字段的值:<ul><li>NO – 检测到差错</li><li>YES – 没有检测到差错，仍可能有错</li></ul></li></ul></li><li>注意:当作加法时，最高位进比特位的进位需要加到结果中</li><li><img src="/images/计算机网络/DraggedImage-17.png"></li></ul></li><li><strong>CRC</strong><ul><li><img src="/images/计算机网络/DraggedImage-18.png"></li><li>将数据比特D看作一个二进制数</li><li>选择r+1比特模式(生成式)G<ul><li>目标:选择r个CRC 比特R, 使得 &lt;D,R&gt; 被G整除 (以2为模)</li><li>接收方知道G, 用G除以&lt;D,R&gt;。如果有非零余数:检测到差错!</li><li>能够检测所有小于r+1比特的突发差错</li></ul></li><li><img src="/images/计算机网络/DraggedImage-19.png"></li></ul></li></ul><h3><span id="可靠传输原理">可靠传输原理</span></h3><p><em>SW0协议</em></p><ul><li><strong>信道不丢包</strong></li><li>停止等待(stop-and-wait, SW)协议</li><li>方案<ul><li>接到正确PKT，发送一个肯定确认(ACK)</li><li>收到错误PKT，发送一个 否定确认(NAK)，重传原 PKT</li></ul></li><li>问题：若信道丢包，则发送方会一致等待接收方的确认到来，从而产生<em>协议死锁</em></li><li><img src="/images/计算机网络/DraggedImage-20.png"></li></ul><p><em>SW1协议</em></p><ul><li><strong>信道丢包</strong></li><li>解决方案: <em>增加超时定时器</em></li><li>每发PKT，启动超时定时器，称为<em>超时重传机制</em></li><li>重传时间略大于RTT</li><li>问题：当确认分组丢失时，接收方会收到两个同样的PKT</li><li><img src="/images/计算机网络/DraggedImage-21.png"></li></ul><p><em>SW2协议</em></p><ul><li>解决方案: 增加一种新机制：<strong>发送序号</strong></li><li>序号只需1比特，因为它可以让接收方知道发送方是否在重传前一个分组</li><li>问题：若ACK迟到，则发送方判断包超时重发，结果刚发完就收到了ACK，SW2无法知道这个ACK确认的是哪个包</li><li><img src="/images/计算机网络/DraggedImage-22.png"></li></ul><p><em>SW3协议</em>(rdt2.2)</p><ul><li>解决方案: 增加<strong>确认序号机制</strong>，分辨出确认对应哪个分组</li><li>综合以上机制为SW协议，或自动重传请求 (ARQ, Automatic Repeat Request)<ul><li>差错检测</li><li>接收方确认</li><li>重传</li><li>定时器</li><li>序号</li></ul></li><li>发送方FSM <img src="/images/计算机网络/DraggedImage-23.png"></li></ul><p>作业</p><ol type="1"><li>链路层协议能够向网络层提供哪些可能的服务? 举例说明链路层协议相应的服务 答：链路层协议能够向网络层提供的服务包括:<em>成帧、差错检测、可靠交付、 媒体访问、流量控制</em>。 例如，HDLC 协议提供了数据链路层的成帧和 CRC 检测功能等。</li><li>考虑4 bit的生成多项式G(x)=x3+1，假设数据M(x) 的值为10101010。附加比特R(x)的值是什么?</li></ol><p><em>流水线可靠数据传输协议</em></p><ul><li>流水线: 发送方允许发送多个传输中、未应答的分组<ul><li>必须增加序号范围</li><li>发送方和/或接收方设有缓冲</li></ul></li><li>例子 <img src="/images/计算机网络/DraggedImage-24.png"></li></ul><p><strong>回退N步 (Go-Back-N, GBN)</strong></p><ul><li>发送方<ul><li>在分组首部需要K比特序号，2的k次方=N</li><li>“窗口”最大为N, 允许N个连续的没有应答分组</li><li><img src="/images/计算机网络/DraggedImage-25.png"></li><li>ACK(n)：确认所有（包括序号n）的分组-&gt;<strong>累计ACK</strong><ul><li>可能收到重复的分组</li></ul></li><li>对每个传输分组用<em>同一个计时器</em></li><li>timeout(n)：重传窗口中的<em>分组n及所有更高序号的分组</em></li><li>发送窗口为3，序号为0, 1, 2, 3 <img src="/images/计算机网络/DraggedImage-26.png"></li></ul></li><li>接收方<ul><li>接收方根据滑动窗口的序号按序接收分组，<em>窗口内连续</em></li><li>窗口中<em>失序分组及后面将被丢弃</em></li><li>接收方采用<strong>累积确认</strong>的方式，可以不一一确认</li><li>GBN协议的接收窗口的长度为1<ul><li>如果允许接收窗口的长度大于1，就不必重发已发送过的N个分组，于是得到选择重传协议</li></ul></li></ul></li></ul><p><strong>选择重传 (Selective Repeat, SR)</strong></p><ul><li>接收方分别确认所有正确接收的报文段<ul><li><em>缓存分组</em>, 以便最后按序交付给上层</li></ul></li><li>发送方只需要<em>重传没有收到ACK的分组</em><ul><li>发送方定时器<em>对每个没有确认的分组计时</em></li></ul></li><li>发送窗口<ul><li>N个连续的序号</li><li>也需要限制已发送但尚未应答分组的序号</li><li><strong>窗口长度小于等于序号空间的一半</strong></li></ul></li><li><img src="/images/计算机网络/DraggedImage-27.png"></li><li>发送方<ul><li>上层传来数据：<ul><li>如果窗口中下一个序号可用, 发送报文段</li></ul></li><li>timeout(n)：重传分组n，重启计时器</li><li>ACK(n)：在[发送基，发送基+N\]<ul><li>标记分组 n 已经收到</li><li>如果n 是最小未收到应答的分组，向前滑动窗口基指针到下一个未确认序号</li></ul></li></ul></li><li>接收方<ul><li>分组n在[接收基，接收基+N-1\]<ul><li>发送ACK(n)</li><li>失序：缓存</li><li>按序：交付(也交付所有缓存的按序分组),向前滑动窗口到下一个未收到报文段的序号</li></ul></li><li>分组n在[接收基-N，接收基-1\]<ul><li>发送ACK(n)</li></ul></li><li>其他：忽略</li></ul></li><li><img src="/images/计算机网络/DraggedImage-28.png"></li></ul><p>作业</p><ol type="1"><li>在课件中给出了SW3的发送方FSM，请画出协议SW3的接收方的FSM。 <img src="/images/计算机网络/DraggedImage-29.png"></li><li>考虑讨论流水线时的例子，网络跨越国家的例子。窗口长度设置成多少时，才能使该信道的利用率超过90%?</li><li>考虑一种GBN协议，其发送方窗口为3，序号范围为1,024。假设在时刻t， 接收方期待的下一个有序分组的序号是k。假设介质不会对报文重新排序。 回答以下问题:<ol type="a"><li>在t时刻，发送方窗口内的报文序号可能是多少?为什么? b.在t时刻，在当前传播回到发送方的所有可能报文中，ACK字段中所有可能值是多少?为什么?</li></ol></li></ol><h3><span id="多路访问协议">多路访问协议</span></h3><p>多个发送/接收结点<em>同时使用广播信道</em>，如何协调它们<em>共享</em>一个信道 ？</p><p>信道只有一个，访问结点多个，如何设计共享算法？</p><ul><li>当多个结点频繁访问信道<ul><li>协同结点无碰撞，统一控制效率高</li></ul></li><li>当大量结点偶尔访问信道<ul><li>结点随机占资源，简单算法解碰撞</li></ul></li></ul><p>多路访问协议</p><ul><li>信道划分<ul><li>将信道划分为较小的“段” (<em>时隙，频率，编码</em>) 为每个结点分配一部分专用</li></ul></li><li>轮流<ul><li>结点轮流，信息较多的轮流发送的时间较长</li></ul></li><li>随机访问<ul><li>不划分信道，允许碰撞</li><li>设法从“碰撞”恢复</li><li>大量结点以小概率发送分组<ul><li>以信道全部速率R传输</li><li>结点间无优先权协调</li></ul></li><li>随机访问MAC协议定义了:<ul><li>如何检测碰撞</li><li>如何从碰撞中恢复 (例如，经延迟后重新传输)</li></ul></li><li>随机访问MAC协议的实例:<ul><li>ALOHA</li><li>时隙ALOHA</li><li>CSMA, CSMA/CD, CSMA/CA</li></ul></li></ul></li></ul><p><em>信道划分MAC协议: TDMA</em></p><ul><li>“循环”访问信道</li><li>每个站点在每个循环中获得固定长度时隙(长度=分组传输时间)</li><li>不使用的时隙则空闲</li></ul><p><em>信道划分MAC协议: FDMA</em></p><ul><li>信道频谱划分为频带</li><li>每个站点分配固定的频带</li><li>频带中未使用的传输时间空闲</li></ul><p><em>TDMA和FDMA特点</em></p><ul><li>消除了碰撞且公平<ul><li>结点在每个帧时间内得到了专用的传输速率R/N bps</li></ul></li><li>若系统仅有少数几个有大量分组要发送的结点<ul><li>分配的频率或时隙被浪费</li></ul></li><li>适合场合<ul><li>所有结点都持续有大量数据发送</li></ul></li></ul><p>轮流协议</p><ul><li>令牌传递（无中心）<ul><li>控制令牌从一个结点顺序地传递到下一个</li></ul></li><li>轮询（有中心）<ul><li>主结点“邀请”从结点依次传输</li></ul></li><li>适用于希望共享信道但却无法预测访问结点的数量的场景</li></ul><p><strong>ALOHA</strong></p><ul><li>非时隙ALOHA: 无同步要求<ul><li><img src="/images/计算机网络/DraggedImage-30.png"></li></ul></li><li>时隙ALOHA<ul><li><img src="/images/计算机网络/DraggedImage-31.png"></li><li>效率：最大1/e=0.37</li><li>优点<ul><li>效率高</li></ul></li><li>缺点<ul><li>有碰撞/空闲时隙，浪费时隙</li><li>时钟同步困难</li></ul></li></ul></li></ul><p><strong>CSMA(载波侦听多路访问)</strong></p><ul><li><em>发前先听</em><ul><li>如果侦听到信道忙, 推迟传输</li><li>如果侦听到信道空闲: 传输整个帧</li><li><em>仍可出现碰撞</em>: 传播时延意味着两个结点也许不能听到其他结点传输</li></ul></li><li><em>边发边听</em><ul><li>发送时侦听到信道忙, 立即停止;</li><li>转发强化冲突信号</li></ul></li></ul><p><strong>CSMA/CD (碰撞检测)</strong></p><ul><li>在短时间内检测到碰撞</li><li>碰撞的传输尽快结束，以减少信道浪费</li><li>碰撞检测<ul><li>在有线的LAN中容易: 测量信号强度，比较传输的和接收的信号</li><li>在无线LAN中困难:碰撞可能听不到</li></ul></li><li><img src="/images/计算机网络/DraggedImage-32.png"></li></ul><p>协议比较</p><ul><li>信道划分MAC协议<ul><li>在高负载时高效、公平地共享信道</li><li>低负载时低效:信道访问中延时，当1个活跃结点时，甚至仅有分配了 1/N 带宽!</li></ul></li><li>随机访问MAC协议<ul><li>低负载是有效:单个结点能够全面利用信道</li><li>高负载:碰撞开销大</li></ul></li><li>轮流协议<ul><li>兼有两方面的优点!</li></ul></li></ul><p>作业</p><ol type="1"><li>在分析多路访问协议时进行了哪些假设?现有的几十种多路访问协议是如何分类的?这种分类的方法与结点数 量和结点访问信道的频率是否有关?</li><li><img src="/images/计算机网络/DraggedImage-33.png"></li></ol><h3><span id="以太网">以太网</span></h3><p><em>以太网(Ethernet)帧结构</em></p><ul><li><img src="/images/计算机网络/DraggedImage-34.png"></li><li>前导码<ul><li>模式为10101010 的7个字节，后跟模式为 10101011 的一个字节</li><li>用于同步接收方，发送方时钟速率</li></ul></li><li>地址: 6字节<ul><li>如果适配器接收具有匹配的<em>目的地址</em>或<em>广播地址</em>(如ARP分组)的帧, 它将帧中的数据提交给网络层协议</li><li>否则, 适配器丢弃帧</li></ul></li><li>类型: 指示较高层协议 (大多数为IP但也可以支持其他类型如 Novell IPX和AppleTalk)</li><li>CRC: 在接收方核对;如果检测到差错，该帧被丢弃</li></ul><p><em>MAC地址</em></p><ul><li>LAN地址=物理地址=MAC地址，通常用6字节16进制表示<ul><li>如1a-03-65-3F-2e-46</li></ul></li><li>共有2的48次方个LAN地址</li><li>IEEE地址分配方式：固定前24 bit，公司生成后24 bit，每个适配器具有唯一MAC地址</li><li>适配器的MAC地址具有扁平(没有层次)结构，且保持不变</li></ul><p><em>以太网协议(CSMA/CD)</em></p><ul><li><strong>无连接</strong>: 在发送和接收适配器之间没有握手</li><li><strong>不可靠</strong>: 接收适配器不向发送适配器发送应答或否定应答</li><li><strong>发前先听；边发边听；强化碰撞；指数后退</strong></li><li>CSMA/CD<ol type="1"><li>适配器从网络层接收数据报并生成帧</li><li>如果适配器感知信道空闲，它开始传输帧；如果它感知信道忙，等待信道空闲再传输</li><li>当适配器传输整个帧时，一直在检测</li><li>如果检测传输过程中的其他传输, 中止并发送强化冲突信号</li><li>中止后, 适配器进入指数回退: 在第m次碰撞后, 适配器随机地从[0,1,2,…, 2^m-1]选择一个K值。适配器等待K·512 比特时间并返回到第2步</li></ol></li></ul><p>特点</p><ul><li>强化冲突信号<ul><li>确保所有的其他传输方都知道碰撞</li><li>48 bit长</li></ul></li><li>比特时间<ul><li>对10 Mbps 以太网传每比特需 0.1 μs</li><li>对K=1023, 等待时间约为50 msec</li></ul></li><li>指数回退算法<ul><li>目标：估计当前负载，适应重传尝试<ul><li>重负载时，随机等待时间更长</li></ul></li><li>首次碰撞后: 从[0,1] 中 选择K；时延是K*512 bit 传输时间</li><li>第二次碰撞后: 从[0,1,2,3]选择 K ……</li><li>10次碰撞后, 从[0,1,2,3,4,…, 1023] 选择K</li></ul></li><li>效率 <img src="/images/计算机网络/DraggedImage-35.png"></li></ul><h3><span id="链路层交换机">链路层交换机</span></h3><p>集线器</p><ul><li>将来自某链路的比特放大后从其他所有链路传出</li><li>可能与来自其他结点的比特碰撞</li><li>无帧缓存</li><li>集线器相当于一根导线，碰撞检测由适配器完成</li></ul><p><strong>交换机</strong></p><ul><li>存储并转发以太网帧</li><li>当帧在网段上转发时，检查帧首部并基于MAC目的地址，选择性地向一个或多个出链路转发帧</li><li>当帧在网段上转发时，使用CSMA/CD 访问网段</li><li>全双工、无碰撞</li><li>透明性<ul><li>主机不知道交换机存在</li></ul></li><li>即插即用, 自学习<ul><li>交换机不必配置</li></ul></li><li>流量隔离<ul><li>交换机将子网分割成LAN段</li><li>交换机过滤分组:<ul><li>相同LAN段的帧通常不在其他LAN段上转发</li><li>段成为分离的碰撞域</li></ul></li></ul></li></ul><p><strong>交换机表</strong></p><ul><li>当收到帧时，交换机“学习”到发送方位置：入链路</li><li>在交换机表中记录下发送方/位置对</li><li>表结构：(MAC地址，接口，TTL)</li></ul><p>帧过滤/转发算法</p><ol type="1"><li>记录与发送主机关联的链路</li><li>使用MAC目的地址索引交换机表 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if 找到目的地项</span><br><span class="line">then&#123;</span><br><span class="line"> if 目的地位于帧到达的段</span><br><span class="line">then 丢弃帧</span><br><span class="line">else 在指示的接口转发该帧</span><br><span class="line">&#125;</span><br><span class="line">else 洪泛</span><br></pre></td></tr></table></figure></li></ol><p>作业</p><ol type="1"><li>考虑某让所有结点直接与一个集线器相连的100 Mbps的100BASE-T以太网。为了获得0.5的效率，结点和集线器之间的最大距离是多少？假设帧长为64 byte并且中间没有转发器。这个最大距离也确保正在传输的结点A能够检测出当A在传输时是否有其他任何结点在传输吗？为什么？你得到的最大距离和实际的100 Mbps标准比较将有什么结论？ <em>只要T0&gt;2t(tao)就能检测出有其他节点传输</em>？</li><li>考虑在图3-26环境中的交换机的情况。假定(i)A向D发送一个帧，(ii)D向A回答一个帧，(iii)C向D发送一个帧，(iv)D向C回答一个帧。该交换机表初始为空。显示在这些时间的前后该交换机表的状态。对于这些事件的每个，确定传输的帧在上面的转发的链路，并简要地论证你的答案。 <img src="/images/计算机网络/DraggedImage-36.png"></li></ol><h2><span id="网络互联">网络互联</span></h2><h3><span id="网络层概述">网络层概述</span></h3><p>异构网络</p><ul><li>在体系结构和通信协议方面具有差异的计算机网络</li><li>在寻址方法、分组长度、路由选择、差错恢复等方面不同，无法直接通信</li></ul><p>互联互通需采用<em>网络层中继系统</em>对不同协议的语法、语义和时序进行转换</p><ul><li>IP具有统一的协议和地址，为全局性寻址和路由选择进而实现网络互联互通提供了可能</li><li>IP网络是虚拟网络，提供全局性路由选择和转发功能，下层网络提供了分组传送交付功能</li><li>路由器是连接异构网络的关键设备，至少有两个接口，最高层是网络层</li><li>端系统有协议栈所有层次，沿途网络层协议的共同作用下，形成了主机到主机的端到端路径</li></ul><p>网络层服务</p><ul><li>底层直接连接的网络可为<em>异构</em>，网络层提供互联互通</li><li>多条传送分组，需要网间路由器进行<em>分组转发</em>和<em>路由选择</em></li><li>关键功能<ul><li>转发</li><li>路由选择</li><li><em>路由</em>：分组从源到目的地所经过的端到端路径</li></ul></li></ul><p>分组交付</p><ul><li>直接交付<ul><li>在一个<em>直接连接的网络</em>上时，分组从一台主机上直接传送到另一台主机的过程</li></ul></li><li><em>间接交付</em><ul><li><em>不</em>在一个直接连接的网络上时，源主机必须先把分组发给一个路由器</li><li>可能使用不同的网络地址</li></ul></li></ul><h3><span id="网络服务模型">网络服务模型</span></h3><p>网络服务模型与采取的链接方式有关</p><ul><li>面向连接服务<ul><li>虚电路 (Virtual-Circuit, VC) 网络<ul><li>连接</li></ul></li></ul></li><li>无连接服务<ul><li>数据报 (Datagram) 网络<ul><li>在网络层无呼叫建立</li><li>路由器:没有端到端连接的状态<ul><li>无网络级“连接”的概念</li></ul></li><li>分组使用目的主机地址转发<ul><li>在相同源和目的对可能采用不同的路径 <img src="/images/计算机网络/DraggedImage-37.png"></li></ul></li></ul></li></ul></li></ul><p>因特网IP服务模型（数据报网络）的优势</p><ul><li>简化了中继设备路由器的设计</li><li>容易互联使用不同的链路层技术</li><li>网络故障容易修复</li><li>尽力而为<ul><li>不可靠</li><li>无连接</li><li>服务是尽力而为的<ul><li>编址方案</li><li>提供标识因特网中所有主机的方法</li></ul></li></ul></li><li><em>不可靠的、尽力而为和无连接分组交付系统</em> <img src="/images/计算机网络/DraggedImage-38.png"></li></ul><p>作业</p><ol type="1"><li>根据图4-1，为什么说IP网络是一个虚拟网络? 如果IP网络不实际传输分组，那么它的作用是什么? 答：<em>直接连接的网络是能够实际传送分组的通信网</em>，<em>但</em>它们通常覆盖区域较小、<em>协议异构</em>且没有统一的地址，无法互联互通。设计了具有统一 IP 地址和规格的 IP 协议，其他<em>异构网络通过 IP 网络转换了格式进行中继</em>，使得它们能够网络互联互通。因此，<em>IP 网络</em>相当于在异构的直接连接的网络之上构建的一个虚拟网络，它<em>仅仅提供在各个异构子网之间</em> <strong>全局性路由选择和转发功能</strong>，而下面网络则提供了分组实际的通信功能。</li><li>根据图4-2，试填写出路由器R3的转发表内容</li><li>分组的直接交付和间接交付有什么区别与联系?在<br>交付过程中，它们分别要用到哪些层次的地址?</li></ol><h3><span id="网际协议ip">网际协议（IP）</span></h3><p><em>IP数据报</em></p><ul><li><img src="/images/计算机网络/DraggedImage-39.png"></li><li>分片和重新组装<ul><li>MTU-最大传输长度</li><li>大IP 数据报被分 割(“分段”)<ul><li>一个长数据报分成几个短数据报</li><li>仅在最后目的地“重新装配”</li><li>IP首部比特用于标识、排序相关段 <img src="/images/计算机网络/DraggedImage-40.png"></li></ul></li></ul></li></ul><p><em>IP编址</em></p><ul><li>点分十进制记法</li><li>IP地址: 对主机、路由器 接口的32 bit 标识符</li><li>接口: 在主机/路由器和物理链路之间的连接<ul><li>路由器通常具有多个接口</li><li>主机可能具有多个接口</li><li>IP编址与每个接口相联系</li></ul></li><li><em>子网掩码</em><ul><li>早期表示的IP地址 = {&lt;网络号&gt;, &lt;子网号&gt;, &lt;主机号&gt;\}</li><li>例：192.168.143.3/27， 即子网掩码共有27个连续的1</li></ul></li><li>无类别域间路由选择（CIDR）<ul><li>对于解决因特网路由器转发表空间急剧膨胀的问题至关重要</li><li>IP地址 = {&lt;网络地址&gt;/&lt;前缀&gt;\} <img src="/images/计算机网络/DraggedImage-41.png"></li><li><strong>最长前缀匹配原则</strong> <img src="/images/计算机网络/DraggedImage-42.png"><ul><li>200.19.25.170前20 bit与表中的第一项 匹配，而该地址的前<em>23 bit</em>与表中的第二项匹配:应选择与表中的第二项相匹配</li></ul></li></ul></li><li>特殊的IP地址 <img src="/images/计算机网络/DraggedImage-43.png"></li><li>网络怎样得到IP地址的子网部分?<ul><li>从它的ISP的地址空间得到分配的部分</li></ul></li><li>ISP怎样得到地址块?<ul><li>从<em>因特网名字与号码分配团体( Internet Corporation for Assigned Names and Numbers,ICANN ) </em></li></ul></li></ul><p><strong>DHCP: Dynamic Host Configuration Protocal</strong></p><ul><li>目的：使主机在它进入网络时从网络服务器动态获取其IP地址<ul><li>能够更新IP和租用期</li><li>允许地址重复</li><li>支持移动用户</li></ul></li><li>概述<ul><li>主机广播 <em>DHCP discover</em> 报文</li><li>DHCP服务器用 <em>DHCP offer</em> 报文响应</li><li>主机请求IP地址 <em>DHCP request</em> 报文</li><li>DHCP服务器发送地址 <em>DHCP ack</em> 报文 <img src="/images/计算机网络/DraggedImage-44.png"></li></ul></li><li>不仅仅提供IP地址<ul><li>IP地址</li><li>客户第一跳路由器地址</li><li>DNS服务器的名字和IP地址</li><li>网络掩码</li></ul></li><li>详细过程<ul><li>DHCP请求依次封装在UDP 中、IP中、802.3 Ethernet中</li><li>以太网帧在LAN中广播 (dest: FFFFFFFFFFFF), 被运行DHCP服务器的主机名路由器收到</li><li>Ethernet依次解封装到IP、 UDP、DHCP</li></ul></li></ul><p><em>NAT 网络地址转换</em></p><ul><li>外部仅看到本地网络使用的一个IP地址<ul><li>对ISP无需分配地址范围:对所有设备只用一个IP地址</li><li>能够改变本地网络中的设备地址，而不必通知外部</li><li>本地网络中的设备不显式地可寻址、由外部所见(增强安全性) <img src="/images/计算机网络/DraggedImage-45.png"></li></ul></li><li>争议<ul><li>路由器的处理上升为第三层</li><li>违反了端到端原则<ul><li>应用设计者必须要考虑 NAT可能性，如 P2P应用程序</li></ul></li><li>地址短缺应当由IPv6来解决</li></ul></li></ul><p><strong>ARP: Address Resolution Protocol</strong></p><ul><li>问题：虚拟网络IP地址与直接相连的网络MAC地 址如何打交道?</li><li><em>链路层协议</em></li><li>LAN上每个IP结点(主机、 路由器)都有ARP表</li><li>ARP表: 结点的IP/MAC 地址映射<ul><li><em>&lt;IP地址; MAC地址; TTL&gt;</em></li><li>TTL (寿命): 地址映射被 B 忘记的时间(常为20分钟)</li></ul></li><li>节点在相同LAN<ul><li>A向B发数据报, 且B的MAC地址不在A的ARP表中</li><li>A广播ARP 请求分组, 包含B的IP地址</li><li>目的地MAC地址 = FF-FF-FF-FF-FF-FF</li><li>LAN上所有机器接收 ARP请求</li><li>B接收ARP分组，用自己MAC地址回答A</li><li>A在其ARP表中缓存(保存) IP与MAC的地址对，直到信息超时<ul><li>软状态:除非不断更新信息，否则超时</li><li>ARP是“<em>即插即用</em>”的 结点自行创建其ARP表，无需网络管理员干预 <img src="/images/计算机网络/DraggedImage-46.png"></li></ul></li></ul></li><li>节点在不同LAN<ul><li>A比较E的网络地址，发现不在相同网络，送路由器R(间接)</li><li>A使用ARP从10.10.10.4得到R的MAC地址</li><li>A生成以<em>R的MAC地址作</em>为目的地的<em>链路层帧</em>,帧包含<em>A到E</em> <strong>IP 数据报</strong></li><li>A的适配器发送帧，R的适配器接收帧</li><li>R从帧中看到它目的地是E，使用选路协议确定路由器端口</li><li>R出端口发现E在右侧网络，用ARP得到E的MAC(直接)</li><li>R生成包含A到E IP数据报的帧向E发送</li><li>E收到来自A的IP分组 <img src="/images/计算机网络/DraggedImage-47.png"></li></ul></li></ul><p><em>ICMP: Internet Control Message Protocol</em></p><ul><li>设计用于网 络维护和管理</li><li>允许端系统或路由器报告差错情况，为网管人员提供适当的工具以查询网络结点的信息</li><li><em>IP 数据报携带ICMP 报文</em></li><li>Traceroute原理<ul><li>源向目的地发送一系列UDP段<ul><li>第一个 TTL = 1</li><li>第二个 TTL= 2,</li><li>......</li><li>最后一跳为不可能的端口号</li></ul></li><li>当第n个数据报到达第n个路由器:<ul><li>路由器丢弃数据报</li><li>向源发送一个ICMP报文(类型11, 代码0) 报文包括路由器名字和IP地址</li></ul></li><li>当ICMP报文到达，源计算 RTT</li><li>停止规则<ul><li>UDP段最终到达目的地主机</li><li>目的地返回ICMP “主机不可达”分组 (类型3, 代码3)</li><li>当源得到该ICMP, 停止</li></ul></li></ul></li></ul><p>作业</p><ol type="1"><li>从IP协议支持网络层编址和转发两大功能的角度看，IP协议数据报首部 至少要包括哪些字段?这些字段应当包括什么内容?</li><li>考虑使用8 bit主机地址的数据报网络。假定一台路由器使用最长前缀匹 配并具有下列转发表: <img src="/images/计算机网络/DraggedImage-48.png"> 对这4个接口，给出相关的目的主机地址的范围和在该范围中的地址数量。</li><li>在4-14网络环境中，若内网有30台主机从172.16.0.0/24地址块 中分配地址，公网地址为150.20.20.1。当内网主机浏览公网 Web网站(用80端口)和用FTP下载文件(用20端口)时，NAT的 端口随机申请。试填入NAT转换表的值。</li><li>在图4-17所示的网络中，端系统A要与端系统E通信。试简述 它们之间具体的通信过程。</li><li>设计ICMP用于处理网络管理问题的基本思路是什么? Traceroute程序的工作原理符合这个基本思路吗?</li></ol><h3><span id="路由选择协议及其算法">路由选择协议及其算法</span></h3><p><strong>路由选择</strong></p><ul><li>节点是路由器</li><li>边是物理链路</li><li>链路代价：时延、费用或拥塞等级</li><li>分类<ul><li>分散<ul><li>路由器知道物理相连的邻居、到邻居的链路费用</li><li>计算的迭代过程，与邻居交换信息</li><li><em>距离矢量（Distance-Vector, DV）算法</em></li></ul></li><li>全局<ul><li>所有路由器具有完全的拓扑、链路费用信息</li><li><em>链路状态（Link State algorithm, LS）算法</em></li></ul></li><li>静态</li><li>动态</li></ul></li></ul><p><strong>RIP：路由选择信息协议</strong></p><ul><li>距离矢量算法</li><li>距离测度: 跳的数量(最大 = 15跳)</li><li>特点<ul><li>仅与相邻路由器交换信息</li><li>交换本路由器选路表中的更新信息</li><li>按固定时间间隔交换信息，约30秒</li><li>根据更新信息，对本地RIP表进行处理</li></ul></li><li>思想<ul><li>如果邻居知道到达目的地的距离，且自己知道到达邻居的距离，则能算出自己到达目的地的距离<ul><li>每个结点周期性地向其邻居发送自己距离矢量</li><li>当结点x接收到来自邻居的新DV估计，它使用Bellman-Ford方程更新其自己的DV <img src="/images/计算机网络/DraggedImage-49.png"></li></ul></li></ul></li><li>每个结点： <img src="/images/计算机网络/DraggedImage-50.png"></li><li>算法 <img src="/images/计算机网络/DraggedImage-51.png"></li><li>问题<ul><li>链路费用变化<ul><li>好消息传播得快</li><li>坏消息传播得慢—“<em>计数到无</em>”问题!P171</li><li>在算法稳定前，反复迭代</li></ul></li></ul></li><li>例子 <img src="/images/计算机网络/DraggedImage-52.png"></li></ul><p><strong>OSPF：开放最短路优先</strong></p><ul><li>使用<em>链路状态(link state)</em>算法:<ul><li>网络拓扑和所有链路的费用都已知，可作为LS算法的输入</li></ul></li><li>LS算法依靠两种机制进行路由计算<ul><li>LS信息的可靠传输</li><li>积累的链路状态知识</li></ul></li><li>OSPF两个技术要点<ul><li>使用洪泛链路状态信息的链路状态协议</li><li>Dijkstra最低费用路径算法</li></ul></li><li>特色<ul><li>安全性：所有OSPF报文经鉴别（以防攻击）</li><li>允许多条费用相同的路径</li><li>在大规模网络中，用层次的OSPF</li></ul></li><li>Dijkstra算法<ul><li>知道网络所有结点的拓扑、链路费用</li><li>从一个结点(源)到所有其他 结点计算最低费用路径</li><li>迭代: k次迭代后，得知到k 个目的地的最低费用路径</li><li><code>c(x,y)</code>: 从结点x到y的链路 费用; = ∞ 如果非直接邻居</li><li><code>D(v)</code>:从源到目的地v路径费用的当前值</li><li><code>p(v)</code>: 从源到v沿路径的前任结点</li><li><code>N‘</code>: 已知在最小费用路径中的结点集合 <img src="/images/计算机网络/DraggedImage-53.png"></li></ul></li></ul><p>BGP和层次路由选择</p><ul><li>先将某区域的路由器聚合成为 “自治系统” （AS）</li><li>在相同AS中的路由器运行相同的路由选择协议</li><li>不同的AS中的路由器通过AS间的路由选择协议选路</li><li>BGP：边界网关协议</li></ul><h3><span id="路由器的工作原理">路由器的工作原理</span></h3><p>功能</p><ul><li><strong>转发</strong>：两个异构通信子网中的分组经过路由器的帧格式转换，实现了异构网络的互联</li><li><strong>路由选择</strong>：路由器通过执行路由选择协议，更新了转发表，并使分组到达正确的输出端口</li></ul><p>体系结构 <img src="/images/计算机网络/DraggedImage-54.png"></p><ul><li>输入接口卡 <img src="/images/计算机网络/DraggedImage-55.png"></li><li>输出接口卡 <img src="/images/计算机网络/DraggedImage-56.png"></li><li>控制器卡<ul><li>维护本地路由转发表</li><li>确定分组的输出接口</li><li>执行路由器中的网络管理功能</li></ul></li><li>交换结构<ul><li>内存交换</li><li>经总线交换</li><li>经互联网络交换</li></ul></li></ul><p>作业</p><ol type="1"><li>考虑图4-27上的网络。试用距离矢量算法给出结点b的距离表表项生成过程</li><li>考虑图4-27的网络。用Dijkstra的最短路算法计算出从b到所有网络结点的最短路径。通过计算一个类似于表4-10的表， 给出该算法的工作过程</li><li>BGP有哪些主要功能。描述在BGP中是如何检测路径中的环路 答：BGP 是 AS 之间供可达路径的分层路由选择协议。BGP 具有以下功能:<ol type="1"><li>从相邻 AS 处获得子网可达性信息;</li><li>向本 AS 内部的所有路由器传播这些可达性信息;</li><li>基于可达性信息和 AS 策略，决定到达子网的“好”路由。BGP 从相邻 AS 获得子网可达性信息，基于自己的策略，决定是否向其他 AS 通告， 一旦通告就承诺向该子网转发数据报;</li><li>BGP 还向本 AS 内部的所有路由器传播相关可达性信息。 在 AS-PATH 属性包含了传递前缀的通告所经过的 AS，由此可以判断是否存 在环路。</li></ol></li><li>观察图4-30所示的路由器体系结构。如何体现出路由器具有互联异构网络、转发和选择路由等几项关键功能。 答：<ul><li>互联异构网络:不同异构通信子网中的分组经过路由器的物理层、链路层和网络层功能转换，在 IP 层实现地址和报文结构的统一，能够进行统一寻址。</li><li>转发:分组进入路由器不同输入接口卡后，通过将分组目的地址与转发表进行比较，经过交换结构后，由输出接口卡输出到不同路由器不同接口。</li><li>路由选择:路由器接收来自不同路由器的路由选择报文，通过执行路由选择协议，更新了转发表内容，使分组能够到达正确的输出端口 。这些功能由路由器的控制器卡供，包括路由计算与更新、拓扑和地址信息交换。</li></ul></li></ol><h2><span id="端到端协议">端到端协议</span></h2><h3><span id="运输层协议概述">运输层协议概述</span></h3><p>运输服务和协议</p><ul><li>为形形色色的应用层进程利用共同的网络层尽力而为服务，提供了<em>多路复用／分解</em>的功能，以及<strong>可靠传输、流量控制和网络拥塞控制</strong>功能</li><li>可靠、按序的交付：TCP<ul><li>面向连接服务</li><li>可靠数据传送服务</li><li>拥塞控制服务</li><li>传送的数据单位是TCP报文段</li></ul></li><li>不可靠、不按序交付: UDP<ul><li>扩展了尽力而为IP基本服务</li><li>传送的数据单位是 UDP 报文或用户数据报</li></ul></li></ul><h3><span id="多路复用与多路分解">多路复用与多路分解</span></h3><p><em>端口</em></p><ul><li>定位器端口连同IP地址，唯一标识进程</li><li>端口扩展了网络地址</li><li>进程标识符标识本地进程</li><li>端口号为16 bit的数，其大小在0到65535之间</li><li>0到1023范围的端口号称为周知端口号</li></ul><p>进程通过<em>套接字(socket)</em>来描述网络两端进程间的通信链。</p><p>UDP的多路复用／分解</p><ul><li>UDP套接字由二元组标识 ：<em>(目的地IP地址, 目的地端口号) </em></li><li>具有<em>不同</em>源IP地址和/或源端口号的IP数据报可定向到<em>相同</em>的套接字</li><li>主机上进程目的端口号相同，UDP套接字相同</li><li>一个UDP套接字对应着一条UDP通信链</li></ul><p><em>TCP的多路复用／分解</em></p><ul><li>TCP套接字由四元组标识: <em>(源IP地址, 源端口号; 目的地IP地址, 目的端口号) </em></li><li>服务器主机可能支持许多并行的TCP套接字<ul><li>每个套接字由其自己的四元组标识</li></ul></li><li>Web服务器对每个连接的客户具有不同的套接字<ul><li>如非持续HTTP将为每个请求具有不同的套接字</li></ul></li></ul><h3><span id="udp">UDP</span></h3><p>UDP优点</p><ul><li>无连接</li><li>简单</li><li>效率高</li><li>面向报文</li><li>没有拥塞控制</li></ul><p>UDP只做了运输协议的最少工作在IP之上加入<em>多路复用/多路分解</em>和<em>错误检测</em></p><p>重要应用</p><ul><li>DNS</li><li>RIP选路表更新报文</li><li>网络管理数据</li></ul><p><img src="/images/计算机网络/DraggedImage-57.png"></p><p>UDP校验和=互联网校验和</p><p>作业</p><ol type="1"><li>根据网络应用的时延和可靠性可以将它们分为几类?运输层是否应当由此设计几种不同的协议?因特网的运输层协议能够为网络应用提供哪些服务?不能够提供哪些服务? 答：<strong>不能够提供</strong>带宽和时延保证、安全性服务等</li><li>可以认为端口号是一种地址吗?如果是，它是标识什么的地址?将端口号分为周知端口号和一般端口号有什么好处， 这与网络应用的模式有关系吗? 答：好处：<em>大大地降低了出处差错的可能性</em>。一般在 C/S 模式中，服务器端口通常使用周知端口好，而且必须要长期处于 打开状态，因此端口号划分与网络设计模式有关。</li><li>给出标识图5-5中TCP套接字的所有四元组。与UDP套接字忽略了源端的标识信息相比，TCP的套接字标识能力是增强了还是削弱了?</li></ol><h3><span id="tcp">TCP</span></h3><p>特点</p><ul><li>面向连接</li><li>点对点</li><li>全双工<ul><li>MSS：最大报文段长度</li><li>MTU：最大传输单元</li></ul></li><li>可靠的交付服务</li><li>客户／服务器模式</li><li>面向字节流</li><li>流量控制</li><li>拥塞控制</li></ul><p><img src="/images/计算机网络/DraggedImage-58.png"></p><p>TCP 的首部包括以下内容：</p><ol type="1"><li>源端口 source port</li><li>目的端口 destination port</li><li>序号 sequence number</li><li>确认号 acknowledgment number</li><li>数据偏移 offset</li><li>保留 reserved</li><li>标志位 tcp flags</li><li>窗口大小 window size</li><li>检验和 checksum</li><li>紧急指针 urgent pointer</li><li>选项 tcp options</li></ol><p><em>TCP可靠数据传输机制</em></p><ul><li>使用<em>序号、确认、超时重传、滑动窗口</em>等机制</li><li>数据是无结构、有序的字节流<ul><li>报文段的<em>序号</em>是该报文段字节流的<em>首字节编号</em></li></ul></li><li>TCP的高效载答机制<ul><li>确认机制是<em>捎带(piggybacked)</em>的</li><li>确认号是<em>期望收到的下一字节的编号</em></li></ul></li><li>累积确<ul><li>确认号隐含表明了前面所有字节已正确收到</li></ul></li><li>对失序报文段的处理方式<ul><li>未规定，可用“回退N步协议”和“选择重传协议”</li></ul></li><li>初始序号的选择<ul><li>双方均可<em>随机地选择</em></li></ul></li><li>超时时限 &gt; RTT</li><li>RTT估计值 = (1 - a) x RTT估计值 + a x RTT样本<ul><li>指数加权移动平均</li><li>典型值 a = 0.125</li></ul></li><li>RTT偏差</li></ul><p>作业</p><ol type="1"><li>主机A和B经一条TCP连接通信，并且主机B已经收到了来自A的 到字节248的所有字节。假定主机A随后向主机B发送两个紧接 着的报文段。第一个和第二个报文段分别包含了40和60 byte的数据。在第一个报文段中，序号是249，源端口号是503, 目的地端口号是80。无论何时主机B接收到来自主机A的报文段，它都会发送确认。<ol type="a"><li>在从主机A发往B的第二个报文段中，序号、源端口号和目的端口号各是什么?</li><li>如果第一个报文段在第二个报文段之前到达，在第一个到达报文段的确认中，确认号、源端口号和目的端口号各是什么?</li><li>如果第二个报文段在第一个报文段之前到达，在第一个到达报文段的 确认中，确认号是什么?</li><li>假定由A发送的两个报文段按序到达B。第一个确认丢失了而第二个确认在第一个超时间隔之后到达，如在下一页上的图中所显示的那样。 画出时序图，显示这些报文段和发送的所有其他报文段和确认。(假设没 有其他分组丢失。)对于你图上每个报文段，标出序号和数据的字节编号; 对于你增加的每个应答，标出确认号。</li></ol></li></ol><p><em>TCP流量控制</em></p><ul><li>让<em>接收方控制</em>发送方</li><li>控制方法：<em>发送方</em>维护一个<strong>接收窗口</strong></li><li>工作原理<ul><li>设置接收窗口Rwin<ul><li>Rwin用于向发送方提示<em>接收方的缓存还有多大</em></li><li><code>Rwin = RcvBuffer - [LastByteRcvd - LastByteRead]</code></li></ul></li><li>发送方不使接收缓存溢出<ul><li><code>LastbyteSent - LastByteAcked ≤ Rwin</code></li></ul></li><li>使TCP缓存不溢出<ul><li><code>LastbyteRcvd - LastByteRead ≤ RcvBuffer</code></li></ul></li><li>当接收窗口为<strong>0</strong>时，<em>A应当周期性地发送只有一个字节数据的报文段</em> <img src="/images/计算机网络/DraggedImage-59.png"></li></ul></li><li><em>流量控制与拥塞控制的区别</em><ul><li>流量控制是<strong>某TCP接收方</strong>针对<em>其发送方</em>所采取的措施</li><li>拥塞控制是TCP发送方<em>针对网络拥堵</em>情况所采取的措施</li></ul></li></ul><p><em>TCP连接管理</em></p><ul><li>三次握手<ol type="1"><li>客户向服务器发送TCP <em>SYN报文段</em><ul><li>指定初始序号</li><li>没有数据</li></ul></li><li>服务器收到SYN 报文段, 用<em>SYN ACK报文段</em>回复<ul><li>服务器为该连接分配缓冲区和变量</li><li>指定服务器初始序号</li></ul></li><li>客户收到SYN ACK，用<em>ACK报文段</em>回复，可能包含数据 <img src="/images/计算机网络/DraggedImage-60.png"></li></ol></li><li>四次挥手<ol type="1"><li>客户机向服务器发送<em>FIN报文段</em><ul><li>客户不再发送数据</li></ul></li><li>服务器收到FIN后，返回<em>ACK报文段</em><ul><li>通知应用进程对方关闭连接</li><li>服务器仍然可以发送数据</li></ul></li><li>服务器发送完数据，发送<em>FIN ACK报文段</em><ul><li>服务器释放连接，不再发送数据</li></ul></li><li>客户收到FIN ACK后，回复<em>ACK报文段</em><ul><li>等待超时，连接关闭</li></ul></li><li>服务器收到ACK后，连接关闭 <img src="/images/计算机网络/DraggedImage-61.png"></li></ol></li><li><em>为什么等待超时再关闭？</em><ul><li>确保全部接收服务器(B)发来的数据</li><li>有可以最后一个ACK丢失。所以<em>TIME_WAIT状态就是用来重发可能丢失的ACK报文</em></li></ul></li></ul><p><img src="/images/计算机网络/DraggedImage-62.png"></p><p><em>拥塞控制原理</em> <img src="/images/计算机网络/DraggedImage-63.png"></p><ul><li>成因<ul><li>当对网络中<em>某种资源的需求超过了其可用部分</em>。所出现的网络性能变差直至系统崩溃现象</li><li><em>Σ对资源的需求 &gt; 可用资源</em></li></ul></li><li>思路<ul><li>增加瓶颈资源</li><li><strong>抑制流量注入</strong></li><li>闭环控制</li></ul></li><li>方法<ul><li>端到端的拥塞控制<ul><li>不能从网络得到明确的反馈</li><li>从端系统根据观察到的时延/丢失推断出拥塞</li><li>TCP✅</li></ul></li><li>网络辅助的拥塞控制<ul><li>路由器为端系统提供反馈</li></ul></li></ul></li></ul><p>作业</p><ol type="1"><li>观察图5-9所示的TCP报文段结构，其中哪些字段分别与多路复用/分解功能有关?哪些字段分别与可靠数据传输功能有关?哪些字段分别与流量控制功能有关?哪些字段分别与拥塞控制传输功能有关? 答：源端口和目的端口；序号、确认号和检验和；窗口大小；序号和确认号</li><li>TCP创建连接采用了三次握手过程。分析第三次握手有何作用?当TCP一端释放连接后，这端是否还能够发送报文段?此时，另一端是否还能够继续发送报文段? 答：<em>在 TCP 创建连接的三次握手过程中，第三次握手表明第一次握手的确 是自己发送的，以防止第一次握手是以前遗留的连接</em>。 <img src="/images/计算机网络/DraggedImage-64.png"></li><li>网络拥塞的主要成因有哪些?它们带来的危害分别有哪些?有哪几种网络拥塞控制方法? 答：端到端；网络辅助</li><li>分析产生网络拥塞条件的式(5-6)，其中的资源通常包括哪些内容?该公式能够为设计和解决网络管理和网络安全方案及问题提供哪些思路?</li></ol><h3><span id="tcp拥塞控制">TCP拥塞控制</span></h3><p>TCP感知拥塞方法</p><ul><li>TCP拥塞控制：<strong>端系统</strong>采取措施使网络不致拥塞</li><li><em>超时</em>：确认报文没有及时返回，判断报文段“丢失”，即出现了<em>网络拥塞</em></li><li><em>冗余ACK</em>：多次收到对某个报文段的ACK<ul><li>报文<em>未按序</em>达到，只能对按序接收到的最后一字节数据重复确认</li></ul></li><li>丢包事件<ul><li>某TCP报文段<em>确认超时</em></li><li>收到对相同报文段的<em>3个冗余ACK</em></li></ul></li><li>控制发送速率方法<ul><li>维护一个<strong>拥塞窗口</strong><code>CWin</code></li><li><code>发送窗口上限值 ≤ min{CWin, RWin}</code></li></ul></li></ul><p><strong>TCP拥塞控制机制</strong></p><ul><li>基本思想<ul><li>当<em>出现丢包事件</em>时，<strong>迅速</strong><em>减小拥塞窗口CWin</em> 的长度，使发送方降低其发送速率，而<em>一般情况下</em>则须<strong>谨慎</strong>地<em>增加 CWin</em> 的长度。</li></ul></li><li><strong>慢启动（SS）</strong><ul><li>基本思想<ul><li>先<em>从较小</em>的拥塞窗口(如1个 MSS)<em>开始</em>，<em>逐步试探出</em>网络状态，而试探的增长速率要迅速，直至接近某个阈值</li></ul></li><li>连接开始时，拥塞窗口<code>CWin = 1 MSS</code></li><li>以<em>指数率</em>快速增加速率，直到进入<strong>拥塞避免区域</strong>或<strong>发生丢包</strong><ul><li><strong> 每收到ACK</strong>，拥塞窗口<code>CWin = CWin + 1</code>，呈现倍增效果 <img src="/images/计算机网络/DraggedImage-65.png"></li></ul></li><li>总结：初始速率很低，但以指数率快速增加</li></ul></li><li><strong>加性增和乘性减（AIMD）</strong><ul><li>加性增<ul><li>基本思想<ul><li>当网络可能进入拥塞状态时，将<em>指数增长</em>的发送速率降低为<em>线性增长</em>的发送速率</li></ul></li><li>如<strong>没有</strong>检测到丢包事件， <strong>每个RTT</strong>时间拥塞窗口值<code>CWin = CWin + 1</code></li><li><strong>状态变量ssthresh</strong>：从慢启动阶段进入拥塞避免阶段的<em>阈值</em></li></ul></li><li>乘性减<ul><li>基本思想<ul><li>急剧减小拥塞窗口</li></ul></li><li><strong>超时事件</strong>后：<ul><li><code>ssthresh = CWin / 2</code></li><li><code>CWin = 1</code></li><li>重新进入<em>慢启动</em></li></ul></li><li>收到<strong>3个冗余ACK</strong>后（Reno）：<ul><li><code>ssthresh = CWin / 2</code></li><li><code>CWin = CWin / 2</code></li><li>继续<em>加性增</em> <img src="/images/计算机网络/DraggedImage-66.png"></li></ul></li></ul></li></ul></li><li>小结<ul><li>当<code>CWin &lt; ssthresh</code>时，发送方处于<strong>慢启动</strong>阶段, CWin<strong>指数增长</strong></li><li>当<code>CWin &gt; ssthresh</code>时，发送方处于<strong>拥塞避免</strong>阶 段, CWin<strong>线性增长</strong></li><li>当出现<strong>3个冗余确认</strong>时, 阈值<code>ssthresh = CWin/2</code>，且<code>CWin = ssthresh</code>后<strong>线性增长</strong></li><li>当<strong>超时</strong>发生时，阈值<code>ssthresh = CWin/2</code>，并 且<code>CWin = 1 MSS</code>后<strong>慢启动</strong> <img src="/images/计算机网络/DraggedImage-67.png"></li></ul></li><li>快速重传（Fast Retransmit）<ul><li>一旦对某报文段收到了3个冗余ACK，可以在该报文段的<strong>定时器过期之前</strong>就重传丢失的报文段</li></ul></li><li>快速恢复（Fast Recovery）<ul><li>对<em>TCP Tahoe</em>，当发生丢包事件，立即将拥塞窗口减 速至1 MSS，然后转入慢启动阶段</li><li>对新版<em>TCP Reno</em>，一旦收到3个冗余ACK后， 取消慢启动并转入拥塞避免阶段</li></ul></li></ul><p>TCP的公平性 <img src="/images/计算机网络/DraggedImage-68.png"> <img src="/images/计算机网络/DraggedImage-69.png"></p><ul><li>多媒体应用不希望用TCP</li><li>TCP对用户公平且稳定网络，TCP友好(TCP friendly)</li><li>不能防止2台主机之间打开多个并行连接</li></ul><p>作业</p><ol type="1"><li>TCP拥塞控制的基本思想是什么?有哪些基本拥塞控制机 制?试简要阐述它们的基本思想</li><li>考虑下图中TCP窗口长度作为时间的函数。 <img src="/images/计算机网络/DraggedImage-70.png"> 假设<em>TCP Reno</em>是一个经历如上所示行为的协议，回答下列问题。在各种情况中，请简要地论证你的回答<ol type="1"><li>指出当TCP慢启动运行时的时间间隔</li><li>指出当TCP拥塞避免运行时的时间间隔</li><li>在第16个传输轮回之后，报文段的丢失是根据3个重复确认还是根据超时 检测出来的?</li><li>在第22个传输轮回之后，报文段的丢失是根据3个重复确认还是根据超时 检测出来的?</li><li>在第一个传输轮回里，ssthresh的初始值设置为多少?</li><li>在第18个传输轮回里，ssthresh的值设置为多少?</li><li>在第24个传输轮回里，ssthresh的值设置为多少?</li><li>第70个报文段在哪一个传输轮回内发送?</li><li>假定在第26个发送轮回后，通过收到3个冗余ACK检测出有分组丢失，拥塞的窗口长度和ssthresh的值将应当是多少?</li></ol></li><li>若通信信道带宽为1Gbps,两个端系统之间的时延为 15ms，而TCP的发送窗口最大为65535字节。试计算:能达到的最大吞吐量是多少?信道的利用率是多少?</li></ol><h2><span id="网络应用协议">网络应用协议</span></h2><h3><span id="域名系统dns">域名系统DNS</span></h3><p>域名系统</p><ul><li><em>分布式数据库</em>:由层次化的许多名字服务器实现</li><li><em>应用层协议</em>：主机、路由器、 名字服务器间通信，以解析名字 (进行地址/名字转换)<ul><li>供应用程序而不是人直接使用</li><li>因特网核心功能，作为应用层协议实现</li><li>复杂性位于网络“边缘”</li></ul></li><li>域名系统维护了一组名字到值的映射关系</li><li>给定一个主机名，域名系统解析返回一个值， 如IP地址</li><li>DNS协议运行在<strong>UDP</strong>之上，使用53号端口 <img src="/images/计算机网络/DraggedImage-71.png"> <img src="/images/计算机网络/DraggedImage-72.png"></li><li>类型<ul><li>根域名服务器(root name server)<ul><li>负责com, org, net, edu等，以及所有顶级国家域cn、uk等</li></ul></li><li>顶级域名服务器(top-level domain，TLD)<ul><li>负责管理在该顶级域名服务器注册的所有二级域名</li></ul></li><li>权威域名服务器(authoritative name server)<ul><li>为本组织的服务器(如Web和电子邮件)提供映射，通常有基本、辅助(备份)服务器</li></ul></li><li>本地域名服务器(local name server)<ul><li>默认域名服务器</li></ul></li></ul></li><li>交互<ul><li>递归查询(recursive query)</li><li>迭代查询(iterative query)<ul><li>后3个查询</li></ul></li></ul></li></ul><p>作业</p><ol type="1"><li>如果在本地域名服务器、根服务器和顶级域名服务器的无法找到某公司的域名，请阐述解析该公司域名的过程 答：主机要经过如下过程: (1)DNS 查询报文发向本地 DNS 服务器，它将查询转发到权威 DNS 服务器; (2)DNS 权威服务器将查询转发到顶级域名服务器; (3)顶级域名服务器将查询转发到根域名服务器; (4)跟域名服务器在 com 顶级域名服务器解析该公司的权威服务器; (5)由权威服务器就可以解析到该公司的本地域名服务器。</li><li>对同一个域名向DNS服务器发出好几次的DNS请求报文后， 每一次得到IP地址都不一样。这可能吗? 答：如果一个域名与多个 IP 地址对应，这是可能的。这种技术可用于负载 均衡场合。</li><li>电子邮件系统在运输层使用了TCP来传送邮件。为什么还会有发送的电子邮件对方没有收到的情况出现?请解释原因。 答：一份电子邮件必要经过: (1)从发送方用户代理通过 SMTP 向发送方 邮件服务器 (2)发送方邮件服务器通过 SMTP 向接收方邮件服务器发送邮件 (3)接收方用户代理用 POP3 或 IMAP 从接收方邮件服务器读取邮件 等 3 个环节。 尽管每个应用协议都是基于 TCP 的，可以保证邮件每次端到端传输的可靠 性，但并不能保证:<ol type="1"><li>在发送邮件服务器或接收邮件服务器因服务器故障或缓存溢等原因导致的邮件丢失;</li><li>邮件服务器未工作，邮件发送不出去。电子邮件本身并没有端到端的可靠性保障机制。</li></ol></li></ol><h3><span id="http">HTTP</span></h3><p>HTTP工作过程</p><ul><li>客户向服务器发起TCP连接，80端口</li><li>服务器接受来自客户TCP连接</li><li>在浏览器(HTTP客户)和 Web服务器(HTTP服务器) 之间交换HTTP报文(应用层协议报文)</li><li>关闭TCP 连接</li><li>HTTP是<strong>无状态的</strong></li><li><em>RTT</em><ul><li>从客户到服务器发送一个分组并返回所历经的时间</li></ul></li><li><strong>响应时间</strong>：2RTT + 传输时间<ul><li>一个RTT发起TCP连接</li><li>文件传输时间 <img src="/images/计算机网络/DraggedImage-73.png"> * 连接方式</li></ul></li><li>非持续HTTP<ul><li>至多一个对象经过一个TCP连接发送</li><li>HTTP/1.0</li><li>问题<ul><li>每个对象要求2RTT</li><li>操作系统必须为每个TCP连 接工作并逐个分配资源</li><li>但浏览器经常打开并行TCP 连接以获取引用的对象</li></ul></li></ul></li><li><strong>持续HTTP</strong><ul><li>多个对象能够经过客户和服务器之间的单个TCP连接发送</li><li>无流水线的持续<ul><li>仅当前面的响应已经收到，客户才发出新的请求</li><li>对每个引用对象用1RTT</li></ul></li><li>有流水线的持续<ul><li>HTTP/1.1</li><li>只要客户遇到一个引用对象， 它发送请求</li></ul></li><li>例子 <img src="/images/计算机网络/DraggedImage-74.png"><ul><li>基本HTML文件、8个图片和5个视频</li><li>流水线持续连接的响应时间<ul><li><code>2 * RTT + 8 * t1 + 5 * t2</code></li></ul></li><li>无流水持续连接的响应时间<ul><li><code>RTT + 8 * (RTT + t1) + 5 * (RTT + t2) = 14 * RTT + 8 * t1 + 5 * t2</code></li></ul></li><li>并行非持续连接的响应时间<ul><li><code>2 * RTT + t2</code></li><li>服务器负担大</li><li>对象小时开销大</li></ul></li></ul></li></ul></li></ul><p>请求报文格式 <img src="/images/计算机网络/DraggedImage-75.png"></p><p>响应报文格式 <img src="/images/计算机网络/DraggedImage-76.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP/IP </tag>
            
            <tag> 计算机网络 </tag>
            
            <tag> 本科课程 </tag>
            
            <tag> UDP </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>物联网通信技术</title>
      <link href="/2017/06/29/%E7%89%A9%E8%81%94%E7%BD%91%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/"/>
      <url>/2017/06/29/%E7%89%A9%E8%81%94%E7%BD%91%E9%80%9A%E4%BF%A1%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><strong>目录</strong></p><!-- toc --><ul><li><a href="#无线通信基础">无线通信基础</a><ul><li><a href="#信号传输">信号传输</a></li><li><a href="#编码和调制">编码和调制</a></li></ul></li><li><a href="#无线网络基础">无线网络基础</a><ul><li><a href="#多址接入mac">多址接入（MAC）</a></li></ul></li><li><a href="#802154zigbee">802.15.4/Zigbee</a><ul><li><a href="#概述">概述</a></li><li><a href="#物理层">物理层</a></li><li><a href="#mac层">MAC层</a></li><li><a href="#网络层">网络层</a></li><li><a href="#tinyos">TinyOS</a></li></ul></li><li><a href="#无线局域网">无线局域网</a><ul><li><a href="#mac层-1">MAC层</a></li><li><a href="#功耗管理">功耗管理</a></li></ul></li><li><a href="#无线广域网">无线广域网</a><ul><li><a href="#大容量的小区制利用有限频段覆盖无限大面积">大容量的小区制：利用有限频段覆盖无限大面积</a></li><li><a href="#gsmgprs">GSM/GPRS</a></li><li><a href="#cdma">CDMA</a></li><li><a href="#3g">3G</a></li></ul></li><li><a href="#物联网通信架构">物联网通信架构</a><ul><li><a href="#基于ip的物联网通信架构">基于IP的物联网通信架构</a></li><li><a href="#6lowpan">6LowPAN</a></li></ul></li><li><a href="#各种技术对比">各种技术对比！</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="无线通信基础">无线通信基础</span></h2><h3><span id="信号传输">信号传输</span></h3><p><em>信号</em></p><ul><li>时域概念<ul><li>模拟信号</li><li>数字信号</li><li>周期信号</li><li>非周期信号</li></ul></li><li>频域概念<ul><li>一个电磁信号由多种频率成分组成</li><li>基频：当一个信号的所有频率成分都是某个频率的整数倍时，后者称为基频</li><li>频谱：一个信号包涵的频率范围</li><li>绝对带宽：一个信号的频谱宽度</li><li>有效带宽：一个信号的绝大部分能量集中在相当窄的频带内</li></ul></li><li>数据与信号<ul><li>数据：传达某种意义或信息的实体</li><li>信号：数据的电气或电磁表示</li><li>传输：通过信号的传播和处理进行数据通信的过程</li></ul></li><li>数据率与带宽 <img src="/images/物联网通信技术/DraggedImage.png"> <img src="/images/物联网通信技术/DraggedImage-1.png"><ul><li>数据率：数据能够进行通信的速率，单位b/s<ul><li>数据率 = 2*基频</li></ul></li><li>带宽：传输信号的带宽，受发送器和传输媒体限制<ul><li>信道无噪声：尼奎斯特带宽 <img src="/images/物联网通信技术/DraggedImage-2.png"><ul><li>B：带宽</li></ul></li><li>信道有噪声<ul><li>信噪比，SNR, S/N：信号功率／噪声功率 <img src="/images/物联网通信技术/DraggedImage-3.png"></li><li>分贝：用来表示信号强度的增益、损耗以及<em>相对值</em></li><li><strong>dB &amp; dBm</strong> <img src="/images/物联网通信技术/DraggedImage-4.png"></li></ul></li></ul></li></ul></li><li>信道容量：给定条件下，在某一通信线路（信道）上，数据可以被传输的最大速率<ul><li>香农容量公式 <img src="/images/物联网通信技术/DraggedImage-5.png"></li><li>举例 <img src="/images/物联网通信技术/DraggedImage-6.png"></li></ul></li><li>传输媒体：数据传输系统中发送器和接收器之间的物理路径<ul><li>导向：双绞线、光纤</li><li>非导向：大气</li></ul></li><li>复用<ul><li>FDM</li><li>TDM</li><li>OFDM：正交频分复用</li></ul></li></ul><p><em>天线</em></p><ul><li>各向同性天线</li><li>偶极天线</li><li>抛物反射天线</li></ul><p><strong>天线增益</strong></p><ul><li>天线定向性度量</li><li>天线增益定义为<em>在一特定方向的功率输出</em>： <img src="/images/物联网通信技术/DraggedImage-7.png"></li></ul><p>传播</p><ul><li>直线传播<ul><li><strong>自由空间损耗公式</strong><ul><li>未考虑天线增益 <img src="/images/物联网通信技术/DraggedImage-8.png"> <img src="/images/物联网通信技术/DraggedImage-9.png"></li><li>考虑天线增益 <img src="/images/物联网通信技术/DraggedImage-10.png"> <img src="/images/物联网通信技术/DraggedImage-11.png"></li></ul></li><li>实质就是空间的损耗减去发送端和接收端的增益</li></ul></li><li>信噪比SNR <img src="/images/物联网通信技术/DraggedImage-12.png"> <img src="/images/物联网通信技术/DraggedImage-13.png"></li><li>衰减原因<ul><li>大气吸收</li><li>多普勒效应</li><li>多径<ul><li>反射</li><li>衍射</li><li>散射</li></ul></li></ul></li></ul><p>衰落</p><ul><li>由于信道的变化导致接收信号的功率随时间、地理位置、频率等变化</li><li>慢衰落</li><li>快衰落<ul><li>描述信号<em>幅值</em>的<em>瞬时变化</em>，与<strong>多径传播</strong>有关</li></ul></li></ul><p>接收</p><ul><li>接收基噪声基底<ul><li>RNF = kTW + NF</li><li>kTW：理论热噪声基底</li><li>NF：噪声系数</li></ul></li><li><strong>接收机灵敏度</strong> <img src="/images/物联网通信技术/DraggedImage-14.png"></li></ul><h3><span id="编码和调制">编码和调制</span></h3><p>数字信号-模拟信号</p><ul><li>幅移键控（ASK）<ul><li>用振幅恒定的载波表示一个二进制数</li><li><em>在光纤中传播数字数据时使用</em></li><li><strong>优点</strong><ul><li>简单</li></ul></li><li><strong>缺点</strong><ul><li>最易受噪声影响</li><li>效率低</li></ul></li></ul></li><li>频移键控（FSK）<ul><li>用不同频率表示不同的二进制值</li><li><em>用于高频率无线（或同轴电缆）的传输</em></li><li>多进制：带宽效率高，但易出错</li><li><strong>优点</strong><ul><li>比ASK抗干扰强</li><li>电压噪声可以忽略</li></ul></li><li><strong>缺点</strong><ul><li>需要频谱最大</li></ul></li></ul></li><li>相移键控（PSK）<ul><li>二相相移键控（BPSK）</li><li>差分相移键控（DPSK）<ul><li>通过与前面的信号比较决定相移</li></ul></li><li>四相相移键控（QPSK）</li><li>多相位相移键控</li><li><em>用途：广泛使用</em></li><li><strong>优点</strong><ul><li>比ASK抗干扰强，和ASK用相同带宽</li><li>比FSK带宽利用率高</li></ul></li><li><strong>缺点</strong><ul><li>检测、恢复信号比ASK、FSK更复杂</li></ul></li></ul></li><li>计算带宽 <img src="/images/物联网通信技术/DraggedImage-15.png"></li></ul><h2><span id="无线网络基础">无线网络基础</span></h2><h3><span id="多址接入mac">多址接入（MAC）</span></h3><p>MAC层定义用户需要时如何访问无线信道</p><ul><li>随机访问<ul><li>ALOHA, CSMA</li></ul></li><li>有序访问<ul><li>令牌总线（环）</li></ul></li><li>确定性访问<ul><li>FDMA, TDMA, CDMA</li></ul></li><li>组合</li></ul><p><em>CSMA：载波监听</em></p><ul><li>发前先听</li><li>1-持续CSMA<ul><li>一有空就发</li></ul></li><li>p-持续CSMA<ul><li>有空闲随机概率p发送</li></ul></li></ul><p>CSMA/CD</p><ul><li>发前先听，边发边听</li><li>无线中难于检测冲突</li></ul><p>隐藏节点问题</p><ul><li>在无线环境中，当两个节点相距较远时，无发进行载波监听 <img src="/images/物联网通信技术/DraggedImage-16.png"></li></ul><p><strong>CSMA/CA</strong></p><ul><li>冲突避免CA = Collision Avoidance</li><li>监听到信道空闲，维持一段时间后，再随机等待一段时间仍然空闲，才提交数据</li><li>RTS-CTS握手<ul><li>设备发送数据之前，先发送RTS帧给目标端，等待目标端回应CTS帧后才开始发送 <img src="/images/物联网通信技术/DraggedImage-17.png"></li></ul></li><li>暴露节点问题 <img src="/images/物联网通信技术/DraggedImage-18.png"></li></ul><p><em>总结对比</em></p><ul><li>随机访问：CSMA<ul><li><em>轻载：快速响应</em></li><li>重载：吞吐量下降</li><li>实现简单</li></ul></li><li>确定性协议：TDMA，FDMA<ul><li>带宽保证</li><li>平均延迟较高</li><li>延迟变化小</li><li>同步、协调等机制</li></ul></li><li>混合：CSMA/TDMA<ul><li>自适应、开销大</li></ul></li></ul><h2><span id="802154zigbee">802.15.4/Zigbee</span></h2><h3><span id="概述">概述</span></h3><p>ZigBee技术优点</p><ol type="1"><li>低功耗</li><li>低成本</li><li>低速率</li><li>近距离</li><li>短时延</li><li>高容量</li><li>高安全</li><li>免执照频段</li></ol><h3><span id="物理层">物理层</span></h3><p><img src="/images/物联网通信技术/DraggedImage-19.png"></p><p>Symbol</p><ul><li>Symbol的具体内容和采用的调制方式有关<ul><li>2.4GHz, 4bit数据用一个Symbol表示，16种</li><li>其他，1bit数据用一个Symbol表示，2种</li></ul></li></ul><p>功能</p><ul><li>打开和关闭收发器</li><li>信道能量检测</li><li>链路质量指示</li><li>空闲信道评估</li><li>信道频率选择</li><li>在物理介质上发送和接收数据包</li></ul><h3><span id="mac层">MAC层</span></h3><p>数据传输</p><ul><li>数据由装置发送给协调者</li><li>数据由协调者发送给装置</li><li>数据由网路装置中对等传输（星状拓扑不支持）</li></ul><p><em>信标使能网络（Beacon mode）</em></p><ul><li>超帧：实现协调器和设备的时间同步、识别PAN及设备之间的通信（<em>不支持网状拓扑结构</em>）<ul><li>CAP（Contention Access Period）采用时隙CSMA/CA</li><li>CFP（Contention Free Period）采用时隙GTS机制通信</li></ul></li><li>通信时间划分<ul><li>活跃期（划分为16个等长的slot）<ul><li>信标帧发送阶段</li><li>CAP</li><li>CFP <img src="/images/物联网通信技术/DraggedImage-20.png"></li></ul></li><li>睡眠期</li></ul></li><li><em>BO</em>：<em>信标级数</em>，取值范围0到14，等于15时表示不使用超帧结构</li><li><em>SO</em>：<em>超帧级数</em>，取值范围0到14，但必须保证<strong>SO不大于BO</strong>，当二者相等时，表示该超帧中不包含非活跃期</li><li><em>Duty Cycle</em><ul><li>活跃时间2^(-(BO-SO))</li><li>睡眠时间1-2^(-(BO-SO))</li><li>（N总-N非活跃）/N总 <img src="/images/物联网通信技术/DraggedImage-21.png"></li></ul></li><li><strong>CAP</strong><ul><li>CAP开始于beacon帧之后，结束于CFP开始之前的时隙边界上。如果CFP长度为0，CAP结束于超帧活动区末端</li><li>长度至少为MinCAPLength个符号长度，可以通过调节CFP长度动态的增减</li><li><em>除了确认帧和紧跟因数据请求而发送的确认帧之后的数据帧以外</em>，所有CAP内的帧都是用CSMA/CA</li><li>必须保证该传输事务结束时距CAP结束至少还有一个帧间间隔（IFS），以保证接收方有时间处理该帧；否则延迟到下一个CAP发送</li><li>帧间隔时间IFS<ul><li>ACK延时t_ACK发送</li><li>SIFS：当前一个DATA帧长度小于等于MaxSIFSFrameSize(18)时，后一个帧至少延时SIFS发送<ul><li>SIFS的典型值是12 Symbols</li></ul></li><li>LIFS：前一个帧长大于18，后一帧延迟LIFS发送<ul><li>LIFS的典型值是40 Symbols <img src="/images/物联网通信技术/DraggedImage-22.png"></li></ul></li></ul></li></ul></li><li><strong>CFP</strong><ul><li>CFP是为了保证某个设备的QoS而设置的。它开始于CAP结束后的时隙边界上，结束于超帧活动区域尾部</li><li>CFP扩大或减小取决于所有GTS的总长度</li><li>在GTS内传输不用CSMA/CA</li><li>保证传输结束时距它的GTS结束至少有一个帧间间隔</li><li><em>GTS: Guaranteed Time Slot</em><ul><li>用于低延迟或对数据传输带宽有特殊要求的应用</li><li>协调者通过超帧负责分配，最多分配7个，每个可以占用1个或多个时间片</li></ul></li></ul></li><li>CSMA/CA时隙 UnitBackoffPeriod：20 Symbols</li><li><em>CSMA/CA退避算法</em><ul><li>NB：后退次数，已执行的back off的次数</li><li>CW：碰撞窗口长度，单位为backoff period, 20 Symbols，含义是必须执行几次帧测频道皆为闲置时才可将数据送出，<em>初始值为2</em></li><li>BE：后退指数，Backoff Time = 2^BE - 1，取值0-5 <img src="/images/物联网通信技术/DraggedImage-23.png"> <img src="/images/物联网通信技术/DraggedImage-24.png"></li><li><em>2CCA</em>：为了保护ACK，因为ACK需要延迟t_ACK时间才能发送，只检测一个CCA可能会导致碰撞 <img src="/images/物联网通信技术/DraggedImage-25.png"> <img src="/images/物联网通信技术/DraggedImage-26.png"> <img src="/images/物联网通信技术/DraggedImage-27.png"></li></ul></li><li>数据由装置发送给协调器（直接传输） <img src="/images/物联网通信技术/DraggedImage-28.png"></li><li>数据由协调者发送给装置（间接传输） <img src="/images/物联网通信技术/DraggedImage-29.png"></li></ul><p><em>信标不使能网络（Non-beacon mode）</em></p><ul><li>无超帧，通过无时隙的CSMA/CA机制发送数据</li><li>某一节点的退避周期和PAN中任何其他的节点的退避周期无关</li><li>无时隙CSMA/CA <img src="/images/物联网通信技术/DraggedImage-30.png"> <img src="/images/物联网通信技术/DraggedImage-31.png"></li><li>数据由装置发送给协调器（直接传输） <img src="/images/物联网通信技术/DraggedImage-32.png"></li><li>数据由协调者发送给装置（间接传输） <img src="/images/物联网通信技术/DraggedImage-33.png"></li></ul><p><strong>性能分析</strong></p><ul><li>实例：2.4GHz频段上使用<em>非时隙</em>CSMA/CA能够达到的数据传输率250kbps? <em>有退避、CCA、必要的间隔</em><ol type="1"><li>信道访问时间<ul><li>{0, 2^BE-1}周期，1CCA</li><li>假设信道空闲，退避1次即可，BE=macMinBE=3</li><li>最长访问时间=InitialblockoffPeriod + CCA = (2^3 - 1) x UnitBackoffPeriod + CCA = 7 x 320 + 128 (微秒)= 2.368 ms</li><li>其中 InitialblockoffPeriod = 8 symbols UnitBackoffPeriod = 20 symbols 1 symbol = 16 (微秒)</li></ul></li><li>数据帧传输时间 <img src="/images/物联网通信技术/DraggedImage-34.png"><ul><li>最大有效载荷：MaxPHYPacketSize = 127 <img src="/images/物联网通信技术/DraggedImage-35.png"></li></ul></li><li>确认传输时间 <img src="/images/物联网通信技术/DraggedImage-36.png"><ul><li>不使用CSMA/CA.....................</li></ul></li></ol></li></ul><h3><span id="网络层">网络层</span></h3><p>路由</p><ul><li><em>树形路由</em><ul><li>有信标</li><li>地址分配<ul><li>基于树的深度新加入的路由节点被赋予一个连续的地址范围</li><li><strong>该范围中的第一个整数为该节点的地址</strong>，余下的数用于分配子节点 <img src="/images/物联网通信技术/DraggedImage-37.png"></li><li><code>Cm</code>：最大孩子个数</li><li><code>Rm</code>：最大子路由节点个数</li><li><code>Lm</code>：网络最大深度，<code>[0 ~ Lm]</code></li><li><strong>分配方案</strong><ul><li>具有深度<code>d &lt; Lm</code>的路由节点的<em>地址范围</em>为<code>A(d)</code><ul><li><code>if d = Lm - 1, then A(d) = 1 + Cm</code></li><li><code>else A(d) = 1 + Cm - Rm + Rm * A(d+1)</code></li></ul></li><li>深度为<code>Lm</code>的路由节点和终端设备的地址范围为1</li></ul></li><li>地址分配实例<ul><li>给定<code>Rm = 2, Cm = 4, Lm = 3</code></li><li>分配：<ul><li><code>A(3) = 1</code></li><li><code>A(2) = 1 + 4 - 2 + 2 * A(3) = 5</code></li><li><code>A(1) = 1 + 4 - 2 + 2 * A(2) = 13</code></li><li><code>A(0) = 1 + 4 - 2 + 2 * A(1) = 29</code></li><li>Range: <code>[0 ~ 28]</code></li><li>根节点地址：<code>0</code></li><li>第一层节点的地址范围：<code>[1 ~ 13], [14, 26], 27, 28</code></li><li>第二层节点的地址范围：<code>{[2 ~ 6], [7 ~ 11], 12, 13}, {[15 ~ 19], [20 ~ 24], 25, 26}</code> <img src="/images/物联网通信技术/DraggedImage-38.png"></li></ul></li></ul></li></ul></li></ul></li><li>网状路由<ul><li>无信标，对等传输</li><li>有路由能力：AODV</li></ul></li></ul><p><strong>AODV</strong></p><ul><li>路由发现过程<ul><li>要向某一目的节点发送数据的节点广播一个<em>RREQ消息</em></li><li>收到<em>RREQ消息</em>的节点继续广播</li><li>当节点广播<em>RREQ</em>时，同时设置一个指向源节点的<em>反向路径</em>（丢弃收到的重复路由请求分组）</li><li>AODV假定连接是对称的</li><li>当目的节点收到<em>RREQ</em>时，发送路由回复消息</li><li>路由回复<em>RREP</em>消息沿路由请求转发时设置的反向路径传回源节点</li><li>如果中间节点知道目的节点的路径，且该路径较新，也可以发送<em>RREP</em></li><li>使用序列号定义路径的新旧，被发现的时间的远近 <img src="/images/物联网通信技术/DraggedImage-39.png"> <img src="/images/物联网通信技术/DraggedImage-40.png"> <img src="/images/物联网通信技术/DraggedImage-41.png"> <img src="/images/物联网通信技术/DraggedImage-42.png"> <img src="/images/物联网通信技术/DraggedImage-43.png"> <img src="/images/物联网通信技术/DraggedImage-44.png"> <img src="/images/物联网通信技术/DraggedImage-45.png"> <img src="/images/物联网通信技术/DraggedImage-46.png"> <img src="/images/物联网通信技术/DraggedImage-47.png"></li></ul></li></ul><p><img src="/images/物联网通信技术/DraggedImage-48.png"></p><h3><span id="tinyos">TinyOS</span></h3><p><em>启动／停止</em> <img src="/images/物联网通信技术/DraggedImage-49.png"> <img src="/images/物联网通信技术/DraggedImage-50.png"></p><p><em>发送数据</em> <img src="/images/物联网通信技术/DraggedImage-51.png"> <img src="/images/物联网通信技术/DraggedImage-52.png"></p><p><em>接收数据</em> <img src="/images/物联网通信技术/DraggedImage-53.png"></p><p><em>选信道</em> 在makefile里加入：<code>PFLAGS += -DCC2420_DEF_CHANNEL=13</code></p><p><em>AM Type</em> 代码中的<code>id</code> enum { AM_BLINKTORADIO = 6, };</p><p><em>包格式</em></p><ul><li><code>00</code>：表示AM数据包</li><li>目标地址（2B）</li><li>源地址（2B）</li><li>消息长度（1B）</li><li>组号（1B）</li><li>AM Type (1B)</li><li>Payload (最大28B)<ul><li>nodeid (2B)</li><li>counter (2B)</li></ul></li></ul><h2><span id="无线局域网">无线局域网</span></h2><h3><span id="mac层">MAC层</span></h3><p>帧定义</p><ul><li>控制帧</li><li>数据帧</li><li>管理帧</li><li>MAC首部：30字节</li><li>帧主体：数据部分，<strong>不超过2312字节（如果数据长度大于2312则要分片！）</strong>；通常小于1500字节</li><li>帧检验序列FCS：4字节 <img src="/images/物联网通信技术/DraggedImage-54.png"></li></ul><p><img src="/images/物联网通信技术/DraggedImage-55.png"></p><p><em>分布式协调功能（DCF）</em>子层使用<em>CSMA/CA</em>机制，向上提供争用服务。 <em>点协调功能（PCF）</em>子层使用集中控制的接入算法，把数据权<em>轮流</em>交给各个站从而避免了碰撞的产生。</p><p>帧间间隔IFS</p><ul><li>SIFS：短<ul><li>ACK帧、CTS帧、MAC帧分片的数据帧、回答AP探寻的帧、<em>PCF</em>中AP发送的任何帧 <img src="/images/物联网通信技术/DraggedImage-56.png"></li></ul></li><li>PIFS：<em>点协调PCF</em>功能帧间间隔，比SIFS长；在<em>PCF</em>方式下使用，没有争用 <img src="/images/物联网通信技术/DraggedImage-57.png"></li><li>DIFS：<em>分布协调DCF</em>功能帧间间隔，在<em>DCF</em>方式中用来发送数据帧和管理帧。</li></ul><p><strong>分布式协调DCF</strong></p><ul><li>CSMA/CA<ul><li>发前先听，空闲等待<em>DIFS</em>，发送</li><li>为什么空闲后还要等待？<ul><li>可能有其他的站有高优先级的帧要发送</li></ul></li><li>源站发送了数据帧；目的站正确接收此帧，隔<em>SIFS</em>后，向源站发送确认帧ACK</li><li>若源站没有在规定时间内收到ACK，则需重传此帧，直到收到或放弃</li><li><em>虚拟载波监听（Virtual Carrier Sense）</em><ul><li>让源站将它要占用信道的时间通知给其他站，以便使其他站在此时间内停止发送数据</li><li>表示其他站并没有监听信道，而是由于收到了<em>源站的通知</em>，才不发送数据</li></ul></li><li>网络分配向量<ul><li>当检测到MAC帧首部的持续时间字段时，就调整自己的<em>网络分配向量NAV</em></li><li>NAV指出了必须经过多少时间才能完成数据帧的这次传输，才能使信道转入空闲状态</li></ul></li><li>争用窗口<ul><li>不仅要等待一个<em>DIFS</em>，还要进入<em>争用窗口</em>，并计算<em>随机退避时间</em>以便再次试图接入到信道</li></ul></li><li>二进制指数退避算法<ul><li>第<code>i</code>次退避在<code>2^{2+i}</code>个时隙中随机选择一个<ul><li>第<code>1</code>次退避在<code>8</code>个（0-7）时隙中随机选择一个</li><li>第<code>3</code>次退避在<code>32</code>个时隙中随机选择一个</li></ul></li><li>仅在要发送<em>第一个</em>数据帧时检测到信道空闲时才<strong>不</strong>使用退避算法！</li><li>除此之外所有情况都要用！即<ul><li>发送第一帧时检测到信道忙</li><li>每次重传后</li><li>每次成功发送后</li></ul></li></ul></li><li>退避计时器（backoff timer）<ul><li>若信道空闲，则退避计时器就<em>继续</em>倒计时</li><li>若信道忙，就<em>冻结</em>退避计时器的剩余时间，重新等待变为空闲，再经过DIFS后，<em>从剩余时间继续</em></li><li>如果计时器减小到0，则开始发送整个数据帧 <img src="/images/物联网通信技术/DraggedImage-58.png"> <img src="/images/物联网通信技术/DraggedImage-59.png"></li></ul></li><li>RTS/CTS <img src="/images/物联网通信技术/DraggedImage-60.png"> <img src="/images/物联网通信技术/DraggedImage-61.png"></li></ul></li><li>与802.15.14 MAC层CSMA/CA区别<ul><li>空闲信道检测只需一个CCA，802.15.14需要2个</li><li>无限制回退</li><li>回退算法：802.15.14无冻结</li><li>虚拟载波监听！！</li></ul></li></ul><p><strong>点协调 PCF</strong></p><ul><li>每个超帧周期分为<em>CFP</em>和<em>CP</em><ul><li><em>CFP</em>阶段传输实时业务，使用<strong>PCF</strong></li><li><em>CP</em>使用<em>DCF</em> <img src="/images/物联网通信技术/DraggedImage-62.png"></li></ul></li><li>轮询列表<ul><li>一个<code>CF-Poll</code>授权发送一个帧</li></ul></li><li>调度算法<ul><li>PC到Station</li><li>Round-Robin Scheme (R-Poll)：地址从小到大轮询</li><li>Cyclic Shift Polling Scheme (CS-Poll)：循环移动列表顺序</li><li>FIFO：缓存队列里的数据帧顺序 <img src="/images/物联网通信技术/DraggedImage-63.png"> <img src="/images/物联网通信技术/DraggedImage-64.png"> <img src="/images/物联网通信技术/DraggedImage-65.png"> <img src="/images/物联网通信技术/DraggedImage-66.png"></li></ul></li></ul><h3><span id="功耗管理">功耗管理</span></h3><p>TIM：Traffic Indiction Map，标志哪个STA有缓存的帧 DTIM：发送TIM广播包</p><p><em>Power-Save mode (PS)</em></p><ul><li>每个<code>Listen_Interval</code>周期内激活接收器</li><li>STA进入PS模式应通知AP，所有到它那的帧都会被缓存 <img src="/images/物联网通信技术/DraggedImage-67.png"> <img src="/images/物联网通信技术/DraggedImage-68.png"></li><li>通信<ul><li>关闭射频，定期睡眠</li><li>AP缓存发往该终端的数据包</li><li>缓存信息在TIM里说明</li><li>醒来的终端需要用<code>PS-Poll</code>帧来接收数据包</li></ul></li><li>AP响应<code>PS-Poll</code><ul><li>立即响应 <img src="/images/物联网通信技术/DraggedImage-69.png"></li><li>有分片的立即响应 <img src="/images/物联网通信技术/DraggedImage-70.png"></li><li>推迟响应 <img src="/images/物联网通信技术/DraggedImage-71.png"></li></ul></li></ul><h2><span id="无线广域网">无线广域网</span></h2><h3><span id="大容量的小区制利用有限频段覆盖无限大面积">大容量的小区制：利用有限频段覆盖无限大面积</span></h3><p><img src="/images/物联网通信技术/DraggedImage-72.png"></p><p>思想是用许多小功率的发射机代替单个的大功率发射机，每一个小的功率覆盖区只提供服务范围内的一小部分覆盖。 相邻小区使用<em>不同信道组</em>，从而防止相互干扰。 通过限制小区的覆盖面积，使得同信道组可以在不同地方重复使用。</p><p>为整个系统中的所有基站选择和分配信道组的设计过程叫做<em>频率复用</em>。 * 多个不同频率的小区cell构成簇cluster；不同簇使用对应的相同频率</p><p><strong>越区切换 Handoff</strong> 在<em>不中断通讯</em>的情况下从一个小区穿越到另一个小区时：</p><ul><li>识别一个新的BS</li><li>把语音信道和控制信道同时切换到新的BS</li><li>切换请求的优先级高于呼叫请求</li><li>切换步骤<ul><li>测量控制</li><li>测量报告</li><li>切换判决</li><li>切换执行 分类</li></ul></li><li>硬切换<ul><li>在频率<em>不同</em>的小区切换，先断旧连接，再建立新连接（GSM）</li></ul></li><li>软切换<ul><li>在频率<em>相同</em>的小区切换，新建连接成功后，再拆旧连接（CDMA） <img src="/images/物联网通信技术/DraggedImage-73.png"></li></ul></li></ul><p>切换规则 <img src="/images/物联网通信技术/DraggedImage-74.png"></p><ul><li>相对信号强度准则<ul><li><em>切换点A</em>，原基站信号强度满足通话要求时，仍可能切换</li></ul></li><li>具有门限规定的相对信号强度准则<ul><li>门限<code>Th2</code>时，<em>切换点B</em>，当前基站信号低于门限，新基站信号更强</li><li>门限高时，接近于<em> 相对信号强度准则</em>；</li><li>门限太低，增大越区时延</li></ul></li><li>具有滞后余量的相对信号强度准则<ul><li>新基站信号强（滞后余量<code>h</code>）很多时，<em>切换点C</em>，避免乒乓效应</li></ul></li><li>具有滞后余量和门限规定的相对信号强度准则<ul><li><em>切换点D</em></li></ul></li></ul><p>实际应用</p><ul><li>1G蜂窝<ul><li>MSC（移动交换中心）决定是否切换</li><li>时延10s</li></ul></li><li>2G蜂窝<ul><li>MS辅助决定切换</li><li>时延1～2s</li></ul></li></ul><p><strong>位置管理</strong> 数据库（每个MSC建立）</p><ul><li><em>原籍位置寄存器HLR</em><ul><li>注册用户信息</li><li>用户预订业务</li><li>记账信息</li><li><em>位置访问寄存器VLR</em></li></ul></li></ul><p>主要任务</p><ul><li>位置登记：更新HLR/VLR</li><li>呼叫传递：根据HLR/VLR定位移动台，确定处于哪个小区 <img src="/images/物联网通信技术/DraggedImage-75.png"></li></ul><p>呼叫传递</p><ol type="1"><li>MS通过基站向MSC发呼叫初始化</li><li>MSC通过地址翻译过程确定<strong>被呼</strong><em>HLR</em>，并向<em>HLR</em>发送位置请求信息</li><li><em>HLR</em>确定被叫所在<em>VLR</em>，向<em>VLR</em>发送路由请求，<em>VLR</em>将该消息转发给<strong>被叫</strong>服务的MSC</li><li><em>MSC</em>为<strong>被叫</strong>服务分配临时本地号码<em>TLDN</em>，并向<em>HLR</em>发送含有该号码的应答</li><li><em>HLR</em>将上述消息转发给<strong>主呼</strong>MS服务的MSC</li><li><strong>主叫</strong>MSC根据上述信息通过SS7向被叫MSC请求呼叫建立 <img src="/images/物联网通信技术/DraggedImage-76.png"></li></ol><p><strong>支持的用户数</strong></p><ul><li>话务量<ul><li>每个用户产生的负载密度为 <img src="/images/物联网通信技术/DraggedImage-77.png"></li><li>若有C个信道，则每个信道的负载密度为 <img src="/images/物联网通信技术/DraggedImage-78.png"></li></ul></li><li>系统容量与阻塞概率 <img src="/images/物联网通信技术/DraggedImage-79.png"><ul><li><code>Pr</code>代表<em>呼叫被拒绝</em>的概率，<code>A</code>是话务量，<code>C</code>为中继信道数</li></ul></li><li>爱尔兰呼损表 <img src="/images/物联网通信技术/DraggedImage-80.png"></li><li>举例计算支持用户数 <img src="/images/物联网通信技术/DraggedImage-81.png"> <img src="/images/物联网通信技术/DraggedImage-82.png"></li></ul><p>Tradeoffs <img src="/images/物联网通信技术/DraggedImage-83.png"></p><h3><span id="gsmgprs">GSM/GPRS</span></h3><p><em>FDMA</em> + <em>TDMA</em> <img src="/images/物联网通信技术/DraggedImage-84.png"></p><p>GSM</p><ul><li>电路交换网络</li><li>语音服务</li></ul><p>数据服务支持</p><ul><li>GPRS（General Packet Radio Service）</li><li>EDGE（Enhanced Data GSM Environment） <img src="/images/物联网通信技术/DraggedImage-85.png"></li></ul><h3><span id="cdma">CDMA</span></h3><p>扩频复用 <img src="/images/物联网通信技术/DraggedImage-86.png"></p><p>正交编码 <img src="/images/物联网通信技术/DraggedImage-87.png"></p><p>特点</p><ul><li>频率分集</li><li>多路阻抗</li><li>保密</li><li>故障弱化</li><li>自我干扰</li><li>软切换</li><li><strong>发射功率小</strong></li><li>数据传输率：9.6kb/s</li><li>频道带宽：1.25MHz</li></ul><p>CMDA vs. GSM</p><ul><li>通信质量好</li><li>赛车、断讯问题少</li><li>其他功能差不多</li><li>发射功率小</li></ul><h3><span id="3g">3G</span></h3><p>WCDMA, CDMA2000, TD-SCDMA, WiMax</p><p><strong>极品对比图</strong> <img src="/images/物联网通信技术/DraggedImage-88.png"></p><h2><span id="物联网通信架构">物联网通信架构</span></h2><h3><span id="基于ip的物联网通信架构">基于IP的物联网通信架构</span></h3><p><img src="/images/物联网通信技术/DraggedImage-89.png"></p><p>优势</p><ul><li>互通性</li><li>架构的稳定性和普遍性</li><li>可扩展性</li><li>易于配置和管理</li><li>开放性</li><li>安全性</li><li>已经建立好的各种服务.... <img src="/images/物联网通信技术/DraggedImage-90.png"></li></ul><p>挑战</p><ul><li>在资源受限的物体上实现完整的IP协议栈</li><li>低功耗有损网络下的IP数据包传输</li><li>低功耗有损网络下的路由</li></ul><h3><span id="6lowpan">6LowPAN</span></h3><p><img src="/images/物联网通信技术/DraggedImage-91.png"></p><p><img src="/images/物联网通信技术/DraggedImage-92.png"></p><h2><span id="各种技术对比">各种技术对比！</span></h2><p><img src="/images/物联网通信技术/DraggedImage-93.png"> <img src="/images/物联网通信技术/DraggedImage-94.png"> <img src="/images/物联网通信技术/DraggedImage-95.png"></p><p>ZigBee</p><ul><li>低功耗</li><li>低成本</li><li>低速率<ul><li>20-250kbps</li></ul></li><li>近距离<ul><li>10-100m</li></ul></li><li>短延时<ul><li>睡眠转工作15ms</li><li>接入网络30ms</li><li>蓝牙 3-10s</li><li>WiFi需要3s</li></ul></li><li>高容容<ul><li>每个主节点管 254个</li><li>最多65000个</li></ul></li><li>安全</li><li>免执照频段<ul><li>2.4GHz</li></ul></li></ul><p>CDMA</p><ul><li>多路阻抗</li><li>保密</li><li>故障弱化</li><li>自我干扰</li><li><strong>发射功率小-&gt;省电（相比于GSM相比）</strong><ul><li>正常通话时<code>0.1mW</code></li></ul></li><li>数据传输率：9.6kb/s</li><li>频道带宽：1.25MHz</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> 本科课程 </tag>
            
            <tag> 物联网 </tag>
            
            <tag> TinyOS </tag>
            
            <tag> ZigBee </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>物联网中间件技术</title>
      <link href="/2017/06/25/%E7%89%A9%E8%81%94%E7%BD%91%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%8A%80%E6%9C%AF/"/>
      <url>/2017/06/25/%E7%89%A9%E8%81%94%E7%BD%91%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><strong>目录</strong></p><!-- toc --><ul><li><a href="#绪论">绪论</a></li><li><a href="#中间件的工作原理">中间件的工作原理</a></li><li><a href="#j2ee简介">J2EE简介</a></li><li><a href="#j2ee-ejb构件基础">J2EE-EJB构件基础</a></li><li><a href="#ejb构件开发">EJB构件开发</a></li><li><a href="#rfid中间件">RFID中间件</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="绪论">绪论</span></h2><p><strong>中间件</strong>定义</p><ul><li>一种独立的软件或者服务，物联网服务可以借助中间件在不同的系统之间共享资源。它能提供透明的数据传输能力，承担物理空间到信息空间的映射，实现对物理对象的感知和信息获取、清洗、融合等。</li><li>Software that connects two otherwise separate applications.</li><li>是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源；中间件位于客户机/服务器的操作系统之上，<em>管理计算资源和网络通信</em> <img src="/images/物联网中间件技术/DraggedImage.png"></li><li>左中右的中：位于应用系统间, <em>提供通信服务</em></li><li>上中下的中：位于应用系统和操作系统间，提供<em>应用编程接口(抽象)</em>并管理计算资源</li></ul><p><em>分布式软件结构</em></p><ul><li>两层结构 <img src="/images/物联网中间件技术/DraggedImage-1.png"><ul><li>客户程序直接访问数据库，用户界面代码和业务逻辑代码交织在一起</li><li><em>问题</em><ul><li>客户端负担重</li><li>客户端可移植性不好</li><li>系统可维护性不好</li><li>数据安全性不好</li></ul></li></ul></li><li><strong>三层结构</strong> <img src="/images/物联网中间件技术/DraggedImage-2.png"><ul><li>将业务逻辑代码移到中间层</li><li>客户程序<em>只能通过中间层间接地访问数据库</em>，即<ul><li>降低了客户端的负担</li><li>改善了其可移植性</li><li>提高了系统的数据安全性</li></ul></li><li>业务逻辑代码与用户界面代码<em>相对独立</em>，也在很大程度上<em>提高了系统的可维护性</em></li></ul></li></ul><p><em>分类</em></p><ul><li>消息中间件(MOM:Message-oriented Middleware)</li><li>数据库中间件(Database Middleware)</li><li>远程过程调用中间件(RPC: Remote process Call)</li><li>对象请求代理中间件(ORB: Object Request Broker)</li><li>事务请求代理中间件(TP Monitor: Transaction Process Monitor)</li></ul><p><em>物联网中间件</em> <img src="/images/物联网中间件技术/DraggedImage-3.png"></p><ul><li><em>功能</em><ul><li><strong>屏蔽异构性</strong><ul><li>计算机硬件之间的异构性</li><li>物联网异构性</li></ul></li><li>实现互操作<ul><li>实现各应用系统和应用平台之间互操作</li></ul></li><li>信息预处理<ul><li>过滤海量信息，统计分析融合成有意义事件再传输给应用系统</li></ul></li><li>可扩展性</li></ul></li><li><em>OPC</em><ul><li>OPC是<em>连接</em>数据源(<em>OPC服务器</em>)和数据使用者(<em>OPC应用程序</em>)之间的<em>软件接口标准</em>。</li></ul></li><li><em>CEP</em><ul><li><em>复杂事件处理(Complex Event Progressing)</em>技术是一种新兴的基于<strong>事件流</strong>的技术<ul><li>通过分析事件间的<em>关系</em>，利用<em>过滤、关联、聚合</em>等技术最终由简单事件<em>产生高级事件</em>或商业流程。</li></ul></li></ul></li></ul><h2><span id="中间件的工作原理">中间件的工作原理</span></h2><p><em>构件</em> <img src="/images/物联网中间件技术/DraggedImage-4.png"></p><ul><li><em>接口</em>：定义分布式对象能力的约定。构件之间可见的只有接口，通常是跨语言的</li><li><em>数据类型</em>：分布式对象交互需定义在分布式对象之间传输的数据类型。需要一种独立于语言和平台的数据类型系统</li><li><em>编组与解组</em>：串行化流数据与程序员处理的有类型数据之间需 编组与解组</li><li><em>对象句柄</em>：对象句柄是对<em>远端分布式对象的引用</em></li><li><em>对象创建</em>：创建一个新的分布式对象实例的机制</li><li><em>对象调用</em>：分布式对象的调用的机制</li></ul><p><em>中间件</em></p><ul><li>抽取软件的<em>共性成分</em>由<strong>系统级软件</strong>完成， 向开发人员屏蔽系统低层的复杂度，从而在高层保持整体复杂度的相对稳定</li><li>依据所抽取出的应用软件中的<strong>不同共性</strong>设计与实现不同类型的<em>中间件</em><ul><li>数据访问中间件：支撑应用程序访问数据库，对异构环境下的数据库实现联接</li><li>消息中间件：为应用程序提供发送和接收异步消息支持</li></ul></li></ul><p><em>集成中间件</em></p><ul><li><strong>功能</strong><ul><li><em>提供构件运行环境</em><ul><li>管理构件的<em>实例及其生命周期、管理构件的元信息</em>等</li></ul></li><li><em>提供互操作机制</em><ul><li>开发人员在开发与调用分布式对象时，无需自己编写<em>处理底层通信</em>的代码</li></ul></li><li><em>提供公共服务</em><ul><li><em>公共服务</em>又称为系统级服务，指由中间件(应用服务器 )实现的、应用程序使用的软件系统中<em>共性程度高</em>的功能成分<ul><li>事务服务</li><li>安全服务</li><li>命名服务</li><li>持久性服务</li><li>消息服务</li><li>分布式垃圾回收服务</li><li>资源管理服务</li></ul></li></ul></li></ul></li></ul><p><em>Stub/Skeleton</em> <img src="/images/物联网中间件技术/DraggedImage-5.png"></p><ol type="1"><li><em>客户程序</em>将调用请求发送给<em>客户端桩</em>，对于客户程序来说，<strong>桩</strong>就是服务程序在客户端的代理</li><li><em>客户端桩</em>负责将远程调用请求进行编组并通过通信总线发送给<em>服务端</em></li><li>调用请求经通信总线传送到<em>服务端框架</em></li><li><em>服务端框架</em>将调用请求解组并分派给<em>真正的远程对象实现(服务程序)</em></li><li><em>服务程序</em>完成客户端的调用请求，将结果返回给<em>服务端框架</em></li><li><em>服务端框架</em>将调用结果编组并通过通信总线发送给<em>客户端桩</em></li><li><em>客户端桩</em>将调用结果解组并返回给<em>客户程序</em></li><li><em>客户程序</em>得到调用结果</li></ol><h2><span id="j2ee简介">J2EE简介</span></h2><p><img src="/images/物联网中间件技术/DraggedImage-6.png"></p><p>构件／容器结构</p><ul><li>构成J2EE 应用系统的<em>构件</em>都<em>运行在</em>某种J2EE <em>容器</em>中</li><li>容器<ul><li>为构件提供公共服务</li><li>为构件之间的交互或者是构件访问后台数据提供支持</li><li>提供运行环境</li></ul></li></ul><p><em>J2EE应用构件</em> <img src="/images/物联网中间件技术/DraggedImage-7.png"></p><ul><li>客户端构件<ul><li>Applets<ul><li>Applet 是具有图形用户界面的特殊的Java 类</li><li>运行在Web浏览器中</li><li>运行在支持Applet编程模型的容器中</li><li>在J2EE 应用中Applets 一般用来提供用户界面</li><li>Applet类自身不包含main 入口函数，它被容器调度执行</li><li>无需安装，从Web上下载运行在浏览器上</li></ul></li><li>Application Clients<ul><li>Application Client 指有图形用户界面的独立 Java 程序</li><li>与applet 不同，Application Client 通常包含main 入口函数且需要在 每个使用的客户端 机器上安装</li></ul></li><li>很多 J2EE 应用中均<em>不使用</em>Application Client 或 Applet 作为客户端程序，客户端的用户界面一般由<em>Web 页面</em>来提供</li></ul></li><li>服务器端构件<ul><li>Web构件<ul><li>Servlets</li><li>JSP<ul><li>一类特殊的<em>HTML文档</em></li><li>通过在HTML 文档中嵌入JSP 特定的标签来允许程序员在页面中加入<em>Java 代码</em>来<em>动态</em>生成页面内容</li></ul></li></ul></li><li>EJB构件<ul><li>实体构件</li><li>会话构件</li><li>消息驱动构件</li></ul></li></ul></li></ul><p><em>J2EE应用开发</em></p><ul><li>应用程序基本结构 <img src="/images/物联网中间件技术/DraggedImage-8.png"><ul><li>Java目标文件：<code>.jar</code>文件，用来打包EJB构件、Application Client以及它们需要的辅助Java目标文件</li><li>Web目标文件：<code>.war</code>文件，用来 打包Web 构件(Servlet、JSP)以及静态页面相关的文件(如HTML 文档、图片等)</li><li>企业目标文件：<code>.ear</code>的文件， 用来打包完整的J2EE 应用</li></ul></li><li>一个完整的J2EE应用中可以包含若干个Java目标文件和若干个Web目标文件</li><li>在打包 Java 目标文件、Web 目标文件与企业目标文件时都需要提供相应的<em>部署描述符</em></li><li><strong>部署描述符</strong><ul><li>Deployment Descriptor，简称DD</li><li>一个布署描述符是一个XML格式的文件，该文件中描述了当前模块中所<em>包含的内容(构件或模块)</em>所<strong>需要的环境</strong></li><li>EJB 模块的布署描述符——<code>ejb-jar.xml</code><ul><li><em>同一EJB 模块</em>中的所有EJB 构件<em>共享</em>该模块的布署描述符</li><li>描述每一个EJB 构件的<em>Home接口、 Remote 接口以及真正提供服务的类</em>的<strong>名字</strong></li><li>描述<strong>构件类型及需要容器提供的服务</strong>：如果是Session Beans，说明是<em>哪种类型</em>的Session Bean;如果是Entity Bean，说明是否需要容器提供的 <em>持久性管理服务及相关的信息</em>;说明该EJB 是否需要由容器来<em>控制事务</em>，如果需要，怎样控制;说明该EJB 的<em>安全控制策略</em>等等。</li><li>当这些相关的特性发生变化时，可以<strong>不</strong>修改EJB 的源程序，而仅通过<em>修改部署描述符</em>就可以使得EJB 去适应新的环境。</li></ul></li><li>Web 模块的布署描述符——<code>web.xml</code><ul><li><em>同一Web 模块</em>中的所有构件<em>共享</em>该模块的布署描述符</li><li>首先描述<em>当前模块包含的构件</em>(包括Servlet、JSP、表态页面等);</li><li>为当前模块中的构件说明<em>安全控制规则</em>;</li><li>由于J2EE 应用的Web 模块中经常需要配置应用使用的<em>用户认证方式</em>，因为在典型的J2EE 应用中，客户端通常通过浏览器直接访问Web 模块中的构件，Web 模块中的构件首先与访问者接触，因此通常在Web模块中完成对用户身份的认证。</li></ul></li><li>J2EE 应用的布署描述符——<code>application.xml</code><ul><li>描述当前应用中包含的<em>所有模块</em></li><li>还可能定义应用使用的<em>安全性角色</em></li></ul></li></ul></li><li>MVC <img src="/images/物联网中间件技术/DraggedImage-9.png"></li></ul><p><em>思考题</em></p><ul><li>J2EE 应用中构件/容器能够为应用构件提供哪些好处?<ul><li>为应用构件提供公共服务</li><li>为应用构件之间的交互或者是应用构件访问后台数据提供支持</li><li>提供应用构件运行环境</li></ul></li><li>组成 J2EE 应用的应用构件主要有哪几种？每种应用构件在J2EE 应用中的基本作用是什么？<ul><li>两种：客户端构件和服务端构件</li><li>基本作用：<ul><li>客户端构件：提供图形用户界面，调用后台接口</li><li>服务端构件：提供数据服务、业务逻辑等</li></ul></li></ul></li><li>请简单描述 J2EE 应用程序的基本结构，说明布署描述符的主要作用<ul><li>基本结构：Java目标文件、Web目标文件、企业目标文件和部署描述符</li><li>部署描述符作用<ul><li>描述当前模块中所<em>包含的内容(构件或模块)</em>所<strong>需要的环境</strong></li><li>描述<strong>构件类型及需要容器提供的服务</strong></li></ul></li></ul></li></ul><h2><span id="j2ee-ejb构件基础">J2EE-EJB构件基础</span></h2><p><em>EJB构件概述</em></p><ul><li>EJB 构件是由公共服务框架自动管理的分布式的服务端商业构件<ul><li>分布式对象技术-提供分布式对象的支持</li><li>服务端构件技术-提供服务端构件管理的支持</li><li>CTM(ComponentTransactionMonitor)技术-提供公共服务框架的支持</li></ul></li><li>特点<ul><li><em>公共服务框架</em><ul><li>提供大量系统级服务</li><li>开发者关注商业逻辑实现，提高开发效率</li></ul></li><li><em>平台独立性</em><ul><li>沿袭了JAVA的平台无关性</li></ul></li><li><em>封装特性</em><ul><li>定义标准服务API 来封装现有的基础性服务</li></ul></li><li><em>可定制性</em><ul><li>修改EJB 构件的运行时配置以满足特定用户的需求</li></ul></li><li><em>协议无关性</em><ul><li>支持客户端通过多种EJB 访问EJB 构件</li></ul></li><li><em>通用性</em><ul><li>方便支持不同规模的应用系统，即可以在任何时间增加客户系统，而不需修改核心的应用系统</li><li>系统资源可伸缩性</li></ul></li></ul></li></ul><p><em>EJB与Java Bean的比较</em></p><ul><li><em>用途及功能</em><ul><li>EJB 构件通常用于<em>服务端应用开发</em></li><li>Java Bean 构件通常用于<em>客户端应用开发</em>或作为服务端<em>EJB 构件的补充</em></li><li>Java Bean <em>不能</em>使用Java 企业版平台提供的公共服务框架的支持</li></ul></li><li><em>部署&amp;定制</em><ul><li>EJB 构件是<em>可布署的</em>，即EJB 构件可以作为独立的软件单元 被布署到EJB 应用服务器上，是应用构件</li><li>Java Bean 是开发构件，<em>不能被部署为独立的单元</em></li><li>EJB 构件是部署时<em>可定制的</em></li><li>Java Bean 构件的定制通常仅发生在<em>开发阶段</em>，部署时不能对其进行定制</li></ul></li><li><em>远程访问能力</em><ul><li>EJB 构件是分布式对象，可以被客户应用或者其它EJB构件<em>进行远程访问</em></li><li>普通的Java Bean 构件只能<em>在其构成的应用中使用</em>，不能提供远程访问的能力</li></ul></li><li><em>终端可见性</em><ul><li>EJB 构件是服务端构件，运行在服务端，没有人机交互界面，<em>对终端用户不可见</em></li><li><em>部分JavaBeans 构件对终端用户可见</em>，如GUI 应用中 使用的按钮构件等</li></ul></li></ul><p><em>EJB体系结构</em></p><ul><li>EJB容器<ul><li>EJB 容器为EJB 构件<em>提供运行环境</em>并<em>管理运行于其中的EJB</em></li><li>EJB 容器为EJB 的执行<em>提供系统级的服务</em></li></ul></li><li>EJB服务器<ul><li>EJB 服务器是遵循EJB 定义的构件模型的CTM 实现，<em>一个EJB 服务器可以包含一个或多个EJB 容器</em>，EJB 服务器<em>为EJB 容器的运行提供公共服务框架</em>。</li></ul></li><li>EJB客户端<ul><li>EJB 客户端泛指<em>调用EJB 构件提供业务操作的软件实体</em>，EJB 构件的客户端可以有多种形式<ul><li>可以是独立的Java程序也可以是其他EJB</li></ul></li></ul></li><li><strong>Enterprise Java Bean</strong><ul><li>开发者实现的核心构件EJB</li><li>是EJB 客户端所调用的操作的<em>真正实现者</em></li><li>可以被部署到EJB 应用服务器上，用来组装大型的EJB 应用</li></ul></li><li><em>Home接口</em><ul><li>Home 接口(Home Interface)包含<em>EJB 生命周期管理</em>相关的方法，客户程序使用Home接口<em>创建或删除EJB 的实例</em></li><li><em>每个Home 接口都依赖于一个类(bean)来提供 Home 接口中约定的功能</em>，该类由容器自动生成，程序员只需定义接口</li></ul></li><li><em>Remote接口</em><ul><li>Remote 接口包含EJB 实现的商业方法的声明， 它实际上<em>约定了EJB 所提供的服务</em></li><li>实现接口的类由容器自动生成，但<em>真正的操作是由EJB构件实现的</em></li><li>客户程序只能通过Remote 接口来<em>间接地访问EJB 实现 的商业方法</em>，不能直接进行调用</li></ul></li><li>LocalHome/Local接口<ul><li><code>LocalHome = Home, Local = Remote</code></li><li>与Home接口和Remote相比，本地接口的不同之处在于 客户应用通过<em>本地接口</em>发起的调用是<strong>进程内的本地调用</strong>， 因此比远程接口调用有<em>更高的效率</em></li></ul></li><li>￼每个EJB 构件<em>都</em>有一对<em>对应的Home 接口与 Remote 接口</em>和/或一对对应的LocalHome接口与 Local 接口，从这种意义上讲，我们通常认为一个<em>完整的EJB 构件</em>包含：<ul><li><strong>Enterprise Bean类</strong><ul><li><em>实现业务逻辑</em></li></ul></li><li><strong>Home接口</strong><ul><li><em>定义创建、查找EJB的方法</em></li></ul></li><li><strong>Remote接口</strong><ul><li><em>定义在bean中实现业务逻辑的方法</em></li></ul></li></ul></li></ul><p><em>EJB构件开发</em> <img src="/images/物联网中间件技术/DraggedImage-10.png"></p><ul><li>会话构件(Session Bean)<ul><li>Session bean 存在于客户应用与应用服务器<strong>交互</strong>的时间段内，是用来和客户端做交互的</li><li>和实体Bean 相比，Session bean 中的<strong>数据不保存在数据库中</strong></li><li>Session bean 又可分为两类<ul><li><em>有状态的Session Bean</em> 要跨方法调用<em>保存会话状态</em>，一个有状态的 Session Bean 实例<em>同时只处理一个客户应用的请求</em>，典型地如网上购物系统中提供购物车功能的Session Bean</li><li><em>无状态的Session Bean</em>在方法调用中间<em>不维护任何状态</em>，一个无状态的Session bean 实例可以<em>同时处理多个客户应用的请求</em>，典型地如网上证券系统中提供股票信息查询功能的Session Bean</li></ul></li></ul></li><li>实体构件(Entity Bean)<ul><li><em>Entity Bean 代表数据库中的记录</em>，在EJB 中是用来封装数据库操作的，与Session Bean相比，逻辑上可以认为Entity Bean 在数据库中的数据存在期间都会存在</li><li>同样与数据库中的数据类似，Entity Bean <em>可以被多个客户应用共享访问</em></li></ul></li><li>消息驱动构件(Message Driven Bean)<ul><li>Message Driven Bean 主要用来处理异步消息，因此通常在异步编程模式下使用</li></ul></li><li><em>会话构件与实体构件</em><ul><li>客户端<em>通过会话bean连接服务器</em>，<em>会话bean通过实体bean访问数据库</em>，这使得既可以保存客户端的信息又可以保存数据库记录的信息</li><li>会话bean经常用于涉及<em>多个实体bean</em>的业务处理和控制逻辑</li></ul></li><li>Hello World Session Bean例子 <img src="/images/物联网中间件技术/DraggedImage-11.png"></li><li><strong>EJB构件访问流程</strong> <img src="/images/物联网中间件技术/DraggedImage-12.png"></li><li>EJB构件的实现步骤<ol type="1"><li>创建Remote接口</li><li>创建Home接口</li><li>创建Bean的实现类</li><li>编译Remote接口、Home接口、bean实现类</li><li>创建部署描述符</li><li>将以上三个文件与部署描述符文件打包为一个 ejb-jar文件</li><li>部署EJB构件</li></ol></li></ul><p><strong>接口设计原则</strong></p><ul><li>Remote接口设计原则<ul><li>继承性约束<ul><li>每个Remote 接口必须继承<em>EJBObject</em> 接口</li><li>包含用于<em>管理实现remote 接口的EJB 对象的方法</em></li></ul></li><li>方法对应规则<ul><li>Remote 接口中出现的<em>每一个方法的声明</em>都必须在相应的<em>Enterprise Bean类中有一个对应方法的实现</em></li><li>其中每个方法的<strong>参数和返回值必须完全相同</strong>，抛出的<strong>异常必须匹配</strong><ul><li>匹配的含义是指<em>接口</em>中方法抛出<em>异常的集合</em>必须<strong>包含</strong> <em>Bean 类中</em>对应方法抛出<em>异常的集合</em></li><li>即接口方法中出现的异常，Bean类中可以出现，也可以不出现，但是<em>不允许Bean 类中方法抛出接口对应方法中没有声明的异常</em></li></ul></li></ul></li><li>RMI 约束<ul><li>Remote 接口中的方法<strong>必须抛出RemoteException 异常</strong>，该异常报告网络通信错误</li><li>方法定义中的<em>参数与返回值必须是合法</em>的Java RMI 类型的参数/返回值</li></ul></li></ul></li><li>Home接口设计原则<ul><li>继承性约束<ul><li>每个Home 接口必须继承<em>EJBHome</em> 接口</li><li>其中包含了<em>Enterprise Bean 生命周期管理的方法</em></li></ul></li><li>方法对应规则<ul><li>Home 接口中的每个<em>create</em> 方法都必须在相应的<br>Enterprise Bean 类中有一个对应的<em>ejbCreate</em> 方法</li><li>匹配同上</li></ul></li><li>RMI约束<ul><li><em>RemoteException</em>同上</li><li>Home 接口中的每个<em>create 方法</em>必须抛出 <em>CreateException</em>异常，该异常用于报告EJB 实例的初始化错误</li></ul></li></ul></li></ul><p><em>Enterprise Bean 类设计原则</em></p><ul><li>接口约束<ul><li>Enterprise bean 类必须实现<em>EnterpriseBean接口</em></li><li><code>EnterpriseBean</code>接口中定义了Enterprise Bean <em>生命周期管理的方法</em>，实现该接口是Enterprise Bean 与普通java bean 的重要区别</li></ul></li><li>可见性约束<ul><li>Enterprise bean 类必须定义为<em>public 类</em></li></ul></li><li>商用方法约束<ul><li>Enterprise bean 类<strong>必须实现Remote 接口中定义的业务逻辑</strong>操作</li></ul></li><li>生命周期管理方法约束<ul><li>Enterprise Bean 类<strong>必须实现</strong>Home 接口中定义的create 方法对应的 <strong>ejbCreate 方法</strong></li></ul></li></ul><p><em>思考与练习！</em></p><ul><li>EJB 构件与普通的Java Bean 有哪些主要区别? 他们分别适合于什么场合的开发? 见前面</li><li>EJB 体系结构中基于Stub/Skeleton 结构与客户端交互的直接构件不是EJB，而是容器自动生成的对象，采用这样的结构有什么好处? 不会</li><li>在 EJB 体系结构中，Home 接口与Remote 接口的主要作用是什么?为什么还要引入LocalHome 与Local 接口，这对接口使用时有哪些限制? 见前面</li><li><em>EJB构件的访问流程? </em> <img src="/images/物联网中间件技术/DraggedImage-13.png"><ol type="1"><li>查找Home对象的引用</li><li>JNDI返回Home对象的引用</li><li>向Home接口请求一个EJB对象</li><li>Home对象创建一个EJB对象</li><li>Home对象返回给客户的EJB对象的引用</li><li>客户端通过Remote接口调用bean方法</li><li>EJB对象请求Enterprise Bean调用bean实例的相应方法</li><li>Enterprise Bean返回调用结果给EJB对象</li><li>EJB对象把返回值返回给客户端</li></ol></li></ul><h2><span id="ejb构件开发">EJB构件开发</span></h2><p><em>无状态会话Bean</em></p><ul><li>无状态会话Bean每次调用只对客户提供业务逻辑， 但<em>不保存客户端的任何数据状态</em></li><li>无状态会话Bean的状态，被保持在客户端，容器不负责管理</li><li>用途<ul><li>如果<em>数据</em>实际上是<em>瞬时映像</em>，则建议使用无状态会话 Bean</li><li>如果<em>数据状态</em>非常<em>敏感</em>，则<em>不</em>要使用无状态会话 Bean，这些情况可以使用有状态会话Bean，将用户状态保存到服务器中</li></ul></li><li>无状态会话Bean：生命周期由<em>容器</em>控制</li><li>当部署一个EJB时，容器会为这个Bean分配几个实例到<em>组件池</em>中</li><li>当客户请求一个Bean时，J2EE服务器将一个<em>预先被实例化</em>的Bean分配出去</li><li>空闲的Bean<ul><li>不在方法或事务中</li><li>客户长时间不用</li></ul></li><li>如果全部实例都已用完，则会自动生成一个新的实例放到池中，并分配给请求者</li><li>举例：<em>返回服务端当前系统时间</em><ul><li>Remote接口（回忆设计原则） <img src="/images/物联网中间件技术/DraggedImage-14.png"></li><li>Home接口<ul><li>Home 接口中包含EJB 构件<em>生命周期管理</em>的相关方法，客户程序使用Home Interface <em>创建、查找或删除</em>EJB 的实例 <img src="/images/物联网中间件技术/DraggedImage-15.png"></li><li>由于<em>无状态会话构件</em>的对象可能<em>被多个客户端共享</em>地访问 ，因此 EJB 规范<strong>不允许某个客户端使用特定的参数初始化</strong>无状态会话构件的对象，进而使得无状态会话构件Home 接口中<strong>只能包含没有参数的create 方法</strong></li></ul></li><li>Enterprise Bean 类<ul><li>Enterprise Bean 类首先要按照Remote 接口的约定<em>实现商业方法getCurTime</em>，其次要实现 Home 接口中<code>create</code> 方法对应的<em><code>ejbCreate</code> 方法与会话构件生命周期相关的方法</em> <img src="/images/物联网中间件技术/DraggedImage-16.png"></li></ul></li></ul></li></ul><p><em>EJB生命周期管理</em></p><ul><li>与普通的 Java 类相比，Enterprise Bean 类中多 出了<code>ejbCreate</code>、<code>ejbRemove</code>、<code>ejbPassivate</code>、 <code>ejbActivate</code>、<code>setSessionContext</code> 等EJB 生命周 期管理相关的方法</li><li>无状态会话构件的生命周期<ul><li><em>方法就绪状态</em><ul><li>方法就绪状态表明对应无状态会话构件对象已被创建，可以为客户端提供服务</li></ul></li><li><em>不存在状态</em><ul><li>不存在状态表明EJB 容器中不存在对应无状态会话构件的实例 ，处于不存在状态的<em>实例还未被创建</em> <img src="/images/物联网中间件技术/DraggedImage-17.png"></li></ul></li><li>无状态的会话构件<strong>实例的创建和删除都是由容器自动控制 </strong>，容器也<em>不</em>允许客户端调用Home 接口中的<code>remove</code> 方法来删除实例</li></ul></li></ul><p><em>思考</em></p><ul><li>EJB构件的实现步骤？</li><li>如果没有Home接口和Remote接口，开发人员需要做哪些工作?</li></ul><p><em>有状态会话Bean</em></p><ul><li>该EJB 构件实现网上购物系统中购物车的基本功能，包括添加商品、去除商品、查找商品、清空 购物车、提交商品等</li><li>由于该构件的实例(对象)<em>需要保存与特定客户端相关的会话状态</em>，即特定客户所选择的商品等相关信息，因此设计为<em>有状态的会话构件</em>。</li><li>Remote接口 <img src="/images/物联网中间件技术/DraggedImage-18.png"></li><li>Home接口 <img src="/images/物联网中间件技术/DraggedImage-19.png"></li><li>Enterprise Bean 类 <img src="/images/物联网中间件技术/DraggedImage-20.png"> <img src="/images/物联网中间件技术/DraggedImage-21.png"> <img src="/images/物联网中间件技术/DraggedImage-22.png"></li><li><em>生命周期</em><ul><li>方法就绪状态</li><li>不存在状态<ul><li>实例未被创建</li></ul></li><li>钝化状态<ul><li>对应有状态会话构件对象已被转移至<em>持久存储介质</em>，暂时不能使用 <img src="/images/物联网中间件技术/DraggedImage-23.png"></li></ul></li><li>因为<em>有状态会话构件</em>需<em>保存与特定客户端相关的中间状态</em>， 因此每个实例/对象都是被一个客户端所专用的。这就使得每个客户端都需要一个专门的有状态会话bean 来为它服务，则很有可能在服务端<em>同时存在大量的EJB 实例</em>，从而导致服务端<em>内存开销太大</em>。</li><li>为了<em>限制服务端内存使用总量</em>，当EJB 实例的数量过多时， 容器仅仅会在内存中保留那些正在使用或者刚被使用的实例 ，会<em>把其它的实例转移到持久存储介质</em>上(不是删除)，此时被转移到持久存储介质上的实例会从<em>方法就绪状态</em>进入<em>钝化状态</em>。</li><li>当客户端出现<em>超时</em>时，容器会把持久存储介质中的实例<em>删除</em>掉，该实例进入<em>不存在状态</em></li><li>只要有新的客户端请求，容器就会创建新的实例</li></ul></li></ul><p><em>实体构件与持久化技术</em> <img src="/images/物联网中间件技术/DraggedImage-24.png"> 基于<em>实体构件</em>的支持，业务逻辑构件<em>以对象的方式</em>看待与处理数据库中的数据，从而大致简化数据库开发的目的。</p><p>常用的Java持久化方案</p><ul><li>基于DAO和JDBC<ul><li>这种方案通过DAO来实现数据的持久化操作，具体实现时，<em>DAO通过JDBC来完成对数据库的访问</em>。这种方案 <em>要求开发人员对JDBC 的底层信息要比较熟悉</em>。</li></ul></li><li><strong>基于ORM</strong><ul><li>ORM的全称为Object Relational Mapping，其基本思想将关系型数据库中的数据利用某种机制<em>映射为Java 对象</em>，在业务逻辑构件看来，数据库中的数据以Java 对象的形式出现，通常<em>每个对象对应数据库中的一条记录</em>，因此数据库操作也就转换成了对Java 对象的操作。而这种数据与 Java 对象之间的映射通常可以获得自动化机制的支持，从而将开发人员从基于JDBC 的复杂开发中解脱出来</li></ul></li></ul><p><em>实体构件</em></p><ul><li>最典型的情况是一个<code>EntityBean</code>和数据库中有一个<em>表</em>相对应，而<code>EntityBean</code>的每一个<em>实例</em>对应表中的<em>一行</em>数据</li><li><em>EntityBean和SessionBean的不同之处</em><ul><li>EntityBean是持久性的<ul><li>应用程序结束或者服务器终止EntityBean的状态仍然保留</li></ul></li><li>允许共享访问<ul><li>EntityBean可以被多客户端所共享</li></ul></li><li>拥有主键并且会参与和其他EntityBean的关联</li></ul></li><li>用途<ul><li>Bean代表一个商务<em>实体</em>而不是一个过程<ul><li>例如表示<em>信用卡</em>的<code>CreditCardEJB</code>要做成<code>EntityBean</code>， 而<em>信用卡核实</em>的<code>VerifierEJB</code>就只能做成<code>Session Bean</code></li></ul></li><li>Bean的状态是需要<em>持久存储</em>的</li><li>持久性管理机制<ul><li>BMP：Bean管理的持久性<ul><li>相关数据库操作<em>由开发人员在构件实现代码中通过JDBC 编程实现</em></li><li>须在EntityBean中手工编写访问数据库的代码</li></ul></li><li><em>CMP：容器管理的持久性</em><ul><li>相关数据库操作由容器自动完成，<em>容器会自动生成访问数据库的代码</em></li><li>开发者无需为数据库访问编码</li></ul></li></ul></li></ul></li><li>生命周期<ul><li>就绪状态<ul><li>实体构件实例建立了与EJB对象的关联，已经和数据库记录对应起来，可以处理客户应用的请求</li></ul></li><li>不存在状态</li><li>池状态<ul><li>实体构件的实例存在于实例池中，容器<em>新创建的实例</em>会进入这个状态 <img src="/images/物联网中间件技术/DraggedImage-25.png"></li></ul></li><li>客户端程序调用Home接口中的方法<em>创建或查找</em>到某个实体构件实例时，该实例会从<em>池状态</em>进入<em>就绪状态</em></li></ul></li><li><em>EBJ 1.1实体构件</em><ul><li>封装数据库税率表中的数据操作 <img src="/images/物联网中间件技术/DraggedImage-26.png"></li><li>Remote接口 <img src="/images/物联网中间件技术/DraggedImage-27.png"></li><li>Home接口 <img src="/images/物联网中间件技术/DraggedImage-28.png"> Home 接口中的操作实际用于数据库表中<em>记录</em>的创建 (插入)、查找与删除</li><li>Enterprise Bean 类 <img src="/images/物联网中间件技术/DraggedImage-29.png"></li></ul></li><li><em>EJB 2.0实体构件</em><ul><li><strong>区别</strong><ul><li>Enterprise Bean 类的区别<ul><li>在 EJB1.1 中，Enterprise Bean 类由开发人员定义</li><li>在EJB2.0 中，Enterprise Bean 类由容器生成，开发人员仅定义一个抽象基类</li></ul></li><li>Enterprise Bean 数据成员的区别<ul><li>在EJB2.0 中与<em>数据库字段对应的Bean属性不由用户定义</em>， 用户仅定义对应的<code>set</code>和<code>get</code>方法，具体属性的定义由容器生成，这样容器可以对属性进行优化</li><li>在EJB2.0 的CMP构件中，还有一种特殊的字段，<em>cmr ( Container Managed Relationship)字段</em>，用于关联其它的表(实体构件)。在组装/ 部署时，<em>可以设置由容器自动维护表之间的关联关系</em></li></ul></li><li>接口区别<ul><li>EJB2.0 引入了<em>本地接口</em>，实体构件的进程内客户端可以通过本地接口获得更好的调用效率</li></ul></li></ul></li><li>订单表与送货地址表结构 <img src="/images/物联网中间件技术/DraggedImage-30.png"> 可以为地址EJB提供本地接口，订单EJB可通过地址 EJB 的<em>本地接口获得较高的访问效率</em></li><li>地址EJB: Local接口 <img src="/images/物联网中间件技术/DraggedImage-31.png"></li><li>地址EJB: LocalHome接口 <img src="/images/物联网中间件技术/DraggedImage-32.png"></li><li>地址EJB: Enterprise Bean类的抽象基类 <img src="/images/物联网中间件技术/DraggedImage-33.png"> <img src="/images/物联网中间件技术/DraggedImage-34.png"></li><li>订单EJB:Remote 接口 <img src="/images/物联网中间件技术/DraggedImage-35.png"></li><li>订单EJB: Home 接口 <img src="/images/物联网中间件技术/DraggedImage-36.png"></li><li>订单EJB: Enterprise Bean类的抽象基类 <img src="/images/物联网中间件技术/DraggedImage-37.png"> …. 定义一个 <em>CMR(Container Managed Relationship)字段</em>对应的一对<code>set</code>与<code>get</code>方法，CMR字段的类型为所关联的实体构件的<em>Remote或 Local接口</em></li></ul></li></ul><p><em>思考题</em></p><ol type="1"><li>有状态会话构件与无状态会话构件有什么区别? 请分别从定义、生命周期、开发与部署的角度进行描述。</li><li>什么是有状态会话构件的生命周期的”钝化“状态?作用是什么?</li><li>实体构件包括哪两种持久性管理机制?</li><li>EJB2.x 的实体构件与EJB1.x 的实体构件有哪些主要区别?</li><li><p>以下为实现可供客户端远程访问的网上购物系统中购物车功能的EJB构件的Home 接口与Remote 接口代码，请分别指出代码中违背设计原则之处 。(16分) Remote接口: <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> shopping;</span><br><span class="line"><span class="keyword">import</span> javax.ejb.*;</span><br><span class="line"><span class="keyword">import</span> java.rmi.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ShoppingBag</span> <span class="keyword">extends</span> <span class="title">EJBLocalObject</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addCom</span> <span class="params">(Commodity comm)</span>  <span class="keyword">throws</span> RemoteException</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeComm</span> <span class="params">(Commodity comm)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> NoSuchCommodityException</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">()</span> <span class="keyword">throws</span> BagEmptyException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Home接口: <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> shopping;</span><br><span class="line"><span class="keyword">import</span> javax.ejb.*;</span><br><span class="line"><span class="keyword">import</span> java.rmi.*;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ShoppingBagHome</span> <span class="keyword">extends</span> <span class="title">EJBLocalHome</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> ShoppingBag <span class="title">create</span><span class="params">(String customerName)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> RemoteException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>答：<ol type="1"><li><code>public interface ShoppingBag extends EJBLocalObject</code>违反继承性约束，应继承<code>EJBObject</code></li><li>函数<code>removeComm</code>和<code>commit </code>违反RMI约束，应抛出<code>RemoteException </code>异常</li><li><code>public interface ShoppingBagHome extends EJBLocalHome</code>违反继承性约束，应继承<code>EJBHome</code>4. 函数<code>create</code>违反RMI约束，还应抛出<code>CreateException</code>异常</li></ol></li></ol><h2><span id="rfid中间件">RFID中间件</span></h2><p><em>RFID系统构成</em></p><ul><li>电子标签</li><li>读写器</li><li>系统高层<ul><li>计算机网络 <img src="/images/物联网中间件技术/DraggedImage-38.png"></li></ul></li></ul><p><em>RFID中间件的必要性</em></p><ul><li>数据采集点分散，读写器矩阵、标签打印或贴标等设备多样，<em>众多底层硬件设备需统一管理</em></li><li>一个RFID系统可能服务于多个后台系统，需对<em>RFID端口与后台系统的对应关系进行统一管理</em></li><li>RFID系统的原始数据采集是分散的，需<em>分布式处理的系统结构</em></li><li>后台应用系统的现有统一接口不能满足<em>读写器设备</em>及其<em>数据采集场景</em>的<em>多样性需求</em></li><li>不断增加的RFID数据采集端口的<em>海量数据</em> ，并不是后台应用系统所直接需要的，必须经<em>过滤分类、统计分析处理</em>之后，才能提交使用</li><li>随着应用的<em>扩张</em>需求，读写器数量和种类 会更新或增加，后端应用程序也会增加或改变，其数据结构或格式也会发生变化</li></ul><p><em>RFID中间件概念</em> 在RFID应用中，为RFID硬件和应用程序交互<strong>提供通用服务</strong>(具有标准的程序接口和协议)，<em>实现后台网络与RFID读写器无缝连接的一项重要技术</em>。</p><p><em>RFID中间件功能</em></p><ul><li><em>硬件管理</em><ul><li>RFID基础设施管理</li><li>连接RFID读写器，读取RFID标签数据</li><li>控制RFID读写设备按照预定的方式工作，保证不同读写设备之间能很好的配合协调</li></ul></li><li><em>数据采集</em></li><li><em>数据处理</em><ul><li>加工处理来自读写器的所有信息和事件流</li><li>对标签数据进行过滤、分组和计数，以减少发往信息网络系统的数据量</li><li>并防止错误识读、多读信息。按照一定的规则筛选过滤数据 ，去除阅读器产生的冗余、错误的标签数据。将真正有效的数据传送给后台的信息系统</li><li>生成报告时只上传关心的数据(分组统计)</li></ul></li><li>数据传输<ul><li>为分布式异构环境下的应用程序提供可靠数据通信服务，保证读写器和企业级分布式应用系统平台之间的<em>可靠通信</em></li></ul></li></ul><p><em>EPC GLOBAL</em></p><ul><li>组成<ul><li>电子产品编码EPC <img src="/images/物联网中间件技术/DraggedImage-39.png"><ul><li>Header (8bit) - Tag version number</li><li>EPC Manager (28bit) - Manufacturer ID</li><li>Object class (24bit) - Manufacturer’s product ID</li><li>Serial Number (36bit) - Unit ID</li></ul></li><li>识别系统（读写器和电子标签）</li><li>中间件</li><li><em>物联网名称解析服务 IOT-NS</em><ul><li>将电子标签识别ID号转换成对应的<em>统一资源标识符 (URI)</em></li></ul></li><li><em>物联网信息发布服务 IOT-IS</em><ul><li>对物联网中的信息进行处理和发布</li><li>网上存放物品信息的计算机称为<em>物联网信息服务器</em></li></ul></li></ul></li><li>构成 <img src="/images/物联网中间件技术/DraggedImage-40.png"></li><li>技术规范<ul><li>标签编码规范</li><li>射频标签逻辑通信接口规范</li><li>Savant中间件规范</li><li>ONS对象名称解析服务规范</li><li>PML语言</li></ul></li></ul><p><em>Savant</em></p><ul><li>SAVANT是Auto-ID Center提出的<em>分层、模块化的中间件组件</em>，是具有<em>数据捕获、监控、传送</em>功能的数据挖掘工具</li><li>处理模块与外部世界的联系就通过2个规范中定义的接口实现<ul><li><em>Reader接口</em>：提供与标签阅读器的联系</li><li><em>应用接口</em>：提供与外部应用软件的联系 <img src="/images/物联网中间件技术/DraggedImage-41.png"></li></ul></li><li>RFID中间件和EPCIS捕获应用之间，定义了<em>RFID事件过滤和采集接口(ALE) </em> <img src="/images/物联网中间件技术/DraggedImage-42.png"><ul><li>基本操作<ul><li>应用发一个请求到ALE的接口要求读或写标签，ALE Engine处理从读写器传回来的数据产生报告返回给应用</li></ul></li><li>请求模式 <img src="/images/物联网中间件技术/DraggedImage-43.png"> <img src="/images/物联网中间件技术/DraggedImage-44.png"> <img src="/images/物联网中间件技术/DraggedImage-45.png"></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 本科课程 </tag>
            
            <tag> 物联网 </tag>
            
            <tag> 中间件 </tag>
            
            <tag> Java </tag>
            
            <tag> EJB </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Combined Multi-dimension Bloom Filter</title>
      <link href="/2017/04/19/Combined%20Multi-dimension%20Bloom%20Filter/"/>
      <url>/2017/04/19/Combined%20Multi-dimension%20Bloom%20Filter/</url>
      
        <content type="html"><![CDATA[<p>​ A Bloom filter is a space-efficient probabilistic data structure, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. False positive matches are possible, but false negatives are not – in other words, a query returns either &quot;possibly in set&quot; or &quot;definitely not in set&quot;. Elements can be added to the set, but not removed (though this can be addressed with a &quot;counting&quot; filter); the more elements that are added to the set, the larger the probability of false positives.</p><a id="more"></a><h2><span id="standard-bloom-filter">Standard Bloom Filter</span></h2><p>​ Let’s briefly review the standard bloom filter. A bloom filter is used to represent a set <span class="math inline">\(S = \{s_1, s_2, ...,s_n\}\)</span> with a m-bit array and each bit of which is denoted by <span class="math inline">\(BF[0], BF[1], …, BF[m-1]\)</span>. Initially, the m-bit array is initiated with 0 and we define hash functions. Each of them can reflect each element <span class="math inline">\(x \in S\)</span> to a number <span class="math inline">\(h_i(x) \in \{0, 1, ..., m-1\}\)</span> randomly, where <span class="math inline">\(i \in \{0, 1, .., k-1\}\)</span>. Whenever inserting an element, hashing it with the <span class="math inline">\(k\)</span> hash functions, so we get <span class="math inline">\(k\)</span> indexes. Then letting <span class="math inline">\(BF[h_i(x)] = 1\)</span> for each <span class="math inline">\(i \in \{0, 1, .., k-1\}\)</span>. Given an element <span class="math inline">\(y\)</span>, we check each <span class="math inline">\(BF[h_i(y)]\)</span> , if all of them equal to <span class="math inline">\(1\)</span> , then we assume is in the set <span class="math inline">\(S\)</span> even though it may actually not. Hence a Bloom Filter may yield false positives. However, if there is one of them equals to <span class="math inline">\(0\)</span>, then the element <span class="math inline">\(y\)</span> is definitely not in the set <span class="math inline">\(S\)</span> .</p><p>​ For example, after inserting <span class="math inline">\(x,y,z\)</span> , if we want to figure out whether <span class="math inline">\(w\)</span> is in the set, since <span class="math inline">\(BF[h_2(w)] = 0\)</span> , the Bloom Filter will tell us is not in the set, as illustrated in the figure Figure 1.</p><p><img src="/images/figure1.png"></p><p>​ <strong>Figure 1 An example of Bloom Filter</strong></p><p>​ In order to analyze the possibility that a Bloom Filter gives a false positive, we denote a Bloom Filter with a three-element tuple <span class="math inline">\((n,m,k)\)</span> and further assume that each <span class="math inline">\(\{0, 1, ..., m-1\}\)</span> hash function is uniform distributed, which means the number in has equal possibility to be chosen by a hash function. Therefore, given a hash function, the possibility of one specific position in BF equals to 0 is: <span class="math display">\[1 - \frac{1}{m}\]</span> Then, with respect to all hash functions, the possibility becomes to: <span class="math display">\[(1-\frac{1}{m})^k\]</span> After inserted elements, the possibility is: <span class="math display">\[(1-\frac{1}{m})^{nk}\]</span> If a specific item leads the Bloom Filter to yield a false positive, all of the results of must equal to 1, whose possibility is: <span class="math display">\[[1-(1-\frac{1}{m})^{nk}]^k\]</span> According to the definition of , we can approximately represent the possibility as: <span class="math display">\[f_{BBF} = [1-(1+\frac{1}{(-m)})^{(-m)\frac{nk}{(-m)}}]^k \approx (1-e^{-\frac{kn}{m}})^k\]</span> The standard Bloom Filter is basic for extension of Bloom Filters. From now on, it is termed basic Bloom Filter (BBF).</p><h2><span id="multi-dimension-bloom-filter">Multi-dimension Bloom Filter</span></h2><p>​ In order to store multi-dimension data, for example <span class="math inline">\(l\)</span> dimensions, we can simply use <span class="math inline">\(l\)</span> basic Bloom Filters to store each dimension, which called a Multi-dimension Bloom Filter (MDBF). When we want to identify whether element <span class="math inline">\(x\)</span> is in the set, just compute <span class="math inline">\(BBF_1[x_0], ..., BBF_l[x_{l-1}]\)</span>, if all of them equal to <span class="math inline">\(1\)</span>, then we consider <span class="math inline">\(x\)</span> is one of the elements of the set. Similarly as the basic Bloom Filter, such multi-dimension Bloom Filter may also yield a false positive. However, if one of them equals to <span class="math inline">\(0\)</span>, the element <span class="math inline">\(x\)</span> certainly not belong to this set. Figure 2 illustrates that how a MDBF works.</p><p><img src="/images/figure2.png"></p><p>​ <strong>Figure 2 Multi-dimension Bloom Filter illustration</strong></p><p>​ Nonetheless, the false positive rate of such MDBF is not as ideal as expected, because it may give a false positive even if none of the basic Bloom Filters makes a false decision. For example, we have a set <span class="math inline">\(S = \{(red, blue), (blue, black)\}\)</span> and we want to figure out whether <span class="math inline">\((red, black)\)</span> is in <span class="math inline">\(S\)</span>. So the first BBF would say that is an attribute of the set and the second BBF says <span class="math inline">\(black\)</span> is also an attribute of <span class="math inline">\(S\)</span>, so the MDBF thinks <span class="math inline">\((red, black)\)</span> is a member of <span class="math inline">\(S\)</span>, which is obviously a false positive. Therefore, we need another Bloom Filter or couple of Bloom Filters to represent the combined information of each dimensional attribute to reduce the error rate.</p><h2><span id="combined-multi-dimension-bloom-filter">Combined Multi-dimension Bloom Filter</span></h2><p>​ The ideal MDBF produces a false positive only when all of the basic Bloom Filters yield false positives, so the error rate of an ideal -dimension MDBF is: <span class="math display">\[f_{iMDBF} = (f_{BBF})^l = (1-e^{-\frac{kn}{m}})^{kl}\]</span> ​ To achieve such false positive rate, we need not only store the attribute of each dimension, but also have to store the relationship among all dimensions. One way to do this is adding a combined Bloom Filter to represent the combination of each attribute, which is called combined multi-dimension Bloom Filter (CMDBF). The question is how to represent such combined information. A simple solution is using the result of XOR different dimensional attributes’ hashing indexes as the hash index of the combined Bloom Filter, which is <span class="math inline">\(CBF[h_{1,i}[x_0]\oplus h_{2,i}[x_1] ... \oplus h_{l,i}[x_{l-1}]]=1\)</span> for <span class="math inline">\(i \in \{0, 1, ..,k-1\}\)</span>, where <span class="math inline">\(CBF\)</span> refers to the combined Bloom Filter, as illustrated in Figure 3.</p><p><img src="/images/figure3.png"></p><p>​ <strong>Figure 3 Combined Multi-dimension Bloom Filter illustration</strong></p><p>​ Obviously, the error rate of CMDBF is lower than MDBF since CMDBF has a combined Bloom Filter to represent the relationship among all the dimensions. CMDBF will make a false positive when some of the basic Bloom Filters make mistakes as well as the combined Bloom Filter yields a false decision.</p><p>​ Let’s mathematically compute the error rate of CMDBF, we represent a CMDBF by a 4-tuple <span class="math inline">\((n,m,k,l)\)</span>, where <span class="math inline">\(n\)</span> represents the number of elements in the set, <span class="math inline">\(m\)</span> represents the size of a basic Bloom Filter, <span class="math inline">\(k\)</span> represents the number of hash functions each basic Bloom Filter has, and <span class="math inline">\(l\)</span> represents the dimensions of the elements. Since <span class="math display">\[h_{1,i}[x_0], h_{2,i}[x_1] ... , h_{l,i}[x_{l-1}] \sim U(0, m-1)\]</span> where , therefore, <span class="math display">\[h_{1,i}[x_0]\oplus h_{2,i}[x_1] ... \oplus h_{l,i}[x_{l-1}]\sim U(0,m-1)\]</span> So, the false positive rate of CBF equals to that of BBF, <span class="math display">\[f_{CBF} = f_{BBF} =  (1-e^{-\frac{kn}{m}})^k\]</span> Then, the error rate of CMDBF is <span class="math display">\[f_{CMDBF} = f_{MDBF}f_{CBF} = f_{MDBF}(1-e^{-\frac{kn}{m}})^k\]</span> Since <span class="math inline">\(0&lt;(1-e^{-\frac{kn}{m}})^k&lt;1\)</span>, the false positive rate of CMDBF is lower than that of MDBF.</p><h2><span id="conclusion">Conclusion</span></h2><p>​ Even though the combined multi-dimension Bloom Filter consumes more space of a m-bit array, it can represent the multi-dimension elements as a whole entity rather than represents it as many independent attributes, which contributes to a lower false positive rate significantly.</p><h2><span id="references">References</span></h2><p>[1] DEKE G, HONGHUI C, JIE W, et al. Theory and network application of dynamic bloom filters[A]. Proc of IEEE Infocom Barcelona[C]. Spain, 2006. 1-12.</p><p>[2] XIE Kun, QIN Zheng, et al. Combine multi-dimension Bloom filter for membership queries. Journal on Communications.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Structure </tag>
            
            <tag> Bloom Filter </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>射频识别技术（RFID）</title>
      <link href="/2017/01/08/RFID/"/>
      <url>/2017/01/08/RFID/</url>
      
        <content type="html"><![CDATA[<p><strong>目录</strong></p><!-- toc --><ul><li><a href="#第一章-物联网识别技术">第一章 物联网识别技术</a><ul><li><a href="#物联网基本概念">物联网基本概念</a></li><li><a href="#物联网识别技术">物联网识别技术</a></li><li><a href="#传统自动识别技术">传统自动识别技术</a></li></ul></li><li><a href="#第二章-条形码基本概念">第二章 条形码基本概念</a><ul><li><a href="#条形码barcode基本知识">条形码(Barcode)基本知识</a></li><li><a href="#商品条码">商品条码</a><ul><li><a href="#ean-13码">EAN-13码</a></li><li><a href="#ean-8码">EAN-8码</a></li><li><a href="#upc-a">UPC-A</a></li><li><a href="#upc-e码">UPC-E码</a></li><li><a href="#库德巴条码">库德巴条码</a></li><li><a href="#128条码">128条码</a></li></ul></li><li><a href="#isbn码和issn码">ISBN码和ISSN码</a><ul><li><a href="#isbn">ISBN</a></li><li><a href="#issn">ISSN</a></li></ul></li><li><a href="#快速响应矩阵码">快速响应矩阵码</a></li></ul></li><li><a href="#第三章-条码识别技术及应用">第三章 条码识别技术及应用</a></li><li><a href="#第四章-射频识别技术">第四章 射频识别技术</a><ul><li><a href="#rfid系统组成及特点">RFID系统组成及特点</a></li><li><a href="#rfid技术的理论基础">RFID技术的理论基础</a><ul><li><a href="#数据传输原理">数据传输原理</a></li><li><a href="#能量传输原理">能量传输原理</a></li><li><a href="#数据传输编码">数据传输编码</a></li><li><a href="#数据校验方法">数据校验方法</a></li></ul></li><li><a href="#rfid系统工程">RFID系统工程</a><ul><li><a href="#rfid系统性能指标">RFID系统性能指标</a></li></ul></li><li><a href="#rfid技术的应用发展面临的问题">RFID技术的应用发展面临的问题</a></li></ul></li><li><a href="#第五章-电子标签">第五章 电子标签</a><ul><li><a href="#电子标签的组成及工作原理">电子标签的组成及工作原理</a><ul><li><a href="#mifare-1射频卡的结构">Mifare 1射频卡的结构</a></li><li><a href="#mifare-1射频卡的特点">Mifare 1射频卡的特点</a></li><li><a href="#mifare-1射频卡的存储结构">Mifare 1射频卡的存储结构</a></li></ul></li><li><a href="#电子标签种类">电子标签种类</a><ul><li><a href="#按能量来源分类">按能量来源分类</a></li><li><a href="#按工作频率分类">按工作频率分类</a></li><li><a href="#按标签读写方式分类">按标签读写方式分类</a></li><li><a href="#按标签用途分类">按标签用途分类</a></li><li><a href="#按标签功能分类">按标签功能分类</a></li></ul></li><li><a href="#双频rfid系统">双频RFID系统</a><ul><li><a href="#有源系统">有源系统</a></li><li><a href="#无源系统">无源系统</a></li><li><a href="#双频rfid系统的应用">双频RFID系统的应用</a></li></ul></li><li><a href="#电子标签协议">电子标签协议</a></li><li><a href="#电子标签的天线">电子标签的天线</a></li><li><a href="#电子标签信息的写入方式">电子标签信息的写入方式</a></li><li><a href="#电子标签性能因素">电子标签性能因素</a></li></ul></li><li><a href="#第六章-读写器">第六章 读写器</a><ul><li><a href="#读写器的工作原理">读写器的工作原理</a><ul><li><a href="#读写器工作流程">读写器工作流程</a></li></ul></li><li><a href="#读写器天线">读写器天线</a><ul><li><a href="#读写器的天线种类">读写器的天线种类</a></li></ul></li><li><a href="#读写器的发展趋势">读写器的发展趋势</a></li><li><a href="#作业">作业</a></li></ul></li><li><a href="#第七章-rfid技术标准体系">第七章 RFID技术标准体系</a><ul><li><a href="#rfid标准体系">RFID标准体系</a></li></ul></li><li><a href="#第八章-rfid系统关键技术">第八章 RFID系统关键技术</a><ul><li><a href="#rfid系统的安全技术">RFID系统的安全技术</a><ul><li><a href="#rfid系统的安全需求">RFID系统的安全需求</a></li><li><a href="#rfid安全技术">RFID安全技术</a></li></ul></li><li><a href="#多标签识别技术">多标签识别技术</a></li><li><a href="#多读写器防碰撞技术">多读写器防碰撞技术</a></li></ul></li><li><a href="#第九章-rfid应用系统的构建">第九章 RFID应用系统的构建</a><ul><li><a href="#电子标签选择">电子标签选择</a></li><li><a href="#读写器选择">读写器选择</a></li></ul></li><li><a href="#第十章-rfid技术应用">第十章 RFID技术应用</a><ul><li><a href="#基于rfid的典型物联网系统epc">基于RFID的典型物联网系统EPC</a></li></ul></li><li><a href="#电子钱包">电子钱包</a></li><li><a href="#rfid术语">RFID术语</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="第一章-物联网识别技术">第一章 物联网识别技术</span></h2><h3><span id="物联网基本概念">物联网基本概念</span></h3><ul><li>物联网就是“物物相连的互联网”，其目标是将所有物体联系起来形成一个庞大的<strong>物物相连</strong>的互联网络。<ul><li>第一，物联网的<strong>核心和基础仍然是互联网</strong>，是在互联网基础上的延伸和扩展的网络;</li><li>第二，其用户端延伸和扩展到了<strong>任何物体与物体之间</strong>，进行信息交换和通信。</li></ul></li><li>物联网的实施需要三个步骤<ul><li>物体标识</li><li>感知与获取</li><li>通信与计算</li></ul></li><li>层次-P3<ul><li>感知层</li><li>网络层</li><li>应用层</li></ul></li></ul><h3><span id="物联网识别技术">物联网识别技术</span></h3><p>物能够开口说话的条件</p><ol type="1"><li>要有相应的接收器</li><li>要有数据传输通路</li><li>要有一定的存储功能</li><li>要有中央处理器</li><li>要有操作系统</li><li>要有专门的应用程序</li><li>要有数据发送器</li><li>遵循物联网的各种协议</li><li>在世界网络中有可被识别的唯一编号</li></ol><h3><span id="传统自动识别技术">传统自动识别技术</span></h3><ul><li>磁条技术 以前银行卡</li><li>生物特征识别技术 指纹识别，虹膜识别</li><li>语音识别技术<br></li><li>图像识别技术 车牌识别、遥感技术、医用图像处理</li><li>光学字符识别技术 传真、扫描和复印</li><li>条码识别技术 超市商品</li><li>IC卡识别技术 手机卡、公交卡</li></ul><h2><span id="第二章-条形码基本概念">第二章 条形码基本概念</span></h2><h3><span id="条形码barcode基本知识">条形码(Barcode)基本知识</span></h3><p>条码技术包括：</p><ul><li>编码技术</li><li>符号技术</li><li>识读技术</li><li>印刷技术</li><li>检测技术</li></ul><p>条码的分类</p><ul><li>按条码的长度可分为：<ul><li>定长条码<ul><li>如EAN-13</li></ul></li><li>非定长条码<ul><li>如EAN-128</li></ul></li></ul></li><li>按排列方式可分为：<ul><li>连续型条码：每个条码字符之间不存在间隔</li><li>非连续型条码：每个条码字符之间存在间隔</li></ul></li><li>从校验方式可分为：<ul><li>自校验型条码</li><li>非自校验型条码</li></ul></li><li>按维数可分为：<ul><li>一维码</li><li>二维码</li><li>三维码</li></ul></li></ul><h3><span id="商品条码">商品条码</span></h3><ul><li>EAN-13</li><li>EAN-8</li><li>UPC-A</li><li>UPC-E</li></ul><h4><span id="ean-13码">EAN-13码</span></h4><p>European Article Number 欧洲物品编码</p><ul><li>共13位代码</li><li>比较通用</li><li>主要应用于超市和其他零售业</li></ul><p>编码</p><ul><li>前缀码</li><li>厂商识别代码</li><li>商品项目代码</li><li>校验码</li></ul><p>结构</p><ul><li>左侧空白区</li><li>起始符</li><li>左侧数据符</li><li>中间分隔符</li><li>右侧数据符</li><li>校验符</li><li>终止符</li><li>右侧空白区</li></ul><h4><span id="ean-8码">EAN-8码</span></h4><ul><li>共8位数，包括国别码2位，产品代码5位及检查码1位</li><li>左右资料编码规则同EAN-13</li><li>条码面积小</li></ul><h4><span id="upc-a">UPC-A</span></h4><p>UPC-A商品条码是用来表示UCC-12商品标识代码的条码符号，由美国统一代码委员会(UCC)制定的一种条码码制。</p><ul><li>结构基本与EAN-13相同，12位</li><li>UPC-A条码是EAN-13码的一种特殊形式，UPC-A条码与EAN-13码中N1=0兼容</li></ul><h4><span id="upc-e码">UPC-E码</span></h4><p>在特定条件下，12位的UPC-A条码可以被表示为一种<strong>缩短形式</strong>的条码符号即UPC-E条码</p><ul><li>不含中间分隔符和校验符</li></ul><h4><span id="库德巴条码">库德巴条码</span></h4><ul><li>库德巴条码是一种条、空均表示信息的非连续型、非定长、具有自校验功能的双向条码。它由条码字符及对应的供人识别字符组成。</li><li>它的字符集共包括16个字符: 即数字字符0<sub>9(10个数字)、英文字母A</sub>D(4个字母)和特殊字符“+”(加号) 、“-” (减号)、“$”(美元符号)、“:”(冒号)、“/”(斜杠)、“·”(圆点)。</li><li>库德巴条码由左侧空白区、起始符、数据符、终止符及右侧空白区构成</li></ul><h4><span id="128条码">128条码</span></h4><p>EAN-128码开始于1981年推出，是一种长度可变、连续性的字母数字条码，较为复杂，但其所能支持的字符比其他一维条码多，有不同的编码方式可供交互运用，因此其应用弹性较大。</p><ul><li>可应用於货运栈版标签、携带式资料库、连续性资料段、流通配送标签等</li><li>UCC/EAN-128条码是唯一能够表示应用标识的条码符号。UCC/EAN-128 可编码的信息包括项目标识、计量、数量、日期、交易参考信息、位置等</li></ul><h3><span id="isbn码和issn码">ISBN码和ISSN码</span></h3><ul><li>ISBN (International Standard Book Number)<ul><li><strong>国际标准书号</strong></li></ul></li><li>ISSN(International Standard Serial Number)<ul><li><strong>国际标准期刊号</strong></li></ul></li></ul><h4><span id="isbn">ISBN</span></h4><ul><li>2007.1.1前，ISBN由10位数字组成，分四个部分:组号(国家、地区、语言的代号)，出版社号，书序号和检验码。</li><li>2007.1.1起，实行新版ISBN，由13位数字组成，分为5段，即在原来的10位数字前加上3位EAN图书产品代码“978”</li><li>目的和作用<ul><li>有助于简化图书发行及管理手续，便于出版品统计及国际交流。</li><li>世界各地的出版机构、书商、及图书馆都可以利用国际标准书号迅速而有效的识别某一本书及其版本、装订形式。</li><li>不论原书是以何种文字书写，都可用电报或电话传真订购，并以电脑作业处理。</li></ul></li></ul><h4><span id="issn">ISSN</span></h4><ul><li>常见的期刊、杂志、丛刊、年刊等大都属于国际标准期刊号的编号与编码范围。每一种期刊在注册登记时，就得到一个永久专属的 ISSN ，<strong>一个 ISSN 只对应一个刊名;而一个刊名也只有一个ISSN</strong>。</li><li>当该刊名变更时，就得另申请一个 ISSN 。如果期刊停刊，那么被删除的 ISSN 也不会被其他期刊再使用。</li></ul><h3><span id="快速响应矩阵码">快速响应矩阵码</span></h3><p>QR Code - Quick Response</p><ul><li>超高速识读</li><li>可靠性高、成本低</li><li>数据容量大</li><li>全方位识读</li><li>能够有效地表示中国汉字、日本汉字、图像<em>???</em></li><li>保密防伪性强、使用方便</li></ul><h2><span id="第三章-条码识别技术及应用">第三章 条码识别技术及应用</span></h2><p>相关术语</p><ul><li>条码识读器(Barcode Reader)</li><li>扫描器(Scanner)</li><li>译码(Decode)</li><li>译码器(Decoder)</li><li>首读率(FirstReadRate)</li><li>误码率(Misread Rate)</li><li>拒识率(Non-read Rate)</li></ul><h2><span id="第四章-射频识别技术">第四章 射频识别技术</span></h2><h3><span id="rfid系统组成及特点">RFID系统组成及特点</span></h3><p>组成</p><ul><li>电子标签</li><li>读写器</li><li>数据管理系统</li></ul><p>与条码识别技术的根本差别</p><ul><li>条码技术是一种<strong>光学技术</strong></li><li>RFID是一种<strong>无线电技术</strong></li></ul><p>特点</p><ol type="1"><li>识别速度快、识别距离远</li><li>体积小型化，形状多样化，易封装</li><li>抗污染能力和耐久性</li><li>可重复使用</li><li>穿透性和无屏障阅读</li><li>数据的记忆容量大</li><li>安全性较高</li></ol><h3><span id="rfid技术的理论基础">RFID技术的理论基础</span></h3><p>RFID技术作为一种非接触式的自动识别技术，其数据通信基础就是读写器与电子标签之间的<strong>无线载波通信技术</strong>。</p><h4><span id="数据传输原理">数据传输原理</span></h4><p>在RFID系统中，读写器和电子标签之间的通信通过电磁波来实现。</p><ul><li>按照通信距离，可以划分为<strong>近场和远场</strong>。相应的，读写器和电子标签之间的数据交换方式被划分:<ol type="1"><li>负载调制<ol type="1"><li>负载调制就是利用负载的某些差异或负载的变动而使源的某种或某些参数发生相应改变的过程或效应</li></ol></li><li>反向散射调制<ol type="1"><li>雷达原理模型，发射出去的电磁波，碰到目标后反射，同时携带回目标信息，依据的是<strong>电磁波的空间传播规律</strong></li></ol></li></ol></li></ul><h4><span id="能量传输原理">能量传输原理</span></h4><ul><li>无源RFID系统的电子标签通过电磁场供电，电子标签的功耗越大，读写距离越近，性能越差</li></ul><h4><span id="数据传输编码">数据传输编码</span></h4><p>数据编码是将数据表示成适当的信号形式，以便数据的传输和处理。在数据传输系统中，有三种数据编码技术:</p><ul><li>数字数据的模拟信号编码<ul><li>幅移键控(ASK)法</li><li>频移键控(FSK)法 (Frequency Shift Keying)</li><li>相移键控(PSK)法 (Phase Shift Keying)</li></ul></li><li>数字数据的数字信号编码<ul><li>脉冲编码调制PCM(Pulse Code Modulation)技术</li></ul></li><li>模拟数据的数字信号编码<ul><li>为了高信号抗干扰能力，并且便于信号接收同步，通常采用更为有效的信号编码方法 (不归零码、差分不归零码、曼彻斯特码及差分曼彻斯特码等)</li></ul></li></ul><p><img src="/images/code.png"></p><p>优缺点</p><p>选择编码方式的考虑因素</p><ul><li>编码方式的选择要考虑电子标签能量的来源</li><li>编码方式的选择要考虑数据的校验和保护</li><li>编码方式的选择要考虑数据的检测错误能力</li></ul><h4><span id="数据校验方法">数据校验方法</span></h4><ul><li>奇偶校验（Parity Check）</li><li>纵向冗余校验（Longitudinal Redundancy Check, LRC）</li><li>循环冗余码校验（Cyclic Redundancy Check, CRC）</li></ul><h3><span id="rfid系统工程">RFID系统工程</span></h3><p>RFID系统借助空间传输通道工作的过程可归结为三种事件模型:能量、时序和数据。能量是时序得以实现的基础，时序是数据交换的实现方式，数据交换是目的。</p><h4><span id="rfid系统性能指标">RFID系统性能指标</span></h4><ol type="1"><li>数据传输速率<ol type="1"><li>只读速率</li><li>无限读写速率</li><li>有限读写速率</li></ol></li><li>读写距离</li><li>电子标签与天线间的射频载波频率</li><li>多标签读写特性</li><li>电子标签存储容量</li><li>工作方式<ol type="1"><li>全双工(Full Duplex，FDX)</li><li>半双工(Half Duplex，HDX)</li><li>时序(Sequence，SEQ)</li></ol></li><li>RFID系统的接口形式<ul><li>RS232, RS482, RJ45, 韦根, 无线网络</li></ul></li><li>数据载体<ol type="1"><li>EEPROM:电可擦可编程只读存储器（主要使用）</li><li>FRAM: Ferroelectric Random Access Memory铁电随机存取存储器</li><li>SRAM: 静态随机存取存储器</li></ol></li><li>状态模式</li><li>能量供应方式</li></ol><h3><span id="rfid技术的应用发展面临的问题">RFID技术的应用发展面临的问题</span></h3><ol type="1"><li>标准制定问题</li><li>标签成本问题</li><li>关键技术问题<ul><li>如多标签识别问题、防碰撞技术问题、高速运动中的对象识别问题等等</li></ul></li><li>安全与隐私问题</li></ol><h2><span id="第五章-电子标签">第五章 电子标签</span></h2><h3><span id="电子标签的组成及工作原理">电子标签的组成及工作原理</span></h3><p><strong>电子标签=天线(或线圈)+标签芯片</strong></p><ul><li>标签芯片相当于一个单片系统(SoC):收发功能+存贮功能</li></ul><p>从纯技术的角度来说，射频识别技术的核心在电子标签，阅读器是根据电子标签的设计而设计的。</p><p>标签芯片一般<strong>由编码/解码器、电源、解调器、存储器、控制器和负载调制</strong>组成。</p><h4><span id="mifare-1射频卡的结构">Mifare 1射频卡的结构</span></h4><p> Mifare 1 IC射频卡采用先进的芯片工艺制作，内建有高速的CMOS、EEPROM和MCU等，卡片的电气部分:</p><ul><li>天线:卡片的天线是只有几组绕线的线圈。</li><li>ASIC:卡片的ASIC由一个高速(106KB波特率)的RF接口，一个控制单元和一个8K位EEPROM组成。</li></ul><h4><span id="mifare-1射频卡的特点">Mifare 1射频卡的特点</span></h4><ul><li><p>M1卡所具有的独特的Mifare射频接口标准已被制定为国际标准ISO/IEC 14443 TYPE A 标准。</p></li><li><p>M1卡上具有先进的数据通信加密和双向验证密码系统，而且具有防冲突功能，能在同一时间处理读写器天线的有效工作距离内冲突的多张卡片。</p></li><li><p>M1卡与读写器通信使用握手式半双工通信协议，卡片上有高速的CRC协处理器，符合CCITT标准。</p></li><li><p>卡片制造时具有唯一的卡片系列号，没有重复的相同的两张Mifare卡片。</p></li><li><p>卡片上内建8 K 位 EEPROM 存储容量，并划分为16个扇区，每个扇区划分为4个数据存储块，每个扇区可由多种方式的密码管理。</p></li><li><p>卡片上还内建有增值/减值的专项的数学运算电路，非常适合公交、地铁等行业的检票、收费系统等典型的快捷交易，时间最长不超过100 ms。</p></li></ul><h4><span id="mifare-1射频卡的存储结构">Mifare 1射频卡的存储结构</span></h4><p>M1卡的存储容量为8192位×1位字长，即1K×8位字长。采用EEPROM作为存储介质。</p><p>整个结构划分为16个扇区，编号为0~15;</p><ul><li>每个扇区由4块(Block)，分别为块0、块1、块2、块3，每块有16个字节，一个扇区共有64个字节</li><li>实际中，也可将16个扇区的64个块按绝对地址编号为0~63。</li><li>第0扇区的块0(即绝对地址0块)，它用于存放厂商代码，已经固化，不可更改。其中字节0~3为卡的序列号;字节4为序列号的校验码;字节5为卡片大小的数值;字节6和字节7为卡的类型号，即Tag type字节;其他字节由厂商另加定义。</li></ul><h3><span id="电子标签种类">电子标签种类</span></h3><h4><span id="按能量来源分类">按能量来源分类</span></h4><ul><li>获取电能方式<ul><li>无源标签（主流）</li><li>半有源标签</li><li>有源标签</li></ul></li><li>使用电能方式<ul><li>被动式标签<ul><li>必须利用读写器的载波来调制自身的信号，标签产生电能的装置是天线和线圈</li></ul></li><li>半被动式标签<ul><li>电子标签本身带有电池，但是标签并不通过自身能量主动发送数据给读写器，电池只负责对标签内部电路供电</li></ul></li><li>主动式标签<ul><li>有源系统，用自身能量主动地发送数据给读写器</li></ul></li></ul></li></ul><h4><span id="按工作频率分类">按工作频率分类</span></h4><ul><li>低频电子标签（30～300kHz）<ul><li>低频标签一般为无源式电子标签，其工作能量通过电感耦合方式从读写器耦合线圈的辐射近场中获得</li><li>优势<ul><li>标签芯片一般采用普通的CMOS工艺，具有省电、廉价的特点;</li><li>工作频率不受无线电频率管制约束;</li><li>可以穿透水、有机组织、木材等，粘附在装有水、动物组织、金属、木材和液体的容器上</li><li>非常适合近距离、低速度、数据量要求较少的识别应用等</li></ul></li><li>劣势<ul><li>数据传输速率最低，标签存贮数据量也较少，只能适合低速、近距离识别应用</li><li>低频电子标签灵活性差，不易被识别;</li><li>与超高频标签相比:标签天线匝数更多，成本更高一些;</li><li>低频标签没有防碰撞能力，读取电子标签数据时只能一对一进行读取，不可能同时读取多个标签</li></ul></li><li>主要应用<ul><li>牧业的管理系统</li><li>汽车防盗和无钥匙开门系统的应用</li><li>马拉松赛跑系统的应用</li><li>动停车场收费和车辆管理系统</li><li>动加油系统的应用</li><li>酒店门锁系统的应用</li><li>门禁和安全管理系统</li></ul></li></ul></li><li>中高频电子标签（3～30MHz，典型13.56MHz）<ul><li>无源，与低频原理一样</li></ul></li><li>超高频标签（300～1000MHz）<ul><li>433MHz频率用于主动式标签，而860~960MHz频段大部分用于被动式标签和一些半被动式标签</li><li>860~960MHz这一频段常常可认为是一个单独的频率900MHz或者915MHz。工作在这一频段的标签和读写器称为超高频标签和超高频读写器</li></ul></li><li>微波标签<ul><li>微波频段从1~10GHz，但RFID应用公使用其中的两个频段:2.45GHz和5.8GHz</li></ul></li></ul><h4><span id="按标签读写方式分类">按标签读写方式分类</span></h4><ul><li>只读标签<ul><li>内部只有只读存储器(Read Only Memory, ROM)</li></ul></li><li>可读可写标签<ul><li>随机存取器(Random Access Memory, RAM)</li></ul></li><li>一次写入多次读出标签<ul><li>一次写入多次读出(Write Once Read Many, WORM)</li></ul></li></ul><h4><span id="按标签用途分类">按标签用途分类</span></h4><p>很多，如温度、振动、双频防盗等</p><h4><span id="按标签功能分类">按标签功能分类</span></h4><ul><li>1位电子标签🏷️<ul><li>只能表示两个状态1和0</li><li>它是最早的商用电子标签，主要应用在20世纪60年代的商品电子监视器(EAS)中。它<strong>不需要芯片</strong>，可以采用<strong>射频法</strong>、微波法、分频法、电磁法和声磁法等方法进行工作。</li></ul></li><li>声表面波标签<ul><li>声表面波(Surface Acoustic Wave, SAW)</li></ul></li><li>无芯片标签<ul><li>不含有IC芯片的电子标签，如前两个</li></ul></li><li>芯片标签<ul><li>天线、射频电路和控制电路组成，具有存储功能</li></ul></li><li>微处理器标签<ul><li>拥有独立的CPU和操作系统</li><li>集成各类传感器检测功能，无线通信功能</li></ul></li></ul><h3><span id="双频rfid系统">双频RFID系统</span></h3><h4><span id="有源系统">有源系统</span></h4><p>双频电子标签由<strong>嵌入式处理器</strong>和<strong>软件、卡内发射和接收天线</strong>、<strong>收发电路以及高能电池</strong>组成。</p><p>双频电子标签工作在两个频点上，平时处于<strong>睡眠状态</strong>，当进入系统工作区后，被发射天线(路标)发出的低频无线电信号激活，发射出惟一的加密识别码无线电信号。</p><p>可以解决传统有源电子标签<strong>耗电大和控制距离</strong>两大难题 。</p><h4><span id="无源系统">无源系统</span></h4><ul><li>与有源双频系统相比，无源双频系统具有体积小、系统紧凑和成本低廉等特点。</li><li>采用双频技术的RFID系统同时具有低频和高频系统各自的优点，即具有较强的穿透能力、较远的识别距离和高速的识别能力。</li></ul><h4><span id="双频rfid系统的应用">双频RFID系统的应用</span></h4><p>双频(Dual Frequency，DF)</p><ol type="1"><li><p>供应链管理包括木质托盘、集装箱、水果箱、纸卷跟</p><p>踪等方面</p></li><li><p>人员自由流跟踪与个性化身份认证</p></li><li><p>动物跟踪与识别包括羊群、牛群、猪、马以及野生动物的跟踪与识别</p></li><li><p>采矿作业与地下路网管理</p></li><li><p>运动计时</p></li></ol><h3><span id="电子标签协议">电子标签协议</span></h3><ul><li>ISO/IEC 14443(A/B)</li><li>ISO/IEC 15693</li><li>ISO/IEC 18000-6(A/B)</li><li>EPCglobal Generation2(Gen2)</li></ul><h3><span id="电子标签的天线">电子标签的天线</span></h3><p>天线是发射和接收电磁波的一个重要的无线电设备，主要是将接收到的电磁波转换成电流信号，或者将电流信号转换成电磁波。</p><h3><span id="电子标签信息的写入方式">电子标签信息的写入方式</span></h3><p>电子标签作为标识对象的核心部件，其内部信息要在使用前或使用过程中通过一定的方式写入到标签存储芯片中。其信息的写入方式大致可以分为以下三种类型:</p><ul><li>  (1)电子标签在出厂时，即已将完整的标签信息写入标签。这种情况下，应用过程中，电子标签一般具有只读功能。</li><li>  (2)电子标签信息的写入采用有线接触方式实现，一般称这种标签信息写入装置为编程器。这种接触式的电子标签信息写入方式通常具有多次改写的能力。</li><li>  (3)电子标签在出厂后，允许用户通过专用设备以无接触的方式向电子标签中写入数据信息。这种专用写入功能通常与电子标签读取功能结合在一起形成电子标签读写器。</li></ul><h3><span id="电子标签性能因素">电子标签性能因素</span></h3><ol type="1"><li>能量来源</li><li>电子标签的方向和位置</li><li>电子标签的放置</li><li>标签堆垛(Tag Stacking)</li><li>标签的极化方向</li><li>标签的移动速度</li><li>环境因素</li><li>读取和写入</li></ol><h2><span id="第六章-读写器">第六章 读写器</span></h2><h3><span id="读写器的工作原理">读写器的工作原理</span></h3><p>硬件</p><ul><li>所有的读写器硬件均可简化为<strong>天线</strong>、<strong>高频接口</strong>、<strong>控制单元</strong>和<strong>外围接口</strong>四个基本模块。<ul><li>外围接口：RS232, RS485, RJ45, 无线网络接口</li></ul></li></ul><p>软件</p><ul><li>控制软件</li><li>导入软件</li><li>解码器</li></ul><h4><span id="读写器工作流程">读写器工作流程</span></h4><p>RFID系统数据采集一般有两种工作模式:</p><ul><li>一是以读写器为主的工作模式，多用于无源标签</li><li>二是以标签为主的工作模式，必须是有源标签</li></ul><h3><span id="读写器天线">读写器天线</span></h3><p>天线的主要参数包括:工作频率、频带宽度、方向性增益、极化方式、波瓣宽度。</p><ol type="1"><li><p>天线的工作频率和频带宽度</p><p>天线的工作频率和频带宽度应当符合RFID系统的频率范围要求，如天线可以工作在860-960MHz频率范围之间。</p></li><li><p>天线的增益</p><p>天线的增益是指在输入功率相等的条件下，实际天线与理想的辐射单元在空间同一点处所产生的信号的功率密度之比，它定量地描述了天线集中辐射输入功率的程度。</p></li><li><p>天线的极化方向</p><p>天线向周围空间辐射电磁波，电磁波由电场和磁场构成。电场的方向就是天线极化方向，天线的极化方式分为<strong>线极化(水平极化和垂直极化)和圆极化(左旋极化和右旋极化)</strong>两种。</p></li><li><p>天线的波瓣宽度</p></li></ol><h4><span id="读写器的天线种类">读写器的天线种类</span></h4><ol type="1"><li>线圈天线</li><li>微带贴片天线</li><li>偶极子天线</li><li>隧道天线</li><li>天线阵列</li></ol><h3><span id="读写器的发展趋势">读写器的发展趋势</span></h3><ol type="1"><li>多功能</li><li>智能多天线端口</li><li>多种数据接口</li><li>多制式兼容</li><li>小型化</li><li>多频段兼容</li><li>低成本</li><li>新技术</li></ol><h3><span id="作业">作业</span></h3><p>6-3 在一RFID应用系统中，读写器主要实现哪些功能？</p><ol type="1"><li>与电子标签的通信功能</li><li>与计算机之间的通信功能</li><li>多标签同时读取，防碰撞</li><li>校验读写过程中的错误信息</li><li>对于有源电子标签，能够读其电量🔋</li></ol><p>6-7 如何衡量读写器天线的性能好坏？</p><p>根据工作频率、频带宽度、方向性增益、极化方式和波瓣宽度来衡量。</p><p>6-8 对于分体式读写器，在读写器和天线之间的连接时应该注意哪些问题？</p><p>避免使用非屏蔽电缆，否则会产生不良效应。</p><h2><span id="第七章-rfid技术标准体系">第七章 RFID技术标准体系</span></h2><p>国际非电离辐射保护委员会(International Commission on Non-ionizing Radiation Protection，ICNIRP)</p><p>RFID标准体系结构</p><ul><li>RFID技术标准</li><li>RFID应用标准</li><li>RFID数据内容标准</li><li>RFID性能标准</li></ul><h3><span id="rfid标准体系">RFID标准体系</span></h3><p><strong>ISO/IEC 10536</strong></p><ul><li>密耦合集成电路卡(Contactless Integrated Circuit Card，CICC)</li></ul><p><strong>ISO/IEC 14443</strong></p><ul><li>近耦合集成电路卡 (Proximity Integrated Circuit Card，PICC )</li><li>Type A卡<ul><li>Mifare Light、MIFARE1、Mifare2 (即:Mifare Pro)等。在亚洲等地区，Type A技术和产品占据了很大的市场份额</li><li>NFC逐渐成为智能手机标配功能。国内NFC应用最为广泛的将是Type A，如Mifare、NFC Tag、移动支付等</li></ul></li><li>Type B卡<ul><li>二代居民身份证</li><li>TYPE B与TYPE A相比，由于调制深度和编码方式的不同，具有传输能量不中断、速率更高、抗干扰能力更强的优点</li></ul></li><li>物理特性</li><li>空中接口和初始化</li><li>防冲突和传输协议</li><li>扩展命令集和安全特性</li><li>超短距离智慧卡标准</li></ul><p><strong>ISO/IEC 15693</strong></p><ul><li>疏耦合集成电路卡(Vicinity Integrated Circuit Card，VICC)</li><li>ISO/IEC 15693采用的载波频率仍为13.56MHz，主要包括物理特性、空中接口和初始化、防冲突和传输协议、扩展命令集和安全特性四个部分</li><li>短距离智慧卡标准</li></ul><p><strong>ISO/IEC 18000</strong></p><ul><li>单品管理</li><li>供应链和物流</li></ul><p>全球贸易项目代码(Global Trade Item Number)</p><p><strong>EPC 电子标签的存储结构</strong></p><p>符合EPC Class1 Gen2(简称C1G2)协议V109版的EPC电子标签的存储结构是相同的。只是不同厂家的Tag存储器容量大小不同 EPC 标签分为四个独立的存储区块(Bank)。</p><p><img src="/images/EPC.png"></p><p>标签芯片内部带有一定容量的非易失性存储器，按照EPCGlobal C1G2协议，四个独立的存储区块(Bank):</p><ul><li>Reserved区(Bank00)：存储Kill Password(灭活口令)和AccessPassword(访问口令)。(4 words)</li><li>EPC区(Bank01)：存储EPC编码，EPCGlobal根据不同的应用领域制定了不同规则的国际通用编码，长度在96位以上。(16bytes)</li><li>TID区(Bank10)：存储标签识别号码，每个TID号码都在标签出厂时设定，是世界唯一的。(12words、24bytes)</li><li>User区(Bank11)：存储用户自定义的数据。(32words)</li></ul><p>• 此外还有各区块的Lock(锁定)状态位等用到的也是存储性质的单元</p><p><strong>TID(Tag identifier)数据信息涵义</strong></p><p><img src="/images/TID.png"></p><ul><li>TID的数据格式统一为E2xxxxxxx(此处x并不与实际数据存在一一对应的关系)</li><li>003(十六进制)表示芯片商代号，各支持Gen2协议的芯片商向EPCglobal申请获得唯一的代号，常见厂商码见下表</li><li>412(十六进制)表示标签型号(具体代表某大类物品)</li><li>之后为标签序列号<ul><li>不同标签的TID均不相同，利用TID可以保证每一标签的唯一性并标识出该标签的制造商、制造批次等信息</li></ul></li></ul><h2><span id="第八章-rfid系统关键技术">第八章 RFID系统关键技术</span></h2><h3><span id="rfid系统的安全技术">RFID系统的安全技术</span></h3><p>针对RFID系统的安全攻击手段和方式主要分为以下两种:</p><ol type="1"><li>对RFID系统进行破坏、扰乱的攻击<ul><li>通过干扰、阻塞无线信道或其它手段，产生异常环境，使RFID发生故障，或进行拒绝服务的攻击等</li><li>通过对标签的屏蔽和失调来使得标签无效，例如在天线周围覆盖一层金属箔，使得天线无法工作</li><li>还有的是进行永久性的破坏，例如对标签的微芯片进行机械的拆除，或者是将标签放在微波炉等的强磁场环境下，这些都会对标签进行永久性的破坏，当然标签内的数据也会永远的丢失</li><li>在标签附近放一个阻塞标签，不断地发射干扰信号，使RFID系统不能正常通信，此时服务就会终止，妨碍读写器对合法标签的读写</li><li>对于这一类的攻击，目前还没有有效的对策来解决</li></ul></li><li>对通信数据的采集、复制和修改<ul><li>对于这一类攻击，加密程序就是很好的解决方法，例如对于读写器和标签之间的相互认证，读写器和标签之间的数据传输的加密，以及周期性的密钥更新</li><li>存在的问题就是运用了加密协议后会大大增加能量的消耗，因此被动电子标签技术目前还没有运用加密协议</li></ul></li></ol><h4><span id="rfid系统的安全需求">RFID系统的安全需求</span></h4><ol type="1"><li>机密性</li><li>完整性</li><li>可用性</li><li>真实性</li><li>隐私性</li></ol><h4><span id="rfid安全技术">RFID安全技术</span></h4><ol type="1"><li>物理安全机制<ul><li>Kill命令</li><li>法拉第笼</li><li>主动干扰法</li><li>阻塞标签</li><li>只读标签</li><li>动态频率法</li><li>天线能量分析法</li><li>指令识别法</li></ul></li><li>逻辑安全机制<ul><li>访问控制</li><li>认证</li><li>加密算法</li></ul></li></ol><h3><span id="多标签识别技术">多标签识别技术</span></h3><p>无线电通信系统中，多路存取方法的解决方式一般具有以下几种方式:</p><ul><li>空分多路法(Space Division Multiple Access，SDMA)</li><li>频分多路法(Frequency Division Multiple Access，FDMA)</li><li>码分多路法(Code Division Multiple Access，CDMA)</li><li>时分多路法(Time Division Multiple Access，TDMA)</li></ul><p><strong>多标签碰撞</strong></p><p>在<strong>信道共用</strong>、<strong>信号频率</strong>相同的情况下，多个电子标签<strong>同时</strong>向读写器发送信号，这些信号就会相互干扰而产生信道争夺的情况，产生数据碰撞。</p><ol type="1"><li>空分多路SDMA</li><li>频分多路FDMA<ul><li>频分多路法是把若干个使用不同载波频率的传输通路同时供给通信用户使用的技术</li></ul></li><li>码分多路CDMA<ul><li>码分多路法是一种共享信道的方法，每个用户可在同一时间使用同样的频带进行通信。但使用的是基于码型的分割信道的方法，即每个用户分配一个地址码，各个码型互不重叠，通信各方之间不会相互干扰，且抗干拢能力强</li></ul></li><li>时分多路TDMA<ul><li>时分复用(Time division Multiplexing-TDM)是利用各信号的抽样值在时间上不相互重叠来达到在同一信道中传输多路信号的一种方法。</li></ul></li></ol><p>综合分析来看</p><ul><li>SDMA 法由于其复杂的天线系统产生的高费用，使得其应用不是很广泛</li><li>FDMA法因其读写器的费用比较高，电子标签的差异也要求较高，应用也受到了限制</li><li>CDMA法的频带利用率低、信道容量较小、地址码选择较难、接收时地址码捕获时间较长，其通信频带及技术复杂性等使得它很难在RFID系统中推广应用</li></ul><p>因此，在RFID系统中，<strong>TDMA应用比较广泛</strong>。</p><h3><span id="多读写器防碰撞技术">多读写器防碰撞技术</span></h3><p>随着RFID系统的大规模应用，越来越多的应用场合(如物流供应链管理，位置跟踪等)需要RFID读写器网络来监视整个覆盖的区域，可能会出现在一定范围内多个读写器阅读同一个标签的情况。</p><p>阅读器的信号区有可能出现相互重叠，则读写器之间会互相干扰，其中任一个阅读器与标签的通信，可能会严重干扰其他阅读器对该标签的正常读取，这种多阅读器间的读写冲突问题称为<strong>阅读器防碰撞问题</strong>。</p><p>读写器的碰撞问题分为两类:</p><ul><li>读写器与读写器之间的干扰问题<ul><li>当一个读写器发送一个信号而与另一个读写器的工作相干扰时，读写器之间的频率干扰就产生了</li><li>当一个读写器发送的信号有足够的强度，并且被第二个读写器收到时，就掩盖了或阻塞了它与标签的通信</li></ul></li><li>多读写器到标签之间的干扰问题<ul><li>当一个标签处在多个读写器的查询区域中，由于各读写器的相互干扰，有可能使得没有一个读写器可以读到该区域的标签</li></ul></li></ul><h2><span id="第九章-rfid应用系统的构建">第九章 RFID应用系统的构建</span></h2><p><strong>实施RFID应用系统的流程</strong></p><ul><li>阶段0 - 启动</li><li>阶段1<ul><li>现场调研</li><li>业务分析、总体方案规划</li><li>实践检验</li></ul></li><li>阶段2 项目试点</li><li>阶段3 正式项目</li></ul><h3><span id="电子标签选择">电子标签选择</span></h3><p>在进行标签选择时，需要考虑的标签技术参数有: 能量要求、容量要求、工作频率、数据传输速率、读/写速度、读/写方式、识读距离、标签外形、数据安全性要求等。</p><ol type="1"><li>标签的类型</li><li>标签的形状和尺寸</li><li>关于标签的加工</li><li>如何在国外适用</li></ol><h3><span id="读写器选择">读写器选择</span></h3><p>读写器的技术参数包括: 工作频率、输出功率、数据传输速率、I/O端口形式、读写器是否可调等</p><ol type="1"><li>适用形态<ul><li>固定读写器</li><li>手持式读写器</li></ul></li><li>输入／输出的类型</li><li>天线的选择</li><li>读取的性能</li></ol><h2><span id="第十章-rfid技术应用">第十章 RFID技术应用</span></h2><h3><span id="基于rfid的典型物联网系统epc">基于RFID的典型物联网系统EPC</span></h3><p>EPC系统是在计算机互联网的基础上，利用RFID、无线数据通信等技术，通过全球统一标识系统编码技术给每一个实体对象一个唯一代码，构造了一个实现全球物品信息实时共享的物联网。</p><p><img src="/images/EPC1.png"></p><p><img src="/images/EPC2.png"></p><h2><span id="电子钱包">电子钱包</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2B 00 00 00 D4 FF FF FF 2B 00 00 00 09 F6 09 F6</span><br><span class="line">充值金额      充值金额取反  余额        块号      块号取反</span><br></pre></td></tr></table></figure><p>前四个字节为实际充值数据，如这里的 2B 00 00 00，接下来四个字节为它的取反，即 D4 FF FF FF，接下来四个字节是卡内实际金额，即 2B 00 00 00，后面的四个字节分为两个字节一组，这两组完全一样，为 09 F6 09 F6，其中09是绝对块号，即扇区号*4+块号，所以实际是第二扇区第一块，最后 F6 = FF - 09。</p><h2><span id="rfid术语">RFID术语</span></h2><ul><li>ISBN (International Standard Book Number) - 国际标准书号</li><li>ISSN (International Standard Serial Number) - 国际标准期刊号</li><li>FSK (Frequency Shift Keying) - 频移键控法</li><li>PSK (Phase Shift Keying) - 相移键控法</li><li>PCM (Pulse Code Modulation) - 脉冲编码调制技术</li><li>PC (Parity Check) - 奇偶校验</li><li>LRC (Longitudinal Redundancy Check) - 纵向冗余校验</li><li>CRC (Cyclic Redundancy Check) - 循环冗余码校验</li><li>FDX (Full Duplex) - 全双工</li><li>HDX (Half Duplex) - 半双工</li><li>SEQ (Sequence) - 时序</li><li>FRAM (Ferroelectric Random Access Memory) - 铁电随机存取存储器</li><li>ROM (Read Only Memory) - 只读存储器</li><li>RAM (Random Access Memory) - 随机存取器</li><li>WORM (Write Once Read Many) - 一次写入多次读出</li><li>DF (Dual Frequency) - 双频</li><li>TS (Tag Stacking) - 标签堆垛</li><li>ICNIRP (International Commission on Non-ionizing Radiation Protection) - 国际非电离辐射保护委员会</li><li>SAW (Surface Acoustic Wave) - 声表面波</li><li>CICC (Contactless Integrated Circuit Card) - 耦合集成电路卡</li><li>PICC (Proximity Integrated Circuit Card) - 近耦合集成电路卡</li><li>VICC (Vicinity Integrated Circuit Card) - 疏耦合集成电路卡</li><li>SDMA (Space Division Multiple Access) - 空分多路法</li><li>FDMA (Frequency Division Multiple Access) - 频分多路法</li><li>CDMA (Code Division Multiple Access) - 码分多路法</li><li>TDMA (Time Division Multiple Access) - 时分多路法</li><li>TDM (Time division Multiplexing) - 时分复用</li><li>MOM (Message-Oriented Middleware) - 面向消息的中间件</li><li>EMS (Event Management System) - 事件管理系统</li><li>RIED (Real-time In-Memory Event Database) - 实时内存事件数据库</li><li>TMS (Task Management System) - 任务管理系统</li><li>ERP (Enterprise Resource Planning) - 企业资源规划</li><li>MES (Management Execution System) - 管理执行系统</li><li>SOAP (Simple Object Access Protocol) - 简单对象访问协议</li><li>RFU (Reserved for Future ISO/IEC Use) - 保留供将来使用</li><li>SOF (Start Of Frame, Type B) - 帧的开始，类型 B</li><li>EOF (end of frame) - 帧结束</li><li>AFI (application family identifier) - 应用族识别符，应用的卡预选准则</li><li>VCD (vicinity coupling device) - 附近式耦合设备</li><li>ONS (Object Name Server) - 对象名称解析服务</li><li>PML (Physical Markup Language) - 物理标识语言</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 本科课程 </tag>
            
            <tag> 物联网 </tag>
            
            <tag> RFID </tag>
            
            <tag> QR-Code </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>嵌入式操作系统</title>
      <link href="/2017/01/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
      <url>/2017/01/06/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p><strong>目录</strong></p><!-- toc --><ul><li><a href="#第一章">第一章</a></li><li><a href="#第二章">第二章</a></li><li><a href="#第三章">第三章</a></li><li><a href="#第四章">第四章</a></li><li><a href="#第五章">第五章</a></li><li><a href="#第六章">第六章</a></li><li><a href="#第七章">第七章</a></li><li><a href="#第八章">第八章</a></li><li><a href="#tinyos">TinyOS</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="第一章">第一章</span></h2><ul><li>多道<ul><li>多道程序设计技术是在计算机主存中同时存放几道相互独立的程序，使它们在管理程序控制之下，相互穿插地运行。<strong>当一个程序无法使用处理器资源的时候（做I/O的时候），系统可以调用另一个程序在处理器上运行。</strong></li><li>特征：多道、宏观上并行、微观上串行</li></ul></li><li>分时<ul><li>分时技术是将处理器的时间<strong>分成很短的时间片</strong>，将这些时间片<strong>轮流分配给在内存中的用户程序使用</strong>。</li><li>分时系统具有的特点<ol type="1"><li>独立性（各用户感觉独占资源）</li><li>及时性</li><li>交互性</li></ol></li></ul></li><li>并发<ul><li>在系统里有多个同时进行的活动</li></ul></li><li>共享<ul><li>进程之间共享系统资源</li></ul></li><li>不确定性<ul><li>系统中含有大量不确定的事件</li></ul></li></ul><h2><span id="第二章">第二章</span></h2><ul><li>硬件支持：<ol type="1"><li>处理机的状态：目态、管态<ol type="1"><li>管态指CPU上运行管理程序所处的状态，目态是指CPU上运行用户程序所处的态；</li><li>二者的区别：特权级不同，CPU在管态下可以使用全部机器指令，包括一组特权指令，可以使用所有的资源，访问整个存储区。CPU在用户态下只能使用用户态非特权指令，访问规定的存储区，使用一部分资源。</li><li>从用户态到管态切换的唯一途径是中断</li></ol></li><li>特权指令<ol type="1"><li>改变机器状态的指令</li><li>修改特殊寄存器的指令</li><li>涉及外部设备的输入/输出指令</li></ol></li></ol></li><li>中断<ul><li>中断实质是一个受保护的控制转移(protected control transfer)</li><li>中断分类：I/O、外中断、机器故障中断、程序性中断、访管中断</li><li>操作系统具备处理同时性活动的能力，重要的硬件支持是：中断系统</li></ul></li></ul><h2><span id="第三章">第三章</span></h2><ul><li>系统功能调用<ul><li>命令行</li><li>图形用户界面</li></ul></li><li>程序接口</li></ul><h2><span id="第四章">第四章</span></h2><ul><li><p>并发：若干个程序段同时在系统中运行，若这些程序的执行在时间上存在重叠，则称为程序并发执行。</p><ul><li>特点：失去了封闭性；程序与计算不再一一对应</li></ul></li><li><p>进程</p><ul><li>进程是一个程序在给定的初始环境和活动空间下，在处理机上的一次执行过程</li><li>组成<ul><li>进程控制块</li><li>进程的执行程序</li><li>进程总是处于某个队列</li><li>处于某种状态</li><li>占用系统某些资源</li></ul></li></ul></li><li><p>线程</p><ul><li>轻量级进程</li></ul></li><li>状态变迁<ul><li>无 等待-》运行 ❌</li><li>无 就绪-》等待 ❌</li><li><img src="/images/OS/process_state_trans.png"></li><li>如果系统中有N个进程，运行的进程最多几个，最少几个；就绪、等待呢？<ul><li>运行的进程最多一个，最少0个</li><li>就绪最多N - 1个，最少0个</li><li>等待最多N个，最少0个</li></ul></li><li>一个状态的发生，是否一定导致另一个状态的发生？列出所有可能<ul><li>运行 -&gt; 就绪 一定有 就绪 -&gt; 运行</li><li>就绪 -&gt; 运行 不一定有 运行 -&gt; 就绪</li></ul></li></ul></li><li><p>合作关系</p><ul><li><p>进程的相互制约关系产生原因：资源共享、进程合作</p></li><li><p>互斥</p><ul><li>当某一进程正在访问某临界资源时，就不允许其他进程进入，否则就会产生无法估计的错误。</li><li>源于对独占设备的竞争</li></ul></li><li><p>同步</p><ul><li><p>源于进程的合作</p></li><li><p>共享缓冲区的合作进程同步</p><ul><li><p>生产者-消费者问题</p><ul><li><p>Full：缓冲区产品数目，初值为0</p></li><li><p>Empty：缓冲区可存放产品的空位，初值为n</p></li><li><p>Mutex:缓冲区互斥信号灯，初值为1</p></li><li><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">producer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(生产未完成) &#123;</span><br><span class="line">    生产一个产品;</span><br><span class="line">    p(empty);</span><br><span class="line">    p(mutex);</span><br><span class="line">    将产品放入缓冲区;</span><br><span class="line">    v(mutex);</span><br><span class="line">    v(full);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">consumer</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (还要继续消费) &#123;</span><br><span class="line">    p(full);</span><br><span class="line">    p(mutex);</span><br><span class="line">    从缓冲区取出一个产品;</span><br><span class="line">    v(mutex);</span><br><span class="line">    v(empty);</span><br><span class="line">    消费产品;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>读者写者问题？</p></li><li><p>誊抄问题</p></li></ul></li></ul></li><li><p>在地球上，竞争和合作是永恒的！</p></li><li><p>临界资源</p><ul><li>一次仅允许一个进程访问的资源</li></ul></li><li><p>临界区</p><ul><li>每个进程中访问临界资源的<strong>程序段</strong>称为临界区</li></ul></li><li><p>原子、原语：不可分割、不可中断的程序</p></li><li><p>信号灯P、V操作</p><ul><li><p>P</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  s--;</span><br><span class="line">  <span class="keyword">if</span> (s &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    挂起该进程;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>V</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  s++;</span><br><span class="line">  <span class="keyword">if</span> (s &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    唤醒等待S的进程;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>信号灯（s, q）</p><ul><li>s代表可用资源的数目，初值应该大于等于0</li></ul></li><li><p><img src="/images/OS/process_corporate.png"></p></li><li><p>s13 = 0 表示进程P1尚未执行完成</p></li><li><p>s23 = 0 表示进程P2尚未执行完成</p></li><li><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">P1</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">....;</span><br><span class="line">  v(s13);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">P2</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  ....;</span><br><span class="line">  v(s23);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">P3</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  p(s13);</span><br><span class="line">  p(s23);</span><br><span class="line">  .....;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>思路：为每个只能在进程i结束后才能执行的进程j设置是否可开始的信号灯<span class="math inline">\(S_{ij}\)</span>，其初值为0，这些进程执行前先对<span class="math inline">\(S_{ij}\)</span>进行p操作。</p></li></ul></li></ul></li><li>IPC<ul><li><p>fork</p><ul><li><p>子进程值为0，父进程中为一大于0整数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pid_t</span> p1, p2, p3;</span><br><span class="line"><span class="keyword">if</span> ((p1 = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// child process</span></span><br><span class="line">    execv(<span class="string">"./get"</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> ((p2 = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// child process</span></span><br><span class="line">    execv(<span class="string">"./copy"</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> ((p3 = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// child process</span></span><br><span class="line">    execv(<span class="string">"./put"</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    wait(<span class="literal">NULL</span>);</span><br><span class="line">    wait(<span class="literal">NULL</span>);</span><br><span class="line">    wait(<span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>并发实践，P80左右，注意有无else</p></li></ul></li><li><p>线程</p><ul><li>线程(Thread)是一个动态的对象，是处理机调度的基本单位，表示一个进程中的一个控制点，执行一系列的指令。</li><li>进程是系统资源的分配单位；线程是处理机调度的对象</li><li>与进程相同的地方<ul><li>线程共享父进程的代码段和数据段，拥有相同的优先级</li></ul></li><li>不同的地方<ul><li>每个线程拥有自己的PC，寄存器和栈指针</li></ul></li><li>上下文切换<ul><li>同一个进程中线程切换简单，因为进程中所有线程是共享一个上下文的</li></ul></li><li>实验<ul><li>飞机售票</li></ul></li></ul></li><li>调度<ul><li><p>循环轮转</p><p><img src="/images/OS/rotate.png"></p><ul><li>固定时间片<ul><li>优点：实现简单、系统开销小</li><li>缺点：不灵活，当系统中进程较少时，系统开销大</li></ul></li></ul></li><li><p>优先级</p><ul><li>多级反馈队列调度算法</li></ul><p><img src="/images/OS/priority&amp;timeslice.png"></p><p><img src="/images/OS/优先级.png"></p><ul><li>I/O量大-&gt;高优先就绪队列，<strong>优先照顾</strong></li><li>计算量大-&gt;低优先就绪队列，但一次可执行500ms，<strong>适当照顾</strong></li><li>I/O多-&gt;优先执行，系统的外部设备经常忙</li><li>I/O少-&gt;时间片长，上下文切换少系统开销小</li></ul></li></ul></li></ul><h2><span id="第五章">第五章</span></h2><ul><li>死锁<ul><li>死锁就是两个或两个以上的进程等候着一个永远不会发生的事件时所处的一种系统状态。</li><li>四个必要条件<ul><li>互斥-Mutual Exclusion</li><li>不可剥夺-No preemption</li><li>部分分配-Hold and wait</li><li>循环等待-Circular wait</li></ul></li></ul></li><li>预防<ul><li>预先分配一个进程要用的所有资源（静态分配）是防止死锁的一种安全而简单的方法<ul><li>破坏部分分配条件</li><li>缺点：设备（资源）的浪费太大</li></ul></li></ul></li><li>避免<ul><li>有序资源分配<ul><li>系统中的所有资源统一编号（如打印机为1，磁带机为2...）</li><li>申请时必须以上升的次序</li><li>系统要求<ul><li>对必须使用的而且属于同一类的资源，必须一次申请完</li><li>在申请不同类资源时，必须按设备编号依次申请</li></ul></li></ul></li><li>最简单的银行家算法（书上的例子）<ul><li>银行家算法要求进入系统的进程必须说明它对各类资源类型的实例的最大需求量。这一数量不能超过系统各类资源的总数。当进程申请一组资源时，该算法需要检查申请者对各类资源的最大需求量，<strong>如果系统现存的各类资源的数量可以满足当前它对各类资源的最大需求量，就满足当前的申请</strong>；否则进程必须等待，直到其他进程释放足够的资源为止。</li><li>问题<ul><li>考察每个进程对各个资源的申请需花费较多的时间</li><li>过于谨慎</li></ul></li></ul></li></ul></li></ul><h2><span id="第六章">第六章</span></h2><ul><li>映射<ul><li>逻辑、物理转换</li><li>静态地址映射<ul><li>在作业装入过程中进行地址映射</li><li>需软件重定位装入程序</li><li>需要花费较多CPU时间</li><li>不灵活</li></ul></li><li>动态地址映射<ul><li>在程序执行期间进行地址映射</li><li>需要硬件地址变换机构-重定位寄存器</li><li>地址变换快</li><li>灵活</li></ul></li></ul></li><li><p>分配</p><ul><li>放置策略</li><li>调入策略<ul><li>请调</li><li>预调</li></ul></li><li>淘汰策略</li></ul></li><li>扩充<ul><li>虚拟存储-为用户提供一种不受物理存储器结构和容量限制的存储器</li><li>核心<ul><li>程序执行的局部性原理</li><li>逻辑地址和物理地址的分离</li></ul></li></ul></li><li>保护<ul><li>上下界 -&gt; 物理<ul><li>下界寄存器：存放程序装入内存后的开始地址</li><li>上界寄存器：存放程序装入内存后的末地址</li><li>（下界寄存器）<span class="math inline">\(\le\)</span> 物理地址 &lt; （上界寄存器）</li></ul></li><li>基址限长 -&gt; 逻辑<ul><li>0 <span class="math inline">\(\le\)</span> 逻辑地址 &lt; 限长</li></ul></li><li>仅适用于连续分配</li></ul></li><li>动态分区<ul><li><p>自由主存队列</p><p><img src="/images/OS/M_RIB.png"><img src="/images/OS/PD.png"></p><p><img src="/images/OS/free.png"></p></li><li><p>首次适应算法</p><ul><li><p>按空闲区首址升序的方法组织</p></li><li><p>尽可能地利用低地址的空闲区，而尽量地保证高地址的大空闲区</p><p><img src="/images/OS/first.png"></p></li></ul></li><li><p>最佳适应算法</p><ul><li><p>按空闲区大小升序方法组织</p></li><li><p>将申请者放入与其大小最接近的空闲区中</p></li><li><p>若系统中存在与申请区大小相等的空闲区，这种算法肯定能将这种空闲区分配给申请者（首次适应则不一定）</p><p><img src="/images/OS/best.png"></p></li></ul></li><li><p>最坏适应算法</p><ul><li><p>按空闲区大小降序的方法组织</p></li><li><p>将最大的空闲区切去一部分给请求者</p></li><li><p>克服最佳适应算法把空闲区分割得太小的缺点</p><p><img src="/images/OS/worst.png"></p></li></ul></li><li><p>高、低地址优先</p></li></ul></li><li>页式系统<ul><li><p>页表</p><table><thead><tr class="header"><th>页号</th><th>块号</th></tr></thead><tbody></tbody></table></li><li><p>快表</p><ul><li>Translation Look-aside Buffers, TLB</li></ul></li><li><p>地址变换过程</p><p><img src="/images/OS/trans.png"></p><p>内存地址 = 块号 * 页大小 + 位移量</p><ul><li>按字节编址</li><li>1KB = 10位</li><li>2KB = 11位</li><li>1MB = 20位</li><li>1GB = 30位</li></ul><p>程序地址以十进制给出</p><ul><li>页号 = 虚地址 % 页大小</li><li>位移量 = 虚地址 mod 页大小</li></ul></li><li><p>TLB</p><p><img src="/images/OS/TLB.png"></p><ul><li>查TLB = <span class="math inline">\(\epsilon\)</span> 时间</li><li>查内存 = 1 毫秒</li><li>命中率 = <span class="math inline">\(\alpha\)</span></li><li>Effective Access Time(EAT) = <span class="math inline">\((1+\epsilon)\alpha+(2+\epsilon)(1-\alpha)\)</span></li></ul></li><li><p>请求分页，扩充页表位</p><ul><li><p>扩展页表</p><table><thead><tr class="header"><th>页号</th><th>块号</th><th>中断</th><th>辅存地址</th><th>引用</th><th>修改</th><th>访问方法</th></tr></thead><tbody></tbody></table></li><li><p>中断位：0 -&gt; 在内存，1 -&gt; 不在内存</p></li><li><p>引用位：0 -&gt; 没有进程访问，1 -&gt; 有进程访问</p></li><li><p>修改位：0 -&gt; 调入后没修改，2 -&gt; 调入后修改过</p></li></ul></li><li><p>页面置换算法</p><ul><li><p>先进先出</p><ul><li>建立一个页面进入主存的先后次序表</li><li>建立一个替换指针，指向最早进入主存的页面</li><li>当需要置换一页时，选择替换指向的一页，然后调整替换指针的内容</li><li>每次有新页面进入内存更新次序表</li></ul></li><li><p>LRU-Least Recently Used</p><ul><li><p>需要淘汰页时，选择最长时间未使用的页</p><p><img src="/images/OS/LRU.png"></p></li></ul></li><li><p>近似LRU（实现）</p><p><img src="/images/OS/LRU流程.png"></p><p><img src="/images/OS/LRUeg.png"></p></li></ul></li></ul></li><li><p>页式系统最终面貌</p><p><img src="/images/OS/page.png"></p><p>优点：</p><ul><li>不要求作业的程序和数据段在内存中连续存放，解决了碎片问题</li><li>可以利用的存贮空间大大增加，提高了主存利用率</li><li>请求式系统提供了统一管理的虚拟存储实现方案</li></ul><p>缺点：</p><ul><li>硬件支持，成本</li><li>系统开销大，页表维护与管理，缺页中断</li><li>抖动</li></ul></li><li><p>段页式系统</p><ul><li>区别、变换<ul><li>页是物理单位，段是逻辑单位</li><li>页大小是固定的，段大小不固定</li></ul></li><li>段页式系统：段内分页</li><li>难度小于课件上例子</li></ul></li></ul><h2><span id="第七章">第七章</span></h2><ul><li>独立性：用户在编程式所使用的设备与实际设备无关<ul><li>逻辑设备名：用户指定的设备名（可更改的）</li><li>物理名：系统提供的设备的标准名称（不可更改）</li><li>优点<ul><li>方便用户</li><li>改善设备利用率</li><li>提高系统的可扩展性和可适应性</li></ul></li></ul></li><li><p>独占设备：采用动态分配有可能造成死锁</p><ul><li>让一个设备在整个运行区间独占使用</li></ul></li><li><p>共享设备：不会死锁</p><ul><li>由多个作业、进程共同使用的设备</li></ul></li><li><p>设备分配</p><ul><li>先来先服务</li><li>优先级高者优先</li><li>独占分配：在一作业执行前，将它所要使用的设备分配给它；当它结束撤离时，将分配给它的这类设备收回</li><li>共享分配：动态分配，进程提出资源申请，由设备管理模块进行分配，进程使用完毕后立即归还</li><li>虚拟分配<ul><li>将独占设备转换为共享设备的一种技术</li><li>通常把用来代替独占类型设备的那部分外存空间称为<strong>虚拟设备</strong></li><li>当进程需要与独占设备交换信息时，系统将分配磁盘空间，并建立相应的数据结构，这种分配方法称为虚拟分配</li></ul></li></ul><p>​</p></li><li>缓冲管理<ul><li><p>预存缓写</p></li><li><p>不让进程长时间等待外设完成操作</p></li><li><p>缓写</p><p><img src="/images/OS/缓冲.png"></p></li></ul></li></ul><h2><span id="第八章">第八章</span></h2><ul><li>文件<ul><li>逻辑结构<ul><li>流式 Byte Sequence<ul><li>无结构，流式文件是相关的字符的集合，文件的长度为所含字符数</li></ul></li><li>记录式 Record Structure<ul><li>记录式文件是记录的集合，每个记录由相关的域构成</li></ul></li></ul></li><li>物理结构<ul><li><p>连续文件</p><ul><li>文件内容存放在连续编号的磁盘块中</li><li>优点<ul><li>结构简单，容易实现</li><li>不需要额外开销</li></ul></li><li>缺点<ul><li>空间利用率低</li><li>不利于文件的动态增加和修改</li></ul></li></ul></li><li><p>串联文件</p><ul><li>文件的内容放在若干不要求连续编号的磁盘块中</li><li>一个文件占用的磁盘块链接成一个磁盘块链，链接指针存放在每磁盘块的最末一个字（或第一个字）</li><li>优点<ul><li>存储空间利用率高</li><li>文件动态扩充和修改容易</li></ul></li><li>缺点<ul><li>随机存取效率太低</li></ul></li></ul></li><li><p>FAT</p><ul><li>文件映照</li><li>把串联文件中的链接集中在一个结构中，这样既保持了串联文件的优点，也克服了其缺点</li></ul><p><img src="/images/OS/FAT.png"></p></li><li><p>索引文件</p><ul><li>每个文件有一个索引表，登记文件的逻辑块与物理块间的对应关系</li></ul><p><img src="/images/OS/index.png"></p><ul><li>i_addr[0]~i_addr[9] 为直接索引</li><li>i_addr[10]为一级间接索引块</li><li>i_addr[11]为二级间接索引块</li><li>i_addr[12]为三级间接索引块</li></ul></li></ul></li></ul></li><li>空闲空间<ul><li><p>位示图</p><ul><li><p>用一个位向量表示哪一块空闲</p><p><img src="/images/OS/bitmap.png"></p></li></ul></li><li><p>成组连接-Grouping</p><p><img src="/images/OS/group.png"></p><ul><li><p>空闲inode</p><ul><li>s_nfree 空闲块数，初值为1</li><li>s_free[100] 空闲块块号，s_free[0]初值为0</li></ul></li><li><p>第一组是99块，中间都是100块，最后一组&lt;=100块</p></li><li><p>回收算法free</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">free</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (s_nfree &lt; <span class="number">100</span>) &#123;</span><br><span class="line">    s_free[s_nfree++] = 释放磁盘块号;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    将s_free[]写到释放磁盘块中;</span><br><span class="line">    s_nfree = <span class="number">1</span>;</span><br><span class="line">    s_free[<span class="number">0</span>] = 释放磁盘号;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>分配算法alloc</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">磁盘块 alloc()</span><br><span class="line">&#123;</span><br><span class="line">  s_nfree--;</span><br><span class="line">  <span class="keyword">if</span> (s_nfree == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (s_free[<span class="number">0</span>] == <span class="number">0</span>) &#123;</span><br><span class="line">      sleep();</span><br><span class="line">    &#125;</span><br><span class="line">    a = s_free[<span class="number">0</span>];</span><br><span class="line">    将s_free[<span class="number">0</span>]块读到filsys;</span><br><span class="line">    s_nfree = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> s_free[s_nfree];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li>文件图示<ul><li><p>树形</p><p><img src="/images/OS/filetree.png"></p><ul><li><p>目录文件是有文件目录项组成的文件</p></li><li><p>文件目录项由文件名和inode组成</p><table><thead><tr class="header"><th>文件名</th><th>inode</th></tr></thead><tbody></tbody></table></li></ul><p><strong>inode</strong></p><p><img src="/images/OS/inode.png"></p></li><li><p>绝对／相对路径</p></li><li><p>链接</p><ul><li>硬链接：目录项中指向同一个inode</li><li>软链接：目录项中指向不同的inode，链接文件的磁盘块里存储链接对象的inode</li></ul></li><li><p>文件共享</p><ul><li>被多个用户使用，由存取权限控制</li><li>被多个进程使用，但各用自己的读写指针</li><li>被多个进程使用，但共享读写指针</li></ul></li><li><p>文件操作（FCB）</p><p><img src="/images/OS/FCB.png"></p><ul><li>打开</li><li>重命名</li><li>移动</li></ul></li></ul></li></ul><h2><span id="tinyos">TinyOS</span></h2><ul><li>组件化编程，连接配置文件<ul><li>Application = Graph of Components</li></ul></li><li>执行机制<ul><li>分阶段作业，无阻塞</li><li>主动消息通信</li></ul></li><li>中断</li><li>事件<ul><li>事件驱动</li><li>优先级高于任务</li></ul></li><li>任务<ul><li>轻量级线程。任务之间平等，不能相互抢占，先入先出进行调度</li><li>任务一般用于对时间要求不是很高的应用中，要求每个任务都很短小，能够使系统的负担较轻</li><li>不能有返回值和参数</li></ul></li></ul><p><strong>习题</strong></p><ol type="1"><li>输入输出控制的主要功能是什么？<ul><li>解释用户的I/O系统调用命令</li><li>设备驱动</li><li>中断处理</li></ul></li><li>实时系统的基本特征：<ul><li>安全性</li><li>实时性</li><li>高可靠</li><li><strong>没有</strong>公平响应！</li></ul></li><li>文件的物理结构：<ul><li>连续</li><li>串联</li><li>索引</li></ul></li><li>设备独立性是指<strong>用户程序中使用的设备独立于具体的物理设备</strong></li><li>所谓操作系统虚拟机的概念，是指<strong>在裸机上配置操作系统</strong></li><li>常用的资源分配策略有优先调度和<strong>先来先服务</strong>两种</li><li>文件目录采用树型结构而不采用简单表结构的最主要原因是<strong>解决重名问题</strong></li><li>在请求分页系统中，为实现淘汰页面的功能，在页表中增加<strong>引用位</strong>和<strong>改变位</strong>两个数据项</li><li>常用的设备分配技术有独占分配、共享分配和<strong>虚拟分配</strong>3种</li><li>文件系统中的链接技术，指的是在<strong>目录表目</strong>之间进行链接</li><li>操作系统是由一组资源管理程序组成的，其中<strong>文件系统</strong>是对软件资源的管理。</li><li>UNIX缓冲管理中，使用的队列结构有<strong>空闲缓冲区队列</strong>和<strong>设备缓冲区队列</strong>两种</li><li>在整个中断向量处理过程中，硬件负责<strong>中断响应</strong>过程</li><li>进程从结构上讲，包括<strong>程序、数据和PCB</strong>几个部分</li><li><strong>一组进程间发生了死锁</strong>，这时这些进程都占有资源</li><li><strong>用户存取信息</strong>是用来进行I/O操作的基本单位</li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 本科课程 </tag>
            
            <tag> 操作系统 </tag>
            
            <tag> OS </tag>
            
            <tag> TinyOS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>物联网存储技术</title>
      <link href="/2017/01/05/%E7%89%A9%E8%81%94%E7%BD%91%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF/"/>
      <url>/2017/01/05/%E7%89%A9%E8%81%94%E7%BD%91%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><strong>目录</strong></p><!-- toc --><ul><li><a href="#元数据管理">元数据管理</a></li><li><a href="#重复数据删除">重复数据删除</a></li><li><a href="#固态存储技术">固态存储技术</a></li><li><a href="#溯源数据的高效存储管理及应用">溯源数据的高效存储管理及应用</a></li><li><a href="#名词解释">名词解释</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="元数据管理">元数据管理</span></h2><p>元数据描述件系统组织结构的数据(描述数据的数据)，即访问数据之前必须访问的数据的描述信息和空间组织信息。</p><ul><li>OBS(Object-based Storage，对象存储)，OSD(Obeject-based Storage Device，对象存储设备)</li><li>在OBS系统中，元数据分为物理视图（约占元数据总量90%）和逻辑视图（约占元数据总量10%）。<ul><li><strong>物理视图</strong>负责将<strong>对象的逻辑块映射到存储物理介质</strong>，以支持对象在块存储设备上的工作，存放在<strong>OSD</strong>上</li><li><strong>逻辑视图</strong>用于<strong>描述整个系统的命名空间、目录层次结构和访问控制策略，将文件映射为存储对象</strong>，存放在<strong>MDS</strong>上。</li><li>存储在<strong>OSD</strong>中的元数据负责OSD上<strong>局部</strong>的数据管理</li><li>而<strong>MDS</strong>上维护管理的元数据则负责整个存储系统中<strong>全局的数据布局、负载调度与访问控制</strong>是OBS元数据管理的<strong>重点</strong></li></ul></li></ul><p>元数据表</p><ul><li>用来描述文件与对象之间的对应关系</li><li>flag为0表示一个文件对应多个对象，索引号字段表示各对象在文件中的物理逻辑顺序，偏移值字段表示该对象在对应文件中的偏移首地址</li><li>flag为1则表示多个文件存在一个对象中，索引号字段表示各文件在对象中的物理逻辑顺序，偏移值字段表示各文件在中该对象的偏移首地址</li><li>OSD号是各存储设备（OSD）在OBS存储系统中的全局唯一标识</li><li>对象号则是根据一定的命名规则形成的对象标识符，通常是一个全局唯一的128位无符号数</li></ul><p>MDS的基本功能</p><ul><li>维护全局树形目录结构</li><li>提供给客户统一的目录视图</li><li>完成客户端提交的文件请求到对象的映射</li><li>并给出所属对象的存储位置</li><li>元数据的本地存储管理</li><li>安全策略</li><li>对象分布管理：负载均衡</li><li>Cache的一致性维护</li></ul><p>元数据管理方式</p><ul><li>核心问题：<strong>元数据在集群上的分配策略</strong></li><li>合理的分配策略可以使元数据在各MDS上均匀分布，来自客户端的访问负载也可以均衡的分布在各个MDS上，在整个MDS集群中尽量分散热点元数据</li><li>静态目录子树分割<ul><li>按照传统的文件组织方式，将全局目录树划分为若干子树，每个MDS节点上面维护一个或多个子树，各节点共同组成全局的逻辑视图</li><li>优点<ul><li>简单</li><li>最大程度的保留了目录的层次逻辑结构</li><li>便于利用文件访问的空间局部性</li><li>用户的文件访问请求只需涉及一台MDS，各个MDS彼此独立</li></ul></li><li>缺点<ul><li>若某个目录子树下面的自目录或文件成为访问<strong>热点</strong>，则存放该目录子树的MDS节点将负载过重，成为MDS集群中的瓶颈</li><li>当加入或删除MDS节点时，需要人工的调整目录子树的分配，大大<strong>限制了MDS集群的可扩展性</strong></li></ul></li></ul></li><li>静态哈希<ul><li>静态哈希方法通过将文件标识符、目录/文件名或其他文件特征值进行哈希运算，映射分配到不同的MDS节点上</li><li>优点<ul><li>将全局元数据均匀的分配到MDS集群各节点上，不会因为存在热点目录导致MDS负载不均衡</li><li>客户的文件访问请求，只要经过简单的哈希运算便可以定位到目标MDS</li></ul></li><li>缺点<ul><li>由于放弃了系统目录结构的空间局部性，在对子目录进行遍历操作，要涉及MDS中大量节点的工作</li><li>对子目录进行重命名操作将导致大量元数据迁移；</li><li>客户端上的Cache也因为不断刷新而降低了命中率</li><li>集群中加入或删除MDS节点时，必然需要更改哈希函数，将导致MDS集群中元数据的重新分配，大量元数据迁移，因此其可扩展性能很有限</li></ul></li></ul></li><li>Lazy Hybrid<ul><li>采用文件的全路径名进行哈希运算，这样<strong>相同路径下的所有文件被映射存放到同一MDS上</strong>，这些文件的<strong>元数据进一步通过哈希分散开来</strong>，并使用一个元数据查找表（Metadata Look-up Table，MLT）来记录分布信息</li><li>优点<ul><li>既保留了一定的目录结构，又充分分散了热点目录下的元数据</li><li>采用了一种<strong>访问控制链表</strong>描述文件的安全权限，将目录权限的检查合结合文件的元数据中，不必遍历文件路径的所有目录层次才能确定该文件的访问权限</li><li>将元数据的更新操作暂存延迟到该元数据再次访问的时候进行，分散MDS的更新负担</li></ul></li><li>缺点<ul><li>与静态哈希类似</li></ul></li></ul></li><li>动态目录子树分割<ul><li>将全局目录划分为若干目录子树，分布存储在MDS集群各节点上，当系统中出现热点子目录或目录子树过于庞大时，则采用哈希的方法将该子目录下的所有<strong>元数据分配到集群其他MDS节点上</strong>。</li><li>优点<ul><li>最大程度保留目录结构，以便充分利用文件的空间局部性</li><li>动态的进行元数据迁移，调整集群负载</li></ul></li><li>缺点<ul><li>在文件访问负载不断变化的情况下，如何能使系统根据负载情况自适应调整元数据分布，是一个实现难题</li></ul></li></ul></li><li>动态哈希<ul><li>提供了相对负载均衡、弹性更新策略和全生命周期管理三种策略，通过MDS之间的检测，将高负载MDS中的部分元数据向低负载MDS迁移</li><li>当需添加或移出MDS时<ul><li>采用弹性更新策略进行负载调度</li><li>全生命周期管理利用缓存发现热点并制作副本</li><li>分担元数据访问负载</li></ul></li></ul></li><li>HBA<ul><li>设计思想是在每个MDS上建立两级布隆过滤器阵列（Bloom-filter arrays），第一级是<strong>LRU Bloom-filter</strong>，用来记录本地MDS访问最频繁的文件，体积小但查找快；第二级Bloom-filter用来<strong>记录本地MDS存储的所有文件</strong>，体积大但查找慢。</li><li>同时，每台MDS还保存了集群中<strong>其他MDS节点的两级Bloom-filter</strong>，构成了两级记录全局文件分布信息的Bloom-filter阵列</li><li>当LRU表发生溢出时，LRU替换策略将会在相应LRU BF中触发一个增删操作。</li><li>当LRU BF的改变超过一个阈值时，该元数据服务器将会向其他所有元数据服务器广播新的LRU BF来更新它在其他服务器的副本</li><li>优点<ul><li>HBA策略不关心元数据的具体分配方式，而是通过将客户请求进行两级Bloom-filter阵列查找快速定向到存储该请求文件元数据的MDS上，提高了访问速度</li></ul></li><li>缺点<ul><li>不命中带在的请求广播会增加系统额外负担</li></ul></li></ul></li><li>G-HBA<ul><li>引入了分组的概念，将MDS集群根据物理位置等因素分成若干小组，每个小组维持着一个全局的两级Bloom-filter阵列，分布的存储在各MDS节点上</li><li>优点<ul><li>客户请求到来时，MDS首先查询本地的部分Bloom-filter阵列，命中则直接将请求重定向，否则首先在组内组播查询，若再不命中则在组外广播。这样的设计<strong>显著减少了HBA系统中客户请求广播带来的网络负载</strong></li></ul></li></ul></li></ul><p>元数据管理方式对比</p><ul><li><em>静态目录子树分割</em>与<em>静态哈希</em>是最<strong>基本</strong>的元数据分配策略，管理简单而易于实施，但在目录结构或名称发生变化时会导致大量元数据迁移，MDS集群节点的加入与删除也会导致元数据的重新分配，因此可扩展性较差。</li><li>HBA与G-HBA则为元数据管理发展了一种新的设计思路，既在原有元数据分配策略的基础上建立一个逻辑层，充分利用客户访问的时间局部性，结合Bloom-filter结构的高速查询，使客户请求能够快速定位，<strong>显著的分担了MDS的工作负载，提高了MDS集群的整体性能</strong>。</li><li>LH策略、动态目录子树分割与动态哈希在前两种基本策略基础上进行了改进，通过使用延迟更新策略、元数据查找表、负载动态调整等方法，使元数据管理获得更有效的管理，但是也不可避免的<strong>继承了</strong>静态目录子树分割与静态哈希的<strong>缺点</strong>。</li></ul><p>Bloom Filter</p><p>误判率为： <span class="math display">\[f = (1- (1-\frac{1}{m})^{nk})^k = (1-e^{-\frac{kn}{m}})^k = (1-p)^k\]</span> 最优的哈希函数个数 <span class="math display">\[g = \ln f = k\ln(1-e^{-\frac{kn}{m}})\]</span></p><p><span class="math display">\[\frac{\partial g}{\partial k} = \ln(1-e^{-\frac{kn}{m}}) + \frac{kn}{m}\frac{e^{-\frac{kn}{m}}}{1-e^{-\frac{kn}{m}}} = \ln(1-p) + \frac{kn}{m}\frac{p}{1-p}\]</span></p><p>令<span class="math inline">\(\frac{\partial g}{\partial k} = 0\)</span>，解得：<span class="math inline">\(k = \frac{m}{n}\ln2\)</span> <span class="math display">\[f_{min} = (1-e^{-\ln2})^{\frac{m}{n}\ln2} = (\frac{1}{2})^{\frac{m}{n}\ln2} = (0.6185)^{\frac{m}{n}}\]</span> 应用</p><ul><li>字典存储</li><li>数据库</li><li>分布式缓存</li><li>P2P/Overlay网络应用</li></ul><h2><span id="重复数据删除">重复数据删除</span></h2><p><strong>为什么重复数据删除？</strong></p><ul><li>高效地节约存储空间，数据保存时间更长，或者备份更多</li><li>减少网络中数据的传输量，也可以提高备份恢复的性能</li><li>广域网环境，减少数据传输量的意义就更加明显，可以更容易地实现远程备份或容灾</li><li>帮助用户节约时间和成本<ul><li>数据的恢复速度更快</li><li>随着备份存储设备的减少，空间、电力、散热的成本消耗也在降低</li></ul></li></ul><p><strong>重删流程</strong></p><ul><li>文件数据流分块。</li><li>数据块哈希指纹。</li><li>指纹查找。</li><li>数据存储</li></ul><p><img src="/images/物联网存储技术/重删流程图.png"></p><p><strong>应用</strong></p><ul><li>备份和归档系统。</li><li>主存储文件系统。</li><li>内存的缓存设计。</li><li>虚拟机存储优化。</li></ul><p><strong>重复数据删除的粒度</strong></p><ul><li>文件级<ul><li>通过检查文件的属性来确定重复文件。</li><li>这种方法去重的<strong>效果不如</strong>其他粒度级别</li><li>但是<strong>技术比较简单，而且速度快</strong>。</li></ul></li><li>数据块级<ul><li>定长分块</li><li>变长分块</li><li>将数据切分成大小相同的块。每个块都被赋予一个“指纹”，通过“指纹”与数据索引（指纹库）的比较判断是否为重复数据。</li><li>如果块分割的越小，块数量相应就越多，索引也就越多。（产生较高的数据去重比率）。</li><li>不过，我们还要评估一个重要的指标—就是<strong>I/O的压力</strong>，它<strong>与数据比较的频度成正比</strong>，加之数据块越小索引就越大，这可能导致备份性能的下降。</li></ul></li><li>字节级<ul><li>通过在新旧文件之间进行逐个字节的比较实现的。</li><li>对性能的影响却非常大。</li></ul></li><li>粒度越小，重复数据删除所带来的元数据越多</li></ul><p><strong>重复数据删除时间</strong></p><ul><li><strong>在线</strong>机制是指在<strong>数据到达存储设备之前</strong>对相同的数据进行删除，存储设备上仅存储唯一的不重复的数据。</li><li><strong>离线</strong>的实现机制是事先采用一个磁盘缓冲区，<strong>先</strong>将所有到达的数据<strong>缓暂存</strong>到一个磁盘缓冲区中，等所有的数据全部写完之后，<strong>在系统空闲的时刻</strong>，将磁盘缓冲区的数据重新读取出来再<strong>查找和删除其重复的数据</strong>。</li></ul><p><strong>重复数据删除位置</strong></p><p>数据的传输和存储分为两端，一个为数据的发送方，即源端；另一个为数据的接收方和存储方，即目标端。</p><ul><li>源端重复数据删除。<ul><li><strong>在数据开始传送之前</strong>，在源端将重复的数据进行删除，即重复的数据不需要进行传输和存储。</li></ul></li><li>目标端重复数据删除。<ul><li><strong>在目标端的存储设备</strong>上删除重复的数据。在这种实现机制下，重复数据删除所带来的实现开销全部集中在目标端，源端不需要做任何的有关于重复数据删除的操作。</li></ul></li></ul><p><strong>变长分块分块算法</strong></p><ul><li>基于内容的分块算法</li><li>Rabin 指纹分块算法</li><li>Hash算法<ul><li>MD表示消息摘要(Message Digest，简记为MD)，MD5以512比特一块的方式处理输入的消息文本，每个块又划分为16个32比特的子块。算法的输出是由4个32比特的块组成，将它们级联成一个128比特的摘要值。</li><li>重复删除技术通常采用MD-5 (a 128 字节的散列) 或 SHA-1 (a 160字节的散列) 算法</li><li>发生散列冲突的概率小于行星碰撞地球</li><li>hash碰撞并不意味着数据会全部丢失。数据被错误识别的这个文件会被破坏。所有其它的数据会被正确地恢复。</li></ul></li></ul><p><strong>问题与挑战</strong></p><ul><li>可扩展性</li><li>吞吐率</li><li>内存开销</li><li>恢复性能</li></ul><p><strong>总结</strong></p><ul><li>重删分块算法<ul><li>定长&amp;变长</li><li>分块大小</li></ul></li><li>哈希指纹算法<ul><li>SHA-1、MD5</li><li>写吞吐率</li><li>文件大小</li><li>哈希算法</li></ul></li><li>读性能<ul><li>文件碎片</li></ul></li><li>分块算法，仍然继续。</li><li>哈希摘要，已经成熟。</li><li>指纹查找，依旧挑战。</li><li>数据读取，潜在问题。</li></ul><h2><span id="固态存储技术">固态存储技术</span></h2><p><strong>半导体存储设备</strong></p><ul><li>闪存（Flash）<ul><li>电容性</li></ul></li><li>相变存储器（PCM）<ul><li>电阻性</li></ul></li></ul><p><strong>SSD优势</strong></p><ul><li>SSD没有机械部件，抗震动</li><li>SSD不需要马达，低能耗</li><li>SSD高性能</li><li>SSD价格在不断下降</li></ul><p><strong>固态存储相关技术</strong></p><ul><li>SSD：Solid State Disk 固态盘<ul><li>基本存储介质是NAND FLASH</li><li>由一个嵌入式控制器控制NAND FLASH的操作</li><li>RAM作为buffer</li><li>通过IDE,SATA,PCI-e等总线对外提供块接口</li><li>读请求：块级接口</li><li>写请求：扇区为单位</li><li>先擦后写</li><li>主要模块<ul><li>数据缓存管理模块<ul><li>好的buffer策略能够提高SSD的整体性能</li></ul></li><li>闪存翻译层模块 FTL (Flash Translation Layer)<ul><li>Address Mapping (地址映射)<ul><li>&lt;lsn, size&gt; -&gt; &lt;package，die，plane，block，page&gt;</li><li>页级映射（好，长，大，大，高）</li><li>块级映射（差，短，小，小，低）</li><li>混合映射（较差....）</li></ul></li><li>Wear leveling (损耗平衡)<ul><li>动态损耗平衡<ul><li>在请求到达时，选取擦除次数较少的块作为请求的物理地址。</li></ul></li><li>静态损耗平衡<ul><li>将冷数据从原块取出，存放在擦除次数过多的块，原来存放冷数据的块被释放出来，接受热数据的擦写。</li></ul></li></ul></li><li>Garbage collection (垃圾回收)<ul><li>SSD在使用过程中，会产生大量失效页，在SSD的容量到达一定阈值时，需要调用GC函数，清除所有失效页，以增加可用空间</li></ul></li></ul></li></ul></li></ul></li><li>SCM：Storage-Class Memory 存储级内存<ul><li>非易失</li><li>零或低空闲能耗</li><li>类似磁盘一样的容量</li><li>接近DRAM的存取延迟</li><li>字节级编址</li><li>集成SCM的策略<ul><li>缓存策略</li><li>存储替代策略</li><li>内存替代混合策略</li><li>单级存储策略</li></ul></li></ul></li></ul><p><strong>SSD的接口标准</strong></p><ul><li>目前：IDE和SATA</li><li>将来：PCI-E</li></ul><p><strong>性能标准</strong></p><ul><li>测试前提<ul><li>读写比例（R/W：75/25, 50/50）</li><li>请求块大小（2KB、128KB）</li><li>测试过程中是否调用过GC操作</li><li>保留空间是多少（20%）</li></ul></li></ul><p>能耗</p><ul><li>产品标称上的功率不一定能够反映SSD真实的能耗。<strong>因为不同的SSD的内部结构可能有所差别，而且智能的功耗管理系统在SSD实际运行时会对能耗有影响。</strong></li><li>因此，能反映能耗的指标是：<strong>完成相同的IO访问请求，所消耗的总能量</strong>，或者是<strong>单位能耗所能完成的IO访问数</strong>。</li></ul><p><strong>自适应的动态缓存管理算法</strong></p><ul><li>核心思想：利用两次突发性请求周期间的相对空闲时间段，以及固态盘内的空闲资源，提前写回固态盘缓存中的部分数据。</li><li>提前写回的优势在于：当后续写请求没有命中缓存时，可将之前提前写回的数据直接删除，腾出空间后，将该写请求的数据直接保存在缓存中，避免了实时的缓存数据写回闪存导致这个写请求的延时。</li><li>组成<ol type="1"><li>动态阈值调整算法</li><li>动态内存分区调整算法</li></ol></li></ul><h2><span id="溯源数据的高效存储管理及应用">溯源数据的高效存储管理及应用</span></h2><p><strong>溯源的概念及研究的意义</strong></p><ul><li>在系统领域，一个数据的溯源是<strong>所有影响这个数据最终状态的进程和数据</strong></li><li>溯源揭示了数据对象的过去或产生过程，使得人们对复杂的海量数据本身的分析和理解更加透彻</li></ul><p><strong>溯源数据的存储</strong></p><p>该溯源图信息可用Key-Value数据库（例如BerkeleyDB或Redis），或采用图数据库（例如Neo4j）进行存储。</p><table><thead><tr class="header"><th style="text-align: center;">数据库名称</th><th style="text-align: center;">数据表记录</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">ProvenanceDB</td><td style="text-align: center;">&lt;pnode号，属性信息&gt;</td></tr><tr class="even"><td style="text-align: center;">NameDB</td><td style="text-align: center;">&lt;Name，pnode号&gt;</td></tr><tr class="odd"><td style="text-align: center;">ParentDB</td><td style="text-align: center;">&lt;子pnode号，父pnode号，time&gt;</td></tr><tr class="even"><td style="text-align: center;">ChildDB</td><td style="text-align: center;">&lt;父pnode号，子pnode号，time&gt;</td></tr></tbody></table><p><strong>溯源的主要应用领域</strong></p><ul><li>监控加工环节</li><li>重现实验结果</li><li>跟踪犯罪行为</li><li>审计财务账目</li><li>可以采用溯源存储系统的技术手段来管理物理网中的溯源信息，对实际物品/操作进行管控</li><li>利用溯源手段，对物联网中的物品进行追踪，是记录物品流向的重要手段</li></ul><p><strong>重大挑战：数据量大</strong></p><ul><li>数据的每次读写操作都会产生溯源数据，从而导致溯源数据量巨大，通常是原始数据量的10倍以上</li><li>当把一个大的溯源图压缩的足够小到能放在内存中时，对于溯源的高效查询是非常重要的</li><li>为什么需要压缩？为什么程序运行慢？（内存占比高）</li></ul><p><strong>传统数据压缩方法</strong></p><ul><li>gzip: window size 64KB</li><li>bzip2: window size 900KB</li><li>7Z: window size 1GB</li><li>缺点：窗口之外的数据无法压缩</li><li>使用经典的压缩工具，如bzip、zblic等，可以最大限度地压缩溯源，但这些工具导致的溯源信息很难被查询。</li></ul><p>迁移压缩</p><ul><li>将相似的溯源信息重组到一起，再应用压缩器进行压缩</li></ul><p><strong>通过挖掘溯源的基本特征来进行压缩</strong></p><ul><li>web压缩和字典编码结合的方法来进行压缩<ul><li>充分分析和挖掘了溯源数据的基本特征</li><li>充分利用了 web图和溯源图在结构上的相似性，并挖掘了溯源节点属性中所存在的大量重复性的字符串信息</li></ul></li></ul><p><strong>溯源的基本特征</strong></p><ul><li>溯源数据的组成<ul><li>身份信息 (节点属性)+祖先信息（边上信息）</li></ul></li><li>溯源图中包含有大量重复性信息</li><li>溯源图和web图都具有以下两个特征<ul><li><strong>局部性</strong><ul><li>web图：一个网页链接通常会指向同一个URL域中的网页。</li><li>溯源图：一个进程(溯源节点)依赖于很多库文件，这些库文件通常在同一目录。这些库文件代表的溯源节点编号在同一区段。</li></ul></li><li><strong>相似性</strong><ul><li>web图：两个邻近的网页很有可能拥有相同的邻居。</li><li>溯源图： 两个进程（溯源节点）依赖于同一个库文件。</li></ul></li></ul></li><li>溯源数据需要被查询</li></ul><p><strong>Web图压缩和字典编码（Web+Dictionary）</strong></p><ul><li>利用溯源图和web图的相似性，充分挖掘溯源图中数据存在的局部性和相似性，来压缩祖先信息</li><li>字典编码可将身份信息和祖先信息边上存在的任何重复性字符串进行编码，具有极其灵活以及足够细粒度的编码方式</li></ul><p><strong>溯源trace和溯源图，以及web图之间的映射</strong></p><p><img src="/images/物联网存储技术/relationship.png"></p><ul><li>溯源trace中的标记“A INPUT[ANC] B” 表示 <strong>B是A的一个祖先</strong>，这意味着溯源图中有一条<strong>从 A 指向 B</strong>的边.</li></ul><p><strong>web图压缩</strong></p><ul><li><p>溯源数据</p><ul><li>15.1 INPUT [ANC] 3.1</li><li>15.1 INPUT [ANC] 11.0</li><li>15.1 INPUT [ANC] 13.1</li><li>15.1 INPUT [ANC] 14.1</li><li>15.1 INPUT [ANC] 17.1</li><li>16.1 INPUT [ANC] 11.0</li><li>16.1 INPUT [ANC] 14.1</li><li>16.1 INPUT [ANC] 19.1</li><li>16.1 INPUT [ANC] 20.1</li><li>16.1 INPUT [ANC] 21.1</li><li>16.1 INPUT [ANC] 33.1</li></ul></li><li><p>邻接表</p><table><thead><tr class="header"><th>Node</th><th>outd</th><th>ancestors</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>3, 11, 13, 14, 17</td></tr><tr class="even"><td>16</td><td>6</td><td>11, 14, 19, 20, 21, 33</td></tr></tbody></table></li><li><p>寻找相似祖先列表</p><table><thead><tr class="header"><th>node</th><th>outd</th><th>ref.</th><th>copy list</th><th>ancestors</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>0=15-15</td><td></td><td>3, 11, 13, 14, 17</td></tr><tr class="even"><td>16</td><td>6</td><td>1=16-15</td><td>01010</td><td>19, 20, 21, 33</td></tr></tbody></table></li><li><p>编码连续的祖</p><p>#intervals表示有几个连续的串</p><p>Left extreme表示跟Node的差距</p></li></ul><table><thead><tr class="header"><th>node</th><th>outd</th><th>ref</th><th>copy list</th><th>inter</th><th>left</th><th>len</th><th>res</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>0</td><td></td><td>1</td><td>-2</td><td>2</td><td>3,11,17</td></tr><tr class="even"><td>16</td><td>6</td><td>1</td><td>01010</td><td>1</td><td>3</td><td>3</td><td>33</td></tr></tbody></table><ul><li>用祖先节点之间的间距进行编码</li></ul><table><thead><tr class="header"><th>node</th><th>outd</th><th>ref</th><th>copy list</th><th>inter</th><th>left</th><th>len</th><th>res</th></tr></thead><tbody><tr class="odd"><td>15</td><td>5</td><td>0</td><td></td><td>1</td><td>-2</td><td>2</td><td>-12,8,6</td></tr><tr class="even"><td>16</td><td>6</td><td>1</td><td>01010</td><td>1</td><td>3</td><td>3</td><td>17</td></tr></tbody></table><ul><li>每个节点的编码：<span class="math inline">\(r\ [b\ B_1 … B_b] i\ E_1 L_1 …E_i L_i R_1 … R_k\)</span><ul><li>r: 参考号</li><li>b: copy list中bit的数量</li><li><span class="math inline">\(B_1…B_b\)</span>: copy list中bit位的值</li><li>i: interval的个数</li><li><span class="math inline">\(E_1…E_i\)</span>: Left Extremes</li><li><span class="math inline">\(L_1…L_i\)</span>: Length</li><li><span class="math inline">\(R_1…R_k\)</span>: Residuals</li></ul></li></ul><p><strong>字典编码</strong></p><ul><li>用较小的整数将重复性字符串进行编码</li><li>可将身份信息上的重复性字符串（如进程执行参数和环境变量）、以及祖先边上的重复性字符串（如时间信息）进行编码</li><li>具有极其灵活以及足够细粒度的编码方式（可找出相同字符串，或者字符串中的相同前缀、后缀）</li></ul><p><img src="/images/物联网存储技术/diccode.png"></p><p><strong>入侵检测中的溯源</strong></p><p>例子：一个远程的攻击者，通过攻击主机上的<code>vsftpd-2.3.4</code>的backdoor漏洞，获得根用户访问权限。然后入侵者以<code>root</code>权限登陆 <code>shell</code>，并通过<code>vi</code>命令篡改了文件<code>f1</code>和<code>f2</code>。</p><p><img src="/images/物联网存储技术/attack.png"></p><p>进行计算机取证</p><ul><li>怎么入侵</li><li>入侵后都干了什么（修改文件，泄漏秘密，安装后门等）</li><li>修补系统漏洞，尝试恢复入侵者造成的修改</li></ul><p>发现入侵检测点</p><ul><li>文件系统完整性检查（Tripwire，AIDE）</li><li>网络检测</li><li>沙盒</li></ul><p>分析入侵行为</p><ul><li>系统/网络日志（Snort，Ethereal）</li><li>磁盘状态（The Coroner’s Toolkit）</li></ul><p>当前取证方法的不足</p><ul><li>系统日志记录不够全面，缺乏必要信息</li><li>网络消息可能被加密</li><li>磁盘状态仅显示了文件的最终状态</li></ul><p>基于溯源的入侵检测总体设计</p><ul><li><p>收集器</p><ul><li>实时监控应用，生成溯源信息</li><li>截获系统调用，跟踪收集文件、进程和网络socket的溯源信息</li><li>修剪大量繁杂的溯源信息来避免误检。</li><li>使用结构化的key-value 数据库来记录和查询入侵信息</li><li>溯源数据库<ul><li>Pnode节点号唯一的标识了每个对象</li><li>ParentDB 和 ChildDB 分别存储了一个节点的父节点和子节点</li><li>RuleDB 存储了代表对象之间依赖性关系的经常性事件</li></ul></li></ul></li><li><p>检测器</p><ul><li><p>从溯源中抽取依赖性信息，建立规则库和检测入侵</p></li><li><p>规则建立</p><ul><li>通过存储经常性事件依赖性关系生成规则，并编码规则</li><li><ol type="1"><li>多次运行一个正常的程序来获取它的溯源信息R</li></ol></li><li><ol start="2" type="1"><li>对于每个R, 划分为 <span class="math inline">\(R=\{Dep_1, …Dep_n\}\)</span>, 其中<span class="math inline">\(Dep_i = (A, B)\)</span>表示 A是 B的父节点</li></ol></li><li><ol start="3" type="1"><li>将每个<span class="math inline">\(Dep_i\)</span>使用字典编码方法来减少在A和B中重复的字符串</li></ol></li><li><ol start="4" type="1"><li>将所有这些<span class="math inline">\(Dep_i\)</span>放进规则库<span class="math inline">\(G\)</span>, 即<span class="math inline">\(G= \{Dep_1, … Dep_k\}\)</span>.</li></ol></li></ul><p><img src="/images/物联网存储技术/rule.png"></p></li><li><p>路径匹配</p><ul><li>基于溯源的路径匹配算法</li><li><ol type="1"><li>获取所检测程序的溯源信息R, 将它表示为<span class="math inline">\(R= \{Dep_1, … Dep_n\}\)</span></li></ol></li><li><ol start="2" type="1"><li>对于R中的每个<span class="math inline">\(Dep_i\)</span> , 如果,<span class="math inline">\(Dep_i = (A, B) \in G\)</span> 则设置它的可疑度<span class="math inline">\(d_i = 0\)</span>, 否则设置可疑度为1</li></ol></li><li><ol start="3" type="1"><li>寻找R中长度为W的路径, 将路径表示为 <span class="math inline">\((Dep_1, … Dep_w)\)</span>, 将路径决策值p表示为<span class="math inline">\(p = \frac{\sum_{i=1}^wd_i}{W}\)</span></li></ol></li><li><ol start="4" type="1"><li>设置阈值T, 如果 P&gt; T, 则警报会响起，相应的溯源路径会输出, 程序被判断为不正常.</li></ol></li></ul></li><li><p>警报输出</p><ul><li>提供直截了当的入侵路径信息来减少误检和帮助取证分析。</li></ul></li></ul></li><li><p>分析器</p><ul><li>分析入侵的系统漏洞和入侵来源</li></ul></li></ul><p><strong>优化、过滤溯源图</strong></p><ol type="1"><li><p>忽略一些特定的对象</p><p>比如login进程会读写文件/var/run/utmp，导致新的login进程依赖于之前的login进程；Mount、umount会写文件/etc/mtab，而bash进程在产生时会读取该文件，导致依赖于mount进程；</p></li><li><p>隐藏只被读的文件</p><p>通常是库文件或者配置文件</p></li><li><p>过滤”辅助”进程</p><p>Bash进程产生id进程、consoletype进程和dircolors进程</p></li></ol><h2><span id="名词解释">名词解释</span></h2><table><thead><tr class="header"><th>中文</th><th>英文</th><th>缩写</th></tr></thead><tbody><tr class="odd"><td>元数据服务器</td><td>Metadata server</td><td>MDS</td></tr><tr class="even"><td>对象存储</td><td>Object-based Storage</td><td>OBS</td></tr><tr class="odd"><td>对象存储设备</td><td>Object-based Storage Device</td><td>OSD</td></tr><tr class="even"><td>元数据查找表</td><td>Metadata Look-up Table</td><td>MLT</td></tr><tr class="odd"><td>闪存翻译层</td><td>Flash Translation Layer</td><td>FTL</td></tr><tr class="even"><td>消息摘要</td><td>Message Digest</td><td>MD</td></tr><tr class="odd"><td>相变存储器</td><td>Phase-change Memory</td><td>PCM</td></tr><tr class="even"><td>地址映射</td><td>Address mapping</td><td>AM</td></tr><tr class="odd"><td>损耗平衡</td><td>Wear leveling</td><td>WL</td></tr><tr class="even"><td>垃圾回收</td><td>Garbage Collection</td><td>GC</td></tr><tr class="odd"><td>存储级内存</td><td>Storage-Class Memory</td><td>SCM</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Bloom Filter </tag>
            
            <tag> 本科课程 </tag>
            
            <tag> 物联网 </tag>
            
            <tag> 对象存储 </tag>
            
            <tag> 重复数据删除 </tag>
            
            <tag> 元数据管理 </tag>
            
            <tag> SSD </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>揭秘二维码—原理与实践</title>
      <link href="/2016/11/14/%E6%8F%AD%E7%A7%98%E4%BA%8C%E7%BB%B4%E7%A0%81%E2%80%94%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/"/>
      <url>/2016/11/14/%E6%8F%AD%E7%A7%98%E4%BA%8C%E7%BB%B4%E7%A0%81%E2%80%94%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h2><span id="什么是二维码">什么是二维码</span></h2><p>二维码，英文：<strong>Quick Response Code</strong>， 简称 <strong>QR</strong> 码。二维码最初由日本一家公司发明，后由国际标准化组织ISO批准进行标准化。现在二维码在我们生活中广泛使用，它具有比条形码更强的数据表示能力和更强的纠错能力。</p><p>我认为，<strong>二维码就是一种编码，把我们要传递的数据进行编码并转换成另外一种形式呈现出来</strong>。</p><a id="more"></a><h2><span id="技术原理">技术原理</span></h2><p>注：文中所指的QR Code Spec : <a href="http://www.codeplex.com/Download?ProjectName=qrcodenet&amp;DownloadId=284291" target="_blank" rel="noopener">ISO/IEC 18004:2000(E) - QR code specification </a>。</p><h3><span id="整体结构">整体结构</span></h3><p>二维码的整体结构如下图所示：</p><p><img src="/images/QR_Structure.png"></p><p>整体分为两大部分：功能区（Function Patterns）和编码区（Encoding region）。</p><p>功能区里又分为：</p><ul><li>Finder Pattern：用于让解码器定位二维码的位置，分别位于三个角</li><li>Separator：起分隔作用</li><li>Timing Patterns：相当于坐标轴</li><li>Alignment Patterns：帮助解码器重新同步坐标映射，在二维码有一定污损的情况下</li></ul><p>编码区里分为：</p><ul><li>Format Information：用来存储纠错等级和掩码（mask）类型</li><li>Version Information：二维码一共有40个尺寸，Version 1是21 x 21的矩阵，Version 2是 25 x 25的矩阵，Version 3是29的尺寸，每增加一个version，就会增加4的尺寸。在 &gt;= Version 7以上，需要预留两块3 x 6的区域存放一些版本信息</li><li>剩下的区域用来存放数据和纠错码</li></ul><h3><span id="编码方式">编码方式</span></h3><p>二维码有多种编码模式，这里介绍四种：</p><ul><li><p><strong>Numeric Mode</strong>：支持数字0～9</p></li><li><p><strong>Alphanumeric Mode</strong>：包括数字0～9，大写字母A～Z，和一些符号空格 $ % * + - . / : 。这些字符会映射成一个字符索引表。如下所示：</p><p><img src="/images/EncodingAM.png"></p><p>编码的过程是把字符两两分组，然后转成上表的45进制，然后转成11bits的二进制，如果最后有一个落单的，那就转成6bits的二进制。</p></li><li><p><strong>Byte Mode</strong>：这个模式可以编码的字符就比上一个多一些，每把个bit构成一个字符，总共可以表示256个不同字符，具体映射表见QR Code Spec的Table 6</p></li><li><p><strong>Kanji Mode</strong>：双字节编码，这个模式可以编码日文，也可以用于中文编码，下图是一个示例：</p><p><img src="/images/Kanji-mode.png"></p></li></ul><p>每种编码模式都有对应的标识符，如表1所示。模式表示要放在数据的前面。</p><table><thead><tr class="header"><th>Mode</th><th>indicator</th></tr></thead><tbody><tr class="odd"><td>Numeric</td><td>0001</td></tr><tr class="even"><td>Alphanumeric</td><td>0010</td></tr><tr class="odd"><td>Byte</td><td>0100</td></tr><tr class="even"><td>Kanji</td><td>1000</td></tr></tbody></table><p>​ 表1 Mode Indicator</p><p>下面我们来看一个具体示例。</p><p>我们用Alphanumeric模式编码 AC-42 这5个字符，假设为Version1：</p><ol type="1"><li><p>从字符索引表中找到 “AC-42” 这五个字符的索引：(10, 12, 41, 4, 2)</p></li><li><p>两两分组：(10, 12), (41, 4), (2)</p></li><li><p>把每一组转成11bits的二进制，落单的转成6bits的二进制：</p><p>(10, 12) = 10 * 45 + 12 = 462 = 00111001110</p><p>(41, 4) = 41 * 25 + 4 = 1849 = 11100111001</p><ol start="2" type="1"><li>= 000010</li></ol></li><li><p>把这些二进制连接起来：00111001110 11100111001 000010</p></li><li><p>把字符的个数转成二进制，不同的Version对应的bit个数如Table3所示。Version1对应的是9bits，总共5个字符，转换成9-bit二进制数就是：000000101</p><p><img src="/images/Count-Indicator.png"></p></li><li><p>在数据前面加上模式标识符0010和上一步得到的字符数编码：0010 000000101 00111001110 11100111001 000010</p></li></ol><h3><span id="结束和补齐">结束和补齐</span></h3><p>假如我们有个HELLO WORLD的字符串要编码，根据上述示例，我们得到一下编码：</p><table><colgroup><col style="width: 7%"><col style="width: 16%"><col style="width: 75%"></colgroup><thead><tr class="header"><th>模式</th><th>字符数</th><th>Hello world编码</th></tr></thead><tbody><tr class="odd"><td>0010</td><td>000001011</td><td>01100001011 01111000110 10001011100 10110111000 10011010100 001101</td></tr></tbody></table><p>我们还要加上结束符：</p><table><colgroup><col style="width: 7%"><col style="width: 15%"><col style="width: 70%"><col style="width: 7%"></colgroup><thead><tr class="header"><th>模式</th><th>字符数</th><th>Hello world编码</th><th>结束符</th></tr></thead><tbody><tr class="odd"><td>0010</td><td>000001011</td><td>01100001011 01111000110 10001011100 10110111000 10011010100 001101</td><td>0000</td></tr></tbody></table><p><strong>按8bits重排</strong></p><p>如果所有的编码加起来不是8个倍数我们还要在后面加上足够的0，比如上面一共有78个bits，所以，我们还要加上2个0，然后按8个bits分好组：</p><p>00100000   01011011   00001011   01111000   11010001   01110010   11011100   01001101   01000011   010000<strong>00</strong></p><p><strong>补齐码（Padding Bytes）</strong></p><p>最后，如果如果还没有达到我们最大的bits数的限制，我们还要加一些补齐码，Padding Bytes就是重复下面的两个bytes：<strong>11101100 00010001</strong> 。关于每一个Version的每一种纠错级别的最大Bits限制，可以参看QR Code Spec的第33页的Table-7一表，下面是这个表的一部分，里面也包含可表示的最大字符数：</p><p><img src="/images/table7.png"></p><p>假设我们需要编码的是Version 1的Q纠错级，那么，其最大需要104个bits，而我们上面只有80个bits，所以，还需要补24个bits，也就是需要3个Padding Bytes，我们就添加三个，于是得到下面的编码：</p><p>00100000 01011011 00001011 01111000 11010001 01110010 11011100 01001101 01000011 01000000 <strong>11101100 00010001 11101100</strong></p><p>上面的编码就是数据码了，叫Data Codewords，每一个8bits叫一个codeword，我们还要对这些数据码加上纠错信息。</p><h3><span id="纠错码">纠错码</span></h3><p>正是因为有了纠错码的存在，二维码才可以在有一定污损的情况下被正确识别，这也是好多二维码中间有图标或头像依然可以被扫出来的理论基础。</p><p>二维码有四个纠错级别，分别如下：</p><p><img src="/images/table8.png"></p><p><strong>二维码的纠错方式也是通过增加冗余位来实现纠错</strong>，这一点在本质上和（分组）奇偶校验，CRC循环校验等纠错方式是相同的，纠正 <span class="math inline">\(t\)</span> 个错误就需要 <span class="math inline">\(2t\)</span> 个纠错码。</p><p>具体来说，首先，我们需要对数据码进行分组，也就是分成不同的Block，然后对各个Block进行纠错编码，对于如何分组，我们可以查看QR Code Spec的第38页的Table-9的定义表，下面是该表的一部分：</p><p><img src="/images/table9.png"></p><p>倒数第二列表示了需要分多少个纠错块，最后一列表示每个纠错块的具体情况，(c, k, r) 分别代表：</p><ul><li>c：该块中总共的Codeword个数</li><li>k：数据Codeword的个数</li><li>r：可以纠正的错误个数，所以纠错码的位(Codeword)数等于 2r</li></ul><p>举个例子，上述的Version 5 + Q纠错级：需要4个Blocks（2个Blocks为一组，共两组），头一组的两个Blocks中各15个Codewords数据 + 各 18个Codewords的纠错码。下图给一个5-Q的示例（因为二进制写起来会让表格太大，所以都用了十进制）：</p><table><colgroup><col style="width: 4%"><col style="width: 4%"><col style="width: 45%"><col style="width: 45%"></colgroup><thead><tr class="header"><th>组</th><th>块</th><th>数据</th><th>纠错码</th></tr></thead><tbody><tr class="odd"><td>1</td><td>1</td><td>67 85 70 134 87 38 85 194 119 50 6 18 6 103 38</td><td>213 199 11 45 115 247 241 223 229 248 154 117 154 111 86 161 111 39</td></tr><tr class="even"><td>1</td><td>2</td><td>246 246 66 7 118 134 242 7 38 86 22 198 199 146 6</td><td>87 204 96 60 202 182 124 157 200 134 27 129 209 17 163 163 120 133</td></tr><tr class="odd"><td>2</td><td>1</td><td>182 230 247 119 50 7 118 134 87 38 82 6 134 151 50 7</td><td>148 116 177 212 76 133 75 242 238 76 195 230 189 10 108 240 192 141</td></tr><tr class="even"><td>2</td><td>2</td><td>70 247 118 86 194 6 151 50 16 236 17 236 17 236 17 236</td><td>235 159 5 173 24 147 59 33 106 40 255 172 82 2 131 32 178 236</td></tr></tbody></table><h4><span id="reed-solomon-code">Reed Solomon Code</span></h4><p>关于每一块的纠错码是怎么来的，它是通过<a href="http://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction" target="_blank" rel="noopener">Reed-Solomon error correction</a>（里德-所罗门纠错算法）实现的，这个地方应该是二维码最难的地方了。RS码是基于 <a href="https://www.wikiwand.com/en/Finite_field" target="_blank" rel="noopener">有限域</a>的编码，这点和<a href="https://www.wikiwand.com/en/Cyclic_redundancy_check" target="_blank" rel="noopener">CRC循环冗余校验</a>是一样的。</p><p>在这个有限域(<strong>GF(2)</strong>)中，四则运算都是按比特模2的四则运算，即两个数的加减法就是按位异或（没有进位和借位），乘法和除法的相加过程也是模2加法。</p><p>每一个二进制数，都可以表示成一个多项式，每一位代表该项的系数，第几位代表指数，如100011101 可以表示为<span class="math inline">\(x^8 + x^4 + x^3 + x^2 + 1\)</span>。</p><p><strong>纠错码就是用数据多项式除以某一个本原多项式<span class="math inline">\(g(x)\)</span>得到的余数</strong>。其中，本原多项式是什么就不多再解释，有兴趣的自行了解，在QR Code Spec中的附录A中有列出；这里面的除法是模2除法。</p><p>关于具体纠错方法和实现就不在这里展开，首先我的理解得也不是很清楚，其次这里面涉及的东西太多，尤其是数学知识，都说清楚可能需要专门写一篇文章。</p><h3><span id="最终编码">最终编码</span></h3><p>在画图前，还需要一步穿插放置的过程。</p><p>对于数据码：把每个块的第一个Codewords先拿出来按顺度排列好，然后再取第一块的第二个，如此类推。如，上述示例中的一部分Data Codewords如下：</p><table><thead><tr class="header"><th style="text-align: center;">块1</th><th>67</th><th>85</th><th>70</th><th>134</th><th>87</th><th>38</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">块 2</td><td>246</td><td>246</td><td>66</td><td>7</td><td>118</td><td>134</td></tr><tr class="even"><td style="text-align: center;">块 3</td><td>182</td><td>230</td><td>247</td><td>119</td><td>50</td><td>7</td></tr><tr class="odd"><td style="text-align: center;">块4</td><td>70</td><td>247</td><td>118</td><td>86</td><td>194</td><td>6</td></tr></tbody></table><p>我们先取第一列的：67， 246， 182， 70 然后再取第二列的：67， 246， 182， 70， 85，246，230 ，247 如此类推：67， 246， 182， 70， 85，246，230 ，247 ………  ……… ，38，6，50，17，7，236</p><p>对于纠错码，也是一样的过程，然后，再把这两组放在一起（纠错码放在数据码之后）得到：</p><p>67, 246, 182, 70, 85, 246, 230, 247, 70, 66, 247, 118, 134, 7, 119, 86, 87, 118, 50, 194, 38, 134, 7, 6, 85, 242, 118, 151, 194, 7, 134, 50, 119, 38, 87, 16, 50, 86, 38, 236, 6, 22, 82, 17, 18, 198, 6, 236, 6, 199, 134, 17, 103, 146, 151, 236, 38, 6, 50, 17, 7, 236, 213, 87, 148, 235, 199, 204, 116, 159, 11, 96, 177, 5, 45, 60, 212, 173, 115, 202, 76, 24, 247, 182, 133, 147, 241, 124, 75, 59, 223, 157, 242, 33, 229, 200, 238, 106, 248, 134, 76, 40, 154, 27, 195, 255, 117, 129, 230, 172, 154, 209, 189, 82, 111, 17, 10, 2, 86, 163, 108, 131, 161, 163, 240, 32, 111, 120, 192, 178, 39, 133, 141, 236</p><p>这就是我们的数据区。</p><p><strong>Remainder Bits</strong></p><p>对于某些Version的二维码，上面的还不够长度，还要加上Remainder Bits。比如：上述的5Q版的二维码，还要加上7个bits，Remainder Bits加零就好了。关于哪些Version需要多少个Remainder bit，可以参看QR Code Spec的Table-1的定义表。</p><hr><h2><span id="画二维码图">画二维码图</span></h2><p><strong>Finder Pattern</strong></p><p>终于到了激动人心的画图环节。首先，先把Position Detection图案画在三个角上，无论Version如何，这个图案的尺寸就是这么大：</p><p><img src="/images/finder.png"></p><p>接着用 HELLO WORLD 的例子，画完之后如下图所示：</p><p><img src="/images/draw_finder.png"></p><p><strong>Alignment Pattern</strong></p><p>然后，再把Alignment图案画上，无论Version如何，这个图案的尺寸就是这么大：</p><p><img src="/images/alignment-pattern.png"></p><p>关于Alignment的位置，可以查看QR Code Spec的第83页的Table-E.1的定义表，下面是该表的一部分：</p><p><img src="/images/tableE.png"></p><p>举个例子，Version 2 的值是6和18。因此 Alignment Pattern 的位置应以(行，列)的 (18, 18) 为中心，因为 (6, 6), (6, 18), (18, 6) 和 Finder Patterns 的位置冲突，所以只剩一个。</p><p>画完如下：</p><p><img src="/images/draw_align.png"></p><p><strong>Timing Pattern</strong></p><p>接下来是Timing Pattern的黑白相间的线：</p><p><img src="/images/Timing-Pattern.png"></p><p>画完如下：</p><p><img src="/images/draw_timing.png"></p><p><strong>Format Information</strong></p><p>再接下来是Formation Information，下图中的蓝色部分:</p><p><img src="/images/Format-Information.png"></p><p>Format Information是一个15个bits的信息，每一个bit的位置如下图所示：</p><p><img src="/images/format.png"></p><p>注1：图中的Dark Module，那是永远出现的 注2：图中的第14位是最高位（The Most Significant Bit），第0位是最低位（The Least significant bit），即如果你得到的结果是100100001101000，那么第14位应该是1，第0位应该是0.</p><p>这15个bits中包括：</p><ul><li><p>5个数据bits：其中，2个bits用于表示使用什么样的Error Correction Level， 3个bits表示使用什么样的Mask，每个纠错级别的标识符如Table25所示:</p><p><img src="/images/table25.png"></p></li><li><p>10个纠错bits，通过BCH码来计算。BCH码也是一种比较麻烦的编码，RS码是BCH码的一种特殊情况，有兴趣的读者自己了解一下。</p></li></ul><p>最后这15个bits还要与101010000010010做XOR操作，这样就保证不会因为我们选用了00的纠错级别和000的Mask，从而造成全部为白色，这会增加我们的扫描器的图像识别的困难。</p><p>举个例子：</p><p>假设纠错级别是M： 00 Mask标识符： 101 数据： 00101 BCH码： 0011011100 掩码： 101010000010010 与掩码异或： 100000011001110</p><p>画完如下：</p><p><img src="/images/draw_format.png"></p><p><strong>Version Information</strong></p><p>Version7以后需要这个编码，下图中的蓝色部分：</p><p><img src="/images/Version-Information.png"></p><p>Version Information一共是18个bits，其中包括6个bits的版本号以及12个bits的纠错码，具体怎么放的有需要的可以去看QR Code Spec第54页的8.10节，这里不再赘述。</p><p><strong>数据码和纠错码</strong></p><p>重头戏来了，终于可以正而八经地填充数据了。</p><p>数据是一块一块填充的，每一块应该是一个矩形（比较理想的情况），一块有8个bit正好对应一个Codeword。举个例子，Version2的数据填充应该是这个样子：</p><p><img src="/images/v2.png"></p><p>看起来是不是有点复杂？</p><p>我们看到D1~D9都是正常的矩形，其他的就什么情况都有了，下面来具体看看每一小块该怎么填。</p><p>每一种数据块的填充都有两种模式，分别是上升和下降，先看普通的矩形：</p><p><img src="/images/rect.png"></p><p>注意，这里面的第0位是每个Codeword的最低位（the least significant bit），而第7位是最高位（the most significant bit），不要搞错了。</p><p>由于我们需要折返着填，所以在转向的时候可能出现下面的情况：</p><p><img src="/images/turn.png"></p><p>而且我们填充的时候还不能替换了功能区的值，所以还要绕过去：</p><p><img src="/images/go.png"></p><p>就这几种情况，看上去有点复杂，编程不好实现，但实际上自己只要实际写写看就会发现填充规律是<strong>相同</strong>的：从右下角开始沿着红线填我们的各个bits，1是黑色，0是白色。如果遇到了上面的非数据区，则绕开或跳过。</p><p><img src="/images/Data-Placement.png"></p><p>画完如下：</p><p><img src="/images/draw_data.png"></p><p><strong>Mask</strong></p><p>这样下来，我们的图就填好了，但是，也许那些点并不均衡，如果出现大面积的空白或黑块，会告诉我们扫描识别的困难。所以，我们还要做Masking操作。QR Code Spec中说了，QR码有8个Mask你可以使用，如下所示：</p><p><img src="/images/mask.png"></p><p>每个图下面的数字标识符，公式是对应的条件，当条件满足时，该点是黑的。</p><p>生成好相应mask之后，就和原始填充好的图案进行异或操作，注意mask不能和功能区异或，只能和数据区进行异或。</p><p>Mask过后的二维码就成最终的图了：</p><p><img src="/images/draw_mask.png"></p><h2><span id="实践">实践</span></h2><p>根据上面的流程再加上QR Code Spec，我们就可以编码实现生成二维码了！</p><p>这里附上我做的<a href="https://github.com/NeymarL/qr-code" target="_blank" rel="noopener">demo</a>。</p><p><img src="/images/github.png"></p><h2><span id="参考">参考</span></h2><p><a href="http://www.codeplex.com/Download?ProjectName=qrcodenet&amp;DownloadId=284291" target="_blank" rel="noopener">ISO/IEC 18004:2000(E) - QR code specification </a></p><p><a href="http://coolshell.cn/articles/10590.html" target="_blank" rel="noopener">二维码的生成细节和原理</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> QR Code </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Paper Reading - Context Encoder</title>
      <link href="/2016/10/23/Context%20Encoder/"/>
      <url>/2016/10/23/Context%20Encoder/</url>
      
        <content type="html"><![CDATA[<p>前两天看了一下Context Encoder的相关论文，这个东西可以用于理解图片的语义，比如<strong>填补图片的缺失区域</strong>。我只研究出了它大概怎么做的，有些细节还没搞懂，以此记录一下。</p><a id="more"></a><h2><span id="overall">Overall</span></h2><p>整体网络由两部分构成，分别是编码器(Encoder)和解码器(Decoder)，中间由Channel-wise fully-connected layer 连接，如下图所示。</p><p><img src="/images/CD-structure.png"></p><h2><span id="encoder">Encoder</span></h2><p>编码器用于从图片提取高维特征，其结构来自 <em>AlexNet</em> 的前5个卷积层和相应的池化层(<em>pool5</em>)，并随机初始化权重。</p><h2><span id="channel-wise-fully-connected-layer">Channel-wise fully-connected layer</span></h2><p>为了能综合各个 feature map 的信息，通常是用全连接层(fully-connected layer)来做，但是这么做的话参数太多了，训练比较困难，于是就采用分组的策略。</p><p>假设有 <span class="math inline">\(m\)</span> 个 feature map，每个feature map的大小是 <span class="math inline">\(n*n\)</span>，该层输出也是 <span class="math inline">\(m\)</span> 个 feature map，每个大小为 <span class="math inline">\(n*n\)</span>， 但是与全连接不同的是，每个feature map 只和自己全连接，不和其他feature map连接，这样的话需要的参数是 <span class="math inline">\(mn^4\)</span>，相较于全连接层的 <span class="math inline">\(m^2n^4\)</span>。</p><h2><span id="decoder">Decoder</span></h2><p>解码器是使用编码器的特征生成缺失的图像。生成图像使用 <em>up-convolutinal/upsampling layers</em>，每层后跟一个线性整流(ReLU)层。</p><p>up-convolutinal可以被理解为先反池化再卷积(<em>unpooling+convolution</em>)。反池化就是池化的逆过程，把一个大小为 <span class="math inline">\(s*s\)</span> 的feature map反池化，只需把每个像素变为 <span class="math inline">\(s*s\)</span> 的像素块，只有每个块左上脚的像素和原来一样，其他值为0，如 <span class="math inline">\(s = 2\)</span> 的反池化如下图(左)所示：</p><p><img src="/images/unpooling.png"></p><p>它还可以被理解成是步长(stride)为小数的卷积层：正常的卷积层步长为一个整数 <span class="math inline">\(f\)</span>，那么逆卷积层(<em>deconvolutin/up-convolutinal layers</em>) 就相当于是步长为 <span class="math inline">\(\frac{1}{f}\)</span> 的卷积层。实现逆卷积层的一个自然办法就是实现一个步长为 <span class="math inline">\(f\)</span> 的向后卷积(<em>backwards convolution</em>)，只用简单地 reverses the forward and backward passes of convolution(论文里这么写的，不是很懂什么意思)。</p><p>解码可以通过添加一系列这样的 <em>upsampling layers</em> 实现，直到生成的图像达到目标大小。</p><h2><span id="loss-function">Loss function</span></h2><p>整个网络的损失函数由两部分组成，一部分是重建损失(<em>reconstruction loss</em>)，另一部分是对抗损失(<em>adversarial loss</em>)。</p><p><strong>重建损失</strong>是一个L2损失，为了捕获缺失区域的整体结构并且保持上下文的连续性，但是L2损失在预测时趋向于均值，如果只用L2损失，预测出来就非常模糊，如下图(c)所示。<strong>对抗损失</strong>就是为了使预测结果更加真实，它有从分布中挑选出一个特定模式的效果。</p><p><img src="/images/loss.png"></p><p>对于每个图片 <span class="math inline">\(x\)</span>，送给整个编码器 <span class="math inline">\(F\)</span> 去训练，产生最终结果记为 <span class="math inline">\(F(x)\)</span>。令 <span class="math inline">\(\hat{M}\)</span> 为一个二进制掩码矩阵，图片的缺失区域值为1，其他区域为0 。那么我们实际送给编码器训练的图片就是 <span class="math inline">\((1-\hat{M})\odot x\)</span> ，其中 <span class="math inline">\(\odot\)</span> 为按位相乘。</p><p><strong>Reconstruction Loss</strong></p><p>那么重建损失的表达式就为： <span class="math display">\[L_{rec}(x) = ||\hat{M}\odot(x-F((1-\hat{M})\odot x))||^2_2\]</span> 论文中说使用L1损失和L2损失差别不大。尽管这个损失很简单，但它能促使解码器生成预测目标的大致轮廓，一般不能生成高频的细节，如上图(c)所示。我们觉得出现这种情况是因为预测一个分布的平均值对L2损失来说更加“安全”，因为这样能最小化每个像素的平均误差，但这样就会导致模糊的结果。</p><p><strong>Adverarial Loss</strong></p><p>为了减轻上面的问题，我们又加了一个对抗损失。</p><p>对抗损失基于 <em>Generative Adversarial Networks(GAN)</em>，原始GAN是这样的：为了一个使<strong>生成模型</strong> <span class="math inline">\(G\)</span> 学习某种数据分布，GAN同时训练一个与之对抗的<strong>判别模型</strong> <span class="math inline">\(D\)</span> 来提供 <span class="math inline">\(G\)</span> 的损失。<span class="math inline">\(G\)</span> 和 <span class="math inline">\(D\)</span> 都是 parametric function，其中 <span class="math inline">\(G\)</span> 是一个从噪声分布 <span class="math inline">\(Z\)</span> 到数据分布 <span class="math inline">\(\chi\)</span> 的映射。学习过程就是判别模型 <span class="math inline">\(D\)</span> 接收 <span class="math inline">\(G\)</span> 的输出和真实样例作为输入，并尝试区分它们，输出哪个是真实样本哪个是生成出来的，而 <span class="math inline">\(G\)</span> 的目标就是通过输出结果尽可能接近“真实”来混淆 <span class="math inline">\(D\)</span> 的判断。</p><p>所以 GAN 的目标就为： <span class="math display">\[\min_G\max_D E_{x\in \chi}[\log(D(x))] + E_{z\in Z}[\log(1-D(G(z)))]\]</span> 这里边的 <span class="math inline">\(E\)</span> 是什么意思没有搞懂，感觉不像是数学期望的意思。如果把 <span class="math inline">\(G\)</span> 和 <span class="math inline">\(D\)</span> 的目标分开来写的话，那 <span class="math inline">\(D\)</span> 的目标就是： <span class="math display">\[\max_D E_{x\in \chi}[\log(D(x))] + E_{z\in Z}[\log(1-D(G(z)))]\]</span> <span class="math inline">\(G\)</span> 的目标是： <span class="math display">\[\max_G E_{z\in Z}[\log(D(G(z)))]\]</span> 回到我们的问题，所以 context encoder 的对抗损失就是： <span class="math display">\[L_{adv} = \max_D E_{x\in \chi}[\log(D(x)) + \log(1-D(F((1-\hat{M})\odot x)))]\]</span> 这个目标使得整个编码器的输出看起来更加真实。</p><p><strong>Joint Loss</strong></p><p>所以整体的损失函数就定义为： <span class="math display">\[L = \lambda_{rec}L_{rec} + \lambda_{adv}L_{adv}\]</span> 在填补图片缺失区域这个问题中，超参数的选择分别为 <span class="math inline">\(\lambda_{rec} = 0.99\)</span> 和 <span class="math inline">\(\lambda_{adv} = 0.01\)</span>。</p><p>整个模型的大概怎么做的就是这样了，具体细节还需要在看论文和代码。</p><p>附：</p><p><img src="/images/network.png"></p><p>​ 针对Inpainting任务的具体模型</p><h2><span id="reference">Reference</span></h2><p><a href="https://arxiv.org/pdf/1604.07379v1" target="_blank" rel="noopener">Context Encoders: Feature Learning by Inpainting</a></p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi5yYCF4O7PAhUJlZQKHc1wB-YQFggvMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1406.2661&amp;usg=AFQjCNErq4Snyx25yb_clgYjWGAiFMYkow&amp;sig2=4ULZmy8sVRVUdboTQI-aKw" target="_blank" rel="noopener">I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NIPS, 2014.</a></p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi79s6p4O7PAhUHspQKHfVzC2IQFggwMAE&amp;url=https%3A%2F%2Farxiv.org%2Fpdf%2F1411.5928&amp;usg=AFQjCNGPEI4w9KrBWZcicHemUf7CaHwZOw&amp;sig2=M2UUrea6sVMh7z5WUoxK_g" target="_blank" rel="noopener">A. Dosovitskiy, J. T. Springenberg, and T. Brox. Learning togenerate chairs with convolutional neural networks. CVPR,2015.</a></p><p><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html" target="_blank" rel="noopener">J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015</a></p><p><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjFnubk4O7PAhXBmpQKHcnVBWkQFggfMAA&amp;url=https%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&amp;usg=AFQjCNFlGsSmTUkJw0gLJ0Ry4cm961B7WA&amp;sig2=_qDaDLGSlvAoxbyfkxLeGA" target="_blank" rel="noopener">A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classification with deep convolutional neural networks. In NIPS, 2012</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CV </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Random sample consensus</title>
      <link href="/2016/10/15/ransac/"/>
      <url>/2016/10/15/ransac/</url>
      
        <content type="html"><![CDATA[<p>随机抽样一致（<strong>Random sample consensus</strong> ，<strong>RANSAC</strong>）是一种迭代方法，用来排除异常数据（outliers）对模型的影响。</p><p>这个算法基于一个基本假设：数据集中正常的样本（inliers）可以很好地拟合给定模型，异常数据则不行，比如异常样本代入模型损失会很大。</p><a id="more"></a><h2><span id="algorithm">Algorithm</span></h2><p>算法主要分为两步：</p><ol type="1"><li>从全部数据集中随机抽取一小部分，我们假设这部分数据都是正常的，用这部分数据训练模型。采样集的大小是能训练模型的最小样本数。</li><li>用这个模型测试其他剩余样本，如果某个样本的损失小于某个阈值，则认为它是和抽样出的样本是一致的，即也是正常样本；若某个样本的损失大于阈值，则认为它是异常样本。</li></ol><p>所有正常样本的集合叫做一致集（consensus set），重复上面两个步骤，直到找到一致集中包含足够多的样本或者到达最大循环次数。</p><p>具体描述：</p><ol type="1"><li>从原始数据中采样出一个子集，假设为正常样本集。</li><li>用上述子集训练模型</li><li>用其他样本测试该模型。对于拟合很好的样本点，可以通过损失小于某一阈值来判断，把它加入一致集。</li><li>如果一致集的样本有足够多的样本，则认为该模型很好，拟合了大部分正常样本。</li><li>然后，用一致集和采样集中的样本重新训练模型，这也许会进一步提升模型的效果，如果整体损失比上次迭代小，则更新最佳拟合模型。</li><li>重复步骤1～5，直到一致集样本足够多或者达到最大迭代次数，返回最佳拟合模型。</li></ol><p>伪代码：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Given:</span><br><span class="line">    data – a set of observed data points</span><br><span class="line">    model – a model that can be fitted to data points</span><br><span class="line">    n – the minimum number of data values required to fit the model</span><br><span class="line">    k – the maximum number of iterations allowed in the algorithm</span><br><span class="line">    t – a threshold value <span class="keyword">for</span> determining when a data point fits a model</span><br><span class="line">    d – the number of close data values required to assert that a model fits well to data</span><br><span class="line"></span><br><span class="line">Return:</span><br><span class="line">    bestfit – model parameters which best fit the data (or nul <span class="keyword">if</span> no good model is found)</span><br><span class="line"></span><br><span class="line">iterations = <span class="number">0</span></span><br><span class="line">bestfit = nul</span><br><span class="line">besterr = something really large</span><br><span class="line"><span class="keyword">while</span> iterations &lt; k &#123;</span><br><span class="line">    maybeinliers = n randomly selected values from data</span><br><span class="line">    maybemodel = model parameters fitted to maybeinliers</span><br><span class="line">    alsoinliers = empty set</span><br><span class="line">    <span class="keyword">for</span> every point in data not in maybeinliers &#123;</span><br><span class="line">        <span class="keyword">if</span> point fits maybemodel with an error smaller than t</span><br><span class="line">             add point to alsoinliers</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> the number of elements in alsoinliers is &gt; d &#123;</span><br><span class="line">        <span class="comment">% this implies that we may have found a good model</span></span><br><span class="line">        <span class="comment">% now test how good it is</span></span><br><span class="line">        bettermodel = model parameters fitted to all points in maybeinliers and alsoinliers</span><br><span class="line">        thiserr = a measure of how well model fits these points</span><br><span class="line">        <span class="keyword">if</span> thiserr &lt; besterr &#123;</span><br><span class="line">            bestfit = bettermodel</span><br><span class="line">            besterr = thiserr</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    increment iterations</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> bestfit</span><br></pre></td></tr></table></figure><p>Python代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ransac</span><span class="params">(data, model, n, k, t, d)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    data – a set of observed data points</span></span><br><span class="line"><span class="string">    model – a model that can be fitted to data points</span></span><br><span class="line"><span class="string">    n – the minimum number of data values required </span></span><br><span class="line"><span class="string">    to fit the model</span></span><br><span class="line"><span class="string">    k – the maximum number of iterations allowed </span></span><br><span class="line"><span class="string">    in the algorithm</span></span><br><span class="line"><span class="string">    t – a threshold value for determining </span></span><br><span class="line"><span class="string">    when a data point fits a model</span></span><br><span class="line"><span class="string">    d – the number of close data values required to </span></span><br><span class="line"><span class="string">    assert that a model fits well to data</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        bestfit – model parameters which best fit the data </span></span><br><span class="line"><span class="string">          (or nul if no good model is found)</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    train_data_x = [[data[<span class="number">0</span>][i]] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data[<span class="number">0</span>]))]</span><br><span class="line">    train_data_y = data[<span class="number">1</span>]</span><br><span class="line">    iterations = <span class="number">0</span></span><br><span class="line">    bestfit = <span class="number">0</span></span><br><span class="line">    besterr = <span class="number">10000</span></span><br><span class="line">    <span class="keyword">while</span> iterations &lt; k:</span><br><span class="line">        indexes = [rnd.randrange(<span class="number">0</span>, len(data[<span class="number">0</span>])) </span><br><span class="line">                   <span class="keyword">for</span> i <span class="keyword">in</span> range(n)]</span><br><span class="line">        maybeinliners_x = [train_data_x[i] <span class="keyword">for</span> i <span class="keyword">in</span> indexes]</span><br><span class="line">        maybeinliners_y = [train_data_y[i] <span class="keyword">for</span> i <span class="keyword">in</span> indexes]</span><br><span class="line">        maybemodel = model.fit(maybeinliners_x,</span><br><span class="line">                               maybeinliners_y)</span><br><span class="line">        alsoinliers = set()</span><br><span class="line">        predict = maybemodel.predict(train_data_x)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(train_data_x)):</span><br><span class="line">            points_x = train_data_x[i]</span><br><span class="line">            <span class="keyword">if</span> points_x <span class="keyword">not</span> <span class="keyword">in</span> maybeinliners_x:</span><br><span class="line">                data_loss = loss(train_data_y[i], predict[i])</span><br><span class="line">                <span class="keyword">if</span> data_loss &lt; t:</span><br><span class="line">                    alsoinliers.add((points_x[<span class="number">0</span>],</span><br><span class="line">                                     train_data_y[i]))</span><br><span class="line">        <span class="keyword">if</span> len(alsoinliers) &gt; d:</span><br><span class="line">            <span class="comment"># this implies that we may have found a good model</span></span><br><span class="line">            <span class="comment"># now test how good it is</span></span><br><span class="line">            inliers_x = [[point[<span class="number">0</span>]] <span class="keyword">for</span> point <span class="keyword">in</span> alsoinliers]</span><br><span class="line">            inliers_y = [point[<span class="number">1</span>] <span class="keyword">for</span> point <span class="keyword">in</span> alsoinliers]</span><br><span class="line">            inliers_x.extend(maybeinliners_x)</span><br><span class="line">            inliers_y.extend(maybeinliners_y)</span><br><span class="line">            bettermodel = model.fit(inliers_x, inliers_y)</span><br><span class="line">            predict = maybemodel.predict(inliers_x)</span><br><span class="line">            thiserr = np.sqrt(np.average(</span><br><span class="line">                (inliers_y - predict) ** <span class="number">2</span>))</span><br><span class="line">            <span class="keyword">if</span> thiserr &lt; besterr:</span><br><span class="line">                besterr = thiserr</span><br><span class="line">                bestfit = bettermodel</span><br><span class="line">        iterations = iterations + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> bestfit</span><br></pre></td></tr></table></figure><h2><span id="demo">DEMO</span></h2><p>生成了一部分可以用直线拟合的数据和一些随机噪声，比例为 <span class="math inline">\(1:1\)</span> ，如下图所示：</p><p><img src="/images/dataset.png"></p><p>用线性回归直接拟合和RANSAC算法的结果：</p><p><img src="/images/good.png"></p><h2><span id="parameters">Parameters</span></h2><p>RANSAC算法中有几个超参数需要调试：</p><ul><li><p>t, d : 这两个参数需要根据应用和数据集来调节</p></li><li><p>k（最大迭代次数）：可以从理论上确定。</p><p>定义 <span class="math inline">\(p\)</span> 是RANSAC算法在某次迭代采样时只采样到正常样本的概率。如果这真的发生了，那么这次迭代将训练出一个很好的模型，所以 <span class="math inline">\(p\)</span> 也代表了RANSAC算法得出一个好结果的概率。再定义 <span class="math inline">\(w\)</span> 为每次采样时，采到一个正常点的概率，即 <span class="math inline">\(w\)</span> =  number of inliers in data / number of points in data。假设一次采样选取 <span class="math inline">\(n\)</span> 的样本，那么这次采样选择的样本全部都是正常样本的概率为 <span class="math inline">\(w^n\)</span>（假设为放回采样），至少选择一个异常样本的概率就为 <span class="math inline">\(1-w^n\)</span>。总共迭代 <span class="math inline">\(k\)</span> 次，那么这 <span class="math inline">\(k\)</span> 次采样都至少有一个异常样本的概率为：<span class="math inline">\((1-w^n)^k\)</span>，应该等于 <span class="math inline">\(1-p\)</span>，即 <span class="math display">\[1-p=(1-w^n)^k\]</span> 两边同时取对数得： <span class="math display">\[k = \frac{\log(1-p)}{\log(1-w^n)}\]</span> 实际上我们是不放回采样，所以还要在上面的基础上加上 <span class="math inline">\(k\)</span> 的标准差。<span class="math inline">\(k\)</span> 的标准差定义为： <span class="math display">\[SD(k) = \frac{\sqrt{1-w^n}}{w^n}\]</span></p></li></ul><h2><span id="advantages-and-disadvantages">Advantages and disadvantages</span></h2><p>优势：</p><ul><li>可以做模型参数的 <a href="https://www.wikiwand.com/en/Robust_statistics" target="_blank" rel="noopener">robust estimation</a></li></ul><p>劣势：</p><ul><li><p>没有时间上界，即不会自然收敛，只能靠最大迭代次数限制。有时可能最后一次迭代才找到一个好的模型，有时可能第一次就找到了</p></li><li><p>需要根据不同问题手动调试参数（一些阈值）</p></li><li><p>只能同时评估一种模型</p></li><li><p>不是所有时候都能找到合适的模型，尤其是在异常样本个数大于 50% 的时候，如下图所示：</p></li></ul><p><img src="/images/bad.png"></p><p>​</p><h2><span id="参考">参考</span></h2><p><a href="https://www.wikiwand.com/en/Random_sample_consensus" target="_blank" rel="noopener">Random sample consensus</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Statistics </tag>
            
            <tag> RANSAC </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>隐马尔科夫模型（HMM）</title>
      <link href="/2016/10/02/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88HMM%EF%BC%89/"/>
      <url>/2016/10/02/%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B%EF%BC%88HMM%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p>隐马尔科夫模型(HMM, Hidden Markov Model)可用标注问题，在语音识别、NLP、生物信息、模式识别等领域被实践证明是有效的算法。</p><!-- toc --><ul><li><a href="#前言">前言</a><ul><li><a href="#hmm定义">HMM定义</a></li><li><a href="#马尔可夫链">马尔可夫链</a></li></ul></li><li><a href="#hmm的确定">HMM的确定</a></li><li><a href="#hmm的3个基本问题">HMM的3个基本问题</a><ul><li><a href="#概率计算">概率计算</a><ul><li><a href="#暴力算法">暴力算法</a></li><li><a href="#前向-后向算法">前向－后向算法</a></li></ul></li><li><a href="#学习算法">学习算法</a><ul><li><a href="#监督学习">监督学习</a></li><li><a href="#baum-welch-算法">Baum-Welch 算法</a></li></ul></li><li><a href="#预测算法">预测算法</a><ul><li><a href="#近似算法">近似算法</a></li><li><a href="#viterbi算法">Viterbi算法</a></li></ul></li></ul></li><li><a href="#总结">总结</a></li><li><a href="#参考">参考</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="前言">前言</span></h2><h3><span id="hmm定义">HMM定义</span></h3><p>隐马尔可夫模型（HMM）是关于时序的概率模型，描述由一个隐藏的马尔可夫链生成不可预测的状态随机序列，再由各个状态生成观测随机序列的过程。</p><p><img src="/images/1475388928648.png"></p><p>​ 图1. 隐马尔可夫模型的图结构</p><p>图1中的 <span class="math inline">\(z_1, z_2 … z_{n+1}\)</span> 是 <span class="math inline">\(n+1\)</span> 个不可观测状态，由马尔可夫链连接，称为<strong>状态序列</strong>；<span class="math inline">\(x_1, x_2, …, x_{n+1}\)</span> 是由状态序列生成的观测随机序列，称为<strong>观测序列</strong>。其中，序列中的每个位置可以看作是一个<strong>时刻</strong>。</p><h3><span id="马尔可夫链">马尔可夫链</span></h3><p>下面的介绍摘自Wikipedia：</p><blockquote><p><strong>马尔可夫链</strong>（英语：Markov chain），又称<strong>离散时间马可夫链</strong>（discrete-time Markov chain，缩写为<strong>DTMC</strong>），因俄国数学家<a href="https://www.wikiwand.com/zh-hans/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB" target="_blank" rel="noopener">安德烈·马尔可夫</a>（俄语：Андрей Андреевич Марков）得名，为<a href="https://www.wikiwand.com/zh-hans/%E7%8B%80%E6%85%8B%E7%A9%BA%E9%96%93_(%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8)" target="_blank" rel="noopener">状态空间</a>中经过从一个状态到另一个状态的转换的<a href="https://www.wikiwand.com/zh-hans/%E9%9A%8F%E6%9C%BA%E8%BF%87%E7%A8%8B" target="_blank" rel="noopener">随机过程</a>。该过程要求具备“无记忆”的性质：下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的“无记忆性”称作<a href="https://www.wikiwand.com/zh-hans/%E9%A6%AC%E5%8F%AF%E5%A4%AB%E6%80%A7%E8%B3%AA" target="_blank" rel="noopener">马可夫性质</a>。马尔科夫链作为实际过程的统计模型具有许多应用。</p><p>在马尔可夫链的每一步，系统根据概率分布，可以从一个状态变到另一个状态，也可以保持当前状态。状态的改变叫做转移，与不同的状态改变相关的概率叫做转移概率。<a href="https://www.wikiwand.com/zh-hans/%E9%9A%8F%E6%9C%BA%E6%BC%AB%E6%AD%A5" target="_blank" rel="noopener">随机漫步</a>就是马尔可夫链的例子。随机漫步中每一步的状态是在图形中的点，每一步可以移动到任何一个相邻的点，在这里移动到每一个点的概率都是相同的（无论之前漫步路径是如何的）。</p></blockquote><p>回到我们的模型中，由于 <span class="math inline">\(z_1, z_2, …, z_{n+1}\)</span> 是一条马尔可夫链，所以链中某一状态 <span class="math inline">\(z_i\)</span> 发生的概率只与 <span class="math inline">\(z_{i-1}\)</span> 有关，表达成公式就是：</p><p><span class="math display">\[P(Z_i = z_i|Z_{i-1}=z_{i-1}, Z_{i-2}=z_{i-2}, …, Z_1 = z_1) = P(Z_i = z_i|Z_{i-1} = z_{i-1})\]</span></p><p>还有一点就是，由于 <span class="math inline">\(z_2\)</span> 和 <span class="math inline">\(x_1\)</span> 都是由 <span class="math inline">\(z_1\)</span> “生成”出来的，所以在不知道 <span class="math inline">\(z_1\)</span> 的情况下， <span class="math inline">\(x_1\)</span> 和 <span class="math inline">\(z_2\)</span> 是<strong>不</strong>独立的；由于 <span class="math inline">\(x_2\)</span> 是由 <span class="math inline">\(z_2\)</span> 生成的，若把 <span class="math inline">\(x_2\)</span> 和 <span class="math inline">\(z_2\)</span> 看成一个整体，那么这个整体与 <span class="math inline">\(x_1\)</span> 也是<strong>不</strong>独立的；所以在 <span class="math inline">\(z_1\)</span>, <span class="math inline">\(z_2\)</span> 都不可观察（未知）的前提下，<span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span> <strong>不相互独立</strong>。</p><p>这一点与其它机器学习算法比如 Logistic Regression, SVM, Decision Tree 等都不一样，那些算法都是假设每个样本相互独立，而HMM就恰恰相反，要求样本间有某种联系。就拿中文分词来举例，正常人说的每一句话里，前一个字和后一个字都应该是<strong>有联系的</strong>，有的联系很紧密，我们把它认为是一个词语，有的联系不那么强，我们认为是词与词之间的分隔，显然每个字之间都不是独立的。这也就解释了为什么HMM可以用做中文分词而那些算法不可以。</p><h2><span id="hmm的确定">HMM的确定</span></h2><p>HMM由初始概率分布 <span class="math inline">\(\pi\)</span>，状态转移概率分布 <span class="math inline">\(A\)</span> 以及观测概率分布 <span class="math inline">\(B\)</span> 确定，把它们三个合起来表示成 <span class="math inline">\(\lambda\)</span>，即：<span class="math display">\[\lambda = (A, B, \pi)\]</span></p><p>分别来解释一下这三个都是什么东西。</p><p>定义 <span class="math inline">\(Q\)</span> 为所有可能的状态的集合，<span class="math inline">\(N\)</span> 是所有可能的状态数，即 <span class="math inline">\(Q=\{q_1, q_2, …, q_N\}\)</span>。</p><ul><li>对于中文分词的例子来说，可能的状态只有两个：<span class="math inline">\(0, 1\)</span>，<span class="math inline">\(0\)</span> 表示这个字不是这个词的最后一个字，<span class="math inline">\(1\)</span> 表示这个字是这个词的末尾，该分割了。所以 <span class="math inline">\(Q = \{0, 1\}, N = 2\)</span>。</li></ul><p>定义 <span class="math inline">\(V\)</span> 是所有可能的观测的集合，<span class="math inline">\(M\)</span> 是可能的观测数，即 <span class="math inline">\(V = \{v_1, v_2, …, v_M\}\)</span></p><ul><li>对于中文分词的例子来说，<span class="math inline">\(V\)</span> 就是语料库里的所有字，而汉字在计算机里实际是用编码表示的，若是两字节编码，则只有 <span class="math inline">\(2^{16} = 65536\)</span> 种情况，所以 <span class="math inline">\(M = 65536\)</span>。</li></ul><p>再定义 <span class="math inline">\(I\)</span> 是长度为 <span class="math inline">\(T\)</span> 的状态序列，<span class="math inline">\(O\)</span> 是对应的观测序列，即：<span class="math inline">\(I = \{i_1, i_2, …, i_T\}\ \ O = \{o_1, o_2, …, o_T\}\)</span>。</p><ul><li>状态序列 <span class="math inline">\(I\)</span> 对应图1中的 <span class="math inline">\(z_1, z_2, …, z_n\)</span>，观测序列 <span class="math inline">\(O\)</span> 对应图1的 <span class="math inline">\(x_1, x_2, … , x_n\)</span>，只不过换了个名字。</li></ul><p><strong>状态转移概率分布<span class="math inline">\(A\)</span></strong></p><p>状态转移概率是个什么东西呢，其实就是从一个状态转移到另一个状态的概率，具体来说就是 <span class="math inline">\(t\)</span> 时刻的隐状态处于状态 <span class="math inline">\(q_i\)</span>，即 <span class="math inline">\(i_t = q_i\)</span> 的条件下，<span class="math inline">\(t+1\)</span> 时刻隐状态转换到状态 <span class="math inline">\(q_j\)</span>，即 <span class="math inline">\(i_{t+1} = q_j\)</span> 的概率，这个就是从 <span class="math inline">\(q_i\)</span> 转换到 <span class="math inline">\(q_j\)</span> 的转移概率，定义为 <span class="math inline">\(a_{ij}\)</span>，那么它的公式就是：<span class="math inline">\(a_{ij} = P(i_{t+1} = q_j|i_t=q_i)\)</span>。</p><p>我们总共有 <span class="math inline">\(N\)</span> 的可能的状态，每个状态都有一定的概率转移到其它的状态，所以状态转移概率应该有 <span class="math inline">\(N*N\)</span> 个，为方便表示，我们把它写成一个 <span class="math inline">\(N*N\)</span> 的矩阵，定义为 <span class="math inline">\(A\)</span>，也就是<strong>状态转移概率分布</strong>，也叫<strong>状态转移概率矩阵</strong>。</p><p><span class="math display">\[A = [a_{ij}]_{N*N}\]</span>，其中 <span class="math inline">\(a_{ij} = P(i_{t+1} = q_j|i_t = q_i)\)</span></p><p><strong>观测概率分布 <span class="math inline">\(B\)</span> </strong></p><p>观测概率又是什么鬼呢，其实也很简单，就是由隐状态 <span class="math inline">\(i_t\)</span> 生成观测 <span class="math inline">\(o_t\)</span> 的概率，具体来说就是时刻 <span class="math inline">\(t\)</span> 处于状态 <span class="math inline">\(q_i\)</span>，即 <span class="math inline">\(i_t = q_i\)</span> 的条件下，生成观测 <span class="math inline">\(v_k\)</span> 的概率，记为 <span class="math inline">\(b_{ik}\)</span>，写成公式就是 <span class="math inline">\(b_{ik} = P(o_t = v_k|i_t=q_i)\)</span>。</p><p>由于每个隐状态有 <span class="math inline">\(N\)</span> 种可能，观测有 <span class="math inline">\(M\)</span> 种可能，所以观测概率应有 <span class="math inline">\(M*N\)</span> 个，为方便表示，我们把它写成一个 <span class="math inline">\(N*M\)</span> 的矩阵，定义为 <span class="math inline">\(B\)</span>，也就是 <strong>观测概率分布</strong>，也叫<strong>观测概率矩阵</strong>，又叫<strong>发射矩阵</strong>或<strong>混淆矩阵</strong>。</p><p><span class="math display">\[B = [b_{ij}]_{N*M}\]</span>，其中 <span class="math inline">\(b_{ik} = P(o_t = v_k|i_t=q_i)\)</span></p><p><strong>初始概率分布 <span class="math inline">\(\pi\)</span></strong></p><p>所谓初始概率就是在 <span class="math inline">\(t = 1\)</span> 时刻选择某一状态的概率。如 <span class="math inline">\(\pi_i\)</span> 是时刻 <span class="math inline">\(t=1\)</span> 处于状态 <span class="math inline">\(q_i\)</span> 的概率，即 <span class="math inline">\(\pi_i = P(i_1 = q_i)\)</span>。</p><p>显然应该有 <span class="math inline">\(N\)</span> 个初始概率，定义 <span class="math inline">\(\pi\)</span> 为<strong>初始概率向量</strong>，共有 <span class="math inline">\(N\)</span> 的元素。</p><p><strong>参数总结</strong></p><p>HMM由<strong>初始概率分布 <span class="math inline">\(\pi\)</span></strong>、<strong>状态转移概率分布<span class="math inline">\(A\)</span></strong> 以及<strong>观测概率分布 <span class="math inline">\(B\)</span> </strong>确定。因此，HMM可以用三元符号表示，称为HMM的三要素：<span class="math inline">\(\lambda = (A, B, \pi)\)</span></p><p><strong>HMM的两个基本性质</strong></p><p>齐次假设： <span class="math display">\[P(i_t|i_{t-1}, o_{t-1}, i_{t-2}, o_{t-2}, …, i_1, o_1) = P(i_t|i_{t-1})\]</span> 观测独立性假设： <span class="math display">\[P(o_t|i_t, i_{t-1}, o_{t-1}, …, i_1, o_1) = P(o_t|i_t)\]</span> 这两个性质或者说假设均来自<a href="#马尔可夫链">马尔可夫链</a>，在前面也略有提到，应该可以理解吧。</p><h2><span id="hmm的3个基本问题">HMM的3个基本问题</span></h2><p>不知道大家看到这里是什么感觉，有没有觉得这个模型很怪，心想：这玩意咋训练？</p><p>反正我刚学到这的时候是有这种感觉的，这也就引出了HMM的3个最重要的问题：<strong>概率计算</strong>、<strong>学习</strong>和<strong>预测</strong>。</p><p>大体来解释一下：</p><ul><li>概率计算问题：给定模型 <span class="math inline">\(\lambda = (A, B, \pi)\)</span> 和观测序列 O = {o_1, o_2, …, o_T}，计算模型 <span class="math inline">\(\lambda\)</span> 下观测序列 <span class="math inline">\(O\)</span> 出现的概率 <span class="math inline">\(P(O|\lambda)\)</span></li><li>学习问题：已知观测序列 <span class="math inline">\(O=\{o_1, o_2, …, o_T\}\)</span>，估计模型 <span class="math inline">\(\lambda=(A, B, \pi)\)</span> 的参数，使得在该模型下观测序列 <span class="math inline">\(P(O|\lambda)\)</span> 最大。</li><li>预测问题：已知模型 <span class="math inline">\(\lambda=(A,B,\pi)\)</span> 和观测序列 <span class="math inline">\(O=\{o_1, o_2, …, o_T\}\)</span>，求给定观测序列条件概率 <span class="math inline">\(P(I|O, \lambda)\)</span> 最大的状态序列 <span class="math inline">\(I\)</span>。</li></ul><h3><span id="概率计算">概率计算</span></h3><p>目标：给定模型 <span class="math inline">\(\lambda = (A, B, \pi)\)</span> 和观测序列 O = {o_1, o_2, …, o_T}，计算模型 <span class="math inline">\(\lambda\)</span> 下观测序列 <span class="math inline">\(O\)</span> 出现的概率 <span class="math inline">\(P(O|\lambda)\)</span>。</p><p>概率计算有三种方法：暴力求解，<strong>前向算法</strong>和<strong>后向算法</strong>，后两者实际上式<strong>动态规划</strong>算法。</p><h4><span id="暴力算法">暴力算法</span></h4><p>算法思想：按照概率公式，列举所有可能的长度为 <span class="math inline">\(T\)</span> 的状态序列 <span class="math inline">\(I = \{i_1, i_2, …, i_T\}\)</span>，求各个状态序列 <span class="math inline">\(I\)</span> 与观测序列 <span class="math inline">\(O=\{o_1, o_2, …, o_T\}\)</span> 的联合概率 <span class="math inline">\(P(O, I|\lambda)\)</span>，然后对所有可能的状态序列求和，从而得到 <span class="math inline">\(P(O|\lambda)\)</span>。</p><p>先求 <span class="math inline">\(P(O, I|\lambda)\)</span>，然后对所有 <span class="math inline">\(I\)</span> 加和即可。</p><p>我们可以把联合概率分解为条件概率的乘积：<span class="math inline">\(P(O, I|\lambda) = P(O|I, \lambda)P(I|\lambda)\)</span></p><p>状态序列 <span class="math inline">\(\{i_1, i_2, …, i_T\}\)</span> 的概率怎么求呢？一步一步来。 <span class="math display">\[\begin{array}{lcl}P(I|\lambda) = P(i_1, i_2, …, i_T|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = P(i_2, …, i_T|\lambda)\cdot P(i_1|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = P(i_2, …, i_T|\lambda)\cdot \pi_{i_1} \\\ \ \ \ \ \ \ \ \ \ \ \ = \pi_{i_1} \cdot P(i_3, ..., i_T|\lambda)P(i_2|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = \pi_{i_1} a_{i_1i_2} \cdot P(i_3, ..., i_T|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = \ .... \\\ \ \ \ \ \ \ \ \ \ \ \ = \pi_{i_1} a_{i_1i_2}a_{i_2i_3}...a_{i_{T-1}i_T}\end{array}\]</span> 同理可以求观测序列的概率： <span class="math display">\[P(O|I, \lambda) = b_{i_1o_1}b_{i_2o_2}...b_{i_To_T}\]</span> 所以 <span class="math inline">\(O\)</span> 和 <span class="math inline">\(I\)</span> 同时出现的联合概率是： <span class="math display">\[P(O,I|\lambda) = P(O|I, \lambda)P(I|\lambda) = \pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}...a_{i_{T-1}i_T}b_{i_ToT}\]</span> 对所有可能的状态序列 <span class="math inline">\(I\)</span> 求和，得到观测序列 <span class="math inline">\(O\)</span> 的概率： <span class="math display">\[P(O|\lambda) = \sum_I P(O, I|\lambda) = \sum_{i_1, i_2, ..., i_T}\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}...a_{i_{T-1}i_T}b_{i_ToT}\]</span> 这样就求解出观测序列 <span class="math inline">\(O\)</span> 的概率，也不是很难，不是吗？</p><p>接下来我们来分析一下这个算法的<strong>时间复杂度</strong>。</p><p>由于要穷举所有 <span class="math inline">\(I\)</span> 的可能性， <span class="math inline">\(I\)</span> 的长度是 <span class="math inline">\(T\)</span>，每个 <span class="math inline">\(i\)</span> 有 <span class="math inline">\(N\)</span> 种可能性，所以总共有 <span class="math inline">\(N^T\)</span> 个 <span class="math inline">\(I\)</span>。计算每个 <span class="math inline">\(I\)</span> 需要做 <span class="math inline">\(2T\)</span> 次乘法，因此，时间复杂度为 <span class="math inline">\(O(TN^T)\)</span>，超级高。</p><h4><span id="前向-后向算法">前向－后向算法</span></h4><p>我们思考一个问题，我们在求最长递增子序列、最大连续子数组或是KMP中next数组的计算，无不用到同一个思想：在前 <span class="math inline">\(k\)</span> 个已知的情况下求第 <span class="math inline">\(k+1\)</span> 个。</p><p>我们借鉴这种优化思想来定义两个概念：前向概率和后向概率。</p><p><img src="/images/1475388965126.png"></p><p>​ 图2:前向概率和后向概率示意图</p><p>定义前向概率 <span class="math inline">\(\alpha_t(i)\)</span> 为 <span class="math inline">\(t\)</span> 时刻下隐状态为 <span class="math inline">\(q_i\)</span> 并且观测到观测序列 <span class="math inline">\(o_1, o_2, …, o_t\)</span> 的概率，即 <span class="math display">\[\alpha_t(i) = P(o_1, o_2, ..., o_t, i_t = q_i|\lambda)\]</span> 其中，<span class="math inline">\(o\)</span> 等于图2中的 <span class="math inline">\(y\)</span>，<span class="math inline">\(i\)</span> 等于图2中的 <span class="math inline">\(q\)</span>，和我们之前的定义相同。</p><p>同理定义后向概率 <span class="math inline">\(\beta_t(i)\)</span> 为已知 <span class="math inline">\(t\)</span> 时刻的状态为 <span class="math inline">\(q_i\)</span>，观测到输出序列为 <span class="math inline">\(o_{y+1}, …, o_T\)</span> 的概率，即： <span class="math display">\[\beta_t(i) = P(o_{t+1}, o_{t+2}, ..., o_T|i_t = q_i, \lambda)\]</span> <strong>前向算法</strong></p><p>思想：递推计算前向概率 <span class="math inline">\(\alpha_t(i)\)</span> 及观测序列概率 <span class="math inline">\(P(O|\lambda)\)</span>。</p><p>初值：<span class="math inline">\(\alpha_1(i) = P(o_1, i_1=q_i|\lambda) = \pi_ib_{io_1}\)</span></p><p>递推：对于 <span class="math inline">\(t = 1, 2, …, T-1\)</span>， <span class="math display">\[\begin{array}{lcl}\alpha_{t+1}(i) = P(o_1, ..., o_{t+1}, i_{t+1}=q_i|\lambda) \\\ \ \ \ \ \ \ \ \ \ \ \ = (\sum_{j=1}^N P(o_1, ..., o_t, i_t=q_j|\lambda) \cdot a_{ji})\cdot b_{io_{t+1}} \\\ \ \ \ \ \ \ \ \ \ \ \ = (\sum_{j=1}^Na_t(j)a_{ji})b_{io_{i+1}}\end{array}\]</span> 最终：<span class="math inline">\(P(O|\lambda) = \sum_{i=1}^N\alpha_T(i)\)</span></p><p>我们再分析一下该算法的复杂度，每计算一个 <span class="math inline">\(\alpha_T(i)\)</span> 需要 <span class="math inline">\(T\)</span> 次迭代，每次迭代需要计算约 <span class="math inline">\(N\)</span> 次乘法，共计算 <span class="math inline">\(N\)</span> 次，因此，前向算法的时间复杂度为 <span class="math inline">\(O(N^2T)\)</span>。</p><p>相比于暴力求解，通过递推的方式大大降低了时间复杂度，原因在于暴力求解重复计算了好多东西，而递推公式每一步都可以利用上一步的结果。</p><p><strong>后向算法</strong></p><p>思想：和前向算法类似，也是递推的思想。</p><p>初值：<span class="math inline">\(\beta_T(i) = 1\)</span></p><p>递推：对于 <span class="math inline">\(t = T-1, T-2, …, 1\)</span> <span class="math display">\[\begin{array}{lcl}\beta_t(i) = P(o_{t+1}, ..., o_T|i_t = q_i, \lambda) \\\ \ \ \ \ \ \ \ = \sum_{j=1}^N(P(o_{t+2}, ..., o_T|i_{t+1}=q_j, \lambda) \cdot a_{ji}b_{jo_{t+1}}) \\\ \ \ \ \ \ \ \ = \sum_{j=1}^N(a_{ji}b_{jo_{t+1}}\beta_{t+1}(j))\end{array}\]</span> 最终：<span class="math inline">\(P(O|\lambda) = \sum_{i=1}^N\pi_ib_{io_1}\beta_1(i)\)</span></p><p>同理后向算法的时间复杂度也是 <span class="math inline">\(O(N^2T)\)</span>。</p><p><strong>前后向关系</strong></p><p>我们计算一下观测到观测序列 <span class="math inline">\(O\)</span> 并且 <span class="math inline">\(t\)</span> 时刻的状态为 <span class="math inline">\(q_i\)</span> 的概率： <span class="math display">\[\begin{array}{lcl}\ \ \ \ P(i_t = q_i, O|\lambda) \\= P(O|i_t = q_i, \lambda)P(i_t = q_i|\lambda)\\= P(o_1, ..., o_t, o_{t+1}, ...., o_T|i_t=q_i,\lambda)P(i_t=q_i|\lambda)\\= P(o_1, ..., o_t|i_t=q_i, \lambda)P(o_{i+1}, ..., o_T|i_t=q_i,\lambda)P(i_t=q_i|\lambda)\\= P(o_1, ..., o_t, i_t=q_i|\lambda)P(o_{i+1}, ..., o_T|i_t=q_i,\lambda)\\= \alpha_t(i)\beta_t(i)\end{array}\]</span> 正好等于 <span class="math inline">\(\alpha\)</span> 和 <span class="math inline">\(\beta\)</span> 的乘积，是不是很有意思。</p><p><strong>单个状态的概率</strong></p><p>我们定义单个状态的概率为 <span class="math inline">\(\gamma_t(i)\)</span>，即给定模型 <span class="math inline">\(\lambda\)</span> 和观测 <span class="math inline">\(O\)</span>，在时刻 <span class="math inline">\(t\)</span> 处于状态 <span class="math inline">\(q_i\)</span> 的概率，写成公式就是： <span class="math display">\[\gamma_t(i) = P(i_t = q_i|O, \lambda)\]</span> 用上前面的结论进一步推导一下： <span class="math display">\[\gamma_t(i) = P(i_t=q_i|O,\lambda)=\frac{P(i_t=q_i,O|\lambda)}{P(O|\lambda)}=\frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^N\alpha_t(i)\beta_t(i)}\]</span> 所以求它为了干嘛？？？</p><p>当然是有用的了，我们想想 <span class="math inline">\(\gamma_t(i)\)</span> 代表了啥，是给定模型 <span class="math inline">\(\lambda\)</span> 和观测 <span class="math inline">\(O\)</span>，在时刻 <span class="math inline">\(t\)</span> 处于状态 <span class="math inline">\(q_i\)</span> 的概率。那我们可以把时刻 <span class="math inline">\(t\)</span> 处于所有状态的概率都求出来，然后取一个最大的作为预测值，对所有时刻都这么做，从而得到一个状态序列 <span class="math inline">\(I^*=\{i_1^*, i_2^*, …, i_T^*\}\)</span>，将它作为预测结果，这不就解决了预测问题吗！</p><p><strong>两个状态的联合概率</strong></p><p>定义两个状态的联合概率 <span class="math inline">\(\xi_t(i,j)\)</span> 为给定模型 <span class="math inline">\(\lambda\)</span> 和观测 <span class="math inline">\(O\)</span>，在时刻 <span class="math inline">\(t\)</span> 处于状态 <span class="math inline">\(q_i\)</span> 且时刻 <span class="math inline">\(t+1\)</span> 处于状态 <span class="math inline">\(q_j\)</span> 的概率，即： <span class="math display">\[\xi_t(i,j) = P(i_t = q_i, i_{t+1}=q_j|O, \lambda)\]</span> 进一步推导： <span class="math display">\[\begin{array}{lcl}\xi_t(i, j) = P(i_t = q_i, i_{t+1}=q_j|O, \lambda) \\\ \ \ \ \ \ \ \ \ \ \ = \frac{P(i_t=q_i, i_{t+1=q_j},O|\lambda)}{P(O|\lambda)}\\\ \ \ \ \ \ \ \ \ \ \ = \frac{P(i_t=q_i, i_{t+1=q_j},O|\lambda)}{\sum_{i=1}^N\sum_{j=1}^NP(i_t=q_i, i_{t+1=q_j},O|\lambda)}\end{array}\]</span> 其中，<span class="math inline">\(P(i_t=q_i, i_{t+1=q_j},O|\lambda) = \alpha_t(i)a_{ij}b_{jo_{t+1}}\beta_{t+1}(j)\)</span>。</p><p><strong>期望</strong></p><p>在观测 <span class="math inline">\(O\)</span> 下状态 <span class="math inline">\(i\)</span> 出现的期望： <span class="math display">\[\sum_{t=1}^T\gamma_t(i)\]</span> 在观测 <span class="math inline">\(O\)</span> 下状态 <span class="math inline">\(i\)</span> 转移到状态 <span class="math inline">\(j\)</span> 的期望： <span class="math display">\[\sum_{t=1}^{T-1}\xi_t(i, j)\]</span></p><p>这些都是在为后面做铺垫。</p><h3><span id="学习算法">学习算法</span></h3><p>HMM的学习方法分为监督学习和无监督学习两种。</p><ul><li>若训练数据包括观测序列和壮态序列，则HMM的学习非常简单，是监督学习；</li><li>若训练数据只有观测序列，则HMM的学习需要使用<a href="https://www.liuhe.website/index.php?/Articles/single/53" target="_blank" rel="noopener">EM算法</a>，是非监督学习。</li></ul><h4><span id="监督学习">监督学习</span></h4><p><strong>Bernoulli大数定理</strong></p><p>一言以概：<strong>频率的极限是概率</strong>。</p><p><strong>学习方法</strong></p><p>HMM的监督学习方法很简单，而且有点无趣，直接统计就行，这里直接列出公式。</p><p>初始概率 <span class="math display">\[\hat{\pi_i} = \frac{|q_i|}{\sum_i|q_i|}\]</span> 转移概率 <span class="math display">\[\hat{a_{ij}} = \frac{|q_{ij}|}{\sum_{j=1}^N|q_{ij}|}\]</span> 观测概率 $$</p><p> = </p><p>$$</p><h4><span id="baum-welch-算法">Baum-Welch 算法</span></h4><p>若训练数据只有观测序列，则HMM的学习需要使用<a href="https://neymarl.github.io/2016/09/22/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3EM%E7%AE%97%E6%B3%95/" target="_blank" rel="noopener">EM算法</a>，是非监督学习。</p><p><img src="/images/1475389008451.png"></p><p>​ 图3.EM算法框架</p><p>所有观测数据写成 <span class="math inline">\(O = (o_1, o_2, …, o_T)\)</span>，所有隐数据写成 <span class="math inline">\(I=(i_1,i_2, …, i_T)\)</span>，完全数据是 <span class="math inline">\((O, I) = (o_1, o_2, …, o_T, i_1, i_2, …, i_T)\)</span>，则完全数据的对数似然为 <span class="math inline">\(\ln P(O,I|\lambda)\)</span>。</p><p>设 <span class="math inline">\(\overline{\lambda}\)</span> 是HMM参数的当前估计值，<span class="math inline">\(\lambda\)</span> 为待求的参数，则EM算法中的 <span class="math inline">\(Q\)</span>，即条件概率为： <span class="math display">\[\begin{array}{lcr}Q(\lambda, \overline{\lambda}) = P(I|O,\overline{\lambda})\\\ \ \ \ \ \ \ \ \ \ \ \ \ = \frac{P(O,I|\overline{\lambda})}{P(O|\overline{\lambda})}\\\ \ \ \ \ \ \ \ \ \ \ \ \ \propto P(O,I|\overline{\lambda})\end{array}\]</span> EM算法中的M步为： <span class="math display">\[\lambda = \arg\max_\lambda \sum_IP(O,I|\overline{\lambda})\cdot \ln P(O,I|\lambda)\]</span> 根据<a href="#暴力算法">暴力算法</a>中的计算结果： <span class="math display">\[P(O,I|\lambda) =\pi_{i_1}b_{i_1o_1}a_{i_1i_2}b_{i_2o_2}...a_{i_{T-1}i_T}b_{i_ToT}\]</span> 化简得： <span class="math display">\[\begin{array}{lcr}\ \ \ \sum_IP(O,I|\overline{\lambda})\cdot \ln P(O,I|\lambda)\\= \sum_I\ln \pi_{i_1}P(O,I|\overline{\lambda})\\+ \sum_I(\sum_{t=1}^{T-1}\ln a_{i_ti_{t+1}})P(O,I|\overline{\lambda})\\+ \sum_I(\sum_{t=1}^T\ln b_{i_to_t})P(O,I|\overline{\lambda})\end{array}\]</span> 接下来就是极大化上面的式子，求得参数 <span class="math inline">\(A, B, \pi\)</span>。</p><p>由于该三个参数分别位于三个项中，可分别极大化。</p><p>先求 <span class="math inline">\(\pi\)</span> 看看：<span class="math inline">\(\sum_I\ln \pi_{i_1}P(O,I|\overline{\lambda}) = \sum_{i=1}^N\ln \pi_{i}P(O,i_1=i|\overline{\lambda})\)</span>，注意到 <span class="math inline">\(\pi_i\)</span> 满足加和为 <span class="math inline">\(1\)</span>，利用Lagrange乘数法，构造Lagrange函数得： <span class="math display">\[L(\pi_i, \gamma) = \sum_{i=1}^NP(O,i_1=i|\overline{\lambda}) + \gamma(\sum_{i=1}^N\pi_i - 1)\]</span> 其中，<span class="math inline">\(\gamma\)</span> 为Lagrange乘子，对 <span class="math inline">\(L\)</span> 求偏导并令其等于零，得到： <span class="math display">\[P(O,i_1=1|\overline{\lambda}) + \gamma\pi_i = 0\]</span> 对所有 <span class="math inline">\(i\)</span> 求和，得到： <span class="math display">\[\gamma = -P(O|\overline{\lambda})\]</span> 把 <span class="math inline">\(\gamma\)</span> 代回上式，得到初始状态概率： <span class="math display">\[\pi_i = \frac{P(O,i_1=1|\overline{\lambda})}{P(O|\overline{\lambda})} = \frac{P(O,i_1=i|\overline{\lambda})}{\sum_{i=1}^NP(O,i_1=i|\overline{\lambda})} ＝ \frac{\gamma_1(i)}{\sum_{i=1}^N\gamma_1(i)}\]</span> 对于转移概率和观测概率，用同样的方法，可以得到： <span class="math display">\[a_{ij} = \frac{\sum_{t=1}^{T-1}P(O,i_t=i, i_{t+1}=j|\overline{\lambda})}{\sum_{t=1}^{T-1}P(O,i_t=i|\overline{\lambda})} = \frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}\]</span></p><p><span class="math display">\[b_{ik} = \frac{\sum_{t=1}^TP(O,i_t=i|\overline{\lambda})I(o_t=v_k)}{\sum_{t=1}^TP(O,i_t=i|\overline{\lambda})} = \frac{\sum_{t=1,o_t=v_k}^T\gamma_t(i)}{\sum_{t=1}^T\gamma_t(i)}\]</span></p><p>至此，我们通过EM算法推出了参数更新公式，参数学习的问题就全部解决了。</p><h3><span id="预测算法">预测算法</span></h3><p>预测算法有两种，一个是近似算法，另一个是Viterbi算法。</p><h4><span id="近似算法">近似算法</span></h4><p>其实近似算法在讲单个状态的概率 <span class="math inline">\(\gamma_t(i)\)</span> 的时候就已经提到了。</p><p>在每个时刻 <span class="math inline">\(t\)</span> 选择在该时刻最有可能出现的状态 <span class="math inline">\(i_t^*\)</span>，从而得到一个状态序列 <span class="math inline">\(I^* = \{i_1^*, i_2^*, …, i_T^*\}\)</span>，将它作为预测结果。</p><p>我们已经知道单个状态的概率： <span class="math display">\[\gamma_t(i) =\frac{P(i_t=q_i,O|\lambda)}{P(O|\lambda)}=\frac{\alpha_t(i)\beta_t(i)}{\sum_{i=1}^N\alpha_t(i)\beta_t(i)}\]</span> 直接选择概率最大的 <span class="math inline">\(i\)</span> 作为最有可能的状态即可。</p><p>但是这么计算有个问题就是可能会出现此状态在实际中可能不会发生的情况。</p><h4><span id="viterbi算法">Viterbi算法</span></h4><p>Viterbi算法实际是用<strong>动态规划</strong>解HMM预测问题，用DP求概率最大的路径（最优路径），这时一条路径对应一个状态序列。</p><p>定义变量 <span class="math inline">\(\delta_t(i)\)</span>：在时刻 <span class="math inline">\(t\)</span> 状态为 <span class="math inline">\(i\)</span> 的所有路径中，概率的最大值。即： <span class="math display">\[\delta_t(i) = \max_{i_1,i_2, ..., i_{t-1}}P(i_t=i, i_{t-1}, ..., i_1, o_t, ..., o_1|\lambda)\]</span> 初值： <span class="math display">\[\delta_1(i) = P(i_1=i,o_1|\lambda) = \pi_ib_{io_1}\]</span> 递推： <span class="math display">\[\delta_{t+1}(i) =\max_{i_1,i_2, ..., i_{t}}P(i_{t+1}=i, i_{t}, ..., i_1, o_{t+1}, ..., o_1|\lambda) = \max_{1\leqslant j \leqslant N}(\delta_t(j)a_{ji})\cdot b_{io_{t+1}}\]</span> 终止： <span class="math display">\[P^* = \max_{1\leqslant i \leqslant N}\delta_T(i)\]</span> 最后求出来的 <span class="math inline">\(P^*\)</span> 是最大概率路径的概率，若要知道具体是哪条路还需在递推时标记一下。</p><p>我们多想一点，看到这里的时候有木有觉得Viterbi算法和<a href="#前向－后向算法">前向算法</a>很像？如果你翻回去看一眼的话，就会发现Viterbi算法和前向算法唯一的区别就是把求和号 <span class="math inline">\(\sum\)</span> 换成了取最大值 <span class="math inline">\(\max\)</span> ！是不是很有意思，其实数学里有很多这种情况，仅仅是换个符号就可以得到另一个很有用的结论！你有没有感受到数学之美呢？</p><h2><span id="总结">总结</span></h2><ul><li>HMM解决标注问题，在语音识别、NLP、生物信息、模式识别等领域被广泛使用。</li><li>如果观测状态是连续值，可将多项式分布改成高斯分布或高斯混合分布。</li><li>隐马尔可夫模型虽然有点难，但也非常好玩。</li></ul><h2><span id="参考">参考</span></h2><ul><li><p>李航,统计学习方法,清华大学出版社,2012</p></li><li><p>Christopher M. Bishop. Pattern Recognition and Machine Learning</p><p>Chapter 10. Springer-Verlag, 2006</p></li><li><p>Radiner L,Juang B. An introduction of hidden markov Models. IEEEASSP Magazine, 1986</p></li><li><p>Lawrence R. Rabiner. A tutorial on hidden Markov models andselected applications in speech recognition. Proceedings of theIEEE 77.2, pp. 257-286, 1989</p></li><li><p>Jeff A. Bilmes. A gentle tutorial of the EM algorithm and itsapplication to parameter estimation for Gaussian mixture andhidden Markov models. 1998.</p></li><li><p>https://en.wikipedia.org/wiki/Hidden_Markov_model</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> HMM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深入理解EM算法</title>
      <link href="/2016/09/22/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3EM%E7%AE%97%E6%B3%95/"/>
      <url>/2016/09/22/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3EM%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p>In statistics, an <a href="https://www.wikiwand.com/en/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="noopener">expectation–maximization (EM) algorithm</a> is an iterative method for finding <strong>maximum likelihood</strong> or <strong>maximum a posteriori (MAP)</strong> estimates of parameters in statistical models, where the model depends on <strong>unobserved latent variables</strong>.</p></blockquote><!-- toc --><ul><li><a href="#直观理解高斯混合模型gmm">直观理解高斯混合模型(GMM)</a><ul><li><a href="#最大似然估计">最大似然估计</a></li><li><a href="#问题-随机变量无法直接完全观察到">问题 : 随机变量无法直接(完全)观察到</a></li></ul></li><li><a href="#em算法">EM算法</a></li><li><a href="#从理论公式推导gmm">从理论公式推导GMM</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="直观理解高斯混合模型gmm">直观理解高斯混合模型(GMM)</span></h2><h3><span id="最大似然估计">最大似然估计</span></h3><p>最大似然估计(<strong>Maximum Likelihood Estimation, MLE</strong>)是为了找出<strong>找出与样本的分布最接近的概率分布模型</strong>。</p><p>ps : 熟悉最大似然估计的同学可以跳过这部分 :)</p><p>举个简单的例子：10次抛硬币的结果是: 正正反正正正反反正正。假设 <span class="math inline">\(p\)</span> 是每次抛硬币结果为正的概率。则得到这样的实验结果的概率是: <span class="math display">\[P = pp(1-p)ppp(1-p)(1-p)pp = p^7(1-p)^3\]</span> 最大化 <span class="math inline">\(P\)</span> 解得最优解是 <span class="math inline">\(p = 0.7\)</span>，与直观感觉 <span class="math inline">\(p = \frac{正面次数}{抛的次数} = \frac{7}{10} = 0.7\)</span> 一致。</p><p><strong>二项分布的最大似然估计</strong></p><p>对上面的例子简单推广一下：投硬币试验中，进行 <span class="math inline">\(N\)</span> 次独立试验，<span class="math inline">\(n\)</span> 次朝上， <span class="math inline">\(N-n\)</span>次朝下。假定朝上的概率为 <span class="math inline">\(p\)</span>, 使用对数似然函数作为目标函数： <span class="math display">\[f(n\ |\ p) = \log(p^n(1-p)^{N-n})\]</span></p><p>对 <span class="math inline">\(p\)</span> 求偏导并令其等于零，求对数似然函数最大时 <span class="math inline">\(p\)</span> 的值：</p><p><span class="math display">\[\begin{array}{lcr}\frac{\partial f(n\ |\ p)}{\partial p} = \frac{n}{p} - \frac{N-n}{1-p} = 0 \\\Rightarrow p = \frac{n}{N}\end{array}\]</span></p><p><strong>高斯分布的最大似然估计</strong></p><p>进一步考虑，若给定一组样本 <span class="math inline">\(x_1,x_2...x_n\)</span>, 已知它们来自于高斯分布 <span class="math inline">\(N(μ,σ)\)</span>, 试估计参数 <span class="math inline">\(μ,σ\)</span>。</p><p>高斯分布的<strong>概率密度</strong>函数 : <span class="math display">\[f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x-\mu)^2}{2\sigma^2})\]</span></p><p>将 <span class="math inline">\(X_i\)</span> 的样本值 <span class="math inline">\(x_i\)</span> 带入, 得到似然函数 :</p><p><span class="math display">\[L(x) = \prod_{i=1}^n\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x_i-\mu)^2}{2\sigma^2})\]</span></p><p>取对数并化简得：</p><p><span class="math display">\[\begin{array}{lcr}l(x) = \log \prod_{i=1}^n\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) \\\ \ \ \ \ = \sum_{i=1}^n\log\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) \\\ \ \ \ \ = \sum_{i=1}^n \log\frac{1}{\sqrt{2\pi}\sigma} + \sum_{i=1}^n-\frac{(x_i-\mu)^2}{2\sigma^2} \\\ \ \ \ \ = -\frac{n}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2\end{array}\]</span></p><p>最大化上述对数似然函数，即对 <span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\sigma\)</span> 求偏导并令其等于零，解得：</p><p><span class="math display">\[\begin{cases}\mu = \frac{1}{n}\sum_{i=1}^nx_i \\\sigma^2 = \frac{1}{n}\sum_{i=1}^n(x_i - \mu)^2\end{cases}\]</span></p><p>这两个值就是样本均值和样本方差，和矩估计的结果是一致的，并且意义非常直观：<strong>样本的均值即高斯分布的均值, 样本的伪方差即高斯分布的方差</strong>。</p><h3><span id="问题-随机变量无法直接完全观察到">问题 : 随机变量无法直接(完全)观察到</span></h3><p>随机挑选10000位志愿者，测量他们的身高: 若样本中存在男性和女性，身高分别服从 <span class="math inline">\(N(μ_1,σ_1)\)</span> 和 <span class="math inline">\(N(μ_2,σ_2)\)</span> 的分布，试估计 <span class="math inline">\(μ_1,σ_1,μ_2,σ_2\)</span> 。</p><p>更加一般化的描述如下：随机变量 <span class="math inline">\(X\)</span> 是有 <span class="math inline">\(K\)</span> 个高斯分布混合而成，取各个高斯分布的概率（权值）为 <span class="math inline">\(π_1,π_2... π_K\)</span>，第 <span class="math inline">\(i\)</span> 个高斯分布的均值为 <span class="math inline">\(μ_i\)</span>，方差为 <span class="math inline">\(Σ_i\)</span>。若观测到随机变量 <span class="math inline">\(X\)</span> 的一系列样本 <span class="math inline">\(x_1,x_2,...,x_n\)</span>，试估计参数 <span class="math inline">\(π\)</span>，<span class="math inline">\(μ\)</span>，<span class="math inline">\(Σ\)</span>。</p><p>建立目标对数似然函数：</p><p><span class="math display">\[l_{\pi,\mu,\Sigma}(x) = \sum_{i=1}^N\log(\sum_{k=1}^K\pi_kN(x_i\ |\ \mu_k, \Sigma_k))\]</span></p><p>由于在对数函数里面又有加和，我们<strong>没法</strong>直接用求导解方程的办法直接求得最大值。为了解决这个问题，我们分成两步。</p><p><strong>第一步 : 估算数据来自哪个组份</strong></p><p>估计数据由每个组份生成的概率 : 对于每个样本 <span class="math inline">\(x_i\)</span>，它由第 <span class="math inline">\(k\)</span> 个组份生成的概率为</p><p><span class="math display">\[\gamma(i, k) = \frac{\pi_kN(x_i\ |\ \mu_k, \Sigma_k)}{\sum_{j=1}^K\pi_jN(x_i\ |\ \mu_j, \Sigma_j)}\]</span></p><p>上式中的 <span class="math inline">\(μ\)</span> 和 <span class="math inline">\(Σ\)</span> 也是待估计的值，因此采样迭代法: 在计算 <span class="math inline">\(γ(i,k)\)</span> 时假定 <span class="math inline">\(μ\)</span> 和 <span class="math inline">\(Σ\)</span> 已知; <span class="math inline">\(γ(i,k)\)</span> 亦可看成组份 <span class="math inline">\(k\)</span> 在生成数据 <span class="math inline">\(x_i\)</span> 时所做的贡献。</p><p><strong>第二步 : 估计每个组份的参数</strong></p><p>对于所有的样本点，对于组份 <span class="math inline">\(k\)</span> 而言，可看做生成了 <span class="math inline">\(\{\gamma(i, k)x_i\ |\ i = 1,2,...N\}\)</span> 这些点。组份 <span class="math inline">\(k\)</span> 是一个标准的高斯分布，利用上面的结论可以得出:</p><p><span class="math display">\[\begin{cases}N_k = \sum_{i=1}^N\gamma(i, k) \\\mu_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)x_i \\\Sigma_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)(x_i - \mu_k)(x_i-\mu_k)^T \\\pi_k = \frac{N_k}{N} = \frac{1}{N}\sum_{i=1}^N\gamma(i, k)\end{cases}\]</span></p><p>然后就可以迭代了，我们先拍脑门给一个 <span class="math inline">\(\gamma(i, k)\)</span> ，然后在已知 <span class="math inline">\(\gamma\)</span> 的情况下计算第二步四个量，然后再代入第一步更新 <span class="math inline">\(\gamma\)</span>，然后再计算第二步 ... 如此往复，直到收敛。</p><h2><span id="em算法">EM算法</span></h2><p>其实上述的高斯混合模型就是EM算法的一个应用，接下来我们用公式正式推导一下EM算法。</p><p><strong>EM算法的提出</strong></p><p>假定有训练集 <span class="math inline">\(\{x^{(1)}, x^{(2)}, ... , x^{(m)}\}\)</span>，包含 <span class="math inline">\(m\)</span> 个独立样本，希望从中找到该组数据的模型 <span class="math inline">\(p(x,z)\)</span> 的参数，其中 <span class="math inline">\(z\)</span> 是一个隐变量。</p><p><strong>通过最大似然估计建立目标函数</strong></p><p><span class="math display">\[l(\theta) = \sum_{i=1}^m\log p(x\ ;\theta) = \sum_{i=1}^m\log \sum_z p(x,z;\theta)\]</span></p><p>由于 <span class="math inline">\(z\)</span> 是隐随机变量，不方便直接找到参数估计。所以我们采用以下策略：计算 <span class="math inline">\(l(θ)\)</span> 下界，求该下界的最大值；重复该过程，直到收敛到<strong>局部最大值</strong>。</p><p>如下图所示，<span class="math inline">\(P(x\ |\ \theta)\)</span> 是我们的目标函数，我们想在绿线那个点的下方找到一个函数 <span class="math inline">\(r(x\ |\ \theta)\)</span>，使 <span class="math inline">\(r(x\ |\ \theta)\)</span> 严格小于 <span class="math inline">\(P(x\ |\ \theta)\)</span>，并且我们希望在绿线那个点上 <span class="math inline">\(r(x\ |\ \theta) = P(x\ |\ \theta)\)</span>。找到了 <span class="math inline">\(r(x\ |\ \theta)\)</span> 之后我们可以求 <span class="math inline">\(r(x\ |\ \theta)\)</span> 的最大值，也就是红线处，然后重复以上步骤，直到收敛到局部最大值。</p><p><img src="/images/1474462011618.png"></p><p><strong>Jensen不等式</strong></p><p>在推导如何找下界 <span class="math inline">\(r(x\ |\ \theta)\)</span> 之前，先来看一下Jensen不等式，等下要用到。</p><p>若 <span class="math inline">\(f\)</span> 是凸函数，则： <span class="math display">\[f(\theta x + (1 - \theta) y) \leqslant \theta f(x) + (1-\theta)f(y) \]</span></p><p>把上推广一下，若 <span class="math inline">\(\theta_1, ..., \theta_k \geqslant 0, \ \theta_1 + ... + \theta_k = 1\)</span>，则： <span class="math display">\[f(\theta_1x_1 + ... + \theta_k\theta_k) \leqslant \theta_1f(x_1) + ... + \theta_kf(x_k)\]</span></p><p><span class="math inline">\(\theta_i\)</span> 也可以看作是 <span class="math inline">\(x_i\)</span> 发生的概率，这样的话就得到： <span class="math display">\[f(E(x)) \leqslant E(f(x))\]</span></p><p><strong>寻找下界</strong></p><p>我们继续求 <span class="math inline">\(P(x\ |\ \theta)\)</span> 的下界。</p><p>令 <span class="math inline">\(Q_i\)</span> 是 <span class="math inline">\(z\)</span> 的某一个分布，<span class="math inline">\(Qi≥0\)</span>，应用Jesen不等式有:</p><p><span class="math display">\[\begin{array}{lcl}l(\theta) = \sum_{i=1}^m\log \sum_z p(x,z;\theta) \\\ \ \ \ \ \ = \sum_{i=1}^m\log \sum_{z^{(i)}} p(x^{(i)},z^{(i)};\theta) \\\ \ \ \ \ \ = \sum_{i=1}^m\log \sum_{z^{(i)}} Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} \\\ \ \ \ \ \ \geqslant \sum_{i=1}^m \sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\end{array}\]</span></p><p>最后那个式子即为我们要寻找的下界，为了使等号成立，<span class="math inline">\(\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\)</span> 需要是一个常数，即</p><p><span class="math display">\[\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})} = C\]</span></p><p>进一步分析，为了满足Jessen不等式，还需要 <span class="math inline">\(\sum_zQ_i(z^{(i)}) = 1\)</span>，所以 <span class="math inline">\(Q_i(z^{(i)})\)</span> 应该能约掉 <span class="math inline">\(p(x^{(i)},z^{(i)}; \theta)\)</span>，并且进行归一化：</p><p><span class="math display">\[\begin{array}{lcl}Q_i(z^{(i)}) = \frac{p(x^{(i)},z^{(i)};\theta)}{\sum_zp(x^{(i)},z^{(i)};\theta)} \\\ \ \ \ \ \ \ \ \ \ \ = \frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)};\theta)} \\\ \ \ \ \ \ \ \ \ \ \ = p(z^{(i)}\ |\ x^{(i)}; \theta)\end{array}\]</span></p><p>解出来就是一个<strong>条件概率</strong>！</p><p><strong>EM算法整体框架</strong></p><p><img src="/images/1474470389249.png"></p><p><strong>E step</strong>，求每组数据的期望（实际是条件概率），然后<strong>M setp</strong>，最大化期望，之后再翻回去更新期望，如此往复直至收敛，这就是所谓<strong>期望最大化算法（EM）</strong>。</p><h2><span id="从理论公式推导gmm">从理论公式推导GMM</span></h2><p>随机变量 <span class="math inline">\(X\)</span> 是有 <span class="math inline">\(K\)</span> 个高斯分布混合而成，取各个<strong>高斯分布</strong>的概率为 <span class="math inline">\(φ_1φ_2... φ_K\)</span>，第 <span class="math inline">\(i\)</span> 个高斯分布的均值为 <span class="math inline">\(μ_i\)</span>，方差为 <span class="math inline">\(Σ_i\)</span>。若观测到随机变量 <span class="math inline">\(X\)</span> 的一系列样本 <span class="math inline">\(x_1,x_2,...,x_n\)</span>，试估计参数 <span class="math inline">\(φ\)</span>，<span class="math inline">\(μ\)</span>，<span class="math inline">\(Σ\)</span>。</p><p>按照EM算法的思想，我们来推导一下。</p><p><strong>E-step</strong></p><p><span class="math display">\[w_j^{(i)} = Q_i(z^{(i)} = j) = P(z^{(i)} = j\ |\ x^{(i)}; \phi, \mu, \Sigma)\]</span></p><p><strong>M-step</strong></p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \sum_{i=1}^m \sum_{z^{(i)}}Q_i(z^{(i)})\log\frac{p(x^{(i)},z^{(i)};\phi, \mu, \Sigma)}{Q_i(z^{(i)})} \\= \sum_{i=1}^m \sum_{j=1}^k Q_i(z^{(i)} = j)\log\frac{p(x^{(i)}|z^{(i)}=j; \mu, \Sigma)p(z^{(i)}=j; \phi)}{Q_i(z^{(i)} = j)} \\= \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \frac{\frac{1}{(2\pi)^{2/n}|\Sigma_j|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot \phi_j}{w_j^{(i)}}\end{array}\]</span></p><p>其中，<span class="math inline">\(p(z^{(i)}=j; \phi)\)</span> 为第 <span class="math inline">\(i\)</span> 个样本的隐变量属于 <span class="math inline">\(j\)</span> 类的概率，也就是 <span class="math inline">\(\phi_j\)</span>。</p><p>把上式对均值 <span class="math inline">\(\mu_l\)</span> 求偏导得：</p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \bigtriangledown_{\mu_l} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \frac{\frac{1}{(2\pi)^{2/n}|\Sigma_j|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot \phi_j}{w_j^{(i)}} \\= \bigtriangledown_{\mu_l} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)} (-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j)) \\= \sum_{i=1}^m w_l^{(i)}(\Sigma_l^{-1}x^{(i)}-\Sigma_l^{-1}\mu_l)\end{array}\]</span></p><blockquote><p>补充：<span class="math inline">\(\frac{\partial(x^TAx)}{\partial x} = 2Ax\)</span></p></blockquote><p>令上式等于 <span class="math inline">\(0\)</span>，解的均值：</p><p><span class="math display">\[\mu_l = \frac{\sum_{i=1}^mw^{(i)}_lx^{(i)}}{\sum_{i=1}^mw^{(i)}_l}\]</span></p><p>对 <span class="math inline">\(\Sigma_j\)</span> 求偏导并令其等于零可以得出：</p><p><span class="math display">\[\Sigma_j = \frac{\sum_{i=1}^mw^{(i)}_j(x^{(i)}-\mu_j)(x^{(i)}-\mu_j)^T}{\sum_{i=1}^mw^{(i)}_j}\]</span></p><p>继续对 <span class="math inline">\(\phi_j\)</span> 求偏导得到：</p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \bigtriangledown_{\phi_j} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \frac{\frac{1}{(2\pi)^{2/n}|\Sigma_j|^{1/2}}\exp(-\frac{1}{2}(x^{(i)}-\mu_j)^T\Sigma_j^{-1}(x^{(i)}-\mu_j))\cdot \phi_j}{w_j^{(i)}} \\= \bigtriangledown_{\phi_j} \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \phi_j\end{array}\]</span></p><p>我们发现令其等于零并不能解出 <span class="math inline">\(\phi_j\)</span>，而且 <span class="math inline">\(\phi_j\)</span> 还有一个等值约束：<span class="math inline">\(\sum_{j=1}^k\phi_j = 1\)</span>，所以我们用<strong>Lagrange乘数</strong>法来求解这个约束问题。</p><p><strong>建立Lagrange函数</strong></p><p><span class="math display">\[L(\phi, \beta) = \sum_{i=1}^m \sum_{j=1}^k w_j^{(i)}\log \phi_j + \beta(\sum_{j=1}^k\phi_j  - 1)\]</span></p><p>对Lagrange函数求偏导：</p><p><span class="math display">\[\frac{\partial}{\partial \phi_j}L(\phi,\beta) = \sum_{i=1}^m\frac{w^{(i)}_j}{\phi_j} + \beta\]</span></p><p>令其等于零：</p><p><span class="math display">\[\begin{array}{lcl}\ \ \ \ \sum_{i=1}^m\frac{w^{(i)}_j}{\phi_j} + \beta = 0 \\\Rightarrow \sum_{i=1}^m w^{(i)}_j + \beta\cdot \phi_j = 0 \\\Rightarrow \sum_{j=1}^k\sum_{i=1}^m w^{(i)}_j + \sum_{i=1}^k\beta\cdot \phi_j = 0 \\\Rightarrow \sum_{i=1}^m\sum_{j=1}^k w^{(i)}_j + \beta = 0 \\\Rightarrow \sum_{i=1}^m1 + \beta = 0 \\\Rightarrow \beta = -m \\\Rightarrow \sum_{i=1}^m\frac{w^{(i)}_j}{\phi_j} -m = 0 \\\Rightarrow \phi_j = \frac{1}{m}\sum_{i=1}^mw^{(i)}_j\end{array}\]</span></p><p><strong>总结</strong></p><p>对于所有的数据点，可以看作组份 <span class="math inline">\(k\)</span> 生成了这些点。组份 <span class="math inline">\(k\)</span> 是一个标准的高斯分布，总结上面的结论：</p><p><span class="math display">\[\begin{cases}N_k = \sum_{i=1}^N\gamma(i, k) \\\mu_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)x_i \\\Sigma_k = \frac{1}{N_k}\sum_{i=1}^N\gamma(i,k)(x_i - \mu_k)(x_i-\mu_k)^T \\\pi_k = \frac{N_k}{N} = \frac{1}{N}\sum_{i=1}^N\gamma(i, k)\end{cases}\]</span></p><p>得到了与直观理解GMM一样的公式！</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Statistics </tag>
            
            <tag> EM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深入理解聚类算法</title>
      <link href="/2016/09/19/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
      <url>/2016/09/19/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://www.wikiwand.com/zh/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90" target="_blank" rel="noopener">聚类分析</a>（英语：Cluster analysis）是对于统计数据分析的一门技术，在许多领域受到广泛应用，包括机器学习，数据挖掘，模式识别，图像分析以及生物信息。聚类是把相似的对象通过静态分类的方法分成不同的组别或者更多的子集（subset），这样让在同一个子集中的成员对象都有相似的一些属性，常见的包括在坐标系中更加短的空间距离等。</p></blockquote><!-- toc --><ul><li><a href="#距离度量方式">距离度量方式</a></li><li><a href="#k-means">K-Means</a></li><li><a href="#密度聚类">密度聚类</a><ul><li><a href="#dbscan">DBSCAN</a></li><li><a href="#密度最大值聚类">密度最大值聚类</a></li></ul></li><li><a href="#谱聚类">谱聚类</a><ul><li><a href="#基础知识">基础知识</a></li><li><a href="#谱和谱聚类">谱和谱聚类</a></li></ul></li><li><a href="#参考">参考</a></li></ul><!-- tocstop --><a id="more"></a><p><strong>定义</strong></p><p>聚类就是对大量<strong>未知标注</strong>的数据集，按数据的<strong>内在相似性</strong>将数据集划分为多个类别，使类别<strong>内</strong>的数据<strong>相似度较大</strong>而类别<strong>间</strong>的数据<strong>相似度较小</strong>。显然聚类算法属于<strong>无监督</strong>学习。</p><h2><span id="距离度量方式">距离度量方式</span></h2><p>度量数据间的距离/相似性有一系列不同的方式：</p><ul><li>闵可夫斯基距离Minkowski/欧式距离： <span class="math display">\[dist(X, Y) = (\sum_{i=1}^N(x_i - y_i)^p)^{\frac{1}{p}}\]</span></li><li>杰卡德相似系数(Jaccard) ： <span class="math display">\[J(A, B) = \frac{|A\cap B|}{|A\cup B|}\]</span></li><li>余弦相似度(cosine similarity)： <span class="math display">\[\cos(\theta) = \frac{a^Tb}{|a|\cdot|b|}\]</span></li><li>Pearson相似系数： <span class="math display">\[\rho_{XY} = \frac{cov(X, Y)}{\sigma_X\sigma_Y} = \frac{E[(X - \mu_x)(Y - \mu_y)]}{\sigma_X\sigma_Y} = \frac{\sum_{i=1}^n(x_i - \mu_x)(y_i - \mu_y)}{\sqrt{\sum_{i=1}^n(x_i - \mu_x)^2}\cdot\sqrt{\sum_{i=1}^n(y_i - \mu_y)^2}}\]</span></li><li>相对熵(K-L距离)： <span class="math display">\[D(p || q) = \sum_xp(x)\log\frac{p(x)}{q(x)} = E_{p(x)}\log\frac{p(x)}{q(x)}\]</span></li><li>Hellinger距离 <span class="math display">\[D_\alpha(p||q) = \frac{1}{1-\alpha^2}(1 - \int p(x)^{\frac{1+\alpha}{2}}q(x)^{\frac{1-\alpha}{2}}dx)\]</span></li></ul><h2><span id="k-means">K-Means</span></h2><p><strong>聚类的基本思想</strong></p><ul><li>给定一个有 <span class="math inline">\(N\)</span> 个对象的数据集, 构造数据的 <span class="math inline">\(k\)</span> 个簇, <span class="math inline">\(k≤n\)</span>。满足下列条件:<ul><li>每一个簇至少包含一个对象</li><li>每一个对象属于且仅属于一个簇</li></ul></li><li>将满足上述条件的 <span class="math inline">\(k\)</span> 个簇称作一个合理划分，对于给定的类别数目 <span class="math inline">\(k\)</span>, 首先给出初始划分, 通过<strong>迭代</strong>改变样本和簇的<strong>隶属</strong>关系, 使得每一次改进之后的划分方案都较前一次<strong>好</strong>。</li></ul><p><strong>K-means算法</strong></p><p>K-means算法，也被称为k-平均或k-均值，是一种广泛使用的聚类算法。</p><ul><li>假定输入样本为 <span class="math inline">\(S=x_1,x_2,...,x_m\)</span> , 则算法步骤为:<ul><li>选择初始的 <span class="math inline">\(k\)</span> 个类别中心 <span class="math inline">\(μ_1, μ_2, ..., μ_k\)</span></li><li>对于每个样本 <span class="math inline">\(x_i\)</span>，将其标记为距离类别中心最近的类别, 即: <span class="math display">\[label_i = \arg\min_{1\leqslant j \leqslant k}||x_i-\mu_j||\]</span></li><li>将每个类别中心更新为隶属该类别的所有样本的<strong>均值</strong>： <span class="math display">\[\mu_j = \frac{1}{c_j}\sum_{i\in c_j}x_i\]</span></li><li>重复最后两步，直到类别中心的变化<strong>小于某阈值</strong>。</li></ul></li><li>中止条件:<ul><li>迭代次数/簇中心变化率/最小平方误差MSE(MinimumSquaredError</li></ul></li></ul><p><strong>公式化理解</strong></p><p>记 <span class="math inline">\(K\)</span>个簇中心为 <span class="math inline">\(\mu_1,\mu_2,...,\mu_k\)</span> , 每个簇的样本数目为<span class="math inline">\(N_1,N_2,...,N_k\)</span>。 假设使用平方误差作为目标函数： <span class="math display">\[J(\mu_1, ... \mu_k) = \frac{1}{2}\sum_{j=1}^K\sum_{i=1}^{N_j}(x_i - \mu_j)^2\]</span></p><p>对它求偏导并令其等于零得：</p><p><span class="math display">\[\frac{\partial J}{\partial \mu_j} = -\sum_{i=1}^{N_j}(x_i - \mu_j) = 0 \Rightarrow \mu_j = \frac{1}{N_j}\sum_{i=1}^{N_j}x_i\]</span></p><p>正好和K-mean算法中的聚类中心更新规则相同，即每个类别中心更新为隶属该类别的所有样本的<strong>均值</strong>，。所以实际上K-mean算法的损失函数就是上面的<strong>均方误差损失</strong>，更新规则也是<strong>梯度下降</strong>，而均方误差损失是假设误差服从<strong>高斯分布</strong>（推导见<a href="https://www.liuhe.website/index.php?/Articles/single/48" target="_blank" rel="noopener">此处</a>）！也就是说，K-mean算法是假设每个簇的误差是服从正态分布的，虽然这个先验条件很强，但如果实际情况不是这样，K-mean算法也可能给出<strong>很好</strong>的聚类结果。</p><p><strong>K-means算法还对异常点和初始值比较敏感</strong></p><p>若簇中含有异常点，将导致均值偏离严重。以一维数据为例 : 数组 <span class="math inline">\(1, 2, 3, 4, 100\)</span> 的均值为 <span class="math inline">\(22\)</span>，显然离大多数数据都比较远，若改成求数组的中位数 <span class="math inline">\(3\)</span>，在该实例中更为稳妥。这种聚类方式即<strong>K-Mediods聚类(K中值聚类)</strong>，相当于把损失函数换成了绝对误差损失。</p><p>若类中心初始值不同，K-means算法可能会得到完全不同的结果（可能是不好的），比如下图所示：</p><p><img src="/images/1474016250691.png"></p><p><strong>总结</strong></p><ul><li>优点<ul><li>是解决聚类问题的一种经典算法，<strong>简单</strong>、<strong>快速</strong></li><li>对处理大数据集，该算法保持<strong>可伸缩性</strong>和<strong>高效率</strong></li><li>当簇近似为<strong>高斯分布</strong>时，它的效果较好</li><li>可作为其他聚类方法的基础算法，如<a href="#谱聚类">谱聚类</a></li></ul></li><li>缺点<ul><li>在簇的平均值可被定义的情况下才能使用，可能不适用于某些应用</li><li>必须事先给出 <span class="math inline">\(k\)</span> (要生成的簇的数目)，而且对初值敏感, 对于不同的初始值，可能会导致不同结果</li><li>不适合于发现非凸形状的簇或者大小差别很大的簇</li><li>对躁声和孤立点数据敏感</li></ul></li></ul><h2><span id="密度聚类">密度聚类</span></h2><p>密度聚类方法的指导思想是，只要样本点的<strong>密度</strong>大于某阈值，则将该样本添加到最近的簇中。</p><p>这类算法能克服基于距离的算法只能发现“<em>类圆形</em>”(<em>凸</em>)的聚类的缺点，可发现<strong>任意形状的簇</strong>, 且<strong>对噪声数据不敏感</strong>。但计算密度单元的<strong>计算复杂度大</strong>，需要建立空间索引来降低计算量。常用密度聚类的算法有： * DBSCAN * 密度最大值算法</p><h3><span id="dbscan">DBSCAN</span></h3><p><strong>Density-Based Spatial Clustering of Applications with Noise</strong></p><p>它是一个比较有代表性的基于密度的聚类算法。 与划分和层次聚类方法不同，它将簇定义为<strong>密度相连的点的最大集合</strong>，能够把具有足够高密度的区域划分为簇，并可在有“噪声” 的数据中发现任意形状的聚类。</p><p>先来介绍一些相关概念：</p><ul><li>对象的 <span class="math inline">\(ε\)</span>-邻域 : 给定对象在半径 <span class="math inline">\(ε\)</span> 内的区域</li><li>核心对象 : 对于给定的数目 <span class="math inline">\(m\)</span>, 如果一个对象的 <span class="math inline">\(ε\)</span>- 邻域至少包含 <span class="math inline">\(m\)</span> 个对象, 则称该对象为<strong>核心对象</strong></li><li>直接密度可达 : 给定一个对象集合 <span class="math inline">\(D\)</span>, 如果 <span class="math inline">\(p\)</span> 是在 <span class="math inline">\(q\)</span> 的 <span class="math inline">\(ε\)</span>-邻域内, 而 <span class="math inline">\(q\)</span> 是一个核心对象, 我们说对象 <span class="math inline">\(p\)</span> 从对象 <span class="math inline">\(q\)</span> 出发是直接密度可达的</li></ul><p>如右图 <span class="math inline">\(ε=1\)</span>cm, <span class="math inline">\(m=5\)</span>, <img src="/images/1474017928793.png"> <span class="math inline">\(q\)</span>是一个核心对象, 从对象 <span class="math inline">\(q\)</span> 出发到对象 <span class="math inline">\(p\)</span> 是<strong>直接密度可达</strong>的。</p><ul><li><p>密度可达 : 如果存在一个对象链 <span class="math inline">\(p_1p_2...p_n,p_1=q,p_n=p\)</span>, 对 <span class="math inline">\(p_i∈D\)</span>, <span class="math inline">\((1≤i ≤n)\)</span>, <span class="math inline">\(p_{i+1}\)</span> 是从 <span class="math inline">\(p_i\)</span> 关于 <span class="math inline">\(ε\)</span> 和 <span class="math inline">\(m\)</span> <strong>直接密度可达</strong>的, 则对象 <span class="math inline">\(p\)</span> 是从对象 <span class="math inline">\(q\)</span> 关于 <span class="math inline">\(ε\)</span> 和 <span class="math inline">\(m\)</span> <strong>密度可达</strong>的。如下图:<img src="/images/1474018471590.png"></p></li><li>密度相连 : 如果对象集合 <span class="math inline">\(D\)</span> 中存在一个对象 <span class="math inline">\(o\)</span>, 使得对象 <span class="math inline">\(p\)</span> 和 <span class="math inline">\(q\)</span> 是从 <span class="math inline">\(o\)</span> 关于 <span class="math inline">\(ε\)</span> 和 <span class="math inline">\(m\)</span> 密度可达的, 那么对象 <span class="math inline">\(p\)</span> 和 <span class="math inline">\(q\)</span> 是关于 <span class="math inline">\(ε\)</span> 和 <span class="math inline">\(m\)</span> 密度相连的。如下图： <img src="/images/1474018209712.png"></li><li><strong>簇</strong> : 一个基于密度的簇是最大的<strong>密度相连</strong>对象的集合</li><li><p>噪声 : 不包含在任何簇中的对象称为噪声</p></li></ul><p><strong>DBSCAN算法流程</strong></p><ul><li>如果一个点 <span class="math inline">\(p\)</span> 的 <span class="math inline">\(ε\)</span>-邻域包含多于 <span class="math inline">\(m\)</span> 个对象, 则创建一个 <span class="math inline">\(p\)</span> 作为核心对象的新簇</li><li>寻找并合并核心对象<strong>直接</strong>密度可达的对象</li><li>没有新点可以更新簇时, 算法结束</li></ul><p><img src="/images/1474018857997.png"></p><p>由该过程我们可以知道： * 每个簇至少包含一个核心对象 * 非核心对象可以是簇的一部分, 构成了簇的边缘(edge) * 包含过少对象的簇被认为是噪声</p><h3><span id="密度最大值聚类">密度最大值聚类</span></h3><p>密度最大值聚类是一种简洁优美的聚类算法，可以识别各种形状的类簇，并且参数很容易确定。</p><p><strong>一些定义</strong></p><ul><li><strong>局部密度</strong> <span class="math inline">\(\rho_i = \sum_j\chi(d_{ij} - d_c)\)</span>，其中 <span class="math inline">\(\chi(x) = 1, \ if\ x &lt; 0, \ otherwise \ \chi(x) = 0\)</span>，<span class="math inline">\(d_c\)</span> 是一个截断距离，<span class="math inline">\(ρ_i\)</span> 即到对象 <span class="math inline">\(i\)</span> 的距离小于 <span class="math inline">\(d_c\)</span> 的对象的个 数。由于该算法<strong>只对 <span class="math inline">\(ρ_i\)</span> 的相对值敏感</strong>, 所以对 <span class="math inline">\(d_c\)</span> 的选择是稳健的, 一种推荐做法是选择 <span class="math inline">\(d_c\)</span>, 使得平均每个点的邻居数为所有点的 1%-2%</li><li><strong>高局部密度点距离</strong> <span class="math inline">\(\delta_i = \min_{j:\rho_j &gt; \rho_i}(d_{ij})\)</span><ul><li>简称：高密距离</li><li>在密度高于对象 <span class="math inline">\(i\)</span> 的所有对象中, 到对象 <span class="math inline">\(i\)</span> 最近的距离, 即高局部密度点距离</li></ul></li><li>对于密度<strong>最大</strong>的对象, 设置 <span class="math inline">\(δ_i=\max(d_{ij})\)</span> (即 : 该问题中的无穷大)<ul><li>只有那些密度是<strong>局部或者全局最大</strong>的点才会有<strong>远大于正常值</strong>的高局部密度点距离</li></ul></li><li><strong>簇的中心</strong>：那些有着<strong>比较大的局部密度 <span class="math inline">\(ρ_i\)</span> </strong>和<strong>很大的高密距离 <span class="math inline">\(δ_i\)</span> </strong>的点被认为是簇的中心<ul><li>确定簇中心之后, 其他点按照距离已知簇的中心最近进行分类</li></ul></li><li><strong>异常点</strong>：<strong>高密距离 <span class="math inline">\(δ_i\)</span> 较大</strong>但<strong>局部密度 <span class="math inline">\(ρ_i\)</span> 较小</strong>的点是异常点</li></ul><p><strong>密度最大值聚类过程</strong></p><p>下左图是所有点在二维空间的分布, 下右图是以 <span class="math inline">\(ρ\)</span> 为横坐标, 以 <span class="math inline">\(δ\)</span> 为纵坐标绘制的决策图。可以看到, <span class="math inline">\(1\)</span>和 <span class="math inline">\(10\)</span> 两个点的 <span class="math inline">\(ρ_i\)</span> 和 <span class="math inline">\(δ_i\)</span> 都比较大, 作为<strong>簇的中心点</strong>。<span class="math inline">\(26\)</span>、 <span class="math inline">\(27\)</span>、<span class="math inline">\(28\)</span>三个点的 <span class="math inline">\(δ_i\)</span> 也比较大, 但是 <span class="math inline">\(ρ_i\)</span> 较小, 所以是<strong>异常点</strong>。</p><p><img src="/images/1474028836544.png"></p><p><strong>边界和噪声的重认识</strong></p><p>在聚类分析中，通常需要确定每个点划分给某个簇的<strong>可靠性</strong>:</p><ul><li>在该算法中，可以首先为每个簇定义一个<strong>边界区域 (border region)</strong>，亦即<strong>划分给该簇但是距离其他簇的点的距离小于 <span class="math inline">\(d_c\)</span> 的点</strong>的集合。然后为每个簇找到其边界区域的<strong>局部密度最大</strong>的点，令其局部密度为 <span class="math inline">\(ρ_h\)</span>。</li><li>该簇中所有局部密度大于 <span class="math inline">\(ρ_h\)</span> 的点被认为是簇核心的一 部分(亦即将该点划分给该类簇的可靠性很大)，其余的点被认为是该类簇的<strong>光晕(halo)</strong>，亦即可以认为是<strong>噪声</strong>。</li></ul><h2><span id="谱聚类">谱聚类</span></h2><h3><span id="基础知识">基础知识</span></h3><p><strong>特征值和特征向量</strong></p><p>若数 <span class="math inline">\(\lambda\)</span> 和向量 <span class="math inline">\(\overrightarrow{u}\)</span> 对矩阵 <span class="math inline">\(A\)</span> 满足： <span class="math display">\[A\cdot  \overrightarrow{u}= \lambda \cdot \overrightarrow{u} \]</span> 则 <span class="math inline">\(\lambda\)</span> 称为矩阵 <span class="math inline">\(A\)</span> 的一个特征值，<span class="math inline">\(\overrightarrow{u}\)</span> 为对应的特征向量。</p><p>则有以下结论： * <strong>实对称阵的特征值是实数</strong> * 证明略 * <strong>实对称阵不同特征值的特征向量正交</strong> * 证明：令实对称矩阵为 <span class="math inline">\(A\)</span>, 其两个不同的特征值 <span class="math inline">\(λ_1,λ_2\)</span> 对应的特征向量分别是 <span class="math inline">\(μ_1, μ_2\)</span>; * <span class="math inline">\(λ_1,λ_2,μ_1,μ_2\)</span> 都是<strong>实数</strong>或是<strong>实向量</strong> * 有 <span class="math inline">\(A\mu_1 = \lambda_1\mu_1\)</span>，从而： <span class="math display">\[\begin{array}{lcr}\ \ \ \ \ A\mu_2 = \lambda_2\mu_2 \\\Rightarrow \mu_1^T A\mu_2 = \mu_1^T\lambda_2\mu_2 \\\Rightarrow (A^T\mu_1)^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\Rightarrow (A\mu_1)^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\Rightarrow (\lambda_1\mu_1)^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\Rightarrow \lambda_1\mu_1^T\mu_2 = \lambda_2\mu_1^T\mu_2 \\\end{array}\]</span> * 因为 <span class="math inline">\(\lambda_1 \neq \lambda_2\)</span>，所以 <span class="math inline">\(\mu_1^T\mu_2 = 0\)</span>，即 <span class="math inline">\(\mu_1,\mu_2\)</span> 正交。</p><h3><span id="谱和谱聚类">谱和谱聚类</span></h3><ul><li><strong>谱</strong>：方阵作为线性算子，它的所有<strong>特征值</strong>的全体统称方阵的<strong>谱</strong>。<ul><li>我们说一个人靠不靠谱儿，实际上是看他以前做过的事的<strong>稳定程度</strong>，即<strong>方差</strong>。</li><li><strong>方阵</strong>的<strong>谱半径</strong>为<strong>最大的特征值</strong></li><li>普通矩阵 <span class="math inline">\(A\)</span> 的<strong>谱半径</strong>: <span class="math inline">\((A^TA)\)</span> 的<strong>最大特征值</strong></li></ul></li></ul><p><strong>谱聚类</strong>是一种基于<strong>图论</strong>的聚类方法, 通过对样本数据的<strong>拉普拉斯矩阵</strong>的<strong>特征向量</strong>进行聚类, 从而达到对样本数据聚类的目的。</p><p><strong>谱分析的整体过程</strong></p><p>给定一组数据 <span class="math inline">\(x_1,x_2,...x_n\)</span>, 记任意两个点之间的<strong>相似度</strong>(“距离”的减函数)为<span class="math inline">\(s_{ij}=&lt;x_i,x_j&gt;\)</span>, 形成<strong>相似度图(similarity graph)</strong> : <span class="math inline">\(G=(V,E)\)</span> 。如果 <span class="math inline">\(x_i\)</span> 和 <span class="math inline">\(x_j\)</span> 之间的相似度 <span class="math inline">\(s_{ij}\)</span> 大于一定的阈值, 那么两个点是连接的, 权值记做 <span class="math inline">\(s_{ij}\)</span>。</p><p>接下来, 可以用相似度图来解决样本数据的聚类问题 : 找到图的一个划分, 形成若干个组(Group), 使得不同组之间有较低的权值, 组内有较高的权值。</p><p><strong>一些概念</strong></p><ul><li>邻接矩阵 <span class="math inline">\(W = (w_{ij})\ \ i,j=1,...n\)</span>，实际上该矩阵就是相似度矩阵，即 <span class="math inline">\(w_{ij} = s_{ij}\)</span></li><li>度矩阵 <span class="math inline">\(D = (d_{i})\ \ i = 1,...,n\)</span>，该矩阵是个对角阵： <span class="math display">\[d_i = \sum_{j=1}^nw_{ij}\]</span></li><li>高斯相似度 <span class="math inline">\(s(x_i, x_j) = \exp(\frac{-||x_i - x_j||^2}{2\sigma^2})\)</span></li><li><strong>Laplace矩阵</strong>：<span class="math inline">\(L = D - W\)</span><ul><li><span class="math inline">\(L\)</span> 是对称半正定矩阵，最小特征值是 <span class="math inline">\(0\)</span>，相应的特征向量是全 <span class="math inline">\(1\)</span> 向量 <span class="math display">\[\begin{array}{lcr}f^TLf = f^TDf - f^TWf = \sum_{i=1}^nd_if_i^2 - \sum_{i,j=1}^nf_if_jw_{ij} \\= \frac{1}{2}( \sum_{i=1}^nd_if_i^2 - 2\sum_{i,j=1}^nf_if_jw_{ij}  + \sum_{j=1}^nd_jf_j^2) \\= \frac{1}{2}\sum_{i,j=1}^nw_{ij}(f_i-f_j)^2 \geqslant 0\end{array}\]</span></li><li>其中，<span class="math inline">\(f\)</span> 为任意矩阵，所以 <span class="math inline">\(L\)</span> 为半正定矩阵。</li></ul></li><li>Laplace 矩阵的其它形式：<ul><li>对称Laplace矩阵 <span class="math inline">\(L_{sym} = D^{-\frac{1}{2}}LD^{\frac{1}{2}} = I - D^{-\frac{1}{2}}WD^{\frac{1}{2}}\)</span></li><li><strong>随机游走Laplace矩阵</strong> <span class="math inline">\(L_{rw} = D^{-1}L = I - D^{-1}W\)</span><ul><li>之所以叫 Random Walk 是因为 <span class="math inline">\(d_i = \sum_{j=1}^nw_{ij}\)</span>，<span class="math inline">\(D^{-1}W\)</span> 相当于 <span class="math inline">\(W\)</span> 的元素都变成了 <span class="math inline">\(\frac{w_{ij}}{d_i} = \frac{w_{ij}}{\sum_{j=1}^nw_{ij}}\)</span>，相当于做了<strong>归一化</strong>。如果令 <span class="math inline">\(P = D^{-1}W\)</span>，则 <span class="math inline">\(\sum_{j=1}^np_{ij} = 1\)</span>，<span class="math inline">\(p_{ij}\)</span> 就可以看成从点 <span class="math inline">\(i\)</span> 到 <span class="math inline">\(j\)</span> 的概率，也就是 Random Walk 模型了。</li></ul></li></ul></li></ul><p><strong>谱聚类算法</strong></p><ul><li>输入: <span class="math inline">\(n\)</span> 个点 <span class="math inline">\(\{p_i\}\)</span>, 簇的数目 <span class="math inline">\(k\)</span></li><li>计算 <span class="math inline">\(n×n\)</span> 的相似度矩阵 <span class="math inline">\(W\)</span> 和度矩阵 <span class="math inline">\(D\)</span>;</li><li>计算拉普拉斯矩阵 <span class="math inline">\(L=D-W\)</span>;</li><li>计算 <span class="math inline">\(L\)</span> 的前 <span class="math inline">\(k\)</span> 个特征向量 <span class="math inline">\(u_1,u_2,...,u_k\)</span>（<strong>从小到大</strong>排列）;</li><li>将 <span class="math inline">\(k\)</span> 个列向量 <span class="math inline">\(u_1,u_2,...,u_k\)</span> 组成矩阵 <span class="math inline">\(U\)</span>, <span class="math inline">\(U∈R^{n×k}\)</span>;</li><li>对于 <span class="math inline">\(i=1,2,...,n\)</span>, 令 <span class="math inline">\(y_i∈R^k\)</span> 是 <span class="math inline">\(U\)</span> 的第 <span class="math inline">\(i\)</span> 行的向量;</li><li>使用k-means算法将点 <span class="math inline">\((y_i)_{i=1,2,...,n}\)</span> 聚类成簇 <span class="math inline">\(C_1,C_2,...C_k\)</span>;</li><li>输出簇 <span class="math inline">\(A_1,A_2,...A_k\)</span>, 其中, <span class="math inline">\(A_i=\{j\ |\ y_j∈C_i\}\)</span></li></ul><p>使用其它形式的Laplace矩阵算法步骤类似。</p><p>由于最后聚类的过程实际上还是交给k-means来做，所以谱聚类前面所有过程可以看作是给k-means提供更好的特征。</p><p><strong>谱聚类与PCA的联系</strong></p><p>谱聚类中取Laplace矩阵 <span class="math inline">\(L\)</span> <strong>从小到大</strong>的前 <span class="math inline">\(k\)</span> 特征向量，相当于把数据从 <span class="math inline">\(n\)</span> 为降低到 <span class="math inline">\(k\)</span> 维，就是一个<strong>降维</strong>的过程，与PCA是类似的。PCA是取原始数据的<strong>协方差矩阵</strong>的前 <span class="math inline">\(k\)</span> 个特征向量，只不过是<strong>从大到小</strong>排列的。为什么会有顺序区别呢？原因是Laplace矩阵 <span class="math inline">\(L = D - W\)</span> 中的减号，也就是 <span class="math inline">\(L\)</span> 中的特征与原始数据（<span class="math inline">\(W\)</span>）的特征是相反的，所以与PCA取的顺序相反。</p><p><strong>思考与总结</strong></p><ul><li>谱聚类中的 <span class="math inline">\(K\)</span> 如何确定 ?<ul><li><span class="math inline">\(k^* = \arg\max_k|\lambda_{k+1} - \lambda_k|\)</span></li></ul></li><li>最后一步K-Means的作用是什么 ?<ul><li>目标函数是关于子图划分指示向量的函数，该向量的值根据子图划分确定，是离散的。该问题是NP的，转换成求连续实数域上的解，最后用K-Means算法离散化。</li></ul></li><li>未正则/对称/随机游走拉普拉斯矩阵，首选哪个？<ul><li><strong>随机游走拉普拉斯矩阵</strong></li></ul></li><li>谱聚类可以用切割图/随机游走/扰动论等解释</li></ul><h2><span id="参考">参考</span></h2><ul><li>Alex Rodriguez, Alessandro Laio. Clustering by fast search and find of density peak. Science. 2014</li><li>Ulrike von Luxburg. A tutorial on spectral clustering. 2007</li><li>Lang K. Fixing two weaknesses of the spectral method. Advances in Neural Information Processing Systems 18, 715–722. MIT Press, Cambridge, 2006</li><li>Bach F, Jordan M. Learning spectral clustering. Advances in Neural Information Processing Systems 16 (NIPS). 305– 312. MIT Press, Cambridge,2004</li><li>Andrew Rosenberg, Julia Hirschberg, V-Measure: A conditional entropy-based external cluster evaluation measure, 2007.</li><li>W. M. Rand. Objective criteria for the evaluation of clustering methods. Journal of the American Statistical Association. 1971</li><li>Nguyen Xuan Vinh, Julien Epps, James Bailey, Information theoretic measures for clusterings comparison, ICML 2009</li><li>Peter J. Rousseeuw, Silhouettes: a Graphical Aid to the Interpretation and Validation of Cluster Analysis. Computational and Applied Mathematics 20: 53–65, 1987</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Clustering </tag>
            
            <tag> K-Means </tag>
            
            <tag> DBSCAN </tag>
            
            <tag> 谱聚类 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深入理解SVM</title>
      <link href="/2016/09/13/Support%20Vector%20Machine/"/>
      <url>/2016/09/13/Support%20Vector%20Machine/</url>
      
        <content type="html"><![CDATA[<blockquote><p>支持向量机（Support Vector Machine, SVM）是一种分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器。SVM 还包含核技巧，使它成为非线性分类器。</p></blockquote><!-- toc --><ul><li><a href="#线性可分支持向量机">线性可分支持向量机</a><ul><li><a href="#硬间隔最大化">硬间隔最大化</a></li></ul></li><li><a href="#线性支持向量机">线性支持向量机</a><ul><li><a href="#软间隔最大化">软间隔最大化</a></li></ul></li><li><a href="#非线性支持向量机">非线性支持向量机</a><ul><li><a href="#核函数">核函数</a></li></ul></li><li><a href="#smo">SMO</a></li><li><a href="#总结思考">总结思考</a></li><li><a href="#参考文献">参考文献</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="线性可分支持向量机">线性可分支持向量机</span></h2><p>先来介绍一些概念。</p><p><strong>分割超平面</strong></p><p>定义：设 <span class="math inline">\(C\)</span> 和 <span class="math inline">\(D\)</span> 为两不相交的凸集，则存在平面 <span class="math inline">\(P\)</span>，<span class="math inline">\(P\)</span> 可以将 <span class="math inline">\(C\)</span> 和 <span class="math inline">\(D\)</span> 完全分离，则 <span class="math inline">\(P\)</span> 为两集合的分割超平面。</p><p>那么如何定义两个集合的“最优”分割超平面？如下图所示，这些线都可以把两个集合完全分开，那么哪条线是最好的？</p><p><img src="/images/1473584864752.png"></p><blockquote><p>两个集合的距离，定义为两个集合间元素的最短距离。</p></blockquote><p>直观上我们认为如果某一条分割线（或者超平面），使得两个集合到它的<strong>最短距离距离最大</strong>，那么这条分割线（或超平面）就认为是最优的，因为它最大化地分开了两个集合。</p><p><img src="/images/1473585333350.png"></p><p>上图红线为最优分割线，平行于它的左右两条虚线为两个集合的边界，过边界的点（向量）起支撑作用，好像把分割超平面支起来一样，所以这些点就叫<strong>支撑向量</strong>。找到了支撑向量，也就找到了集合边界，也就确定了分割超平面，通过这种方法分类的模型就叫做<strong>支持向量机</strong>。</p><h3><span id="硬间隔最大化">硬间隔最大化</span></h3><p><strong>输入数据</strong></p><p>假设给定一个特征空间上的训练数据集 <span class="math display">\[T=\{(x_1,y_1), (x_2,y_2)...(x_N,y_N)\}\]</span> 其中，<span class="math inline">\(x_i∈R^n\)</span>，<span class="math inline">\(y_i∈\{+1,-1\}\)</span>，<span class="math inline">\(i=1,2,...N\)</span>，<span class="math inline">\(x_i\)</span> 为第 <span class="math inline">\(i\)</span> 个实例(若 <span class="math inline">\(n&gt;1\)</span>，<span class="math inline">\(x_i\)</span> 为向量)；<span class="math inline">\(y_i\)</span> 为 <span class="math inline">\(x_i\)</span> 的类标记。当 <span class="math inline">\(y_i=+1\)</span> 时，称 <span class="math inline">\(x_i\)</span> 为正例；当 <span class="math inline">\(y_i=-1\)</span> 时，称 <span class="math inline">\(x_i\)</span> 为负例；<span class="math inline">\((x_i,y_i)\)</span> 称为样本点。</p><p>给定线性可分训练数据集，通过<strong>间隔最大化</strong>得到的分离超平面为 <span class="math display">\[y(x) = w^T\Phi(x) + b\]</span></p><p>相应的分类决策函数 <span class="math inline">\(f(x) = sign(w^T\Phi(x) + b)\)</span> ，该决策函数称为线性可分支持向量机。</p><p><span class="math inline">\(φ(x)\)</span> 是某个确定的特征空间转换函数，它的作用是将 <span class="math inline">\(x\)</span> 映射到(更高的)维度。最简单直接的：<span class="math inline">\(\Phi(x) = x\)</span>。求解分离超平面问题可以等价为求解相应的<strong>凸二次规划问题</strong>。</p><p><img src="/images/1473595785438.png"></p><p><strong>推导目标函数</strong></p><blockquote><p>点到直线距离 平面一点 <span class="math inline">\(\overrightarrow{x_0}\)</span> 到直线 <span class="math inline">\(y = \overrightarrow{w}\overrightarrow{x} + b\)</span> 的距离为 <span class="math inline">\(\frac{|\overrightarrow{w}\overrightarrow{x} + b|}{||\overrightarrow{w}||}\)</span>，若直线变换为 <span class="math inline">\(y = \frac{\overrightarrow{w}\overrightarrow{x} + b}{||\overrightarrow{w}||}\)</span>，则距离为 <span class="math inline">\(|y(\overrightarrow{x_0})|\)</span></p></blockquote><p>根据题设 <span class="math inline">\(y(x) = w^T\Phi(x) + b\)</span>，有 <span class="math inline">\(y_i(x)\cdot y(x_i) &gt; 0\)</span>，<span class="math inline">\(w\)</span>, <span class="math inline">\(b\)</span> 等比例缩放，则 <span class="math inline">\(t*y\)</span> 的值同样缩放，从而样本 <span class="math inline">\(i\)</span> 到超平面的距离为： <span class="math display">\[\frac{y_i\cdot y(x_i)}{||w||} = \frac{y_i \cdot (w^T\Phi(x_i) + b)}{||w||}\]</span></p><p>我们要求<strong>最短距离最大</strong>的超平面，所以目标函数为：</p><p><span class="math display">\[\arg \max_{w, b}\{\frac{1}{||w||}\min_i[y_i \cdot (w^T\cdot \Phi(x_i) + b)]\}\]</span></p><p>由于我们总可以通过等比例缩放 <span class="math inline">\(w\)</span> 的方法，使得两类点的函数值都满足 <span class="math inline">\(|y|\geqslant 1\)</span>，加上这个约束之后 ： <span class="math inline">\(\min_i[y_i \cdot (w^T\cdot \Phi(x_i) + b)] = 1\)</span>，所以目标函数化简为：</p><p><span class="math display">\[\arg \max_{w,b}\frac{1}{||w||}\]</span> <span class="math display">\[s.t. \ y_i(w^T\cdot \Phi(x_i) + b) \geqslant 1, \ \ i = 1, 2, ... n\]</span></p><p>我们做一下简单的变化，得到：</p><p><span class="math display">\[\arg \min_{w,b}\frac{1}{2}||w||^2\]</span> <span class="math display">\[s.t. \ y_i(w^T\cdot \Phi(x_i) + b) -1 \geqslant 0, \ \ i = 1, 2, ... n\]</span></p><p>求一个带约束的函数的最值，通常使用<a href="https://www.wikiwand.com/en/Lagrange_multiplier" target="_blank" rel="noopener">Lagrange乘数法</a>。</p><blockquote><p>In mathematical optimization, the method of Lagrange multipliers is a strategy for finding the local maxima and minima of a function subject to equality constraints.</p></blockquote><p>Lagrange函数为：</p><p><span class="math display">\[L(w,b,\alpha) = \frac{1}{2}||w||^2- \sum_{i=1}^n\alpha_i(y_i(w^T\cdot \Phi(x_i) + b) - 1)\]</span></p><p>由于我们要求 $_i 0 $，而 <span class="math inline">\((y_i(w^T\cdot \Phi(x_i) + b) - 1)\)</span> 是一个正值，所以 <span class="math inline">\(L(w, b, \alpha) \leqslant \frac{1}{2}||w||^2\)</span>，即 <span class="math inline">\(max_\alpha L(w, b, \alpha) = \frac{1}{2}||w||^2\)</span>，所以原问题是极小极大问题： <span class="math display">\[\min_{w,b}\max_\alpha L(w, b, \alpha)\]</span></p><p>我们再做一下变化，变成原始问题的对偶问题：</p><p><span class="math display">\[\max_\alpha\min_{w,b}L(w, b, \alpha)\]</span></p><blockquote><p>一般情况下，<span class="math inline">\(\min_y\max_x f(x, y) \geqslant \max_x\min_y f(x, y)\)</span>，由于我们的 <span class="math inline">\(L(w, b, \alpha)\)</span> 满足 <a href="https://www.wikiwand.com/en/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions" target="_blank" rel="noopener">KKT条件</a>，所以可以取等号。</p></blockquote><p>由于先求 <span class="math inline">\(\min_{w,b}\)</span>，所以将拉格朗日函数 <span class="math inline">\(L(w,b,\alpha)\)</span> 分别对 <span class="math inline">\(w,b\)</span> 求偏导并令其为 <span class="math inline">\(0\)</span> :</p><p><span class="math display">\[\frac{\partial L}{\partial w} = 0 \Rightarrow w = \sum_{i=1}^n\alpha_i y_i \Phi(x_i)\]</span> <span class="math display">\[\frac{\partial L}{\partial b} = 0 \Rightarrow \sum_{i=1}^n\alpha_i y_i = 0\]</span></p><p>把上面二式代回 <span class="math inline">\(L(w, b, \alpha)\)</span>，并化简得：</p><p><span class="math display">\[\begin{array}{lcl}L(w, b, \alpha) = \frac{1}{2}||w||^2- \sum_{i=1}^n\alpha_i(y_i(w^T\cdot \Phi(x_i) + b) - 1) \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \frac{1}{2}w^Tw - w^T\sum_{i=1}^n\alpha_iy_i\Phi(x_i) - b\sum_{i=1}^n\alpha_iy_i + \sum_{i=1}^n\alpha_i \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \frac{1}{2}w^T\sum_{i=1}^n\alpha_i y_i \Phi(x_i) - w^T\sum_{i=1}^n\alpha_iy_i\Phi(x_i) - b \cdot 0 + \sum_{i=1}^n\alpha_i \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \sum_{i=1}^n\alpha_i - \frac{1}{2}(\sum_{i=1}^n\alpha_i y_i \Phi(x_i))^T\sum_{i=1}^n\alpha_i y_i \Phi(x_i) \\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \sum_{i=1}^n\alpha_i -\frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_jy_iy_j\Phi(x_i)\Phi(x_j)\end{array}\]</span></p><p>继续求 <span class="math inline">\(\min_{w,b}L(w, b, \alpha)\)</span> 对 <span class="math inline">\(\alpha\)</span> 的极大：</p><p><span class="math display">\[\max_\alpha \sum_{i=1}^n\alpha_i - \frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_jy_iy_j\Phi(x_i)\Phi(x_j)\]</span> <span class="math display">\[s.t. \sum_{i=1}^n \alpha_iy_i = 0, \alpha_i \geqslant 0, i = 1, 2, ... n\]</span></p><p>我们对目标函数添加负号，转化为对 <span class="math inline">\(\alpha\)</span> 求极小：</p><p><span class="math display">\[\min_\alpha \frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_jy_iy_j\Phi(x_i)\Phi(x_j) - \sum_{i=1}^n\alpha_i\]</span> <span class="math display">\[s.t. \sum_{i=1}^n \alpha_iy_i = 0, \alpha_i \geqslant 0, i = 1, 2, ... n\]</span></p><p>用某些方法（比如：<a href="#SMO">SMO</a>）求得最优解 <span class="math inline">\(\alpha^*\)</span>，然后可以计算出分隔超平面：</p><p><span class="math display">\[w^* = \sum_{i=1}^n\alpha_i^*y_i\Phi(x_i)\]</span> <span class="math display">\[b^* = y_i - \sum_{i=1}^n\alpha_i^*y_i\Phi(x_i)\cdot \Phi(x_j)\]</span> <span class="math display">\[w^*\Phi(x) + b^* = 0\]</span></p><p>其中，<span class="math inline">\(x_j\)</span> 为某一样本，所以分类决策函数为：</p><p><span class="math display">\[f(x) = sign(w^*\Phi(x) + b^*)\]</span></p><h2><span id="线性支持向量机">线性支持向量机</span></h2><p>解决问题之后我们发现，有时候不一定分类完全正确的超平面就是最好的，容忍些小错误可能会更好，如下图所示：</p><p><img src="/images/1473671960505.png"></p><p>明显虚线比完全分对的实线看起来要好一些，实线可能过拟合了。而且更多的情况是数据集本身就不是线性可分的，解决这些问题就需要用<strong>软间隔最大化的线性支持向量机</strong>了！</p><h3><span id="软间隔最大化">软间隔最大化</span></h3><p>若数据线性不可分，则增加松弛因子 <span class="math inline">\(ξ_i≥0\)</span> , 使函数间隔加上松弛变量大于等于 <span class="math inline">\(1\)</span>。这样, 约束条件变成 : <span class="math display">\[y_i(w\cdot x_i + b) \geqslant 1 - \xi_i\]</span></p><p>则目标函数变为：</p><p><span class="math display">\[\min_{w,b, \xi}\frac{1}{2}||w||^2 + C\sum_{i=1}^n\xi_i\]</span> <span class="math display">\[s.t. y_i(w\cdot x_i + b) \geqslant 1 - \xi_i, \ \xi_i \geqslant 0, \ i = 1,2, ... n\]</span></p><p>其中，参数 <span class="math inline">\(C\)</span> 用于调节容忍错误的程度。当 <span class="math inline">\(C \rightarrow +\infty\)</span> 时，要最小化目标函数，<span class="math inline">\(\xi_i\)</span> 只能取非常非常小的值，即 <span class="math inline">\(\xi_i \rightarrow 0\)</span>，相当于线性可分SVM；当 <span class="math inline">\(C\)</span> 比较小时，<span class="math inline">\(\xi_i\)</span> 可以取得较大的值，从而容错率较大，可防止过拟合。</p><p>构造Lagrange函数： <span class="math display">\[L(w, b, \xi, \alpha, \mu) = \frac{1}{2}||w||^2 + C\sum_{i=1}^n\xi_i -\sum_{i=1}^n\alpha_i(y_i(w^T\cdot \Phi(x_i) + b) - 1 + \xi_i) - \sum_{i=1}^n\mu_i\xi_i\]</span></p><p>对 <span class="math inline">\(w, b, \xi\)</span> 求偏导并令其等于 <span class="math inline">\(0\)</span> 得：</p><p><span class="math display">\[\frac{\partial L}{\partial w} = 0 \Rightarrow \sum_{i=1}^n\alpha_iy_i\Phi(x_i)\]</span> <span class="math display">\[\frac{\partial L}{\partial b} = 0 \Rightarrow \sum_{i=1}^n\alpha_i y_i = 0\]</span> <span class="math display">\[\frac{\partial L}{\partial \xi} = 0 \Rightarrow C - \alpha_i - \mu_i = 0\]</span></p><p>将上面三式代入Lagrange函数得：</p><p><span class="math display">\[\min_{w,b,\xi}L(w,b,\xi,\alpha,\mu) = -\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j)) + \sum_{i=1}^n\alpha_i\]</span></p><p>对上式求关于 <span class="math inline">\(\alpha\)</span> 的极大，得到：</p><p><span class="math display">\[\max_\alpha -\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j)) + \sum_{i=1}^n\alpha_i\]</span> <span class="math display">\[s.t. \sum_{i=0}^n\alpha_iy_i = 0, \ C - \alpha_i - \mu_i = 0, \ \alpha_i \geqslant 0, \mu_i \geqslant 0, i = 1,2...n\]</span></p><p>由于 <span class="math inline">\(C - \alpha_i - \mu_i = 0\)</span>，我们可以知道：<span class="math inline">\(0 \leqslant \alpha_i \leqslant C\)</span>。</p><p>整理得到对偶问题：</p><p><span class="math display">\[\min_\alpha \sum_{i=1}^n\alpha_i-\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j))\]</span> <span class="math display">\[s.t. \sum_{i=0}^n\alpha_iy_i = 0, \ 0 \leqslant \alpha_i \leqslant C,\  i = 1,2...n\]</span></p><p>通过某些方法（比如：<a href="#SMO">SMO</a>）求解约束最优化问题，求得最优解 <span class="math inline">\(\alpha^*\)</span>。</p><p>计算 <span class="math inline">\(w^*\)</span> 和 <span class="math inline">\(b^*\)</span> ：</p><p><span class="math display">\[w^* = \sum_{i=1}^n\alpha_i^*y_i\Phi(x_i)\]</span> <span class="math display">\[b^* = \frac{\max_{i:y_i = -1}w^*\Phi(x_i)+\min_{i:y_i = 1}w^*\Phi(x_i)}{2}\]</span></p><p>注意： * 计算 <span class="math inline">\(b^*\)</span>时，需要使用满足条件 <span class="math inline">\(0&lt;α_j&lt;C\)</span> 的向量 * 实践中往往取<strong>支持向量</strong>的所有值取平均，作为 <span class="math inline">\(b^*\)</span></p><p>求得分离超平面：<span class="math inline">\(w^*\Phi(x) + b^* = 0\)</span></p><p>分类决策函数为：</p><p><span class="math display">\[f(x) = sign(w^*\Phi(x) + b^*)\]</span></p><p><strong>损失函数分析</strong></p><p><img src="/images/1473691411792.png"></p><p>若一正例样本落在 <span class="math inline">\(y=1\)</span> 下侧或正好在线上，则惩罚 <span class="math inline">\(\xi = 0\)</span> ；若落在 <span class="math inline">\(y=0\)</span> 与 <span class="math inline">\(y=1\)</span> 之间，则惩罚为一个小于 <span class="math inline">\(1\)</span> 的数，即 <span class="math inline">\(\xi &lt; 1\)</span>；若正好落在分割线上，则 <span class="math inline">\(\xi = 1\)</span> ；若该样本落在 <span class="math inline">\(y = 0\)</span> 上侧，则惩罚为大于 <span class="math inline">\(1\)</span> 的值，即 <span class="math inline">\(\xi &gt; 1\)</span>。画在坐标轴上就是：</p><p><img src="/images/1473691785170.png"></p><p>其中，蓝色的线就是SVM的损失函数，红色的线是Logistic回归的损失函数，绿色的线是0/1损失。</p><h2><span id="非线性支持向量机">非线性支持向量机</span></h2><p>可以使用核函数，将原始输入空间映射到新的特征空间，从而，使得原本线性不可分的 样本可能在核空间可分，从而实现非线性支持向量机。</p><h3><span id="核函数">核函数</span></h3><p>我们要优化的目标函数为： <span class="math display">\[\min_\alpha \sum_{i=1}^n\alpha_i-\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j(\Phi(x_i)\cdot \Phi(x_j))\]</span></p><p>我们定义核函数 <span class="math inline">\(\kappa(x_i, x_j) = \Phi(x_i) \cdot \Phi(x_j)\)</span>，来代替 <span class="math inline">\(\Phi(x_i)\)</span> 与 <span class="math inline">\(\Phi(x_j)\)</span> 的点积，从而我们不用自己提取 <span class="math inline">\(x\)</span> 的特征 <span class="math inline">\(\Phi(x)\)</span>，只需定义一个核函数来表示两个样本的<strong>相似度</strong>。</p><p>常用的核函数有以下几个： * 多项式核函数：<span class="math inline">\(\kappa(x_1, x_2) = (\alpha \cdot ||x_1 - x_2||^a + r)^b\)</span>，<span class="math inline">\(\alpha, a, b, r\)</span> 为常数 * 高斯核函数RBF：<span class="math inline">\(\kappa(x_1,x_2) = \exp(-\frac{||x_1 - x_2||^2}{2\sigma^2})\)</span> * Sigmoid核：<span class="math inline">\(\kappa(x_1,x_2) = \tanh(\gamma\cdot||x_1-x_2||^a+r)\)</span>，<span class="math inline">\(\gamma,a,r\)</span> 为常数</p><p>在实际应用中，往往依赖<strong>先验领域知识</strong>/<strong>交叉验证</strong>等方案才能选择有效的核函数；若没有更多先验信息，则使用<strong>高斯核函数</strong>。</p><p><strong>核函数映射</strong></p><p><img src="/images/1473693232751.png"></p><p>高斯核函数其实可以在样本周围形成一圈圈等高线，使<strong>正样本上升形成山峰</strong>，<strong>负样本下降形成山谷</strong>，然后总会有一个或多个超平面可以完美分割两类样本，如上图所示。</p><p><img src="/images/1473693532937.png"></p><p>那么多个完美分割的超平面哪个是最好的呢？是粉红色的还是黑色的？</p><p>其实我们只需要把样本到平面的<strong>最短距离求</strong>出来，然后<strong>最大化</strong>这个距离就可以，没错，就是<strong>在核函数映射的空间里做SVM</strong>！而且总是可以找到一个最优的分割平面来分割数据集，这也就是 SVM + kernel trick 异常强大的原因。</p><p><strong>RBF</strong></p><p>在多说一点高斯核函数，<span class="math inline">\(\kappa(x_1,x_2) = \exp(-\frac{||x_1 - x_2||^2}{2\sigma^2})\)</span>。</p><blockquote><p><span class="math inline">\(e^x\)</span> 的Taylor展开：<span class="math inline">\(e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + ... + \frac{x^n}{n!} + R_n\)</span></p></blockquote><p>我们对高斯核函数做一些变换并Taylor展开：</p><p><span class="math display">\[\begin{array}{lcl}\kappa(x_1,x_2) = e^{-\frac{||x_1 - x_2||^2}{2\sigma^2}} = e^{-\frac{(x_1 - x_2)^2}{2\sigma^2}} \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 - 2x_1x_2 + x_2^2}{2\sigma^2}} \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 + x_2^2}{2\sigma^2}} \cdot e^{\frac{x_1x_2}{\sigma^2}} \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 + x_2^2}{2\sigma^2}} \cdot(1 + \frac{1}{\sigma^2}\cdot\frac{x_1x_2}{1!} + (\frac{1}{\sigma^2})^2\cdot\frac{(x_1x_2)^2}{2!} + ... +  (\frac{1}{\sigma^2})^n\cdot\frac{(x_1x_2)^n}{n!} + ...) \\\ \ \ \ \ \ \ \ \ \ \ \ \ = e^{-\frac{x_1^2 + x_2^2}{2\sigma^2}} \cdot (1\cdot1 + \frac{1}{1!}\frac{x_1}{\sigma}\frac{x_2}{\sigma} + \frac{1}{2!}\frac{x_1^2}{\sigma^2}\frac{x_2^2}{\sigma^2} + ... + \frac{1}{n!}\frac{x_1^n}{\sigma^n}\frac{x_2^n}{\sigma^n}+...) \\\ \ \ \ \ \ \ \ \ \ \ \ \ = \Phi(x_1)^T\cdot\Phi(x_2)\end{array}\]</span></p><p>其中，<span class="math inline">\(\Phi(x) = e^{-\frac{x^2}{2\sigma^2}}(1+\sqrt{\frac{1}{1!}}\frac{x}{\sigma} + \sqrt{\frac{1}{2!}}\frac{x^2}{\sigma^2} + ...+\sqrt{\frac{1}{n!}}\frac{x^n}{\sigma^n} + ...)\)</span></p><p>由 <span class="math inline">\(\Phi(x)\)</span> 结果可见高斯核函数实际把特征映射到了<strong>无穷维</strong>，然后由SVM选出几个最优维度进行分类。</p><h2><span id="smo">SMO</span></h2><p>SVM中系数的求解：<strong>Sequential Minimal Optimization</strong></p><p><strong>算法思想</strong> * 有多个拉格朗日乘子 * 每次只选择其中<strong>两个乘子</strong>做优化，其他因子认为是<strong>常数</strong> * 将N个解问题，转换成两个变量的求解问题：并且目标函数是<strong>凸</strong>的</p><p><strong>算法步骤</strong> * 考察目标函数，假设 <span class="math inline">\(α_1\)</span> 和 <span class="math inline">\(α_2\)</span> 是变量，其他是定值： <span class="math display">\[\min_\alpha \sum_{i=1}^n\alpha_i-\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n\alpha_i\alpha_jy_iy_j\kappa(x_i,x_j)\]</span> <span class="math display">\[s.t. \sum_{i=0}^n\alpha_iy_i = 0, \ 0 \leqslant \alpha_i \leqslant C,\  i = 1,2...n\]</span> * 二变量优化问题 <span class="math display">\[y_1 \neq y_2，\begin{cases} L = \max\{0, \alpha_1 - \alpha2\} \\H = \min\{C, C+\alpha_1-\alpha_2\}\end{cases}\]</span> <span class="math display">\[y_1 = y_2，\begin{cases} L = \max\{0, \alpha_1 + \alpha2 - C\} \\H = \min\{C, \alpha_1+\alpha_2\}\end{cases}\]</span> * 迭代公式 <span class="math display">\[g(x) = \sum_{i=1}^ny_i\alpha_i\kappa(x_i, x) + b\]</span> <span class="math display">\[\eta = \kappa(x_1, x_1) + \kappa(x_2, x_2) - 2\kappa(x_1, x_2) = ||\Phi(x_1) - \Phi(x_2)||^2\]</span> <span class="math display">\[E_i = g(x_i) - y_i = (\sum_{j=1}^ny_j\alpha_j\kappa(x_j, x_i) + b) - y_i,\ \ \ i = 1, 2\]</span> <span class="math display">\[\alpha_j^{new} = \alpha_j^{old} + \frac{y_j(E_i - E_j)}{\eta}\]</span> * 迭代 <span class="math inline">\(m\)</span> 次 <span class="math inline">\(\alpha_j\)</span> 没有变化就可以退出迭代了，<span class="math inline">\(m\)</span> 为自己设置的阈值。</p><h2><span id="总结思考">总结思考</span></h2><ul><li>SVM可以用来划分多类别吗?<ul><li>答案是肯定的。</li><li>直接多分类</li><li>1 vs all</li></ul></li><li>SVM和Logistic回归的比较<ul><li>经典的SVM，直接输出类别，不给出后验概率</li><li>Logistic回归，会给出属于哪个类别的后验概率</li><li>二者<strong>目标函数的异同</strong></li></ul></li><li>SVM也可以用于回归问题：SVR</li></ul><h2><span id="参考文献">参考文献</span></h2><ul><li>李航，统计学习方法，清华大学出版社，2012</li><li>Charlie Frogner. Support Vector Machines. 2011</li><li>Corinana Cortes, Vladimir Vapnik. Support-Vector Networks. Machine Learning, 20, 273-297, 1995</li><li>John C. Platt. Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines. 1998</li><li>Andrew W. Moore. Support Vector Machines, 2001</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>提升方法：GBDT , XGBOOST &amp; AdaBoost</title>
      <link href="/2016/09/08/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%EF%BC%9AGBDT%20,%20XGBOOST,%20AdaBoost/"/>
      <url>/2016/09/08/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%EF%BC%9AGBDT%20,%20XGBOOST,%20AdaBoost/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>提升</strong> (<em>boosting</em>) 方法是一种常用的统计学习方法，应用广泛且有效，在分类问题中，它通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，提高分类器性能。</p></blockquote><!-- toc --><ul><li><a href="#gbdt">GBDT</a><ul><li><a href="#提升的概念">提升的概念</a></li><li><a href="#提升算法">提升算法</a></li><li><a href="#梯度提升决策树-gbdt">梯度提升决策树 GBDT</a></li></ul></li><li><a href="#xgboost">XGBOOST</a></li><li><a href="#adaboost">AdaBoost</a><ul><li><a href="#误差分析">误差分析</a></li></ul></li><li><a href="#参考文献">参考文献</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="gbdt">GBDT</span></h2><p>我们知道<strong>随机森林</strong>的决策树分别采样建立, 相对<strong>独立</strong>。 那么引来了如下思考 :</p><ul><li>假定当前一定得到了 <span class="math inline">\(m-1\)</span> 颗决策树, 是否可以通过现有样本和决策树的信息, 对第 <span class="math inline">\(m\)</span> 颗决策树的建立产生有益的影响呢 ?</li><li>各个决策树组成随机森林后, 最后的投票过程可否在建立决策树时即确定呢?</li></ul><p>答案是肯定的，这也就是<strong>提升（boosting）</strong>的方法所解决的问题。</p><h3><span id="提升的概念">提升的概念</span></h3><p><strong>提升</strong>是一个机器学习技术, 可以用于<strong>回归和分类</strong>问题, 它每一步产生一个<strong>弱预测模型</strong>(如决策树), 并<strong>加权累加</strong>到总模型中，最终得带一个<strong>强预测模型</strong>; 如果每一步的弱预测模型生成都是依据损失函数的梯度方向, 则称之为<strong>梯度提升(Gradient boosting)</strong>。</p><p>提升的方法基于这样一个思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好。实际上，就是“<strong>三个臭皮匠顶个诸葛亮</strong>”的道理。</p><p><strong>梯度提升</strong>算法首先给定一个<strong>目标损失函数</strong>, 它的定义域是所有可行的<strong>弱函数集合(基函数)</strong>; 提升算法通过迭代的选择一个<strong>负梯度方向</strong>上的基函数来逐渐逼近局部极小值。这种在函数域的梯度提升观点对机器学习的很多领域有深刻影响。</p><p><strong>梯度提升</strong>算法实际上和<strong>梯度下降</strong>算法是一样的，只不过看问题的角度不同，比如在线性回归中，我们通过梯度下降来优化参数 <span class="math inline">\(\theta\)</span> ，使损失函数能达到（局部）最小值；如果我们换个角度，我们优化的不是 <span class="math inline">\(\theta\)</span>，而是 <span class="math inline">\(h_\theta(x) = \theta^T x\)</span> 这个函数，再通过沿梯度方向下降的方法达到损失函数（局部）最小值，就变成了梯度提升算法。</p><h3><span id="提升算法">提升算法</span></h3><p>给定输入向量 <span class="math inline">\(x\)</span> 和输出变量 <span class="math inline">\(y\)</span> 组成的若干训练样本 <span class="math inline">\((x_1, y_1), (x_2,y_2),...,(x_n,y_n)\)</span> , 目标是找到近似函数 <span class="math inline">\(F(x)\)</span> , 使得损失函数 <span class="math inline">\(L(y,F(x))\)</span> 的损失值最小。</p><p>损失函数 <span class="math inline">\(L(y,F(x))\)</span> 的定义不唯一，典型定义有以下两种：</p><ul><li><span class="math inline">\(L(y,F(x)) = \frac{1}{2}(y - F(x))^2\)</span>，这个定义其实默认误差服从<strong>高斯分布</strong></li><li><span class="math inline">\(L(y,F(x)) =| y - F(x) |\)</span>，这个定义则认为误差服从<strong>Laplace（双指数）分布</strong></li></ul><p>假设最优解为 <span class="math inline">\(F^*(x)\)</span>，则：</p><p><span class="math display">\[F^*(x) =\arg\min_F E(x, y)[L(y, F(x))]\]</span></p><p>该式的意思就是使<strong>损失函数期望风险最小化</strong>的参数 <span class="math inline">\(F(x)\)</span> 为最优解 <span class="math inline">\(F^*(x)\)</span>。</p><p>我们知道任何函数都可以被分解为一族<strong>基函数的线性组合</strong>，比如傅立叶分解可以把任何函数分解为三角函数的线性组合，所以这里的 <span class="math inline">\(F(x)\)</span> 也不例外，我们假设它是一族基函数 <span class="math inline">\(f_i(x)\)</span> 的线性组合，即： <span class="math display">\[F(x) = \sum_{i=1}^M\gamma_if_i(x) + const\]</span></p><p><strong>算法推导</strong></p><p>我们使用梯度提升方法寻找最优解 <span class="math inline">\(F(x)\)</span>, 使得损失函数在训练集上的<strong>期望最小</strong>。方法如下:</p><ul><li><p>首先, 令 <span class="math inline">\(f_0(x) = 1\)</span>，求常系数 <span class="math inline">\(\gamma_0\)</span> : <span class="math display">\[F_0(x) =\gamma_0f_0(x) =\gamma_0 =\arg\min_\gamma\sum_{i=1}^n L(y_i,\gamma)\]</span></p><ul><li>若损失函数采用平方定义，上式可以解得：<span class="math inline">\(F_0(x) =\gamma =\frac{1}{n}\sum_{i=1}^ny_i\)</span></li><li>若损失函数采用绝对值定义，则解 <span class="math inline">\(F_0(x)\)</span> 为 <span class="math inline">\(y_1, y_2 ... y_n\)</span> 的中位数</li></ul></li><li>知道 <span class="math inline">\(F_0(x)\)</span> 之后，接下来用递推的思路来想，如果已知 <span class="math inline">\(F_0(x), F_1(x) ... F_{m-1}(x)\)</span> ，如何求 <span class="math inline">\(F_m(x)\)</span> ？于是得到下面的公式： <span class="math display">\[F_m(x) = F_{m-1}(x) + \arg \min_{f \in H} \sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f(x_i))\]</span></li><li><p>我们可以用<strong>梯度下降</strong>的方法近似计算上式。若使 <span class="math inline">\(\sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f(x_i))\)</span> 取得最小值，我们可以对 <span class="math inline">\(f(x_i)\)</span> 求偏导求出梯度，然后沿负梯度方向下降一个步长 <span class="math inline">\(\gamma_m\)</span>，由于这个步长可以通过<strong>线性搜索</strong>求出最优值，所以该步长与负梯度的乘积可以近似为上式的最小值，于是得到如下的更新公式： <span class="math display">\[F_m(x) = F_{m-1}(x) - \gamma_m \sum_{i=1}^n\nabla_fL(y_i, F_{m-1}(x_i))\]</span></p></li></ul><p><strong>提升算法</strong></p><ol type="1"><li>初始给定模型为常数 <span class="math inline">\(F_0(x) = \arg \min_\gamma \sum_{i=1}^n L(y_i, \gamma)\)</span></li><li>对于 <span class="math inline">\(m=1\)</span> 到 <span class="math inline">\(M\)</span><ol type="1"><li>计算<strong>伪残差 (pseudo residuals)</strong> <span class="math inline">\(r_{im} = [\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}]_{F(x) = F_{m-1}(x)}\)</span> <span class="math inline">\(i = 1, 2 ... n\)</span></li><li>使用数据 <span class="math inline">\(\{(\overrightarrow{x_i}, r_{im})\}_{i=1}^n\)</span> 训练<strong>拟合残差</strong>的基函数 <span class="math inline">\(f_m(x)\)</span> （比如一棵决策树）</li><li>计算步长 $<em>m = </em><em>{i=1}^nL(y_i, F</em>{m-1}(x_i) - f_m(x_i)) $<ul><li>一维优化问题</li></ul></li><li>更新模型：<span class="math inline">\(F_m(x) = F_{m-1}(x) - \gamma_m \cdot f_m(x)\)</span></li></ol></li></ol><h3><span id="梯度提升决策树-gbdt">梯度提升决策树 GBDT</span></h3><p>在提升算法中，如果基函数选择的是决策树，那么算法又叫<strong>梯度提升决策树</strong>，也就是<strong>GBDT</strong>。</p><p><strong>GBDT</strong></p><ul><li>在第 <span class="math inline">\(m\)</span> 步的梯度提升是根据伪残差数据计算决策树 <span class="math inline">\(t_m(x)\)</span>。</li><li><p>令树 <span class="math inline">\(t_m(x)\)</span> 的叶节点数目为 <span class="math inline">\(J\)</span>, 即树 <span class="math inline">\(t_m(x)\)</span> 将输入空间划分为 <span class="math inline">\(J\)</span> 个不相交区域<span class="math inline">\(R_{1m},R_{2m},...,R_{Jm}\)</span> ,并且决策树 <span class="math inline">\(t_m(x)\)</span> 可以在每个区域中给出某个类型的确定性预测。使用指示记号 <span class="math inline">\(I(x)\)</span>, 对于输入 <span class="math inline">\(x\)</span>, <span class="math inline">\(t_m(x)\)</span> 为: <span class="math display">\[t_m(x) = \sum_{j=1}^Jb_{jm}I(x \in R_{jm})\]</span></p></li><li><p>其中，<span class="math inline">\(b_{jm}\)</span> 是样本 <span class="math inline">\(x\)</span> 在区域 <span class="math inline">\(R_{jm}\)</span> 的预测值，<span class="math display">\[I(x) = \begin{cases}1, &amp; x == True \\0, &amp; x == False\end{cases}\]</span></p></li><li>使用线性搜索计算学习率,最小化损失函树<ul><li><span class="math inline">\(F_m(x) = F_{m-1}(x) + \gamma_m \cdot t_m(x)\)</span></li><li><span class="math inline">\(\gamma_m = \arg \min_\gamma\sum_{i=1}^nL(y_i, F_{m-1}(x_i) + \gamma_mt_m(x_i))\)</span></li></ul></li><li>进一步：对树的每个区域分别计算步长，从而系数 <span class="math inline">\(b_{jm}\)</span> 被合并到步长中，从而:<ul><li><span class="math inline">\(F_m(x) = F_{m-1}(x) + \sum_{j=1}^J\gamma_mI(x \in R_{jm})\)</span></li><li><span class="math inline">\(\gamma_{jm} = \arg \min_\gamma\sum_{x_i \in R_{jm}}L(y_i, F_{m-1}(x_i) + \gamma_mt_m(x_i))\)</span></li></ul></li></ul><p><strong>参数设置和正则化</strong></p><p>对训练集拟合过高会降低模型的泛化能力, 需要使用<strong>正则化</strong>技术来降低过拟合。</p><ul><li>对复杂模型增加惩罚项, 如 : 模型复杂度正比于叶结点数目或者叶结点预测值的平方和等</li><li>用决策树剪枝</li><li>叶结点数目控制了树的层数, 一般选择 <span class="math inline">\(4≤J≤8\)</span></li><li>叶结点包含的最少样本数目<ul><li>防止出现过小的叶结点, 降低预测方差</li></ul></li><li>梯度提升迭代次数 <span class="math inline">\(M\)</span> :<ul><li>增加 <span class="math inline">\(M\)</span> 可降低训练集的损失值, 但有过拟合风险</li><li>交叉验证</li></ul></li></ul><p><strong>GBDT总结</strong></p><ul><li>函数估计本来被认为是在函数空间而非参数空间的数值优化问题，而阶段性的加性扩展和梯度下降手段将函数估计转换成参数估计。</li><li>损失函数是最小平方误差、绝对值误差等，则为<strong>回归问题</strong>；而误差函数换成多类别Logistic似然函数，则成为<strong>分类问题</strong>。</li><li>对<strong>目标函数分解成若干基函数的加权</strong>和，是常见的技术手段：<a href="https://neymarl.github.io/2016/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8A)/" target="_blank" rel="noopener">神经网络</a>、径向基函数、傅立叶/小波变换、<a href="https://neymarl.github.io/2016/03/03/Support%20Vector%20Machines%20(SVMs)/" target="_blank" rel="noopener">SVM</a>都可以看到它的影子。</li></ul><h2><span id="xgboost">XGBOOST</span></h2><p><span class="math display">\[F_m(x)=F_{m-1}(x)+\arg\min_{f\in H}\sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f(x_i))\]</span></p><p>普通提升算法包括GBDT在计算上式实采用的是<strong>梯度提升</strong>，也就是只用了一阶导数信息，如果常识<strong>二阶导数</strong>的信息呢？</p><p><strong>目标函数</strong>：<span class="math inline">\(J(f_t) = \sum_{i=1}^nL(y_i, F_{m-1}(x_i) + f_t(x_i)) + \Omega(f_t) + C\)</span> 其中，<span class="math inline">\(\Omega(f_t)\)</span> 为正则项，<span class="math inline">\(C\)</span> 为常数，目的是要求出使目标函数最小的 <span class="math inline">\(f_t\)</span>。</p><blockquote><p>二阶Taylor展式： <span class="math display">\[f(x + \triangle x) = f(x) + f&#39;(x)\triangle x + f&#39;&#39;(x)\triangle x^2 + O(x^3)\]</span></p></blockquote><p>令： <span class="math display">\[g_i = \frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)}, h_i = \frac{\partial^2 L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)}\]</span></p><p>对 <span class="math inline">\(J(f_t)\)</span> 二阶Taylor展开并省略高阶无穷小得：</p><p><span class="math display">\[J(f_t) \approx  \sum_{i=1}^n (L(y_i, F_{m-1}(x_i)) + g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)) + \Omega(f_t) + C\]</span></p><blockquote><p><strong>决策树的描述</strong> * 使用决策树对样本做分类(回归)，是从根结点到叶节点的细化过程；落在相同叶节点的样本的预测值是相同的 * 假定某决策树的叶结点数目为 <span class="math inline">\(T\)</span>，每个叶结点的权值为 <span class="math inline">\(\overrightarrow{w} = (w_1,w_2 ... w_T)\)</span> ，决策树的学习过程，就是构造如何使用特征得到划分，从而得到这些权值的过程。<strong>叶权值就是这个叶节点的预测结果</strong>，若是分类问题，也就是这类样本的标签。 * 样本 <span class="math inline">\(x\)</span> 落在叶结点 <span class="math inline">\(q\)</span> 中，定义描述决策树函数为: <span class="math inline">\(f_t(x) = w_q(x)\)</span> * 一个决策树的核心即“树结构”和“叶权值”</p></blockquote><p>决策树的复杂度可考虑叶结点数和叶权值，如使用叶结点总数和叶权值平方和的加权： <span class="math display">\[\Omega(f_t) = \gamma \cdot T_t + \lambda \cdot \frac{1}{2}\sum_{j=1}^Tw_j^2 \]</span> 其中，<span class="math inline">\(T_t\)</span> 为叶子的个数。</p><p>我们继续来推导目标函数 <span class="math inline">\(J(f_t)\)</span>：</p><p><span class="math display">\[\begin{array}{lcl}J(f_t) = \sum_{i=1}^n [L(y_i, F_{m-1}(x_i)) + g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)] + \Omega(f_t) + C \\\ \ \ \ \ \ \ = \sum_{i=1}^n[g_if_t(x_i) + \frac{1}{2}h_if_t^2(x_i)]+ \Omega(f_t) + C \\\ \ \ \ \ \ \ =\sum_{i=1}^n[g_iw_q(x_i) + \frac{1}{2}h_iw_q^2(x_i)] + \gamma \cdot T_t + \lambda \cdot \frac{1}{2}\sum_{j=1}^Tw_j^2 + C \\\ \ \ \ \ \ \ = \sum_{j=1}^T [(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\sum_{i \in I_j}h_i)w_j^2] + \gamma \cdot T_t + \lambda \cdot \frac{1}{2}\sum_{j=1}^Tw_j^2 + C \\\ \ \ \ \ \ \ = \sum_{j=1}^T[(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\lambda + \sum_{i \in I_j}h_i)w_j^2] + \gamma \cdot T_t + C\end{array}\]</span></p><p>令 <span class="math inline">\(G_j = \sum_{i \in I_j}g_i\)</span>，<span class="math inline">\(H_j = \sum_{i \in I_j}h_i\)</span>，从而： <span class="math display">\[J(f_t) = \sum_{j=1}^T[G_jw_j + \frac{1}{2}(\lambda + H_j)w_j^2] + \gamma \cdot T_t + C\]</span></p><p>对 <span class="math inline">\(w_j\)</span> 求偏导得： <span class="math display">\[\frac{\partial}{\partial w_j}J(f_t) = G_j + (\lambda + H_j)w_j\]</span></p><p>令 <span class="math inline">\(\frac{\partial J(f_t)}{\partial w_j} = 0\)</span>，得： <span class="math display">\[w_j = -\frac{G_j}{\lambda + H_j}\]</span></p><p>回代入目标函数得： <span class="math display">\[J(f_t) = -\frac{1}{2}\sum_{j=1}^T\frac{G_j^2}{\lambda + H_j} + \gamma \cdot T_t\]</span></p><p>这就是目标函数最后的结果，<strong>值越小代表决策树的结构越好</strong>。</p><p>我们要构建一颗决策树 <span class="math inline">\(f_t\)</span>，使目标函数 <span class="math inline">\(J(f_t)\)</span> 达到最小，构建时可借鉴<a href="https://neymarl.github.io/2016/09/02/%E5%86%B3%E7%AD%96%E6%A0%91%20&amp;%20%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%B8%AD%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/" target="_blank" rel="noopener">ID3/C4.5/CART</a>的做法：</p><ul><li>如何进行子树划分？<ul><li>对于某可行划分, 计算划分后的 <span class="math inline">\(J(f_t)\)</span></li><li>对于所有可行划分, 选择 <span class="math inline">\(J(f_t)\)</span> 降低最小的分割点</li></ul></li><li>枚举可行的分割点, 选择增益最大的划分, 继续同样的操作, 直到满足某阈值或得到纯节点<ul><li><span class="math inline">\(Gain(\phi) = \frac{1}{2}[\frac{G_L^2}{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda}]\)</span> <img src="/images/1473252993577.png"></li></ul></li></ul><p><strong>XGBOOST总结</strong></p><ul><li>XGBOOST 与 GBDT 的区别在于更新模型的方法不同，其余都是一样的</li><li>相对于传统的GBDT，XGBoost使用了<strong>二阶信息</strong>，可以更快的在训练集上收敛</li><li>由于“<strong>随机森林族</strong>”本身具备防止过拟合的优势，因此XGBoost仍然一定程度的具有该特性</li><li>XGBoost的实现中使用了<strong>并行/多核计算</strong>, 因此训练速度快; 同时它的原生语言为C/C++, 这是它速度快的实践原因</li></ul><h2><span id="adaboost">AdaBoost</span></h2><p><strong>思考</strong>：如果对GBDT的基函数的学习中，不止考虑函数的参数和权值，而是对样本本身也加权，会得到什么结果呢？这其实就是Adaboost的思想。</p><p><strong>AdaBoost算法</strong></p><ul><li><p>设训练数据集 <span class="math inline">\(T={(x_1,y_1), (x_2,y_2)...(x_N,y_N)}\)</span>，初始化训练数据的权值分布 <span class="math inline">\(D_1 = (w_{11}, w_{12}, ..., w_{1i}, ...., w_{1N})\)</span>, <span class="math inline">\(w_{1i} = \frac{1}{N}\)</span>, <span class="math inline">\(i = 1, 2, ... N\)</span>。</p></li><li>对于 <span class="math inline">\(m = 1, 2, ... M\)</span>，<span class="math inline">\(M\)</span> 为树的棵数:<ul><li><p>使用具有权值分布 <span class="math inline">\(D_m\)</span> 的训练数据集学习, 得到基本分类器 <span class="math display">\[G_m(x) : x \rightarrow \{-1, 1\}\]</span></p></li><li><p>计算 <span class="math inline">\(G_m(x)\)</span> 在训练数据集上的分类误差率: <span class="math display">\[e_m = P(G_m(x_i) \neq y_i) = \sum_{i=1}^Nw_{mi}I(G_m(x_i) \neq y_i)\]</span></p></li><li><p>计算 <span class="math inline">\(G_m(x)\)</span> 的系数 <span class="math display">\[\alpha_m = \frac{1}{2}\log \frac{1-e_m}{e_m}\]</span></p></li><li>更新训练数据集的权值分布 <span class="math display">\[D_{m+1} = (w_{m+1, 1}, w_{m+1, 2}, ...., w_{m+1, i}, ..., w_{m+1, N})\]</span> <span class="math display">\[w_{m+1, i} = \frac{w_{mi}}{Z_m}\exp(-\alpha_m y_iG_m(x_i)), i = 1, 2, ... , N\]</span></li><li>这里，<span class="math inline">\(Z_m\)</span> 是归一化因子： <span class="math display">\[Z_m = \sum_{i=1}^Nw_{mi}\exp(-\alpha_my_iG_m(x_i))\]</span></li><li><p>它使 <span class="math inline">\(D_{m+1}\)</span> 成为一个概率分布（和为1）。</p></li></ul></li><li><p>构建基本分类器的线性组合 <span class="math display">\[f(x) = \sum_{m=1}^M\alpha_mG_m(x)\]</span></p></li><li><p>得到最终分类器： <span class="math display">\[G(x) = sign(f(x)) = sign(\sum_{m=1}^M\alpha_mG_m(x))\]</span></p></li></ul><p><strong>算法解释</strong></p><p>我们先分析 <span class="math inline">\(G_m(x)\)</span> 的系数：<span class="math inline">\(\alpha_m = \frac{1}{2}\log \frac{1-e_m}{e_m}\)</span>，这里的 <span class="math inline">\(e_m\)</span> 是分类错误率。 这个式子实现了这么一个理论：如果一个分类器的分类错误率超过50%，那么这个分类器还不如随机分类（默认均匀分布，随机分50%错误率）来得好，把这个分类器直接反转效果反而会更好。</p><ul><li>如果 <span class="math inline">\(e_m &lt; 0.5\)</span>，则 <span class="math inline">\(1- e_m &gt; 0.5\)</span>，所以 <span class="math inline">\(\frac{1-e_m}{e_m} &gt; 1\)</span>，可以得到 <span class="math inline">\(\log\frac{1-e_m}{e_m} &gt; 0\)</span>，即：<span class="math inline">\(\alpha_m &gt; 0\)</span>，说明如果这个分类器的错误率小于0.5则权值为正，表示可以参考这个分类器的结果，并且错误率越低分类器的权值越大；</li><li>如果 <span class="math inline">\(e_m &gt; 0.5\)</span>，则 <span class="math inline">\(1- e_m &lt; 0.5\)</span>，所以 <span class="math inline">\(\frac{1-e_m}{e_m} &lt; 1\)</span>，可以得到 <span class="math inline">\(\log\frac{1-e_m}{e_m} &lt; 0\)</span>，即：<span class="math inline">\(\alpha_m &lt; 0\)</span>，就相当于把分类器反转。</li></ul><p>再来看权值更新公式，<span class="math inline">\(w_{m+1, i} = \frac{w_{mi}}{Z_m}\exp(-\alpha_m y_iG_m(x_i)), i = 1, 2, ... , N\)</span></p><ul><li><p>先看指数上的一小部分 : <span class="math inline">\(-\alpha_m y_iG_m(x_i)\)</span>，其中 <span class="math inline">\(-\alpha_m\)</span> 为该分类器的权值，<span class="math inline">\(y_i\)</span> 为第 <span class="math inline">\(i\)</span> 个样本的实际类别且 <span class="math inline">\(y_i \in \{-1, 1\}\)</span>，<span class="math inline">\(G_m(x_i)\)</span> 为预测类别。</p><ul><li>若预测类别与实际类别一致，则 <span class="math inline">\(y_iG_m(x_i) &gt; 0\)</span>，反之则 <span class="math inline">\(y_iG_m(x_i) &lt; 0\)</span></li><li>如果该分类器比较靠谱的话（<span class="math inline">\(e_m &lt; 0.5\)</span>），<span class="math inline">\(\alpha_m\)</span> 是个正数，反之是个负数。</li><li>综合起来看：如果靠谱的分类器预测错了（或者不靠谱的分类器预测对了），则 <span class="math inline">\(-\alpha_m y_iG_m(x_i) &gt; 0\)</span>，反之则 <span class="math inline">\(-\alpha_m y_iG_m(x_i) &lt; 0\)</span></li></ul></li><li><p><span class="math inline">\(Z_m\)</span> 是用来归一化的，不用看，把其他部分合起来：</p><ul><li>如果 <span class="math inline">\(-\alpha_m y_iG_m(x_i) &gt; 0\)</span>，则 <span class="math inline">\(\exp(-\alpha_m y_iG_m(x_i)) &gt; 1\)</span>，进而得到 <span class="math inline">\(w_{m+1, i} = w_{mi} * 一个大于1的数\)</span>，即权值增加。</li><li>如果 <span class="math inline">\(-\alpha_m y_iG_m(x_i) &lt; 0\)</span>，则 <span class="math inline">\(\exp(-\alpha_m y_iG_m(x_i)) &lt; 1\)</span>，进而得到 <span class="math inline">\(w_{m+1, i} = w_{mi} * 一个小于1的数\)</span>，即权值降低。</li></ul></li><li><p><strong>结论</strong>：如果分类器预测错了则增加该样本的权值，在下次分类时重点关注该样本；如果分类正确则降低该样本的权值，在下次分类时弱化该样本。也就是样本的权值动态变化，如下图所示：</p></li></ul><p><img src="/images/1473337734827.png"></p><h3><span id="误差分析">误差分析</span></h3><p>AdaBoost算法最终的误差界为：</p><p><span class="math display">\[\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant \frac{1}{N}exp(-y_if(x_i)) = \prod_mZ_m\]</span></p><p><strong>证明</strong></p><ul><li>前半部分：当 <span class="math inline">\(G(x_i) \neq y_i\)</span> 时，<span class="math inline">\(y_if(x_i) &lt; 0\)</span>，因而 <span class="math inline">\(exp(-y_if(x_i)) \geqslant 1\)</span>，而 <span class="math inline">\(\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant 1\)</span>，所以 <span class="math inline">\(\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant \frac{1}{N}exp(-y_if(x_i))\)</span>，前半部分得证。 <br></li><li>后半部分：<ul><li><p>由 <span class="math inline">\(Z_m\)</span> 的定义式得：<span class="math inline">\(w_{mi}exp(-\alpha_my_iG_m(x_i)) = Z_mw_{m+1,i}\)</span> <span class="math display">\[\begin{array}{lcl}\frac{1}{N}exp(-y_if(x_i)) \\= \frac{1}{N}\sum_i\exp(- \sum_{m=1}^M\alpha_my_iG_m(x_i)) \\= \sum_iw_{1i}\prod_{m=1}^M\exp(-\alpha_my_iG_m(x_i)) \\= Z_1\sum_i w_{2,1}\prod_{m=2}^M\exp(-\alpha_my_iG_m(x_i)) \\= Z_1Z_2\sum_i w_{3,1}\prod_{m=3}^M\exp(-\alpha_my_iG_m(x_i)) \\= .... \\= Z_1Z_2...Z_{M-1}\sum_i w_{M,1}\exp(-\alpha_my_iG_m(x_i)) \\= \prod_{m=1}^MZ_m\end{array}\]</span></p></li><li><p>后半部分得证</p></li></ul></li></ul><p>这一结果说明，可以在每一轮选取适当的 <span class="math inline">\(G_m\)</span> 使得 <span class="math inline">\(Z_m\)</span> 最小，从而使训练误差下降最快。</p><p><strong>训练误差界</strong></p><p><span class="math display">\[\begin{array}{lcl}Z_m = \sum_{i=1}^Nw_{mi}\exp(-\alpha_my_iG_m(x_i)) \\\ \ \ \ \ = \sum_{y_i=G_m(x_i)}w_{mi}e^{-\alpha_m} +  \sum_{y_i\neq G_m(x_i)}w_{mi}e^{\alpha_m}\end{array}\]</span></p><p>因为 <span class="math inline">\(\alpha_m = \frac{1}{2}\log\frac{1-e_m}{e_m}\)</span>，<span class="math inline">\(\sum_{y_i=G_m(x_i)}w_{mi} = 1 - e_m\)</span>，<span class="math inline">\(\sum_{y_i\neq G_m(x_i)}w_{mi} = e_m\)</span> 所以 <span class="math display">\[\begin{array}{lcl}Z_m = (1- e_m)e^{-\alpha_m} + e_me^{\alpha_m} \\\ \ \ \ \ = 2\sqrt{e_m(1-e_m)} \\\ \ \ \ \ = \sqrt{1-4\gamma_m^2}\end{array}\]</span> 其中，<span class="math inline">\(\gamma_m = \frac{1}{2} - e_m\)</span>。</p><p>由此得到： <span class="math display">\[\prod_{m=1}^MZ_m = \prod_{m=1}^M \sqrt{1-4\gamma_m^2} \leqslant \exp(-2\sum_{m=1}^M\gamma_m^2)\]</span></p><p>取 <span class="math inline">\(\gamma_1, \gamma_2....\)</span> 的最小值，记为 <span class="math inline">\(\gamma\)</span>， 则有： <span class="math display">\[\frac{1}{N}\sum_{i=1}^NI(G_m(x_i) \neq y_i) \leqslant \exp(-2M\gamma^2)\]</span></p><p>这表明AdaBoost训练误差是<strong>以指数速率下降</strong>的！</p><p><strong>AdaBoost总结</strong></p><ul><li>AdaBoost算法可以看做是采用指数损失函数的提升方法，其每个基函数的学习算法为前向分步算法</li><li>AdaBoost的训练误差是以指数速率下降的</li><li>AdaBoost算法不需要事先知道下界 <span class="math inline">\(\gamma\)</span>，具有<strong>自适应性(Adaptive)</strong>，它能自适应弱分类器的训练误差率</li></ul><h2><span id="参考文献">参考文献</span></h2><ul><li>李航，统计学习方法，清华大学出版社，2012</li><li>Jerome H. Friedman. Greedy Function Approximation: A Gradient Boosting Machine. February 1999</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Boosting </tag>
            
            <tag> GBDT </tag>
            
            <tag> xgboost </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>决策树 &amp; 随机森林中的公式推导</title>
      <link href="/2016/09/02/%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%B8%AD%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"/>
      <url>/2016/09/02/%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E4%B8%AD%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<p><strong>决策树学习的生成算法</strong>主要有三种： * ID3 * Iterative Dichotomiser * C4.5 * CART * Classification And Regression Tree</p><p>决策树建立就是从特征中选择一个作为分类条件把样本划分为两个子集，然后对每个子集做同样的事情直到每个子集都属于相同的标签。所以建立决策树的关键在于每次划分子集的时候选择哪个特征，这也是上面三种算法的最主要区别，下面将一一探讨。</p><a id="more"></a><h2><span id="id3">ID3</span></h2><p>要了解ID3算法首先要了解一下<strong>信息增益</strong>等知识。该算法也可以参考我前面的文章：<a href="http://www.liuhe.website/index.php?/Articles/single/46" target="_blank" rel="noopener">决策树之ID3算法详解</a>。</p><p><strong>信息熵</strong></p><pre><code>在信息论中，熵是接收的每条消息中包含的信息的平均量，又被稱為信息熵、信源熵、平均自信息量。这里，消息代表来自分布或数据流中的事件、样本或特征。（熵最好理解为不确定性的量度而不是确定性的量度，因为越随机的信源的熵越大。）来自信源的另一个特征是样本的概率分布。这里的想法是，比较不可能发生的事情，当它发生了，会提供更多的信息。由于一些其他的原因（下面会有解释），把信息（熵）定义为概率分布的对数的相反数是有道理的。事件的概率分布和每个事件的信息量构成了一个随机变量，这个随机变量的均值（即期望）就是这个分布产生的信息量的平均值（即熵）。                      -- from WikiPedia</code></pre><p>熵的公式定义为： <span class="math display">\[H(X) = E[-\ln P(x)] = -\sum_i P(x_i)ln(P(x_i)) \]</span></p><p>熵的直观解释是对<strong>不确定性</strong>的度量，熵越大不确定性越大，熵越小不确定性越小。</p><p><span class="math inline">\(H(X)\)</span> 随 <span class="math inline">\(P(x_i)\)</span> 变化的曲线为</p><p><img src="/images/1472795562715.png"></p><p>设随机变量 <span class="math inline">\(X\)</span> 只能取两个值 <span class="math inline">\(0\)</span> 和 <span class="math inline">\(1\)</span>，显然当取两个数的概率都为50%的时候不确定性最大，即熵最大为1；若取 <span class="math inline">\(0\)</span> 或取 <span class="math inline">\(1\)</span> 的概率为 100%，则事件完全确定，此时熵为0 。</p><p><strong>条件熵</strong></p><p>下面来讨论一下条件熵，它的定义式为：<span class="math inline">\(H(X, Y) - H(X)\)</span>。</p><p><span class="math inline">\((X,Y)\)</span> 发生所包含的熵,减去 <span class="math inline">\(X\)</span> 单独发生包含的熵： * 在 <span class="math inline">\(X\)</span> 发生的前提下, <span class="math inline">\(Y\)</span> 发生“新”带来的熵 * 该式子定义为 <span class="math inline">\(X\)</span> 发生前提下, <span class="math inline">\(Y\)</span> 的熵: * 条件熵 <span class="math inline">\(H(Y|X)\)</span></p><p>我们来推导一下这个式子等于什么。</p><p><span class="math display">\[\begin{array}{lcl}H(Y|X) = H(X, Y) - H(X) \\= -\sum_{x, y}p(x, y) \ln p(x, y) + \sum_x p(x)\ln p(x) \\= -\sum_{x, y}p(x, y) \ln p(x, y) + \sum_x\sum_y p(x, y) \ln p(x) \\= - \sum_{x, y} p(x, y) (\ln p(x, y) - \ln p(x)) \\= - \sum_{x, y} p(x, y) \ln\frac{p(x, y)}{p(x)} \\= - \sum_{x, y} p(x, y) \ln p(y\ |\ x)\end{array}\]</span></p><p>继续推导我们可以得到：</p><p><span class="math display">\[\begin{array}{lcl}H(X, Y) - H(X) \\=  - \sum_{x, y} p(x, y) \ln p(y\ |\ x) \\= -\sum_{x, y} p(x) p(y\ |\ x) \ln p(y\ |\ x) \\= \sum_x p(x) (- \sum_y p(y\ |\ x) \ln p(y\ |\ x)) \\= \sum_x p(x) H(Y\ |\ X = x) \\= E[H(Y\ |\ X = x)]\end{array}\]</span></p><p>是熵的<strong>数学期望</strong>！</p><p><strong>信息增益</strong></p><ul><li>信息增益表示得知特征 <span class="math inline">\(A\)</span> 的信息而使得类 <span class="math inline">\(X\)</span> 的信息的不确定性减少的程度。</li><li><strong>经验熵</strong>：当熵和条件熵中的概率由数据估计(特别是极大似然估计)得到时,所对应的熵和条件熵分别称为<strong>经验熵</strong>和<strong>经验条件熵</strong>。</li><li><strong>定义</strong>：特征 <span class="math inline">\(A\)</span> 对训练数据集 <span class="math inline">\(D\)</span> 的信息增益 <span class="math inline">\(g(D,A)\)</span>, 定义为集合 <span class="math inline">\(D\)</span> 的经验熵 <span class="math inline">\(H(D)\)</span> 与特征 <span class="math inline">\(A\)</span> 给定条件下 <span class="math inline">\(D\)</span> 的经验条件熵 <span class="math inline">\(H(D|A)\)</span> 之差, 即:<ul><li><span class="math inline">\(g(D,A)=H(D)\ – H(D\ |\ A)\)</span></li></ul></li></ul><p><em>基本记号</em></p><ul><li>设训练数据集为 <span class="math inline">\(D\)</span> , <span class="math inline">\(|D|\)</span> 表示样本个数。</li><li>设有 <span class="math inline">\(K\)</span> 个类 <span class="math inline">\(C_k\)</span> , <span class="math inline">\(k = 1, 2, ... K\)</span> , <span class="math inline">\(C_k\)</span> 为属于类 <span class="math inline">\(C_k\)</span> 的样本个数, 有: $_k | C_k | = | D | $</li><li>设特征 <span class="math inline">\(A\)</span> 有 <span class="math inline">\(n\)</span> 个不同的取值 <span class="math inline">\(\{a_1, a_2, ... a_n\}\)</span> ,根据特征 <span class="math inline">\(A\)</span> 的取值将 <span class="math inline">\(D\)</span> 划分为 <span class="math inline">\(n\)</span> 个子集 <span class="math inline">\(D_1, D_2, ... D_n\)</span> , 为 <span class="math inline">\(| D_i |\)</span> 为 <span class="math inline">\(D_i\)</span> 的样本个数，有：<span class="math inline">\(\sum_i |D_i| = |D|\)</span></li><li>记子集 <span class="math inline">\(D\)</span> 中属于类 <span class="math inline">\(C\)</span> 的样本的集合为 <span class="math inline">\(D_{ik}\)</span> ，<span class="math inline">\(|D_{ik}|\)</span> 为 <span class="math inline">\(D_{ik}\)</span> 的样本个数。</li></ul><p><strong>ID3算法</strong></p><ol type="1"><li>计算数据集 <span class="math inline">\(D\)</span> 的经验熵 <span class="math inline">\(H(D) = -\sum_{k=1}^K \frac{|C_k|}{|D|} log\frac{|C_k|}{|D|}\)</span></li><li>遍历所有特征, 对于特征 <span class="math inline">\(A\)</span> :<ul><li>计算特征 <span class="math inline">\(A\)</span> 对数据集 <span class="math inline">\(D\)</span> 的经验条件熵 <span class="math inline">\(H(D\ |\ A)\)</span></li><li>计算特征 <span class="math inline">\(A\)</span> 的信息增益 : <span class="math inline">\(g(D,A)=H(D) – H(D\ |\ A)\)</span></li><li>选择信息增益<strong>最大</strong>的特征作为当前的分裂特征</li></ul></li></ol><p><strong>条件经验熵 <span class="math inline">\(H(D\ |\ A)\)</span> 计算方法</strong></p><p><span class="math display">\[\begin{array}{lcl}H(D\ |\ A) = H(D, A) - H(A) \\= -\sum_{i,k} p(D_k, A_i) \log p(D_k, A_i) \\= - \sum_{i=1}^n p(A_i) \sum_{k=1}^K p(D_k\ |\ A_i) \log p(D_k\ |\ A_i) \\= - \sum_{i=1}^n \frac{|D_i|}{|D|} \sum_{k=1}^K \frac{|D_{ik}|}{|D_i|} \log \frac{|D_{ik}|}{|D_i|}\end{array}\]</span></p><p>以上就是 ID3 算法的核心内容。</p><p>但是ID3算法有一个问题，算法每次选择一个信息增益最大的特征进行子集划分，这样就会倾向于选择一些取值很多而且每个值对应的样本很少的特征，比如样本序号（如果你把它加入特征的话），若选择样本序号作为划分子集的特征，则可一次划分结束，所有子集都变为叶子节点，<strong>熵为零</strong>，但是这样分类并没有意义，因为它完全<strong>过拟合</strong>了而且<strong>没有任何预测能力</strong>。为了避免这种情况的发生，我们需要改进这种选择特征标准，于是就有了C4.5和CART。</p><h2><span id="c45">C4.5</span></h2><p>C4.5 对 ID3 的主要改进在于每次分割选择特征的标准，由<strong>信息增益</strong>换成了<strong>信息增益率</strong>。</p><p><strong>信息增益率</strong></p><p>定义式： <span class="math display">\[g_r(D, A) = \frac{g(D, A)}{H(A)}\]</span></p><p>其中 <span class="math inline">\(H(A)\)</span> 为选择特征 <span class="math inline">\(A\)</span> 的熵，<span class="math inline">\(H(A) = -\sum_i p(A_i) \log p(A_i) = -\sum \frac{|D_i|}{|D|} \log \frac{|D_i|}{|D|}\)</span></p><h2><span id="cart">CART</span></h2><p><strong>Classification And Regression Tree</strong></p><p>CART 再次更换了选择特征标准，它采用<strong>Gini系数</strong>作为评判标准。</p><p><strong>Gini 系数</strong></p><p>定义式：</p><p><span class="math display">\[Gini(p) = \sum_{k=1}^Kp_k(1-p_k) = 1 - \sum_{k=1}^Kp_k^2 ＝1 - \sum_{k=1}^K(\frac{|C_k|}{|D|})^2 \]</span></p><p>Gini系数看起来比较突兀，根据著名机器学习讲师<a href="http://weibo.com/u/2306141363" target="_blank" rel="noopener">邹博</a>的观点，Gini系数实则是对<strong>信息增益</strong>的近似： * 将 <span class="math inline">\(f(x) = -\ln x\)</span> 在 <span class="math inline">\(x = 1\)</span> 处<strong>一阶展开</strong>，忽略高阶无穷小，得到 <span class="math inline">\(f(x) \approx 1 - x\)</span> * $H(x) = -<em>{k=1}^Kp_k p_k </em>{k=1}^Kp_k(1 - p_k) = Gini(p) $ * Gini系数与熵的对比图如下：</p><p><img src="/images/1472819902545.png"></p><p><strong>三种决策树的学习算法</strong></p><ul><li>ID3 : 使用信息增益/互信息 <span class="math inline">\(g(D,A)\)</span> 进行特征选择<ul><li>取值多的属性,更容易使数据更纯 ,其信息增益更大。</li><li>训练得到的是一棵庞大且深度浅的树 : 不合理。</li></ul></li><li>C4.5 : 信息增益率 <span class="math inline">\(g_r(D,A) = g(D,A) / H(A)\)</span></li><li>CART : 基尼指数</li><li>一个属性的<strong>信息增益(率)/Gini指数越大</strong>, 表明属性对样本的熵减少的能力更强, 这个属性使得<strong>数据由不确定性变成确定性的能力越强</strong>。</li></ul><p><strong>决策树的评价</strong></p><ul><li>假定样本的总类别为 <span class="math inline">\(K\)</span> 个</li><li>对于决策树的某叶结点,假定该叶结点含有样本数目为 <span class="math inline">\(n\)</span> , 其中 第 <span class="math inline">\(k\)</span> 类的样本点数目为 <span class="math inline">\(n_k\)</span>, <span class="math inline">\(k=1,2,...,K\)</span>。<ul><li>若某类样本 <span class="math inline">\(n_j=n\)</span> 而 <span class="math inline">\(n_1,...,n_{j-1},n_{j+1},...,n_K=0\)</span>, 称该结点为<strong>纯结点</strong>;</li><li>若各类样本数目 <span class="math inline">\(n_1=n_2=...=n_k=n/K\)</span>, 称该样本为<strong>均结点</strong>。</li></ul></li><li>纯结点的熵 <span class="math inline">\(H_p=0\)</span>, <strong>最小</strong></li><li>均结点的熵 <span class="math inline">\(H_u=\ln K\)</span>, <strong>最大</strong></li><li>对所有叶结点的<strong>熵求和</strong>, 该值<strong>越小</strong>说明对样本的分类<strong>越精确</strong><ul><li>各叶结点包含的样本数目不同,可使用样本数加权求熵和</li></ul></li><li><strong>评价函数</strong> :<ul><li><span class="math inline">\(C(T) = \sum_{t \in leaf} N_t \cdot H(t)\)</span></li><li>由于该评价函数越小越好, 所以可以称之为“损失函数”。</li></ul></li></ul><p><strong>剪枝</strong></p><p>决策树对训练属于有很好的分类能力, 但对未知的测试数据未必有好的分类能力, 泛化能力弱, 即可能发生<strong>过拟合</strong>现象。</p><p>适当的剪枝可以防止过拟合现象，<strong>三种决策树的剪枝过程算法相同</strong>, 区别仅是对于当前树的评价标准不同。</p><p><strong>剪枝总体思路</strong></p><ul><li>由完全树 <span class="math inline">\(T_0\)</span> 开始,剪枝部分结点得到 <span class="math inline">\(T_1\)</span>, 再次剪枝部分结点得到<span class="math inline">\(T_2\)</span>...直到仅剩树根的树 <span class="math inline">\(T_k\)</span>;</li><li>在验证数据集上对这 <span class="math inline">\(k\)</span> 个树分别评价, 选择损失函数最小的树 <span class="math inline">\(T_α\)</span>。</li></ul><h2><span id="随机森林">随机森林</span></h2><p><strong>Bagging</strong></p><p>在谈随机森林之前先来看看 Bagging 的策略 * bootstrap aggregation * 从样本集中重采样(有重复的)选出 <span class="math inline">\(n\)</span> 个样本 * 在所有属性上, 对这 <span class="math inline">\(n\)</span> 个样本建立分类器 (ID3、C4.5、CART、SVM、Logistic回归等) * 重复以上两步 <span class="math inline">\(m\)</span> 次, 即获得了 <span class="math inline">\(m\)</span> 个分类器 * 将数据放在这 <span class="math inline">\(m\)</span> 个分类器上,最后根据这 <span class="math inline">\(m\)</span> 个分类器的投票结果, 决定数据属于哪一类</p><blockquote><p>Bootstraping的名称来自成语“pull up by your own bootstraps”, 意思是依靠你自己的资源, 称为自助法, 它是一种<strong>有放回的抽样方法</strong>。</p></blockquote><p><img src="/images/1472826789356.png"></p><p><strong>随机森林</strong></p><p>随机森林就是在Bagging的基础上做了些修改： * 从样本中用 Bootstrap 采养出 <span class="math inline">\(n\)</span> 个样本 * 从所有属性中随机选择 <span class="math inline">\(k\)</span> 个属性，建立 CART 树 * 重复以上步骤 <span class="math inline">\(m\)</span> 次，即建立了 <span class="math inline">\(m\)</span> 棵 CART 树 * 这 <span class="math inline">\(m\)</span> 个 CART 形成随机森林,通过投票表决结果，决定数据属于哪一类</p><p>当然可以使用决策树作为基本分类器，也可以使用SVM、Logistic回归等其他分类器, 习惯上, 这些分类器组成的“总分类器”, 仍然叫做<strong>随机森林</strong>。不过随机森林的思想是使用很多个<strong>弱分类器</strong>（受异常点影响较小）投票得出一个<strong>强分类器</strong>，所以把小树们换成SVM、LR等强分类器效果不一定会更好，反而可能会更容易受异常点影响（理论上）。</p><p><strong>投票机制</strong></p><p>投票机制一般有以下几种，少数服从多数用的比较多了： * 简单投票机制 * 一票否决 * 少数服从多数 * 有效多数（加权） * 阈值表决 * 贝叶斯投票机制 * Laplace平滑</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Decision Tree </tag>
            
            <tag> ID3 </tag>
            
            <tag> C4.5 CART </tag>
            
            <tag> 随机森林 </tag>
            
            <tag> Bagging </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>线性回归中的一些公式推导</title>
      <link href="/2016/08/30/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"/>
      <url>/2016/08/30/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<h2><span id="使用极大似然估计推导损失函数">使用极大似然估计推导损失函数</span></h2><p><strong>回归方程</strong></p><p><span class="math display">\[h_\theta(x) = \sum^n_{i=0}\theta_ix_i = \theta^Tx\]</span></p><p>考虑任意一样本 <span class="math inline">\(y^{(i)}\)</span> ，则有： <span class="math display">\[y^{(i)} = \theta^Tx^{(i)} + \epsilon^{(i)}\]</span> 其中 <span class="math inline">\(\epsilon^{(i)}\)</span> 是误差。</p><a id="more"></a><p>由于每个样本的误差 <span class="math inline">\(\epsilon^{(i)}\)</span>： * 独立同分布（IDD） * 具有有限的数学期望和方差</p><p>所以由<a href="https://www.wikiwand.com/zh/%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86" target="_blank" rel="noopener">中心极限定理</a>得：<span class="math inline">\(\epsilon^{(i)}\)</span> 服从均值为0，方差为某一定值 <span class="math inline">\(\sigma^2\)</span> 的正态分布。</p><blockquote><p><strong>中心极限定理</strong>是概率论中的一组定理。中央极限定理说明，<strong>大量相互独立的随机变量，其均值的分布以正态分布为极限</strong>。这组定理是数理统计学和误差分析的理论基础，指出了大量随机变量之和近似服从正态分布的条件。 ——from WikiPedia</p></blockquote><p>则 <span class="math inline">\(\epsilon^{(i)}\)</span> 的概率密度函数为： <span class="math display">\[P(\epsilon^{(i)}) = \frac{1}{\sqrt{2\pi\sigma}}e^{\frac{-(\epsilon^{(i)})^2}{2\sigma^2}} \]</span></p><p>把 $ ^{(i)} = y^{(i)} - <sup>Tx</sup>{(i)}$ 代入上式得：</p><p><span class="math display">\[ P(y^{(i)}|x^{(i)};\theta) = \frac{1}{\sqrt{2\pi\sigma}}\exp(\frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2}) \]</span></p><p><span class="math inline">\(\because\)</span> 所有样本发生的概率独立同分布 <span class="math inline">\(\therefore\)</span> <a href="https://www.wikiwand.com/zh/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">似然函数</a>为所有样本发生概率的乘积，即：</p><p><span class="math display">\[\begin{array}{lcl}L(\theta) = \prod^{m}_{i=1} P(y^{(i)}|x^{(i)};\theta) \\ = \prod^{m}_{i=1} \frac{1}{\sqrt{2\pi\sigma}}\exp(\frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2})  \end{array} \]</span></p><blockquote><p>在数理统计学中，<strong>似然函数</strong>是一种关于统计模型中的参数的函数，表示模型参数中的似然性。似然函数在统计推断中有重大作用，如在最大似然估计和费雪信息之中的应用等等。“似然性”与“或然性”或“概率”意思相近，都是指某种事件发生的可能性，但是在统计学中，“似然性”和“或然性”或“概率”又有明确的区分。概率用于在已知一些参数的情况下，预测接下来的观测所得到的结果，而似然性则是用于在已知某些观测所得到的结果时，对有关事物的性质的参数进行估计。 ——from WikiPedia</p></blockquote><p>对 <span class="math inline">\(L(\theta)\)</span> 取对数得对数似然函数：</p><p><span class="math display">\[\begin{array}{lcl}l(\theta) = \log L(\theta) \\ = \log \prod^{m}_{i=1} \frac{1}{\sqrt{2\pi\sigma}}\exp(\frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2})  \\ = m\log \frac{1}{\sqrt{2\pi\sigma}} + \sum^m_{i=1} \frac{-(y^{(i)} - \theta^Tx^{(i)})^2}{2\sigma^2} \\ = m\log \frac{1}{\sqrt{2\pi\sigma}} - \frac{1}{\sigma^2} \cdot \frac{1}{2} \sum^m_{i=1} (y^{(i)} - \theta^Tx^{(i)})^2\end{array}\]</span></p><p>若要使对数似然函数取得最大值，把常数项和定值去掉，令 <span class="math display">\[J(\theta) = \frac{1}{2}\sum^{m}_{i=1}(y^{(i)} - \theta^Tx^{(i)})^2\]</span> 则 <span class="math inline">\(J(\theta)\)</span> 应取得最小值， 即为损失函数（目标函数）。</p><hr><h2><span id="求解最小二乘意义下参数最优解">求解最小二乘意义下参数最优解</span></h2><p><strong>目标函数</strong></p><p><span class="math display">\[ J(\theta) = \frac{1}{2}\sum^{m}_{i=1}(y^{(i)} - \theta^Tx^{(i)})^2 = \frac{1}{2}(X\theta - y)^T(X\theta - y)\]</span></p><p><strong>求梯度</strong></p><blockquote><p>在向量微积分中，标量场的梯度是一个向量场。标量场中某一点的梯度指向在這點标量场增长最快的方向。 —— from WikiPedia</p></blockquote><p><span class="math display">\[\begin{array}{lcr}\nabla_\theta J(\theta) = \frac{\partial}{\partial \theta}(\frac{1}{2}(X\theta - y)^T(X\theta - y)) \\= \frac{\partial}{\partial \theta}(\frac{1}{2}(\theta^TX^T - y^T)(X\theta - y))\end{array} \\= \frac{\partial}{\partial \theta} (\frac{1}{2}(\theta^TX^TX\theta - \theta^TX^Ty - y^TX\theta + y^Ty) ) \\= \frac{1}{2}(2X^TX\theta - X^Ty - (y^TX)^T) \\= X^TX\theta - X^Ty\]</span></p><p><strong>标量求梯度</strong> <img src="/images/1472541353509.png"></p><p><strong>求驻点</strong></p><p>令 <span class="math inline">\(\nabla_\theta J(\theta) = 0\)</span>，即 <span class="math inline">\(X^TX\theta - X^Ty = 0\)</span>，解得： <span class="math display">\[\theta = (X^TX)^{-1}X^Ty\]</span></p><p>若 <span class="math inline">\(X^TX\)</span> <strong>不可逆</strong>或防止<strong>过拟合</strong>，增加 <span class="math inline">\(\lambda\)</span> 扰动： <span class="math display">\[\theta = (X^TX + \lambda I)^{-1}X^Ty\]</span></p><p>上两式即为最小二乘意义下的参数最优解。</p><h2><span id="logistic-回归的损失函数及参数估计">Logistic 回归的损失函数及参数估计</span></h2><p><strong>Sigmoid函数</strong></p><ul><li>$g(z) =  $</li></ul><p><strong>Sigmoid函数的导数</strong></p><p><span class="math display">\[\begin{array}{lcr}g&#39;(z) = (\frac{1}{1 + e^{-z}})&#39; \\= \frac{e^{-z}}{(1 + e^{-z})^2} \\= \frac{1}{1 + e^{-z}} - \frac{1}{(1 + e^{-z})^2} \\= g(z)(1 - g(z))\end{array}\]</span></p><p><strong>回归方程</strong></p><ul><li><span class="math inline">\(h_\theta(x) = g(\theta^TX) = \frac{1}{1 + e^{-\theta^TX}}\)</span></li></ul><p><strong>损失函数</strong></p><p>设 $y {1, 0} $ 并且服从二向分布，即：</p><p><span class="math display">\[P(y = 1 | x; \theta) = h_\theta(x)\]</span> <span class="math display">\[P(y = 0 | x; \theta) = 1- h_\theta(x)\]</span></p><p>则任意样本 <span class="math inline">\(y^{(i)}\)</span> 的概率密度为</p><p><span class="math display">\[P(y^{(i)} | x^{(i)}; \theta) = h_\theta(x^{(i)})^{y^{(i)}}(1 - h_\theta(x^{(i)}))^{1 - y^{(i)}} \]</span></p><p><span class="math inline">\(\because\)</span> 所有样本发生的概率独立同分布 <span class="math inline">\(\therefore\)</span> <a href="https://www.wikiwand.com/zh/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">似然函数</a>为所有样本发生概率的乘积，即：</p><p><span class="math display">\[\begin{array}{lcr}L(\theta) =  \prod^{m}_{i=1} P(y^{(i)}|x^{(i)};\theta) \\=  \prod^{m}_{i=1} h_\theta(x^{(i)})^{y^{(i)}}(1 - h_\theta(x^{(i)}))^{1 - y^{(i)}}\end{array}\]</span></p><p>对两边同时取对数得对数似然函数为：</p><p><span class="math display">\[\begin{array}{lcr}l(\theta) = \log L(\theta) \\= \log \prod^{m}_{i=1} h_\theta(x^{(i)})^{y^{(i)}}(1 - h_\theta(x^{(i)}))^{1 - y^{(i)}} \\= \sum^m_{i = 1}   y^{(i)} \log h_\theta(x^{(i)}) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))  \\= \sum^m_{i = 1} y^{(i)} \log(\frac{1}{1 + e^{-\theta x^{(i)}}}) + (1 - y^{(i)})\log(\frac{e^{-\theta x^{(i)}}}{1 + e^{-\theta x^{(i)}}}) \\= \sum^m_{i = 1} y^{(i)} \log(\frac{1}{1 + e^{-\theta x^{(i)}}}) + (1 - y^{(i)})\log(\frac{1}{1 + e^{\theta x^{(i)}}}) \\\end{array}\]</span></p><p>令 $J() = -l() = ^m_{i = 1} y^{(i)} (1 + e<sup>{-x</sup>{(i)}}) + (1 - y^{(i)})(1 + e<sup>{x</sup>{(i)}}) $，即为logistic回归的损失函数。</p><p>若令 $y {1, -1} $，进行同样的推导可得另一种形式的损失函数:</p><p><span class="math display">\[J(\theta) = \sum^m_{i = 1} \log(1 + e^{-y^{(i)}\theta x^{(i)}}) \]</span></p><p>证明如下：</p><p><img src="/images/1472545621202.png"></p><p><strong>参数估计</strong></p><p>求梯度，对对数似然函数（损失函数）对 <span class="math inline">\(\theta\)</span> 求偏导得 ：</p><p><span class="math display">\[\begin{array}{lcr}\frac{\partial}{\partial \theta_j}l(\theta) = \frac{\partial}{\partial \theta_j}\sum^m_{i = 1}   y^{(i)} \log h_\theta(x^{(i)}) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)})) \\= \sum^m_{i = 1} y^{(i)}\frac{1}{h_\theta(x^{(i)})}\frac{\partial h_\theta(x^{(i)})}{\partial \theta_j} + (1 - y^{(i)}) \frac{1}{1 - h_\theta(x^{(i)})}\frac{-\partial h_\theta(x^{(i)})}{\partial \theta_j}  \\=  \sum^m_{i = 1} y^{(i)}(1 - h_\theta(x^{(i)}))x_j^{(i)} - (1 - y^{(i)}) h_\theta(x^{(i)})x_j^{(i)} \\= \sum^m_{i = 1} (y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)}\end{array}\]</span></p><p>所以参数的学习规则为：</p><p><span class="math display">\[\theta_j := \theta_j + \alpha(y^{(i)} - h_\theta(x^{(i)}))x_j^{(i)} \]</span></p><p>与线性回归的更新规则相同！</p><p><strong>对数线性模型</strong></p><p><img src="/images/1472546918441.png"></p><h2><span id="softmax-回归">Softmax 回归</span></h2><p><img src="/images/1472547052270.png"></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Linear Regression </tag>
            
            <tag> Logistic Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>阿里音乐流行趋势预测大赛总结</title>
      <link href="/2016/07/22/%E9%98%BF%E9%87%8C%E9%9F%B3%E4%B9%90%E6%B5%81%E8%A1%8C%E8%B6%8B%E5%8A%BF%E9%A2%84%E6%B5%8B%E5%A4%A7%E8%B5%9B%E6%80%BB%E7%BB%93/"/>
      <url>/2016/07/22/%E9%98%BF%E9%87%8C%E9%9F%B3%E4%B9%90%E6%B5%81%E8%A1%8C%E8%B6%8B%E5%8A%BF%E9%A2%84%E6%B5%8B%E5%A4%A7%E8%B5%9B%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2><span id="赛题分析">赛题分析</span></h2><p>题目要求根据用户过去六个月的交互纪录来预测未来两个月歌手的播放量。</p><a id="more"></a><h2><span id="解题思路">解题思路</span></h2><h3><span id="数据感知">数据感知</span></h3><p>刚开始拿到数据之后做了一些简单的统计，发现艺人数量不是很多，只有50个，用户数量35万左右，而且每个用户的平均交互数量很低，半年内只有16次，低于平均值的用户占比70+%。总体来看活跃用户不多，把歌手播放量曲线画出来之后发现大部分的歌手的播放量都在2000以下。</p><h3><span id="预测用户行为">预测用户行为</span></h3><p>开始我们打算通过预测用户的播放行为来预测歌手的播放量，因为感觉这样有理有据，比如一个用户今天播放并下载了一首歌曲，那么他明天很可能还会听这首歌等等。根据这些逻辑我们从历史纪录里提取出了一些特征，然后用这些特征预测下一天的播放量，把预测好的再加入历史纪录用于预测下下一天，如此反复直到预测完2个月的播放量。</p><p>但是这样做有几个问题：</p><ul><li>首先，训练周期太长。光提取特征就要花一个小时左右的时间，再加上训练，合并训练集等，一共要两个小时左右，但这才预测了1天，把60天都预测完需要 60 * 2 = 120 小时，所以这么做肯定不行。</li><li>其次，单个用户的随机性太强，导致训练误差也非常大，而且误差还会积累。 于是我们就放弃了这种方法。</li></ul><h3><span id="时间序列分析">时间序列分析</span></h3><p>时间序列分析的方法也是参赛后在交流群里听说的，有人说用ARIMA能做到6200（当时第一6500+），我就去查了查，发现了时间序列分析这个理论体系。</p><p>于是我也用ARIMA试了，但是遇到一个很蛋疼的问题，ARIMA预测的好坏很依赖于他的参数！虽然50个歌手不多，但是为每个歌手单独调参肯定会累死，大家都用一套参数效果又不好。这时我又发现了R的<code>auto.arima</code>，用这个可以自动调参，但用了之后发现效果也没那么好，记得好像6000分左右吧。</p><h3><span id="均值大法好">均值大法好</span></h3><p>在第一赛季期间总是有人在群里说规则轻松6500，模型打不过规则等，但一直不知道规则是啥，感觉很神秘很牛逼，后来才恍然大悟，这个比赛里它们说的规则就是取均值。</p><p>我就一点一点试，发现取最后十天左右的均值确实可以达到6500，刚发现的时候排名还挺高，后来大家都知道了排名就下来了，不过一直稳定在前100名。</p><p>从此以后我的方法就一直围绕均值展开，各种变花样均值，比如滑动窗口、平滑一下再取均值、STL分解一下再取均值等。</p><h3><span id="回归模型">回归模型</span></h3><p>到了第二赛季，平台上没有提供时间序列算法，只能用回归模型了，先后试了GBDT和XGBOOST，前者预测出来好多负值，非常不靠谱，不造怎么回事，后者还可以，虽然效果不如均值，但最起码比较接近。</p><p>回归模型的好坏主要依赖于特征的选择，就好比你要判断一个人是男是女，如果你的判断依据是头发长短，头发长认为是女生，头发短认为是男生，那么你判断的正确率可能在95%左右；但如果你的判断依据是那个人的染色体数目，那么你的正确率肯定在99.999%以上。</p><p>我在某次选择时加上了下载量这个特征，发现预测78月的效果超过了均值，不过由于没有9、10月的下载量数据，所以用均值替代，我把78月的真实下载量也用均值替代，重新预测78月的播放量发现也比均值的效果好。可是，当我用该方法预测9、10月时，分数TMD也变低了！线上效果又没有均值好，很醉。后来还尝试了不同的特征、feature stack等方法，效果都不如花样均值。</p><p>最后我只有祭出目测大法，才稍稍提了几分，能留在前50实属万幸。</p><h2><span id="赛后总结">赛后总结</span></h2><p>赛后看了其他人写的博客发现，自己数据预处理做的不够，那些爆发点很可能是刷单的，应该清洗掉，但当时没考虑到，而且感觉比赛的时候思维比较局限，总是围绕着一点转来转去，导致最后效果一般。</p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> 数据挖掘 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>决策树之ID3算法详解</title>
      <link href="/2016/07/16/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B9%8BID3%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/"/>
      <url>/2016/07/16/%E5%86%B3%E7%AD%96%E6%A0%91%E4%B9%8BID3%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#决策树简介">决策树简介</a><ul><li><a href="#构造决策树">构造决策树</a></li></ul></li><li><a href="#id3-算法">ID3 算法</a><ul><li><a href="#概揽">概揽</a></li><li><a href="#信息增益">信息增益</a></li><li><a href="#划分数据集">划分数据集</a></li><li><a href="#递归构建决策树">递归构建决策树</a></li></ul></li><li><a href="#总结">总结</a></li><li><a href="#参考">参考</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="决策树简介">决策树简介</span></h2><p>决策树（Decision tree）由一个决策图和可能的结果组成， 用来创建到达目标的规划。决策树建立并用来辅助决策，是一种特殊的树结构。决策树是一个利用像树一样的图形或决策模型的决策支持工具，包括随机事件结果，资源代价和实用性。它是一个算法显示的方法。决策树经常在运筹学中使用，特别是在决策分析中，它帮助确定一个能最可能达到目标的策略。如果在实际中，决策不得不在没有完备知识的情况下被在线采用，一个决策树应该平行概率模型作为最佳的选择模型或在线选择模型算法。决策树的另一个使用是作为计算条件概率的描述性手段。</p><p>機器學習中，決策樹是一個預測模型；他代表的是對象屬性與對象值之間的一種映射關係。樹中每個節點表示某個對象，而每個分叉路徑則代表的某個可能的屬性值，而每個葉結點則對應從根節點到該葉節點所經歷的路徑所表示的對象的值。決策樹僅有單一輸出，若欲有複數輸出，可以建立獨立的決策樹以處理不同輸出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。</p><h3><span id="构造决策树">构造决策树</span></h3><p>在构造决策树时，我们需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时取决定性作用。为了找到决定性特征，划分出最好的结果，我们必须评估每个特征。完成测试之后，原始数据集就被划分为几个数据子集。如果数据子集内的数据不属于同一类型，则需要重复划分数据子集的过程。</p><p>划分数据子集的伪代码 <code>createBranch()</code>如下所示：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">检测数据集中的每个子项是否属于同一分类:</span><br><span class="line"><span class="keyword">if</span> 是 <span class="keyword">return</span> 类标签</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">寻找划分数据集的最好特征</span><br><span class="line">划分数据集</span><br><span class="line">创建分支节点</span><br><span class="line"><span class="keyword">for</span> 每个划分的子集</span><br><span class="line">调用createBranch并增加返回结果到分支节点中</span><br><span class="line"><span class="keyword">return</span> 分支节点</span><br></pre></td></tr></table></figure><p>可见创建决策树就是反复划分数据集的过程，那么如何划分数据集、何时停止划分就是决策树构造的关键，本文主要介绍ID3算法及其实现。</p><h2><span id="id3-算法">ID3 算法</span></h2><h3><span id="概揽">概揽</span></h3><p>ID3算法（Iterative Dichotomiser 3）是一个由Ross Quinlan发明的用于决策树的算法。</p><p>这个算法是建立在奥卡姆剃刀的基础上：越是小型的决策树越优于大的决策树。尽管如此，该算法也不是总是生成最小的树形结构。而是一个启发式算法。奥卡姆剃刀阐述了一个信息熵的概念：</p><p><span class="math display">\[I_E(i)=-\sum _{j=1}^{m}f(i,j)\log _2f(i,j)\]</span></p><p>这个ID3算法可以归纳为以下几点： * 使用所有没有使用的属性并计算与之相关的样本熵值 * 选取其中熵值最小的属性 * 生成包含该属性的节点</p><h3><span id="信息增益">信息增益</span></h3><p>划分数据集的最大原则是：<strong>将无序的数据变得更加有序</strong>。我们可以使用多种方法划分数据集，但是每种方法都有各自优缺点。组织杂乱无章的数据的一种方法就是使用<em>信息论</em>度量信息。</p><p>在划分数据集之前之后信息发生的变化称为<strong>信息增益</strong>，知道如何计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。</p><p>集合信息的度量方式被称为香农熵或简称熵。</p><p><strong>熵（entropy）</strong>定义为信息的期望值，在明晰这个概念之前，我们必须知道信息的定义。如果待分类事务可能划分在多个分类之中，则符号 <span class="math inline">\(x_i\)</span> 的信息定义为</p><p><span class="math display">\[l(x_i) = -log_2p(x_i)\]</span> 其中 <span class="math inline">\(p(x_i)\)</span> 是选择该分类的概率。</p><p>所以计算熵的公式为：</p><p><span class="math display">\[H = -\sum_{i=1}^np(x_i)log_2p(x_i)\]</span> 其中 <span class="math inline">\(n\)</span> 是分类的数目。</p><p>下面的Python代码将示例如何计算给定数据集的熵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcShannonEnt</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    numEntries = len(dataSet)</span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        currentLabel = featVec[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">            labelCounts[currentLabel] = <span class="number">0</span></span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob = float(labelCounts[key]) / numEntries</span><br><span class="line">        shannonEnt -= prob * log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br></pre></td></tr></table></figure><p>把上述代码保存为 <code>decisiontree.py</code>，在为其添加一个创建数据集函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">    dataSet = [[<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">1</span>, <span class="string">'yes'</span>],</span><br><span class="line">               [<span class="number">1</span>, <span class="number">0</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>],</span><br><span class="line">               [<span class="number">0</span>, <span class="number">1</span>, <span class="string">'no'</span>]]</span><br><span class="line">    labels = [<span class="string">'no surfacing'</span>, <span class="string">'flippers'</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br></pre></td></tr></table></figure><p>在Python命令提示符下输入下列命令：</p><p><img src="/images/1468651153427.png"></p><p>熵越高，则混合的数据也越多。得到熵之后，我们就可以按照获取最大信息增益的方法划分数据集。</p><h3><span id="划分数据集">划分数据集</span></h3><p>我们将对每个特征划分数据集的结果计算一次信息熵，然后判断按照哪个特征划分是最好的方式。</p><p>在 <code>decisiontree.py</code> 中加入如下代码： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataSet</span><span class="params">(dataSet, axis, value)</span>:</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:</span><br><span class="line">            reducedFeatVec = featVec[:axis]</span><br><span class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])</span><br><span class="line">            retDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br></pre></td></tr></table></figure></p><p>上述代码使用了三个输入参数：待划分数据集、划分数据集的特征、需要返回的特征的值。我们可以在前面的简单样本数据上测试函数 <code>splitDataSet()</code> 函数：</p><p><img src="/images/1468651789771.png"></p><p>接下来我们将遍历整个数据集，循环计算熵，找到最好的划分方式，在 <code>decisiontree.py</code> 中添加如下函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">chooseBestFeat</span><span class="params">(dataSet)</span>:</span></span><br><span class="line">    numFeatures = len(dataSet[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    baseEntroy = calcShannonEnt(dataSet)</span><br><span class="line">    bestInfoGain = <span class="number">0.0</span></span><br><span class="line">    bestFeature = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numFeatures):</span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        uniqueVals = set(featList)</span><br><span class="line">        newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)</span><br><span class="line">            prob = len(subDataSet) / float(len(dataSet))</span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)</span><br><span class="line">        infoGain = baseEntroy - newEntropy</span><br><span class="line">        <span class="keyword">if</span> infoGain &gt; bestInfoGain:</span><br><span class="line">            bestInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br></pre></td></tr></table></figure><p>在上述代码中调用的数据集需要满足一定的要求： 1. 数据必须是一种由列表元素组成的列表，而且所有元素都要具有相同的数据长度 2. 数据的最后一列或者每个实例的最后一个元素是当前类的标签</p><p>现在我们可以测试上面代码的实际输出结果： <img src="/images/1468652728528.png"></p><p>代码的运行结果告诉我们，第0个特征是最好的用于划分数据集的特征，划分的正确性请读者自行检验。</p><h3><span id="递归构建决策树">递归构建决策树</span></h3><p>目前我们已经学习了从数据集构造决策树算法所需的所有子功能模块，下面我们采用递归的原则构建整个决策树。</p><p><strong>递归结束的条件</strong>是：程序遍历完所有划分数据集的属性，或者每个分支下的所有实例都具有相同的分类。</p><p>如果数据集已经处理了所有属性，但类标签依然不是唯一的，此时我们需要决定如何定义该叶子节点，在这种情况下，我们通常会采用多数表决的方法决定叶子节点的分类。</p><p>打开文本编辑器，添加如下代码到 <code>decisiontree.py</code> 中： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">majorityCnt</span><span class="params">(classList)</span>:</span></span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys():</span><br><span class="line">            classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">        sortedClassCnt = sorted(classCount.iteritems(),</span><br><span class="line">                                key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">return</span> sortedClassCnt[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(dataSet, labels)</span>:</span></span><br><span class="line">    classList = [example[<span class="number">-1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == len(classList):</span><br><span class="line">        <span class="comment"># 类别完全相同时，停止继续划分</span></span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> len(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 遍历完所有特征时返回出现最多的</span></span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeat = chooseBestFeat(dataSet)</span><br><span class="line">    bestFeatLabel = labels[bestFeat]</span><br><span class="line">    DTree = &#123;bestFeatLabel: &#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat])</span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    uniqueVals = set(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels = labels[:]</span><br><span class="line">        DTree[bestFeatLabel][value] = createTree(</span><br><span class="line">            splitDataSet(dataSet, bestFeat, value), subLabels)</span><br><span class="line">    <span class="keyword">return</span> DTree</span><br></pre></td></tr></table></figure></p><p>这里使用python的字典类型存储树的信息，当然也可以定义特殊类型的数据结构，但在这里完全没有必要。</p><p>我们测试一下上述代码的实际输出结果：</p><p><img src="/images/1468654341025.png"></p><p>变量 <code>tree</code> 包含了很多代表树结构的嵌套字典。如果值是类标签，则该节点是叶子节点; 如果值是另一个字典，则该子节点是一个判断节点，这种格式结构不断重复就形成了一棵树。本例中这棵树包含了3个叶子节点以及两个判断节点，如下所示：</p><figure><img src="./1468655345150.png" alt="Alt text|center"><figcaption>Alt text|center</figcaption></figure><h2><span id="总结">总结</span></h2><p>决策树分类器就像带有终止块的流程图，终止块表示分类结果。开始处理数据集时，我们首先要测量集合中数据的不一致性，也就是熵，然后寻找最优方案划分数据集，直到数据集中的所有数据属于同一分类。ID3算法可用于划分标称型数据集。构建决策树时，我们通常采用递归的方法将数据集转化为决策树。</p><p>还有其他决策树构造算法，最流行的是C4.5和CART，详情见下回分解。</p><h2><span id="参考">参考</span></h2><p>《机器学习实战》[美] Peter Harrington https://www.wikiwand.com/en/ID3_algorithm https://www.wikiwand.com/en/Decision_tree</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Decision Tree </tag>
            
            <tag> ID3 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Understanding RNN&amp;LSTM Networks</title>
      <link href="/2016/06/23/Understanding%20RNN%20LSTM%20Networks/"/>
      <url>/2016/06/23/Understanding%20RNN%20LSTM%20Networks/</url>
      
        <content type="html"><![CDATA[<p>转载自：http://colah.github.io/posts/2015-08-Understanding-LSTMs/</p><!-- toc --><ul><li><a href="#recurrent-neural-networks">Recurrent Neural Networks</a></li><li><a href="#the-problem-of-long-term-dependencies">The Problem of Long-Term Dependencies</a></li><li><a href="#lstm-networks">LSTM Networks</a><ul><li><a href="#the-core-idea-behind-lstms">The Core Idea Behind LSTMs</a></li><li><a href="#step-by-step-lstm-walk-through">Step-by-Step LSTM Walk Through</a></li><li><a href="#variants-on-long-short-term-memory">Variants on Long Short Term Memory</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="recurrent-neural-networks">Recurrent Neural Networks</span></h2><p>Humans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. <strong>Your thoughts have persistence.</strong></p><p>Traditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.</p><p>Recurrent neural networks address this issue. They are <strong>networks with loops in them</strong>, allowing information to persist.</p><p><img src="/images/1466525670636.png"></p><p>In the above diagram, a chunk of neural network, <span class="math inline">\(A\)</span> , looks at some input <span class="math inline">\(x_t\)</span> and outputs a value <span class="math inline">\(h_t\)</span>. A loop allows information to be passed from one step of the network to the next.</p><p>These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren’t all that different than a normal neural network. <strong>A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor</strong>. Consider what happens if we unroll the loop: <img src="/images/1466526020324.png"> An unrolled recurrent neural network.</p><p>This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They’re the natural architecture of neural network to use for such data.</p><p>And they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning… The list goes on. I’ll leave discussion of the amazing feats one can achieve with RNNs to Andrej Karpathy’s excellent blog post, <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a>. But they really are pretty amazing.</p><p>Essential to these successes is the use of “<strong>LSTM</strong>s,” a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. It’s these LSTMs that this essay will explore.</p><h2><span id="the-problem-of-long-term-dependencies">The Problem of Long-Term Dependencies</span></h2><p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they’d be extremely useful. But can they? It depends.</p><p>Sometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in “the clouds are in the sky,” we don’t need any further context – it’s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information.</p><p><img src="/images/1466526259739.png"></p><p>But there are also cases where we need more context. Consider trying to predict the last word in the text “I grew up in France… I speak fluent French.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.</p><p>Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.</p><p><img src="/images/1466526327635.png"></p><p>In theory, RNNs are absolutely capable of handling such “long-term dependencies.” A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" target="_blank" rel="noopener">Hochreiter (1991) [German]</a> and <a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="noopener">Bengio, et al. (1994)</a>, who found some pretty fundamental reasons why it might be difficult.</p><p>Thankfully, LSTMs don’t have this problem!</p><h2><span id="lstm-networks">LSTM Networks</span></h2><p><em>Long Short Term Memory networks</em> – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by <a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf" target="_blank" rel="noopener">Hochreiter &amp; Schmidhuber (1997)</a>, and were refined and popularized by many people in following work. They work tremendously well on a large variety of problems, and are now widely used.</p><p>LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!</p><p>All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.</p><p><img src="/images/1466608981114.png"> The repeating module in a standard RNN contains a single layer.</p><p>LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.</p><p><img src="/images/1466609034893.png"> The repeating module in an LSTM contains four interacting layers.</p><p>Don’t worry about the details of what’s going on. We’ll walk through the LSTM diagram step by step later. For now, let’s just try to get comfortable with the notation we’ll be using. <img src="/images/1466609119993.png"></p><p>In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.</p><h3><span id="the-core-idea-behind-lstms">The Core Idea Behind LSTMs</span></h3><p>The key to LSTMs is the <strong>cell state</strong>, the horizontal line running through the top of the diagram.</p><p>The cell state is kind of like a conveyor belt. It runs straight down the entire chain, with only some minor linear interactions. It’s very easy for <strong>information to just flow along it unchanged</strong>.</p><p><img src="/images/1466609290827.png"></p><p>The LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called <strong>gates</strong>.</p><p>Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.</p><p><img src="/images/1466609490979.png"></p><p>The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”</p><p><strong>An LSTM has three of these gates, to protect and control the cell state.</strong></p><h3><span id="step-by-step-lstm-walk-through">Step-by-Step LSTM Walk Through</span></h3><p>The first step in our LSTM is to decide what information we’re going to throw away from the cell state. This decision is made by a sigmoid layer called the “<strong>forget gate layer</strong>.” It looks at <span class="math inline">\(h_{t−1}\)</span> and <span class="math inline">\(x_t\)</span>, and outputs a number between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> for each number in the cell state <span class="math inline">\(C_{t−1}\)</span>. <span class="math inline">\(1\)</span> represents “completely keep this” while a <span class="math inline">\(0\)</span> represents “completely get rid of this.”</p><p>Let’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.</p><p><img src="/images/1466609792498.png"></p><p>The next step is to decide what new information we’re going to store in the cell state. This has two parts. First, a sigmoid layer called the “<strong>input gate layer</strong>” decides which values we’ll update. Next, a tanh layer creates a vector of new candidate values, <span class="math inline">\(C̃_ t\)</span>, that could be added to the state. In the next step, we’ll combine these two to create an update to the state.</p><p>In the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.</p><p><img src="/images/1466610052910.png"></p><p>It’s now time to update the old cell state, <span class="math inline">\(C_{t−1}\)</span>, into the new cell state <span class="math inline">\(C_t\)</span>. The previous steps already decided what to do, we just need to actually do it.</p><p>We multiply the old state by <span class="math inline">\(f_t\)</span>, forgetting the things we decided to forget earlier. Then we add <span class="math inline">\(i_t∗C̃_t\)</span>. This is the new candidate values, scaled by how much we decided to update each state value.</p><p>In the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.</p><p><img src="/images/1466610178378.png"></p><p>Finally, we need to decide what we’re going to output. <strong>This output will be based on our cell state, but will be a filtered version</strong>. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through <span class="math inline">\(tanh\)</span> (to push the values to be between <span class="math inline">\(−1\)</span> and <span class="math inline">\(1\)</span>) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.</p><p>For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.</p><p><img src="/images/1466610206595.png"></p><h3><span id="variants-on-long-short-term-memory">Variants on Long Short Term Memory</span></h3><p>What I’ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it’s worth mentioning some of them.</p><p>One popular LSTM variant, introduced by <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener">Gers &amp; Schmidhuber (2000)</a>, is adding “peephole connections.” This means that we let the gate layers look at the cell state.</p><p><img src="/images/1466610391326.png"></p><p>The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others.</p><p>Another variation is to use <strong>coupled forget and input gates</strong>. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we’re going to input something in its place. We only input new values to the state when we forget something older.</p><p><img src="/images/1466610470154.png"></p><p>A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by <a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho, et al. (2014)</a>. It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.</p><p><img src="/images/1466610557001.png"></p><p>These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by <a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao, et al. (2015)</a>. There’s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by <a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al. (2014)</a>.</p><p>Which of these variants is best? Do the differences matter? <a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al. (2015)</a> do a nice comparison of popular variants, finding that they’re all about the same. <a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz, et al. (2015)</a> tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.</p><h2><span id="conclusion">Conclusion</span></h2><p>Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks!</p><p>Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable.</p><p>LSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, <a href="http://arxiv.org/pdf/1502.03044v2.pdf" target="_blank" rel="noopener">Xu, et al. (2015)</a> do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…</p><p>Attention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by <a href="http://arxiv.org/pdf/1507.01526v1.pdf" target="_blank" rel="noopener">Kalchbrenner, et al. (2015)</a> seem extremely promising. Work using RNNs in generative models – such as <a href="http://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="noopener">Gregor, et al. (2015)</a>, <a href="http://arxiv.org/pdf/1506.02216v3.pdf" target="_blank" rel="noopener">Chung, et al. (2015)</a>, or <a href="http://arxiv.org/pdf/1411.7610v3.pdf" target="_blank" rel="noopener">Bayer &amp; Osendorfer (2015)</a> – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> RNN </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Large Scale Machine Learning</title>
      <link href="/2016/03/24/Large%20Scale%20Machine%20Learning/"/>
      <url>/2016/03/24/Large%20Scale%20Machine%20Learning/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li><li><a href="#mini-batch-gradient-descent">Mini-Batch Gradient Descent</a><ul><li><a href="#stochastic-gradient-descent-convergence">Stochastic Gradient Descent Convergence</a></li></ul></li><li><a href="#online-learning">Online Learning</a></li><li><a href="#map-reduce-and-data-parallelism">Map Reduce and Data Parallelism</a></li></ul><!-- tocstop --><a id="more"></a><p>We mainly <strong>benefit</strong> from a very large dataset when our algorithm has <strong>high variance</strong> when <span class="math inline">\(m\)</span> is small. Recall that if our algorithm has high bias, more data will not have any benefit.</p><p>Datasets can often approach such sizes as <span class="math inline">\(m = 100,000,000\)</span>. In this case, our gradient descent step will have to make a summation over all one hundred million examples. We will want to try to avoid this -- the approaches for doing so are described below.</p><h1><span id="stochastic-gradient-descent">Stochastic Gradient Descent</span></h1><p>Stochastic gradient descent is an alternative to classic (or batch) gradient descent and is more efficient and scalable to large data sets.</p><p>Stochastic gradient descent is written out in a different but similar way: <span class="math display">\[ cost(\theta,(x^{(i)}, y^{(i)})) = \dfrac{1}{2}(h_{\theta}(x^{(i)}) - y^{(i)})^2 \]</span></p><p>The only difference in the above cost function is the elimination of the <span class="math inline">\(m\)</span> constant within <span class="math inline">\(\dfrac{1}{2}\)</span>. <span class="math display">\[ J_{train}(\theta) = \dfrac{1}{m} \displaystyle \sum_{i=1}^m cost(\theta, (x^{(i)}, y^{(i)})) \]</span></p><p><span class="math inline">\(J_{train}\)</span> is now just the average of the cost applied to all of our training examples.</p><p>The algorithm is as follows 1. Randomly 'shuffle' the dataset 2. For <span class="math inline">\(i = 1\dots m\)</span> <span class="math display">\[\Theta_j := \Theta_j - \alpha (h_{\Theta}(x^{(i)}) - y^{(i)}) \cdot x^{(i)}_j\]</span> (for <span class="math inline">\(j = 0,\dots,n\)</span>)</p><p>This algorithm will only try to <strong>fit one training example at a time</strong>.</p><p>This way we can make progress in gradient descent without having to scan all <span class="math inline">\(m\)</span> training examples first.</p><p>Stochastic gradient descent will be unlikely to converge at the global minimum and will instead <strong>wander around it randomly</strong>, but usually yields a result that is close enough.</p><p>Stochastic gradient descent will usually take 1-10 passes through your data set to get near the global minimum.</p><h1><span id="mini-batch-gradient-descent">Mini-Batch Gradient Descent</span></h1><p>Mini-batch gradient descent can sometimes be even faster than stochastic gradient descent. Instead of using all <span class="math inline">\(m\)</span> examples as in batch gradient descent, and instead of using only 1 example as in stochastic gradient descent, we will use some in-between number of examples <span class="math inline">\(b\)</span>.</p><p>Typical values for <span class="math inline">\(b\)</span> range from 2-100 or so.</p><p>For example, with <span class="math inline">\(b = 10\)</span> and <span class="math inline">\(m = 1000\)</span>: Repeat: For <span class="math inline">\(i = 1,11,21,31,\dots,991\)</span>: <span class="math display">\[\theta_j := \theta_j - \alpha \dfrac{1}{10} \displaystyle \sum_{k=i}^{i+9} (h_\theta(x^{(k)}) - y^{(k)})x_j^{(k)}\]</span> (for each <span class="math inline">\(j = 0, \dots, n\)</span>)</p><p>We're simply summing over ten examples at a time.</p><p>The advantage of computing more than one example at a time is that we can use vectorized implementations over the <span class="math inline">\(b\)</span> examples.</p><h2><span id="stochastic-gradient-descent-convergence">Stochastic Gradient Descent Convergence</span></h2><p>How do we choose the learning rate <span class="math inline">\(\alpha\)</span> for stochastic gradient descent? Also, how do we debug stochastic gradient descent to make sure it is getting as close as possible to the global optimum?</p><p>One strategy is to plot the average cost of the hypothesis applied to every 1000 or so training examples. We can compute and save these costs during the gradient descent iterations.</p><p>With a smaller learning rate, it is <strong>possible</strong> that you may get a slightly better solution with stochastic gradient descent. That is because stochastic gradient descent will oscillate and jump around the global minimum, and it will make smaller random jumps with a smaller learning rate.</p><p>If you increase the number of examples you average over to plot the performance of your algorithm, the plot's line will become smoother.</p><p>With a very small number of examples for the average, the line will be too noisy and it will be difficult to find the trend.</p><p>One strategy for trying to actually converge at the global minimum is to slowly decrease <span class="math inline">\(\alpha\)</span> over time. For example <span class="math display">\[\alpha = \dfrac{const1}{iterationNumber + const2}\]</span>.</p><p>However, this is not often done because people don't want to have to fiddle with even more parameters.</p><h1><span id="online-learning">Online Learning</span></h1><p>With a continuous stream of users to a website, we can run an endless loop that gets <span class="math inline">\((x,y)\)</span>, where we collect some user actions for the features in <span class="math inline">\(x\)</span> to predict some behavior <span class="math inline">\(y\)</span>.</p><p>You can update <span class="math inline">\(\theta\)</span> for each individual <span class="math inline">\((x,y)\)</span> pair as you collect them. This way, you can adapt to new pools of users, since you are continuously updating theta.</p><h1><span id="map-reduce-and-data-parallelism">Map Reduce and Data Parallelism</span></h1><p>We can divide up batch gradient descent and dispatch the cost function for a subset of the data to many different machines so that we can train our algorithm in parallel.</p><p>You can split your training set into <span class="math inline">\(z\)</span> subsets corresponding to the number of machines you have. On each of those machines calculate <span class="math inline">\(\displaystyle \sum_{i=p}^{q}(h_{\theta}(x^{(i)}) - y^{(i)}) \cdot x_j^{(i)}\)</span>, where we've split the data starting at <span class="math inline">\(p\)</span> and ending at <span class="math inline">\(q\)</span>.</p><p>MapReduce will take all these dispatched (or 'mapped') jobs and 'reduce' them by calculating: <span class="math display">\[ \Theta_j := \Theta_j - \alpha \dfrac{1}{z}(temp_j^{(1)} + temp_j^{(2)} + \cdots + temp_j^{(z)})\]</span> For all <span class="math inline">\(j = 0, \dots, n\)</span>.</p><p>This is simply taking the computed cost from all the machines, calculating their average, multiplying by the learning rate, and updating theta.</p><p>Your learning algorithm is MapReduceable if it can be expressed as <strong>computing sums of functions over the training set</strong>. Linear regression and logistic regression are easily parallelizable.</p><p>For neural networks, you can compute forward propagation and back propagation on subsets of your data on many machines. Those machines can report their derivatives back to a 'master' server that will combine them.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> MapReduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>推荐系统 （Recommender Systems）</title>
      <link href="/2016/03/19/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%20%EF%BC%88Recommender%20Systems%EF%BC%89/"/>
      <url>/2016/03/19/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%20%EF%BC%88Recommender%20Systems%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#problem-formulation">Problem Formulation</a></li><li><a href="#content-based-recommendations">Content Based Recommendations</a></li><li><a href="#collaborative-filtering">Collaborative Filtering</a><ul><li><a href="#collaborative-filtering-algorithm">Collaborative Filtering Algorithm</a><ul><li><a href="#vectorization-low-rank-matrix-factorization">Vectorization: Low Rank Matrix Factorization</a></li><li><a href="#implementation-detail-mean-normalization">Implementation Detail: Mean Normalization</a></li></ul></li></ul></li></ul><!-- tocstop --><a id="more"></a><h1><span id="problem-formulation">Problem Formulation</span></h1><p>Recommendation is currently a very popular application of machine learning.</p><p>Say we are trying to recommend movies to customers. We can use the following definitions * $n_u = $ number of users * $n_m = $ number of movies * <span class="math inline">\(r(i,j) = 1\)</span> if user <span class="math inline">\(j\)</span> has rated movie <span class="math inline">\(i\)</span> * $y(i,j) = $ rating given by user <span class="math inline">\(j\)</span> to movie <span class="math inline">\(i\)</span> (defined only if <span class="math inline">\(r(i,j) = 1\)</span>)</p><h1><span id="content-based-recommendations">Content Based Recommendations</span></h1><p>We can introduce two features, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> which represents how much romance or how much action a movie may have (on a scale of <span class="math inline">\(0 - 1\)</span>).</p><p>One approach is that we could do linear regression for every single user. For each user <span class="math inline">\(j\)</span>, learn a parameter <span class="math inline">\(\theta^{(j)} \in \mathbb{R}^3\)</span>. Predict user <span class="math inline">\(j\)</span> as rating movie <span class="math inline">\(i\)</span> with <span class="math inline">\((\theta^{(j)})^Tx^{(i)}\)</span> stars.</p><ul><li>$^{(j)} = $ parameter vector for user <span class="math inline">\(j\)</span></li><li>$x^{(i)} = $ feature vector for movie <span class="math inline">\(i\)</span></li><li>For user <span class="math inline">\(j\)</span>, movie <span class="math inline">\(i\)</span>, predicted rating: <span class="math inline">\((\theta^{(j)})^T(x^{(i)})\)</span></li><li>$m^{(j)} = $ number of movies rated by user <span class="math inline">\(j\)</span></li></ul><p>To learn <span class="math inline">\(\theta^{(j)}\)</span>, we do the following <span class="math display">\[min_{\theta^{(j)}} = \dfrac{1}{2}\displaystyle \sum_{i:r(i,j)=1} ((\theta^{(j)})^T(x^{(i)}) - y^{(i,j)})^2 + \dfrac{\lambda}{2} \sum_{k=1}^n(\theta_k^{(j)})^2\]</span> This is our familiar linear regression. The base of the first summation is choosing all <span class="math inline">\(i\)</span> such that <span class="math inline">\(r(i,j) = 1\)</span>.</p><p>To get the parameters for all our users, we do the following: <span class="math display">\[min_{\theta^{(1)},\dots,\theta^{(n_u)}} = \dfrac{1}{2}\displaystyle \sum_{j=1}^{n_u} \sum_{i:r(i,j)=1} ((\theta^{(j)})^T(x^{(i)}) - y^{(i,j)})^2 + \dfrac{\lambda}{2} \sum_{j=1}^{n_u} \sum_{k=1}^n(\theta_k^{(j)})^2\]</span> We can apply our linear regression gradient descent update using the above cost function.</p><p>The only real difference is that we eliminate the constant <span class="math inline">\(\dfrac{1}{m}\)</span>.</p><h1><span id="collaborative-filtering">Collaborative Filtering</span></h1><p><strong>协同过滤</strong></p><p>It can be very difficult to find features such as &quot;amount of romance&quot; or &quot;amount of action&quot; in a movie. To figure this out, we can use <strong>feature finders</strong>.</p><p>We can let the users tell us how much they like the different genres, providing their parameter vector immediately for us.</p><p>To infer the features from given parameters, we use the squared error function with regularization over all the users: <span class="math display">\[min_{x^{(1)},\dots,x^{(n_m)}} \dfrac{1}{2} \displaystyle \sum_{i=1}^{n_m} \sum_{j:r(i,j)=1} ((\theta^{(j)})^T x^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2\]</span></p><p>You can also randomly guess the values for theta to guess the features repeatedly. You will actually converge to a good set of features.</p><h2><span id="collaborative-filtering-algorithm">Collaborative Filtering Algorithm</span></h2><p>To speed things up, we can simultaneously minimize our features and our parameters:</p><p><span class="math display">\[ \large J(x,\theta) = \dfrac{1}{2} \displaystyle \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \dfrac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^{n} (x_k^{(i)})^2 + \dfrac{\lambda}{2}\sum_{j=1}^{n_u} \sum_{k=1}^{n} (\theta_k^{(j)})^2\]</span></p><p>It looks very complicated, but we've only <strong>combined the cost function</strong> for <strong>theta</strong> and the cost function for <strong>x</strong>.</p><p>Because the algorithm can learn them itself, the bias units where <span class="math inline">\(x_0 = 1\)</span> have been removed, therefore <span class="math inline">\(x \in \mathbb{R}^n\)</span> and <span class="math inline">\(\theta \in \mathbb{R}^n\)</span>.</p><p>These are the steps in the algorithm:</p><ol type="1"><li>Initialize <span class="math inline">\(x^{(i)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)}\)</span> to small random values. This serves to break symmetry(对称性) and ensures that the algorithm learns features <span class="math inline">\(x^{(i)},...,x^{(n_m)}\)</span> that are different from each other.</li><li>Minimize <span class="math inline">\(J(x^{(i)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)})\)</span> using gradient descent (or an advanced optimization algorithm). E.g. for every <span class="math inline">\(j=1,...,n_u,i=1,...n_m\)</span>: <span class="math display">\[x_k^{(i)} := x_k^{(i)} - \alpha\left (\displaystyle \sum_{j:r(i,j)=1}{((\theta^{(j)})^T x^{(i)} - y^{(i,j)}) \theta_k^{(j)}} + \lambda x_k^{(i)} \right)\]</span> <span class="math display">\[\theta_k^{(j)} := \theta_k^{(j)} - \alpha\left (\displaystyle \sum_{i:r(i,j)=1}{((\theta^{(j)})^T x^{(i)} - y^{(i,j)}) x_k^{(i)}} + \lambda \theta_k^{(j)} \right)\]</span></li><li>For a user with parameters <span class="math inline">\(\theta\)</span> and a movie with (learned) features <span class="math inline">\(x\)</span>, predict a star rating of <span class="math inline">\(\theta^Tx\)</span>.</li></ol><h3><span id="vectorization-low-rank-matrix-factorization">Vectorization: Low Rank Matrix Factorization</span></h3><p><strong>低秩矩阵分解</strong></p><p>Given matrices <span class="math inline">\(X\)</span> (each row containing features of a particular movie) and <span class="math inline">\(\Theta\)</span> (each row containing the weights for those features for a given user), then the full matrix <span class="math inline">\(Y\)</span> of all predicted ratings of all movies by all users is given simply by: <span class="math inline">\(Y = X\Theta^T\)</span>.</p><p>Predicting how similar two movies <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are can be done using the distance between their respective feature vectors <span class="math inline">\(x\)</span>. Specifically, we are looking for a small value of <span class="math inline">\(||x^{(i)} - x^{(j)}||\)</span>.</p><h3><span id="implementation-detail-mean-normalization">Implementation Detail: Mean Normalization</span></h3><p>If the ranking system for movies is used from the previous lectures, then new users (who have watched no movies), will be assigned new movies incorrectly. Specifically, they will be assigned <span class="math inline">\(\theta\)</span> with all components equal to zero due to the minimization of the regularization term. That is, we assume that the new user will rank all movies 0, which does not seem intuitively correct.</p><p>We rectify this problem by normalizing the data relative to the mean. First, we use a matrix Y to store the data from previous ratings, where the <span class="math inline">\(i\)</span>th row of Y is the ratings for the <span class="math inline">\(i\)</span>th movie and the <span class="math inline">\(j\)</span>th column corresponds to the ratings for the <span class="math inline">\(j\)</span>th user.</p><p>We can now define a vector <span class="math display">\[\mu = [\mu_1, \mu_2, \dots , \mu_{n_m}] \]</span> such that <span class="math display">\[\mu_i = \frac{\sum_{j:r(i,j)=1}{Y_{i,j}}}{\sum_{j}{r(i,j)}}\]</span></p><p>Which is effectively the mean of the previous ratings for the <span class="math inline">\(i\)</span> th movie (where only movies that <strong>have been watched by users are counted</strong>). We now can normalize the data by subtracting <span class="math inline">\(u\)</span>, the mean rating, from the actual ratings for each user (column in matrix <span class="math inline">\(Y\)</span>):</p><p>As an example, consider the following matrix <span class="math inline">\(Y\)</span> and mean ratings <span class="math inline">\(\mu\)</span>: <span class="math display">\[Y = \begin{bmatrix} 5 &amp; 5 &amp; 0 &amp; 0 \newline 4 &amp; ? &amp; ? &amp; 0 \newline 0 &amp; 0 &amp; 5 &amp; 4 \newline 0 &amp; 0 &amp; 5 &amp; 0 \newline \end{bmatrix}, \quad \mu = \begin{bmatrix} 2.5 \newline 2 \newline 2.25 \newline 1.25 \newline \end{bmatrix} \]</span> The resulting <span class="math inline">\(Y&#39;\)</span> vector is: <span class="math display">\[ Y&#39; = \begin{bmatrix} 2.5 &amp; 2.5 &amp; -2.5 &amp; -2.5 \newline 2 &amp; ? &amp; ? &amp; -2 \newline -.2.25 &amp; -2.25 &amp; 3.75 &amp; 1.25 \newline -1.25 &amp; -1.25 &amp; 3.75 &amp; -1.25 \end{bmatrix} \]</span></p><p>Now we must slightly modify the linear regression prediction to include the mean normalization term: <span class="math display">\[(\theta^{(j)})^T x^{(i)} + \mu_i\]</span> Now, for a new user, the initial predicted values will be equal to the <span class="math inline">\(\mu\)</span> term instead of simply being initialized to zero, which is more accurate.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Recommender Systems </tag>
            
            <tag> Collaborative Filtering </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Anomaly Detection</title>
      <link href="/2016/03/19/Anomaly%20Detection/"/>
      <url>/2016/03/19/Anomaly%20Detection/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#problem-motivation">Problem Motivation</a></li><li><a href="#gaussian-distribution">Gaussian Distribution</a></li><li><a href="#algorithm">Algorithm</a></li><li><a href="#developing-and-evaluating-an-anomaly-detection-system">Developing and Evaluating an Anomaly Detection System</a></li><li><a href="#anomaly-detection-vs-supervised-learning">Anomaly Detection vs. Supervised Learning</a></li><li><a href="#choosing-what-features-to-use">Choosing What Features to Use</a></li><li><a href="#multivariate-gaussian-distribution">Multivariate Gaussian Distribution</a></li><li><a href="#anomaly-detection-using-the-multivariate-gaussian-distribution">Anomaly Detection using the Multivariate Gaussian Distribution</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="problem-motivation">Problem Motivation</span></h1><p>Just like in other learning problems, we are given a dataset <span class="math inline">\({x^{(1)}, x^{(2)},\dots,x^{(m)}}\)</span>.</p><p>We are then given a new example, <span class="math inline">\(x_{test}\)</span>, and we want to know whether this new example is abnormal/anomalous.</p><p>We define a &quot;model&quot; <span class="math inline">\(p(x)\)</span> that tells us the probability the example is not anomalous. We also use a threshold <span class="math inline">\(\epsilon\)</span> (epsilon) as a dividing line so we can say which examples are anomalous and which are not.</p><p>A very common application of anomaly detection is detecting fraud: * $x^{(i)} = $ features of user <span class="math inline">\(i\)</span>'s activities * Model <span class="math inline">\(p(x)\)</span> from the data. * Identify unusual users by checking which have <span class="math inline">\(p(x) &lt; \epsilon\)</span>.</p><p>If our anomaly detector is flagging <strong>too many</strong> anomalous examples, then we need to <strong>decrease</strong> our threshold <span class="math inline">\(\epsilon\)</span></p><h1><span id="gaussian-distribution">Gaussian Distribution</span></h1><p>The Gaussian Distribution is a familiar bell-shaped curve that can be described by a function <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span></p><p>Let <span class="math inline">\(x \in \mathbb{R}\)</span>. If the probability distribution of <span class="math inline">\(x\)</span> is Gaussian with mean <span class="math inline">\(\mu\)</span>, variance <span class="math inline">\(\sigma^2\)</span>, then: <span class="math display">\[ x \sim \mathcal{N}(\mu, \sigma^2)\]</span></p><p>The little <span class="math inline">\(\sim\)</span> or 'tilde' can be read as &quot;distributed as.&quot;</p><p>The Gaussian Distribution is parameterized by a mean and a variance.</p><p>Mu, or <span class="math inline">\(\mu\)</span>, describes the center of the curve, called the mean. The width of the curve is described by sigma, or <span class="math inline">\(\sigma\)</span>, called the standard deviation.</p><p>The full function is as follows: <span class="math display">\[\large p(x;\mu,\sigma^2) = \dfrac{1}{\sigma\sqrt{(2\pi)}}e^{-\dfrac{1}{2}(\dfrac{x - \mu}{\sigma})^2}\]</span> We can estimate the parameter <span class="math inline">\(\mu\)</span> from a given dataset by simply taking the average of all the examples: <span class="math display">\[\mu = \dfrac{1}{m}\displaystyle \sum_{i=1}^m x^{(i)}\]</span> We can estimate the other parameter, <span class="math inline">\(\sigma^2\)</span>, with our familiar squared error formula: <span class="math display">\[\sigma^2 = \dfrac{1}{m}\displaystyle \sum_{i=1}^m(x^{(i)} - \mu)^2\]</span></p><h1><span id="algorithm">Algorithm</span></h1><p>Given a training set of examples, <span class="math inline">\(\lbrace x^{(1)},\dots,x^{(m)}\rbrace\)</span> where each example is a vector, <span class="math inline">\(x \in \mathbb{R}^n\)</span>. <span class="math display">\[p(x) = p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma^2_2)\cdots p(x_n;\mu_n,\sigma^2_n)\]</span></p><p>In statistics, this is called an &quot;independence assumption&quot; on the values of the features inside training example <span class="math inline">\(x\)</span>.</p><p>More compactly, the above expression can be written as follows: <span class="math display">\[ p(x) = \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2)\]</span></p><p><strong>The algorithm</strong></p><ol type="1"><li>Choose features <span class="math inline">\(x_i\)</span> that you think might be indicative of anomalous examples.</li><li>Fit parameters <span class="math inline">\(\mu_1,\dots,\mu_n,\sigma_1^2,\dots,\sigma_n^2\)</span>.</li><li>Calculate <span class="math inline">\(\mu_j = \dfrac{1}{m}\displaystyle \sum_{i=1}^m x_j^{(i)}\)</span></li><li>Calculate <span class="math inline">\(\sigma^2_j = \dfrac{1}{m}\displaystyle \sum_{i=1}^m(x_j^{(i)} - \mu_j)^2\)</span></li><li>Given a new example <span class="math inline">\(x\)</span>, compute <span class="math inline">\(p(x)\)</span>: <span class="math display">\[p(x) = \displaystyle \prod^n_{j=1} p(x_j;\mu_j,\sigma_j^2) = \prod\limits^n_{j=1} \dfrac{1}{\sqrt{2\pi}\sigma_j}exp(-\dfrac{(x_j - \mu_j)^2}{2\sigma^2_j})\]</span></li><li>Anomaly if <span class="math inline">\(p(x) &lt; \epsilon\)</span></li></ol><p>A vectorized version of the calculation for <span class="math inline">\(\mu\)</span> is <span class="math display">\[\mu = \dfrac{1}{m}\displaystyle \sum_{i=1}^m x^{(i)}\]</span></p><p>You can vectorize <span class="math inline">\(\sigma^2\)</span> similarly.</p><h1><span id="developing-and-evaluating-an-anomaly-detection-system">Developing and Evaluating an Anomaly Detection System</span></h1><p>To evaluate our learning algorithm, we take some labeled data, categorized into anomalous and non-anomalous examples (<span class="math inline">\(y = 0\)</span> if normal, <span class="math inline">\(y = 1\)</span> if anomalous).</p><p>Among that data, take a large proportion of <strong>good</strong>, non-anomalous data for the training set on which to train <span class="math inline">\(p(x)\)</span>.</p><p>Then, take a smaller proportion of mixed anomalous and non-anomalous examples (you will usually have many more non-anomalous examples) for your cross-validation and test sets.</p><p>For example, we may have a set where 0.2% of the data is anomalous. We take 60% of those examples, all of which are good (<span class="math inline">\(y=0\)</span>) for the training set. We then take 20% of the examples for the cross-validation set (with 0.1% of the anomalous examples) and another 20% from the test set (with another 0.1% of the anomalous).</p><p>In other words, we split the data 60/20/20 training/CV/test and then split the anomalous examples 50/50 between the CV and test sets.</p><p><strong>Algorithm evaluation</strong>:</p><ol type="1"><li>Fit model <span class="math inline">\(p(x)\)</span> on training set <span class="math inline">\(\lbrace x^{(1)},\dots,x^{(m)} \rbrace\)</span></li><li>On a cross validation/test example <span class="math inline">\(x\)</span>, predict:<ul><li>If <span class="math inline">\(p(x) &lt; \epsilon\)</span> (anomaly), then <span class="math inline">\(y = 1\)</span></li><li>If <span class="math inline">\(p(x) \geq \epsilon\)</span> (normal), then <span class="math inline">\(y = 0\)</span></li></ul></li></ol><p>Possible evaluation metrics * True positive, false positive, false negative, true negative. * Precision/recall * <span class="math inline">\(F_1\)</span> score</p><p>Note that we use the cross-validation set to choose parameter <span class="math inline">\(\epsilon\)</span></p><h1><span id="anomaly-detection-vs-supervised-learning">Anomaly Detection vs. Supervised Learning</span></h1><p>When do we use anomaly detection and when do we use supervised learning?</p><p><strong>Use anomaly detection when...</strong></p><ul><li>We have a very small number of positive examples (<span class="math inline">\(y=1\)</span> ... 0-20 examples is common) and a large number of negative (<span class="math inline">\(y=0\)</span>) examples.</li><li>We have many different &quot;types&quot; of anomalies and it is hard for any algorithm to learn from positive examples what the anomalies look like; future anomalies may look nothing like any of the anomalous examples we've seen so far.</li></ul><p><strong>Use supervised learning when...</strong> * We have a large number of both positive and negative examples. In other words, the training set is more evenly divided into classes. * We have enough positive examples for the algorithm to get a sense of what new positives examples look like. The future positive examples are likely similar to the ones in the training set.</p><h1><span id="choosing-what-features-to-use">Choosing What Features to Use</span></h1><p>The features will greatly affect how well your anomaly detection algorithm works.</p><p>We can check that our features are gaussian by plotting a histogram of our data and checking for the bell-shaped curve.</p><p>Some transforms we can try on an example feature <span class="math inline">\(x\)</span> that does not have the bell-shaped curve are: * <span class="math inline">\(log(x)\)</span> * <span class="math inline">\(log(x+1)\)</span> * <span class="math inline">\(log(x + c)\)</span> for some constant * <span class="math inline">\(\sqrt{x}\)</span> * <span class="math inline">\(x^{1/3}\)</span></p><p>We can play with each of these to try and achieve the gaussian shape in our data.</p><p>There is an <strong>error analysis procedure</strong> for anomaly detection that is very similar to the one in supervised learning.</p><p>Our goal is for <span class="math inline">\(p(x)\)</span> to be large for normal examples and small for anomalous examples.</p><p>One common problem is when <span class="math inline">\(p(x)\)</span> is similar for both types of examples. In this case, you need to examine the anomalous examples that are giving high probability in detail and try to figure out new features that will better distinguish the data.</p><p>In general, choose features that might take on unusually large or small values in the event of an anomaly.</p><h1><span id="multivariate-gaussian-distribution">Multivariate Gaussian Distribution</span></h1><p>The multivariate gaussian distribution is an extension of anomaly detection and may (or may not) catch more anomalies.</p><p>Instead of modeling <span class="math inline">\(p(x_1),p(x_2),\dots\)</span> separately, we will model <span class="math inline">\(p(x)\)</span> all in one go. Our parameters will be: <span class="math inline">\(\mu \in \mathbb{R}^n\)</span> and <span class="math inline">\(\Sigma \in \mathbb{R}^{n \times n}\)</span> <span class="math display">\[p(x;\mu,\Sigma) = \dfrac{1}{(2\pi)^{n/2} |\Sigma|^{1/2}} exp(-1/2(x-\mu)^T\Sigma^{-1}(x-\mu))\]</span></p><p>The important effect is that we can model oblong gaussian contours, allowing us to better fit data that might not fit into the normal circular contours.</p><p>Varying <span class="math inline">\(\Sigma\)</span> changes the shape, width, and orientation of the contours. Changing <span class="math inline">\(\mu\)</span> will move the center of the distribution.</p><h1><span id="anomaly-detection-using-the-multivariate-gaussian-distribution">Anomaly Detection using the Multivariate Gaussian Distribution</span></h1><p>When doing anomaly detection with multivariate gaussian distribution, we compute <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> normally. We then compute <span class="math inline">\(p(x)\)</span> using the new formula in the previous section and flag an anomaly if <span class="math inline">\(p(x) &lt; \epsilon\)</span>.</p><p>The original model for <span class="math inline">\(p(x)\)</span> corresponds to a multivariate Gaussian where the contours of <span class="math inline">\(p(x;\mu,\Sigma)\)</span> are axis-aligned.</p><p>The multivariate Gaussian model can automatically capture correlations between different features of x.</p><p>However, the <strong>original model</strong> maintains some advantages: it is <strong>computationally cheaper</strong> (no matrix to invert, which is costly for large number of features) and it performs well even with <strong>small training set size</strong> (in multivariate Gaussian model, it should be greater than the number of features for <span class="math inline">\(\Sigma\)</span> to be invertible).</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Dimensionality Reduction</title>
      <link href="/2016/03/13/Dimensionality%20Reduction/"/>
      <url>/2016/03/13/Dimensionality%20Reduction/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#motivation-i-data-compression">Motivation I: Data Compression</a></li><li><a href="#motivation-ii-visualization">Motivation II: Visualization</a></li><li><a href="#principal-component-analysis-problem-formulation">Principal Component Analysis Problem Formulation</a></li><li><a href="#principal-component-analysis-algorithm">Principal Component Analysis Algorithm</a></li><li><a href="#choosing-the-number-of-principal-components">Choosing the Number of Principal Components</a></li><li><a href="#reconstruction-from-compressed-representation">Reconstruction from Compressed Representation</a></li><li><a href="#advice-for-applying-pca">Advice for Applying PCA</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="motivation-i-data-compression">Motivation I: Data Compression</span></h1><p>We may want to reduce the dimension of our features if we have a lot of redundant data.</p><p>To do this, we find two highly correlated features, plot them, and make a new line that seems to describe both features accurately. We place all the new features on this single line.</p><p>Doing dimensionality reduction will <strong>reduce the total data</strong> we have to store in computer memory and will <strong>speed up our learning algorithm</strong>.</p><p>Note: in dimensionality reduction, we are reducing our features rather than our number of examples. Our variable <span class="math inline">\(m\)</span> will stay the same size; <span class="math inline">\(n\)</span>, the number of features each example from <span class="math inline">\(x^{(1)}\)</span> to <span class="math inline">\(x^{(m)}\)</span> carries, will be reduced.</p><h1><span id="motivation-ii-visualization">Motivation II: Visualization</span></h1><p>It is not easy to visualize data that is more than three dimensions. We can reduce the dimensions of our data to 3 or less in order to plot it.</p><p>We need to find new features, <span class="math inline">\(z_1, z_2\)</span> (and perhaps <span class="math inline">\(z_3\)</span>) that can effectively summarize all the other features.</p><p>Example: hundreds of features related to a country's economic system may all be combined into one feature that you call &quot;Economic Activity.&quot;</p><h1><span id="principal-component-analysis-problem-formulation">Principal Component Analysis Problem Formulation</span></h1><p>The most popular dimensionality reduction algorithm is <em>Principal Component Analysis</em> (<strong>PCA</strong>)</p><p><strong>Problem formulation</strong></p><p>Given two features, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, we want to find a single line that effectively describes both features at once. We then map our old features onto this new line to get a new single feature.</p><p>The same can be done with three features, where we map them to a plane.</p><p>The <strong>goal</strong> of PCA is to reduce the average of all the distances of every feature to the projection line. This is the <strong>projection error</strong>.</p><ul><li>Reduce from 2d to 1d: find a direction (a vector <span class="math inline">\(u^{(1)} \in \mathbb{R}^n\)</span>) onto which to project the data so as to minimize the projection error.</li></ul><p>The more general case is as follows:</p><ul><li>Reduce from n-dimension to k-dimension: Find <span class="math inline">\(k\)</span> vectors <span class="math inline">\(u^{(1)}, u^{(2)}, \dots, u^{(k)}\)</span> onto which to project the data so as to minimize the projection error.</li></ul><p>If we are converting from 3d to 2d, we will project our data onto two directions (a plane), so <span class="math inline">\(k\)</span> will be 2.</p><p><strong>PCA is not linear regression</strong> * In linear regression, we are minimizing the squared error from every point to our predictor line. These are vertical distances. * In PCA, we are minimizing the shortest distance, or shortest orthogonal distances, to our data points.</p><p>More generally, in linear regression we are taking all our examples in <span class="math inline">\(x\)</span> and applying the parameters in <span class="math inline">\(\Theta\)</span> to predict <span class="math inline">\(y\)</span>.</p><p>In PCA, we are taking a number of features <span class="math inline">\(x_1, x_2, \dots, x_n\)</span>, and finding a closest common dataset among them. We aren't trying to predict any result and we aren't applying any theta weights to the features.</p><h1><span id="principal-component-analysis-algorithm">Principal Component Analysis Algorithm</span></h1><p>Before we can apply PCA, there is a data pre-processing step we must perform:</p><p><strong>Data preprocessing</strong></p><ol type="1"><li>Let <span class="math inline">\(μ=\frac{1}{m}\sum^{m}_{i=1}x^{(i)}\)</span>.</li><li>Replace each <span class="math inline">\(x^{(i)}\)</span> with <span class="math inline">\(x^{(i)}−μ\)</span>.</li><li>Let <span class="math inline">\(σ^2_j=\frac{1}{m}\sum_i(x^{(i)}_j)^2\)</span></li><li>Replace each <span class="math inline">\(x^{(i)}_j\)</span> with <span class="math inline">\(\frac{x^{(i)}_j}{σ_j}\)</span>.</li></ol><p>Above, we first subtract the mean of each feature from the original feature. Then we scale all the features (<span class="math inline">\(x_j^{(i)} = \dfrac{x_j^{(i)} - \mu_j}{s_j}\)</span>) We can define specifically what it means to reduce from 2d to 1d data as follows: <span class="math display">\[x^{(i)} \in \mathbb{R}^2 \rightarrow z^{(i)} \in \mathbb{R}\]</span> The <span class="math inline">\(z\)</span> values are all real numbers and are the projections of our features onto <span class="math inline">\(u^{(1)}\)</span>.</p><p>So, PCA has two tasks: figure out <span class="math inline">\(u^{(1)},\dots,u^{(k)}\)</span> and also to find <span class="math inline">\(z_1, z_2, \dots, z_m\)</span>.</p><p><strong>Mathematical proof</strong></p><p>We would like to automatically select the direction <span class="math inline">\(u\)</span> corresponding to the first of the two figures shown above.</p><p>To formalize this, note that given a unit vector <span class="math inline">\(u\)</span> and a point <span class="math inline">\(x\)</span>, the length of the projection of <span class="math inline">\(x\)</span> onto <span class="math inline">\(u\)</span> is given by <span class="math inline">\(x^Tu\)</span>. I.e., if <span class="math inline">\(x^{(i)}\)</span> is a point in our dataset ,then its projection onto <span class="math inline">\(u\)</span> is distance <span class="math inline">\(x^Tu\)</span> from the origin. Hence, to maximize the variance of the projections, we would like to choose a unit-length <span class="math inline">\(u\)</span> so as to <strong>maximize</strong>:</p><p><span class="math display">\[\frac{1}{m}\sum^m_{i=1}(x^{(i)T}u)^2 = \frac{1}{m}\sum^m_{i=1}u^tx^{(i)}x^{(i)T}u = u^T(\frac{1}{m}\sum^m_{i=1}x^{(i)}x^{(i)T})u\]</span></p><p>If you haven’t seen this before, try using the method of <a href="https://www.wikiwand.com/en/Lagrange_multiplier" target="_blank" rel="noopener">Lagrange multipliers(拉格朗日乘数法)</a> to maximize <span class="math inline">\(u^TΣu\)</span> subject to that <span class="math inline">\(u^Tu= 1\)</span>. You should be able to show that <span class="math inline">\(Σu=λu\)</span>, for some <span class="math inline">\(λ\)</span>, which implies <span class="math inline">\(u\)</span> is an eigenvector of <span class="math inline">\(Σ\)</span>, with eigenvalue <span class="math inline">\(λ\)</span>. Because <span class="math inline">\(Σ\)</span> is symmetric(对称的), the <span class="math inline">\(u_i\)</span> ’s will (or always can be chosen to be) orthogonal(正交的 ) to each other.</p><p>We easily recognize that the maximizing this subject to <span class="math inline">\(||u||^2= 1\)</span> gives the principal eigenvector of <span class="math inline">\(Σ =\frac{1}{m}\sum^m_{i=1}x^{(i)}x^{(i)T}\)</span>, which is just the empirical <strong>covariance matrix</strong> of the data (assuming it has <strong>zero mean</strong>).</p><p>To summarize, we have found that if we wish to find a 1-dimensional subspace with with to approximate the data, we should choose <span class="math inline">\(u\)</span> to be the principal eigenvector of <span class="math inline">\(Σ\)</span>. More generally, if we wish to project our data into a k-dimensional subspace (k &lt; n), we should choose <span class="math inline">\(u_1\)</span>, . . . , <span class="math inline">\(u_k\)</span> to be the top <span class="math inline">\(k\)</span> eigenvectors of <span class="math inline">\(Σ\)</span>. The <span class="math inline">\(u_i\)</span>’s now form a new, orthogonal basis for the data.</p><p>Then, to represent <span class="math inline">\(x^{(i)}\)</span> in this basis, we need only compute the corresponding vector <span class="math display">\[y^{(i)}=\begin{bmatrix}u^T_1x^{(i)}     \\u^T_2x^{(i)}    \\\vdots  \\u^T_kx^{(i)}\end{bmatrix}∈\mathbb{R}^k\]</span></p><p>Thus, whereas <span class="math inline">\(x^{(i)}∈\mathbb{R}^n\)</span>, the vector <span class="math inline">\(y^{(i)}\)</span> now gives a lower,k-dimensional, approximation/representation for <span class="math inline">\(x^{(i)}\)</span>. <strong>PCA</strong> is therefore also referred to as a <strong>dimensionality reduction</strong> algorithm. The vectors <span class="math inline">\(u_1\)</span>, . . . , <span class="math inline">\(u_k\)</span> are called the first <span class="math inline">\(k\)</span> principal components of the data.</p><p><strong>The PCA Algorithm</strong></p><p>1.<strong>Compute &quot;covariance matrix&quot;</strong> <span class="math display">\[ \large \Sigma = \dfrac{1}{m}\sum^m_{i=1}(x^{(i)})(x^{(i)})^T \]</span> This can be vectorized in Octave as: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;</span><br></pre></td></tr></table></figure></p><p>We denote the covariance matrix with a <strong>capital sigma</strong> (which happens to be the same symbol for summation, confusingly---they represent entirely different things).</p><p>Note that <span class="math inline">\(x^{(i)}\)</span> is an <span class="math inline">\(n \times 1\)</span> vector, <span class="math inline">\((x^{(i)})^T\)</span> is an <span class="math inline">\(1 \times n\)</span> vector and <span class="math inline">\(X\)</span> is a <span class="math inline">\(m \times n\)</span> matrix (row-wise stored examples). The product of those will be an <span class="math inline">\(n \times n\)</span> matrix, which are the dimensions of <span class="math inline">\(\Sigma\)</span>.</p><p>2.<strong>Compute &quot;eigenvectors&quot; of covariance matrix <span class="math inline">\(\Sigma\)</span></strong> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[U,S,V] = svd(Sigma);</span><br></pre></td></tr></table></figure></p><p><code>svd()</code> is the 'singular value decomposition(奇异值分解)', a built-in Octave function.</p><p>What we actually want out of <code>svd()</code> is the '<code>U</code>' matrix of the Sigma covariance matrix: <span class="math inline">\(U \in \mathbb{R}^{n \times n}\)</span>. U contains <span class="math inline">\(u^{(1)},\dots,u^{(n)}\)</span>, which is exactly what we want.</p><p>3.<strong>Take the first <span class="math inline">\(k\)</span> columns of the U matrix and compute <span class="math inline">\(z\)</span></strong></p><p>We'll assign the first <span class="math inline">\(k\)</span> columns of U to a variable called '<strong>Ureduce</strong>'. This will be an <span class="math inline">\(n \times k\)</span> matrix. We compute z with: <span class="math display">\[ \large z^{(i)} = Ureduce^T \cdot x^{(i)} \]</span></p><p><span class="math inline">\(Ureduce^T\)</span> will have dimensions <span class="math inline">\(k \times n\)</span> while <span class="math inline">\(x^{(i)}\)</span> will have dimensions <span class="math inline">\(n \times 1\)</span>. The product <span class="math inline">\(Ureduce^T \cdot x^{(i)}\)</span> will have dimensions <span class="math inline">\(k \times 1\)</span>.</p><p>To <strong>summarize</strong>, the whole algorithm in octave is roughly: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;  <span class="comment">% compute the covariance matrix</span></span><br><span class="line">[U,S,V] = svd(Sigma);    <span class="comment">% compute our projected directions</span></span><br><span class="line">Ureduce = U(:,<span class="number">1</span>:k);      <span class="comment">% take the first k directions</span></span><br><span class="line">z = Ureduce' * x;        <span class="comment">% compute the projected data points</span></span><br></pre></td></tr></table></figure></p><h1><span id="choosing-the-number-of-principal-components">Choosing the Number of Principal Components</span></h1><p>How do we choose <span class="math inline">\(k\)</span>, also called the number of principal components? Recall that <span class="math inline">\(k\)</span> is the dimension we are reducing to.</p><p>One way to choose <span class="math inline">\(k\)</span> is by using the following formula: * Given the average squared projection error: <span class="math inline">\(\dfrac{1}{m}\sum^m_{i=1}||x^{(i)} - x_{approx}^{(i)}||^2\)</span> * Also given the total variation in the data: <span class="math inline">\(\dfrac{1}{m}\sum^m_{i=1}||x^{(i)}||^2\)</span> * Choose <span class="math inline">\(k\)</span> to be the smallest value such that: <span class="math display">\[\large \dfrac{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)} - x_{approx}^{(i)}||^2}{\dfrac{1}{m}\sum^m_{i=1}||x^{(i)}||^2} \leq 0.01\]</span></p><p>In other words, the squared projection error divided by the total variation should be less than one percent, so that <strong>99% of the variance is retained</strong>.</p><p><strong>Algorithm for choosing <span class="math inline">\(k\)</span></strong></p><ol type="1"><li>Try PCA with <span class="math inline">\(k = 1, 2, \dots\)</span></li><li>Compute <span class="math inline">\(U_{reduce}, z, x\)</span></li><li>Check the formula given above that 99% of the variance is retained. If not, go to step one and increase <span class="math inline">\(k\)</span>.</li></ol><p>This procedure would actually be horribly inefficient. In Octave, we will call svd: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[U,S,V] = svd(Sigma)</span><br></pre></td></tr></table></figure></p><p>Which gives us a matrix S. We can actually check for 99% of retained variance using the S matrix as follows: <span class="math display">\[ \dfrac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}} \geq 0.99 \]</span></p><h1><span id="reconstruction-from-compressed-representation">Reconstruction from Compressed Representation</span></h1><p>If we use PCA to compress our data, how can we uncompress our data, or go back to our original number of features?</p><p>To go from 1-dimension back to 2d we do: <span class="math inline">\(z \in \mathbb{R} \rightarrow x \in \mathbb{R}^2\)</span>.</p><p>We can do this with the equation: <span class="math inline">\(x_{approx}^{(1)} = U_{reduce} \cdot z^{(1)}\)</span>.</p><p>Note that we can only get approximations of our original data.</p><h1><span id="advice-for-applying-pca">Advice for Applying PCA</span></h1><p>The most common use of PCA is to <strong>speed up supervised learning</strong>.</p><p>Given a training set with a large number of features (e.g. <span class="math inline">\(x^{(1)},\dots,x^{(m)} \in \mathbb{R}^{10000}\)</span>) we can use PCA to reduce the number of features in each example of the training set (e.g. <span class="math inline">\(z^{(1)},\dots,z^{(m)} \in \mathbb{R}^{1000}\)</span>).</p><p>Note that we should define the PCA reduction from <span class="math inline">\(x^{(i)}\)</span> to <span class="math inline">\(z^{(i)}\)</span> only on the training set and not on the cross-validation or test sets. You can apply the mapping <span class="math inline">\(z^{(i)}\)</span> to your cross-validation and test sets after it is defined on the training set.</p><p><strong>Applications</strong> * Compressions * Reduce space of data * Speed up algorithm * Visualization of data * Choose k = 2 or k = 3</p><p><strong>Bad use of PCA</strong>: trying to prevent overfitting. We might think that reducing the features with PCA would be an effective way to address overfitting. It might work, but is not recommended because it does not consider the values of our results <span class="math inline">\(y\)</span>. Using just regularization will be at least as effective.</p><p>Don't assume you need to do PCA. <strong>Try your full machine learning algorithm without PCA first</strong>. Then use PCA if you find that you need it.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> PCA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>聚类（Clustering）</title>
      <link href="/2016/03/10/%E8%81%9A%E7%B1%BB%EF%BC%88Clustering%EF%BC%89/"/>
      <url>/2016/03/10/%E8%81%9A%E7%B1%BB%EF%BC%88Clustering%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#unsupervised-learning-introduction">Unsupervised Learning: Introduction</a></li><li><a href="#k-means-algorithm">K-Means Algorithm</a></li><li><a href="#optimization-objective">Optimization Objective</a></li><li><a href="#random-initialization">Random Initialization</a></li><li><a href="#choosing-the-number-of-clusters">Choosing the Number of Clusters</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="unsupervised-learning-introduction">Unsupervised Learning: Introduction</span></h1><p>Unsupervised learning is contrasted from supervised learning because it uses an unlabeled training set rather than a labeled one.</p><p>In other words, we don't have the vector <span class="math inline">\(y\)</span> of expected results, we only have a dataset of features where we can find structure. Clustering is good for: * Market segmentation * Social network analysis * Organizing computer clusters * Astronomical data analysis</p><h1><span id="k-means-algorithm">K-Means Algorithm</span></h1><p>The K-Means Algorithm is the most popular and widely used algorithm for automatically grouping data into coherent subsets.</p><ol type="1"><li>Randomly initialize two points in the dataset called the cluster centroids.</li><li>Cluster assignment: assign all examples into one of two groups based on which cluster centroid the example is closest to.</li><li>Move centroid: compute the averages for all the points inside each of the two cluster centroid groups, then move the cluster centroid points to those averages.</li><li>Re-run (2) and (3) until we have found our clusters.</li></ol><p>Our main variables are: * <span class="math inline">\(K\)</span> (number of clusters) * Training set <span class="math inline">\({x^{(1)}, x^{(2)}, \dots,x^{(m)}}\)</span> * Where <span class="math inline">\(x^{(i)} \in \mathbb{R}^n\)</span></p><p>Note that we <strong>will not use</strong> the <span class="math inline">\(x_0 = 1\)</span> convention.</p><p><strong>The algorithm</strong>: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Randomly initialize K cluster centroids mu(1), mu(2), ..., mu(K)</span><br><span class="line">Repeat:</span><br><span class="line">   for i = 1 to m:</span><br><span class="line">      c(i) := index (from 1 to K) of cluster centroid closest to x(i)</span><br><span class="line">   for k = 1 to K:</span><br><span class="line">      mu(k) := average (mean) of points assigned to cluster k</span><br></pre></td></tr></table></figure></p><p>The <strong>first for-loop</strong> is the 'Cluster Assignment' step. We make a vector c where c(i) represents the centroid assigned to example x(i).</p><p>We can write the operation of the Cluster Assignment step more mathematically as follows: <span class="math display">\[c^{(i)} = argmin_k\ ||x^{(i)} - \mu_k||^2\]</span> That is, each <span class="math inline">\(c^{(i)}\)</span> contains the index of the centroid that has minimal distance to <span class="math inline">\(x^{(i)}\)</span>.</p><p>By convention, we square the right-hand-side, which makes the function we are trying to minimize more sharply increasing. It is mostly just a convention.</p><p>The <strong>second for-loop</strong> is the 'Move Centroid' step where we move each centroid to the average of its group.</p><p>More formally, the equation for this loop is as follows: <span class="math display">\[ \mu_k = \dfrac{1}{n}[x^{(k_1)} + x^{(k_2)} + \dots + x^{(k_n)}] \in \mathbb{R}^n\]</span> Where each of <span class="math inline">\(x^{(k_1)}, x^{(k_2)}, \dots, x^{(k_n)}\)</span> are the training examples assigned to group $ _k$.</p><p>If you have a cluster centroid with 0 points assigned to it, you can randomly <strong>re-initialize</strong> that centroid to a new point. You can also simply <strong>eliminate</strong> that cluster group.</p><p>After a number of iterations the algorithm will converge, where new iterations do not affect the clusters.</p><p>Note on non-separated clusters: some datasets have no real inner separation or natural structure. K-means can still evenly segment your data into <span class="math inline">\(K\)</span> subsets, so can still be useful in this case.</p><h1><span id="optimization-objective">Optimization Objective</span></h1><p>Recall some of the parameters we used in our algorithm: * $c^{(i)} = $ index of cluster (1,2,...,K) to which example <span class="math inline">\(x^{(i)}\)</span> is currently assigned * $_k = $ cluster centroid $ k (<em>k ^n)$ * $</em>{c^{(i)}} = $ cluster centroid of cluster to which example <span class="math inline">\(x^{(i)}\)</span> has been assigned</p><p>Using these variables we can define our cost function: <span class="math display">\[ \large J(c^{(i)},\dots,c^{(m)},\mu_1,\dots,\mu_K) = \dfrac{1}{m}\sum_{i=1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2 \]</span> Our optimization objective is to minimize all our parameters using the above cost function: <span class="math display">\[ \large min_{c,\mu}\ J(c,\mu) \]</span></p><p>That is, we are finding all the values in sets <span class="math inline">\(c\)</span>, representing all our clusters, and <span class="math inline">\(\mu\)</span>, representing all our centroids, that will minimize <strong>the average of the distances</strong> of every training example to its corresponding cluster centroid.</p><p>The above cost function is often called the <strong>distortion</strong>(变形) of the training examples.</p><p>In the <strong>cluster assignment</strong> step, our goal is to: Minimize <span class="math inline">\(J(\dots)\)</span> with <span class="math inline">\(c^{(1)},\dots,c^{(m)}\)</span> (holding <span class="math inline">\(\mu_1,\dots,\mu_K\)</span> fixed)</p><p>In the <strong>move centroid</strong> step, our goal is to: Minimize <span class="math inline">\(J(\dots)\)</span> with <span class="math inline">\(\mu_1,\dots,\mu_K\)</span></p><p>With k-means, it is <strong>not possible for the cost function to sometimes increase</strong>. It should always descend.</p><h1><span id="random-initialization">Random Initialization</span></h1><p>There's one particular recommended method for randomly initializing your cluster centroids.</p><ol type="1"><li>Have <span class="math inline">\(K &lt; m\)</span>. That is, make sure the number of your clusters is less than the number of your training examples.</li><li>Randomly pick <span class="math inline">\(K\)</span> training examples. (Not mentioned in the lecture, but also be sure the selected examples are <strong>unique</strong>).</li><li>Set <span class="math inline">\(\mu_1,\dots,\mu_k\)</span> equal to these <span class="math inline">\(K\)</span> examples.</li></ol><p>K-means <strong>can get stuck in local optima</strong>. To decrease the chance of this happening, you can run the algorithm on many different random initializations. <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for i = 1 to 100:</span><br><span class="line">   randomly initialize k-means</span><br><span class="line">   run k-means to get &apos;c&apos; and &apos;m&apos;</span><br><span class="line">   compute the cost function (distortion) J(c,m)</span><br><span class="line">pick the clustering that gave us the lowest cost</span><br></pre></td></tr></table></figure></p><h1><span id="choosing-the-number-of-clusters">Choosing the Number of Clusters</span></h1><p>Choosing <span class="math inline">\(K\)</span> can be quite arbitrary and ambiguous.</p><p><strong>The elbow method</strong>: plot the cost <span class="math inline">\(J\)</span> and the number of clusters <span class="math inline">\(K\)</span>. The cost function should reduce as we increase the number of clusters, and then flatten out. Choose <span class="math inline">\(K\)</span> at the point where the cost function starts to flatten out.</p><p>However, fairly often, the curve is very gradual, so there's no clear elbow.</p><p>Note: <span class="math inline">\(J\)</span> will always decrease as <span class="math inline">\(K\)</span> is increased. The one exception is if k-means gets stuck at a bad local optimum.</p><p>Another way to choose <span class="math inline">\(K\)</span> is to observe how well k-means performs on a <strong>downstream purpose</strong>. In other words, you choose <span class="math inline">\(K\)</span> that proves to be most useful for some goal you're trying to achieve from using these clusters.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Clustering </tag>
            
            <tag> K-Means </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>卷积神经网络(CNN)</title>
      <link href="/2016/03/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/"/>
      <url>/2016/03/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)/</url>
      
        <content type="html"><![CDATA[<p>卷积神经网络（Convolutional Neural Network, CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。</p><!-- toc --><ul><li><a href="#概揽">概揽</a></li><li><a href="#layers-used-to-build-convnets">Layers used to build ConvNets</a><ul><li><a href="#卷积层convolutional-layer">卷积层（Convolutional layer）</a></li><li><a href="#池化层pooling-layer">池化层(Pooling Layer)</a></li><li><a href="#全连接层fully-connected-layer">全连接层（Fully-connected layer）</a></li></ul></li><li><a href="#卷积神经网络架构">卷积神经网络架构</a><ul><li><a href="#layer-patterns">Layer Patterns</a></li><li><a href="#layer-sizing-patterns">Layer Sizing Patterns</a></li><li><a href="#case-studies">Case Studies</a></li></ul></li><li><a href="#参考">参考</a></li></ul><!-- tocstop --><a id="more"></a><h1><span id="概揽">概揽</span></h1><p><strong>卷积神经网络</strong>（Convolutional Neural Networks / CNNs / ConvNets）与普通神经网络非常相似，它们都由具有可学习的权重和偏置常量(biases)的神经元组成。每个神经元都接收一些输入，并做一些点积计算，输出是每个分类的分数，普通神经网络里的一些计算技巧到这里依旧适用。</p><p>所以哪里不同呢？卷积神经网络默认输入是图像，可以让我们把特定的性质编码入网络结构，使是我们的前馈函数更加有效率，并减少了大量参数。</p><p><strong>具有三维体积的神经元(3D volumes of neurons)</strong> 卷积神经网络利用输入是图片的特点，把神经元设计成三个维度 ： <strong>width</strong>, <strong>height</strong>, <strong>depth</strong>(注意这个depth不是神经网络的深度，而是用来描述神经元的) 。比如输入的图片大小是 32 × 32 × 3 (rgb)，那么输入神经元就也具有 32×32×3 的维度。下面是图解：</p><p><img src="/images/1457405418840.png"> 传统神经网络</p><p><img src="/images/1457405426800.png"> 卷积神经网络</p><p>一个卷积神经网络由很多层组成，它们的输入是三维的，输出也是三维的，有的层有参数，有的层不需要参数。</p><h1><span id="layers-used-to-build-convnets">Layers used to build ConvNets</span></h1><p>卷积神经网络通常包含以下几种层：</p><ul><li><strong>卷积层（Convolutional layer）</strong>，卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。</li><li><strong>线性整流层（Rectified Linear Units layer, ReLU layer）</strong>，这一层神经的活性化函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）<span class="math inline">\(f(x) = max(0, x)\)</span>。</li><li><strong>池化层（Pooling layer）</strong>，通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。</li><li><strong>全连接层（ Fully-Connected layer）</strong>, 把所有局部特征结合变成全局特征，用来计算最后每一类的得分。</li></ul><p>一个卷积神经网络各层应用<a href="http://cs231n.stanford.edu/" target="_blank" rel="noopener">实例</a>： <img src="/images/1457406468399.png"></p><h2><span id="卷积层convolutional-layer">卷积层（Convolutional layer）</span></h2><p><strong>局部感知（Local Connectivity）</strong></p><p>普通神经网络把输入层和隐含层进行“<strong>全连接(Full Connected)</strong>“的设计。从计算的角度来讲，相对较小的图像从整幅图像中计算特征是可行的。但是，如果是更大的图像（如 96x96 的图像），要通过这种全联通网络的这种方法来学习整幅图像上的特征，从计算角度而言，将变得非常耗时。你需要设计 10 的 4 次方（=10000）个输入单元，假设你要学习 100 个特征，那么就有 10 的 6 次方个参数需要去学习。与 28x28 的小块图像相比较， 96x96 的图像使用前向输送或者后向传导的计算方式，计算过程也会慢 10 的 2 次方（=100）倍。</p><p>卷积层解决这类问题的一种简单方法是对隐含单元和输入单元间的连接加以限制：<strong>每个隐含单元仅仅只能连接输入单元的一部分</strong>。例如，每个隐含单元仅仅连接输入图像的一小片相邻区域。（对于不同于图像输入的输入形式，也会有一些特别的连接到单隐含层的输入信号“连接区域”选择方式。如音频作为一种信号输入方式，一个隐含单元所需要连接的输入单元的子集，可能仅仅是一段音频输入所对应的某个时间段上的信号。)</p><p>每个隐含单元连接的输入区域大小叫r神经元的<strong>感受野(receptive field)</strong>。</p><p>由于卷积层的神经元也是三维的，所以也具有深度。卷积层的参数包含一系列过滤器（filter），每个过滤器训练一个深度，有几个过滤器输出单元就具有多少深度。</p><p>具体如下图所示，样例输入单元大小是32×32×3, 输出单元的深度是5, 对于输出单元不同深度的同一位置，与输入图片连接的区域是相同的，但是参数（过滤器）不同。</p><p><img src="/images/1457406711273.png"></p><p>虽然每个输出单元只是连接输入的一部分，但是值的计算方法是没有变的，都是权重和输入的点积，然后加上偏置，这点与普通神经网络是一样的，如下图所示：</p><p><img src="/images/1457407298878.png"></p><p><strong>空间排列（Spatial arrangement）</strong></p><p>一个输出单元的大小有以下三个量控制：<strong>depth</strong>, <strong>stride</strong> 和 <strong>zero-padding</strong>。</p><ul><li><strong>深度(depth)</strong> : 顾名思义，它控制输出单元的深度，也就是filter的个数，连接同一块区域的神经元个数。又名：<strong>depth column</strong></li><li><strong>步幅(stride)</strong>：它控制在同一深度的相邻两个隐含单元，与他们相连接的输入区域的距离。如果步幅很小（比如 stride = 1）的话，相邻隐含单元的输入区域的重叠部分会很多; 步幅很大则重叠区域变少。</li><li><strong>补零(zero-padding)</strong> ： 我们可以通过在输入单元周围补零来改变输入单元整体大小，从而控制输出单元的空间大小。</li></ul><p>我们先定义几个符号：</p><ul><li><span class="math inline">\(W\)</span> : 输入单元的大小（宽或高）</li><li><span class="math inline">\(F\)</span> : 感受野(receptive field)</li><li><span class="math inline">\(S\)</span> : 步幅（stride）</li><li><span class="math inline">\(P\)</span> : 补零（zero-padding)的数量</li><li><span class="math inline">\(K\)</span> : 深度，输出单元的深度</li></ul><p>则可以用以下公式计算一个维度（宽或高）内一个输出单元里可以有几个隐藏单元： <span class="math display">\[\frac{W - F + 2P}{S} + 1\]</span> 如果计算结果不是一个整数，则说明现有参数不能正好适合输入，步幅（stride）设置的不合适，或者需要补零，证明略，下面用一个例子来说明一下。</p><p>这是一个一维的例子，左边模型输入单元有5个，即<span class="math inline">\(W = 5\)</span>, 边界各补了一个零，即<span class="math inline">\(P = 1\)</span>，步幅是1， 即<span class="math inline">\(S = 1\)</span>，感受野是3，因为每个输出隐藏单元连接3个输入单元，即<span class="math inline">\(F = 3\)</span>，根据上面公式可以计算出输出隐藏单元的个数是：<span class="math inline">\(\frac{5 - 3 + 2}{1} + 1 = 5\)</span>，与图示吻合。右边那个模型是把步幅变为2，其余不变，可以算出输出大小为：<span class="math inline">\(\frac{5 - 3 + 2}{2} + 1 = 3\)</span>，也与图示吻合。若把步幅改为3，则公式不能整除，说明步幅为3不能恰好吻合输入单元大小。</p><p><img src="/images/1457416670778.png"></p><p>另外，网络的权重在图的右上角，计算方法和普通神经网路一样。</p><p><strong>参数共享(Parameter Sharing)</strong></p><p>应用参数共享可以大量减少参数数量，参数共享基于一个假设：如果图像中的一点（x1, y1）包含的特征很重要，那么它应该和图像中的另一点（x2, y2）一样重要。换种说法，我们把同一深度的平面叫做<strong>深度切片(depth slice)</strong>（(e.g. a volume of size [55x55x96] has 96 depth slices, each of size [55x55])），那么同一个切片应该共享同一组权重和偏置。我们仍然可以使用梯度下降的方法来学习这些权值，只需要对原始算法做一些小的改动， 这里共享权值的梯度是所有共享参数的梯度的总和。</p><p>我们不禁会问为什么要权重共享呢？一方面，重复单元能够对特征进行识别，而不考虑它在可视域中的位置。另一方面，权值共享使得我们能更有效的进行特征抽取，因为它极大的减少了需要学习的自由变量的个数。通过控制模型的规模，卷积网络对视觉问题可以具有很好的泛化能力。</p><p><strong>卷积（Convolution）</strong></p><p>如果应用参数共享的话，实际上每一层计算的操作就是输入层和权重的<strong>卷积</strong>！这也就是卷积神经网络名字的由来。</p><p>先抛开卷积这个概念不管。为简便起见，考虑一个大小为5×5的图像，和一个3×3的卷积核。这里的卷积核共有9个参数，就记为 <span class="math inline">\(Θ=[θ_{ij}]_{3×3}\)</span> 吧。这种情况下，卷积核实际上有9个神经元，他们的输出又组成一个3×3的矩阵，称为特征图。第一个神经元连接到图像的第一个3×3的局部，第二个神经元则连接到第二个局部（注意，有重叠！就跟你的目光扫视时也是连续扫视一样）。具体如下图所示。</p><p><img src="/images/1457419579658.png"></p><p>图的上方是第一个神经元的输出，下方是第二个神经元的输出。每个神经元的运算依旧是</p><p><span class="math display">\[f(x)=act(\sum_{i,j}^{n}θ_{(n−i)(n−j)}x_{ij}+b)\]</span></p><p>需要注意的是，平时我们在运算时，习惯使用 <span class="math inline">\(θ_{ij}x_{ij}\)</span> 这种写法，但事实上，我们这里使用的是 <span class="math inline">\(θ_{(n−i)(n−j)}x_{ij}\)</span>。</p><p>现在我们回忆一下离散卷积运算。假设有二维离散函数 <span class="math inline">\(f(x,y)\)</span> , <span class="math inline">\(g(x,y)\)</span> ， 那么它们的卷积定义为 <span class="math display">\[f(m,n)∗g(m,n)=\sum_{u}^{∞}\sum_{v}^{∞}f(u,v)g(m−u,n−v)\]</span></p><p>现在发现了吧！上面例子中的9个神经元均完成输出后，实际上等价于图像和卷积核的卷积操作！</p><p><strong>Numpy examples</strong></p><p>下面用numpy的代码具体的说明一下上面的概念和公式等。</p><p>假设输入存储在一个numpy array <code>X</code>里，那么： * 位于 (x, y) 的 depth column 是 <code>X[x, y, :]</code> * 深度为 d 的 depth slice 是 <code>X[:, :, d]</code></p><p>假设X的大小是<code>X.shape: (11,11,4)</code>，并且不用补零（P ＝ 0），过滤器（感受野）大小F ＝ 5，步幅为2（S＝ 2）。那么输出单元的空间大小应该为 (11 - 5) / 2 + 1 = 4，即宽和高都为4 。假设输出存储在 <code>V</code> 中，那么它的计算方式应该为：</p><ul><li><code>V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0</code></li><li><code>V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0</code></li><li><code>V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0</code></li><li><code>V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0</code></li><li></li><li><code>V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1</code></li><li><code>V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1</code></li><li><code>V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1</code></li><li><code>V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1</code></li><li><code>V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1</code></li><li><code>V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1</code></li></ul><p>注意在numpy中 <code>*</code> 表示两个数组对应元素相乘。</p><p><strong>卷积层总结(Summary)</strong></p><ul><li>接收三维输入 <span class="math inline">\(W_1 * H_1 * D_1\)</span></li><li>需要给出4个参数（hyperparameters）：<ul><li>Number of filters <span class="math inline">\(K\)</span>,</li><li>their spatial extent <span class="math inline">\(F\)</span>,</li><li>the stride <span class="math inline">\(S\)</span>,</li><li>the amount of zero padding <span class="math inline">\(P\)</span>.</li></ul></li><li>输出一个三维单元 <span class="math inline">\(W_2 * H_2 * D_2\)</span>，其中：<ul><li><span class="math inline">\(W_2 = \frac{W_1 - F + 2P}{S} + 1\)</span></li><li><span class="math inline">\(H_2 = \frac{H_1 - F + 2P}{S} + 1\)</span></li><li><span class="math inline">\(D_2 = K\)</span><br></li></ul></li><li>应用权值共享，每个filter会产生<span class="math inline">\(F * F * D_1\)</span> 个权重，总共 $(F * F * D_1) * K $ 个权重和 <span class="math inline">\(K\)</span> 个偏置。</li><li>在输出单元，第d个深度切片的结果是由第d个filter 和输入单元做卷积运算，然后再加上偏置而来。</li></ul><h2><span id="池化层pooling-layer">池化层(Pooling Layer)</span></h2><p><strong>池化（pool）</strong>即<strong>下采样（downsamples）</strong>，目的是为了减少特征图。池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种： * 最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。 * 均值池化（Mean Pooling）。取4个点的均值。 * 高斯池化。借鉴高斯模糊的方法。不常用。 * 可训练池化。训练函数 ff ，接受4个点为输入，出入1个点。不常用。</p><p>最常见的池化层是规模为2*2， 步幅为2，对输入的每个深度切片进行下采样。每个MAX操作对四个数进行，如下图所示： <img src="/images/1457434159635.png"></p><p>池化操作将保存<strong>深度大小不变</strong>。</p><p>如果池化层的输入单元大小不是二的整数倍，一般采取边缘补零（zero-padding）的方式补成2的倍数，然后再池化。</p><p><strong>池化层总结(Summary)</strong></p><ul><li>接收单元大小为：<span class="math inline">\(W_1 * H_1 * D_1\)</span></li><li>需要两个参数（hyperparameters）：<ul><li>their spatial extent <span class="math inline">\(F\)</span>,</li><li>the stride <span class="math inline">\(S\)</span>,</li></ul></li><li>输出大小：<span class="math inline">\(W_2 * H_2 * D_2\)</span>，其中：<ul><li><span class="math inline">\(W_2=\frac{W_1−F}{S}\)</span></li><li><span class="math inline">\(H_2=\frac{H_1−F}{S}+1\)</span></li><li><span class="math inline">\(D_2=D_1\)</span></li></ul></li><li>不需要引入新权重</li></ul><h2><span id="全连接层fully-connected-layer">全连接层（Fully-connected layer）</span></h2><p>全连接层和卷积层可以相互转换： * 对于任意一个卷积层，要把它变成全连接层只需要把权重变成一个巨大的矩阵，其中大部分都是0 除了一些特定区块（因为局部感知），而且好多区块的权值还相同（由于权重共享）。 * 相反地，对于任何一个全连接层也可以变为卷积层。比如，一个<span class="math inline">\(K ＝ 4096\)</span> 的全连接层，输入层大小为 <span class="math inline">\(7*7*512\)</span>，它可以等效为一个 <span class="math inline">\(F=7,\ P=0,\ S=1,\ K=4096\)</span> 的卷积层。换言之，我们把 filter size 正好设置为整个输入层大小。</p><h1><span id="卷积神经网络架构">卷积神经网络架构</span></h1><h2><span id="layer-patterns">Layer Patterns</span></h2><p>常见的卷积神经网络架构是这样的： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOL?]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</span><br></pre></td></tr></table></figure></p><p>堆叠几个卷积和整流层，再加一个池化层，重复这个模式知道图片已经被合并得比较小了，然后再用全连接层控制输出。</p><p>上述表达式中 <code>?</code> 意味着0次或1次，通常情况下：<code>N &gt;= 0 &amp;&amp; N &lt;= 3</code>, <code>M &gt;= 0</code>, <code>K &gt;= 0 &amp;&amp; K &lt; 3</code>。</p><p>比如你可以组合出以下几种模式： * <code>INPUT -&gt; FC</code>, 实现了一个线性分类器， 这里 <code>N = M = K = 0</code> * <code>INPUT -&gt; CONV -&gt; RELU -&gt; FC</code> * <code>INPUT -&gt; [CONV -&gt; RELU -&gt; POOL]*2 -&gt; FC -&gt; RELU -&gt; FC</code>. Here we see that there is a single <code>CONV</code> layer between every <code>POOL</code> layer. * <code>INPUT -&gt; [CONV -&gt; RELU -&gt; CONV -&gt; RELU -&gt; POOL]*3 -&gt; [FC -&gt; RELU]*2 -&gt; FC</code> Here we see two CONV layers stacked before every POOL layer. This is generally a good idea for larger and deeper networks, because multiple stacked CONV layers can develop more complex features of the input volume before the destructive pooling operation.</p><h2><span id="layer-sizing-patterns">Layer Sizing Patterns</span></h2><ul><li><strong>Input layer</strong> : 应该是2的整数次幂。比如32，64， 128等。</li><li><strong>Conv Layer</strong> : 使用小的过滤器（filter），$ F = 3 or F = 5$, 步幅 <span class="math inline">\(S=1\)</span>，如果不能恰好拟合输入层，还要边缘补零。如果使用 <span class="math inline">\(F = 3,\ P = 1\)</span>，那么输出大小将与输入一样。如果用更大的过滤器（比如7*7），一般只会在紧挨着原始输入图片的卷积层才会看到。</li><li><strong>Pool Layer</strong> : <span class="math inline">\(F = 2,\ S = 2\)</span></li></ul><h2><span id="case-studies">Case Studies</span></h2><p>大牛们构建的网络</p><ul><li><strong>LeNet</strong>. The first successful applications of Convolutional Networks were developed by Yann LeCun in 1990's. Of these, the best known is the <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target="_blank" rel="noopener">LeNet</a> architecture that was used to read zip codes, digits, etc.</li><li><strong>AlexNet</strong>. The first work that popularized Convolutional Networks in Computer Vision was the <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="noopener">AlexNet</a>, developed by Alex Krizhevsky, Ilya Sutskever and Geoff Hinton. The AlexNet was submitted to the <a href="http://www.image-net.org/challenges/LSVRC/2014/" target="_blank" rel="noopener">ImageNet ILSVRC challenge</a> in 2012 and significantly outperformed the second runner-up (top 5 error of 16% compared to runner-up with 26% error). The Network had a similar architecture basic as LeNet, but was deeper, bigger, and featured Convolutional Layers stacked on top of each other (previously it was common to only have a single CONV layer immediately followed by a POOL layer).</li><li><strong>ZF Net</strong>. The ILSVRC 2013 winner was a Convolutional Network from Matthew Zeiler and Rob Fergus. It became known as the <a href="http://arxiv.org/abs/1311.2901" target="_blank" rel="noopener">ZFNet</a> (short for Zeiler &amp; Fergus Net). It was an improvement on AlexNet by tweaking the architecture hyperparameters, in particular by expanding the size of the middle convolutional layers.</li><li><strong>GoogLeNet</strong>. The ILSVRC 2014 winner was a Convolutional Network from <a href="http://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">Szegedy et al.</a> from Google. Its main contribution was the development of an Inception Module that dramatically reduced the number of parameters in the network (4M, compared to AlexNet with 60M). Additionally, this paper uses Average Pooling instead of Fully Connected layers at the top of the ConvNet, eliminating a large amount of parameters that do not seem to matter much.</li><li><strong>VGGNet</strong>. The runner-up in ILSVRC 2014 was the network from Karen Simonyan and Andrew Zisserman that became known as the <a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="noopener">VGGNet</a>. Its main contribution was in showing that the depth of the network is a critical component for good performance. Their final best network contains 16 CONV/FC layers and, appealingly, features an extremely homogeneous architecture that only performs 3x3 convolutions and 2x2 pooling from the beginning to the end. It was later found that despite its slightly weaker classification performance, the VGG ConvNet features outperform those of GoogLeNet in multiple transfer learning tasks. Hence, the VGG network is currently the most preferred choice in the community when extracting CNN features from images. In particular, their <a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/" target="_blank" rel="noopener">pretrained model</a> is available for plug and play use in Caffe. A downside of the VGGNet is that it is more expensive to evaluate and uses a lot more memory and parameters (140M).</li><li><strong>ResNet</strong>. <a href="http://arxiv.org/abs/1512.03385" target="_blank" rel="noopener">Residual Network</a> developed by Kaiming He et al. was the winner of ILSVRC 2015. It features an interesting architecture with special skip connections and features heavy use of batch normalization. The architecture is also missing fully connected layers at the end of the network. The reader is also referred to Kaiming's presentation (<a href="https://www.youtube.com/watch?v=1PGLj-uKT1w" target="_blank" rel="noopener">video</a>, <a href="http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf" target="_blank" rel="noopener">slides</a>), and some <a href="https://github.com/gcr/torch-residual-networks" target="_blank" rel="noopener">recent experiments</a> that reproduce these networks in Torch.</li></ul><h1><span id="参考">参考</span></h1><p><a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">CS231n: Convolutional Neural Networks for Visual Recognition</a> <a href="https://www.wikiwand.com/zh-hans/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" target="_blank" rel="noopener">卷积神经网络-维基百科</a> <a href="http://deeplearning.stanford.edu/wiki/index.php/%E5%8D%B7%E7%A7%AF%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96" target="_blank" rel="noopener">卷积特征提取</a> <a href="http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi" target="_blank" rel="noopener">卷积神经网络全面解析</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>初识SVM</title>
      <link href="/2016/03/03/Support%20Vector%20Machines%20(SVMs)/"/>
      <url>/2016/03/03/Support%20Vector%20Machines%20(SVMs)/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#optimization-objective">Optimization Objective</a></li><li><a href="#large-margin-intuition">Large Margin Intuition</a></li><li><a href="#mathematics-behind-large-margin-classification">Mathematics Behind Large Margin Classification</a></li><li><a href="#kernels-i">Kernels I</a></li><li><a href="#kernels-ii">Kernels II</a></li><li><a href="#using-an-svm">Using An SVM</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="optimization-objective">Optimization Objective</span></h2><p>The Support Vector Machine (SVM) is yet another type of supervised machine learning algorithm. It is sometimes cleaner and more powerful.</p><p>Recall that in logistic regression, we use the following rules: * if <span class="math inline">\(y=1\)</span>, then <span class="math inline">\(h_θ(x)≈1\)</span> and <span class="math inline">\(Θ^Tx≫0\)</span> * if <span class="math inline">\(y=0\)</span>, then <span class="math inline">\(h_θ(x)≈0\)</span> and <span class="math inline">\(Θ^Tx≪0\)</span></p><p>Recall the cost function for (unregularized) logistic regression:</p><p><span class="math display">\[J(θ)=\frac{1}{m}\sum_{i=1}^m−y^{(i)}\log(h_θ(x^{(i)}))−(1−y^{(i)})\log(1−h_θ(x^{(i)}))\]</span> <span class="math display">\[=\frac{1}{m}\sum_{i=1}^m−y^{(i)}\log(\frac{1}{1+e^{−θ^Tx^{(i)}}})−(1−y^{(i)})\log(1−\frac{1}{1+e^{−θ^Tx^{(i)}}})\]</span></p><p>To make a support vector machine, we will modify the first term of the cost function <span class="math inline">\((−\log(h_θ(x))=−\log(\frac{1}{1+e^{−θ^Tx}}))\)</span> so that when <span class="math inline">\(θ^Tx\)</span> (from now on, we shall refer to this as <span class="math inline">\(z\)</span>) is greater than 1, it outputs 0. Furthermore, for values of <span class="math inline">\(z\)</span> less than 1, we shall use a straight decreasing line instead of the sigmoid curve.(In the literature, this is called a hinge loss function.)</p><p><img src="/images/1456900464932.png"></p><p>Similarly, we modify the second term of the cost function <span class="math inline">\((−\log(1−h_θ(x))=−log(1−\frac{1}{1+e^{−θ^Tx}}))\)</span> so that when <span class="math inline">\(z\)</span> is less than -1, it outputs 0. We also modify it so that for values of <span class="math inline">\(z\)</span> greater than -1, we use a straight increasing line instead of the sigmoid curve.</p><p><img src="/images/1456900546259.png"></p><p>We shall denote these as <span class="math inline">\(\text{cost}_1(z)\)</span> and <span class="math inline">\(\text{cost}_0(z)\)</span> (respectively, note that <span class="math inline">\(\text{cost}_1(z)\)</span> is the cost for classifying when y=1, and <span class="math inline">\(\text{cost}_0(z)\)</span> is the cost for classifying when <span class="math inline">\(y=0\)</span>), and we may define them as follows (where k is an arbitrary constant defining the magnitude(大小) of the slope of the line): <span class="math display">\[z = \theta^Tx\]</span> <span class="math display">\[\text{cost}_0(z) = \max(0, k(1+z))\]</span> <span class="math display">\[\text{cost}_1(z) = \max(0, k(1-z))\]</span></p><p>Recall the full cost function from (regularized) logistic regression:</p><p><span class="math display">\[ J(\theta) = \frac{1}{m} \sum_{i=1}^m y^{(i)}(-\log(h_\theta(x^{(i)}))) + (1 - y^{(i)})(-\log(1 - h_\theta(x^{(i)}))) + \dfrac{\lambda}{2m}\sum_{j=1}^n \Theta^2_j \]</span></p><p>Note that the negative sign has been distributed into the sum in the above equation.</p><p>We may transform this into the cost function for support vector machines by substituting <span class="math inline">\(\text{cost}_0(z)\)</span> and <span class="math inline">\(\text{cost}_1(z)\)</span>:</p><p><span class="math display">\[ J(\theta) = \frac{1}{m} \sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{\lambda}{2m}\sum_{j=1}^n \Theta^2_j \]</span></p><p>We can optimize this a bit by multiplying this by <span class="math inline">\(m\)</span> (thus removing the <span class="math inline">\(m\)</span> factor in the denominators). Note that this does not affect our optimization, since we're simply multiplying our cost function by a positive constant (for example, minimizing <span class="math inline">\((u-5)^2 + 1\)</span> gives us 5; multiplying it by 10 to make it <span class="math inline">\(10(u-5)^2 + 10\)</span> still gives us 5 when minimized). <span class="math display">\[ J(\theta) = \sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{\lambda}{2}\sum_{j=1}^n \Theta^2_j \]</span></p><p>Furthermore, convention dictates that we regularize using a factor <span class="math inline">\(C\)</span>, instead of <span class="math inline">\(\lambda\)</span>, like so: <span class="math display">\[ J(\theta) = C\sum_{i=1}^m y^{(i)} \ \text{cost}_1(\theta^Tx^{(i)}) + (1 - y^{(i)}) \ \text{cost}_0(\theta^Tx^{(i)}) + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \]</span></p><p>This is equivalent to multiplying the equation by <span class="math inline">\(C = \dfrac{1}{\lambda}\)</span>, and thus results in the same values when optimized. Now, when we wish to regularize more (that is, reduce overfitting), we decrease <span class="math inline">\(C\)</span>, and when we wish to regularize less (that is, reduce underfitting), we increase <span class="math inline">\(C\)</span>.</p><p>Finally, note that the hypothesis of the Support Vector Machine is not interpreted as the probability of <span class="math inline">\(y\)</span> being 1 or 0 (as it is for the hypothesis of logistic regression). Instead, it outputs either 1 or 0. (In technical terms, it is a discriminant function.)</p><p><span class="math display">\[ h_\theta(x) = \begin{cases} 1 &amp; \text{if} \ \Theta^Tx \geq 0 \\ 0 &amp; \text{otherwise} \end{cases} \]</span></p><h2><span id="large-margin-intuition">Large Margin Intuition</span></h2><p>A useful way to think about Support Vector Machines is to think of them as <strong>Large Margin Classifiers</strong>. * If <span class="math inline">\(y = 1\)</span>, we want <span class="math inline">\(\Theta^Tx \geq 1\)</span> (not just <span class="math inline">\(\geq 0\)</span>) * If <span class="math inline">\(y = 0\)</span>, we want <span class="math inline">\(\Theta^Tx \leq -1\)</span> (not just <span class="math inline">\(&lt; 0\)</span>)</p><p>Now when we set our constant <span class="math inline">\(C\)</span> to a very large value (e.g. 100,000), our optimizing function will constrain(强迫) <span class="math inline">\(\Theta\)</span> such that the equation <span class="math inline">\(A\)</span> (the summation of the cost of each example) equals 0. We impose(强加) the following constraints on <span class="math inline">\(\Theta\)</span>:</p><p><span class="math display">\[ \Theta^Tx \geq 1\ if\ y = 1\ and\ \Theta^Tx \leq -1\ if\ y=0 \]</span></p><p>If <span class="math inline">\(C\)</span> is very large, we must choose <span class="math inline">\(\Theta\)</span> parameters such that: <span class="math display">\[ \sum_{i=1}^m y^{(i)}\text{cost}_1(\Theta^Tx) + (1 - y^{(i)})\text{cost}_0(\Theta^Tx) = 0 \]</span></p><p>This reduces our cost function to: <span class="math display">\[ \large \begin{align*} J(\theta) = C \cdot 0 + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \newline = \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \end{align*} \]</span></p><p>Recall the decision boundary from logistic regression (the line separating the positive and negative examples). In SVMs, the decision boundary has the special property that it is <strong>as far away as possible</strong> from both the positive and the negative examples.</p><p>The distance of the decision boundary to the nearest example is called the margin. Since SVMs maximize this margin, it is often called a Large Margin Classifier.</p><p>The SVM will separate the negative and positive examples by a <strong>large margin</strong>.</p><p>This large margin is only achieved when <span class="math inline">\(C\)</span> is very large.</p><p>Data is linearly separable when a straight line can separate the positive and negative examples.</p><p>If we have outlier examples that we don't want to affect the decision boundary, then we can reduce <span class="math inline">\(C\)</span>.</p><p>Increasing and decreasing <span class="math inline">\(C\)</span> is similar to respectively decreasing and increasing <span class="math inline">\(\lambda\)</span>, and can simplify our decision boundary.</p><h2><span id="mathematics-behind-large-margin-classification">Mathematics Behind Large Margin Classification</span></h2><p><strong>Vector Inner Product</strong></p><p>Say we have two vectors, <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>: <span class="math display">\[ \begin{align*} u = \begin{bmatrix} u_1 \newline u_2 \end{bmatrix} &amp; v = \begin{bmatrix} v_1 \newline v_2 \end{bmatrix} \end{align*} \]</span></p><p>The length of vector <span class="math inline">\(v\)</span> is denoted <span class="math inline">\(||v||\)</span>, and it describes the line on a graph from origin (0,0) to <span class="math inline">\((v_1,v_2)\)</span>.</p><p>The length of vector <span class="math inline">\(v\)</span> can be calculated with <span class="math inline">\(\sqrt{v_1^2 + v_2^2}\)</span> by the Pythagorean theorem(勾股定理).</p><p>The projection(投影) of vector <span class="math inline">\(v\)</span> onto vector <span class="math inline">\(u\)</span> is found by taking a right angle from <span class="math inline">\(u\)</span> to the end of <span class="math inline">\(v\)</span>, creating a right triangle.</p><ul><li>$p = $ length of projection of <span class="math inline">\(v\)</span> onto the vector <span class="math inline">\(u\)</span>.</li><li><span class="math inline">\(u^Tv= p \cdot ||u||\)</span></li></ul><p>Note that $ u^Tv = ||u|| ||v|| $ where $ $ is the angle between <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>. Also, $ p = ||v|| $. If you substitute <span class="math inline">\(p\)</span> for $ ||v|| $, you get <span class="math inline">\(u^Tv= p \cdot ||u||\)</span>.</p><p>So the product <span class="math inline">\(u^Tv\)</span> is equal to the length of the projection times the length of vector <span class="math inline">\(u\)</span>.</p><p>In our example, since <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are vectors of the same length, <span class="math inline">\(u^Tv = v^Tu\)</span>. <span class="math display">\[u^Tv = v^Tu = p \cdot ||u|| = u_1v_1 + u_2v_2 \]</span></p><p>If the angle between the lines for <span class="math inline">\(v\)</span> and <span class="math inline">\(u\)</span> is greater than 90 degrees, then the projection <span class="math inline">\(p\)</span> will be negative. <span class="math display">\[ \begin{align*} &amp;min_\Theta \dfrac{1}{2}\sum_{j=1}^n \Theta_j^2 \newline &amp;= \dfrac{1}{2}(\Theta_1^2 + \Theta_2^2 + \dots + \Theta_n^2) \newline &amp;= \dfrac{1}{2}(\sqrt{\Theta_1^2 + \Theta_2^2 + \dots + \Theta_n^2})^2 \newline &amp;= \dfrac{1}{2}||\Theta ||^2 \newline \end{align*} \]</span></p><p>We can use the same rules to rewrite <span class="math inline">\(\Theta^Tx^{(i)}\)</span>:</p><p><span class="math display">\[ \Theta^Tx^{(i)} = p^{(i)} \cdot ||\Theta || = \Theta_1x_1^{(i)} + \Theta_2x_2^{(i)} + \dots + \Theta_nx_n^{(i)} \]</span></p><p>So we now have a new optimization objective by substituting <span class="math inline">\(p^{(i)} \cdot ||\Theta ||\)</span> in for <span class="math inline">\(\Theta^Tx^{(i)}\)</span>: * If <span class="math inline">\(y = 1\)</span>, we want <span class="math inline">\(p^{(i)} \cdot ||\Theta || \geq 1\)</span> * If <span class="math inline">\(y = 0\)</span>, we want <span class="math inline">\(p^{(i)} \cdot ||\Theta || \leq -1\)</span></p><p>The reason this causes a &quot;large margin&quot; is because: the vector for $$ is perpendicular(垂直的、正交的) to the decision boundary. In order for our optimization objective (above) to hold true, we need the absolute value of our projections <span class="math inline">\(p^{(i)}\)</span> to be as large as possible.</p><p>If <span class="math inline">\(\Theta_0 = 0\)</span>, then all our decision boundaries will intersect (0,0). If $ _0 0 $, the support vector machine will still find a large margin for the decision boundary.</p><h2><span id="kernels-i">Kernels I</span></h2><p>Kernels allow us to make complex, non-linear classifiers using Support Vector Machines.</p><p>Given <span class="math inline">\(x\)</span>, compute new feature depending on proximity(接近度) to landmarks <span class="math inline">\(l^{(1)},\ l^{(2)},\ l^{(3)}\)</span>.</p><p>To do this, we find the &quot;similarity&quot; of <span class="math inline">\(x\)</span> and some landmark <span class="math inline">\(l^{(i)}\)</span>: <span class="math display">\[ f_i = similarity(x, l^{(i)}) = \exp(-\dfrac{||x - l^{(i)}||^2}{2\sigma^2}) \]</span></p><p>This &quot;similarity&quot; function is called a Gaussian Kernel. It is a specific example of a kernel. The similarity function can also be written as follows: <span class="math display">\[ f_i = similarity(x, l^{(i)}) = \exp(-\dfrac{\sum^n_{j=1}(x_j-l_j^{(i)})^2}{2\sigma^2}) \]</span></p><p>There are a couple properties of the similarity function: * If <span class="math inline">\(x \approx l^{(i)}\)</span>, then <span class="math inline">\(f_i = \exp(-\dfrac{\approx 0^2}{2\sigma^2}) \approx 1\)</span> * If <span class="math inline">\(x\)</span> is far from <span class="math inline">\(l^{(i)}\)</span>, then <span class="math inline">\(f_i = \exp(-\dfrac{(large\ number)^2}{2\sigma^2}) \approx 0\)</span></p><p>In other words, if <span class="math inline">\(x\)</span> and the landmark are close, then the similarity will be close to 1, and if <span class="math inline">\(x\)</span> and the landmark are far away from each other, the similarity will be close to 0.</p><p>Each landmark gives us the features in our hypothesis: <span class="math display">\[ \begin{align*} l^{(1)} \rightarrow f_1 \newline l^{(2)} \rightarrow f_2 \newline l^{(3)} \rightarrow f_3 \newline \dots \newline h_\Theta(x) = \Theta_1f_1 + \Theta_2f_2 + \Theta_3f_3 + \dots \end{align*} \]</span></p><p><span class="math inline">\(\sigma^2\)</span> is a parameter of the Gaussian Kernel, and it can be modified to increase or decrease the drop-off of our feature <span class="math inline">\(f_i\)</span>.</p><p>Combined with looking at the values inside <span class="math inline">\(\Theta\)</span>, we can choose these landmarks to get the general shape of the decision boundary.</p><h2><span id="kernels-ii">Kernels II</span></h2><p>One way to get the landmarks is to put them in the exact same locations as all the training examples. This gives us <span class="math inline">\(m\)</span> landmarks, with one landmark per training example.</p><p>Given example <span class="math inline">\(x\)</span>:</p><ul><li><span class="math inline">\(f_1 = similarity(x,l^{(1)})\)</span>,</li><li><span class="math inline">\(f_2 = similarity(x,l^{(2)})\)</span>,</li><li><span class="math inline">\(f_3 = similarity(x,l^3)\)</span>,</li><li>and so on.</li></ul><p>This gives us a &quot;feature vector,&quot; <span class="math inline">\(f^{(i)}\)</span> of all our features for example <span class="math inline">\(x^{(i)}\)</span>. We may also set <span class="math inline">\(f_0 = 1\)</span> to correspond with <span class="math inline">\(\Theta_0\)</span>. Thus given training example <span class="math inline">\(x^{(i)}\)</span>: <span class="math display">\[ x^{(i)} \rightarrow \begin{bmatrix} f_1^{(i)} = similarity(x^{(i)}, l^{(1)}) \newline f_2^{(i)} = similarity(x^{(i)}, l^{(2)}) \newline \dots \newline f_m^{(i)} = similarity(x^{(i)}, l^{(m)}) \newline \end{bmatrix} \]</span></p><p>Now to get the parameters <span class="math inline">\(\Theta\)</span> we can use the SVM minimization algorithm but with <span class="math inline">\(f^{(i)}\)</span> substituted in for <span class="math inline">\(x^{(i)}\)</span>: <span class="math display">\[ \large min_\Theta C \sum_{i=1}^m y^{(i)}\text{cost}_1(\Theta^Tf^{(i)}) + (1 - y^{(i)})\text{cost}_0(\theta^Tf^{(i)}) + \dfrac{1}{2}\sum_{j=1}^n \Theta^2_j \]</span></p><p>Using kernels to generate <span class="math inline">\(f^{(i)}\)</span> is not exclusive to SVMs and may also be applied to logistic regression. However, because of computational optimizations on SVMs, kernels combined with SVMs is much faster than with other algorithms, so kernels are almost always found combined only with SVMs.</p><p><strong>Choosing SVM Parameters</strong></p><p>Choosing <span class="math inline">\(C\)</span> (recall that <span class="math inline">\(C = \dfrac{1}{\lambda}\)</span>) * If <span class="math inline">\(C\)</span> is large, then we get higher variance/lower bias * If <span class="math inline">\(C\)</span> is small, then we get lower variance/higher bias</p><p>The other parameter we must choose is <span class="math inline">\(\sigma^2\)</span> from the Gaussian Kernel function:</p><ul><li>With a large <span class="math inline">\(\sigma^2\)</span>, the features <span class="math inline">\(f_i\)</span> vary more smoothly, causing higher bias and lower variance.</li><li>With a small <span class="math inline">\(\sigma^2\)</span>, the features <span class="math inline">\(f_i\)</span> vary less smoothly, causing lower bias and higher variance.</li></ul><h2><span id="using-an-svm">Using An SVM</span></h2><p>There are lots of good SVM libraries already written. A. Ng often uses 'liblinear' and 'libsvm'. In practical application, you should use one of these libraries rather than rewrite the functions.</p><p>In practical application, the choices you do need to make are:</p><ul><li>Choice of parameter C</li><li>Choice of kernel (similarity function)<ul><li>No kernel (&quot;linear&quot; kernel) -- gives standard linear classifier</li><li>Choose when <span class="math inline">\(n\)</span> is large and when <span class="math inline">\(m\)</span> is small</li><li>Gaussian Kernel (above) -- need to choose <span class="math inline">\(\sigma^2\)</span></li><li>Choose when <span class="math inline">\(n\)</span> is small and <span class="math inline">\(m\)</span> is large</li></ul></li></ul><p>The library may ask you to provide the kernel function.</p><p>Note: do perform <strong>feature scaling</strong> before using the Gaussian Kernel.</p><p>Note: not all similarity functions are valid kernels. They must satisfy &quot;Mercer's Theorem,&quot; which guarantees that the SVM package's optimizations run correctly and do not diverge.</p><p>You want to train <span class="math inline">\(C\)</span> and the parameters for the kernel function using the <strong>training</strong> and <strong>cross-validation</strong> datasets.</p><p><strong>Multi-class Classification</strong></p><p>Many SVM libraries have multi-class classification built-in.</p><p>You can use the one-vs-all method just like we did for logistic regression, where <span class="math inline">\(y \in {1,2,3,\dots,K}\)</span> with <span class="math inline">\(\Theta^{(1)}, \Theta^{(2)}, \dots,\Theta{(K)}\)</span>. We pick class <span class="math inline">\(i\)</span> with the largest <span class="math inline">\((\Theta^{(i)})^Tx\)</span>.</p><p><strong>Logistic Regression vs. SVMs</strong></p><ul><li>If <span class="math inline">\(n\)</span> is large (relative to <span class="math inline">\(m\)</span>), then use logistic regression, or SVM without a kernel (the &quot;linear kernel&quot;)</li><li>If <span class="math inline">\(n\)</span> is small and <span class="math inline">\(m\)</span> is intermediate, then use SVM with a Gaussian Kernel</li><li>If <span class="math inline">\(n\)</span> is small and <span class="math inline">\(m\)</span> is large, then manually create/add more features, then use logistic regression or SVM without a kernel.</li></ul><p>In the first case, we don't have enough examples to need a complicated polynomial hypothesis. In the second example, we have enough examples that we may need a complex non-linear hypothesis. In the last case, we want to increase our features so that logistic regression becomes applicable.</p><p>Note: a neural network is likely to work well for any of these situations, but may be <strong>slower</strong> to train.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Machine Learning System Design</title>
      <link href="/2016/02/29/Machine%20Learning%20System%20Design/"/>
      <url>/2016/02/29/Machine%20Learning%20System%20Design/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#prioritizing-what-to-work-on">Prioritizing What to Work On</a></li><li><a href="#error-analysis">Error Analysis</a></li><li><a href="#error-metrics-for-skewed-classes">Error Metrics for Skewed Classes</a></li><li><a href="#trading-off-precision-and-recall">Trading Off Precision and Recall</a></li><li><a href="#data-for-machine-learning">Data for Machine Learning</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="prioritizing-what-to-work-on">Prioritizing What to Work On</span></h2><p>Different ways we can approach a machine learning problem:</p><ul><li>Collect lots of data (for example &quot;honeypot&quot; project but doesn't always work)</li><li>Develop sophisticated features (for example: using email header data in spam emails)</li><li>Develop algorithms to process your input in different ways (recognizing misspellings in spam).</li></ul><p>It is difficult to tell which of the options will be helpful. Error Analysis</p><h2><span id="error-analysis">Error Analysis</span></h2><p>The recommended approach to solving machine learning problems is:</p><ul><li>Start with a simple algorithm, implement it quickly, and test it early.</li><li>Plot learning curves to decide if more data, more features, etc. will help</li><li>Error analysis: manually examine the errors on examples in the cross validation set and try to spot a trend.</li></ul><p>It's important to get error results as a single, numerical value. Otherwise it is difficult to assess your algorithm's performance. You may need to process your input before it is useful. For example, if your input is a set of words, you may want to treat the same word with different forms (fail/failing/failed) as one word, so must use &quot;stemming software&quot; to recognize them all as one.</p><h2><span id="error-metrics-for-skewed-classes">Error Metrics for Skewed Classes</span></h2><p>It is sometimes difficult to tell whether a reduction in error is actually an improvement of the algorithm.</p><p>For example: In predicting a cancer diagnoses where 0.5% of the examples have cancer, we find our learning algorithm has a 1% error. However, if we were to simply classify every single example as a 0, then our error would reduce to 0.5% even though we did not improve the algorithm.</p><p>This usually happens with skewed(倾斜) classes; that is, when our class is very rare in the entire data set.</p><p>Or to say it another way, when we have lot more examples from one class than from the other class.</p><p>For this we can use <strong>Precision/Recall</strong>.</p><p>Predicted: 1, Actual: 1 --- True positive Predicted: 0, Actual: 0 --- True negative Predicted: 0, Actual, 1 --- False negative Predicted: 1, Actual: 0 --- False positive</p><table><colgroup><col style="width: 55%"><col style="width: 44%"></colgroup><thead><tr class="header"><th style="text-align: center;">table</th><th style="text-align: center;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">Predicted: 1, Actual: 1 --- True positive</td><td style="text-align: center;">Predicted: 1, Actual: 0 --- False positive</td></tr><tr class="even"><td style="text-align: center;">Predicted: 0, Actual, 1 --- False negative</td><td style="text-align: center;">Predicted: 0, Actual: 0 --- True negative</td></tr></tbody></table><p><strong>Precision</strong> : of all patients we predicted where y=1, what fraction actually has cancer?</p><p><span class="math display">\[\frac{True\ Positives}{Total\ number\ of\ predicted\ positives}=\frac{True\ Positives}{True\ Positives + False\ positives}\]</span></p><p><strong>Recall</strong> : Of all the patients that actually have cancer, what fraction did we correctly detect as having cancer?</p><p><span class="math display">\[\frac{True\ Positives}{Number\ of\ actual\ positives}=\frac{True\ Positives}{True\ Positives + False\ negatives}\]</span></p><p>These two metrics give us a better sense of how our classifier is doing. We want <strong>both</strong> precision and recall to be <strong>high</strong>.</p><p>In the example at the beginning of the section, if we classify all patients as 0, then our recall will be <span class="math inline">\(\frac{0}{0+f}=0\)</span>, so despite having a lower error percentage, we can quickly see it has worse <strong>recall</strong>.</p><p>Note 1: if an algorithm predicts only negatives like it does in one of exercises, the precision is not defined, it is impossible to divide by 0. F1 score will not be defined too.</p><p>Note 2: a manual calculation of precision and other functions is a error prone process. it is very easy though to create an Excel file for this. Put into it a table 2*2 for all necessary input values, label them like &quot;TruePositives&quot;, &quot;FalsePositives&quot;, and on other cells of Excel add formulas like =SUM(TruePositive, FalsePositive, TrueNegative, FalseNegative), label this one AllExamples. Then on another cell label Accuracy and a formula: =SUM(TruePositive,TrueNegative)/AllExamples. The same with others. After 10 minutes you will have a spreadsheet for all examples and questions.</p><h2><span id="trading-off-precision-and-recall">Trading Off Precision and Recall</span></h2><p>We might want a confident prediction of two classes using logistic regression. One way is to increase our threshold:</p><p><span class="math display">\[Predict\ 1\ if:\ h_θ(x)≥0.7\]</span> <span class="math display">\[Predict\ 0\ if:\ h_θ(x)&lt;0.7\]</span></p><p>This way, we only predict cancer if the patient has a 70% chance.</p><p>Doing this, we will have <strong>higher precision</strong> but <strong>lower recall</strong> (refer to the definitions in the previous section).</p><p>In the opposite example, we can lower our threshold:</p><p><span class="math display">\[Predict\ 1\ if:\ h_θ(x)≥0.3\]</span> <span class="math display">\[Predict\ 0\ if:\ h_θ(x)&lt;0.3\]</span></p><p>That way, we get a very safe prediction. This will cause <strong>higher recall</strong> but <strong>lower precision</strong>.</p><ul><li>The greater the threshold, the greater the precision and the lower the recall.</li><li>The lower the threshold, the greater the recall and the lower the precision.</li></ul><p>In order to turn these two metrics into one single number, we can take the <span class="math inline">\(F\)</span> value.</p><p>One way is to take the <strong>average</strong>: <span class="math display">\[\frac{P+R}{2}\]</span></p><p>This does not work well. If we predict all <span class="math inline">\(y=0\)</span> then that will bring the average up despite having 0 recall. If we predict all examples as <span class="math inline">\(y=1\)</span>, then the very high recall will bring up the average despite having 0 precision.</p><p>A better way is to compute the <span class="math inline">\(F\ Score\)</span> (or <strong>F1 score</strong>):</p><p><span class="math display">\[F\ Score=2\frac{PR}{P+R}\]</span></p><p>In order for the <span class="math inline">\(F\ Score\)</span> to be large, both <strong>precision</strong> and <strong>recall</strong> must be <strong>large</strong>.</p><p>We want to train precision and recall on the <strong>cross validation set</strong> so as not to bias our test set.</p><h2><span id="data-for-machine-learning">Data for Machine Learning</span></h2><p>How much data should we train on?</p><p>In certain cases, an &quot;inferior(差的) algorithm,&quot; if given enough data, can outperform(胜过) a superior algorithm with less data.</p><p>We must choose our features to have <strong>enough</strong> information. A useful test is: Given input x, would a human expert be able to confidently predict y?</p><p><strong>Rationale(原理) for large data</strong>: if we have a <strong>low bias</strong> algorithm (many features or hidden units making a very complex function), then the larger the training set we use, the less we will have overfitting (and the more accurate the algorithm will be on the test set).</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> F1 </tag>
            
            <tag> Recall </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>应用机器学习的一些建议</title>
      <link href="/2016/02/27/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/"/>
      <url>/2016/02/27/%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BB%BA%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#deciding-what-to-try-next">Deciding What to Try Next</a></li><li><a href="#evaluating-a-hypothesis">Evaluating a Hypothesis</a></li><li><a href="#the-test-set-error">The test set error</a></li><li><a href="#model-selection-and-trainvalidationtest-sets">Model Selection and Train/Validation/Test Sets</a></li><li><a href="#diagnosing-bias-vs-variance">Diagnosing Bias vs. Variance</a></li><li><a href="#regularization-and-biasvariance">Regularization and Bias/Variance</a></li><li><a href="#learning-curves">Learning Curves</a></li><li><a href="#deciding-what-to-do-next-revisited">Deciding What to Do Next Revisited</a><ul><li><a href="#diagnosing-neural-networks">Diagnosing Neural Networks</a></li></ul></li><li><a href="#model-selection">Model Selection:</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="deciding-what-to-try-next">Deciding What to Try Next</span></h2><p>Errors in your predictions can be troubleshooted by: * Getting more training examples * Trying smaller sets of features * Trying additional features * Trying polynomial features * Increasing or decreasing <span class="math inline">\(\lambda\)</span></p><p>Don't just pick one of these avenues at random. We'll explore diagnostic techniques for choosing one of the above solutions in the following sections.</p><h2><span id="evaluating-a-hypothesis">Evaluating a Hypothesis</span></h2><p>A hypothesis may have low error for the training examples but still be inaccurate (because of overfitting).</p><p>With a given dataset of training examples, we can split up the data into two sets: a training set and a test set.</p><p>The new procedure using these two sets is then: 1. Learn <span class="math inline">\(\Theta\)</span> and minimize <span class="math inline">\(J_{train}(\Theta)\)</span> using the training set 2. Compute the test set error <span class="math inline">\(J_{test}(\Theta)\)</span></p><h2><span id="the-test-set-error">The test set error</span></h2><p>For linear regression: <span class="math display">\[J_{test}(\Theta) = \dfrac{1}{2m_{test}} \sum_{i=1}^{m_{test}}(h_\Theta(x^{(i)}_{test}) - y^{(i)}_{test})^2\]</span> For classification ~ Misclassification error (aka 0/1 misclassification error): <span class="math display">\[err(h_\Theta(x),y) = \begin{matrix} 1 &amp; \mbox{if } h_\Theta(x) \geq 0.5\ and\ y = 0\ or\ h_\Theta(x) &lt; 0.5\ and\ y = 1\newline 0 &amp; \mbox otherwise \end{matrix} \]</span> This gives us a binary 0 or 1 error result based on a misclassification.</p><p>The average test error for the test set is <span class="math display">\[ \large \text{Test Error} = \dfrac{1}{m_{test}} \sum^{m_{test}}_{i=1} err(h_\Theta(x^{(i)}_{test}), y^{(i)}_{test}) \]</span></p><p>This gives us the proportion(比例) of the test data that was misclassified.</p><h2><span id="model-selection-and-trainvalidationtest-sets">Model Selection and Train/Validation/Test Sets</span></h2><p>Just because a learning algorithm fits a training set well, that does not mean it is a good hypothesis.</p><p>The error of your hypothesis as measured on the data set with which you trained the parameters will be lower than any other data set.</p><p>In order to choose the model of your hypothesis, you can test each degree of polynomial and look at the error result.</p><p><strong>Without the Validation Set</strong> 1. Optimize the parameters in <span class="math inline">\(\Theta\)</span> using the training set for each polynomial degree. 2. Find the polynomial degree <span class="math inline">\(d\)</span> with the least error using the test set. 3. Estimate the generalization error also using the test set with <span class="math inline">\(J_{test}(\Theta^{(d)})\)</span>, (d = theta from polynomial with lower error);</p><p>In this case, we have trained one variable, <span class="math inline">\(d\)</span>, or the degree of the polynomial, using the test set. This will cause our error value to be greater for any other set of data.</p><p>To solve this, we can introduce a third set, the <strong>Cross Validation Set</strong>, to serve as an intermediate set that we can train <span class="math inline">\(d\)</span> with. Then our test set will give us an accurate, non-optimistic error.</p><p>One example way to break down our dataset into the three sets is: * Training set: 60% * Cross validation set: 20% * Test set: 20%</p><p>We can now calculate three separate error values for the three different sets.</p><p><strong>With the Validation Set</strong> 1. Optimize the parameters in <span class="math inline">\(\Theta\)</span> using the training set for each polynomial degree. 2. Find the polynomial degree <span class="math inline">\(d\)</span> with the least error using the cross validation set. 3. Estimate the generalization error using the test set with <span class="math inline">\(J_{test}(\Theta^{(d)})\)</span>, (d = theta from polynomial with lower error);</p><p>This way, the degree of the polynomial <span class="math inline">\(d\)</span> has not been trained using the test set.</p><h2><span id="diagnosing-bias-vs-variance">Diagnosing Bias vs. Variance</span></h2><p>In this section we examine the relationship between the degree of the polynomial <span class="math inline">\(d\)</span> and the underfitting or overfitting of our hypothesis.</p><ul><li>We need to distinguish whether <strong>bias</strong>(偏离) or <strong>variance</strong>(方差) is the problem contributing to bad predictions.</li><li><strong>High bias</strong> is <strong>underfitting</strong> and <strong>high variance</strong> is <strong>overfitting</strong>. We need to find a golden mean between these two.</li></ul><p>The training error will tend to <strong>decrease</strong> as we increase the degree <span class="math inline">\(d\)</span> of the polynomial.</p><p>At the same time, the cross validation error will tend to <strong>decrease</strong> as we increase <span class="math inline">\(d\)</span> up to a point, and then it will <strong>increase</strong> as <span class="math inline">\(d\)</span> is increased, forming a convex curve.</p><ul><li>High bias (underfitting): both <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be high. Also, <span class="math inline">\(J_{CV}(\Theta) \approx J_{train}(\Theta)\)</span>.</li><li>High variance (overfitting): <span class="math inline">\(J_{train}(\Theta)\)</span> will be low and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be much greater than <span class="math inline">\(J_{train}(\Theta)\)</span>.</li></ul><p>The is represented in the figure below:</p><p><img src="/images/1456537039223.png"></p><h2><span id="regularization-and-biasvariance">Regularization and Bias/Variance</span></h2><p>Instead of looking at the degree <span class="math inline">\(d\)</span> contributing to bias/variance, now we will look at the regularization parameter <span class="math inline">\(\lambda\)</span>.</p><ul><li>Large <span class="math inline">\(\lambda\)</span>: High bias (underfitting)</li><li>Intermediate <span class="math inline">\(\lambda\)</span>: just right</li><li>Small <span class="math inline">\(\lambda\)</span>: High variance (overfitting)</li></ul><p>A large lambda heavily penalizes all the <span class="math inline">\(\Theta\)</span> parameters, which greatly simplifies the line of our resulting function, so causes underfitting.</p><p>The relationship of <span class="math inline">\(\lambda\)</span> to the training set and the variance set is as follows:</p><ul><li>Low <span class="math inline">\(\lambda\)</span>: <span class="math inline">\(J_{train}(\Theta)\)</span> is low and <span class="math inline">\(J_{CV}(\Theta)\)</span> is high (<strong>high variance/overfitting</strong>).</li><li>Intermediate <span class="math inline">\(\lambda\)</span>: <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> are somewhat low and <span class="math inline">\(J_{train}(\Theta) \approx J_{CV}(\Theta)\)</span>.</li><li>Large <span class="math inline">\(\lambda\)</span>: both <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be high (<strong>underfitting/high bias</strong>)</li></ul><p>The figure below illustrates the relationship between lambda and the hypothesis:</p><p><img src="/images/1456537437295.png"></p><p>In order to choose the model and the regularization <span class="math inline">\(\lambda\)</span>, we need: 1. Create a list of lambda (i.e. <span class="math inline">\(\lambda \in \lbrace0, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32, 0.64, 1.28, 2.56, 5.12, 10.24\rbrace\)</span>); 2. Select a lambda to compute; 3. Create a model set like degree of the polynomial or others; 4. Select a model to learn <span class="math inline">\(\Theta\)</span>; 5. Learn the parameter <span class="math inline">\(\Theta\)</span> for the model selected, using <span class="math inline">\(J_{train}(\Theta)\)</span> with <span class="math inline">\(\lambda\)</span> selected (this will learn <span class="math inline">\(\Theta\)</span> for the next step); 6. Compute the train error using the learned <span class="math inline">\(\Theta\)</span> (computed with <span class="math inline">\(\lambda\)</span> ) on the <span class="math inline">\(J_{train}(\Theta)\)</span> without regularization or <span class="math inline">\(\lambda\)</span> = 0; 7. Compute the cross validation error using the learned <span class="math inline">\(\Theta\)</span> (computed with <span class="math inline">\(\lambda\)</span>) on the <span class="math inline">\(J_{CV}(\Theta)\)</span> without regularization or <span class="math inline">\(\lambda\)</span> = 0; 8. Do this for the entire model set and lambdas, then select the best combo that produces the lowest error on the cross validation set; 9. Now if you need visualize to help you understand your decision, you can plot to the figure like above with: (<span class="math inline">\(\lambda\)</span> x Cost <span class="math inline">\(J_{train}(\Theta)\)</span>) and (<span class="math inline">\(\lambda\)</span> x Cost <span class="math inline">\(J_{CV}(\Theta)\)</span>); 10. Now using the best combo <span class="math inline">\(\Theta\)</span> and <span class="math inline">\(\lambda\)</span>, apply it on <span class="math inline">\(J_{test}(\Theta)\)</span> to see if it have a good generalization of the problem. 11. To help decide the best polynomial degree and <span class="math inline">\(\lambda\)</span> to use, we can diagnose(诊断) with the learning curves, that is the next subject.</p><h2><span id="learning-curves">Learning Curves</span></h2><p>Training 3 examples will easily have 0 errors because we can always find a quadratic curve that exactly touches 3 points.</p><ul><li>As the training set gets larger, the error for a quadratic function increases.</li><li>The error value will plateau out after a certain <span class="math inline">\(m\)</span>, or training set size.</li></ul><p><strong>With high bias</strong></p><ul><li><strong>Low training set size</strong>: causes <span class="math inline">\(J_{train}(\Theta)\)</span> to be low and <span class="math inline">\(J_{CV}(\Theta)\)</span> to be high.</li><li><strong>Large training set size</strong>: causes both <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> to be high with <span class="math inline">\(J_{train}(\Theta) \approx J_{CV}(\Theta)\)</span>.</li></ul><p>If a learning algorithm is suffering from <strong>high bias</strong>, getting more training data will <strong>not (by itself) help much</strong>.</p><p>For high variance, we have the following relationships in terms of the training set size: <strong>With high variance</strong></p><ul><li><strong>Low training set size</strong>: <span class="math inline">\(J_{train}(\Theta)\)</span> will be low and <span class="math inline">\(J_{CV}(\Theta)\)</span> will be high.</li><li><strong>Large training set size</strong>: <span class="math inline">\(J_{train}(\Theta)\)</span> increases with training set size and <span class="math inline">\(J_{CV}(\Theta)\)</span> continues to decrease without leveling off. Also, <span class="math inline">\(J_{train}(\Theta) &lt; J_{CV}(\Theta)\)</span> but the difference between them remains significant.</li></ul><p>If a learning algorithm is suffering from <strong>high variance</strong>, getting more training data is <strong>likely to help</strong>.</p><p><img src="/images/1456538443823.png"> <img src="/images/1456538447332.png"></p><h2><span id="deciding-what-to-do-next-revisited">Deciding What to Do Next Revisited</span></h2><p>Our decision process can be broken down as follows:</p><ul><li>Getting more training examples<ul><li>Fixes high variance</li></ul></li><li>Trying smaller sets of features<ul><li>Fixes high variance</li></ul></li><li>Adding features<ul><li>Fixes high bias</li></ul></li><li>Adding polynomial features<ul><li>Fixes high bias</li></ul></li><li>Decreasing <span class="math inline">\(\lambda\)</span><ul><li>Fixes high bias</li></ul></li><li>Increasing <span class="math inline">\(\lambda\)</span><ul><li>Fixes high variance</li></ul></li></ul><h3><span id="diagnosing-neural-networks">Diagnosing Neural Networks</span></h3><ul><li>A neural network with <strong>fewer</strong> parameters is prone(倾向于) to <strong>underfitting</strong>. It is also computationally cheaper.</li><li>A <strong>large</strong> neural network with more parameters is prone to <strong>overfitting</strong>. It is also computationally expensive. In this case you can use regularization (increase <span class="math inline">\(\lambda\)</span>) to address the overfitting.</li></ul><p>Using a <strong>single hidden layer</strong> is a good <strong>starting default</strong>. You can train your neural network on a number of hidden layers using your cross validation set.</p><h2><span id="model-selection">Model Selection:</span></h2><ul><li>Choosing M the order of polynomials.</li><li>How can we tell which parameters Θ to leave in the model (known as &quot;model selection&quot;)?</li></ul><p>There are several ways to solve this problem:</p><ol type="1"><li>Get more data (very difficult).</li><li>Choose the model which best fits the data without overfitting (very difficult).</li><li>Reduce the opportunity for overfitting through regularization.</li></ol><p><strong>Bias: approximation(近似值) error (Difference between expected value and optimal value)</strong> * High Bias = UnderFitting (BU) * <span class="math inline">\(J_{train}(\Theta)\)</span> and <span class="math inline">\(J_{CV}(\Theta)\)</span> both will be high and <span class="math inline">\(J_{train}(\Theta) \approx J_{CV}(\Theta)\)</span></p><p><strong>Variance: estimation(估计) error due to finite(有限的) data</strong> * High Variance = OverFitting (VO) * <span class="math inline">\(J_{train}(\Theta)\)</span> is low and <span class="math inline">\(J_{CV}(\Theta) \gg J_{train}(\Theta)\)</span></p><p><strong>Intuition for the bias-variance trade-off:</strong></p><ul><li>Complex model =&gt; sensitive to data =&gt; much affected by changes in X =&gt; high variance, low bias.</li><li>Simple model =&gt; more rigid =&gt; does not change as much with changes in X =&gt; low variance, high bias.</li></ul><p>One of the most important goals in learning: finding a model that is just right in the bias-variance trade-off.</p><p><strong>Regularization Effects:</strong></p><ul><li>Small values of λ allow model to become finely tuned to noise leading to large variance =&gt; overfitting.</li><li>Large values of λ pull weight parameters to zero leading to large bias =&gt; underfitting.</li></ul><p><strong>Model Complexity Effects:</strong></p><ul><li>Lower-order polynomials (low model complexity) have high bias and low variance. In this case, the model fits poorly consistently.</li><li>Higher-order polynomials (high model complexity) fit the training data extremely well and the test data extremely poorly. These have low bias on the training data, but very high variance.</li></ul><p>In reality, we would want to choose a model somewhere in between, that can generalize well but also fits the data reasonably well.</p><p><strong>A typical rule of thumb when running diagnostics is:</strong></p><ul><li>More training examples fixes high variance but not high bias.</li><li>Fewer features fixes high variance but not high bias.</li><li>Additional features fixes high bias but not high variance.</li><li>The addition of polynomial and interaction features fixes high bias but not high variance.</li><li>When using gradient descent, decreasing lambda can fix high bias and increasing lambda can fix high variance (lambda is the regularization parameter).</li><li>When using neural networks, small neural networks are more prone to under-fitting and big neural networks are prone to over-fitting. Cross-validation of network size is a way to choose alternatives.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Bias </tag>
            
            <tag> Variance </tag>
            
            <tag> Overfitting </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>神经网络(Neural Network)(下)</title>
      <link href="/2016/02/22/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8B)/"/>
      <url>/2016/02/22/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8B)/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#cost-function">Cost Function</a></li><li><a href="#backpropagation-algorithm">Backpropagation Algorithm</a></li><li><a href="#backpropagation-intuition">Backpropagation Intuition</a></li><li><a href="#implementation-note-unrolling-parameters">Implementation Note: Unrolling Parameters</a></li><li><a href="#gradient-checking">Gradient Checking</a></li><li><a href="#putting-it-together">Putting it Together</a></li><li><a href="#nn-for-linear-systems">NN for linear systems</a><ul><li><a href="#introduction">Introduction</a></li><li><a href="#testing-your-linear-nn">Testing your linear NN</a></li></ul></li><li><a href="#reference">Reference</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="cost-function">Cost Function</span></h2><p>Let's first define a few variables that we will need to use: * <span class="math inline">\(L\)</span> = total number of layers in the network * <span class="math inline">\(s_l\)</span>= number of units (not counting bias unit) in layer <span class="math inline">\(l\)</span> * <span class="math inline">\(K\)</span> = number of output units/classes</p><p>Recall that in neural networks, we may have many output nodes. We denote <span class="math inline">\(h_Θ(x)_k\)</span> as being a hypothesis that results in the <span class="math inline">\(k^{th}\)</span> output.</p><p>Our cost function for neural networks is going to be a <strong>generalization</strong> of the one we used for logistic regression.</p><p>Recall that the cost function for regularized logistic regression was:</p><p><span class="math display">\[J(θ)=−\frac{1}{m}[∑^m_{i=1}y^{(i)}log(h_θ(x^{(i)}))+(1−y^{(i)})log(1−h_θ(x^{(i)}))]+\frac{λ}{2m}∑^n_{j=1}θ^2_j\]</span></p><p>For neural networks, it is going to be slightly more complicated:</p><p><span class="math inline">\(J(Θ)=−\frac{1}{m}[∑^m_{i=1}∑_{k=1}^Ky^{(i)}_klog((h_Θ(x^{(i)}))_k)+(1−y^{(i)}_k)log(1−(h_Θ(x^{(i)}))_k)]+\frac{λ}{2m}\sum_{l=1}^{L−1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1}(Θ^{(l)}_{j,i})^2\)</span></p><figure><img src="/images/1473765472300.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>We have added a few nested summations to account for our multiple output nodes. In the first part of the equation, between the square brackets, we have an additional nested summation that loops through the number of output nodes.</p><p>In the regularization part, after the square brackets, we must account for multiple theta matrices. <strong>The number of columns in our current theta matrix is equal to the number of nodes in our current layer (including the bias unit)</strong>. <strong>The number of rows in our current theta matrix is equal to the number of nodes in the next layer (excluding the bias unit)</strong>. As before with logistic regression, we square every term.</p><p>Note: * the double sum simply adds up the logistic regression costs calculated for each cell in the output layer; * the triple sum simply adds up the squares of all the individual Θs in the entire network. * the i in the triple sum does <strong>not</strong> refer to training example i</p><h2><span id="backpropagation-algorithm">Backpropagation Algorithm</span></h2><p>&quot;Backpropagation&quot; is neural-network terminology(术语) for minimizing our cost function, just like what we were doing with gradient descent in logistic and linear regression.</p><p>Our goal is to compute: <span class="math display">\[min_ΘJ(Θ)\]</span></p><p>That is, we want to minimize our cost function <span class="math inline">\(J\)</span> using an optimal set of parameters in theta.</p><p>In this section we'll look at the equations we use to compute the partial derivative of <span class="math inline">\(J(Θ)\)</span>: <span class="math display">\[\frac{∂}{∂Θ^{(l)}_{i,j}}J(Θ)\]</span></p><p>In backpropagation we're going to compute for every node: <span class="math inline">\(δ^{(l)}_j\)</span> = &quot;<strong>error</strong>&quot; of node <span class="math inline">\(j\)</span> in layer <span class="math inline">\(l\)</span></p><p>Recall that <span class="math inline">\(a^{(l)}_j\)</span> is activation node <span class="math inline">\(j\)</span> in layer <span class="math inline">\(l\)</span>.</p><p>For the last layer, we can compute the vector of delta values with: <span class="math display">\[δ^{(L)}=a^{(L)}−y\]</span></p><figure><img src="/images/1473765394042.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>Where <span class="math inline">\(L\)</span> is our total number of layers and <span class="math inline">\(a^{(L)}\)</span> is the vector of activation units for the last layer. So our &quot;<strong>error values</strong>&quot; for the last layer are simply the differences of our actual results in the last layer and the correct outputs in <span class="math inline">\(y\)</span>.</p><p>To get the delta values of the layers before the last layer, we can use an equation that steps us back from right to left: <span class="math display">\[δ^{(l)}=((Θ^{(l)})^Tδ^{(l+1)}) .∗ g′(z^{(l)})\]</span></p><figure><img src="/images/1473765325959.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>The delta values of layer <span class="math inline">\(l\)</span> are calculated by multiplying the delta values in the next layer with the theta matrix of layer <span class="math inline">\(l\)</span>. We then element-wise multiply that with a function called <span class="math inline">\(g&#39;\)</span>, or <em>g-prime</em>, which is the derivative of the activation function <span class="math inline">\(g\)</span> evaluated with the input values given by <span class="math inline">\(z^{(l)}\)</span>.</p><p>The <em>g-prime</em> derivative terms can also be written out as: <span class="math display">\[g′(z^{(l)})=a^{(l)} .∗ (1−a^{(l)})\]</span></p><p>This can be shown and proved in calculus.</p><p><span class="math display">\[g(z)=\frac{1}{1+e^{−z}}\]</span> <span class="math display">\[\begin{array}{lcr}\frac{∂g(z)}{∂z}=−(\frac{1}{1+e^{−z}})^2\frac{∂}{∂z}(1+e^{−z}) \\\ \ \ \ \ \ \ \ \ =−(\frac{1}{1+e^{−z}})^2e^{−z}(−1) \\\ \ \ \ \ \ \ \ \ =(\frac{1}{1+e^{−z}})(\frac{1}{1+e^{−z}})(e^{−z}) \\\ \ \ \ \ \ \ \ \ =(\frac{1}{1+e^{−z}})(\frac{e^{−z}}{1+e^{−z}}) \\\ \ \ \ \ \ \ \ \ =g(z)(1−g(z))\end{array}\]</span></p><p>The full backpropagation equation for the inner nodes is then: <span class="math display">\[δ^{(l)}=((Θ^{(l)})^Tδ^{(l+1)}) .∗ a^{(l)} .∗ (1−a^{(l)})\]</span></p><p>We can compute our partial derivative terms by multiplying our activation values and our error values for each training example t: <span class="math display">\[\frac{∂J(Θ)}{∂Θ^{(l)}_{i,j}}=\frac{1}{m}\sum^m_{t=1}a^{(t)(l)}_jδ^{(t)(l+1)}_i\]</span></p><p><img src="/images/1473766072648.png" alt="Alt text"> <span class="math display">\[\frac{\partial}{\partial W^{(l)}_{ij}} J(W,b;x,y)= \frac{\partial}{\partial z^{(l+1)}_{i}}J(W,b;x,y) \cdot \frac{\partial z^{(l+1)}_i}{\partial W^{(l)}_{ij}} = a^{(l)}_j\delta^{(l+1)}_i\]</span></p><p>This however <strong>ignores regularization</strong>, which we'll deal with later.</p><p>Note: <span class="math inline">\(δ^{l+1}\)</span> and <span class="math inline">\(a^{l+1}\)</span> are vectors with <span class="math inline">\(s_{l+1}\)</span> elements. Similarly, <span class="math inline">\(a^{(l)}\)</span> is a vector with <span class="math inline">\(s_l\)</span> elements. Multiplying them produces a matrix that is <span class="math inline">\(s_{l+1}\)</span> by <span class="math inline">\(s_l\)</span> which is the <strong>same dimension</strong> as <span class="math inline">\(Θ^{(l)}\)</span>. That is, the process produces a gradient term for every element in <span class="math inline">\(Θ^{(l)}\)</span>. (Actually, <span class="math inline">\(Θ^{(l)}\)</span> has <span class="math inline">\(s_{l+1} + 1\)</span> rows, so the dimensionality is not exactly the same).</p><p>We can now take all these equations and put them together into a backpropagation algorithm:</p><figure><img src="/images/1456125275491.png" alt="Backpropagation Algorithm"><figcaption>Backpropagation Algorithm</figcaption></figure><p><strong>Backpropagation Algorithm</strong></p><ul><li>Given training set {(<span class="math inline">\(x^{(1)}\)</span>, <span class="math inline">\(y^{(1)}\)</span>)⋯(<span class="math inline">\(x^{(m)}\)</span>, <span class="math inline">\(y^{(m)}\)</span>)}</li><li>Set <span class="math inline">\(Δ^{(l)}_{i,j} := 0\)</span> for all (<span class="math inline">\(l\)</span>, <span class="math inline">\(i\)</span>, <span class="math inline">\(j\)</span>)</li><li>For training example <span class="math inline">\(t=1\)</span> to <span class="math inline">\(m\)</span>:<ul><li>Set <span class="math inline">\(a^{(1)} := x^{(t)}\)</span></li><li>Perform <strong>forward propagation</strong> to compute <span class="math inline">\(a^{(l)}\)</span> for <span class="math inline">\(l=2,3,…,L\)</span></li><li>Using <span class="math inline">\(y^{(t)}\)</span>, compute <span class="math inline">\(δ^{(L)}=a^{(L)}−y^{(t)}\)</span></li><li>Compute <span class="math inline">\(δ^{(L−1)}\)</span>,<span class="math inline">\(δ^{(L−2)}\)</span>,…,<span class="math inline">\(δ^{(2)}\)</span> using <span class="math inline">\(δ^{(l)}=((Θ^{(l)})^Tδ^{(l+1)}) .∗ a^{(l)} .∗ (1−a^{(l)})\)</span></li><li><span class="math inline">\(Δ^{(l)}_{i,j} :=Δ^{(l)}_{i,j}+a^{(l)}_jδ^{(l+1)}_i\)</span> or with vectorization, <span class="math inline">\(Δ^{(l)} :=Δ^{(l)}+δ^{(l+1)}(a^{(l)})^T\)</span></li></ul></li><li><span class="math inline">\(D^{(l)}_{i,j} := \frac{1}{m}(Δ^{(l)}_{i,j}+λΘ^{(l)}_{i,j})\)</span> If <span class="math inline">\(j≠0\)</span></li><li><span class="math inline">\(D^{(l)}_{i,j} := \frac{1}{m}Δ^{(l)}_{i,j}\)</span> If <span class="math inline">\(j=0\)</span></li></ul><p>The capital-delta matrix is used as an &quot;<strong>accumulator</strong>&quot; to add up our values as we go along and eventually compute our partial derivative.</p><p>The actual proof is quite involved, but, the <span class="math inline">\(D^{(l)}_{i,j}\)</span> terms are the partial derivatives and the results we are looking for: <span class="math inline">\(D^{(l)}_{i,j} = \frac{∂J(Θ)}{∂Θ^{(l)}_{i,j}}\)</span>.</p><h2><span id="backpropagation-intuition">Backpropagation Intuition</span></h2><p>The cost function is: <span class="math inline">\(J(Θ)=−\frac{1}{m}[∑^m_{i=1}∑_{k=1}^Ky^{(i)}_klog((h_Θ(x^{(i)}))_k)+(1−y^{(i)}_k)log(1−(h_Θ(x^{(i)}))_k)]+\frac{λ}{2m}\sum_{l=1}^{L−1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1}(Θ^{(l)}_{j,i})^2\)</span></p><p>If we consider simple non-multiclass classification (k = 1) and disregard regularization, the cost is computed with: <span class="math display">\[cost(t)=y^{(t)}log(h_θ(x^{(t)}))+(1−y^{(t)})log(1−h_θ(x^{(t)}))\]</span></p><p>More intuitively you can think of that equation roughly as: <span class="math display">\[cost(t)≈(h_θ(x^{(t)})−y^{(t)})^2\]</span></p><p>Intuitively, <span class="math inline">\(δ^{(l)}_j\)</span> is the &quot;error&quot; for <span class="math inline">\(a^{(l)}_j\)</span> (unit <span class="math inline">\(j\)</span> in layer <span class="math inline">\(l\)</span>)</p><p>More formally, the delta values are actually the derivative of the cost function: <span class="math display">\[δ^{(l)}_j=\frac{∂}{∂z^{(l)}_j}cost(t)\]</span></p><p>Recall that our derivative is the slope of a line tangent to the cost function, so the steeper the slope the more incorrect we are.</p><p>Note: In lecture, sometimes <strong>i</strong> is used to <strong>index a training example</strong>. Sometimes it is used to <strong>index a unit in a layer</strong>. In the Back Propagation Algorithm described here, <strong>t</strong> is used to <strong>index a training example</strong> rather than overloading the use of i.</p><h2><span id="implementation-note-unrolling-parameters">Implementation Note: Unrolling Parameters</span></h2><p>With neural networks, we are working with sets of matrices: <span class="math inline">\(Θ_1\)</span>, <span class="math inline">\(Θ_2\)</span>, <span class="math inline">\(Θ_3\)</span>,… <span class="math inline">\(D_1\)</span>, <span class="math inline">\(D_2\)</span>, <span class="math inline">\(D_2\)</span>,…</p><p>In order to use optimizing functions such as &quot;<code>fminunc()</code>&quot;, we will want to &quot;<strong>unroll</strong>&quot; all the elements and put them into one long vector: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]</span><br><span class="line">deltaVector = [ D1(:); D2(:); D3(:) ]</span><br></pre></td></tr></table></figure></p><p>If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11, then we can get back our original matrices from the &quot;unrolled&quot; versions as follows: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Theta1 = <span class="built_in">reshape</span>(thetaVector(<span class="number">1</span>:<span class="number">110</span>),<span class="number">10</span>,<span class="number">11</span>)</span><br><span class="line">Theta2 = <span class="built_in">reshape</span>(thetaVector(<span class="number">111</span>:<span class="number">220</span>),<span class="number">10</span>,<span class="number">11</span>)</span><br><span class="line">Theta3 = <span class="built_in">reshape</span>(thetaVector(<span class="number">221</span>:<span class="number">231</span>),<span class="number">1</span>,<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><h2><span id="gradient-checking">Gradient Checking</span></h2><p>Gradient checking will assure that our backpropagation works as intended. We can approximate the derivative of our cost function with: <span class="math display">\[\frac{∂}{∂Θ}J(Θ) ≈ \frac{J(Θ+ϵ)−J(Θ−ϵ)}{2ϵ}\]</span></p><p>With multiple theta matrices, we can approximate the derivative with respect to <span class="math inline">\(Θ_j\)</span> as follows: <span class="math display">\[\frac{∂}{∂Θ_j}J(Θ) ≈ \frac{J(Θ_1,…,Θ_{j+ϵ},…,Θ_n)−J(Θ_1,…,Θ_{j−ϵ},…,Θ_n)}{2ϵ}\]</span></p><p>A good small value for <span class="math inline">\(ϵ\)</span> (epsilon), guarantees the math above to become true. If the value be much smaller, may we will end up with numerical problems. The professor Andrew usually uses the value <span class="math inline">\(ϵ=10^{−4}\)</span>.</p><p>We are only adding or subtracting epsilon to the <span class="math inline">\(Θ_j\)</span> matrix. In octave we can do it as follows: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">epsilon = <span class="number">1e-4</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n,</span><br><span class="line">  thetaPlus = theta;</span><br><span class="line">  thetaPlus(<span class="built_in">i</span>) += epsilon;</span><br><span class="line">  thetaMinus = theta;</span><br><span class="line">  thetaMinus(<span class="built_in">i</span>) -= epsilon;</span><br><span class="line">  gradApprox(<span class="built_in">i</span>) = (J(thetaPlus) - J(thetaMinus))/(<span class="number">2</span>*epsilon)</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure></p><p>We then want to check that <code>gradApprox</code> ≈ <code>deltaVector</code>.</p><p>Once you've verified <strong>once</strong> that your backpropagation algorithm is correct, then you don't need to compute gradApprox again. <strong>The code to compute gradApprox is very slow</strong>.</p><h2><span id="putting-it-together">Putting it Together</span></h2><p>First, <strong>pick a network architecture</strong>; choose the <strong>layout</strong> of your neural network, including how many hidden units in each layer and how many layers total. * Number of input units = dimension of features <span class="math inline">\(x^{(i)}\)</span> * Number of output units = number of classes * Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units) * Defaults: 1 hidden layer. If more than 1 hidden layer, then the same number of units in every hidden layer.</p><p><strong>Training a Neural Network</strong></p><ol type="1"><li>Randomly initialize the weights</li><li>Implement forward propagation to get <span class="math inline">\(h_θ(x^{(i)})\)</span></li><li>Implement the cost function</li><li>Implement backpropagation to compute partial derivatives</li><li>Use gradient checking to confirm that your backpropagation works. Then disable gradient checking.</li><li>Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta.</li></ol><p>When we perform forward and back propagation, we loop on every training example: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:m,</span><br><span class="line">   Perform forward propagation and backpropagation using example (x(<span class="built_in">i</span>),y(<span class="built_in">i</span>))</span><br><span class="line">   (Get activations a(l) and delta terms d(l) <span class="keyword">for</span> l = <span class="number">2</span>,...,L</span><br></pre></td></tr></table></figure></p><h2><span id="nn-for-linear-systems">NN for linear systems</span></h2><h3><span id="introduction">Introduction</span></h3><p>The NN we created for classification can easily be modified to have a linear output.</p><p>First solve the 4th programming exercise. You can create a new function script, nnCostFunctionLinear.m, with the following characteristics * There is only one output node, so you do not need the 'num_labels' parameter. * Since there is one linear output, you do not need to convert y into a logical matrix. * You still need a non-linear function in the hidden layer. * The non-linear function is often the <code>tanh()</code> function - it has an output range from -1 to +1, and its gradient is easily implemented. Let <span class="math inline">\(g(z)=tanh(z)\)</span>. * The gradient of tanh is <span class="math inline">\(g′(z)=1−g(z)^2\)</span>. Use this in backpropagation in place of the sigmoid gradient. * Use linear regression for the NN output (do not use a sigmoid function on the output layer). * Cost computation: Use the linear cost function for <span class="math inline">\(J\)</span> (from ex1 and ex5) for the unregularized portion. For the regularized portion, use the same method as ex4. * Where <code>reshape()</code> is used to form the Theta matrices, replace 'num_labels' with '1'.</p><p>You will also need to create a <code>predictLinear()</code> function, using the <code>tanh()</code> function in the hidden layer, and a linear output.</p><h3><span id="testing-your-linear-nn">Testing your linear NN</span></h3><p>Here is a test case for your <code>nnCostFunctionLinear()</code> <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% inputs</span></span><br><span class="line">nn_params = [<span class="number">31</span> <span class="number">16</span> <span class="number">15</span> <span class="number">-29</span> <span class="number">-13</span> <span class="number">-8</span> <span class="number">-7</span> <span class="number">13</span> <span class="number">54</span> <span class="number">-17</span> <span class="number">-11</span> <span class="number">-9</span> <span class="number">16</span>]'/ <span class="number">10</span>;</span><br><span class="line">il = <span class="number">1</span>;</span><br><span class="line">hl = <span class="number">4</span>;</span><br><span class="line">X = [<span class="number">1</span> ; <span class="number">2</span> ; <span class="number">3</span>];</span><br><span class="line">y = [<span class="number">1</span> ; <span class="number">4</span> ; <span class="number">9</span>];</span><br><span class="line">lambda = <span class="number">0.01</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% command</span></span><br><span class="line">[<span class="built_in">j</span> g] = nnCostFunctionLinear(nn_params, il, hl, X, y, lambda)</span><br><span class="line"></span><br><span class="line"><span class="comment">% results</span></span><br><span class="line"><span class="built_in">j</span> =  <span class="number">0.020815</span></span><br><span class="line">g =</span><br><span class="line">    <span class="number">-0.0131002</span></span><br><span class="line">    <span class="number">-0.0110085</span></span><br><span class="line">    <span class="number">-0.0070569</span></span><br><span class="line">     <span class="number">0.0189212</span></span><br><span class="line">    <span class="number">-0.0189639</span></span><br><span class="line">    <span class="number">-0.0192539</span></span><br><span class="line">    <span class="number">-0.0102291</span></span><br><span class="line">     <span class="number">0.0344732</span></span><br><span class="line">     <span class="number">0.0024947</span></span><br><span class="line">     <span class="number">0.0080624</span></span><br><span class="line">     <span class="number">0.0021964</span></span><br><span class="line">     <span class="number">0.0031675</span></span><br><span class="line">    <span class="number">-0.0064244</span></span><br></pre></td></tr></table></figure></p><p>Now create a script that uses the 'ex5data1.mat' from ex5, but without creating the polynomial terms. With 8 units in the hidden layer and MaxIter set to 200, you should be able to get a final cost value of 0.3 to 0.4. The results will vary a bit due to the random Theta initialization. If you plot the training set and the predicted values for the training set (using your <code>predictLinear()</code> function), you should have a good match.</p><h2><span id="reference">Reference</span></h2><ul><li><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">机器学习 Andrew Ng</a></li><li><a href="http://deeplearning.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">UFLDL教程</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Neural Network </tag>
            
            <tag> Dense </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>神经网络(Neural Network)(上)</title>
      <link href="/2016/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8A)/"/>
      <url>/2016/02/18/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(Neural%20Network)(%E4%B8%8A)/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#非线性假想函数">非线性假想函数</a></li><li><a href="#神经和大脑">神经和大脑</a></li><li><a href="#模型解释">模型解释</a><ul><li><a href="#vectorized-implementation">Vectorized implementation</a></li></ul></li><li><a href="#举例说明">举例说明</a><ul><li><a href="#x_1-and-x_2"><span class="math inline">\(x_1\)</span> AND <span class="math inline">\(x_2\)</span></a></li><li><a href="#nor-or-xnor">NOR、OR、XNOR</a></li></ul></li><li><a href="#multiclass-classification">Multiclass Classification</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="非线性假想函数">非线性假想函数</span></h2><p>对一个非常复杂的数据集进行线性回归是不明智的。假设你要构造一个包含很多非线性项的逻辑回归函数： <span class="math display">\[g(\theta_0 + \theta_1x^2_1 + \theta_2x_1x_2 + \theta_3x_1x_3 + \theta_4x^2_2 + \theta_5x_2x_3 + \theta_6x^2_3)\]</span></p><p>总共有6个参数。事实上 ，当多项式项数足够多时，那么可能能够得到一个分开正样本和负样本的分界线，当只有两项时，这种方法确实能得到不错的结果。因为你可以把 <span class="math inline">\(x_1\)</span> 和 <span class="math inline">\(x_2\)</span> 的所有组合都包含到多项式中。但是对于许多复杂的机器学习问题，涉及的项往往多于两项。我们之前已经讨论过房价预测的问题，假设现在要处理的是关于住房的分类问题而不是一个回归问题。假设你对一栋房子的多方面特点都有所了解，你想预测房子在未来半年内能被卖出去的概率，这是一个分类问题。我们可以想出很多特征，对于不同的房子有可能有上百个特征，对于这类问题，如果要包含所有的二次项，即使只包含二项式或多项式的计算，最终的多项式也会有很多。</p><p>包含所有 <span class="math inline">\(n\)</span> 个特征 <span class="math inline">\(r\)</span> 次项的多项式项的个数是：<span class="math inline">\(\frac{(n+r-1)!}{r!(n-1)!}\)</span></p><p>比如有100个特征，那么所有二次项的个数为 <span class="math inline">\(\frac{(100 + 2 - 1)!}{(2*(100 - 1)!)} = 5050\)</span></p><p>We can approximate the growth of the number of new features we get with all quadratic terms with <span class="math inline">\(O(n^2/2)\)</span>. And if you wanted to include all cubic terms in your hypothesis, the features would grow asymptotically at <span class="math inline">\(O(n^3)\)</span>. These are very steep growths, so as the number of our features increase, the number of quadratic or cubic features increase very rapidly and becomes quickly impractical.</p><p>神经网络提供了一种可行的方式来应用有许多特征的复杂的函数的学习。</p><h2><span id="神经和大脑">神经和大脑</span></h2><p>神经网络模型就是模仿我们大脑的学习过程。</p><p>我们的大脑只用一个学习算法学习所有不同的函数。科学家尝试切断连接耳朵与控制听觉的的神经并把光感应器官上和控制听觉的神经重新连接起来，结果控制听觉的神经学会了看(see)。</p><p>这叫神经可塑性(<a href="https://www.wikiwand.com/en/Neuroplasticity" target="_blank" rel="noopener">Neuroplasticity</a>)，并有许多例子证明它是正确的。</p><h2><span id="模型解释">模型解释</span></h2><p>Let's examine how we will represent a hypothesis function using neural networks.</p><p>At a very simple level, neurons are basically computational units that take input (dendrites树突) as electrical input (called &quot;spikes&quot;) that are channeled to outputs (axons轴突).</p><p>In our model, our dendrites are like the input features (x1⋯xn), and the output is the result of our hypothesis function.</p><p>In this model our <span class="math inline">\(x_0\)</span> input node is sometimes called the &quot;bias unit.&quot; It is always equal to 1.</p><p>In neural networks, we use the same logistic function as in classification: <span class="math inline">\(\frac{1}{1+e^{−θ^Tx}}\)</span>. In neural networks however we sometimes call it a sigmoid (logistic) activation function.</p><p>Our &quot;theta&quot; parameters are sometimes instead called &quot;weights&quot; in the neural networks model.</p><p>Visually, a simplistic representation looks like: <span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2\end{bmatrix}→[   ]→h_θ(x)\]</span></p><p>Our input nodes (layer 1) go into another node (layer 2), and are output as the hypothesis function.</p><p>The first layer is called the &quot;input layer&quot; and the final layer the &quot;output layer,&quot; which gives the final value computed on the hypothesis.</p><p>We can have intermediate layers of nodes between the input and output layers called the &quot;hidden layer.&quot; We label these intermediate or &quot;hidden&quot; layer nodes <span class="math inline">\(a^2_0⋯a^2_n\)</span> and call them &quot;activation units.&quot;</p><p><span class="math inline">\(a^{(j)}_i\)</span> = <strong>&quot;activation&quot; of unit i in layer j</strong> <span class="math inline">\(Θ^{(j)}\)</span> = <strong>matrix of weights controlling function mapping from layer j to layer j+1</strong></p><p>If we had one hidden layer, it would look visually something like:</p><p><span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2 \\x_3\end{bmatrix}→\begin{bmatrix}a_1^{(2)}  \\a_2^{(2)} \\a_3^{(2)} \end{bmatrix}→h_θ(x)\]</span></p><p>The values for each of the &quot;activation&quot; nodes is obtained as follows:</p><p><span class="math display">\[a^{(2)}_1=g(Θ^{(1)}_{10}x_0+Θ^{(1)}_{11}x_1+Θ^{(1)}_{12}x_2+Θ^{(1)}_{13}x_3)\]</span> <span class="math display">\[a^{(2)}_2=g(Θ^{(1)}_{20}x_0+Θ^{(1)}_{21}x_1+Θ^{(1)}_{22}x_2+Θ^{(1)}_{23}x_3)\]</span> <span class="math display">\[a^{(2)}_3=g(Θ^{(1)}_{30}x_0+Θ^{(1)}_{31}x_1+Θ^{(1)}_{32}x_2+Θ^{(1)}_{33}x_3)\]</span> <span class="math display">\[h_\theta(x) = a^{(3)}_1 = g(Θ^{(2)}_{10}a_0^{(2)}+Θ^{(2)}_{11}a^{(2)}_1+Θ^{(2)}_{12}a_2^{(2)}+Θ^{(2)}_{13}a_3^{(2)})\]</span></p><p>This is saying that we compute our activation nodes by using a <span class="math inline">\(3×4\)</span> matrix of parameters. We apply each row of the parameters to our inputs to obtain the value for one activation node. Our hypothesis output is the logistic function applied to the sum of the values of our activation nodes, which have been multiplied by yet another parameter matrix <span class="math inline">\(Θ^{(2)}\)</span> containing the weights for our second layer of nodes.</p><p>Each layer gets its own matrix of weights, <span class="math inline">\(Θ^{(j)}\)</span>.</p><p>The dimensions of these matrices of weights is determined as follows: <strong>If network has <span class="math inline">\(s_j\)</span> units in layer <span class="math inline">\(j\)</span> and <span class="math inline">\(s_{j+1}\)</span> units in layer <span class="math inline">\(j+1\)</span>, then <span class="math inline">\(Θ^{(j)}\)</span> will be of dimension <span class="math inline">\(s_{j+1}×(s_j+1)\)</span>.</strong></p><p>The <span class="math inline">\(+1\)</span> comes from the addition in <span class="math inline">\(Θ^{(j)}\)</span> of the &quot;bias nodes,&quot; <span class="math inline">\(x_0\)</span> and <span class="math inline">\(Θ^{(j)}_0\)</span>. In other words the output nodes will not include the bias nodes while the inputs will.</p><p>Example: layer 1 has 2 input nodes and layer 2 has 4 activation nodes. Dimension of <span class="math inline">\(Θ^{(1)}\)</span> is going to be <span class="math inline">\(4×3\)</span> where <span class="math inline">\(s_j=2\)</span> and <span class="math inline">\(s_{j+1}=4\)</span>, so <span class="math inline">\(s_{j+1}×(s_j+1)=4×3\)</span>.</p><h3><span id="vectorized-implementation">Vectorized implementation</span></h3><p>We're going to define a new variable <span class="math inline">\(z^{(j)}_k\)</span> that encompasses the parameters inside our <span class="math inline">\(g\)</span> function. In our previous example if we replaced the variable <span class="math inline">\(z\)</span> for all the parameters we would get: <span class="math display">\[a^{(2)}_1=g(z^{(2)}_1)\]</span> <span class="math display">\[a^{(2)}_2=g(z^{(2)}_2)\]</span> <span class="math display">\[a^{(2)}_3=g(z^{(2)}_3)\]</span></p><p>In other words, for layer <span class="math inline">\(j=2\)</span> and node <span class="math inline">\(k\)</span>, the variable z will be:</p><p><span class="math inline">\(z^{(2)}_k=Θ^{(1)}_{k,0}x_0+Θ^{(1)}_{k,1}x_1+⋯+Θ^{(1)}_{k,n}x_n\)</span></p><p>The vector representation of <span class="math inline">\(x\)</span> and <span class="math inline">\(z^{(j)}\)</span> is:</p><p><span class="math display">\[x=\begin{bmatrix}x_0  \\x_1 \\\vdots \\x_n\end{bmatrix} z(j)=\begin{bmatrix}z_1^{(j)}  \\z_2^{(j)} \\\vdots \\z_n^{(j)}\end{bmatrix}\]</span></p><p>Setting <span class="math inline">\(x=a^{(1)}\)</span>, we can rewrite the equation as: <span class="math display">\[z^{(j)} = Θ^{(j−1)}a^{(j−1)}\]</span></p><p>We are multiplying our matrix <span class="math inline">\(Θ^{(j−1)}\)</span> with dimensions <span class="math inline">\(s_j×(n+1)\)</span> (where <span class="math inline">\(s_j\)</span> is the number of our activation nodes) by our vector <span class="math inline">\(a^{(j−1)}\)</span> with height <span class="math inline">\((n+1)\)</span>. This gives us our vector <span class="math inline">\(z^{(j)}\)</span> with height <span class="math inline">\(s_j\)</span>. Now we can get a vector of our activation nodes for layer <span class="math inline">\(j\)</span> as follows: <span class="math display">\[a^{(j)}=g(z^{(j)})\]</span></p><p>Where our function <span class="math inline">\(g\)</span> can be applied element-wise to our vector <span class="math inline">\(z^{(j)}\)</span>.</p><p>We can then add a bias unit (equal to 1) to layer <span class="math inline">\(j\)</span> after we have computed <span class="math inline">\(a^{(j)}\)</span>. This will be element <span class="math inline">\(a^{(j)}_0\)</span> and will be equal to 1.</p><p>To compute our final hypothesis, let's first compute another z vector: <span class="math display">\[z^{(j+1)}=Θ^{(j)}a^{(j)}\]</span></p><p>We get this final <span class="math inline">\(z\)</span> vector by multiplying the next theta matrix after <span class="math inline">\(Θ^{(j−1)}\)</span> with the values of all the activation nodes we just got.</p><p>This last theta matrix (<span class="math inline">\(Θ^{(j)}\)</span>) will have only one row so that our result is a single number. We then get our final result with: <span class="math display">\[h_Θ(x)=a^{(j+1)}=g(z^{(j+1)})\]</span></p><p>Notice that in this <strong>last step</strong>, between layer <span class="math inline">\(j\)</span>and layer <span class="math inline">\(j+1\)</span>, we are doing exactly the same thing as we did in logistic regression.</p><p>Adding all these intermediate layers in neural networks allows us to more elegantly produce interesting and more complex non-linear hypotheses.</p><h2><span id="举例说明">举例说明</span></h2><h3><span id="x_1-and-x_2"><span class="math inline">\(x_1\)</span> AND <span class="math inline">\(x_2\)</span></span></h3><p>A simple example of applying neural networks is by predicting <span class="math inline">\(x_1\)</span> <strong>AND</strong> <span class="math inline">\(x_2\)</span>, which is the logical <em>'and'</em> operator and is only true if both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are <span class="math inline">\(1\)</span>.</p><p>The graph of our functions will look like: <span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2\end{bmatrix}→[g(z^{(2)})]→h_Θ(x)\]</span></p><p>Remember that <span class="math inline">\(x_0\)</span> is our bias variable and is always 1.</p><p>Let's set our first theta matrix as: <span class="math inline">\(Θ^{(1)} = [\)</span> <span class="math inline">\(-30\)</span> <span class="math inline">\(20\)</span> <span class="math inline">\(20]\)</span></p><p>This will cause the output of our hypothesis to only be positive if both <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are <span class="math inline">\(1\)</span>. In other words: <span class="math inline">\(h_Θ(x)=g(−30+20x_1+20x_2)\)</span></p><p><span class="math inline">\(x_1=0\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=0\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(−30) ≈ 0\)</span> <span class="math inline">\(x_1=0\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=1\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(−10)≈0\)</span> <span class="math inline">\(x_1=1\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=0\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(−10)≈0\)</span> <span class="math inline">\(x_1=1\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(x_2=1\)</span> <span class="math inline">\(then\)</span> <span class="math inline">\(g(10)≈1\)</span></p><p>So we have constructed one of the fundamental operations in computers by using a small neural network rather than using an actual AND gate. Neural networks can also be used to simulate all the other logical gates.</p><h3><span id="nor-or-xnor">NOR、OR、XNOR</span></h3><p>The <span class="math inline">\(Θ^{(1)}\)</span> matrices for <span class="math inline">\(AND\)</span>, <span class="math inline">\(NOR\)</span>, and <span class="math inline">\(OR\)</span> are:</p><p><span class="math inline">\(AND\)</span>: <span class="math display">\[Θ^{(1)} = \begin{bmatrix}-30 &amp; 20 &amp; 20\end{bmatrix}\]</span></p><p><span class="math inline">\(NOR\)</span>: <span class="math display">\[Θ^{(1)} = \begin{bmatrix}10 &amp; -20 &amp; -20\end{bmatrix}\]</span></p><p><span class="math inline">\(OR\)</span>: <span class="math display">\[Θ^{(1)}=\begin{bmatrix}-10 &amp; 20 &amp; 20\end{bmatrix}\]</span></p><p>We can combine these to get the <span class="math inline">\(XNOR\)</span> logical operator (which gives 1 if <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are both 0 or both 1). <span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2\end{bmatrix}→\begin{bmatrix}a_1^{(2)}  \\a_2^{(2)} \\\end{bmatrix}→[a^{(3)}]→h_Θ(x)\]</span></p><p>For the transition between the first and second layer, we'll use a <span class="math inline">\(Θ^{(1)}\)</span> matrix that combines the values for <span class="math inline">\(AND\)</span> and <span class="math inline">\(NOR\)</span>: <span class="math display">\[Θ^{(1)}=\begin{bmatrix}-30 &amp; 20 &amp; 20 \\10 &amp; -20 &amp; -20\end{bmatrix}\]</span> For the transition between the second and third layer, we'll use a <span class="math inline">\(Θ^{(2)}\)</span> matrix that uses the value for <span class="math inline">\(OR\)</span>: <span class="math display">\[Θ^{(2)}=\begin{bmatrix}-10 &amp; 20 &amp; 20\end{bmatrix}\]</span></p><p>Let's write out the values for all our nodes: <span class="math inline">\(a^{(2)}=g(Θ^{(1)}⋅x)\)</span> <span class="math inline">\(a^{(3)}=g(Θ^{(2)}⋅a^{(2)})\)</span> <span class="math inline">\(h_Θ(x)=a^{(3)}\)</span></p><p>And there we have the <span class="math inline">\(XNOR\)</span> operator using one hidden layer!</p><h2><span id="multiclass-classification">Multiclass Classification</span></h2><p>To classify data into multiple classes, we let our hypothesis function return a vector of values. Say we wanted to classify our data into one of four final resulting classes:</p><p><span class="math display">\[\begin{bmatrix}x_0  \\x_1 \\x_2 \\\vdots \\x_n\end{bmatrix} → \begin{bmatrix}a_0^{(2)}  \\a_1^{(2)} \\a_2^{(2)} \\\vdots \\\end{bmatrix} → \begin{bmatrix}a_0^{(3)}  \\a_1^{(3)} \\a_2^{(3)} \\\vdots \\\end{bmatrix}→ ... → \begin{bmatrix}h_\theta(x)_1  \\h_\theta(x)_2 \\h_\theta(x)_3 \\h_\theta(x)_4 \\\end{bmatrix} →\]</span></p><p>Our final layer of nodes, when multiplied by its theta matrix, will result in another vector, on which we will apply the <span class="math inline">\(g()\)</span> logistic function to get a vector of hypothesis values.</p><p>Our resulting hypothesis for one set of inputs may look like: <span class="math display">\[h_Θ(x)=\begin{bmatrix}0 \\0 \\1 \\0\end{bmatrix}\]</span></p><p>In which case our resulting class is the third one down, or <span class="math inline">\(h_Θ(x)_3\)</span>.</p><p>We can define our set of resulting classes as <span class="math inline">\(y\)</span>: <span class="math display">\[y(i)=\begin{bmatrix}1 \\0 \\0 \\0\end{bmatrix},\begin{bmatrix}0 \\1 \\0 \\0\end{bmatrix}, \begin{bmatrix}0 \\0 \\1 \\0\end{bmatrix}, \begin{bmatrix}0 \\0 \\0 \\1\end{bmatrix}\]</span></p><p>Our final value of our hypothesis for a set of inputs will be one of the elements in <span class="math inline">\(y\)</span>.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Neural Network </tag>
            
            <tag> Dense </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>正则化解决过度拟合问题</title>
      <link href="/2016/02/07/%E6%AD%A3%E5%88%99%E5%8C%96%E8%A7%A3%E5%86%B3%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/"/>
      <url>/2016/02/07/%E6%AD%A3%E5%88%99%E5%8C%96%E8%A7%A3%E5%86%B3%E8%BF%87%E5%BA%A6%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<blockquote><p>前言：通常一个学习演算法是借由训练范例来训练的。亦即预期结果的范例是可知的。而学习者则被认为须达到可以预测出其它范例的正确的结果，因此，应适用于一般化的情况而非只是训练时所使用的现有资料（根据它的归纳偏向）。然而，学习者却会去适应训练资料中太特化但又随机的特征，特别是在当学习过程太久或范例太少时。在过适的过程中，当预测训练范例结果的表现增加时，应用在未知资料的表现则变更差。——From <a href="https://zh.wikipedia.org/zh-hans/%E9%81%8E%E9%81%A9?oldformat=true" target="_blank" rel="noopener">WikiPedia</a></p></blockquote><a id="more"></a><!-- toc --><ul><li><a href="#过度拟合overfitting问题">过度拟合(Overfitting)问题</a></li><li><a href="#代价函数cost-function">代价函数（Cost Function）</a></li><li><a href="#正则化线性回归">正则化线性回归</a><ul><li><a href="#梯度下降gradient-descent">梯度下降(Gradient Descent)</a></li><li><a href="#正规方程normal-equation">正规方程(Normal Equation)</a></li></ul></li><li><a href="#正则化逻辑回归">正则化逻辑回归</a><ul><li><a href="#代价函数">代价函数</a></li><li><a href="#梯度下降">梯度下降</a></li></ul></li></ul><!-- tocstop --><h2><span id="过度拟合overfitting问题">过度拟合(Overfitting)问题</span></h2><p>正则化(Regularzation)就是被设计为解决过度拟合问题的。</p><p>在一个函数拟合数据集的时候会出现三种情况：欠拟合(<strong>high bias</strong> or <strong>underfitting</strong>)、正好拟合和过拟合(<strong>overfitting</strong> or <strong>high variance</strong>)。</p><ul><li><p>欠拟合(<strong>high bias</strong> or <strong>underfitting</strong>)是我们的假想函数对数据趋势拟合程度非常糟糕，造成这种情况通常是由于函数太简单或者使用的参数非常少；</p></li><li><p>过拟合(<strong>overfitting</strong> or <strong>high variance</strong>)是假想函数对训练数据拟合的非常好，但是对未知数据的预测却不尽如人意，通常是由假象函数非常复杂并且使用的参数非常多，使函数产生许多不必要的波浪。</p></li></ul><p>解决过度拟合问题主要有两个方法： 1. 减少特征（参数）的数量 * 自己决定保留哪些特征 * 用一些选择算法来决定保留哪些特征 2. 正则化 * 保留所有特征（参数），但是减小参数<span class="math inline">\(\theta_j\)</span>的值。</p><h2><span id="代价函数cost-function">代价函数（Cost Function）</span></h2><p>假设我们用一个二次函数来拟合一些数据,它给了我们一个对数据很好的拟合，然而如果我们用一个更高次的多项式去拟合，比如 <span class="math inline">\(θ_0+θ_1x+θ_2x^2+θ_3x^3+θ_4x^4\)</span>，我们最终可能得到一个曲线能非常好地拟合训练集，但是它过度拟合了数据，一般性并不是很好。</p><p>让我们考虑下面的假设：我们想要加上惩罚项从而使参数 <span class="math inline">\(θ_3\)</span> 和 <span class="math inline">\(θ_4\)</span> 足够的小，而避免直接删掉它们，只需如下修改代价函数： <span class="math display">\[\min_θ \frac{1}{2m}(\sum^m_{i=1}(h_θ(x^{(i)})−y^{(i)})^2+1000⋅θ^2_3+1000⋅θ^2_4)\]</span></p><p>我们对代价函数添加一些了项：加上 1000 乘以 <span class="math inline">\(θ_3\)</span> 的平方，再加上 1000 乘以 <span class="math inline">\(θ_4\)</span> 的平方，1000 只是我随便写的某个较大的数字而已。现在，如果我们要最小化这个函数，为了使这个新的代价函数最小化，我们要让 <span class="math inline">\(θ_3\)</span> 和 <span class="math inline">\(θ_4\)</span> 尽可能得小，对吧？如果我们这么做了，<span class="math inline">\(θ_3\)</span> 和 <span class="math inline">\(θ_4\)</span>可能会趋近于０，结果接近成一个二次函数。</p><p>更一般地可以表明，这些参数的值越小通常对应于越光滑的函数，也就是更加简单的函数。因此，就不易发生过拟合的问题。</p><p>由于在实际应用中参数可能很多，比如有100个，需要用正则化，但是我不知道具体哪个参数或哪几个参数需要缩小，所以我们只能让所有参数从<span class="math inline">\(θ_1\)</span> <span class="math inline">\(θ_2\)</span> <span class="math inline">\(θ_3\)</span> 直到 <span class="math inline">\(θ_{100}\)</span> 的值变小。(顺便说一下，按照惯例来讲，我们从第一个这里开始，所以我实际上没有去惩罚 <span class="math inline">\(θ_0\)</span> , 因此 <strong><span class="math inline">\(θ_0\)</span> 的值是大的</strong>, 这就是一个约定。)</p><p>所以代价函数被修改为： <span class="math display">\[\min_θ \frac{1}{2m}[\sum^m_{i=1}(h_θ(x^{(i)})−y^{(i)})^2+\lambda \sum^n_{j=1}\theta^2_j]\]</span></p><p>其中 <span class="math inline">\(\lambda\)</span> 为<strong>正则化参数(regularization parameter)</strong>。</p><p><span class="math inline">\(\lambda\)</span> 要做的就是控制在两个不同目标中的<strong>平衡</strong>关系。第一个目标就是我们想要使<strong>假设更好地拟合训练数据</strong>，我们希望假设能够很好的适应训练集; 而第二个目标是我们想要<strong>保持参数值较小</strong>。通过正则化目标函数，它会找到这两者之间的平衡，从而保持假设的形式相对简单, 来避免过度的拟合。</p><p>不过，如果 <span class="math inline">\(\lambda\)</span> 设置过大，假想函数可能会过于光滑平坦而导致欠拟合(underfitting)。</p><h2><span id="正则化线性回归">正则化线性回归</span></h2><p>对于线性回归的求解，我们之前推导了两种学习算法，一种基于<strong>梯度下降</strong>，一种基于<strong>正规方程</strong>。我们将继续把这两个算法推广到<strong>正则化线性回归</strong>中去 。</p><h3><span id="梯度下降gradient-descent">梯度下降(Gradient Descent)</span></h3><p>因为我们不惩罚第零项参数，所以我们把梯度下降的迭代方程中更新 <span class="math inline">\(\theta_0\)</span> 和更新其他参数分开，变为如下形式： <span class="math inline">\(Repeat\{\)</span> <span class="math display">\[\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)}\]</span> <span class="math display">\[\theta_j := \theta_j - \alpha [(\frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}) + \frac{\lambda}{m}\theta_j]\]</span> <span class="math inline">\(\}\)</span></p><p>这一项 <span class="math inline">\(\frac{\lambda}{m}\theta_j\)</span> 就是正则化。</p><p>第二个方程也可以合并同类项变成： <span class="math display">\[\theta_j := \theta_j(1 - \alpha\frac{\lambda}{m}) - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\]</span></p><p>由于 <span class="math inline">\(α\frac{λ}{m}\)</span> 通常是很小的，所以方程的第一项 <span class="math inline">\(1 - \alpha\frac{\lambda}{m}\)</span> 一般来说将是一个比1小一点点的值。我们可以把它想成一个像0.99一样的数字，所以对 <span class="math inline">\(θ_j\)</span> 更新的结果可以看作是被替换为 <span class="math inline">\(θ_j\)</span> 的0.99倍，也就是 <span class="math inline">\(θ_j\)</span> 乘以0.99把 <span class="math inline">\(θ_j\)</span> 向 0 压缩了一点点，所以这使得 <span class="math inline">\(θ_j\)</span> 小了一点，更正式地说 θj 的平方范数更小了。另外，方程的第二项实际上跟我们加入了正则项之前一样。</p><h3><span id="正规方程normal-equation">正规方程(Normal Equation)</span></h3><p>正则化的正规方程如下： <span class="math display">\[\theta = (X^TX + \lambda \cdot L)^{-1}X^Ty\]</span> 其中，<span class="math display">\[L = \begin{bmatrix}0     \\&amp; 1 \\&amp; &amp; 1 \\ &amp; &amp; &amp; \ddots &amp; \\  &amp; &amp;  &amp; &amp; 1\end{bmatrix}\]</span> 它的维度是<span class="math inline">\((n+1)×(n+1)\)</span>。</p><p>即使 <span class="math inline">\(X^TX\)</span> 是不可逆的，正则化之后，即加上 <span class="math inline">\(\lambda \cdot L\)</span> 之后，该矩阵 <span class="math inline">\(X^TX + \lambda \cdot L\)</span> 一定是可逆的。</p><h2><span id="正则化逻辑回归">正则化逻辑回归</span></h2><h3><span id="代价函数">代价函数</span></h3><p>复习一下逻辑回归的代价函数： <span class="math display">\[J(\theta) = -\frac{1}{m}\sum^{m}_{i = 1}[y^{(i)}\log(h_\theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\theta(x^{(i)}))]\]</span></p><p>我们通过在最后多加上一项来完成正则化： <span class="math display">\[J(\theta) = -\frac{1}{m}\sum^{m}_{i = 1}[y^{(i)}\log(h_\theta(x^{(i)})) + (1-y^{(i)})\log(1-h_\theta(x^{(i)}))] + \frac{\lambda}{2m}\sum^{n}_{j=1}\theta_j^2\]</span></p><p>向量形式为： <span class="math display">\[J(\theta) = -\frac{1}{m}(\log(g(X\theta))^Ty + \log(1-g(X\theta))^T(1-y)) + \frac{\lambda}{2m}temp^Ttemp\]</span> 其中 <span class="math inline">\(temp = \theta;temp(1) = 0;\)</span></p><p><strong>注意从1开始而不是从0开始！</strong></p><h3><span id="梯度下降">梯度下降</span></h3><p><span class="math inline">\(Repeat\{\)</span> <span class="math display">\[\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)}\]</span> <span class="math display">\[\theta_j := \theta_j - \alpha [(\frac{1}{m} \sum^m_{i = 1} (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}) + \frac{\lambda}{m}\theta_j]\]</span> <span class="math inline">\(\}\)</span></p><p>除了 <span class="math inline">\(h_\theta\)</span> 表示不同以外，其他与线性回归的方程一样。</p><p>最后关于梯度（偏导数）的向量形式： <span class="math display">\[\frac{\partial}{\partial\theta}J(\theta) = \frac{1}{m}[X^T(g(X\theta) - \overrightarrow{y}) + \lambda_v .* \theta]\]</span> 其中<span class="math inline">\(\lambda_v = \begin{bmatrix} 0 &amp; \lambda &amp; \lambda &amp; \cdots &amp; \lambda \\ \end{bmatrix}^T\)</span></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Regularization </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Logistic Regression</title>
      <link href="/2016/02/03/Logistic%20Regression/"/>
      <url>/2016/02/03/Logistic%20Regression/</url>
      
        <content type="html"><![CDATA[<p>Now we are switching from regression problems to <strong>classification problems</strong>. Don't be confused by the name &quot;Logistic Regression&quot;; it is named that way for historical reasons and is actually an approach to <strong>classification</strong> problems, <strong>not regression</strong> problems.</p><a id="more"></a><!-- toc --><ul><li><a href="#classification">Classification</a></li><li><a href="#hypothesis-representation">Hypothesis Representation</a></li><li><a href="#decision-boundary">Decision Boundary</a></li><li><a href="#cost-function">Cost Function</a></li><li><a href="#simplified-cost-function-and-gradient-descent">Simplified Cost Function and Gradient Descent</a><ul><li><a href="#gradient-descent">Gradient Descent</a></li></ul></li><li><a href="#advanced-optimization">Advanced Optimization</a></li><li><a href="#multiclass-classification-one-vs-all">Multiclass Classification: One-vs-all</a></li></ul><!-- tocstop --><h2><span id="classification">Classification</span></h2><p>Instead of our output vector <span class="math inline">\(y\)</span> being a continuous range of values, it will only be 0 or 1. <span class="math display">\[y∈\{0,1\}\]</span></p><p>Where 0 is usually taken as the &quot;<strong>negative class</strong>&quot; and 1 as the &quot;<strong>positive class</strong>&quot;, but you are free to assign any representation to it.</p><p>We're only doing two classes for now, called a &quot;<strong>Binary Classification Problem</strong>.&quot;</p><p>One method is to use linear regression and map all predictions greater than 0.5 as a 1 and all less than 0.5 as a 0. This method doesn't work well because <em>classification is not actually a linear function</em>.</p><h2><span id="hypothesis-representation">Hypothesis Representation</span></h2><p>Our hypothesis should satisfy: <span class="math display">\[0≤h_θ(x)≤1\]</span></p><p>Our new form uses the &quot;<strong>Sigmoid Function</strong>&quot;, also called the &quot;<strong>Logistic Function</strong>&quot;: <span class="math display">\[hθ(x)=g(θ^Tx)\]</span> <span class="math display">\[z=θ^Tx\]</span> <span class="math display">\[g(z)=\frac{1}{1+e^{−z}}\]</span></p><figure><img src="/images/1454474534412.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>The function <span class="math inline">\(g(z)\)</span>, shown here, maps any real number to the (0, 1) interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification. Try playing with interactive plot of sigmoid function <a href="https://www.desmos.com/calculator/bgontvxotm" target="_blank" rel="noopener">here</a>.</p><p>We start with our old hypothesis (linear regression), except that we want to restrict the range to 0 and 1. This is accomplished by plugging <span class="math inline">\(θ^Tx\)</span> into the Logistic Function.</p><p><span class="math inline">\(h_θ\)</span> will give us the <strong>probability</strong> that our output is 1. For example, <span class="math inline">\(h_θ(x)=0.7\)</span> gives us the probability of 70% that our output is 1.</p><p><span class="math display">\[h_θ(x)=P(y=1∣x ;θ)=1−P(y=0∣x ;θ)\]</span> <span class="math display">\[P(y=0∣x;θ)+P(y=1∣x ;θ)=1\]</span> Our probability that our prediction is 0 is just the complement of our probability that it is 1 (e.g. if probability that it is 1 is 70%, then the probability that it is 0 is 30%).</p><h2><span id="decision-boundary">Decision Boundary</span></h2><p>In order to get our discrete 0 or 1 classification, we can translate the output of the hypothesis function as follows:</p><p><span class="math display">\[h_θ(x)≥0.5→y=1\]</span> <span class="math display">\[h_θ(x)&lt;0.5→y=0\]</span></p><p>The way our logistic function <span class="math inline">\(g\)</span> behaves is that when its input is greater than or equal to zero, its output is greater than or equal to 0.5:</p><p><span class="math display">\[g(z)≥0.5\]</span> when <span class="math inline">\(z≥0\)</span></p><p>Remember.-</p><p><span class="math display">\[z=0,e^0=1,g(z)=1/2\]</span> <span class="math display">\[z→∞,e^{−∞}→0,g(z)=1\]</span> <span class="math display">\[z→−∞,e^∞→∞,g(z)=0\]</span></p><p>So if our input to g is <span class="math inline">\(θ^TX\)</span>, then that means:</p><p><span class="math display">\[h_θ(x)=g(θ^Tx)≥0.5\]</span> when<span class="math inline">\(θ^Tx≥0\)</span></p><p>From these statements we can now say:</p><p><span class="math display">\[θ^Tx≥0→y=1\]</span> <span class="math display">\[θ^Tx&lt;0→y=0\]</span></p><p>The <strong>decision boundary</strong> is the line that separates the area where y=0 and where y=1. It is created by our hypothesis function.</p><p><strong>Example</strong>:</p><p><span class="math display">\[θ=\begin{bmatrix}5 \\-1 \\0\\\end{bmatrix}\]</span> <span class="math inline">\(y=1\)</span> if <span class="math inline">\(5+(−1)x1+0x2≥0\)</span> <span class="math inline">\(5−x1≥0\)</span> <span class="math inline">\(−x1≥−5\)</span> <span class="math inline">\(x1≤5\)</span></p><p>Our decision boundary then is a straight vertical line placed on the graph where <span class="math inline">\(x_1=5\)</span>, and everything to the left of that denotes <span class="math inline">\(y=1\)</span>, while everything to the right denotes <span class="math inline">\(y=0\)</span>.</p><p>Again, the input to the sigmoid function <span class="math inline">\(g(z)\)</span> (e.g. <span class="math inline">\(θ^TX\)</span>) need not be linear, and could be a function that describes a circle (e.g. <span class="math inline">\(z=θ_0+θ_1x^2_1+θ_2x^2_2\)</span>) or any shape to fit our data.</p><h2><span id="cost-function">Cost Function</span></h2><p>We <strong>cannot</strong> use the same cost function that we use for linear regression because the Logistic Function will cause the output to be wavy, causing many local optima. In other words, it will not be a convex function. Instead, our cost function for logistic regression looks like:</p><p><span class="math display">\[J(θ)=\frac{1}{m}∑_{i=1}^mCost(h_θ(x^{(i)}),y^{(i)})\]</span></p><p><span class="math inline">\(Cost(h_θ(x),y)=−log(h_θ(x))\)</span> <code>if</code> <span class="math inline">\(y = 1\)</span> $Cost(h_θ(x),y)=−log(1−h_θ(x)) $ <code>if</code> <span class="math inline">\(y = 0\)</span></p><p><img src="/images/1454494932330.png" alt="Alt text"> <img src="/images/1454494937253.png" alt="Alt text"></p><p>The more our hypothesis is off from <span class="math inline">\(y\)</span>, the larger the cost function output. If our hypothesis is equal to <span class="math inline">\(y\)</span>, then our cost is <span class="math inline">\(0\)</span>:</p><p><span class="math inline">\(Cost(h_θ(x),y)=0\)</span> <span class="math inline">\(if\)</span> <span class="math inline">\(h_θ(x)=y\)</span> <span class="math inline">\(Cost(h_θ(x),y)→∞\)</span> <span class="math inline">\(if\)</span> <span class="math inline">\(y=0\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(h_θ(x)→1\)</span> <span class="math inline">\(Cost(h_θ(x),y)→∞\)</span> <span class="math inline">\(if\)</span> <span class="math inline">\(y=1\)</span> <span class="math inline">\(and\)</span> <span class="math inline">\(h_θ(x)→0\)</span></p><p>If our correct answer '<span class="math inline">\(y\)</span>' is 0, then the cost function will be 0 if our hypothesis function also outputs 0. If our hypothesis approaches 1, then the cost function will approach infinity.</p><p>If our correct answer '<span class="math inline">\(y\)</span>' is 1, then the cost function will be 0 if our hypothesis function outputs 1. If our hypothesis approaches 0, then the cost function will approach infinity.</p><p><strong>Note</strong> that writing the cost function in this way guarantees that <span class="math inline">\(J(θ)\)</span> is convex for logistic regression.</p><h2><span id="simplified-cost-function-and-gradient-descent">Simplified Cost Function and Gradient Descent</span></h2><p>We can compress our cost function's two conditional cases into one case:</p><p><span class="math display">\[Cost(h_θ(x),y)=−ylog(h_θ(x))−(1−y)log(1−h_θ(x))\]</span></p><p>Notice that when y is equal to 1, then the second term <span class="math inline">\(((1−y)log(1−h_θ(x)))\)</span> will be zero and will not affect the result. If y is equal to 0, then the first term <span class="math inline">\((−ylog(h_θ(x)))\)</span> will be zero and will not affect the result.</p><p>We can fully write out our entire cost function as follows:</p><p><span class="math display">\[J(θ)=−\frac{1}{m}\sum_{i=1}^m[y^{(i)}\log(h_θ(x^{(i)}))+(1−y^{(i)})\log(1−h_θ(x^{(i)}))]\]</span></p><p>A <strong>vectorized</strong> implementation is:</p><p><span class="math display">\[J(θ)=−\frac{1}{m}(\log(g(Xθ))^Ty+\log(1−g(Xθ))^T(1−y))\]</span></p><h3><span id="gradient-descent">Gradient Descent</span></h3><p>Remember that the general form of gradient descent is: <span class="math inline">\(Repeat\{\)</span> <span class="math display">\[θ_j := θ_j−α\frac{∂}{∂θ_j}J(θ)\]</span> <span class="math inline">\(\}\)</span></p><p>We can work out the derivative part using calculus to get: <span class="math inline">\(Repeat\{\)</span> <span class="math display">\[θ_j := θ_j−\frac{α}{m}\sum_{i=1}^m(h_θ(x^{(i)})−y^{(i)})x^{(i)}_j\]</span> <span class="math inline">\(\}\)</span></p><p>Notice that this algorithm is <strong>identical</strong> to the one we used in <strong>linear regression</strong>. We still have to simultaneously update all values in theta.</p><p>A <strong>vectorized</strong> implementation is:</p><p><span class="math display">\[θ :=θ − \frac{α}{m}X^T(g(Xθ)− \overrightarrow{y} )\]</span></p><h2><span id="advanced-optimization">Advanced Optimization</span></h2><p>&quot;<strong>Conjugate gradient</strong>&quot;, &quot;<strong>BFGS</strong>&quot;, and &quot;<strong>L-BFGS</strong>&quot; are more sophisticated, faster ways to optimize theta instead of using gradient descent. A. Ng suggests you do not write these more sophisticated algorithms yourself (unless you are an expert in numerical computing) but use them pre-written from libraries. Octave provides them.</p><p>We first need to provide a function that computes the following two equations:<span class="math inline">\(J(θ)\)</span>, <span class="math inline">\(\frac{∂}{∂θ_j}J(θ)\)</span></p><p>We can write a single function that returns both of these: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[jVal, gradient]</span> = <span class="title">costFunction</span><span class="params">(theta)</span></span></span><br><span class="line">  jval = [...code to compute J(theta)...];</span><br><span class="line">  gradient = [...code to compute derivative of J(theta)...];</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p><p>Then we can use octave's &quot;<code>fminunc()</code>&quot; optimization algorithm along with the &quot;<code>optimset()</code>&quot; function that creates an object containing the options we want to send to &quot;<code>fminunc()</code>&quot;. (Note: the value for <code>MaxIter</code> should be an integer, not a character string - errata in the video at 7:30) <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options = optimset(<span class="string">'GradObj'</span>, <span class="string">'on'</span>, <span class="string">'MaxIter'</span>, <span class="number">100</span>);</span><br><span class="line">initialTheta = <span class="built_in">zeros</span>(<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure></p><p>We give to the function &quot;<code>fminunc()</code>&quot; our cost function, our initial vector of theta values, and the &quot;<code>options</code>&quot; object that we created beforehand.</p><h2><span id="multiclass-classification-one-vs-all">Multiclass Classification: One-vs-all</span></h2><p>Now we will approach the classification of data into more than two categories. Instead of <span class="math inline">\(y = \{0,1\}\)</span> we will expand our definition so that <span class="math inline">\(y = \{0,1...n\}\)</span>.</p><p>In this case we divide our problem into <span class="math inline">\(n+1\)</span> (+1 because the index starts at 0) binary classification problems; in each one, we predict the probability that '<span class="math inline">\(y\)</span>' is a member of one of our classes.</p><p><span class="math display">\[y∈\{0,1...n\}\]</span> <span class="math display">\[h^{(0)}_θ(x)=P(y=0∣x ;θ)\]</span> <span class="math display">\[h^{(1)}_θ(x)=P(y=1∣x ;θ)\]</span> <span class="math display">\[⋯\]</span> <span class="math display">\[h^{(n)}_θ(x)=P(y=n∣x ;θ)\]</span> <span class="math display">\[prediction=\max_i(h^{(i)}_θ(x))\]</span></p><p>We are basically choosing one class and then lumping all the others into a single second class. We do this repeatedly, applying binary logistic regression to each case, and then use the hypothesis that returned the highest value as our prediction.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Logistic Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Octave Tutorial</title>
      <link href="/2016/02/01/Octave%20Tutorial/"/>
      <url>/2016/02/01/Octave%20Tutorial/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#basic-operations">Basic Operations</a></li><li><a href="#moving-data-around">Moving Data Around</a><ul><li><a href="#dimensions">Dimensions</a></li><li><a href="#loading-data">Loading data</a></li><li><a href="#indexing">Indexing</a></li></ul></li><li><a href="#computing-on-data">Computing on Data</a><ul><li><a href="#matrix-operation">Matrix operation</a></li><li><a href="#useful-functions">Useful functions</a></li></ul></li><li><a href="#plotting-data">Plotting Data</a></li><li><a href="#control-statements-for-while-if-statements">Control statements: <code>for</code>, <code>while</code>, <code>if</code> statements</a></li><li><a href="#functions">Functions</a></li><li><a href="#vectorization">Vectorization</a></li><li><a href="#working-on-and-submitting-programming-exercises">Working on and Submitting Programming Exercises</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="basic-operations">Basic Operations</span></h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% Change Octave prompt  </span></span><br><span class="line">PS1(<span class="string">'&gt;&gt; '</span>);</span><br><span class="line"><span class="comment">%% Change working directory in windows example:</span></span><br><span class="line">cd <span class="string">'c:/path/to/desired/directory name'</span></span><br><span class="line"><span class="comment">%% Note that it uses normal slashes and does not use escape characters for the empty spaces.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% elementary operations</span></span><br><span class="line"><span class="number">5</span>+<span class="number">6</span></span><br><span class="line"><span class="number">3</span><span class="number">-2</span></span><br><span class="line"><span class="number">5</span>*<span class="number">8</span></span><br><span class="line"><span class="number">1</span>/<span class="number">2</span></span><br><span class="line"><span class="number">2</span>^<span class="number">6</span></span><br><span class="line"><span class="number">1</span> == <span class="number">2</span>  <span class="comment">% false</span></span><br><span class="line"><span class="number">1</span> ~= <span class="number">2</span>  <span class="comment">% true.  note, not "!="</span></span><br><span class="line"><span class="number">1</span> &amp;&amp; <span class="number">0</span></span><br><span class="line"><span class="number">1</span> || <span class="number">0</span></span><br><span class="line">xor(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%% variable assignment</span></span><br><span class="line">a = <span class="number">3</span>; <span class="comment">% semicolon suppresses output</span></span><br><span class="line">b = <span class="string">'hi'</span>;</span><br><span class="line">c = <span class="number">3</span>&gt;=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">% Displaying them:</span></span><br><span class="line">a = <span class="built_in">pi</span></span><br><span class="line"><span class="built_in">disp</span>(a)</span><br><span class="line"><span class="built_in">disp</span>(sprintf(<span class="string">'2 decimals: %0.2f'</span>, a))</span><br><span class="line"><span class="built_in">disp</span>(sprintf(<span class="string">'6 decimals: %0.6f'</span>, a))</span><br><span class="line">format long</span><br><span class="line">a</span><br><span class="line">format short</span><br><span class="line">a</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%%  vectors and matrices</span></span><br><span class="line">A = [<span class="number">1</span> <span class="number">2</span>; <span class="number">3</span> <span class="number">4</span>; <span class="number">5</span> <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">v = [<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line">v = [<span class="number">1</span>; <span class="number">2</span>; <span class="number">3</span>]</span><br><span class="line">v = [<span class="number">1</span>:<span class="number">0.1</span>:<span class="number">2</span>]  <span class="comment">% from 1 to 2, with stepsize of 0.1. Useful for plot axes</span></span><br><span class="line">v = <span class="number">1</span>:<span class="number">6</span>        <span class="comment">% from 1 to 6, assumes stepsize of 1 (row vector)</span></span><br><span class="line"></span><br><span class="line">C = <span class="number">2</span> * <span class="built_in">ones</span>(<span class="number">2</span>,<span class="number">3</span>)  <span class="comment">% same as C = [2 2 2; 2 2 2]</span></span><br><span class="line">w = <span class="built_in">ones</span>(<span class="number">1</span>,<span class="number">3</span>)    <span class="comment">% 1x3 vector of ones</span></span><br><span class="line">w = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line">w = <span class="built_in">rand</span>(<span class="number">1</span>,<span class="number">3</span>)  <span class="comment">% drawn from a uniform distribution </span></span><br><span class="line">w = <span class="built_in">randn</span>(<span class="number">1</span>,<span class="number">3</span>) <span class="comment">% drawn from a normal distribution (mean=0, var=1)</span></span><br><span class="line">w = <span class="number">-6</span> + <span class="built_in">sqrt</span>(<span class="number">10</span>)*(<span class="built_in">randn</span>(<span class="number">1</span>,<span class="number">10000</span>));  <span class="comment">% (mean = -6, var = 10) - note: add the semicolon</span></span><br><span class="line">hist(w)     <span class="comment">% plot histogram using 10 bins (default)</span></span><br><span class="line">hist(w,<span class="number">50</span>)  <span class="comment">% plot histogram using 50 bins</span></span><br><span class="line"><span class="comment">% note: if hist() crashes, try "graphics_toolkit('gnu_plot')" </span></span><br><span class="line"></span><br><span class="line">I = <span class="built_in">eye</span>(<span class="number">4</span>)    <span class="comment">% 4x4 identity matrix</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% help function</span></span><br><span class="line">help <span class="built_in">eye</span></span><br><span class="line">help <span class="built_in">rand</span></span><br><span class="line">help help</span><br></pre></td></tr></table></figure><h2><span id="moving-data-around">Moving Data Around</span></h2><h3><span id="dimensions">Dimensions</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% dimensions</span></span><br><span class="line">sz = <span class="built_in">size</span>(A) <span class="comment">% 1x2 matrix: [(number of rows) (number of columns)]</span></span><br><span class="line"><span class="built_in">size</span>(A,<span class="number">1</span>)  <span class="comment">% number of rows</span></span><br><span class="line"><span class="built_in">size</span>(A,<span class="number">2</span>)  <span class="comment">% number of cols</span></span><br><span class="line"><span class="built_in">length</span>(v)  <span class="comment">% size of longest dimension</span></span><br></pre></td></tr></table></figure><h3><span id="loading-data">Loading data</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% loading data</span></span><br><span class="line">pwd    <span class="comment">% show current directory (current path)</span></span><br><span class="line">cd <span class="string">'C:\Users\ang\Octave files'</span>   <span class="comment">% change directory </span></span><br><span class="line">ls     <span class="comment">% list files in current directory </span></span><br><span class="line">load q1y.dat    <span class="comment">% alternatively, load('q1y.dat')</span></span><br><span class="line">load q1x.dat</span><br><span class="line">who    <span class="comment">% list variables in workspace</span></span><br><span class="line">whos   <span class="comment">% list variables in workspace (detailed view) </span></span><br><span class="line">clear q1y       <span class="comment">% clear w/ no argt clears all</span></span><br><span class="line">v = q1x(<span class="number">1</span>:<span class="number">10</span>);  <span class="comment">% first 10 elements of q1x (counts down the columns)</span></span><br><span class="line">save hello.mat v;   <span class="comment">% save variable v into file hello.mat</span></span><br><span class="line">save hello.txt v -ascii; <span class="comment">% save as ascii</span></span><br><span class="line"><span class="comment">% fopen, fread, fprintf, fscanf also work  [[not needed in class]]</span></span><br></pre></td></tr></table></figure><h3><span id="indexing">Indexing</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% indexing</span></span><br><span class="line">A(<span class="number">3</span>,<span class="number">2</span>)  <span class="comment">% indexing is (row,col)</span></span><br><span class="line">A(<span class="number">2</span>,:)  <span class="comment">% get the 2nd row. </span></span><br><span class="line">        <span class="comment">% ":" means every element along that dimension</span></span><br><span class="line">A(:,<span class="number">2</span>)  <span class="comment">% get the 2nd col</span></span><br><span class="line">A([<span class="number">1</span> <span class="number">3</span>],:) <span class="comment">% print all  the elements of rows 1 and 3</span></span><br><span class="line"></span><br><span class="line">A(:,<span class="number">2</span>) = [<span class="number">10</span>; <span class="number">11</span>; <span class="number">12</span>]     <span class="comment">% change second column</span></span><br><span class="line">A = [A, [<span class="number">100</span>; <span class="number">101</span>; <span class="number">102</span>]]; <span class="comment">% append column vec</span></span><br><span class="line">A(:) <span class="comment">% Select all elements as a column vector.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% Putting data together </span></span><br><span class="line">A = [<span class="number">1</span> <span class="number">2</span>; <span class="number">3</span> <span class="number">4</span>; <span class="number">5</span> <span class="number">6</span>]</span><br><span class="line">B = [<span class="number">11</span> <span class="number">12</span>; <span class="number">13</span> <span class="number">14</span>; <span class="number">15</span> <span class="number">16</span>] <span class="comment">% same dims as A</span></span><br><span class="line">C = [A B] or [A,B]- concatenating A and B matrices side by side</span><br><span class="line">C = [A; B] - Concatenating A and B top and bottom</span><br></pre></td></tr></table></figure><h2><span id="computing-on-data">Computing on Data</span></h2><h3><span id="matrix-operation">Matrix operation</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% initialize variables</span></span><br><span class="line">A = [<span class="number">1</span> <span class="number">2</span>;<span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span>]</span><br><span class="line">B = [<span class="number">11</span> <span class="number">12</span>;<span class="number">13</span> <span class="number">14</span>;<span class="number">15</span> <span class="number">16</span>]</span><br><span class="line">C = [<span class="number">1</span> <span class="number">1</span>;<span class="number">2</span> <span class="number">2</span>]</span><br><span class="line">v = [<span class="number">1</span>;<span class="number">2</span>;<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">%% matrix operations</span></span><br><span class="line">A * C  <span class="comment">% matrix multiplication</span></span><br><span class="line">A .* B <span class="comment">% element-wise multiplication</span></span><br><span class="line"><span class="comment">% A .* C  or A * B gives error - wrong dimensions</span></span><br><span class="line">A .^ <span class="number">2</span> <span class="comment">% element-wise square of each element in A</span></span><br><span class="line"><span class="number">1.</span>/v   <span class="comment">% element-wise reciprocal</span></span><br><span class="line"><span class="built_in">log</span>(v)  <span class="comment">% functions like this operate element-wise on vecs or matrices </span></span><br><span class="line"><span class="built_in">exp</span>(v)</span><br><span class="line"><span class="built_in">abs</span>(v)</span><br><span class="line"></span><br><span class="line">-v  <span class="comment">% -1*v</span></span><br><span class="line"></span><br><span class="line">v + <span class="built_in">ones</span>(<span class="built_in">length</span>(v), <span class="number">1</span>)  </span><br><span class="line"><span class="comment">% v + 1  % same</span></span><br><span class="line"></span><br><span class="line">A'  <span class="comment">% matrix transpose</span></span><br></pre></td></tr></table></figure><h3><span id="useful-functions">Useful functions</span></h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% misc useful functions</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% max  (or min)</span></span><br><span class="line">a = [<span class="number">1</span> <span class="number">15</span> <span class="number">2</span> <span class="number">0.5</span>]</span><br><span class="line">val = <span class="built_in">max</span>(a)</span><br><span class="line">[val,ind] = <span class="built_in">max</span>(a) <span class="comment">% val -  maximum element of the vector a and index - index value where maximum occur</span></span><br><span class="line">val = <span class="built_in">max</span>(A) <span class="comment">% if A is matrix, returns max from each column</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% find</span></span><br><span class="line">a &lt; <span class="number">3</span></span><br><span class="line"><span class="built_in">find</span>(a &lt; <span class="number">3</span>)</span><br><span class="line">A = <span class="built_in">magic</span>(<span class="number">3</span>)</span><br><span class="line">[r,c] = <span class="built_in">find</span>(A&gt;=<span class="number">7</span>)  <span class="comment">% row, column indices for values matching comparison</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% sum, prod</span></span><br><span class="line">sum(a)</span><br><span class="line">prod(a)</span><br><span class="line"><span class="built_in">floor</span>(a) <span class="comment">% or ceil(a)</span></span><br><span class="line"><span class="built_in">max</span>(<span class="built_in">rand</span>(<span class="number">3</span>),<span class="built_in">rand</span>(<span class="number">3</span>))</span><br><span class="line"><span class="built_in">max</span>(A,[],<span class="number">1</span>) -  maximum along columns(defaults to columns - <span class="built_in">max</span>(A,[]))</span><br><span class="line"><span class="built_in">max</span>(A,[],<span class="number">2</span>) - maximum along rows</span><br><span class="line">A = <span class="built_in">magic</span>(<span class="number">9</span>)</span><br><span class="line">sum(A,<span class="number">1</span>)</span><br><span class="line">sum(A,<span class="number">2</span>)</span><br><span class="line">sum(sum( A .* <span class="built_in">eye</span>(<span class="number">9</span>) ))</span><br><span class="line">sum(sum( A .* <span class="built_in">flipud</span>(<span class="built_in">eye</span>(<span class="number">9</span>)) ))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">% Matrix inverse (pseudo-inverse)</span></span><br><span class="line">pinv(A)        <span class="comment">% inv(A'*A)*A'</span></span><br></pre></td></tr></table></figure><h2><span id="plotting-data">Plotting Data</span></h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%% plotting</span></span><br><span class="line">t = [<span class="number">0</span>:<span class="number">0.01</span>:<span class="number">0.98</span>];</span><br><span class="line">y1 = <span class="built_in">sin</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">4</span>*t); </span><br><span class="line"><span class="built_in">plot</span>(t,y1);</span><br><span class="line">y2 = <span class="built_in">cos</span>(<span class="number">2</span>*<span class="built_in">pi</span>*<span class="number">4</span>*t);</span><br><span class="line"><span class="built_in">hold</span> on;  <span class="comment">% "hold off" to turn off</span></span><br><span class="line"><span class="built_in">plot</span>(t,y2,<span class="string">'r'</span>);</span><br><span class="line">xlabel(<span class="string">'time'</span>);</span><br><span class="line">ylabel(<span class="string">'value'</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'sin'</span>,<span class="string">'cos'</span>);</span><br><span class="line">title(<span class="string">'my plot'</span>);</span><br><span class="line">print -dpng <span class="string">'myPlot.png'</span></span><br><span class="line">close;           <span class="comment">% or,  "close all" to close all figs</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); <span class="built_in">plot</span>(t, y1);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>); <span class="built_in">plot</span>(t, y2);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>), clf;  <span class="comment">% can specify the figure number</span></span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>);  <span class="comment">% Divide plot into 1x2 grid, access 1st element</span></span><br><span class="line"><span class="built_in">plot</span>(t,y1);</span><br><span class="line">subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>);  <span class="comment">% Divide plot into 1x2 grid, access 2nd element</span></span><br><span class="line"><span class="built_in">plot</span>(t,y2);</span><br><span class="line">axis([<span class="number">0.5</span> <span class="number">1</span> <span class="number">-1</span> <span class="number">1</span>]);  <span class="comment">% change axis scale</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% display a matrix (or image) </span></span><br><span class="line"><span class="built_in">figure</span>;</span><br><span class="line">imagesc(<span class="built_in">magic</span>(<span class="number">15</span>)), colorbar, colormap gray;</span><br><span class="line"><span class="comment">% comma-chaining function calls.  </span></span><br><span class="line">a=<span class="number">1</span>,b=<span class="number">2</span>,c=<span class="number">3</span></span><br><span class="line">a=<span class="number">1</span>;b=<span class="number">2</span>;c=<span class="number">3</span>;</span><br></pre></td></tr></table></figure><h2><span id="control-statements-for-while-if-statements">Control statements: <code>for</code>, <code>while</code>, <code>if</code> statements</span></h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">v = <span class="built_in">zeros</span>(<span class="number">10</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">10</span>, </span><br><span class="line">    v(<span class="built_in">i</span>) = <span class="number">2</span>^<span class="built_in">i</span>;</span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"><span class="comment">% Can also use "break" and "continue" inside for and while loops to control execution.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">i</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">i</span> &lt;= <span class="number">5</span>,</span><br><span class="line">  v(<span class="built_in">i</span>) = <span class="number">100</span>; </span><br><span class="line">  <span class="built_in">i</span> = <span class="built_in">i</span>+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">i</span> = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">true</span>, </span><br><span class="line">  v(<span class="built_in">i</span>) = <span class="number">999</span>; </span><br><span class="line">  <span class="built_in">i</span> = <span class="built_in">i</span>+<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">i</span> == <span class="number">6</span>,</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">end</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> v(<span class="number">1</span>)==<span class="number">1</span>,</span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">'The value is one!'</span>);</span><br><span class="line"><span class="keyword">elseif</span> v(<span class="number">1</span>)==<span class="number">2</span>,</span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">'The value is two!'</span>);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  <span class="built_in">disp</span>(<span class="string">'The value is not one or two!'</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h2><span id="functions">Functions</span></h2><p>To create a function, type the function code in a text editor (e.g. gedit or notepad), and save the file as &quot;<code>functionName.m</code>&quot;</p><p>Example function: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">squareThisNumber</span><span class="params">(x)</span></span></span><br><span class="line"></span><br><span class="line">y = x^<span class="number">2</span>;</span><br></pre></td></tr></table></figure></p><p>To call the function in Octave, do either:</p><ol type="1"><li><p>Navigate to the directory of the <code>functionName.m</code> file and call the function: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% Navigate to directory:</span></span><br><span class="line">    cd /path/to/function</span><br><span class="line"></span><br><span class="line">    <span class="comment">% Call the function:</span></span><br><span class="line">    functionName(args)</span><br></pre></td></tr></table></figure></p></li><li><p>Add the directory of the function to the load <strong>path</strong> and save it: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% To add the path for the current session of Octave:</span></span><br><span class="line">    addpath(<span class="string">'/path/to/function/'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">% To remember the path for future sessions of Octave, after executing addpath above, also do:</span></span><br><span class="line">    savepath</span><br></pre></td></tr></table></figure></p></li></ol><p>Octave's functions can return more than one value: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[y1, y2]</span> = <span class="title">squareandCubeThisNo</span><span class="params">(x)</span></span></span><br><span class="line">y1 = x^<span class="number">2</span></span><br><span class="line">y2 = x^<span class="number">3</span></span><br></pre></td></tr></table></figure></p><p>Call the above function this way: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[a,b] = squareandCubeThisNo(x)</span><br></pre></td></tr></table></figure></p><h2><span id="vectorization">Vectorization</span></h2><p>Vectorization is the process of taking code that relies on <strong>loops</strong> and converting it into <strong>matrix operations</strong>. It is more efficient, more elegant, and more concise.</p><p>As an example, let's compute our prediction from a hypothesis. Theta is the vector of fields for the hypothesis and x is a vector of variables.</p><p>With loops: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">prediction = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>:n+<span class="number">1</span>,</span><br><span class="line">  prediction += theta(<span class="built_in">j</span>) * x(<span class="built_in">j</span>);</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure></p><p>With vectorization: <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = theta' * x;</span><br></pre></td></tr></table></figure></p><p>If you recall the definition multiplying vectors, you'll see that this one operation does the element-wise multiplication and overall sum in a very concise notation.</p><h2><span id="working-on-and-submitting-programming-exercises">Working on and Submitting Programming Exercises</span></h2><ol type="1"><li>Download and extract the assignment's zip file.</li><li>Edit the proper file 'a.m', where a is the name of the exercise you're working on.</li><li>Run octave and cd to the assignment's extracted directory</li><li>Run the 'submit' function and enter the assignment number, your email, and a password (found on the top of the &quot;Programming Exercises&quot; page on coursera)</li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Octave </tag>
            
            <tag> Matlab </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linear Regression with Multiple Variables</title>
      <link href="/2016/01/31/Linear%20Regression%20with%20Multiple%20Variables/"/>
      <url>/2016/01/31/Linear%20Regression%20with%20Multiple%20Variables/</url>
      
        <content type="html"><![CDATA[<h2><span id="multiple-features">Multiple Features</span></h2><p>Linear regression with multiple variables is also known as &quot;<strong>multivariate linear regression</strong>&quot;.</p><p>We now introduce notation for equations where we can have any number of input variables.</p><a id="more"></a><ul><li><span class="math inline">\(x^{(i)}_j\)</span> = value of feature j in the <span class="math inline">\(i^{th}\)</span> training example</li><li><span class="math inline">\(x^{(i)}\)</span> = the column vector of all the feature inputs of the <span class="math inline">\(i^{th}\)</span> training example</li><li><span class="math inline">\(m\)</span> = the number of training examples</li><li><span class="math inline">\(n\)</span> = <span class="math inline">\(∣x^{(i)}∣\)</span> (the number of features)</li></ul><p>Now define the multivariable form of the hypothesis function as follows, accomodating these multiple features:</p><p><span class="math display">\[h_θ(x)=θ_0+θ_1x_1 + θ_2x_2 + θ_3x_3 +⋯+ θ_nx_n\]</span></p><p>In order to have little intuition about this function, we can think about <span class="math inline">\(θ_0\)</span> as the basic price of a house, <span class="math inline">\(θ_1\)</span> as the price per square meter, <span class="math inline">\(θ_2\)</span> as the price per floor, etc. <span class="math inline">\(x_1\)</span> will be the number of square meters in the house, <span class="math inline">\(x_2\)</span> the number of floors, etc.</p><p>Using the definition of matrix multiplication, our <strong>multivariable hypothesis function</strong> can be concisely represented as:</p><p><span class="math display">\[h_θ(x)=\begin{bmatrix}θ_0      &amp; \cdots &amp; θ_n      \\\end{bmatrix}\begin{bmatrix}x_0\\ \\\vdots \\\\x_n      \\\end{bmatrix} = θ^{T}x\]</span></p><p>This is a vectorization of our hypothesis function for one training example; see the lessons on vectorization to learn more.</p><p>[<strong>Note</strong>: So that we can do matrix operations with theta and x, we will set <span class="math inline">\(x^{(i)}_0 = 1\)</span>, for all values of <span class="math inline">\(i\)</span>. This makes the two vectors <span class="math inline">\(\theta\)</span> and <span class="math inline">\(x^{(i)}\)</span> match each other element-wise (that is, have the same number of elements: n+1).]</p><p>Now we can collect all <em>m</em> training examples each with <em>n</em> features and record them in an <strong>n+1 by m</strong> matrix. In this matrix we let the value of the subscript (feature) also represent the row number (except the initial row is the &quot;zeroth&quot; row), and the value of the superscript (the training example) also represent the column number, as shown here: <span class="math display">\[X = \begin{bmatrix}x^{(1)}_0 &amp; x^{(2)}_0     &amp; \cdots &amp;  x^{(m)}_0     \\x^{(1)}_1 &amp; x^{(2)}_1     &amp; \cdots &amp;  x^{(m)}_1     \\&amp; &amp; \vdots  &amp; \\x^{(1)}_n &amp; x^{(2)}_n     &amp; \cdots &amp;  x^{(m)}_n     \end{bmatrix} = \begin{bmatrix}1 &amp; 1     &amp; \cdots &amp;  1     \\x^{(1)}_1 &amp; x^{(2)}_1     &amp; \cdots &amp;  x^{(m)}_1     \\&amp; &amp; \vdots  &amp; \\x^{(1)}_n &amp; x^{(2)}_n     &amp; \cdots &amp;  x^{(m)}_n     \end{bmatrix}\]</span></p><p>Notice above that the first column is the first training example (like the vector above), the second column is the second training example, and so forth.</p><p>Now we can define <span class="math inline">\(h_θ(X)\)</span> as a row vector that gives the value of <span class="math inline">\(h_θ(x)\)</span> at each of the <em>m</em> training examples: <span class="math display">\[hθ(X)=\begin{bmatrix}θ_0x^{(1)}_0+θ_1x^{(1)}_1+...+θ_nx^{(1)}_n       &amp; \cdots &amp; θ_0x^{(m)}_0+θ_1x^{(m)}_1+...+θ_nx^{(m)}_n      \\\end{bmatrix}\]</span></p><h2><span id="cost-function">Cost function</span></h2><p>For the parameter vector <span class="math inline">\(θ\)</span> (of type <span class="math inline">\(R^{n+1}\)</span> or in <span class="math inline">\(R^{(n+1)×1}\)</span>), the cost function is:</p><p><span class="math display">\[J(\theta) = \frac{1}{2m}\sum^{m}_{i = 1}(h_\theta(x^{(i)}) - y^{(i)})^2\]</span></p><p>The vectorized version is:</p><p><span class="math display">\[J(\theta) = \frac{1}{2m}(X\theta - \overrightarrow{y})^T(X\theta - \overrightarrow{y})\]</span></p><p>Where <span class="math inline">\(\overrightarrow{y}\)</span> denotes the vector of all <em>y</em> values, <span class="math inline">\(X\)</span> represent a matrix of training examples <span class="math inline">\(x^{(i)}\)</span> stored <strong>row-wise</strong>.</p><h2><span id="gradient-descent-for-multiple-variables">Gradient Descent for Multiple Variables</span></h2><p>The gradient descent equation itself is generally the same form; we just have to repeat it for our '<strong>n</strong>' features:</p><p><strong>repeat until convergence:{</strong> <span class="math display">\[\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_0\]</span> <span class="math display">\[\theta_1 := \theta_1 - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_1\]</span> <span class="math display">\[\theta_2 := \theta_2 - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_2\]</span> <span class="math display">\[...\]</span> <strong>}</strong></p><p>In other words:</p><p><strong>repeat until convergence:{</strong> <span class="math display">\[\theta_j := \theta_j - \alpha\frac{1}{m}\sum^{1}_{m}(h_\theta(x^{(i)}) - y^{(i)})  x^{(i)}_j\]</span> <strong>for <span class="math inline">\(j\)</span> <span class="math inline">\(:=\)</span> <span class="math inline">\(0\)</span>...<span class="math inline">\(n\)</span></strong> <strong>}</strong></p><h2><span id="matrix-notation">Matrix Notation</span></h2><p>The Gradient Descent rule can be expressed as:</p><p><span class="math display">\[\theta := \theta - \alpha \bigtriangledown J(\theta)\]</span></p><p>Where <span class="math inline">\(\bigtriangledown J(\theta)\)</span> is a column vector of the form:</p><p><span class="math display">\[\bigtriangledown J(\theta) = \begin{bmatrix}\frac{\partial J(\theta)}{\partial \theta_0}\\\frac{\partial J(\theta)}{\partial \theta_1}\\\vdots \\\frac{\partial J(\theta)}{\partial \theta_n}\\\end{bmatrix}\]</span></p><p>The j-th component of the gradient is the summation of the product of two terms: <span class="math display">\[\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\sum^m_{i = 1}(h_\theta(x^{(i)}) - y^{(i)}) x^{(i)}_j\]</span></p><p>Sometimes, the summation of the product of two terms can be expressed as the product of two vectors.</p><p>Here, the term <span class="math inline">\(x^{(i)}_j\)</span> represents the <span class="math inline">\(m\)</span> elements of the j-th column <span class="math inline">\(\overrightarrow {x_j}\)</span> (j-th feature <span class="math inline">\(\overrightarrow {x_j}\)</span>) of the training set <span class="math inline">\(X\)</span>.</p><p>The other term <span class="math inline">\((h_\theta(x^{(i)}) - y^{(i)})\)</span> is the vector of the deviations between the predictions <span class="math inline">\(h_\theta(x^{(i)})\)</span> and the true values <span class="math inline">\(y^{(i)}\)</span> . Re-writing <span class="math inline">\(\frac{\partial J(\theta)}{\partial \theta_j}\)</span> , we have: <span class="math display">\[\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\overrightarrow{x_j}^T(X\theta - \overrightarrow{y})\]</span> <span class="math display">\[\bigtriangledown J(\theta) = \frac{1}{m}X^T(X\theta - \overrightarrow{y})\]</span></p><p>Finally, the matrix notation (vectorized) of the Gradient Descent rule is: <span class="math display">\[\theta := \theta - \frac{\alpha}{m}X^T(X\theta - \overrightarrow{y})\]</span></p><h2><span id="feature-normalization">Feature Normalization</span></h2><p>We can speed up gradient descent by having each of our input values in roughly the same range. This is because <span class="math inline">\(\theta\)</span> will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven.</p><p>The way to prevent this is to modify the ranges of our input variables so that they are all roughly the same. Ideally: <span class="math inline">\(-1 \le x_i \le 1\)</span> or <span class="math inline">\(-0.5 \le x_i \le 0.5\)</span></p><p>These aren't exact requirements; we are only trying to speed things up. The goal is to get all input variables into roughly one of these ranges, give or take a few.</p><p>Two techniques to help with this are <strong>feature scaling</strong> and <strong>mean normalization</strong>. * Feature scaling involves dividing the input values by the range (i.e. the maximum value minus the minimum value) of the input variable, resulting in a new range of just 1. * Mean normalization involves subtracting the average value for an input variable from the values for that input variable, resulting in a new average value for the input variable of just zero.</p><p>To implement both of these techniques, adjust your input values as shown in this formula: <span class="math display">\[x_i := \frac{x_i - \mu_i}{s_i}\]</span></p><p>Where <span class="math inline">\(\mu_i\)</span> is the <strong>average</strong> of all the values and <span class="math inline">\(s_i\)</span> is the maximum of the range of values <em>minus</em> the minimum or is the <em>standard deviation</em>.</p><p><strong>Example</strong>: <span class="math inline">\(x_i\)</span> is housing prices in range 100-2000. Then, <span class="math inline">\(x_i := \frac{price - 1000}{1900}\)</span>, where 1000 is the average price and 1900 is the maximum (2000) minus the minimum (100).</p><h2><span id="gradient-descent-tips">Gradient Descent Tips</span></h2><p><strong>Debugging gradient descent</strong> Make a plot with <strong>number of iterations</strong> on the x-axis. Now plot the cost function, <span class="math inline">\(J(\theta)\)</span> over the number of iterations of gradient descent. If <span class="math inline">\(J(\theta)\)</span> ever increases, then you probably need to decrease <span class="math inline">\(\alpha\)</span>.</p><p><strong>Automatic convergence test</strong> Declare convergence if <span class="math inline">\(J(\theta)\)</span> decreases by less than <span class="math inline">\(\epsilon\)</span> in one iteration, where <span class="math inline">\(\epsilon\)</span> is some small value such as <span class="math inline">\(10^{-3}\)</span>. However in practice it's difficult to choose this threshold value.</p><p>It has been proven that if learning rate <span class="math inline">\(\alpha\)</span> is sufficiently small, then <span class="math inline">\(J(\theta)\)</span> will decrease on every iteration. <em>Andrew Ng</em> recommends decreasing <span class="math inline">\(\alpha\)</span> by multiples of 3.</p><h2><span id="features-and-polynomial-regression">Features and Polynomial Regression</span></h2><p>We can improve our features and the form of our hypothesis function in a couple different ways.</p><p>We can <strong>combine multiple features into one</strong>. For example, we can combine <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> into a new feature <span class="math inline">\(x_3\)</span> by taking <span class="math inline">\(x_1 \cdot x_2\)</span>.</p><h3><span id="polynomial-regression">Polynomial Regression</span></h3><p>Our hypothesis function need not be linear (a straight line) if that does not fit the data well.</p><p>We can <strong>change the behavior or curve</strong> of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).</p><p>For example, if our hypothesis function is <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1\)</span> then we can simply <strong>duplicate</strong> the instances of <span class="math inline">\(x_1\)</span> to get the quadratic function <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2\)</span> or the cubic function <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_1^2 + \theta_3x_1^3\)</span></p><p>In the cubic version, we have created new features <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span> where <span class="math inline">\(x_2 = x_1^2\)</span> and <span class="math inline">\(x_3 = x_1^3\)</span>.</p><p>To make it a square root function, we could do: <span class="math inline">\(h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2\sqrt{x_1}\)</span></p><p>One important thing to keep in mind is, if you choose your features this way then <strong>feature scaling</strong> becomes very important.</p><p>eg. if <span class="math inline">\(x_1\)</span> has range 1 - 1000 then <span class="math inline">\(x_1^2\)</span> range of becomes 1 - 1000000 and that of <span class="math inline">\(x_1^3\)</span> becomes 1 - 1000000000</p><h2><span id="normal-equation">Normal Equation</span></h2><p>The &quot;normal equation&quot; is a version of finding the optimum <strong>without iteration</strong>.</p><p>The <a href="http://www.wikiwand.com/zh-hans/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="noopener">proof</a> for this equation requires knowledge of linear algebra and is fairly involved, so you do not need to worry about the details.</p><p><span class="math display">\[\theta = (X^TX)^{-1}X^Ty\]</span></p><p>There is <strong>no need to do feature scaling</strong> with the normal equation.</p><p>The following is a comparison of gradient descent and the normal equation: | Gradient Descent | Normal Equation | | :--- | :--- | | Need to choose <span class="math inline">\(\alpha\)</span> | No need to choose <span class="math inline">\(\alpha\)</span> | | Needs many iterations | No need to iterate | | Works well when n is large | Slow if n is very large |</p><p>With the normal equation, computing the inversion has complexity <span class="math inline">\(O(n^3)\)</span>. So if we have a very large number of features, the normal equation will be slow. In practice, according to <em>A. Ng</em>, when <strong>n</strong> exceeds <strong>10,000</strong> it might be a good time to go from a normal solution to an iterative process.</p><h3><span id="normal-equation-demonstration">Normal Equation Demonstration</span></h3><ul><li><span class="math inline">\(\theta\)</span> is a <span class="math inline">\((n+1)\)</span> x <span class="math inline">\(1\)</span> matrix</li><li><span class="math inline">\(X\)</span> is a <span class="math inline">\(m\)</span> x <span class="math inline">\((n+1)\)</span> matrix so <span class="math inline">\(X^T\)</span> is a <span class="math inline">\((n+1)\)</span> x <span class="math inline">\(m\)</span> matrix</li><li><span class="math inline">\(\overrightarrow{y}\)</span> is a <span class="math inline">\(m\)</span> x <span class="math inline">\(1\)</span> vector</li></ul><p><span class="math inline">\(X\theta = \overrightarrow{y}\)</span> The point is to inverse <span class="math inline">\(X\)</span> , but as <span class="math inline">\(X\)</span> is not a square matrix we need to use <span class="math inline">\(X^T\)</span> to have a square matrix <span class="math inline">\((X^T)X\theta = (X^T)\overrightarrow{y}\)</span></p><p>Associative matrix multiplication <span class="math inline">\((X^TX)\theta = X^T\overrightarrow{y}\)</span> Assuming <span class="math inline">\((X^TX)\)</span> invertible <span class="math inline">\(\theta = (X^TX)^{-1}X^T\overrightarrow{y}\)</span></p><h3><span id="normal-equation-noninvertibility">Normal Equation Noninvertibility</span></h3><p>When implementing the normal equation in octave we want to use the <code>pinv</code> function rather than <code>inv</code>.</p><p><span class="math inline">\(X^TX\)</span> may be <strong>noninvertible</strong>. The common causes are: * Redundant features, where two features are very closely related (i.e. they are linearly dependent) * Too many features (e.g. <span class="math inline">\(m \le n\)</span>). In this case, delete some features or use &quot;<strong>regularization</strong>&quot; (to be explained in a later lesson).</p><p>Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Linear Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linear Regression with One Variable</title>
      <link href="/2016/01/30/Linear%20Regression%20with%20One%20Variable/"/>
      <url>/2016/01/30/Linear%20Regression%20with%20One%20Variable/</url>
      
        <content type="html"><![CDATA[<h2><span id="model-representation">Model Representation</span></h2><p>Recall that in <em>regression problems</em>, we are taking input variables and trying to map the output onto a <em>continuous</em> expected result function.</p><p>Linear regression with one variable is also known as &quot;<strong>univariate linear regression</strong>.&quot;</p><p>Univariate linear regression is used when you want to predict a <strong>single output</strong> value from a <strong>single input</strong> value. We're doing <strong>supervised learning</strong> here, so that means we already have an idea what the input/output cause and effect should be.</p><a id="more"></a><h2><span id="the-hypothesis-function">The Hypothesis Function</span></h2><p>Our hypothesis function has the general form:</p><p><span class="math inline">\(h_θ(x)=θ_0+θ_1x\)</span></p><p>We give to <span class="math inline">\(h_θ\)</span> values for <span class="math inline">\(θ_0\)</span> and <span class="math inline">\(θ_1\)</span> to get our output '<span class="math inline">\(y\)</span>'. In other words, we are trying to create a function called <span class="math inline">\(h_θ\)</span> that is able to reliably map our input data (the x's) to our output data (the y's).</p><p><strong>Example</strong>: | x (input) | y (output)| | :--- | :--- | | 0 | 4 | | 1 | 7 | | 2 | 7| | 3 | 8|</p><p>Now we can make a random guess about our <span class="math inline">\(h_θ\)</span> function: <span class="math inline">\(θ_0=2\)</span> and <span class="math inline">\(θ_1=2\)</span>. The hypothesis function becomes <span class="math inline">\(h_θ(x)=2+2x\)</span>.</p><p>So for input of 1 to our hypothesis, y will be 4. This is off by 3.</p><h2><span id="cost-function">Cost Function</span></h2><p>We can measure the accuracy of our hypothesis function by using a <strong>cost function</strong>. This takes an average (actually a fancier version of an average) of all the results of the hypothesis with inputs from x's compared to the actual output y's.</p><p><span class="math inline">\(J(θ_0,θ_1)=\frac{1}{2m}∑_{i=1}^{m}(h_θ(x_i)−y_i)^2\)</span></p><p>To break it apart, it is <span class="math inline">\(\frac{1}{2}\overline{x}\)</span> where <span class="math inline">\(\overline{x}\)</span> is the mean of the squares of <span class="math inline">\(h_θ(x_i) - y_i\)</span>, or the difference between the predicted value and the actual value.</p><p>This function is otherwise called the &quot;<strong>Squared error function</strong>&quot;, or <strong>Mean squared error</strong>(均方误差). The mean is halved <span class="math inline">\((\frac{1}{2m})\)</span> as a convenience for the computation of the <em>gradient descent</em>(梯度下降), as the derivative(导数) term of the square function will cancel out the <span class="math inline">\(\frac{1}{2}\)</span> term.</p><p>Now we are able to concretely measure the accuracy of our predictor function against the correct results we have so that we can predict new results we don't have.</p><figure><img src="/images/1454124395514.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="gradient-descent">Gradient Descent</span></h2><p>So we have our hypothesis function and we have a way of measuring how accurate it is. Now what we need is a way to automatically improve our hypothesis function. That's where gradient descent comes in.</p><p>Imagine that we graph our hypothesis function based on its fields <span class="math inline">\(θ_0\)</span> and <span class="math inline">\(θ_1\)</span> (actually we are graphing the cost function for the combinations of parameters). This can be kind of confusing; we are moving up to a higher level of abstraction. We are not graphing x and y itself, but the guesses of our hypothesis function.</p><p>We put <span class="math inline">\(θ_0\)</span> on the x axis and <span class="math inline">\(θ_1\)</span> on the z axis, with the cost function on the vertical y axis. The points on our graph will be the result of the <strong>cost function</strong> using our hypothesis with those specific theta parameters.</p><p>We will know that we have succeeded when our cost function is at the very bottom of the pits in our graph, i.e. when its value is the <em>minimum</em>.</p><p>The way we do this is by taking the <strong>derivative</strong> (the line tangent to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down that derivative by the parameter <span class="math inline">\(α\)</span>, called the <strong>learning rate</strong>.</p><p>The gradient descent equation is:</p><p><em>repeat until convergence(收敛):</em>{ <span class="math inline">\(θ_j : = θ_j − α \frac{∂}{∂θ_j}J(θ_0,θ_1)\)</span> <code>for j=0 and j=1</code> }</p><p>Intuitively, this could be thought of as:</p><p>repeat until convergence:{ <span class="math inline">\(θ_j : = θ_j − α\)</span>[Slope of tangent aka derivative] }</p><p><strong>Simultaneous update</strong></p><p><span class="math inline">\(temp0 := \theta - \alpha\frac{\partial}{\partial\theta_0}J(\theta_0, \theta_1)\)</span> <span class="math inline">\(temp1 := \theta - \alpha\frac{\partial}{\partial\theta_1}J(\theta_0, \theta_1)\)</span> <span class="math inline">\(\theta_0 := temp0\)</span> <span class="math inline">\(\theta_1 := temp1\)</span></p><p><strong>Learning rate <span class="math inline">\(\alpha\)</span></strong></p><figure><img src="/images/1454134071519.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="gradient-descent-for-linear-regression">Gradient Descent for Linear Regression</span></h2><p>When specifically applied to the case of linear regression, a new form of the gradient descent equation can be derived. We can substitute our actual cost function and our actual hypothesis function and modify the equation to (the derivation of the formulas are out of the scope of this course, but a really great one can be <a href="http://math.stackexchange.com/questions/70728/partial-derivative-in-gradient-descent-for-two-variables/189792#189792" target="_blank" rel="noopener">found here</a>:</p><p><em>repeat until convergence</em>: { <span class="math inline">\(θ_0 : = θ_0 − α\frac{1}{m}∑_{i=1}^{m}(h_θ(x_i)−y_i)\)</span> <span class="math inline">\(θ_1 : = θ_1 − α\frac{1}{m}∑_{i=1}^{m}(h_θ(x_i)−y_i)x_i\)</span> }</p><p>where <span class="math inline">\(m\)</span> is the size of the training set, <span class="math inline">\(θ_0\)</span> a constant that will be changing simultaneously with <span class="math inline">\(θ_1\)</span> and <span class="math inline">\(x_i,y_i\)</span> are values of the given training set.</p><p>Note that we have separated out the two cases for <span class="math inline">\(θ_j\)</span> and that for <span class="math inline">\(θ_1\)</span> we are multiplying <span class="math inline">\(x_i\)</span> at the end due to the derivative.</p><p>The point of all this is that if we start with a guess for our hypothesis and then repeatedly apply these gradient descent equations, our hypothesis will become more and more accurate.</p><p><strong>Batch Gradient Descent</strong></p><p>Batch : Each step of gradient descent uses all the training examples.</p><h2><span id="whats-next">What's Next</span></h2><p>Instead of using linear regression on just one input variable, we'll generalize and expand our concepts so that we can predict data with multiple input variables. Also, we'll solve for <span class="math inline">\(θ_0\)</span> and <span class="math inline">\(θ_1\)</span> exactly without needing an iterative function like gradient descent.</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Linear Regression </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Introduction to machine learning</title>
      <link href="/2016/01/29/Introduction%20to%20machine%20learning/"/>
      <url>/2016/01/29/Introduction%20to%20machine%20learning/</url>
      
        <content type="html"><![CDATA[<h2><span id="what-is-machine-learning">What is Machine Learning?</span></h2><p>Two definitions of Machine Learning are offered. Arthur Samuel described it as: &quot;the field of study that gives computers the ability to learn without being explicitly programmed.&quot; This is an older, informal definition.</p><blockquote><p>Tom Mitchell provides a more modern definition: &quot;A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.&quot;</p></blockquote><a id="more"></a><p><strong>Example: playing checkers.</strong></p><ul><li>E = the experience of playing many games of checkers</li><li>T = the task of playing checkers.</li><li>P = the probability that the program will win the next game.</li></ul><h2><span id="supervised-learning">Supervised Learning</span></h2><blockquote><p>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.</p></blockquote><p>Supervised learning problems are categorized into <strong>regression</strong> and <strong>classification</strong> problems. * In a <strong>regression</strong> problem, we are trying to predict results within a <strong>continuous</strong> output, meaning that we are trying to map input variables to some continuous function. * In a <strong>classification</strong> problem, we are instead trying to predict results in a <strong>discrete</strong> output. In other words, we are trying to <strong>map input variables into discrete categories</strong>.</p><p><strong>Example:</strong></p><p>Given data about the size of houses on the real estate market, try to predict their price. Price as a function of size is a <strong>continuous</strong> output, so this is a <strong>regression</strong> problem.</p><p>We could turn this example into a classification problem by instead making our output about whether the house &quot;<em>sells for more or less than the asking price.</em>&quot; Here we are classifying the houses based on price into two <strong>discrete</strong> categories.</p><h2><span id="unsupervised-learning">Unsupervised Learning</span></h2><blockquote><p>Unsupervised learning, on the other hand, allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.</p></blockquote><p>We can derive this structure by <strong>clustering</strong> the data based on relationships among the variables in the data.</p><p>With unsupervised learning there is no feedback based on the prediction results, i.e., there is no teacher to correct you. It’s not just about clustering. For example, associative memory is unsupervised learning.</p><p><strong>Example:</strong></p><p><strong>Clustering</strong>: Take a collection of 1000 essays written on the US Economy, and find a way to automatically group these essays into a small number that are somehow similar or related by different variables, such as word frequency, sentence length, page count, and so on.</p><p><strong>Associative</strong>: Suppose a doctor over years of experience forms associations in his mind between patient characteristics and illnesses that they have. If a new patient shows up then based on this patient’s characteristics such as symptoms, family medical history, physical attributes, mental outlook, etc the doctor associates possible illness or illnesses based on what the doctor has seen before with similar patients. This is not the same as rule based reasoning as in expert systems. In this case we would like to <em>estimate a mapping function from patient characteristics into illnesses</em>.</p><blockquote><p>From : https://www.coursera.org/learn/machine-learning/supplement/X64SM/introduction</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>记录：在 Docker 上配置 PHP 应用</title>
      <link href="/2016/01/17/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%9C%A8%20Docker%20%E4%B8%8A%E9%85%8D%E7%BD%AE%20PHP%20%E5%BA%94%E7%94%A8/"/>
      <url>/2016/01/17/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%9C%A8%20Docker%20%E4%B8%8A%E9%85%8D%E7%BD%AE%20PHP%20%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>什么是Docker</strong> docker的英文本意是码头工人，也就是搬运工，这种搬运工搬运的是集装箱（Container），集装箱里面装的可不是商品货物，而是任意类型的App，Docker把App（叫Payload）装在Container内，通过Linux Container技术的包装将App变成一种标准化的、可移植的、自管理的组件，这种组件可以在你的latop上开发、调试、运行，最终非常方便和一致地运行在production环境下。</p></blockquote><a id="more"></a><h2><span id="起">起</span></h2><p>起因是腾讯云的学生审核通过了，然后就花一块钱买了个服务器，就想在腾讯云上也配置下我的（前）博客，但是又不想每次都重新配置环境，于是就想到了Docker，折腾了两三天网站总算是可以跑了，这里记录一下踩坑过程。</p><blockquote><p>Docker的核心底层技术是LXC（Linux Container），Docker在其上面加了薄薄的一层，添加了许多有用的功能。<a href="http://stackoverflow.com/questions/17989306/what-does-docker-add-to-lxc-tools-the-userspace-lxc-tools" target="_blank" rel="noopener">这篇stackoverflow</a>上的问题和答案很好地诠释了Docker和LXC的区别，能够让你更好的了解什么是Docker， 简单翻译下就是以下几点： * Docker提供了一种可移植的配置标准化机制，允许你一致性地在不同的机器上运行同一个Container；而LXC本身可能因为不同机器的不同配置而无法方便地移植运行； Docker以App为中心，为应用的部署做了很多优化，而LXC的帮助脚本主要是聚焦于如何机器启动地更快和耗更少的内存； * Docker为App提供了一种自动化构建机制（Dockerfile），包括打包，基础设施依赖管理和安装等等； * Docker提供了一种类似git的Container版本化的机制，允许你对你创建过的容器进行版本管理，依靠这种机制，你还可以下载别人创建的Container，甚至像git那样进行合并； * Docker Container是可重用的，依赖于版本化机制，你很容易重用别人的Container（叫Image），作为基础版本进行扩展； * Docker Container是可共享的，有点类似github一样，* Docker有自己的INDEX，你可以创建自己的Docker用户并上传和下载Docker Image； * Docker提供了很多的工具链，形成了一个生态系统；这些工具的目标是自动化、个性化和集成化，包括对PAAS平台的支持等；</p></blockquote><hr><p>我之前其实是买过一本Docker的书的，但是还没来得及怎么看，这次突然要用就赶紧翻了翻，也Google了一下，发现了这个网站 : <a href="http://dockerpool.com/static/books/docker_practice/index.html" target="_blank" rel="noopener">Docker —— 从入门到实践</a>，结果发现书里的内容和这里基本一样，连名字也差不多，早知道就不买书了。</p><p>就这样开始了学习Docker之旅。</p><h2><span id="承">承</span></h2><p>我的网站环境是nginx+php+mysql，鉴于数据库还用原来服务器上的就好，所以只需要配置nginx与php。</p><p>这里有两个选项： * nginx和php放到一个docker里 * 把nginx和php分开放到两个docker里</p><p>前者明显看起来简单一些，因为不涉及容器互联等问题还省事，但其实这种将所有服务放在一个容器内的模式有个形象的非官方称呼：Fat Container。与之相对的是将服务分拆到容器的模式。从Docker的设计可以看到，构建镜像的过程中可以指定唯一一个容器启动的指令，<strong>因此Docker天然适合一个容器只运行一种服务</strong>，而这也是官方更推崇的。</p><p>由于我一开始并不知道一个docker只能运行一个服务，所以我选了第一种方案，然后就多踩了一个大坑。</p><p>当时遇到这么一个有趣的现象：我用Dockerfile创建镜像，Dockerfile最后包含这么两条启动服务的命令 <figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"nginx"</span>]</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"php-fpm"</span>]</span></span><br></pre></td></tr></table></figure></p><p>nginx天生就是后台服务，而php-fpm一这种方式可以前台运行，看起来这种组合挺好，容器启动之后也不会立刻终止，而是一直在运行，但是访问不了网站！！</p><p>这是为什么呢？ 因为nginx在最后那个容器里没有启动，具体为什么没有启动我也不是很清楚，这也就是说Docker天然适合一个容器只运行一种服务的原因吧。可是如果只保留nginx的话，也会因为它是后台运行所以容器刚运行就会停止。</p><p>然后我就好奇别人的nginx是怎么运行的。我就看了看<a href="https://hub.docker.com/_/nginx/" target="_blank" rel="noopener">nginx的官方镜像</a>，再它的dockerfile最后写的是： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</span><br></pre></td></tr></table></figure></p><p>查了查然后知道通过这个参数可以让nginx前台运行，而不会使容器直接停止。</p><p>然后我就把Dockerfile修改成这样： <figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"php-fpm"</span>]</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"nginx"</span>, <span class="string">"-g"</span>, <span class="string">"daemon off;"</span>]</span></span><br></pre></td></tr></table></figure></p><p>大家应该也看出来了，这样就喜闻乐见地解析不了php了。</p><h2><span id="转">转</span></h2><p>接着我就好奇别人的集成好多服务的docker是怎么启动的，google到了几个这样的应用，然后就发现了<a href="http://supervisord.org/" target="_blank" rel="noopener">supervisord</a>，这个东东是一个进程管理器，可以完美解决上述问题，只需一个配置文件： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[supervisord]</span><br><span class="line">nodaemon=true</span><br><span class="line"></span><br><span class="line">[program:php-fpm]</span><br><span class="line">command=php-fpm</span><br><span class="line"></span><br><span class="line">[program:nginx]</span><br><span class="line">command=nginx</span><br></pre></td></tr></table></figure></p><p>配置和启动命令就可以写成： <figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ADD</span><span class="bash"> ./supervisord.conf /etc/supervisord.conf</span></span><br><span class="line"><span class="bash">CMD [<span class="string">"supervisord"</span>]</span></span><br></pre></td></tr></table></figure></p><h2><span id="合">合</span></h2><p>这样困扰我好久的问题就解决了。不过这只是我踩到的总多坑的其中之一，算是比较大的一个，也是稍微有点分享价值的一个，相比这个问题的解决方案而言，解决这个问题的过程更有价值一些吧，故在此记录一下。</p><p>ps : 还有个小坑也值得注意一下，我用centos7作为基础镜像，通过yum安装的php不自带mysqli模块，需要手动安装<code>RUN yum install -y php-mysqli</code>，这个当时找问题也找了好久。</p><blockquote><p><strong>参考</strong> http://dockerpool.com/static/books/docker_practice/index.html http://tech.uc.cn/?p=2726 http://avnpc.com/pages/build-php-develop-env-by-docker</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后台开发 </tag>
            
            <tag> PHP </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>TCP/IP 浅析</title>
      <link href="/2016/01/10/IP%20%E6%B5%85%E6%9E%90/"/>
      <url>/2016/01/10/IP%20%E6%B5%85%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#建立tcp连接的过程">建立TCP连接的过程</a></li><li><a href="#tcp传输的过程">TCP传输的过程</a></li><li><a href="#结束连接">结束连接</a></li><li><a href="#tcp数据传输不同于udp之处">TCP数据传输不同于UDP之处</a></li><li><a href="#tcp连接的各种状态">tcp连接的各种状态</a></li><li><a href="#实践部分">实践部分</a><ul><li><a href="#抓包">抓包</a></li><li><a href="#socket-服务器">Socket 服务器</a></li></ul></li></ul><!-- tocstop --><a id="more"></a><h2><span id="建立tcp连接的过程">建立TCP连接的过程</span></h2><p><strong>三路握手</strong></p><p><img src="/images/1452307217663.png"></p><blockquote><p>TCP用三路握手（three-way handshake）过程创建一个连接。在连接创建过程中，很多参数要被初始化，例如序号被初始化以保证按序传输和连接的强壮性。</p></blockquote><p>一对终端同时初始化一个它们之间的连接是可能的。但通常是由一端打开一个套接字（socket）然后监听来自另一方的连接，这就是通常所指的被动打开（passive open）。服务器端被被动打开以后，用户端就能开始创建主动打开（active open）。</p><ol type="1"><li>客户端通过向服务器端发送一个<code>SYN</code>来创建一个主动打开，作为三路握手的一部分。客户端把这段连接的序号设定为随机数 <strong>A</strong>。</li><li>服务器端应当为一个合法的<code>SYN</code>回送一个<code>SYN/ACK</code>。<code>ACK</code> 的确认码应为 <strong>A+1</strong>，<code>SYN/ACK</code> 包本身又有一个随机序号 <strong>B</strong>。</li><li>最后，客户端再发送一个<code>ACK</code>。当服务端受到这个<code>ACK</code>的时候，就完成了三路握手，并进入了连接创建状态。此时包序号被设定为收到的确认号 <strong>A+1</strong>，而响应则为 <strong>B+1</strong>。</li></ol><p><a href="https://neymarl.github.io/2016/01/02/Wireshark%20%E6%8A%93%E5%8C%85%E6%8C%87%E5%8D%97/#tcp-%E4%B8%89%E8%B7%AF%E6%8F%A1%E6%89%8B%E5%88%86%E6%9E%90" target="_blank" rel="noopener">实例参看这里</a></p><h2><span id="tcp传输的过程">TCP传输的过程</span></h2><p><strong>序列号和确认</strong></p><p>在TCP的连接创建状态，两个主机的TCP层间要交换<strong>初始序号（ISN:initial sequence number）</strong>。这些序号用于标识字节流中的数据，并且还是<strong>对应用层的数据字节进行记数</strong>的整数。</p><p>通常在每个TCP报文段中都有一对序号和确认号。<strong>TCP报文发送者认为自己的字节编号为序号，而认为接收者的字节编号为确认号。</strong></p><p>TCP报文的接收者为了确保可靠性，在接收到一定数量的连续字节流后才发送确认。这是对TCP的一种扩展，通常称为<strong>选择确认（Selective Acknowledgement）</strong>。选择确认使得TCP接收者可以对乱序到达的数据块进行确认。<strong>每一个字节传输过后，ISN号都会递增1。</strong></p><p>通过使用序号和确认号，TCP层可以把收到的报文段中的字节按正确的顺序交付给应用层。序号是32位的无符号数，在它增大到232-1时，便会回绕到0。对于ISN的选择是TCP中关键的一个操作，它可以确保强壮性和安全性。</p><p><strong>数据传输实例</strong></p><p>打开Wireshark抓包，然后浏览器输入 http://www.liuhe.website，等加载完毕停止抓包。</p><p>找到<img src="/images/1452309211801.png">这条HTTP请求，然后Follow TCP stream，得到如图所示界面： <img src="/images/1452309279437.png"></p><p>前面三条TCP报文是三路握手建立TCP连接的过程，紧接着客户端发送第一个包含序列号1和766字节数据的报文给服务器。 <img src="/images/1452309404266.png"></p><p>服务器接收到TCP报文之后返回一条确认报文，该报文内只有报头，没有数据，用确认号767来表示已完全收到。如图所示： <img src="/images/1452313151381.png"></p><p>然后服务器继续发送HTTP响应，TCP报文包含序列号1和201字节数据，如下图所示： <img src="/images/1452313422647.png"></p><p>客户端以一个没有数据的TCP报文段来回复（只含报头），用确认号202来表示已完全收到并请求下一个报文段。 <img src="/images/1452314346326.png"></p><p>就这样一直继续下去直到数据传输完毕。</p><hr><p>然而当这些数据包都是相连的情况下，接收方没有必要每一次都回应。比如，他收到第1到5条TCP报文段，只需回应第五条就行了。如果第3条TCP报文段被丢失了，尽管他收到了第4和5条，然而他只能回应第2条。 发送方在发送了第三条以后，没能收到回应，因此当时钟（timer）过时（expire）时，他重发第三条。（每次发送者发送一条TCP报文段后，都会再次启动一次时钟：RTT）。 <img src="/images/1452314666698.png"></p><h2><span id="结束连接">结束连接</span></h2><p>连接终止使用了<strong>四路握手过程（four-way handshake）</strong>，在这个过程中每个终端的连接都能独立地被终止。因此，一个典型的拆接过程需要每个终端都提供一对<code>FIN</code>和<code>ACK</code>。</p><p><img src="/images/1452314985544.png"></p><p>不过我在抓包时发现关闭连接时是服务器发送了ACK和FIN，然后客户端返回ACK确认关闭，可能是客户端第一个发出来的FIN没抓到还是怎么回事不太清楚。 <img src="/images/1452315669659.png"></p><p>##与Unix sock文件的区别</p><p>Unix domain socket 或者 IPC socket是一种终端，可以使同一台操作系统上的两个或多个进程进行数据通信。与Internet socket不同的是，它<strong>不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等</strong>，只是将应用层数据从一个进程拷贝到另一个进程。</p><p>Unix domain sockets 使用系统文件的地址来作为自己的身份。它可以被系统进程引用。所以两个进程可以同时打开一个Unix domain sockets来进行通信。不过<strong>这种通信方式是发生在系统内核里而不会在网络里传播</strong>。</p><h2><span id="tcp数据传输不同于udp之处">TCP数据传输不同于UDP之处</span></h2><ul><li>有序数据传输</li><li>重发丢失的数据包</li><li>舍弃重复的数据包</li><li>无错误数据传输</li><li>阻塞/流量控制</li><li>面向连接（确认有创建三方交握，连接已创建才作传输。）</li></ul><h2><span id="tcp连接的各种状态">tcp连接的各种状态</span></h2><p>下面为 TCP 状态码列表，以 S 指代服务器，C 指代客户端，S&amp;C 表示两者，S/C 表示两者之一：[1]</p><ul><li><strong>LISTEN</strong> S 等待从任意远程 TCP 端口的连接请求。侦听状态。</li><li><strong>SYN-SENT</strong> C 在发送连接请求后等待匹配的连接请求。通过<code>connect()</code>函数向服务器发出一个同步（SYNC）信号后进入此状态。</li><li><strong>SYN-RECEIVED</strong> S 已经收到并发送同步（SYNC）信号之后等待确认（ACK）请求。</li><li><strong>ESTABLISHED</strong> S&amp;C 连接已经打开，收到的数据可以发送给用户。数据传输步骤的正常情况。此时连接两端是平等的。</li><li><strong>FIN-WAIT-1</strong> S&amp;C 主动关闭端调用<code>close()</code>函数发出FIN请求包，表示本方的数据发送全部结束，等待TCP连接另一端的确认包或FIN请求包。</li><li><strong>FIN-WAIT-2</strong> S&amp;C 主动关闭端在FIN-WAIT-1状态下收到确认包，进入等待远程 TCP 的连接终止请求的半关闭状态。这时可以接收数据，但不再发送数据。</li><li><strong>CLOSE-WAIT</strong> S&amp;C 被动关闭端接到FIN后，就发出ACK以回应FIN请求，并进入等待本地用户的连接终止请求的半关闭状态。这时可以发送数据，但不再接收数据。</li><li><strong>CLOSING</strong> S&amp;C 在发出FIN后，又收到对方发来的FIN后，进入等待对方对连接终止（FIN）的确认（ACK）的状态。少见。</li><li><strong>LAST-ACK</strong> S&amp;C 被动关闭端全部数据发送完成之后，向主动关闭端发送FIN，进入等待确认包的状态。</li><li><strong>TIME-WAIT</strong> S/C 主动关闭端接收到FIN后，就发送ACK包，等待足够时间以确保被动关闭端收到了终止请求的确认包。【按照 RFC 793，一个连接可以在 TIME-WAIT 保证最大四分钟，即最大分段寿命（maximum segment lifetime）的2倍】</li><li><strong>CLOSED</strong> S&amp;C 完全没有连接。</li></ul><p><strong>TCP状态转换图解</strong> <img src="/images/1452349572799.png"> 上图描述了 TCP 的11种状态的转换关系。 * 图中的圆角矩形表示状态，箭头表示状态之间的转换。 * 图中用粗线表示客户端主动和被动的服务器端建立连接的正常过程： * <strong>客户端的状态变迁用粗实线</strong> * <strong>服务器端的状态变迁用粗虚线</strong> * 细线用于不常见的序列，如复位、同时打开、同时关闭等。 * 图中的每条状态变换线上均标有<strong>“事件／动作”</strong>： * 事件是指用户执行了系统调用（ CONNECT 、 LISTEN 、 SEND 或 CLOSE ）、收到一个报文段（ SYN 、 FIN 、 ACK 或 RST ）、或者是出现了超过两倍最大的分组生命期的情况； * 动作是指发送一个报文段（ SYN 、 FIN 或 ACK ）或什么也没有（用“－”表示）。</p><p><strong>粗实线表示客户的正常路径；粗虚线表示服务器的正常路径；细线表示不常见的事件。</strong>每个连接均开始于 CLOSED 状态。当一方执行了被动的连接原语（ LISTEN ）或主动的连接原语（ CONNECT ）时，它便会脱离 CLOSED 状态。如果此时另一方执行了相对应的连接原语，连接便建立了，并且状态变为 ESTABLISHED 。任何一方均可以首先请求释放连接，当连接被释放后，状态又回到了 CLOSED 。</p><p><strong>正常状态转换过程</strong></p><ol type="1"><li>服务器端首先执行 LISTEN 原语进入被动打开状态（ LISTEN ），等待客户端连接；</li><li>当客户端的一个应用程序发出 CONNECT 命令后，本地的 TCP 实体为其创建一个连接记录并标记为 SYN SENT 状态，然后给服务器发送一个 SYN 报文段；</li><li>服务器收到一个 SYN 报文段，其 TCP 实体给客户端发送确认 ACK 报文段同时发送一个 SYN 信号，进入 SYN RCVD 状态；</li><li>客户端收到 SYN + ACK 报文段，其 TCP 实体给服务器端发送出三次握手的最后一个 ACK 报文段，并转换为 ESTABLISHED 状态；</li><li>服务器端收到确认的 ACK 报文段，完成了三次握手，于是也进入 ESTABLISHED 状态。 在此状态下，双方可以自由传输数据。当一个应用程序完成数据传输任务后，它需要关闭 TCP 连接。假设仍由客户端发起主动关闭连接。</li><li>客户端执行 CLOSE 原语，本地的 TCP 实体发送一个 FIN 报文段并等待响应的确认（进入状态 FIN WAIT 1 ）；</li><li>服务器收到一个 FIN 报文段，它确认客户端的请求发回一个 ACK 报文段，进入 CLOSE WAIT 状态；</li><li>客户端收到确认 ACK 报文段，就转移到 FIN WAIT 2 状态，此时连接在一个方向上就断开了；</li><li>服务器端应用得到通告后，也执行 CLOSE 原语关闭另一个方向的连接，其本地 TCP 实体向客户端发送一个 FIN 报文段，并进入 LAST ACK 状态，等待最后一个 ACK 确认报文段；</li><li>客户端收到 FIN 报文段并确认，进入 TIMED WAIT 状态，此时双方连接均已经断开，但 TCP 要等待一个 2 倍报文段最大生存时间 MSL （ Maximum Segment Lifetime ），确保该连接的所有分组全部消失，以防止出现确认丢失的情况。当定时器超时后， TCP 删除该连接记录，返回到初始状态（ CLOSED ）。</li><li>服务器收到最后一个确认 ACK 报文段，其 TCP 实体便释放该连接，并删除连接记录，返回到初始状态（ CLOSED ）。</li></ol><p><del>关于操作系统怎么维护内核还为找到相关资料</del></p><h2><span id="实践部分">实践部分</span></h2><h3><span id="抓包">抓包</span></h3><p>关于Wireshark抓包详见<a href="http://www.liuhe.website/index.php?/Articles/single/20" target="_blank" rel="noopener">这里</a></p><h3><span id="socket-服务器">Socket 服务器</span></h3><p>用python写的简单Socket服务器，实现了如下功能： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">绑定一个本地端口</span><br><span class="line">在浏览器中访问http://localhost:&lt;your_port&gt;/hello</span><br><span class="line">显示一个hello world</span><br><span class="line"></span><br><span class="line">在浏览器中访问http://localhost:&lt;your_port&gt;/info?name=xxx&amp;age=xxx</span><br><span class="line">显示hello, I&apos;m &lt;name_in_the_url&gt; and xxx years old.</span><br><span class="line"></span><br><span class="line">通过postman表单提交http://localhost:&lt;your_port&gt;/form</span><br><span class="line">数据</span><br><span class="line">username=xxx</span><br><span class="line">password=xxx</span><br><span class="line">可以简单的存储，也可以不存储</span><br><span class="line">直接在网页上显示出来</span><br><span class="line">I&apos;m &lt;username_posted&gt; and my password is &lt;password_posted&gt;</span><br></pre></td></tr></table></figure></p><p>主要代码如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">class SimpleSocketServer:</span><br><span class="line">    def __init__(self, addr, bufsize):</span><br><span class="line">        self.s = socket(AF_INET, SOCK_STREAM)   # 网络通信, TCP</span><br><span class="line">        self.s.bind(addr)                       # 绑定的IP与端口</span><br><span class="line">        self.s.listen(5)                        # 开始TCP监听, 并指定最多允许多少个客户连接到服务器</span><br><span class="line">        self.GET = &#123;&#125;   # 存储GET的参数</span><br><span class="line">        self.POST = &#123;&#125;  # 存储POST的参数</span><br><span class="line">        self.bufsize = bufsize</span><br><span class="line"></span><br><span class="line">    def __del__(self):</span><br><span class="line">        self.s.close()</span><br><span class="line"></span><br><span class="line">    def listen(self):</span><br><span class="line">        while True:</span><br><span class="line">            self.GET = &#123;&#125;    # 初始化为空字典</span><br><span class="line">            self.POST = &#123;&#125;</span><br><span class="line">            print &apos;Waiting for connection...&apos;</span><br><span class="line">            conn, addr = self.s.accept()    # 接受TCP连接，并返回新的套接字与IP地址</span><br><span class="line">            print &apos;Connected by &apos;, addr     # 输出客户端的IP地址</span><br><span class="line">            data = conn.recv(self.bufsize)  # 接收数据</span><br><span class="line">            self.response(data, conn)</span><br><span class="line">            conn.close()</span><br><span class="line"></span><br><span class="line">    def response(self, data, conn):</span><br><span class="line">        print data</span><br><span class="line">        if self.isGET(data):    # 判断方法是GET还是POST</span><br><span class="line">            str = self.what(data, &apos;GET&apos;)   # 获取HTTP请求路径</span><br><span class="line">            if str == &apos;hello&apos;:</span><br><span class="line">                conn.send(&apos;Hello World!&apos;)</span><br><span class="line">            elif str == &apos;info&apos;:</span><br><span class="line">                if not &apos;name&apos; in self.GET or not &apos;age&apos; in self.GET:</span><br><span class="line">                    conn.send(&apos;What the fuck !&apos;) # 错误信息</span><br><span class="line">                else:</span><br><span class="line">                    conn.send(&quot;hello, I&apos;m &quot; + self.GET[&apos;name&apos;] + &quot; and &quot;</span><br><span class="line">                              + self.GET[&apos;age&apos;] + &quot; years old.&quot;)</span><br><span class="line">        elif self.isPOST(data):</span><br><span class="line">            str = self.what(data, &apos;POST&apos;)</span><br><span class="line">            if str == &apos;form&apos;:</span><br><span class="line">                if not &apos;username&apos; in self.POST or not &apos;password&apos; in self.POST:</span><br><span class="line">                    conn.send(&apos;What the fuck !&apos;)</span><br><span class="line">                else:</span><br><span class="line">                    conn.send(&quot;I&apos;m &quot; + self.POST[&apos;username&apos;] + &quot; and my password is &quot; + self.POST[&apos;password&apos;] + &quot;.&quot;)</span><br><span class="line"></span><br><span class="line">    def what(self, data, method=&apos;GET&apos;):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">解析HTTP请求路径和参数，返回路径，参数存在GET或POST字典里</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        i = 0</span><br><span class="line">        # find &apos;/&apos;</span><br><span class="line">        while i &lt; len(data):</span><br><span class="line">            if data[i] == &apos;/&apos;:</span><br><span class="line">                break</span><br><span class="line">            i += 1</span><br><span class="line">        str = &apos;&apos;</span><br><span class="line">        i = i + 1</span><br><span class="line">        while i &lt; len(data) and data[i] != &apos; &apos; and data[i] != &apos;?&apos;:</span><br><span class="line">            str += data[i]</span><br><span class="line">            i += 1</span><br><span class="line">        if(data[i] == &apos;?&apos;):</span><br><span class="line">            i += 1</span><br><span class="line">        while i &lt; len(data) and data[i] != &apos; &apos;:</span><br><span class="line">            key = &apos;&apos;</span><br><span class="line">            value = &apos;&apos;</span><br><span class="line">            # get key</span><br><span class="line">            while i &lt; len(data) and data[i] != &apos; &apos; and data[i] != &apos;=&apos;:</span><br><span class="line">                key += data[i]</span><br><span class="line">                i += 1</span><br><span class="line">            if data[i] != &apos;=&apos;:</span><br><span class="line">                break</span><br><span class="line">            i += 1</span><br><span class="line">            # get value</span><br><span class="line">            while i &lt; len(data) and data[i] != &apos; &apos; and data[i] != &apos;&amp;&apos;:</span><br><span class="line">                value += data[i]</span><br><span class="line">                i += 1</span><br><span class="line">            if value:</span><br><span class="line">                self.GET[key] = value</span><br><span class="line">                if method == &apos;POST&apos;:</span><br><span class="line">                    self.POST[key] = value</span><br><span class="line">            if data[i] == &apos;&amp;&apos;:</span><br><span class="line">                i += 1</span><br><span class="line">        return str</span><br><span class="line"></span><br><span class="line">    def isGET(self, data):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">判断是否为GET请求</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        if data[0] == &apos;G&apos; and data[1] == &apos;E&apos; and data[2] == &apos;T&apos;:</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            return False</span><br><span class="line"></span><br><span class="line">    def isPOST(self, data):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">判断是否为POST请求</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">        if data[0] == &apos;P&apos; and data[1] == &apos;O&apos;:</span><br><span class="line">            return True</span><br><span class="line">        else:</span><br><span class="line">            return False</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP/IP </tag>
            
            <tag> 计算机网络 </tag>
            
            <tag> 后台开发 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>海量数据挖掘（三）：Finding Similar Sets</title>
      <link href="/2016/01/04/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AFinding%20Similar%20Sets/"/>
      <url>/2016/01/04/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9AFinding%20Similar%20Sets/</url>
      
        <content type="html"><![CDATA[<blockquote><p>此系列为Cousera上Standford的<a href="https://class.coursera.org/mmds-002" target="_blank" rel="noopener">Mining Massive Datasets</a>课程学习笔记。 这是该系列的第三篇笔记：<strong>Finding Similar Sets</strong></p></blockquote><a id="more"></a><!-- toc --><ul><li><a href="#应用介绍-applications">应用介绍 Applications</a><ul><li><a href="#相似文档-similar-documents">相似文档 Similar Documents</a></li></ul></li><li><a href="#shingles">Shingles</a><ul><li><a href="#shingles-和相似度的关系">Shingles 和相似度的关系</a></li><li><a href="#压缩">压缩</a></li></ul></li><li><a href="#minhashing">Minhashing</a><ul><li><a href="#jaccard-similarity">Jaccard Similarity</a></li><li><a href="#from-sets-to-boolean-matrices">From Sets to Boolean Matrices</a></li><li><a href="#four-types-of-rows">Four Types of Rows</a></li><li><a href="#minhashing-1">Minhashing</a></li><li><a href="#性质">性质</a></li><li><a href="#minhashing-的实现">Minhashing 的实现</a></li></ul></li><li><a href="#locality-sensitive-hashing">Locality-Sensitive Hashing</a><ul><li><a href="#lsh">LSH</a><ul><li><a href="#lsh-for-minhashing-signatures">LSH for Minhashing Signatures</a></li></ul></li><li><a href="#hash-function-for-one-bucket">Hash Function for One Bucket</a></li><li><a href="#analysis-of-lsh">Analysis of LSH</a></li><li><a href="#lsh-summary">LSH Summary</a></li></ul></li><li><a href="#applications-of-lsh">Applications of LSH</a><ul><li><a href="#实体解析-entity-resolution">实体解析 Entity Resolution</a></li><li><a href="#指纹匹配-fingerprint-matching">指纹匹配 Fingerprint Matching</a></li><li><a href="#finding-duplicate-news-articles">Finding Duplicate News Articles</a></li></ul></li></ul><!-- tocstop --><h2><span id="应用介绍-applications">应用介绍 Applications</span></h2><p>许多数据挖掘的问题都可以被化为是找相似集的问题，比如： 1. 具有很多相似单词的页面可以被认为是相同的主题.. 2. 找具有相似品味的NetFlix(一家在世界多国提供网路随选串流影片的公司)用户，向他们推荐电影。 3. 实体解析(Entity resolution)</p><h3><span id="相似文档-similar-documents">相似文档 Similar Documents</span></h3><p>给定一堆文档，比如web页面，找到具有大量相同文字的文档对，可以用来发现： * 镜像站点。应用：网页去重 * 抄袭，包括大量引用。 * 来自不同的站点的相似的文章，比如多家媒体都报道某一事件。</p><p><strong>基本技术</strong></p><ol type="1"><li><strong>Shingling</strong> : 把文档，邮件等等转换成集合。</li><li><strong>Minhashing</strong> : 把大的集合转换成短的标志(signature)并且保持着相似性。</li><li><strong>Locality-sensitive hashing</strong> : 专注于可能相似的标志对儿(pairs of signature)。</li></ol><p><strong>图解</strong></p><p><img src="/images/1451286062856.png"></p><h2><span id="shingles">Shingles</span></h2><blockquote><p><strong>k-shingle</strong> 或 <strong>k-gram</strong> 是指文档中连续出现的 <strong>k</strong> 个字符构成的序列。</p></blockquote><p>举例说明： 给定 <code>k=2 , doc = abcab</code> 。 每两个字符构成一个shingle, 即： <code>ab</code>, <code>bc</code>, <code>ca</code>, <code>ab</code>，所以2-Shingles的集合就为：<code>{ab, bc, ca}</code></p><p>这样就可以用一个<code>k-shingles</code>的集合表示一个文档！</p><h3><span id="shingles-和相似度的关系">Shingles 和相似度的关系</span></h3><p>如果我们发想两个文档中有大量的shingles相同，那么这两个文档就是相似的而且很直观。</p><p>如果改变文档中的一个单词，只会影响这个单词前后<code>k</code>个字符的<code>k-shingles</code>。</p><p>如果重新把文档中的段落排序，只会影响段落边界周围的<code>2k</code>个<code>k-shingles</code>。</p><p><em>举例说明</em> <code>k = 3</code>， &quot;The dog which chased the cat&quot; <strong>vs</strong> &quot;The dog that chased the cat&quot;</p><p>第二句把第一句的<code>which</code>改成了<code>that</code>，处理之后之只有7个<code>3-shingles</code> 被替换了，分别是：<code>'g w'</code>, <code>' wh'</code>, <code>'whi'</code> , <code>'hic'</code>, <code>'ich'</code>, <code>'ch '</code>和 <code>'h c'</code>。</p><h3><span id="压缩">压缩</span></h3><p>值得注意的是，如果k取的比较大的话（比如比较论文通常取k=9），shingles会很长，就比较浪费空间了，我们可以把shingles通过hash操作变成一个整数（4个字节），我们管这个整数叫 <code>tokens</code>。之后就可以用一组<code>token</code>来表示一个文档了。</p><p>Two documents could (rarely) appear to have shingles in common, when in fact only the hash values were shared.</p><h2><span id="minhashing">Minhashing</span></h2><h3><span id="jaccard-similarity">Jaccard Similarity</span></h3><p>杰卡德相似系数</p><p>两个集合的Jaccard Similarity定义：交集除以并集。</p><blockquote><p><span class="math inline">\(Sim(C_1, C_2) =\frac{ |C_1 \cap C_2|} {|C_1 \cup C_2|}\)</span></p></blockquote><p><img src="/images/1451358527521.png"></p><p>比如上图，两个集合的交集为 <span class="math inline">\(3\)</span>，并集为 <span class="math inline">\(8\)</span>, 所以相似系数为：<span class="math inline">\(\frac{3}{8}\)</span></p><h3><span id="from-sets-to-boolean-matrices">From Sets to Boolean Matrices</span></h3><p>把集合转换成布尔矩阵</p><p>为了方便计算Jaccard Similarity，我们需要把集合转换成矩阵。</p><ul><li><p>矩阵的行表示集合中的各个元素，比如每个<code>k-shingles</code></p></li><li><p>矩阵的列表示各个集合，比如每个文档的<code>k-shingles</code>集合</p></li><li><p>如果行 <span class="math inline">\(e\)</span> 是列 <span class="math inline">\(S\)</span> 的一个成员，那么在<span class="math inline">\(e\)</span>行<span class="math inline">\(S\)</span>列的值为<span class="math inline">\(1\)</span>，否则为<span class="math inline">\(0\)</span></p></li><li><p>两列之间的相似度就是Jaccard 相似度。</p></li><li><p>通常情况下，这会是一个稀疏矩阵。</p></li></ul><p><strong>举个例子</strong> <img src="/images/1451359226406.png"></p><p>图中矩阵只有两列<span class="math inline">\(C_1\)</span>和<span class="math inline">\(C_2\)</span>，他们的相似度就等于都为<span class="math inline">\(1\)</span>的行除以至少有一个为<span class="math inline">\(1\)</span>的行，即： &gt; <span class="math inline">\(Sim(C_1, C_2) = 2/5 = 0.4\)</span></p><h3><span id="four-types-of-rows">Four Types of Rows</span></h3><p>给定两列<span class="math inline">\(C_1\)</span>和<span class="math inline">\(C_2\)</span>，我们定义一下四种类型的行： <img src="/images/1451359444350.png"></p><p>现在可以这么计算Jaccard相似度了：<span class="math inline">\(Sim(C_1, C_2) = \frac{a}{a + b + c}\)</span></p><h3><span id="minhashing">Minhashing</span></h3><p>假设行是随机排列的，定义 <span class="math inline">\(minhash\)</span> <span class="math inline">\(function\)</span> <span class="math inline">\(h(C)\)</span> = the number of the first (in the permuted order) row in which column C has 1 如果没看懂后面有例子。</p><p>通常用一些（比如100）独立的hash function来为每列创建<span class="math inline">\(Signature\)</span>。</p><p>这些signatures存储在一个<span class="math inline">\(signature\)</span> <span class="math inline">\(matrix\)</span>– whose columns represent the sets and the rows represent the minhash values, in order for that column.</p><p><strong>例子</strong></p><p>输入矩阵： <img src="/images/1451362719714.png"></p><p>上图右侧为输入矩阵，左侧为3组随机排列。</p><p>先看第一组（紫色的） * 排列的第一行是矩阵的第五行，该行第二列和第四列为<span class="math inline">\(1\)</span>, 其余为<span class="math inline">\(0\)</span>, 所以该组的minhash value为<code>0 1 0 1</code>; * 排列的第二行是矩阵的第六行，该行第一列和第三行为<span class="math inline">\(1\)</span>,其余为<span class="math inline">\(0\)</span>，所以minhash value的第二、四行不变，第一、三行改为当前行号，即：<code>2 1 2 1</code>; * 由于每列都非零，这组就结束了，最后的minhash value就是<code>2 1 2 1</code>。</p><p>在看第二组（黄色的） * 排列的第一行是矩阵的第三行，该行的第二列和第四列为<span class="math inline">\(1\)</span>，其余列为<span class="math inline">\(0\)</span>，所以minhash value的第二、四列变为当前行号，第一、三列不变，即：<code>0 1 0 1</code> * 排列的第二行是矩阵的第二行，该行第一、四列为<span class="math inline">\(1\)</span>，其余为<span class="math inline">\(0\)</span>，由于minhash value的第四列值不为0，所以第四列值不变，第一列值变为当前行好，即：<code>2 1 0 1</code> * 排列的第三行是矩阵的四行，该行第一、四列值为<span class="math inline">\(1\)</span>，而minhash value里的一、四列已不为0,所以没有变化，即还是：<code>2 1 0 1</code> * 排列的第四行是矩阵的第一行，该行第一、三列值为<span class="math inline">\(1\)</span>，所以minhash value的第三列变为当前行号，其余不变，即：<code>2 1 4 1</code></p><p>第三组留给读者自己练习，总体的标志矩阵(Signature matrix)就是： <img src="/images/1451363798021.png"></p><h3><span id="性质">性质</span></h3><p>所有排列的<span class="math inline">\(h(C_1) = h(C_2)\)</span>的概率等于这两列的Jaccard相似度： &gt; <span class="math inline">\(P(h(C_1) = h(C_2)) = Sim(C_1, C_2)\)</span></p><p>都等于<span class="math inline">\(\frac{a}{a+b+c}\)</span>！</p><p><strong>Why?</strong></p><p><span class="math inline">\(h(C_1) = h(C_2)\)</span>只有在a类型的行中出现，所以<span class="math inline">\(h(C_1) = h(C_2)\)</span>这个事件就相当于a类型的行出现，那么<span class="math inline">\(h(C_1) = h(C_2)\)</span>的概率就是a类型的行出现的概率，即<span class="math inline">\(\frac{a}{a+b+c}\)</span>。</p><p><strong>标志的相似度</strong></p><ul><li>The <strong>similarity of signatures</strong> is the fraction of the minhash functions in which they agree.<ul><li>Thinking of signatures as columns of integers, the similarity of signatures is the fraction of rows in which they agree.</li></ul></li><li>Thus, the expected similarity of two signatures equals the Jaccard similarity of the columns or sets that the signatures represent.<ul><li>And the longer the signatures, the smaller will be the expected error.</li></ul></li></ul><p><strong>Minhash的例子</strong> 输入矩阵和上面那个例子相同： <img src="./1451362719714.png" alt="Input Matrix"></p><p>得到标志矩阵： <img src="/images/1451363798021.png"></p><p>我们来计算一下实际的Jaccard相似度与Signature的相似度。</p><p>先看第一列和第二列，在输入矩阵中没有<span class="math inline">\(a\)</span>类型的行，所以Jaccard相似度为零; 在标志矩阵M中第一、二列也没有相同的一行，Signature相似度也为零。</p><p>再看第一、三列，输入矩阵中只有一行非<span class="math inline">\(a\)</span>类型，所以Jaccard相似度为<span class="math inline">\(0.75\)</span>; 而标志矩阵中有两行值相同，一行值不同，所以Signature相似度为<span class="math inline">\(0.67\)</span></p><p>同理第2、4列的Jaccard相似度为<span class="math inline">\(0.75\)</span>，Signature相似度为<span class="math inline">\(1.00\)</span></p><p>整理一下： | Similarity | 1-3 | 2-4 | 1-2| | :--- | :--- | :--- | :-- | |Jaccard | 0.75 | 0.75 | 0 | |Signature | 0.67 | 1.00 | 0 |</p><p>可见由于排列的组数较少还是有一定误差的。</p><h3><span id="minhashing-的实现">Minhashing 的实现</span></h3><p>困难： * 假设数据量非常大，比如十亿行; * 把十亿行做随机排列是不现实的，也没有必要。 * 不过就算是用之前的随机排列序列，要* 100个随机排列序列，每个序列有十亿个项，光存储这些序列就要大约40TB。 * 随机读取可能会导致系统抖动。</p><p>一个好的读取rows实践是准备很多（比如100个）hash function，避免生产序列。</p><p>对于每一列 <span class="math inline">\(c\)</span> 和每个hash function <span class="math inline">\(h_j\)</span>， 只存储一个值<span class="math inline">\(M(i, c)\)</span>。</p><p>目标是让 <span class="math inline">\(M(i, c)\)</span> 成为每个 <span class="math inline">\(h_i(r)\)</span> 的最小值， <span class="math inline">\(h_i(r)\)</span>等于<span class="math inline">\(r\)</span> where column c has 1 in row r * h i (r) gives order of rows for i th permutation</p><p><strong>具体算法</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for each row r do begin</span><br><span class="line">for each hash function h_i do</span><br><span class="line">compute h_i(r);</span><br><span class="line">for each column c</span><br><span class="line">if c has 1 in row r</span><br><span class="line">for each hash function h_i do</span><br><span class="line">if h_i(r) is samller than M(i, c) then</span><br><span class="line">M(i, c) = h_i(r)</span><br><span class="line">end;</span><br></pre></td></tr></table></figure><p>举例： <img src="/images/1451367036074.png"></p><p>输入矩阵如图所示，取两个hash function : <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">h(x) = x mod 5</span><br><span class="line">g(x) = (2x + 1) mod 5</span><br></pre></td></tr></table></figure></p><p>具体过程如下： <img src="/images/1451367200601.png"></p><p>最后的结果的相似度的 <span class="math inline">\(0\)</span>, 实际的Jaccard相似度是<span class="math inline">\(\frac{1}{5}\)</span> ## Locality-Sensitive Hashing 局部敏感哈希</p><h3><span id="lsh">LSH</span></h3><p>基本思想：Generate from the collection of all elements (signatures in our example) a small list of <strong>candidate pairs</strong>: pairs of elements whose similarity must be evaluated.</p><p>简单来说就是从我们Minhashing得到的标记矩阵生成可能相似的文档对列表。</p><p>候选相似文档对 =&gt; 这一对的Jaccard相似度必须被准确计算出来</p><p><strong>方法</strong></p><ul><li>选一个相似度标准 <span class="math inline">\(t\)</span>，并且 <span class="math inline">\(t &lt; 1\)</span>，如果两个文档的相似度大于 <span class="math inline">\(t\)</span>，则认为这两个文档相似。</li><li>如果列<span class="math inline">\(c\)</span>和列<span class="math inline">\(d\)</span>被视为候选文档对，那么他们一定要满足 <span class="math inline">\(M(i, c) = M(i, d) &gt;= t\)</span> ，其中<span class="math inline">\(M\)</span>是标记矩阵。</li></ul><h4><span id="lsh-for-minhashing-signatures">LSH for Minhashing Signatures</span></h4><p><strong>总体思想</strong>：把标记矩阵里的hash很多遍，只有hash到同一个桶(bucket)里的列才被认为是可能相似的。</p><p><strong>Partion Into Bands</strong></p><p><img src="/images/1451568313351.png"></p><p>如图所示，把标记矩阵的所有行分成 <span class="math inline">\(b\)</span> 个<em>带(bands)</em>，每个带有 <span class="math inline">\(r\)</span> 行。对于每条带，对带里面每列进行hash，分别hash到k个桶中，并让k尽可能得大。</p><p>只有有&gt;=1的band哈希到同一个桶中，就把这两列当作候选相似对。</p><h3><span id="hash-function-for-one-bucket">Hash Function for One Bucket</span></h3><p><img src="/images/1451568830329.png"></p><p><strong>Example - Bands</strong></p><p>假设有 100,000 列，每列有100个标记，因此存储标记需要40MB; 我们希望找到所以相似度大于80%的文档对，用上面的方法，把标记分为20个带，每个带里有5个标记。</p><p>这样的话，如果文档<span class="math inline">\(C_1\)</span>和<span class="math inline">\(C_2\)</span>的相似度是<strong>80%</strong>，那么他们的任意一个带的5个标记都相同的概率是: <span class="math inline">\((0.8)^5 = 0.328\)</span> ，看起来好像不大，但是只要有任意一个带都相同就被认为是候选对，所以他们不被选上的概率，即20个带都不相同的概率为：<span class="math inline">\((1-0.328)^{20} = 0.00035\)</span>，也就是<strong>每3000个相似度为80%的文档对里才会有一对漏选</strong>。</p><p>我们再考虑文档<span class="math inline">\(C_1\)</span>和<span class="math inline">\(C_2\)</span>只有<strong>40%</strong>的相似度，那么他们任意一个带的5个标记都相同的概率为 <span class="math inline">\((0.4)^5 = 0.01\)</span>，则文档<span class="math inline">\(C_1\)</span>和<span class="math inline">\(C_2\)</span>被选为候选对的概率，即他们中有一个带完全相同的概率为: $C_{20}^1 × 0.01 = 0.2 $，就是说每5个40%相似度的文档对里就有一对会被误选为候选对。<strong>但是</strong>相似度小于40%的文档对里误选的概率就非常小了。</p><h3><span id="analysis-of-lsh">Analysis of LSH</span></h3><figure><img src="./1451629865035.png" alt="What We Want"><figcaption>What We Want</figcaption></figure><p>我们希望LSH达到的效果是相似度在我们设定的阈值之下的文档对都不被选进候选文档对，而在其之上的文档对都选进来，<strong>不误选一个也不错选一个</strong>，这是最理想的情况，我们的目标就是向它靠拢。</p><p>如果不使用分带的方法，直接一行一行的看，会出现下图所示的问题： <img src="/images/1451630150113.png"></p><p>这个图纵向是标记完全相同的概率，横向是相似度，由于相似度等于标记(minhash value)相同的概率，所以实际曲线就是这个矩形的对角线，与理想状况的曲线相差甚远，可见误差是非常大的。</p><p>如果把所有行分成b带，每个带有r行，那么曲线如下图所示： <img src="/images/1451631757641.png"></p><p>可以得到在阈值 <span class="math inline">\(t\)</span> 约等于 <span class="math inline">\((\frac{1}{b})^{\frac{1}{r}}\)</span> 时，曲线与理想状态颇为接近，误差非常小。</p><p>数值举例：<span class="math inline">\(b = 20, r = 5\)</span> <img src="/images/1451631969408.png"></p><p>可见文档相似度在70%以上是很容易被选进的，在40%一下是很难选进的，如果阈值定在70%的话且文档相似度分布比较均匀的和误差会很小。</p><h3><span id="lsh-summary">LSH Summary</span></h3><p>Tune to <strong>get</strong> almost all pairs with similar signatures, but <strong>eliminate</strong> most pairs that do not have similar signatures.</p><p><strong>Check</strong> that candidate pairs really do have similar signatures.</p><p><em>Optional</em>: In another pass through data, check that the remaining candidate pairs really represent similar <em>sets</em> . ## Applications of LSH</p><h3><span id="实体解析-entity-resolution">实体解析 Entity Resolution</span></h3><blockquote><p><strong>实体解析(Entity Resolution)</strong>是通过检测记录来判断这些记录是否来自同一个实体。实体可以是人、公司、事件等等。</p></blockquote><p><strong>Typically</strong>, we want to merge records if their values in corresponding fields are similar.</p><p><strong>Matching Customer Records</strong></p><p>这门课的老师曾经应用LSH解决过一个实际问题，这个问题大概是这样：有两个公司A和B，公司A答应把一部分顾客拉拢到公司B，然后B给A一定的费用，一开始挺好，可是好景不长，他们就开始争论到底有多少顾客是从A公司过去的，为此吵得不可开交。</p><p><strong>任务</strong>就是通过两个公司的数据库判断有多少顾客是从A公司过去的。</p><p>注：同一个顾客在两个公司的数据里可能会有一些偏差，比如电话号码变了或者地址变了或者一个用的是小名另一个用的是全名等等。</p><p><strong>现状</strong> 每个公司大概有1百万条记录描述的顾客可能是被A公司送到B公司的。每条记录包括名字、住址和电话，但是处于种种原因，出自同一个人的记录也可能不完全相同(原因如上)。</p><p><strong>方案</strong> 1. 定一个量度。比如每对记录有300分的相似度，每个属性100分。两条记录具有相同的地址和电话但是名字拼写有小的差别，这种就给290分，如果名字区别很大可能就是240分等。</p><ol start="2" type="1"><li>把经过LSH筛选的所有候选记录的分数算出来，分高的就认为是同一个人。</li></ol><p><strong>问题</strong></p><p>需要计算 <span class="math inline">\((1 × 10^6)^2\)</span> 对个分数值，太大了。</p><p><strong>解决方法 : A Simple LSH</strong></p><p>定义3个哈希函数，分别 hash 名字、地址和电话。如果三个属性有一个是相同的就把具体分数算出来。</p><p>这种方法也会丢失一些每个属性的有点小区别的记录对，不过没关系，概率非常小。</p><p><em>额外</em> &gt; <em>How do we hash strings such as names so there is one bucket for each string?</em> <strong>Answer</strong> : Sort the strings instead.</p><h3><span id="指纹匹配-fingerprint-matching">指纹匹配 Fingerprint Matching</span></h3><p><strong>指纹的存储方法</strong> 用一系列<strong>细节特征(minutiae)</strong>代表一个指纹。 * These are features of a fingerprint, e.g., points where two ridges come together or a ridge ends.</p><p><strong>LSH for Fingerprints</strong></p><p>把网格铺在指纹上，相同的指纹会重合。具有细节特征(minutiae)的方格的集合就可以表示一个指纹。另外，treat minutiae near a grid boundary as if also present in adjacent grid points.</p><p><img src="/images/1451741534631.png"></p><p><strong>把LSH应用到指纹匹配</strong></p><ul><li>指纹 = 方格的集合</li><li>不需要minhash，因为方格数不是很多，而且也不是稀疏矩阵</li><li>用一个<strong>位向量(bit-vector)</strong>表示一个指纹：如果那个方格有minutiae，则这个位的值是1。这种方法相对于直接存整数节省了很多空间。</li><li>随机从位向量中取3个集合，每个集合有3个方格（3位）。</li><li>对于每一个集合，只有三位全部为1才被认为是Candidate Pairs 。</li><li>Funny sort of ‘bucketization.”</li></ul><p>拿一个例子说明算法的效果。</p><p><strong>假设</strong> 一般的只有有20%的格子有minutiae，如果两个指纹来自同一个手指，那么他们应该有80%的方格是相同的。</p><p><strong>计算</strong> 任意两个指纹集合在三个格子内都有minutiae的概率为 <span class="math inline">\((0.2)^6 = 0.000064\)</span></p><p>来自同一个手指的两个指纹集合在三个格子内都有minutiae的概率为 <span class="math inline">\(((0.2)(0.8))^3 = 0.004096\)</span></p><p>在1024个集合中至少有一个集合满足上述要求的概率为 <span class="math inline">\(1 - (1 - 0.004096)^{1024} = 0.985\)</span></p><p>不是来自同一个手指但是被选上的概率为 <span class="math inline">\(1-(1-0.000064)^{1024} = 0.063\)</span>，也就是有6.3%的概率误选，并不是很理想，不过我们可以通过增加集合里的方格数，比如变成4或5个，来降低误选率。</p><h3><span id="finding-duplicate-news-articles">Finding Duplicate News Articles</span></h3><p><strong>Problem</strong> : the same article, say from the Associated Press, appears on the Web site of many newspapers, but looks quite different.</p><p>与找相似文档不同的地方在于： * 每份新闻有自己的logo和语言描述 * 不同的广告 * 可能还有到其他文章的链接 * 也可能对原始文章进行了删减</p><p><strong>Special Shingling Technique</strong></p><p>通过观察可以发现，新闻正文中会出现很多停用词(stop words)，然而广告中却没有。</p><p><a href="http://www.wikiwand.com/zh-hans/%E5%81%9C%E7%94%A8%E8%AF%8D" target="_blank" rel="noopener">停用词</a>就是没什么实际含义的词，比如： “<strong>I</strong> recommend <strong>that you</strong> buy Sudzo <strong>for your</strong> laundry.” 停用词就是加粗的那些。如果是广告的话可能就只有 “Buy Sudzo” 了。</p><p>这个特殊的Shingling就是选停用词以及它后面的两个词作为Shingles，拿上面那就话举例，shingles就是 <code>I recommend that</code>、<code>that you buy</code>、<code>you buy Sudzo</code>等等。</p><p><strong>Why it Works</strong></p><ul><li>By requiring each shingle to have a stop word, they biased the mapping from documents to shingles so it picked more shingles from the article than from the ads.</li><li>Pages with the same article, but different ads, have higher Jaccard similarity than those with the same ads, different articles.</li></ul><p><strong>Enter LSH</strong></p><ul><li>Their first attempt at minhashing was very inefficient.</li><li>They were unaware of the importance of doing the minhashing row by row.</li><li>Since their data was column by column, they needed to sort once before minhashing.</li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据挖掘 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Wireshark 抓包指南</title>
      <link href="/2016/01/02/Wireshark%20%E6%8A%93%E5%8C%85%E6%8C%87%E5%8D%97/"/>
      <url>/2016/01/02/Wireshark%20%E6%8A%93%E5%8C%85%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#wireshark-介绍">Wireshark 介绍</a></li><li><a href="#wireshark-开始抓包">Wireshark 开始抓包</a></li><li><a href="#wireshark-窗口介绍">Wireshark 窗口介绍</a></li><li><a href="#wireshark-过滤器">Wireshark 过滤器</a><ul><li><a href="#捕捉过滤器">捕捉过滤器</a></li><li><a href="#显示过滤器">显示过滤器</a></li></ul></li><li><a href="#封包列表">封包列表</a></li><li><a href="#tcp-包解析">TCP 包解析</a></li><li><a href="#tcp-三路握手分析">TCP 三路握手分析</a></li><li><a href="#参考">参考</a></li></ul><!-- tocstop --><a id="more"></a><h2><span id="wireshark-介绍">Wireshark 介绍</span></h2><p>Wireshark是非常流行的网络封包分析软件，功能十分强大。可以截取各种网络封包，显示网络封包的详细信息。 <a href="http://www.wireshark.org/" target="_blank" rel="noopener">官方下载地址</a></p><h2><span id="wireshark-开始抓包">Wireshark 开始抓包</span></h2><p>ps：在Linux上运行Wireshark抓包可能会遇到权限问题，<a href="https://wiki.wireshark.org/CaptureSetup" target="_blank" rel="noopener">解决方案可以参考这里</a></p><p>开始界面： <img src="/images/1451724415086.png"></p><p>选择你正在用的网卡，然后点菜单中的鲨鱼图标就可以进行抓包了！</p><h2><span id="wireshark-窗口介绍">Wireshark 窗口介绍</span></h2><p><img src="/images/1451724570752.png"></p><p>WireShark 主要分为这几个界面</p><ol type="1"><li><p>Display Filter(显示过滤器)， 用于过滤</p></li><li><p>Packet List Pane(封包列表)， 显示捕获到的封包， 有源地址和目标地址，端口号。 颜色不同，代表</p></li><li><p>Packet Details Pane(封包详细信息), 显示封包中的字段</p></li><li><p>Dissector Pane(16进制数据)</p></li><li><p>Miscellanous(地址栏，杂项)</p></li></ol><h2><span id="wireshark-过滤器">Wireshark 过滤器</span></h2><p>Wireshark有两种过滤器，分别是<strong>显示过滤器</strong>与<strong>捕捉过滤器</strong>。</p><p><strong>区别</strong> * 捕捉过滤器（CaptureFilters）：用于决定将什么样的信息记录在捕捉结果中。需要在开始捕捉前设置。 * 显示过滤器（DisplayFilters）：在捕捉结果中进行详细查找。他们可以在得到捕捉结果后随意修改。</p><p><strong>两种过滤器的目的是不同的。</strong> * 捕捉过滤器是数据经过的第一层过滤器，它用于控制捕捉数据的数量，以避免产生过大的日志文件。 * 显示过滤器是一种更为强大（复杂）的过滤器。它允许您在日志文件中迅速准确地找到所需要的记录。</p><h3><span id="捕捉过滤器">捕捉过滤器</span></h3><p><img src="/images/1451724862160.png"></p><ul><li><p><strong>Protocol</strong>（协议）: 可能的值: <code>ether, fddi, ip, arp, rarp, decnet, lat, sca, moprc, mopdl, tcp and udp</code>. 如果没有特别指明是什么协议，则默认使用所有支持的协议。</p></li><li><p><strong>Direction</strong>（方向）: 可能的值: <code>src, dst, src and dst, src or dst</code> 如果没有特别指明来源或目的地，则默认使用 <code>src or dst</code> 作为关键字。 例如， <code>host 10.2.2.2</code> 与 <code>src or dst host 10.2.2.2</code> 是一样的。</p></li><li><p><strong>Host(s)</strong>: 可能的值： <code>net, port, host, portrange</code>. 如果没有指定此值，则默认使用<code>host</code>关键字。 例如，<code>src 10.1.1.1</code>与<code>src host 10.1.1.1</code>相同。</p></li><li><p><strong>Logical Operations</strong>（逻辑运算）: 可能的值：<code>not, and, or</code>. 否(<code>not</code>)具有最高的优先级。或(<code>or</code>)和与(<code>and</code>)具有相同的优先级，运算时从左至右进行。 例如， <code>not tcp port 3128 and tcp port 23</code> 与 <code>(not tcp port 3128) and tcp port 23</code>相同。 <code>not tcp port 3128 and tcp port 23</code> 与 <code>not (tcp port 3128 and tcp port 23)</code>不同。</p></li></ul><p>例子： * <code>tcp dst port 3128</code> //捕捉目的TCP端口为<code>3128</code>的封包。 * <code>ip src host 10.1.1.1</code> //捕捉来源IP地址为<code>10.1.1.1</code>的封包。 * <code>host 10.1.2.3</code> //捕捉目的或来源IP地址为<code>10.1.2.3</code>的封包。 * <code>ether host e0-05-c5-44-b1-3c</code> //捕捉目的或来源MAC地址为<code>e0-05-c5-44-b1-3c</code>的封包。如果你想抓本机与所有外网通讯的数据包时，可以将这里的mac地址换成路由的mac地址即可。 * <code>src portrange 2000-2500</code> //捕捉来源为UDP或TCP，并且端口号在<code>2000</code>至<code>2500</code>范围内的封包。 * <code>not imcp</code> //显示除了icmp以外的所有封包。（icmp通常被ping工具使用） * <code>src host 10.7.2.12 and not dst net 10.200.0.0/16</code> //显示来源IP地址为<code>10.7.2.12</code>，但目的地不是<code>10.200.0.0/16</code>的封包。 * <code>(src host 10.4.1.12 or src net 10.6.0.0/16) and tcp dst portrange 200-10000 and dst net 10.0.0.0/8</code> //捕捉来源IP为<code>10.4.1.12</code>或者来源网络为<code>10.6.0.0/16</code>，目的地TCP端口号在<code>200</code>至<code>10000</code>之间，并且目的位于网络 <code>10.0.0.0/8</code>内的所有封包。 * <code>src net 192.168.0.0 mask 255.255.255.0</code> //捕捉源地址为<code>192.168.0.0</code>网络内的所有封包。</p><h3><span id="显示过滤器">显示过滤器</span></h3><p><img src="/images/1451725452855.png"></p><p>实例： <img src="/images/1451725468174.png"></p><p><strong>过滤表达式的规则</strong></p><p>表达式规则</p><ol type="1"><li><p><strong>协议过滤</strong> 比如TCP，只显示TCP协议。</p></li><li><p><strong>IP 过滤</strong> 比如 <code>ip.src ==192.168.1.102</code> 显示源地址为192.168.1.102， <code>ip.dst==192.168.1.102</code>, 目标地址为192.168.1.102</p></li><li><p><strong>端口过滤</strong> <code>tcp.port ==80</code>, 端口为80的 <code>tcp.srcport == 80</code>, 只显示TCP协议的愿端口为80的。</p></li><li><p><strong>Http模式过滤</strong> http.request.method==&quot;GET&quot;, 只显示HTTP GET方法的。</p></li></ol><h2><span id="封包列表">封包列表</span></h2><p>封包列表的面板中显示，编号，时间戳，源地址，目标地址，协议，长度，以及封包信息。 你可以看到不同的协议用了不同的颜色显示。</p><p>你也可以修改这些显示颜色的规则， View -&gt;Coloring Rules.</p><p><img src="/images/1451725740486.png"></p><p><strong>详细信息</strong></p><p>这个面板是我们最重要的，用来查看协议中的每一个字段。</p><p>各行信息分别为 * <strong>Frame</strong>: 物理层的数据帧概况 * <strong>Ethernet II</strong>: 数据链路层以太网帧头部信息 * <strong>Internet Protocol Version 4</strong>: 互联网层IP包头部信息 * <strong>Transmission Control Protocol</strong>: 传输层T的数据段头部信息，此处是TCP * <strong>Hypertext Transfer Protocol</strong>: 应用层的信息，此处是HTTP协议</p><p><strong>对应的OSI七层模型</strong> <img src="/images/1451725855652.png"></p><h2><span id="tcp-包解析">TCP 包解析</span></h2><p>从下图可以看到wireshark捕获到的TCP包中的每个字段。</p><p><img src="/images/1451725951459.png"></p><h2><span id="tcp-三路握手分析">TCP 三路握手分析</span></h2><p>三路握手的过程为：</p><p><img src="/images/1451726004003.png"></p><p>我们用wireshark实际分析下三次握手的过程</p><p>打开wireshark, 开始抓包后打开浏览器输入 http://www.liuhe.website</p><p>在wireshark中输入http过滤， 然后选中Destination为<code>139.129.38.159</code> 且 <code>GET / HTTP/1.1</code>的那条记录，右键然后点击 “对话过滤器-&gt;TCP”.</p><p>这样做的目的是为了得到与浏览器打开网站相关的数据包，将得到如下图 <img src="/images/1451726264665.png"></p><p>图中可以看到wireshark截获到了三次握手的三个数据包。第四个包才是HTTP的， 这说明HTTP的确是使用TCP建立连接的。</p><p><strong>第一次握手</strong> 客户端通过向服务器端发送一个<code>SYN</code>来创建一个主动打开，作为三路握手的一部分。客户端把这段连接的序号设定为随机数<strong>A</strong>。</p><p><img src="/images/1451726663334.png"></p><p><strong>第二次握手</strong> 服务器端应当为一个合法的<code>SYN</code>回送一个<code>SYN/ACK</code>。<code>ACK</code> 的确认码应为 <strong>A+1</strong>，<code>SYN/ACK</code> 包本身又有一个随机序号 <strong>B</strong>。</p><p><img src="/images/1451726946164.png"></p><p><strong>第三次握手</strong> 最后，客户端再发送一个<code>ACK</code>。当服务端受到这个<code>ACK</code>的时候，就完成了三路握手，并进入了连接创建状态。此时包序号被设定为收到的确认号 <strong>A+1</strong>，而响应则为 <strong>B+1</strong>。</p><p><img src="/images/1451727158983.png"></p><p>就这样通过了TCP三次握手，建立了连接。</p><h2><span id="参考">参考</span></h2><p><a href="http://www.cnblogs.com/tankxiao/archive/2012/10/10/2711777.html#start" target="_blank" rel="noopener">Wireshark基本介绍和学习TCP三次握手</a></p><p><a href="http://fangxin.blog.51cto.com/1125131/735178" target="_blank" rel="noopener">Wireshark抓包工具使用教程以及常用抓包规则</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机网络 </tag>
            
            <tag> 后台开发 </tag>
            
            <tag> Wireshark </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>C++关于对象传值与传引用的总结</title>
      <link href="/2015/12/28/C++%E5%85%B3%E4%BA%8E%E5%AF%B9%E8%B1%A1%E4%BC%A0%E5%80%BC%E4%B8%8E%E4%BC%A0%E5%BC%95%E7%94%A8%E7%9A%84%E6%80%BB%E7%BB%93/"/>
      <url>/2015/12/28/C++%E5%85%B3%E4%BA%8E%E5%AF%B9%E8%B1%A1%E4%BC%A0%E5%80%BC%E4%B8%8E%E4%BC%A0%E5%BC%95%E7%94%A8%E7%9A%84%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2><span id="传值vs传引用">传值VS传引用</span></h2><p>C++在传递<strong>对象类型</strong>的参数时候有两种情况：</p><ul><li>如果是引用就相当于直接把这个对象本身传递过去了</li><li>若是传值则需在进入函数之前通过<strong>拷贝构造函数</strong>建立一个临时对象（如果没有自己写拷贝构造函数则是<strong>浅拷贝</strong>），然后再离开函数之后这个临时对象会自动销毁（调用了<strong>析构函数</strong>）</li></ul><a id="more"></a><h3><span id="深拷贝vs浅拷贝">深拷贝VS浅拷贝</span></h3><p>浅拷贝即<strong>直接复制</strong>对象里的字段 ##### 深拷贝是如果该字段不是指针则直接复制，若是指针则新申请一块内存空间复制指针指向的内容</p><h2><span id="不要在拷贝构造函数里修改源对象">不要在拷贝构造函数里修改源对象</span></h2><p>这点我觉得尤其重要。 之所以这么说是因为拷贝构造函数的调用<strong>不是那么可控的</strong>,不像普通函数一样，只要你不主动调用就不会执行。<strong>拷贝构造函数很可能在你不知道的地方会被调用</strong>，比如上述<strong>函数传值</strong>。若是在调用拷贝构造函数的时候改变了源对象很可能会造成意想不到的结果，除非你考虑得很周全，确认所以会调用拷贝构造函数的地方都需要改变源对象。 所以推荐写拷贝构造函数的时候加上<code>const</code>： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Object(<span class="keyword">const</span> Object&amp; obj);</span><br></pre></td></tr></table></figure></p><h2><span id="拷贝构造函数的调用">拷贝构造函数的调用</span></h2><h4><span id="拷贝构造函数不是所有对象的赋值都会调用只有再创建对象的时候赋值才会调用">拷贝构造函数不是所有对象的赋值都会调用，只有再创建对象的时候赋值才会调用！！！</span></h4><p>比如： <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    A()&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"A!"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    A(A&amp; a)&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Copy"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    A a;        <span class="comment">// A!</span></span><br><span class="line">    A b = a;    <span class="comment">// Copy</span></span><br><span class="line">    A c;        <span class="comment">// A!</span></span><br><span class="line">    c = a;      <span class="comment">// 不输出</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>上述代码输出 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A!</span><br><span class="line">Copy</span><br><span class="line">A!</span><br></pre></td></tr></table></figure></p><p>可见只会在<code>A b = a</code>这句话的时候调用拷贝构造函数，而下面的<code>c = a</code>则不会调用！</p><p>那么问题来了： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class A</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    A()&#123;</span><br><span class="line">        cout &lt;&lt; &quot;A!&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    A(A&amp; a)&#123;</span><br><span class="line">        cout &lt;&lt; &quot;Copy&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">class B</span><br><span class="line">&#123;</span><br><span class="line">public:</span><br><span class="line">    B()&#123;</span><br><span class="line">        cout &lt;&lt; &quot;B!&quot; &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    B(const A&amp; a)&#123;</span><br><span class="line">        cout &lt;&lt; &quot;B(A)!&quot; &lt;&lt; endl;</span><br><span class="line">        this-&gt;a = a;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    A a;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    A a;        // A!</span><br><span class="line">    B b1;       // A! B!</span><br><span class="line">    b1.a = a;   // </span><br><span class="line">    B b2(a);    // A! B(A)!</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>程序输出如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A!</span><br><span class="line">A!</span><br><span class="line">B!</span><br><span class="line">A!</span><br><span class="line">B(A)!</span><br></pre></td></tr></table></figure></p><p>我们来分析一下： 执行<code>A a</code>调用构造函数输出<code>A!</code></p><p>继续执行<code>B b1</code>先调用A的构造函数再调用B的构造函数输出<code>A! B!</code></p><p>继续执行<code>b1.a = a</code>给b1里的a赋值，<strong>这句话没有输出</strong>，也就是说<strong>没有调用A的拷贝构造函数</strong>，这是一个<strong>浅拷贝</strong>。</p><p>继续执行<code>B b2(a)</code>，调用B的有参构造函数并在构造函数里给a赋值，输出<code>A! B(A)!</code>，没有输出<code>Copy</code>，说明也<strong>没有调用A的拷贝构造函数</strong>，也是一个<strong>浅拷贝</strong>。</p><p>那如果A中有复杂的指针类型字段，我想执行<strong>深拷贝</strong>该怎么办呢？</p><p>我只想到一个不是很聪明的解决办法： 可以用先通过<strong>拷贝构造函数</strong>构造一个A对象<strong>（深拷贝）</strong>，再把它的值赋给B里的A对象<strong>（浅拷贝）</strong>，具体代码如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    A a;                // A!</span><br><span class="line">    </span><br><span class="line">    A* t = new A(a);    // Copy</span><br><span class="line">    B b;                // A! B!</span><br><span class="line">    b.a = *t;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>输出： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A!</span><br><span class="line">Copy</span><br><span class="line">A!</span><br><span class="line">B!</span><br></pre></td></tr></table></figure></p><p>这样做可以使<code>b.a</code>达到<strong>深拷贝</strong>的目的，即<code>b.a</code>和<code>a</code>里的指针指向不同的内存地址，而地址上存储的值是一样的。之所以用<code>new</code>一个指针而不是直接创建变量是因为<code>new</code>出的空间可以存活整个程序运行期间存活，而直接创建变量的话可能会因为函数返回而消失。这里的<code>t</code>只是一个中介，之后也不要对其进行操作，会影响到<code>b.a</code>里的指针字段指向的值。</p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>海量数据挖掘（二）：Link Analysis and PageRank</title>
      <link href="/2015/12/27/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ALink%20Analysis%20and%20PageRank/"/>
      <url>/2015/12/27/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9ALink%20Analysis%20and%20PageRank/</url>
      
        <content type="html"><![CDATA[<blockquote><p>此系列为Cousera上Standford的<a href="https://class.coursera.org/mmds-002" target="_blank" rel="noopener">Mining Massive Datasets</a>课程学习笔记。 这是该系列的第二篇笔记：<strong>Link Analysis and PageRank</strong></p></blockquote><a id="more"></a><h2><span id="链接分析-link-analysis">链接分析 Link Analysis</span></h2><h3><span id="图类数据-graph-data">图类数据 Graph Data</span></h3><figure><img src="/images/1450882068603.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>图由一组节点和一组边组成，根据边有没有方向可以分为有向图和无向图。</p><p>社交网络可以用图来描述、媒体网络可以用图来描述、信息网络也可以用图来描述、互联网更可以用图来描述！ <img src="/images/1450882333263.png" alt="Alt text"></p><p>Web也可以看作一张图。</p><h3><span id="web-as-a-graph">Web as a Graph</span></h3><ul><li>Web 可以看作一个有向图<ul><li>节点： 网页</li><li>边 ： 超链接</li></ul></li></ul><p>Web网络图举例：</p><figure><img src="/images/1450882695999.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h3><span id="how-to-organize-the-web">How to organize the Web?</span></h3><p>早些时候，互联网刚起步的时代，人们手动组织<strong>网页目录(Web directories)</strong>，像雅虎、DMOZ等。</p><p>现在都是采用<strong>网页搜索(Web Search)</strong>的形式，信息检索办法: 在一个小的、可信任的页面集合中寻找相关的网页。</p><p><strong>但是</strong>， Web非常大，林子大了什么鸟都有，充满不可信任的的网页、奇怪的东西、垃圾邮件等。</p><blockquote><p><strong>做Web搜索有两大挑战</strong>： 1. 该信任哪些网页？ 2. 什么是最好结果？</p></blockquote><p>对于第一点，可以认为<strong>可信任的页面里的链接一般都互相指向</strong>，这样就可以确定大部分的可信任网页，但并不是绝对的。 对于第二点，在搜索引擎上搜索的绝大部分都是没有最好的答案的，怎么提供用户最想要的答案是个问题。</p><h3><span id="ranking-nodes-on-the-graph">Ranking Nodes on the Graph</span></h3><p><strong>不是所有网页都一样“重要“！</strong> 比如：https://www.baidu.com/ vs http://www.liuhe.website/ 很容易判断熟轻熟重。</p><p>在Web这个图里，每个节点相连的边数差异很大！</p><p>链接分析算法简介： <img src="/images/1450884497971.png" alt="Alt text"></p><h2><span id="pagerank">PageRank</span></h2><h3><span id="the-quotflowquot-formulation">The &quot;Flow&quot; Formulation</span></h3><blockquote><p>计算节点（网页）权重的想法：<strong>把链接当作权重（Links as votes）</strong></p></blockquote><p>基本想法是这样的，<strong>如果一个网页很重要，那么指向它和它指向别的网页的链接应该很多</strong>。有一个问题就是考虑指向它的链接还是它指出去的链接呢？</p><p>如果考虑指出去的链接的话，那只要大家都在自己的网页上放一大堆链接就可以提高PageRank了，这样并不能反应一个网站的重要程度，所以我们<strong>考虑指向该网页的链接</strong>。</p><p>那么还有一个问题，是不是所有指向你的链接都一样重要？？ 显然不是！ 如果Google首页有指向你的链接，你的流量很可能就会爆增，但是<a href="www.liuhe.website">我的首页</a>如果加上指向你的链接可能并不会带来什么流量。</p><p>所以每个链接带来的权重是不一样的，<strong>来自重要的网站的链接权重应该更高些</strong>。</p><p>一个例子： <img src="/images/1450923574723.png" alt="一个例子"></p><h3><span id="简单的递归公式">简单的递归公式</span></h3><p>每个链接的权重与其源网站的重要程度成比例。</p><p>设页面 <span class="math inline">\(j\)</span> 的权重为 <span class="math inline">\(r_j\)</span> ，该页有 <span class="math inline">\(n\)</span> 个指向其他页面的链接，那么，每个链接给那个网站带来的权重为 $ r_j / n $ 。</p><p>页面 <span class="math inline">\(j\)</span> 自己的权重来自所有指向它的链接的权重之和。</p><p>很简单吧？这就是&quot;Flow&quot;模型。</p><figure><img src="/images/1450924042138.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>我们尝试解一下上图中的方程组，即： $ r_y = r_y / 2 + r_a / 2 $ $ r_a = r_y / 2 + r_m $ $ r_m = r_a / 2 $</p><p>发现解并不唯一，只能解得两两之间的关系，原因在于方程组里没有常数，我们还需要加一个条件： $ r_y + r_a + r_m = 1 $</p><p>这样解得：$ r_y = , r_a = , r_m =  $</p><p>像这种小规模例子我们可以直接用高斯消元法球解，但是像web这么大的图肯定不可能人工求解，我们需要一个更好的计算方法。</p><h3><span id="matrix-formulation">Matrix Formulation</span></h3><blockquote><p>警告：以下内容会涉及线性代数以及概率论。</p></blockquote><p>我们用邻接矩阵 <span class="math inline">\(M\)</span> 来表示图，设页面 <span class="math inline">\(i\)</span> 有 $ d_i $ 个外链，如果 $ i -&gt; j $ ，那么 $ M_{ji} =  $ 否则 $ M_{ji} = 0 $ 其中 <span class="math inline">\(M\)</span> 是一个列随机矩阵，每列的和等于1.</p><p>我们再用一个向量 <span class="math inline">\(r\)</span> 来表示所有页面的PageRank，$ r_i $ 是页面 <span class="math inline">\(i\)</span> 的得分，并且 $ _i r_i = 1 $</p><p>现在，上节的方程($ r_j = _{i j}  $)就可以该写成： $  = M  $</p><p>用个例子解释一下： 假设页面 <span class="math inline">\(i\)</span> 链向3个页面，包括 <span class="math inline">\(j\)</span> ，如图所示： <img src="/images/1450973732761.png" alt="Alt text"></p><p>矩阵乘法是这样的，结果矩阵的 <span class="math inline">\([i, j]\)</span> 元素是 $A_{i0} * B_{0j} + A_{i1} * B_{1i} + ... + A_{in} * B_{nj} $ 得到的。 <img src="/images/1450973811824.png" alt="Alt text"></p><p>所以 <span class="math inline">\(M\)</span> 在与 $r $ 相乘的结果也是一个列向量，这个列向量第 <span class="math inline">\(i\)</span> 个元素的值就等于矩阵 <span class="math inline">\(M\)</span> 的第 <span class="math inline">\(j\)</span> 行乘以 <span class="math inline">\(\vec r\)</span> ，数学表达式就是 $ r_j = <em>{k=0}^{n} M</em>{jk}*r_i $，由邻接矩阵所表示的意义可知，这与之前的Flow Equation是等效的。</p><p>一个例子： <img src="/images/1451041071423.png" alt="Alt text"></p><h3><span id="特征向量公式">特征向量公式</span></h3><p>我们先来复习一下什么是特征值(eigenvalue)和特征向量(eigenvector)。</p><blockquote><p>如果表达式：$ A x = x $ 成立，则称<span class="math inline">\(\vec x\)</span>为矩阵<span class="math inline">\(A\)</span>的特征向量， <span class="math inline">\(\lambda\)</span>为矩阵<span class="math inline">\(A\)</span>的特征值，其中 <span class="math inline">\(\vec x\)</span>是任意向量， <span class="math inline">\(\lambda\)</span>是常数。</p></blockquote><p>之前得到的矩阵公式为：<span class="math inline">\(\vec r = M \cdot \vec r\)</span>，正好是符合上述表达式，矩阵<span class="math inline">\(M\)</span>的特征向量就是<span class="math inline">\(\vec r\)</span>，特征值就是<span class="math inline">\(1\)</span>。</p><p>有了这个重大发现之后就可以高效的计算 <span class="math inline">\(\vec r\)</span> 了，我们管这个方法叫<strong>幂迭代(Power iteration)</strong></p><h3><span id="幂迭代-power-iteration">幂迭代 Power Iteration</span></h3><p><strong>幂迭代</strong> * 假设有N个web页面 * 初始化：$ r^{(0)} = [1/N, .... 1/N]^T $ * 迭代：$ r^{(t+1)} = M r^{(t)} $ * 终止条件：$ |r<sup>{(t+1)}-r</sup>{(t)}|_1 &lt; $ * 其中 $ |x|_1 = _{i=1}^{N}|x_i| $</p><p>看了这个之后是不是觉得很好实现？就是一个<code>while</code>循环而已。 还是那个例子： <img src="/images/1451042010630.png" alt="Alt text"> 经过n轮迭代之后，<span class="math inline">\(\vec r\)</span> 的值稳定在$ [6/15, 6/15, 3/15]^T$ ，与之前解方程组的结果一致。</p><h3><span id="random-walk-interpretation">Random Walk Interpretation</span></h3><blockquote><p>现在我们知道PageRank怎么高效的计算了，那么<strong>怎么理解这个网页的“重要“程度这个数值的具体意思呢</strong>？这里提供了一种解释：随机漫游解释。</p></blockquote><p>假设有一个漫步者随机地在网页中漫游： * 在 <span class="math inline">\(t\)</span> 时刻，这个人在某个页面 <span class="math inline">\(i\)</span> * 在 <span class="math inline">\(t+1\)</span> 时刻，漫步者从页面 <span class="math inline">\(i\)</span> 的链接中随机选了一条 * 经由那个链接到达了 <span class="math inline">\(j\)</span> 页面 * 无限重复这一过程</p><p>我们再令一个向量 <span class="math inline">\(p(t)\)</span>，它的第 <span class="math inline">\(i\)</span> 个值即<span class="math inline">\(p_i(t)\)</span>表示在 <span class="math inline">\(t\)</span> 时刻这个漫步者在页面 <span class="math inline">\(i\)</span> 的概率。 所以 <span class="math inline">\(p(t)\)</span> 表示所有页面的概率分布。</p><p>那么漫步者在 <span class="math inline">\(t+1\)</span> 时刻在哪？ 由于选择每个链接是随机的，所以 <span class="math inline">\(t+1\)</span> 时刻漫步者在当前页面指向的每个页面的概率都相等，都等于当前页面的<em>出度分之一</em>，所以有： $ p(t+1) = M p(t) $ 可见这和PageRank的方程是一样的。</p><p>设漫步者会达到一个稳态： $ p(t+1) = M p(t) = p(t) $ 在这个稳态，漫步者在以后任何时刻出现在某个页面的概率都相等，这时 <span class="math inline">\(p(t)\)</span> 是一个<strong>平稳分布(stationary distribution)</strong>。</p><p>所以结论就是： * <strong><span class="math inline">\(\vec r\)</span> 的值是随机漫步的平稳分布</strong> * 一个网页的PageRank得分代表了一个随机漫步者在无限的漫步过程中在某个时间 <span class="math inline">\(t\)</span> 出现在这个页面的概率！</p><h3><span id="存在性和唯一性">存在性和唯一性</span></h3><p>这个随机漫步过程是一个<a href="https://www.wikiwand.com/zh-cn/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE" target="_blank" rel="noopener">马尔科夫过程</a> 所以有： &gt; 对于满足<strong>一定条件</strong>的图，其<strong>平稳分布是唯一</strong>的，并且<strong>终将会达到平稳分布无论在 <span class="math inline">\(t=0\)</span> 时刻的概率初始值是什么</strong>。</p><h3><span id="the-google-formulation">The Google Formulation</span></h3><p>上面说要满足<strong>一定条件</strong>，其平稳分布才会唯一并且无论初始值是什么，接下来就要探讨这一定条件是什么。</p><p>首先来看三个问题：</p><p>$ r_j^{(t+1)} = _{i j} $ 或者 $ r = M r $</p><ul><li>这个东西（<span class="math inline">\(\vec r\)</span>）是否收敛？</li><li>这个东西是否收敛到我们期待的结果？</li><li>得到的结果是否有意义？</li></ul><p>我们一个一个回答。</p><h4><span id="does-this-converge">Does this converge?</span></h4><p>蜘蛛陷阱(Spider trap)：</p><p>假设图中只有两个节点A和B，如图所示： <img src="/images/1451047252190.png" alt="Alt text"> 初始化 $ r_a = 1, r_b = 0 $，按照公式迭代，我们得到一下结果： <img src="/images/1451047369971.png" alt="Alt text"> 0和1不断反转，不会收敛。再来看下一个问题。</p><h4><span id="does-it-converge-to-what-we-want">Does it converge to what we want?</span></h4><p>死胡同问题(Dead end problem)：</p><p>假设图中只有两个节点a和b，如图所示： <img src="/images/1451047684408.png" alt="Alt text"> 初始化 $ r_a = 1, r_b = 0 $，代入公式迭代得到以下结果： <img src="/images/1451047788390.png" alt="Alt text"> 最终收敛到0，这显然不是我们想要的。</p><p>两个问题总结一下： <img src="/images/1451047864892.png" alt="Alt text"></p><h3><span id="problem-spider-traps">Problem : Spider Traps</span></h3><p>假设有图： <img src="/images/1451047965042.png" alt="Alt text"> 其邻接矩阵 <span class="math inline">\(M\)</span> 为： <img src="/images/1451048025790.png" alt="Alt text"> 带入公式迭代，结果为： <img src="/images/1451048077292.png" alt="Alt text"></p><p>最终，<span class="math inline">\(r_m = 1\)</span> 而 $r_y = r_a = 0 $ 。这从漫步者的角度很好理解，在经过一段时间之后，漫步者到达了 <span class="math inline">\(m\)</span> 节点，然而 <span class="math inline">\(m\)</span> 节点只有指向自己的链接，然后就只能一直停留在 <span class="math inline">\(m\)</span> ，所以最后的概率一定是1, 而其他两个节点的概率就变成了0 。</p><p><em>解决方案</em></p><p><strong>随机传送 Random Teleports</strong></p><p>Google解决这个问题的办法是：到达某个节点后 * 有 <span class="math inline">\(\beta\)</span> 的概率随机找一个链接过去 * 剩下 <span class="math inline">\(1-\beta\)</span> 的概率跳到一个随机的页面 * 一般 <span class="math inline">\(\beta\)</span> 的值在 <span class="math inline">\(0.8\)</span> 到 <span class="math inline">\(0.9\)</span> 之间</p><p>这样就使得漫步者在到达m节点之后有一定的概率跳出去！ <img src="/images/1451048656880.png" alt="Alt text"></p><h3><span id="problem-dead-ends">Problem : Dead Ends</span></h3><p>假设有图： <img src="/images/1451048764950.png" alt="Alt text"> 其邻接矩阵为： <img src="/images/1451048788083.png" alt="Alt text"> 由于m节点没有链接到其他界面，所以m的那一列都等于零。 代入公式迭代，得到结果： <img src="/images/1451048888879.png" alt="Alt text"></p><p>漫步者到达m之后发现是死胡同，无路可走了，然而他也不会在m停留，所以最后出现在三个节点的概率都等于0 。</p><p><em>解决方案</em></p><p>依旧是<strong>传送</strong>！</p><p>当漫步者到达死胡同时，传送的概率变为 <span class="math inline">\(1.0\)</span> ，随机传送到任意页面，然后图就变成了如下： <img src="/images/1451049151567.png" alt="Alt text"> 邻接矩阵变为： <img src="/images/1451049212444.png" alt="Alt text"></p><p>这样问题就解决了，漫步这每次到m之后，发现去所有页面的概率都相同且不为零，相当于随机跳转到一个页面。</p><h3><span id="为什么传送可以解决这些问题">为什么传送可以解决这些问题？</span></h3><p>我们知道求解PageRank的过程实际上是一个马尔科夫过程，也叫马尔科夫链。</p><p><strong>马尔科夫链(Markov chains)</strong>： * 拥有一组状态 <span class="math inline">\(X\)</span> * 转移矩阵 <span class="math inline">\(P\)</span> ，且 <span class="math inline">\(P_{ij} = P(X_t=i | X_{t-1} = j)\)</span>，<span class="math inline">\(P_{ij}\)</span> 的意思就是已知上一步在 <span class="math inline">\(j\)</span>，现在这步在 <span class="math inline">\(i\)</span> 的概率 * <span class="math inline">\(\pi\)</span> 是每个状态 <span class="math inline">\(x\)</span> 特定的平稳分布 * 目标就是找到 <span class="math inline">\(\pi\)</span> 使得 <span class="math inline">\(\pi = P \pi\)</span></p><p><strong>条件</strong>： 对于<strong>任意的初始向量</strong>，只要马尔科夫转移矩阵 <span class="math inline">\(P\)</span> 满足<strong>随机的(stochastic)</strong>，<strong>不可约的(irreducible)</strong>和<strong>非周期的(aperiodic)</strong>，那么对矩阵 <span class="math inline">\(P\)</span> 应用幂迭代就一定会收敛到一个不变的向量。</p><p>我们来讨论一下为什么随机传送可以让矩阵 <span class="math inline">\(M\)</span> 满足上述条件。</p><h4><span id="make-m-stochastic">Make M Stochastic</span></h4><p><strong>随机(Stochastic)</strong>的意思就是每列的和加起来等于<span class="math inline">\(1\)</span></p><p>我们知道下面的图会造成死胡同问题(Dead End)： <img src="/images/1451048764950.png" alt="Alt text"> 如果让其在没有出度的节点可以随机跳转到任意节点的话就相当与在 <span class="math inline">\(m\)</span> 节点上新加了几条边： <img src="/images/1451132954313.png" alt="Alt text"> 这样 <span class="math inline">\(m\)</span> 的出度就变成了3，矩阵 <span class="math inline">\(M\)</span> 也变成了： <img src="/images/1451133022738.png" alt="Alt text"> 现在 <span class="math inline">\(M\)</span> 矩阵就满足了随机性，每列的和都等于 <span class="math inline">\(1\)</span>。</p><p>我们把新矩阵记做 <span class="math inline">\(A\)</span>，有如下计算公式： &gt; $ A = M + a^T(e) $</p><p>如果节点 <span class="math inline">\(i\)</span> 没有出度则 <span class="math inline">\(a_i=1\)</span>，否则 <span class="math inline">\(a_i=0\)</span> ; $ e$ 是单位行向量。</p><h4><span id="make-m-aperiodic">Make M Aperiodic</span></h4><p><strong>周期性(periodic)</strong>定义：如果存在一个 $k&gt;1 $ 使得两次到达同一个状态的间隔总是 <span class="math inline">\(k\)</span> 的整数倍，那么这条链就是具有周期性的。</p><figure><img src="/images/1451134156887.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>上图就是一个具有周期性的链，每隔两步就会回到同一状态。 加上随机传送就变成了： <img src="/images/1451134263267.png" alt="Alt text"> 这样不论每隔多少步也不一定会回到同一状态，即<strong>不具有周期性</strong>。</p><h4><span id="make-m-irreducible">Make M Irreducible</span></h4><p><strong>不可约(Irreducible)</strong>的意思是：对于任何状态，都有从这个状态跳到任意另一个状态的可能性。</p><p>如图，其中绿色的线是加上随机跳转之后： <img src="/images/1451134621312.png" alt="Alt text"></p><h3><span id="random-jumps">Random Jumps</span></h3><p>从前面的分析可知，随机跳转可以是 <span class="math inline">\(M\)</span> 满足随机、非周期和不可约的性质，这就是Google的解决方案。</p><ul><li>在每一步，漫步者有两个选择：<ul><li><span class="math inline">\(\beta\)</span> 的可能性随机选一个链接</li><li><span class="math inline">\(1-\beta\)</span> 的可能性跳转到随机页面</li></ul></li></ul><p><strong>PageRank 计算方程</strong> 就变成了： &gt; $ r_j = _{i j}  + (1-) $</p><p>其中 <span class="math inline">\(\sum _{i \to j} \beta \frac{r_i}{d_i}\)</span> 是具有 <span class="math inline">\(\beta\)</span> 的概率随机选择一个链接，<span class="math inline">\((1-\beta)\frac{1}{n}\)</span> 是 <span class="math inline">\(1-\beta\)</span> 的概率跳转到随机页面，其中 <span class="math inline">\(n\)</span> 是图中节点个数。</p><p>我们还打算用幂迭代方法计算PageRank，所以还需要变成矩阵形式。</p><p><strong>The Google Matrix A</strong> &gt; $ A = M + (1 - ) e e^T $</p><p><strong>What is <span class="math inline">\(\beta\)</span> ?</strong> 实践表明 <span class="math inline">\(\beta\)</span> 取在 $0.8 $~ <span class="math inline">\(0.9\)</span> 之间较好，其中 <span class="math inline">\(\beta=0.85\)</span> 时每隔五步跳转一次。</p><p>还是举之前那个例子。。。 图为： <img src="/images/1451135546704.png" alt="Alt text"></p><p>矩阵 <span class="math inline">\(\beta M\)</span> 为： <img src="/images/1451135595638.png" alt="Alt text"></p><p>跳转矩阵为： <img src="/images/1451135650772.png" alt="Alt text"></p><p>所以Google矩阵 <span class="math inline">\(A\)</span> 就是它们的和： <img src="/images/1451135678520.png" alt="Alt text"></p><p>进行幂迭代，结果为： <img src="/images/1451135730531.png" alt="Alt text"></p><p>可见，修正之后的PageRank依旧是m分最高，但也不会有蜘蛛陷阱的问题，比较完美！</p><h3><span id="实际上是如何计算pagerank的">实际上是如何计算PageRank的？</span></h3><p>计算PageRank就是一个幂迭代的过程，按照公式： <span class="math inline">\(r^{new} = A \cdot r^{old}\)</span>，看似很简单。</p><p>如果我们有足够的内存来装下 <span class="math inline">\(A, r^{old}, r^{new}\)</span> 的话确实很简单，我们来算一下到底够不够。</p><p>假设有 <span class="math inline">\(N = 1 × 10^{9}\)</span> 个网页，存每个网页只需要4个字节，即只存一个节点ID，那么存储地址+ID就需要 2 billion * 4 byte，约等于8GB</p><p>如果要存储矩阵A，需要存储 <span class="math inline">\(N^2\)</span> 个地址+ID，大概需要 <span class="math inline">\(10^{18}\)</span> 字节这个数量级的内存空间，显然是没有那么大的！</p><p>我们考虑矩阵 <span class="math inline">\(M\)</span> 的值的分布， 如果 $ j i $ 那么 $ M_{ij} = 1/|d_j| $ ，否则 $ M_{ij} = 0 $，实际情况是每个网页一般只有10个到100个链接，即使整个web有1 billion+ 个网页，所以矩阵 <span class="math inline">\(M\)</span> 大部分值都为0，极少数值非0 ，所以我们可以仅存储非零值来极大地减少所需存储空间。</p><p>而矩阵 <span class="math inline">\(A\)</span> 就不一样了，$ A = M + (1 - ) e e^T $，每个值都是非零的，因为矩阵 <span class="math inline">\(M\)</span> 中等于0的情况在 <span class="math inline">\(A\)</span> 中都被赋予了随机跳转到任意节点的可能性。</p><p>由于 <span class="math inline">\(A\)</span> 不能直接放在内存里计算，而 <span class="math inline">\(M\)</span> 可以，所以要想方设法把 <span class="math inline">\(A\)</span> 的迭代变成 <span class="math inline">\(M\)</span> 的迭代。</p><h4><span id="公式变形">公式变形</span></h4><p>原公式为：$ r = A r $ 其中 $A_{ij} = M_{ij} +  $</p><p>把它展开： <span class="math inline">\(r_i = \sum_{j=1}^{N}A_{ij} \cdot r_j\)</span> <img src="/images/1451140624364.png" alt="Alt text"></p><p>最后我们得到： &gt; $ r = M r + []_N $</p><p>这里假设 <span class="math inline">\(M\)</span> 中没有dead-ends，其中 <span class="math inline">\([x]_n\)</span> 表示一个项全部为 <span class="math inline">\(x\)</span> 的向量。</p><p>经过了这样的变形，我们在每次迭代中只需要： * 计算 $ r^{new} = M r^{old}$ * 在 <span class="math inline">\(r^{new}\)</span> 的每一项上加上常量 $ (1-)/N$ * 如果 <span class="math inline">\(M\)</span> 中有dead-end 的话，那么 $_i r_i^{new} &lt; 1 $ ，我们还需要重新分配一下余下部分，使其和等于1.</p><h4><span id="最终的算法">最终的算法</span></h4><ul><li>输入 ： 图 <span class="math inline">\(G\)</span> 和 参数 <span class="math inline">\(\beta\)</span><ul><li><span class="math inline">\(G\)</span> 是有向图而且可以有 <strong>spider traps</strong> 和 <strong>dead ends</strong></li><li>概率参数 <span class="math inline">\(\beta\)</span></li></ul></li><li>输出：Pagerank 向量 <span class="math inline">\(\vec r\)</span> <img src="/images/1451141342964.png" alt="Alt text"></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据挖掘 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>记录：微信后台开发</title>
      <link href="/2015/12/26/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%BE%AE%E4%BF%A1%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
      <url>/2015/12/26/%E8%AE%B0%E5%BD%95%EF%BC%9A%E5%BE%AE%E4%BF%A1%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<p>微信接口文档 http://mp.weixin.qq.com/wiki/home/index.html 测试号 http://mp.weixin.qq.com/debug/cgi-bin/sandbox?t=sandbox/login</p><a id="more"></a><h3><span id="memcache缓存access_token">Memcache缓存access_token</span></h3><p><a href="http://www.liuhe.website/index.php?/Articles/single/15" target="_blank" rel="noopener">Memcache安装与配置</a></p><h3><span id="通过curl发起http请求">通过cURL发起http请求</span></h3><p>php手册 http://php.net/manual/zh/book.curl.php</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">function</span> <span class="title">http_request</span><span class="params">($url)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    $ch = curl_init(); <span class="comment">// 初始化</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_URL, $url); <span class="comment">// 需要获取的URL地址</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_CUSTOMREQUEST, <span class="string">"GET"</span>); <span class="comment">// get的方式</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, <span class="keyword">false</span>); <span class="comment">// 信任任何证书</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, <span class="keyword">false</span>); <span class="comment">// 不进行任何验证</span></span><br><span class="line">    curl_setopt($ch, CURLOPT_RETURNTRANSFER, <span class="number">1</span>); <span class="comment">// 将curl_exec()获取的信息以文件流的形式返回，而不是直接输出</span></span><br><span class="line">    $output = curl_exec($ch); <span class="comment">// 发出请求</span></span><br><span class="line">    curl_close($ch); <span class="comment">// 关闭cURL</span></span><br><span class="line">    <span class="keyword">return</span> $output;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="处理json数据">处理JSON数据</span></h3><p><a href="http://www.liuhe.website/index.php?/Articles/single/7" target="_blank" rel="noopener">在php语言中使用json</a></p><h3><span id="解析xml">解析xml</span></h3><h4><span id="xml_parser">xml_parser</span></h4><p>php手册 http://php.net/manual/zh/book.xml.php</p><p>建立XML解析器：<code>$p = xml_parser_creat()</code> 开始解析一个XML文档 : <code>xml_parse($data)</code> 将XML解析到数组 : <code>xml_parse_into_struct($p, $data, $vals, $index)</code> 释放解释器：<code>xml_parser_free($p)</code> <del>但是用这个方法解析微信发来的数据包失败了</del></p><h4><span id="simplexmlelement">SimpleXMLElement</span></h4><p>php手册 http://php.net/manual/zh/class.simplexmlelement.php</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 解析成关联数组</span></span><br><span class="line">$msg = (<span class="keyword">array</span>) simplexml_load_string($data, <span class="string">'SimpleXMLElement'</span>, LIBXML_NOCDATA);</span><br></pre></td></tr></table></figure><h4><span id="菜单的click事件响应失败">菜单的CLICK事件响应失败</span></h4><p>未知</p><h4><span id="图文素材上传之后只剩图了">图文素材上传之后只剩图了</span></h4><p>因为内容字符数超了，换了短一点的就可以了。</p><h2><span id="js-sdk">js-sdk</span></h2><p>域名只需要填到<code>.com</code>之类的，后面不用。</p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后台开发 </tag>
            
            <tag> PHP </tag>
            
            <tag> Wechat </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>安装Memcache</title>
      <link href="/2015/12/24/%E5%AE%89%E8%A3%85Memcache/"/>
      <url>/2015/12/24/%E5%AE%89%E8%A3%85Memcache/</url>
      
        <content type="html"><![CDATA[<p>http://php.net/manual/zh/book.memcache.php</p><a id="more"></a><blockquote><p>服务器端主要是安装memcache服务器端，目前的最新版本是 memcached-1.3.0 。 下载：http://www.danga.com/memcached/dist/memcached-1.2.2.tar.gz 另外，Memcache用到了libevent这个库用于Socket的处理，所以还需要安装libevent，libevent的最新版本是libevent-1.3。（如果你的系统已经安装了libevent，可以不用安装） 官网：http://www.monkey.org/<sub>provos/libevent/ 下载：http://www.monkey.org/</sub>provos/libevent-1.3.tar.gz</p></blockquote><p>用wget指令直接下载这两个东西.下载回源文件后。 1. 先安装libevent。这个东西在配置时需要指定一个安装路径，即<code>./configure –prefix=/usr</code>；然后<code>make</code>；然后<code>make install</code>； 2. 再安装memcached，只是需要在配置时需要指定libevent的安装路径即<code>./configure –with-libevent=/usr</code>；然后<code>make &amp;&amp; make install</code>； 这样就完成了Linux下Memcache服务器端的安装。详细的方法如下：</p><h4><span id="分别把memcached和libevent下载回来放到-tmp-目录下">分别把memcached和libevent下载回来，放到 <code>/tmp</code> 目录下：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cd /tmp</span><br><span class="line"># wget http://www.danga.com/memcached/dist/memcached-1.2.0.tar.gz</span><br><span class="line"># wget http://www.monkey.org/~provos/libevent-1.2.tar.gz</span><br></pre></td></tr></table></figure><h4><span id="先安装libevent">先安装libevent：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># tar zxvf libevent-1.2.tar.gz</span><br><span class="line"># cd libevent-1.2</span><br><span class="line"># ./configure –prefix=/usr</span><br><span class="line"># make</span><br><span class="line"># make install</span><br></pre></td></tr></table></figure><h4><span id="测试libevent是否安装成功">测试libevent是否安装成功：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># ls -al /usr/lib | grep libevent</span><br><span class="line">lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent-1.2.so.1 -&gt; libevent-1.2.so.1.0.3</span><br><span class="line">-rwxr-xr-x 1 root root 263546 11?? 12 17:38 libevent-1.2.so.1.0.3</span><br><span class="line">-rw-r–r– 1 root root 454156 11?? 12 17:38 libevent.a</span><br><span class="line">-rwxr-xr-x 1 root root 811 11?? 12 17:38 libevent.la</span><br><span class="line">lrwxrwxrwx 1 root root 21 11?? 12 17:38 libevent.so -&gt; libevent-1.2.so.1.0.3</span><br></pre></td></tr></table></figure><h4><span id="安装memcached同时需要安装中指定libevent的安装位置">安装memcached，同时需要安装中指定libevent的安装位置：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># cd /tmp</span><br><span class="line"># tar zxvf memcached-1.2.0.tar.gz</span><br><span class="line"># cd memcached-1.2.0</span><br><span class="line"># ./configure –with-libevent=/usr</span><br><span class="line"># make</span><br><span class="line"># make install</span><br></pre></td></tr></table></figure><h4><span id="测试是否成功安装memcached">测试是否成功安装memcached：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># ls -al /usr/local/bin/mem*</span><br><span class="line">-rwxr-xr-x 1 root root 137986 11?? 12 17:39 /usr/local/bin/memcached</span><br><span class="line">-rwxr-xr-x 1 root root 140179 11?? 12 17:39 /usr/local/bin/memcached-debug</span><br></pre></td></tr></table></figure><h3><span id="安装memcache的php扩展">安装Memcache的PHP扩展</span></h3><h4><span id="在httppeclphpnetpackagememcache-选择相应想要下载的memcache版本">在http://pecl.php.net/package/memcache 选择相应想要下载的memcache版本。</span></h4><h4><span id="安装php的memcache扩展">安装PHP的memcache扩展</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar vxzf memcache-2.2.1.tgz</span><br><span class="line">cd memcache-2.2.1</span><br><span class="line">/usr/local/php/bin/phpize</span><br><span class="line">./configure --enable-memcache --with-php-config=/usr/bin/php-config --with-zlib-dir</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">// 若 phpize没有找到</span><br><span class="line">// 解决方法：</span><br><span class="line">yum install php-devel</span><br></pre></td></tr></table></figure><h4><span id="上述安装完后会有类似这样的提示">上述安装完后会有类似这样的提示：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Installing shared extensions: </span><br><span class="line">/...</span><br><span class="line">/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/</span><br></pre></td></tr></table></figure><h4><span id="把phpini中的extension_dir-修改为">把php.ini中的extension_dir = “./”修改为</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">extension_dir = “/usr/local/php/lib/php/extensions/no-debug-non-zts-2007xxxx/”</span><br></pre></td></tr></table></figure><h4><span id="添加一行来载入memcache扩展">添加一行来载入memcache扩展：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">extension=memcache.so</span><br></pre></td></tr></table></figure><h3><span id="memcached的基本设置">memcached的基本设置</span></h3><h4><span id="启动memcache的服务器端">启动Memcache的服务器端：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># /usr/local/bin/memcached -d -m 10 -u root -l 127.0.0.1 -p 12000 -c 256 -P /tmp/memcached.pid</span><br><span class="line"></span><br><span class="line">若出现错误：/usr/local/bin/memcached: error while loading shared libraries: libevent-1.3.so.1: cannot open shared object file: No such file or directory</span><br><span class="line"></span><br><span class="line">直接设置链接</span><br><span class="line"></span><br><span class="line">#ln -s /usr/local/libevent/lib/libevent-1.3.so.1 /lib64/libevent-1.3.so.1</span><br></pre></td></tr></table></figure><blockquote><ul><li>-d选项是启动一个守护进程，</li><li>-m是分配给Memcache使用的内存数量，单位是MB，我这里是10MB，</li><li>-u是运行Memcache的用户，我这里是root，</li><li>-l是监听的服务器IP地址</li><li>-p是设置Memcache监听的端口，我这里设置了12000，最好是1024以上的端口，</li><li>-c选项是最大运行的并发连接数，默认是1024，我这里设置了256，按照你服务器的负载量来设定，</li><li>-P是设置保存Memcache的pid文件，我这里是保存在 <code>/tmp/memcached.pid</code></li></ul></blockquote><h4><span id="如果要结束memcache进程执行">如果要结束Memcache进程，执行：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># kill `cat /tmp/memcached.pid`</span><br></pre></td></tr></table></figure><p>也可以启动多个守护进程，不过端口不能重复。</p><h4><span id="重启机器">重启机器</span></h4><h3><span id="memcache环境测试">Memcache环境测试：</span></h3><p>运行下面的php文件，如果有输出This is a test!，就表示环境搭建成功。 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt; ?php</span><br><span class="line">$mem=newMemcache;</span><br><span class="line">$mem-&gt;connect(“<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>”, <span class="number">12000</span>);</span><br><span class="line">$mem−&gt;set(′key′,‘Thisisatest!′,<span class="number">0</span>,<span class="number">60</span>);</span><br><span class="line">$val = $mem−&gt;get(′key′);</span><br><span class="line"><span class="keyword">echo</span> $val;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后台开发 </tag>
            
            <tag> Linux </tag>
            
            <tag> Memcache </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>海量数据挖掘（一）：MapReduce</title>
      <link href="/2015/12/22/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AMapReduce/"/>
      <url>/2015/12/22/%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9AMapReduce/</url>
      
        <content type="html"><![CDATA[<blockquote><p>此系列为Cousera上Standford的<a href="https://class.coursera.org/mmds-002" target="_blank" rel="noopener">Mining Massive Datasets</a>课程学习笔记。 这是该系列的第一篇笔记：<strong>MapReduce</strong></p></blockquote><a id="more"></a><h2><span id="分布式文件系统-distributed-file-systems">分布式文件系统 Distributed File Systems</span></h2><h3><span id="cluster-architecture">Cluster Architecture</span></h3><p>传统的数据挖掘都在一台主机上搞定，而如今数据量之大早已不是一台主机可以处理的了，拿Google举例：</p><ul><li><strong>100亿</strong>个网页</li><li>每个网页平均大小 = <strong>20KB</strong></li><li>总共 10 billion * 20 KB = <strong>200TB</strong></li><li>磁盘读取速度 = <strong>50 MB/sec </strong></li><li>总共读取时间 = 四百万秒 = <strong>46天</strong></li><li>读取数据时间甚至比处理数据时间还要长</li></ul><p>所以现在的集群架构(Cluster Architecture)是这样的： <img src="/images/1450707371717.png" alt="Alt text"></p><p>构成树形结构，上面的节点都是交换机，底层叶子节点是Linux主机集群，每个集群包含14-64个主机节点。</p><p>这种集群架构虽然可以通过并发处理解决IO问题，但是它也面临新的问题： * Linux节点会挂掉 * 如何做到即使某个主机挂了也能永久保存其中的数据？ * 如何处理在计算中节点挂掉的情况？</p><ul><li>网络瓶颈<ul><li>目前网络带宽 = 1 Gbps</li><li>移动10TB的数据大约需要一天</li></ul></li><li>编写分布式的程序比较困难！<ul><li>需要一个简单的模型来消除大部分困难</li></ul></li></ul><h3><span id="mapreduce">MapReduce</span></h3><blockquote><p>Map-Reduce 解决了集群计算的一些困难与挑战。 * <strong>以冗余的方式把数据存储在多个节点</strong>上来保持数据的永久性和可用性。 * <strong>让计算靠近数据</strong>来最小化数据的移动。 * <strong>简单的编程模型</strong></p></blockquote><h3><span id="冗余存储基础设施-redundant-storage-infrastructure">冗余存储基础设施 Redundant Storage Infrastructure</span></h3><ul><li>分布式文件系统<ul><li>Google GFS</li><li>Hadoop HDFS</li></ul></li><li>典型使用场景<ul><li>数据量大</li><li>少更新</li><li>读取频繁</li></ul></li></ul><p>文件分布系统就像以下： <img src="/images/1450709258137.png" alt="Alt text"> <strong>每一“块”的服务器也有计算功能，不光是存储数据！</strong> <img src="/images/1450709278438.png" alt="Alt text"></p><h2><span id="计算模型-conputational-model">计算模型 Conputational model</span></h2><h3><span id="word-count">Word Count</span></h3><blockquote><p>一个例子 Word Count： * 有一个非常大的文本文件 * 需要统计每个单词出现的次数</p></blockquote><ul><li>Case 1 : 整个文件无法读取进内存，但是所有的<code>&lt;word, count&gt;</code>键值对可以存储在内存里。</li></ul><p>这种情况我们可以简单写一个Hash Table，以word作为key，count作为value来实现。</p><ul><li>Case 2 : 连<code>&lt;word, count&gt;</code>都无法完全保存在内存里。</li></ul><p>这种情况可以用一条Linux命令来解决： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words(doc.txt) | sort | uniq -c</span><br></pre></td></tr></table></figure></p><p><code>words</code>是一个程序，用来把文件输出成单词，一行一个。</p><p>这种方法正是MapReduce模型的计算方法，而且还天然地可以并行计算。</p><h3><span id="整体概揽">整体概揽</span></h3><figure><img src="/images/1450710473291.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h3><span id="具体分析">具体分析</span></h3><h4><span id="map">Map</span></h4><p>输入一些原始的键值对，输出中间状态的键值对，一对一或一对多，在上述例子里就是<code>words</code>这个程序，输入文件名，输出<code>&lt;word, 1&gt;</code>的键值对。 <img src="/images/1450710723670.png" alt="Alt text"></p><h4><span id="reduce">Reduce</span></h4><p>把中间状态的键值对按照<code>key</code>分组整理，输出的键值对都已经分好组，在上述例子中就是<code>sort</code>这个命令。</p><p>最后是把每组键值对的<code>value</code>合并成一个。 <img src="/images/1450711030365.png" alt="Alt text"></p><p>整个处理过程中，程序员只需要写两个函数：<code>Map(k, v)</code>和<code>Reduce(K, &lt;V&gt;*)</code>，对于解决不同的问题两个函数的实现各有不同，但是框架都是这一个。 <img src="/images/1450711170607.png" alt="Alt text"></p><h3><span id="并行计算">并行计算</span></h3><ol type="1"><li>大文件拆分成多个部分</li><li>每部分文件分别在一个主机上进行Map计算。</li><li>通过Hash把所有主机Map之后的导入到一个或多个主机里，使具有同一个<code>key</code>的键值对都出现在一个主机里，并在每个主机里分别进行排序。</li><li>在各个主机里分别Reduce</li></ol><figure><img src="/images/1450711387926.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>伪码示例： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">map(key, value):</span><br><span class="line">    <span class="comment"># key: document name; value: text of the document</span></span><br><span class="line">    <span class="keyword">for</span> each word w <span class="keyword">in</span> value:</span><br><span class="line">        emit(w, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">reduce(key, values):</span><br><span class="line">    <span class="comment"># key: a word; value: an iterator over counts</span></span><br><span class="line">    result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> each count v <span class="keyword">in</span> values:</span><br><span class="line">        result += v</span><br><span class="line">    emit(key, result)</span><br></pre></td></tr></table></figure></p><h3><span id="examples">Examples</span></h3><p><img src="/images/1450712456661.png" alt="Alt text"> <img src="/images/1450712474358.png" alt="Alt text"></p><h2><span id="调度和数据流动-scheduling-and-data-flow">调度和数据流动 Scheduling and Data Flow</span></h2><p>描述Map-Reduce的工作图： <img src="/images/1450747181061.png" alt="Alt text"></p><p>并行处理模型，上一节已经描述过了： <img src="/images/1450747276231.png" alt="Alt text"></p><h3><span id="environment">Environment</span></h3><p>Map-Reduce过程需要考虑的问题： * 对输入数据<strong>划分</strong> * 程序的执行在一大堆机器里进行<strong>调度</strong> * 执行<strong>按<code>key</code>分组</strong>这一步骤 * 处理节点(机器)<strong>崩溃</strong> * 管理必要地机器之间的<strong>通信</strong></p><h3><span id="data-flow">Data Flow</span></h3><blockquote><p>输入和最终输出是储存在分布式文件系统上的(DFS)，调度者应尽量调度Map任务&quot;靠近&quot;输入数据实际所存储的地方，让计算靠近数据。</p></blockquote><blockquote><p>中间结果存储在Map工作者和Reduce工作者<strong>本地</strong>的文件系统里。</p></blockquote><blockquote><p>一个Map-Reduce任务的输出通常是另一个Map-Reduce任务的的输入。</p></blockquote><h3><span id="coordination">Coordination</span></h3><blockquote><p>每个Map-Reduce任务都有一个Master节点，Master节点需要负责总体任务的协调与调度。</p></blockquote><p>Master节点需要考虑的问题： * 每个节点的<strong>任务状态</strong>：空闲的(idle), 正在工作的(in-progress), 已完成的(completed) * 有空闲任务的话就找可用的节点去处理 * 当一个Map任务完成时，工作者向Master节点发送<em>R</em>个中间文件的位置和大小，<em>R</em>是Reduce工作者的个数，每个Reduce工作者获得一个中间文件。 * Master节点把数据推送到Reducers节点。 * Master节点还要时不时地ping一下工作者看机器是否还活着。</p><h3><span id="失败处理办法">失败处理办法</span></h3><ul><li>处理Map任务的节点挂了</li></ul><p>由于Map任务输出的中间结果是存储在本地的，所以机器挂了输出的数据也就没了，只能重新做了。 <strong>把挂了节点的Map任务重设成空闲</strong>，不管挂之前是处理中还是已完成，反正数据都没了，然后等着有其他可用节点来完成这个节点的工作。</p><ul><li>处理Reduce任务的节点挂了</li></ul><p>由于Reduce任务输出的最终结果是保存在分布式文件系统上的，我们前面已经讨论过了，一个节点坏了没关系，还有其他节点保存着备份，所以如果该节点是完成Reduce任务之后挂的那就不用管了，数据还在; 如果是没完成就挂了，那就需要重做了。 <strong>只把没做完就挂了的任务重设为空闲</strong>，等着其他节点有空来作。</p><ul><li>Master节点挂了怎么办</li></ul><p>失去了领导者这个<strong>任务只能终止</strong>，然后等待从头重新开始咯。 不过机器的平均使用寿命在1000天左右，单台机器挂掉的概率是很小的，在Map任务和Reduce任务节点的集群里，很可能会出现有一两台挂掉的情况，<strong>对于Master这个单一节点来讲，挂掉的几率非常小</strong>，可以不考虑。</p><h3><span id="map和reduce的工作数量">Map和Reduce的工作数量</span></h3><p>设有<em>M</em>个Map任务，<em>R</em>个Reduce任务，我们的目的就是确定M和R。</p><p>拇指规则（经验）： * 让M远大于集群里节点个数 * 每个DFS区块处理一个map任务，可以减少单个节点的任务量 * 提高动态负载均衡和从挂掉节点恢复的速度 * 通常R比M小</p><h2><span id="优化-refinements">优化 Refinements</span></h2><h3><span id="combiners">Combiners</span></h3><p>通常一个Map任务会处理出许多个具有相同<code>key</code>的键值对，直接把这样的数据传给Reducer会很巨大，网络带宽占用多，有时候可以在传输前<strong>预合并</strong>一下，极大的减少了数据量，发送速度也显著提高。</p><p>合并(combine)函数通常与Reduce函数是一样的。</p><p>回到之前Word Count的例子 Map任务输出结果中可能会有大量的<code>&lt;word, 1&gt;</code>具有相同的<code>key</code>,比如<code>the</code>可能出现了1000次，那么里面就有1000个<code>('the', 1)</code>，这时候可以通过预合并把具有相同<code>key</code>的键值对合并，就变为了<code>('the', 1000)</code>，然后再推送到Reduce任务中，极大减少了传输数据量。 如图所示： <img src="/images/1450752050711.png" alt="Alt text"></p><p>但预合并并不是什么时候都管用的，它要求<strong>Reduce函数满足交换律和结合律</strong>。</p><p>举个例子，比如求和(sum)满足交换律和结合律，即<code>a + b = b + a</code>和<code>(a + b) + c = a + (b + c)</code>，所以它可以在本地预处理。</p><p>如果Reduce函数是求平均值(Average)呢？ 我们都过把大数据分成了很多小块，在每个小块里进行map，然后把输出结果具有相同<code>key</code>的键值对加起来再取平均，然后发送给Reduce任务，Reduce把每个小块的平均值加起来再取平均，得到最终结果。</p><p>得到的是正确结果吗？ <strong>显然不是！</strong></p><p><strong>求平均值这个运算不满足结合律</strong>，分成小块取平均然后加起来再取平均与直接把所有数据加起来取平均是不相等的！</p><p>所以<strong>这个例子不能用与Reduce一样的合并函数</strong>，但也不是没有办法，可以只求出它们的和，不取平均，然后发送到Reduce里，Reduce函数把所有的区块的和加起来再取平均，得到的就是正确结果了。</p><p>再换一个，如果要求中位数(Median)呢？ 那就没辙了，只能直接传原始map输出数据了。</p><h3><span id="分块函数">分块函数</span></h3><figure><img src="/images/1450753330650.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="实现-implementations">实现 Implementations</span></h2><ul><li>Hadoop<ul><li>开源、用java实现</li><li>使用HDFS作为稳定的存储</li><li>下载： http://lucene.apache.org/hadoop/</li></ul></li><li>Hive, Pig<ul><li>在hadoop MapReduce层上面的抽象</li></ul></li><li>Google MapReduce<ul><li>使用Google File System作为存储</li><li>只有google内部可以使用</li></ul></li></ul><figure><img src="/images/1450753341548.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><h2><span id="资源和延伸阅读">资源和延伸阅读</span></h2><p>课件pdf下载</p><p>延伸阅读： <a href="http://research.google.com/archive/mapreduce.html" target="_blank" rel="noopener">MapReduce: Simplified Data Processing on Large Clusters</a></p><p><a href="http://research.google.com/archive/gfs.html" target="_blank" rel="noopener">The Google File System</a></p><p>资源：</p><ul><li>Hadoop Wiki<ul><li><a href="http://wiki.apache.org/hadoop/" target="_blank" rel="noopener">介绍</a></li><li><a href="http://wiki.apache.org/hadoop/GettingStartedWithHadoop" target="_blank" rel="noopener">Getting Start</a></li><li><a href="http://wiki.apache.org/hadoop/HadoopMapReduce" target="_blank" rel="noopener">MapReduce 概揽</a></li><li>http://wiki.apache.org/lucene-hadoop/HadoopMapRedClasses</li><li><a href="http://wiki.apache.org/hadoop/EclipseEnvironment" target="_blank" rel="noopener">Eclipse环境</a></li></ul></li><li><p><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">Hadoop 官网</a></p></li><li><p><a href="http://www.apache.org/dyn/closer.cgi/lucene/" target="_blank" rel="noopener">镜像</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据挖掘 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>记录：用PHP实现简单web框架</title>
      <link href="/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/"/>
      <url>/2015/12/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E7%94%A8PHP%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95web%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这个框架功能比较简单，只有url拦截及自定义、加载静态模板两个功能，之前的博客也是基于这个框架实现的。第一部分是记录实现这个框架所需的php基础知识，第二部分是这两个功能的实现方法。最后还有实现自动登录的最佳实践。</p></blockquote><a id="more"></a><h2><span id="php基础相关">php基础相关</span></h2><h3><span id="_server"><code>$_SERVER</code></span></h3><blockquote><p>服务器和执行环境信息</p></blockquote><p><a href="http://php.net/manual/zh/reserved.variables.server.php" target="_blank" rel="noopener">php手册</a></p><p>几个用到的项： * <code>'REQUEST_METHOD'</code> : 访问页面使用的请求方法；例如，<code>“GET”</code>,<code>“HEAD”</code>，<code>“POST”</code>，<code>“PUT”</code>。 * <code>'REQUEST_URI'</code> : URI 用来指定要访问的页面。例如 <code>“/index.html”</code>。</p><h3><span id="date">Date</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">date(format,timestamp)</span><br></pre></td></tr></table></figure><div class="line-block">参数 | 描述 |<br>:--- | : --- |<br>format | 必需。规定如何返回结果。|<br>timestamp | 可选。 |</div><h4><span id="格式化方式说明">格式化方式说明</span></h4><table><thead><tr class="header"><th style="text-align: left;">格式化方式</th><th style="text-align: left;">说明</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">Y</td><td style="text-align: left;">4位数字年，y为2位数字，如99即1999年</td></tr><tr class="even"><td style="text-align: left;">m</td><td style="text-align: left;">数字月份，前面有前导0，如01。n 为无前导0数字月份</td></tr><tr class="odd"><td style="text-align: left;">F</td><td style="text-align: left;">月份，完整的文本格式，例如 January 或者 March</td></tr><tr class="even"><td style="text-align: left;">M</td><td style="text-align: left;">三个字母缩写表示的月份，例如 Jan 或者 Mar</td></tr><tr class="odd"><td style="text-align: left;">d</td><td style="text-align: left;">月份中的第几天，前面有前导0，如03。j 为无前导0的天数</td></tr><tr class="even"><td style="text-align: left;">w</td><td style="text-align: left;">星期中的第几天，以数字表示，0表示星期天</td></tr><tr class="odd"><td style="text-align: left;">z</td><td style="text-align: left;">年份中的第几天，范围0-366</td></tr><tr class="even"><td style="text-align: left;">W</td><td style="text-align: left;">年份中的第几周，如第32周</td></tr><tr class="odd"><td style="text-align: left;">H</td><td style="text-align: left;">24小时格式，有前导0，h为12小时格式</td></tr><tr class="even"><td style="text-align: left;">G</td><td style="text-align: left;">24小时格式，无前导0，g为对应12小时格式</td></tr><tr class="odd"><td style="text-align: left;">i</td><td style="text-align: left;">分钟格式，有前导0</td></tr><tr class="even"><td style="text-align: left;">s</td><td style="text-align: left;">秒格式，有前导0</td></tr><tr class="odd"><td style="text-align: left;">A</td><td style="text-align: left;">大写上下午，如AM，a为小写</td></tr></tbody></table><p><strong>例子</strong> <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Result with date():&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(<span class="string">"l"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(<span class="string">"l dS \of F Y h:i:s A"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Oct 3,1975 was on a "</span>.date(<span class="string">"l"</span>, mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)).<span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(DATE_RFC822) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(date(DATE_ATOM,mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)) . <span class="string">"&lt;br /&gt;&lt;br /&gt;"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Result with gmdate():&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(<span class="string">"l"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(<span class="string">"l dS \of F Y h:i:s A"</span>) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(<span class="string">"Oct 3,1975 was on a "</span>.gmdate(<span class="string">"l"</span>, mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)).<span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(DATE_RFC822) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="keyword">echo</span>(gmdate(DATE_ATOM,mktime(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">10</span>,<span class="number">3</span>,<span class="number">1975</span>)) . <span class="string">"&lt;br /&gt;"</span>);</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p><p>结果： &gt; Result with <code>date()</code>: Tuesday Tuesday 24th of January 2006 02:41:22 PM Oct 3,1975 was on a Friday Tue, 24 Jan 2006 14:41:22 CET 1975-10-03T00:00:00+0100</p><blockquote><p>Result with <code>gmdate()</code>: Tuesday Tuesday 24th of January 2006 01:41:22 PM Oct 3,1975 was on a Thursday Tue, 24 Jan 2006 13:41:22 GMT 1975-10-02T23:00:00+0000</p></blockquote><h3><span id="字符串">字符串</span></h3><p><code>explode()</code>分割字符串，返回数组。 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">explode(delimiter, string)</span><br></pre></td></tr></table></figure></p><h4><span id="随机字符串">随机字符串</span></h4><ol type="1"><li>预置一个的字符串 $chars ，包括 a – z，A – Z，0 – 9，以及一些特殊字符。</li><li>在 $chars 字符串中随机取一个字符。</li><li>重复第二步n次，可得长度为n的字符串。</li></ol><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">generate_password</span><span class="params">( $length = <span class="number">8</span> )</span> </span>&#123;  </span><br><span class="line"><span class="comment">// 密码字符集，可任意添加你需要的字符  </span></span><br><span class="line">    $chars = ‘abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@<span class="comment">#$%^&amp;*()-_ []&#123;&#125;&lt;&gt;~`+=,.;:/?|’;  </span></span><br><span class="line">    $password = ”;  </span><br><span class="line">    <span class="keyword">for</span> ( $i = <span class="number">0</span>; $i &lt; $length; $i++ )  </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="comment">// 这里提供两种字符获取方式  </span></span><br><span class="line">        <span class="comment">// 第一种是使用 substr 截取$chars中的任意一位字符；  </span></span><br><span class="line">        <span class="comment">// 第二种是取字符数组 $chars 的任意元素  </span></span><br><span class="line">        <span class="comment">// $password .= substr($chars,     mt_rand(0, strlen($chars) – 1), 1);  </span></span><br><span class="line">         $password .= $chars[ mt_rand(<span class="number">0</span>,     strlen($chars) - <span class="number">1</span>) ];  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">return</span> $password;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3><span id="加密">加密</span></h3><p>sha256 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$password = hash(<span class="string">'sha256'</span>, $identifier . $_POST[<span class="string">'password'</span>]);</span><br></pre></td></tr></table></figure></p><h3><span id="session">Session</span></h3><p>每次用之前一定要<code>session_start()</code>： <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session_start();</span><br><span class="line">$_SESSION[$var] = xxxx;</span><br></pre></td></tr></table></figure></p><h3><span id="cookie">Cookie</span></h3><h4><span id="如何创建-cookie">如何创建 cookie？</span></h4><p><code>setcookie()</code>函数用于设置 cookie。</p><p>语法 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setcookie(name, value, expire, path, domain);</span><br></pre></td></tr></table></figure></p><p>例子 在下面的例子中，我们将创建名为 &quot;user&quot; 的 cookie，把为它赋值 &quot;Alex Porter&quot;。我们也规定了此 cookie 在一小时后过期： <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line">setcookie(<span class="string">"user"</span>, <span class="string">"Alex Porter"</span>, time()+<span class="number">3600</span>);</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line"></span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>注释：在发送 cookie 时，cookie 的值会自动进行 URL 编码，在取回时进行自动解码（为防止 URL 编码，请使用 <code>setrawcookie()</code> 取而代之）。</p></blockquote><h4><span id="如何取回-cookie-的值">如何取回 Cookie 的值？</span></h4><p>PHP 的<code>$_COOKIE</code>变量用于取回 cookie 的值。 在下面的例子中，我们取回了名为 <code>&quot;user&quot;</code>的 cookie 的值，并把它显示在了页面上： <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="comment">// Print a cookie</span></span><br><span class="line"><span class="keyword">echo</span> $_COOKIE[<span class="string">"user"</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// A way to view all cookies</span></span><br><span class="line">print_r($_COOKIE);</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p><h4><span id="如何删除-cookie">如何删除 cookie？</span></h4><p>当删除 cookie 时，您应当使过期日期变更为过去的时间点。 删除的例子： <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> </span><br><span class="line"><span class="comment">// set the expiration date to one hour ago</span></span><br><span class="line">setcookie(<span class="string">"user"</span>, <span class="string">""</span>, time()<span class="number">-3600</span>);</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure></p><h3><span id="变参">变参</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">variable</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="keyword">echo</span> func_num_args();         <span class="comment">//输出参数个数</span></span><br><span class="line">     $varArray = func_get_args();     <span class="comment">//获取参数，返回参数数组</span></span><br><span class="line">     <span class="keyword">foreach</span>($varArray <span class="keyword">as</span> $value)</span><br><span class="line">         <span class="keyword">echo</span> $value;</span><br><span class="line">     </span><br><span class="line">     <span class="keyword">echo</span> func_get_arg;       <span class="comment">//获取单个参数</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><h3><span id="反射">反射</span></h3><p>参考：<a href="http://blog.csdn.net/hguisu/article/details/7357421" target="_blank" rel="noopener">PHP的反射机制</a> <a href="http://php.net/manual/zh/book.reflection.php" target="_blank" rel="noopener">php手册</a></p><h4><span id="建立反射类">建立反射类</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$class = <span class="keyword">new</span> ReflectionClass(<span class="string">'Person'</span>);<span class="comment">//建立 Person这个类的反射类  </span></span><br><span class="line">$instance  = $class-&gt;newInstanceArgs($args);<span class="comment">//相当于实例化Person 类</span></span><br></pre></td></tr></table></figure><h4><span id="获取属性properties">获取属性(Properties)</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$properties = $class-&gt;getProperties();  </span><br><span class="line"><span class="keyword">foreach</span>($properties <span class="keyword">as</span> $property) &#123;  </span><br><span class="line">    <span class="keyword">echo</span> $property-&gt;getName().<span class="string">"\n"</span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="获取注释">获取注释</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">foreach</span>($properties <span class="keyword">as</span> $property) &#123;  </span><br><span class="line">    <span class="keyword">if</span>($property-&gt;isProtected()) &#123;  </span><br><span class="line">        $docblock = $property-&gt;getDocComment();  </span><br><span class="line">        preg_match(<span class="string">'/ type\=([a-z_]*) /'</span>, $property-&gt;getDocComment(), $matches);  </span><br><span class="line">        <span class="keyword">echo</span> $matches[<span class="number">1</span>].<span class="string">"\n"</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="获取类的方法">获取类的方法</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>($class-&gt;hasMethod($methodName))&#123;</span><br><span class="line">$method = $class-&gt;getMethod($methodName);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4><span id="执行类的方法">执行类的方法</span></h4><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$instance-&gt;getBiography(); <span class="comment">//执行Person 里的方法getBiography  </span></span><br><span class="line"><span class="comment">//或者：  </span></span><br><span class="line">$ec=$class-&gt;getmethod(<span class="string">'getName'</span>);  <span class="comment">//获取Person 类中的getName方法  </span></span><br><span class="line">$ec-&gt;invoke($instance);       <span class="comment">//执行getName 方法 </span></span><br><span class="line"><span class="comment">// 或者：</span></span><br><span class="line">$method-&gt;invokeArgs($instance, $params); <span class="comment">// $params为数组</span></span><br></pre></td></tr></table></figure><h2><span id="uri">URI</span></h2><blockquote><p>uri结构：<code>apppath/class/method/params</code> uri示例 : <code>www.liuhe.website/index.php?/Articles/single/13</code></p></blockquote><p>实现方法：</p><ul><li>在<code>index.php</code>中通过<code>$_SERVER['REQUEST_URI']</code>获取uri，然后获取<code>className</code>, <code>methodName</code>以及<code>params</code>。</li><li>include相应控制器的文件，即<code>controller/$className.php</code>。</li><li>建立反射类，调用相关method传入相应参数。</li><li>防止直接通过文件目录访问(通过服务器配置rewrite实现)</li></ul><p>code: <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Parse uri , instantiate the class</span></span><br><span class="line"><span class="comment"> * and invoke the method</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">parseRequestUri</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">isset</span>($_SERVER[<span class="string">'REQUEST_URI'</span>])) &#123;</span><br><span class="line">        <span class="keyword">$this</span>-&gt;uri_string = $_SERVER[<span class="string">'REQUEST_URI'</span>];</span><br><span class="line">        <span class="keyword">$this</span>-&gt;segments = explode(<span class="string">'/'</span>, <span class="keyword">$this</span>-&gt;uri_string);</span><br><span class="line">        <span class="comment">// var_dump($this-&gt;segments);</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * get the class name, method name and the params</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (count(<span class="keyword">$this</span>-&gt;segments) &lt;= <span class="number">2</span>) &#123;</span><br><span class="line">            $className = <span class="string">'Articles'</span>;</span><br><span class="line">            $methodName = <span class="string">'home'</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            $className = <span class="keyword">$this</span>-&gt;segments[<span class="number">2</span>];</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">isset</span>(<span class="keyword">$this</span>-&gt;segments[<span class="number">3</span>])) &#123;</span><br><span class="line">                $methodName = <span class="keyword">$this</span>-&gt;segments[<span class="number">3</span>];</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 404 Error</span></span><br><span class="line">                <span class="keyword">$this</span>-&gt;_404Error(<span class="string">"Empty Method"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> ($_SERVER[<span class="string">'REQUEST_METHOD'</span>] == <span class="string">'GET'</span> || $_SERVER[<span class="string">'REQUEST_METHOD'</span>] == <span class="string">'POST'</span>) &#123;</span><br><span class="line">            $params = <span class="keyword">array</span>();</span><br><span class="line">            $len = count(<span class="keyword">$this</span>-&gt;segments);</span><br><span class="line">            <span class="keyword">if</span> ($len &gt; <span class="number">4</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> ($i = <span class="number">4</span>; $i &lt; $len; $i++) &#123;</span><br><span class="line">                    array_push($params, <span class="keyword">$this</span>-&gt;segments[$i]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            $classFile = <span class="string">"controller/$className.php"</span>;</span><br><span class="line">            <span class="keyword">if</span> (!file_exists($classFile)) &#123;</span><br><span class="line">                <span class="comment">// 404 error</span></span><br><span class="line">                <span class="keyword">$this</span>-&gt;_404Error(<span class="string">"File Not Found"</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">             * build reflection class, invoke the method</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">require</span> <span class="string">"$classFile"</span>;</span><br><span class="line">            $rc = <span class="keyword">new</span> ReflectionClass($className);</span><br><span class="line">            <span class="keyword">if</span> (!$rc-&gt;hasMethod($methodName)) &#123;</span><br><span class="line">                <span class="comment">// 404 error</span></span><br><span class="line">                <span class="keyword">$this</span>-&gt;_404Error(<span class="string">"Method Not Found"</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            $instance = $rc-&gt;newInstance();</span><br><span class="line">            $method = $rc-&gt;getMethod($methodName);</span><br><span class="line">            $method-&gt;invokeArgs($instance, $params);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">echo</span> <span class="string">"not set REQUEST_URI"</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2><span id="加载静态模板带参数">加载静态模板（带参数）</span></h2><p>实现方法： * 定义参数结构（占位符）：<code></code> * i 为第i个参数 * 把模板文件加载到内存，用字符串替换函数替换上述占位符。</p><p>code： <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Load a static template</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@var</span> string, array</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">function</span> <span class="title">load</span><span class="params">($page = <span class="string">''</span>, $args = array<span class="params">()</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">empty</span>($page)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    $fileName = <span class="string">"static/$page"</span>;</span><br><span class="line">    $file = fopen($fileName, <span class="string">"r"</span>);</span><br><span class="line">    $content = fread($file, filesize($fileName));</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">empty</span>($args)) &#123;</span><br><span class="line">        $i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (strpos($content, <span class="string">"&#123;&#123;args[$i]&#125;&#125;"</span>) !== <span class="keyword">false</span>) &#123;</span><br><span class="line">            $content = str_replace(<span class="string">"&#123;&#123;args[$i]&#125;&#125;"</span>, $args[$i], $content);</span><br><span class="line">            $i += <span class="number">1</span>;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">echo</span> <span class="string">"$content"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2><span id="实现自动登录">实现自动登录</span></h2><blockquote><p>以下部分来自StackOverflow</p></blockquote><h3><span id="improved-persistent-login-cookie-best-practice">Improved Persistent Login Cookie Best Practice</span></h3><ol type="1"><li>When the user successfully logs in with Remember Me checked, a login cookie is issued in addition to the standard session management cookie.</li><li>The login cookie contains a series identifier and a token. The series and token are <strong>unguessable random numbers </strong>from a suitably large space. Both are stored together in a database table, <strong>the token is hashed </strong>(sha256 is fine).</li><li>When a non-logged-in user visits the site and presents a login cookie, the series identifier is looked up in the database.<ol type="1"><li>If the series identifier is present and the hash of the token matches the hash for that series identifier, the user is considered authenticated. <strong>A new token is generated</strong>, a new hash for the token is stored over the old record, and a new login cookie is issued to the user (it's okay to re-use the series identifier).</li><li>If the series is present but the token does not match, a theft is assumed. The user receives a strongly worded warning and <strong>all of the user's remembered sessions are deleted.</strong></li><li>If the username and series are not present, the login cookie is ignored.</li></ol></li></ol><p>This approach provides defense-in-depth. If someone manages to leak the database table, it does not give an attacker an open door for impersonating users.</p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后台开发 </tag>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Mysqli 使用</title>
      <link href="/2015/12/19/Mysqli%20%E4%BD%BF%E7%94%A8/"/>
      <url>/2015/12/19/Mysqli%20%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h3><span id="连接数据库并获取相关信息">连接数据库并获取相关信息</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$mysqli=@<span class="keyword">new</span> mysqli(<span class="string">"localhost"</span>, <span class="string">"root"</span>, <span class="string">""</span>, <span class="string">"mysql"</span>);</span><br><span class="line"><span class="comment">//如果连接错误</span></span><br><span class="line"><span class="keyword">if</span>(mysqli_connect_errno())&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"连接数据库失败："</span>.mysqli_connect_error();</span><br><span class="line">    $mysqli=<span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">exit</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//获取当前字符集</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;character_set_name().<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//获取客户端信息</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;get_client_info().<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//获取mysql主机信息</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;host_info.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//获取服务器信息</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;server_info.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//获取服务器版本</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;server_version.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="comment">//关闭数据库连接</span></span><br><span class="line">$mysqli-&gt;close();</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="查询数据">查询数据</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//构造SQL语句</span></span><br><span class="line">$query = <span class="string">"SELECT * FROM  designer order by ID LIMIT 3"</span>;</span><br><span class="line"><span class="comment">//执行SQL语句</span></span><br><span class="line">$result = $mysqli-&gt;query($query);</span><br><span class="line"><span class="comment">//遍历结果</span></span><br><span class="line"><span class="keyword">while</span>($row = $result-&gt;fetch_array(MYSQLI_BOTH))&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"id"</span>.$row[<span class="string">'id'</span>].<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//释放结果集</span></span><br><span class="line">$result-&gt;free();</span><br></pre></td></tr></table></figure><p>在这里需要注意的是 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fetch_array(MYSQLI_BOTH)</span><br></pre></td></tr></table></figure></p><p>这个方法，参数有三个，分别是 <code>MYSQLI_BOTH</code>，<code>MYSQLI_NUM</code>，<code>MYSQLI_ASSOC</code>。</p><p>如果参数传入了 <code>MYSQLI_BOTH</code>，返回数组的索引既包括数字和名称。 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">array</span> (size=<span class="number">26</span>)</span><br><span class="line">  <span class="number">0</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="string">'id'</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="number">1</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="string">'name'</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="number">2</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="string">'email'</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="number">3</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br><span class="line">  <span class="string">'phone'</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><p>如果参数传入了 <code>MYSQLI_NUM</code>，返回数组的索引只包含数字。 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">array</span> (size=<span class="number">13</span>)</span><br><span class="line">  <span class="number">0</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="number">1</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="number">2</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="number">3</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><p>如果参数传入了 <code>MYSQLI_BOTH</code>，返回数组的索引只包含名称。 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">array</span> (size=<span class="number">13</span>)</span><br><span class="line">  <span class="string">'id'</span> =&gt; string <span class="string">'10062'</span> (length=<span class="number">5</span>)</span><br><span class="line">  <span class="string">'name'</span> =&gt; string <span class="string">'??'</span> (length=<span class="number">2</span>)</span><br><span class="line">  <span class="string">'email'</span> =&gt; string <span class="string">'1016903103@qq.com'</span> (length=<span class="number">17</span>)</span><br><span class="line">  <span class="string">'phone'</span> =&gt; string <span class="string">'18366119732'</span> (length=<span class="number">11</span>)</span><br></pre></td></tr></table></figure></p><p>其实还有等价的方法 <code>fetch_row()</code>，<code>fetch_assoc()</code> 他们之间的关系如下 <figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">   $result-&gt;fetch_row() </span><br><span class="line">=  mysql_fetch_row() </span><br><span class="line">=  $result-&gt;fetch_array(MYSQLI_NUM) </span><br><span class="line">=  mysql_fetch_array(MYSQLI_NUM)  </span><br><span class="line">返回索引数组</span><br><span class="line"></span><br><span class="line">   $result-&gt;fetch_assoc() </span><br><span class="line">=  mysql_fetch_assoc() </span><br><span class="line">=  $result-&gt;fetch_array(MYSQLI_ASSOC) </span><br><span class="line">=  mysql_fetch_array(MYSQLI_ASSOC)  </span><br><span class="line">返回索引列名</span><br></pre></td></tr></table></figure></p><h3><span id="插入数据">插入数据</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//插入数据</span></span><br><span class="line">$sql=<span class="string">"insert into designer(name,phone) values('hello','18352682923')"</span>;</span><br><span class="line"><span class="comment">//执行插入语句</span></span><br><span class="line">$result=$mysqli-&gt;query($sql);</span><br><span class="line"><span class="comment">//如果执行错误</span></span><br><span class="line"><span class="keyword">if</span>(!$result)&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"SQL语句有误&lt;br&gt;"</span>;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"ERROR:"</span>.$mysqli-&gt;errno.<span class="string">"|"</span>.$mysqli-&gt;error;</span><br><span class="line">    <span class="keyword">exit</span>;    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//如果插入成功，则返回影响的行数</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;affected_rows;</span><br></pre></td></tr></table></figure><h3><span id="更新数据">更新数据</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//更新数据</span></span><br><span class="line">$sql=<span class="string">"update designer set name = 'hello' where id = 10062"</span>;</span><br><span class="line"><span class="comment">//执行插入语句</span></span><br><span class="line">$result=$mysqli-&gt;query($sql);</span><br><span class="line"><span class="comment">//如果执行错误</span></span><br><span class="line"><span class="keyword">if</span>(!$result)&#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"SQL语句有误&lt;br&gt;"</span>;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">"ERROR:"</span>.$mysqli-&gt;errno.<span class="string">"|"</span>.$mysqli-&gt;error;</span><br><span class="line">    <span class="keyword">exit</span>;    </span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//如果插入成功，则返回影响的行数</span></span><br><span class="line"><span class="keyword">echo</span> $mysqli-&gt;affected_rows;</span><br></pre></td></tr></table></figure><h3><span id="预处理语句">预处理语句</span></h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//准备好一条语句放到服务器中，插入语句</span></span><br><span class="line">$sql = <span class="string">"insert into designer(name, email) values(?, ?)"</span>;</span><br><span class="line"><span class="comment">//生成预处理语句</span></span><br><span class="line">$stmt = $mysqli-&gt;prepare($sql);</span><br><span class="line"><span class="comment">//给占位符号每个?号传值（绑定参数） i  d  s  b，第一个参数为格式化字符，ss代表两个字符串，d代表数字</span></span><br><span class="line">$stmt-&gt;bind_param(<span class="string">"ss"</span>, $name, $email);</span><br><span class="line"><span class="comment">//为变量赋值</span></span><br><span class="line">$name = <span class="string">"Mike"</span>;</span><br><span class="line">$email = <span class="string">"mike@live.cn"</span>;</span><br><span class="line"><span class="comment">//执行</span></span><br><span class="line">$stmt-&gt;execute();</span><br><span class="line"><span class="comment">//为变量赋值</span></span><br><span class="line">$name = <span class="string">"Larry"</span>;</span><br><span class="line">$email = <span class="string">"larry@live.cn"</span>;</span><br><span class="line"><span class="comment">//执行</span></span><br><span class="line">$stmt-&gt;execute();</span><br><span class="line"><span class="comment">//最后输出</span></span><br><span class="line"><span class="keyword">echo</span> <span class="string">"最后ID"</span>.$stmt-&gt;insert_id.<span class="string">"&lt;br&gt;"</span>;</span><br><span class="line"><span class="keyword">echo</span> <span class="string">"影响了"</span>.$stmt-&gt;affected_rows.<span class="string">"行&lt;br&gt;"</span>;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后台开发 </tag>
            
            <tag> MySQL </tag>
            
            <tag> PHP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GIT 笔记</title>
      <link href="/2015/12/18/GIT%20%E7%AC%94%E8%AE%B0/"/>
      <url>/2015/12/18/GIT%20%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2><span id="安装git">安装Git</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git</span><br><span class="line">The program &apos;git&apos; is currently not installed. You can install it by typing:</span><br><span class="line">sudo apt-get install git</span><br></pre></td></tr></table></figure><a id="more"></a><p>安装完成之后：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name &quot;Your Name&quot;</span><br><span class="line">$ git config --global user.email &quot;email@example.com&quot;</span><br></pre></td></tr></table></figure><h2><span id="创建版本库">创建版本库</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git init</span><br><span class="line">Initialized empty Git repository in /Users/michael/learngit/.git/</span><br></pre></td></tr></table></figure><p>将文件放入仓库： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git add readme.md </span><br><span class="line">$ git commit -m &quot;add readme&quot;</span><br></pre></td></tr></table></figure></p><h2><span id="时光穿梭机">时光穿梭机</span></h2><p>查看仓库当前状态： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git status</span><br></pre></td></tr></table></figure></p><p>查看修改： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git diff</span><br></pre></td></tr></table></figure></p><h3><span id="版本退回">版本退回</span></h3><p>查看提交日志： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git log</span><br></pre></td></tr></table></figure></p><p>一条日志在一行显示： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git log --pretty=online</span><br></pre></td></tr></table></figure></p><blockquote><p>在Git中，用<code>HEAD</code>表示当前版本，也就是最新的提交<code>3628164...882e1e0</code>（注意我的提交ID和你的肯定不一样），上一个版本就是<code>HEAD^</code>，上上一个版本就是<code>HEAD^^</code>，当然往上100个版本写100个^比较容易数不过来，所以写成<code>HEAD~100</code>。</p></blockquote><p>退回到上一版本： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git reset --hard HEAD^</span><br></pre></td></tr></table></figure></p><p>记录每一条命令： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git reflog</span><br></pre></td></tr></table></figure></p><h3><span id="工作区和暂存区">工作区和暂存区</span></h3><figure><img src="/images/1446625069461.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p><strong>工作区有一个隐藏目录<code>.git</code>，这个不算工作区，而是Git的版本库。</strong></p><blockquote><p>Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支<code>master</code>，以及指向<code>master</code>的一个指针叫<code>HEAD</code>。</p></blockquote><h3><span id="管理修改">管理修改</span></h3><p><strong>每次修改，如果不<code>add</code>到暂存区，那就不会加入到<code>commit</code>中。</strong></p><h3><span id="撤销修改">撤销修改</span></h3><p>丢弃工作区的修改： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -- file</span><br></pre></td></tr></table></figure></p><blockquote><p>命令<code>git checkout -- readme.txt</code>意思就是，把<code>readme.txt</code>文件在工作区的修改全部撤销，这里有两种情况： * 一种是<code>readme.txt</code>自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； * 一种是<code>readme.txt</code>已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。</p></blockquote><p><strong>场景1</strong>：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令<code>git checkout -- file</code>。</p><p><strong>场景2</strong>：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令<code>git reset HEAD file</code>，就回到了场景1，第二步按场景1操作。 <br></p><p><strong>场景3</strong>：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考<em>版本回退</em>一节</p><h3><span id="删除文件">删除文件</span></h3><p>从版本库里删除文件： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git rm file</span><br><span class="line">$ git commit -m &quot;remove file&quot;</span><br></pre></td></tr></table></figure></p><blockquote><p>命令<code>git rm</code>用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，<strong>但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。</strong></p></blockquote><h2><span id="远程仓库">远程仓库</span></h2><p>创建SSH Key： <code>$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot;</code></p><p>如果一切顺利的话，可以在用户主目录里找到.ssh目录，里面有<code>id_rsa</code>和<code>id_rsa.pub</code>两个文件，这两个就是SSH Key的秘钥对，<code>id_rsa</code>是私钥，不能泄露出去，<code>id_rsa.pub</code>是公钥，可以放心地告诉任何人。</p><h3><span id="添加远程库">添加远程库</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote add origin git@github.com:NeymarL/learngit.git</span><br></pre></td></tr></table></figure><blockquote><p>添加后，远程库的名字就是<code>origin</code>，这是Git默认的叫法，也可以改成别的，但是<code>origin</code>这个名字一看就知道是远程库。</p></blockquote><p>把本地库的所有内容推送到远程库上： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push -u origin master</span><br></pre></td></tr></table></figure></p><blockquote><p>加上了<code>-u</code>参数，Git不但会把本地的<code>master</code>分支内容推送的远程新的<code>master</code>分支，还会把本地的<code>master</code>分支和远程的master分支关联起来</p></blockquote><h3><span id="从远程库克隆">从远程库克隆</span></h3><p>从远程库克隆一个本地库： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git@github.com:NeymarL/gitskills.git</span><br></pre></td></tr></table></figure></p><h2><span id="分支管理">分支管理</span></h2><h3><span id="创建与合并分支">创建与合并分支</span></h3><figure><img src="/images/1446626485656.png" alt="Alt text"><figcaption>Alt text</figcaption></figure><p>每次提交，<code>master</code>分支都会向前移动一步，这样，随着你不断提交，<code>master</code>分支的线也越来越长。</p><p>当我们创建新的分支，例如<code>dev</code>时，Git新建了一个指针叫<code>dev</code>，指向<code>master</code>相同的提交，再把<code>HEAD</code>指向<code>dev</code>，就表示当前分支在<code>dev</code>上： <img src="/images/1446626525260.png" alt="Alt text"></p><p>Git创建一个分支很快，因为除了增加一个<code>dev</code>指针，改改<code>HEAD</code>的指向，工作区的文件都没有任何变化！</p><p>Git怎么合并呢？最简单的方法，就是直接把<code>master</code>指向<code>dev</code>的当前提交，就完成了合并： <img src="/images/1446626632797.png" alt="Alt text"></p><p>合并完分支后，甚至可以删除<code>dev</code>分支。删除<code>dev</code>分支就是把<code>dev</code>指针给删掉，删掉后，我们就剩下了一条<code>master</code>分支： <img src="/images/1446626670302.png" alt="Alt text"></p><hr><p>首先，我们创建dev分支，然后切换到dev分支： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout -b dev</span><br><span class="line">Switched to a new branch &apos;dev</span><br></pre></td></tr></table></figure></p><p><code>git checkout</code>命令加上<code>-b</code>参数表示创建并切换，相当于以下两条命令： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git branch dev</span><br><span class="line">$ git checkout dev</span><br></pre></td></tr></table></figure></p><p>然后，用<code>git branch</code>命令查看当前分支： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git branch</span><br><span class="line">* dev</span><br><span class="line">  master</span><br></pre></td></tr></table></figure></p><p><code>git branch</code>命令会列出所有分支，当前分支前面会标一个<code>*</code>号。</p><p>然后，我们就可以在<code>dev</code>分支上正常提交。</p><p><code>dev</code>分支的工作完成，我们就可以切换回<code>master</code>分支： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &apos;master&apos;</span><br></pre></td></tr></table></figure></p><p>切换回<code>master</code>分支后，刚才添加的内容不见了！因为那个提交是在<code>dev</code>分支上，而<code>master</code>分支此刻的提交点并没有变： <img src="/images/1446626948887.png" alt="Alt text"></p><p>现在，我们把dev分支的工作成果合并到master分支上： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git merge dev</span><br></pre></td></tr></table></figure></p><p>合并完成后，就可以放心地删除<code>dev</code>分支了： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git branch -d dev</span><br><span class="line">Deleted branch dev (was fec145a).</span><br></pre></td></tr></table></figure></p><blockquote><p>因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在<code>master</code>分支上工作效果是一样的，但过程更安全。</p></blockquote><p>Git鼓励大量使用分支：</p><ul><li><p>查看分支：<code>git branch</code></p></li><li><p>创建分支：<code>git branch &lt;name&gt;</code></p></li><li><p>切换分支：<code>git checkout &lt;name&gt;</code></p></li><li><p>创建+切换分支：<code>git checkout -b &lt;name&gt;</code></p></li><li><p>合并某分支到当前分支：<code>git merge &lt;name&gt;</code></p></li><li><p>删除分支：<code>git branch -d &lt;name&gt;</code></p></li></ul><h3><span id="解决冲突">解决冲突</span></h3><p>假设，<code>master</code>分支和<code>feature1</code>分支各自都分别有新的提交，变成了这样： <img src="/images/1446627386655.png" alt="Alt text"></p><p>这种情况下，Git无法执行“快速合并”，只能试图把各自的修改合并起来，但这种合并就可能会有冲突，<strong>必须手动解决冲突后再提交。</strong></p><p>提交之后： <img src="/images/1446627526133.png" alt="Alt text"></p><p>用带参数的<code>git log</code>也可以看到分支的合并情况： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ git log --graph --pretty=oneline --abbrev-commit</span><br><span class="line">*   59bc1cb conflict fixed</span><br><span class="line">|\</span><br><span class="line">| * 75a857c AND simple</span><br><span class="line">* | 400b400 &amp; simple</span><br><span class="line">|/</span><br><span class="line">* fec145a branch test</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><h3><span id="分支管理策略">分支管理策略</span></h3><p>通常，合并分支时，如果可能，Git会用<code>Fast forward</code>模式，但这种模式下，删除分支后，会丢掉分支信息。</p><p>如果要用<code>--no-ff</code>强制禁用<code>Fast forward</code>模式，Git就会在<code>merge</code>时生成一个新的<code>commit</code>，这样，从分支历史上就可以看出分支信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git merge --no-ff -m &quot;merge with no-ff&quot; dev</span><br></pre></td></tr></table></figure><p>因为本次合并要创建一个新的<code>commit</code>，所以加上-m参数，把<code>commit</code>描述写进去。</p><p>可以看到，不使用<code>Fast forward</code>模式，<code>merge</code>后就像这样： <img src="/images/1446627786918.png" alt="Alt text"></p><h4><span id="分支策略">分支策略</span></h4><p>在实际开发中，我们应该按照几个基本原则进行分支管理：</p><p>首先，<code>master</code>分支应该是非常稳定的，也就是仅用来发布新版本，<strong>平时不能在上面干活</strong>；</p><p>那在哪干活呢？干活都在<code>dev</code>分支上，也就是说，<code>dev</code>分支是不稳定的，到某个时候，比如1.0版本发布时，再把<code>dev</code>分支合并到<code>master</code>上，在<code>master</code>分支发布1.0版本；</p><p><strong>你和你的小伙伴们每个人都在<code>dev</code>分支上干活</strong>，每个人都有自己的分支，时不时地往<code>dev</code>分支上合并就可以了。</p><p>所以，团队合作的分支看起来就像这样： <img src="/images/1446628189809.png" alt="Alt text"> &gt; 合并分支时，加上<code>--no-ff</code>参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而<code>fast forward</code>合并就看不出来曾经做过合并。</p><h3><span id="bug分支">Bug分支</span></h3><p>Git还提供了一个<code>stash</code>功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git stash</span><br><span class="line">Saved working directory and index state WIP on dev: 6224937 add merge</span><br><span class="line">HEAD is now at 6224937 add merge</span><br></pre></td></tr></table></figure></p><p>现在，用<code>git status</code>查看工作区，就是干净的（除非有没有被Git管理的文件），因此可以放心地创建分支来修复bug。</p><p>首先确定要在哪个分支上修复bug，假定需要在<code>master</code>分支上修复，就从<code>master</code>创建临时分支： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line">Switched to branch &apos;master&apos;</span><br><span class="line">Your branch is ahead of &apos;origin/master&apos; by 6 commits.</span><br><span class="line"></span><br><span class="line">$ git checkout -b issue-101</span><br><span class="line">Switched to a new branch &apos;issue-101&apos;</span><br></pre></td></tr></table></figure></p><p>现在修复bug，修复完成后，切换到master分支，并完成合并，最后删除issue-101分支： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout master</span><br><span class="line"></span><br><span class="line">$ git merge --no-ff -m &quot;merged bug fix 101&quot; issue-101</span><br><span class="line"></span><br><span class="line">$ git branch -d issue-101</span><br></pre></td></tr></table></figure></p><p>现在，是时候接着回到dev分支干活了！ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout dev</span><br></pre></td></tr></table></figure></p><p>用<code>git stash list</code>命令看看之前保存的工作现场： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git stash list</span><br><span class="line">stash@&#123;0&#125;: WIP on dev: 6224937 add merge</span><br></pre></td></tr></table></figure></p><p>工作现场还在，Git把<code>stash</code>内容存在某个地方了，但是需要恢复一下，有两个办法：</p><ul><li><p>一是用<code>git stash apply</code>恢复，但是恢复后，<code>stash</code>内容并不删除，你需要用<code>git stash drop</code>来删除；</p></li><li><p>另一种方式是用<code>git stash pop</code>，恢复的同时把stash内容也删了.</p></li></ul><p>你可以多次<code>stash</code>，恢复的时候，先用<code>git stash list</code>查看，然后恢复指定的<code>stash</code>，用命令： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git stash apply stash@&#123;0&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除； 当手头工作没有完成时，先把工作现场<code>git stash</code>一下，然后去修复bug，修复后，再<code>git stash pop</code>，回到工作现场。</p></blockquote><h3><span id="feature分支">Feature分支</span></h3><p>开发一个新feature，最好新建一个分支；</p><p>如果要丢弃一个没有被合并过的分支，可以通过<code>git branch -D &lt;name&gt;</code>强行删除。</p><h3><span id="多人协作">多人协作</span></h3><p>要查看远程库的信息： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git remote [-v]</span><br></pre></td></tr></table></figure></p><p>但是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？</p><ul><li><code>master</code>分支是主分支，因此要<strong>时刻与远程同步</strong>；</li><li><code>dev</code>分支是开发分支，团队所有成员都需要在上面工作，所以<strong>也需要与远程同步</strong>；</li><li>bug分支只用于在本地修复bug，就<strong>没必要推到远程</strong>了，除非老板要看看你每周到底修复了几个bug；</li><li>feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。</li></ul><p>总之，就是在Git中，<strong>分支完全可以在本地自己藏着玩，是否推送，视你的心情而定！</strong></p><h2><span id="标签管理">标签管理</span></h2><blockquote><p>发布一个版本时，我们通常先在版本库中打一个标签，这样，就唯一确定了打标签时刻的版本。将来无论什么时候，取某个标签的版本，就是把那个打标签的时刻的历史版本取出来。所以，标签也是版本库的一个快照。</p></blockquote><blockquote><p>Git的标签虽然是版本库的快照，但其实它就是指向某个<code>commit</code>的指针（跟分支很像对不对？但是分支可以移动，标签不能移动），所以，创建和删除标签都是瞬间完成的。</p></blockquote><h3><span id="创建标签">创建标签</span></h3><p>在Git中打标签非常简单，首先，切换到需要打标签的分支上，然后，敲命令<code>git tag &lt;name&gt;</code>就可以打一个新标签： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git tag v1.0</span><br></pre></td></tr></table></figure></p><p>可以用命令<code>git tag</code>查看所有标签： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git tag</span><br><span class="line">v1.0</span><br></pre></td></tr></table></figure></p><p>默认标签是打在最新提交的<code>commit</code>上的。有时候，如果忘了打标签，比如，现在已经是周五了，但应该在周一打的标签没有打，怎么办？</p><p>方法是找到历史提交的<code>commit id</code>，然后打上就可以了： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ git log --pretty=oneline --abbrev-commit</span><br><span class="line">6a5819e merged bug fix 101</span><br><span class="line">cc17032 fix bug 101</span><br><span class="line">7825a50 merge with no-ff</span><br><span class="line">6224937 add merge</span><br><span class="line">59bc1cb conflict fixed</span><br><span class="line">400b400 &amp; simple</span><br><span class="line">75a857c AND simple</span><br><span class="line">fec145a branch test</span><br><span class="line">d17efd8 remove test.txt</span><br><span class="line"></span><br><span class="line">比方说要对add merge这次提交打标签，它对应的commit id是6224937，敲入命令：</span><br><span class="line"></span><br><span class="line">$ git tag v0.9 6224937</span><br></pre></td></tr></table></figure></p><p><strong>注意，标签不是按时间顺序列出，而是按字母排序的。</strong> 可以用<code>git show &lt;tagname&gt;</code>查看标签信息： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ git show v0.9</span><br><span class="line">commit 622493706ab447b6bb37e4e2a2f276a20fed2ab4</span><br><span class="line">Author: Michael Liao &lt;askxuefeng@gmail.com&gt;</span><br><span class="line">Date:   Thu Aug 22 11:22:08 2013 +0800</span><br><span class="line"></span><br><span class="line">    add merge</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>还可以创建带有说明的标签，用<code>-a</code>指定标签名，<code>-m</code>指定说明文字： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -a v0.1 -m &quot;version 0.1 released&quot; 3628164</span><br></pre></td></tr></table></figure></p><p>还可以通过<code>-s</code>用私钥签名一个标签： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -s v0.2 -m &quot;signed version 0.2 released&quot; fec145a</span><br></pre></td></tr></table></figure></p><p>签名采用PGP签名，因此，必须首先安装gpg（GnuPG），如果没有找到gpg，或者没有gpg密钥对，就会报错： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpg: signing failed: secret key not available</span><br><span class="line">error: gpg failed to sign the data</span><br><span class="line">error: unable to sign the tag</span><br></pre></td></tr></table></figure></p><p>如果报错，请参考GnuPG帮助文档配置Key。</p><p><strong>小结</strong>： * 命令<code>git tag &lt;name&gt;</code>用于新建一个标签，默认为<code>HEAD</code>，也可以指定一个<code>commit id</code>；</p><ul><li><p><code>git tag -a &lt;tagname&gt; -m &quot;blablabla...&quot;</code>可以指定标签信息；</p></li><li><p><code>git tag -s &lt;tagname&gt; -m &quot;blablabla...&quot;</code>可以用PGP签名标签；</p></li><li><p>命令<code>git tag</code>可以查看所有标签。</p></li></ul><h3><span id="操作标签">操作标签</span></h3><p>如果标签打错了，也可以删除： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -d v0.1</span><br><span class="line">Deleted tag &apos;v0.1&apos; (was e078af9)</span><br></pre></td></tr></table></figure></p><p>因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。</p><p>如果要推送某个标签到远程，使用命令<code>git push origin &lt;tagname&gt;</code>： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin v1.0</span><br></pre></td></tr></table></figure></p><p>或者，一次性推送全部尚未推送到远程的本地标签： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin --tags</span><br></pre></td></tr></table></figure></p><p>如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git tag -d v0.9</span><br><span class="line">Deleted tag &apos;v0.9&apos; (was 6224937)</span><br></pre></td></tr></table></figure></p><p>然后，从远程删除。删除命令也是push，但是格式如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git push origin :refs/tags/v0.9</span><br><span class="line">To git@github.com:michaelliao/learngit.git</span><br><span class="line"> - [deleted]         v0.9</span><br></pre></td></tr></table></figure></p><p><strong>小结</strong></p><ul><li><p>命令<code>git push origin &lt;tagname&gt;</code>可以推送一个本地标签；</p></li><li><p>命令<code>git push origin --tags</code>可以推送全部未推送过的本地标签；</p></li><li><p>命令<code>git tag -d &lt;tagname&gt;</code>可以删除一个本地标签；</p></li><li><p>命令<code>git push origin :refs/tags/&lt;tagname&gt;</code>可以删除一个远程标签。</p></li></ul><h2><span id="自定义git">自定义Git</span></h2><p>让Git显示颜色，会让命令输出看起来更醒目： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global color.ui true</span><br></pre></td></tr></table></figure></p><h3><span id="忽略特殊文件">忽略特殊文件</span></h3><blockquote><p>在Git工作区的根目录下创建一个特殊的<code>.gitignore</code>文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。</p></blockquote><p>不需要从头写<code>.gitignore</code>文件，GitHub已经为我们准备了各种配置文件，只需要组合一下就可以使用了。所有配置文件可以直接在线浏览：https://github.com/github/gitignore</p><p><strong>忽略文件的原则是：</strong></p><ul><li>忽略操作系统自动生成的文件，比如缩略图等；</li><li>忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的<code>.class</code>文件；</li><li>忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。</li></ul><p>最后要把<code>.gitignore</code>提交到Git，就完成了。 检验<code>.gitignore</code>的标准是<code>git status</code>命令是不是说<code>working directory clean</code>。</p><h3><span id="配置别名">配置别名</span></h3><p>如果敲<code>git st</code>就表示<code>git status</code>那就简单多了，当然这种偷懒的办法我们是极力赞成的。</p><p>我们只需要敲一行命令，告诉Git，以后<code>st</code>就表示<code>status</code>： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global alias.st status</span><br></pre></td></tr></table></figure></p><p><code>--global</code>参数是全局参数，也就是这些命令在这台电脑的所有Git仓库下都有用。</p><p>配置一个<code>git last</code>，让其显示最后一次提交信息： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global alias.last &apos;log -1&apos;</span><br></pre></td></tr></table></figure></p><p>甚至还有人丧心病狂地把lg配置成了： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global alias.lg &quot;log --color --graph --pretty=format:&apos;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&apos; --abbrev-commit&quot;</span><br></pre></td></tr></table></figure></p><p>来看看git lg的效果： <img src="/images/1446651004964.png" alt="Alt text"></p><h4><span id="配置文件">配置文件</span></h4><p>配置文件放哪了？每个仓库的Git配置文件都放在<code>.git/config</code>文件中： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ cat .git/config </span><br><span class="line">[core]</span><br><span class="line">    repositoryformatversion = 0</span><br><span class="line">    filemode = true</span><br><span class="line">    bare = false</span><br><span class="line">    logallrefupdates = true</span><br><span class="line">    ignorecase = true</span><br><span class="line">    precomposeunicode = true</span><br><span class="line">[remote &quot;origin&quot;]</span><br><span class="line">    url = git@github.com:michaelliao/learngit.git</span><br><span class="line">    fetch = +refs/heads/*:refs/remotes/origin/*</span><br><span class="line">[branch &quot;master&quot;]</span><br><span class="line">    remote = origin</span><br><span class="line">    merge = refs/heads/master</span><br><span class="line">[alias]</span><br><span class="line">    last = log -1</span><br></pre></td></tr></table></figure></p><p>别名就在<code>[alias]</code>后面，要删除别名，直接把对应的行删掉即可。</p><p>而当前用户的Git配置文件放在用户主目录下的一个隐藏文件<code>.gitconfig</code>中： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat .gitconfig</span><br><span class="line">[alias]</span><br><span class="line">    co = checkout</span><br><span class="line">    ci = commit</span><br><span class="line">    br = branch</span><br><span class="line">    st = status</span><br><span class="line">[user]</span><br><span class="line">    name = Your Name</span><br><span class="line">    email = your@email.com</span><br></pre></td></tr></table></figure></p><p>配置别名也可以直接修改这个文件，如果改错了，可以删掉文件重新通过命令配置。</p><h3><span id="搭建git服务器">搭建Git服务器</span></h3><p>假设你已经有<code>sudo</code>权限的用户账号，下面，正式开始安装。</p><p><strong>第一步，安装git：</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install git</span><br></pre></td></tr></table></figure></p><p><strong>第二步，创建一个git用户，用来运行git服务：</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo adduser git</span><br></pre></td></tr></table></figure></p><p><strong>第三步，创建证书登录：</strong></p><p>收集所有需要登录的用户的公钥，就是他们自己的<code>id_rsa.pub</code>文件，把所有公钥导入到<code>/home/git/.ssh/authorized_keys</code>文件里，一行一个。</p><p><strong>第四步，初始化Git仓库：</strong></p><p>先选定一个目录作为Git仓库，假定是<code>/srv/sample.git</code>，在<code>/srv</code>目录下输入命令： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo git init --bare sample.git</span><br></pre></td></tr></table></figure></p><p>Git就会创建一个裸仓库，裸仓库没有工作区，因为服务器上的Git仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的Git仓库通常都以.git结尾。然后，把<code>owner</code>改为git： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo chown -R git:git sample.git</span><br></pre></td></tr></table></figure></p><p><strong>第五步，禁用shell登录：</strong></p><p>出于安全考虑，第二步创建的git用户不允许登录shell，这可以通过编辑<code>/etc/passwd</code>文件完成。找到类似下面的一行： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git:x:1001:1001:,,,:/home/git:/bin/bash</span><br><span class="line">改为：</span><br><span class="line">git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell</span><br></pre></td></tr></table></figure></p><p>这样，git用户可以正常通过<code>ssh</code>使用git，但无法登录<code>shell</code>，因为我们为git用户指定的<code>git-shell</code>每次一登录就自动退出。</p><p><strong>第六步，克隆远程仓库：</strong></p><p>现在，可以通过<code>git clone</code>命令克隆远程仓库了，在各自的电脑上运行： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git@server:/srv/sample.git</span><br><span class="line">Cloning into &apos;sample&apos;...</span><br><span class="line">warning: You appear to have cloned an empty repository.</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>记录：Archlinux搭建php，nginx，mysql开发环境</title>
      <link href="/2015/12/18/%E8%AE%B0%E5%BD%95%EF%BC%9AArchlinux%E6%90%AD%E5%BB%BAphp%EF%BC%8Cnginx%EF%BC%8Cmysql%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"/>
      <url>/2015/12/18/%E8%AE%B0%E5%BD%95%EF%BC%9AArchlinux%E6%90%AD%E5%BB%BAphp%EF%BC%8Cnginx%EF%BC%8Cmysql%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h2><span id="installation">Installation</span></h2><h3><span id="安装php">安装php</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S php</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="安装php-fpm">安装php-fpm</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S php-fpm</span><br></pre></td></tr></table></figure><h3><span id="安装nginx">安装nginx</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S nginx</span><br></pre></td></tr></table></figure><h3><span id="安装mariadb">安装Mariadb</span></h3><blockquote><p>Mariadb是mysql的一个分支</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> sudo pacman -S mysql</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">## Configuration</span><br><span class="line"></span><br><span class="line">### 配置 Nginx</span><br><span class="line">配置文件：/etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><h1><span id="修改部分">修改部分</span></h1><h1><span id="把root目录移出loaction并加上indexphp">把root目录移出loaction,并加上index.php</span></h1><p>root /usr/share/nginx/html; location / { index index.html index.htm index.php; }</p><h1><span id="注释掉root和param修改pass和inlude">注释掉root和param,修改pass和inlude</span></h1><p>location ~ .php$ { #root html; fastcgi_pass unix:/run/php-fpm/php-fpm.sock; fastcgi_index index.php; #fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; include fastcgi.conf ; } <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">**web目录为 `/usr/share/nginx/html` **</span><br><span class="line"></span><br><span class="line">### 配置 php-fpm</span><br><span class="line">配置文件：/etc/php/php-fpm.conf</span><br><span class="line"></span><br><span class="line">让 listen 的值与之前 nginx 配置中的 fastcgi_pass 值保持一致。</span><br><span class="line"></span><br><span class="line">```shell</span><br><span class="line">$ listen = /run/php-fpm/php-fpm.sock</span><br></pre></td></tr></table></figure></p><h3><span id="配置php">配置php</span></h3><p>配置文件： /etc/php/php.ini</p><p><code>open_basedir</code> 中加上 nginx 服务器的根目录（ /usr/share/nginx/html/ ）。即告诉 php 程序要去解析那个目录下的 php 文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open_basedir = /usr/share/nginx/html/:/srv/http/:/home/:/tmp/:/usr/share/pear/:/usr/share/webapps/</span><br></pre></td></tr></table></figure><p>启用以下扩展。去掉那行开头的分号即可： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">extension=curl.so</span><br><span class="line">extension=gd.so</span><br><span class="line">extension=gettext.so</span><br><span class="line">extension=mysql.so</span><br><span class="line">extension=mysqli.so</span><br><span class="line">extension=phar.so</span><br><span class="line">extension=pdo_mysql.so</span><br></pre></td></tr></table></figure></p><h3><span id="配置数据库">配置数据库</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># Install mariadb</span><br><span class="line">$ mysql_install_db --user=mysql --basedir=/usr --datadir=/var/lib/mysql</span><br><span class="line"></span><br><span class="line"># starting the mysqld.service, &apos;d&apos; is important</span><br><span class="line">$ sudo systemctl start mysqld.service</span><br><span class="line"></span><br><span class="line"># 设置root密码</span><br><span class="line">$ mysql_secure_installation</span><br><span class="line"></span><br><span class="line"># Upgrade MariaDB</span><br><span class="line">$ mysql_upgrade -u root -p</span><br></pre></td></tr></table></figure><h2><span id="启动服务器">启动服务器</span></h2><h3><span id="设置为开机启动">设置为开机启动</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl enable nginx.service</span><br><span class="line">$ sudo systemctl enable mysqld.service</span><br><span class="line">$ sudo systemctl enable php-fpm.service</span><br></pre></td></tr></table></figure><h4><span id="启动服务器">启动服务器</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start nginx.service</span><br><span class="line">$ sudo systemctl start mysqld.service</span><br><span class="line">$ sudo systemctl start php-fpm.service</span><br></pre></td></tr></table></figure><p>配置完毕</p><hr><p>参考： <a href="http://www.it165.net/pro/html/201410/23683.html" target="_blank" rel="noopener">Archlinux 上 Nginx + PHP + Mariadb + DiscuzX2.5 安装小记</a> <a href="https://wiki.archlinux.org/index.php/MySQL" target="_blank" rel="noopener">MySQL-ArchWiki</a> <a href="https://wiki.archlinux.org/index.php/Nginx" target="_blank" rel="noopener">Nginx-ArchWiki</a></p>]]></content>
      
      
      <categories>
          
          <category> 踩坑现场 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后台开发 </tag>
            
            <tag> Linux </tag>
            
            <tag> MySQL </tag>
            
            <tag> PHP </tag>
            
            <tag> Arch </tag>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>gdb基本使用方法</title>
      <link href="/2015/12/17/gdb%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>/2015/12/17/gdb%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>一个除错程序执行的流程通常是这样的：</p><ol type="1"><li>进入除错程序并指定可执行文件。</li><li>指定程序代码所在目录。</li><li>设定断点后执行程序。</li><li>程序于断点中断后，可以 1. 检视程序执行状态；检视变量值或变更变量值 2. 逐步执行程序，或是全速执行程序到下一个断点或是到程序结束为止。</li><li>离开除错程序。</li></ol><a id="more"></a><h3><span id="进入-gdb-及指定可执行档">进入 GDB 及指定可执行档：</span></h3><p>进入 GDB 并读入可执行档 (档名为 <code>PROGRAM</code>)，准备进行除错。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb PROGRAM</span><br></pre></td></tr></table></figure></p><h3><span id="指定程序代码所在目录及检视程序代码">指定程序代码所在目录及检视程序代码</span></h3><p>增加目录<code>DIR</code>到收寻程序代码的目录列表 (如果你的程序代码和可执行档放在同一个目录下，就不须指定程序代码所在目录。)： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) directory DIR</span><br></pre></td></tr></table></figure></p><h4><span id="检视程序代码格式计有">检视程序代码，格式计有：</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(gdb) list // 显示目前执行程序代码前后各五行的程序代码；或是显示从上次 list 之后的程序代码</span><br><span class="line">(gdb) list function // 显示该程序开始处前后五行的程序代码。</span><br><span class="line">(gdb) list - //上次显示程序代码的前面的十行。</span><br></pre></td></tr></table></figure><h3><span id="断点的设定与清除">断点的设定与清除</span></h3><h4><span id="设定断点指令为-break可简写为-b格式计有">设定断点(指令为 <code>break</code>，可简写为 (<code>b</code>)，格式计有：</span></h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(gdb) <span class="keyword">break</span> filename.c:<span class="number">30</span> <span class="comment">// 在 filename.c 的第三十行处停止执行。</span></span><br><span class="line">(gdb) <span class="keyword">break</span> function <span class="comment">// 在进入 function 时中断程序的执行。</span></span><br><span class="line">(gdb) <span class="keyword">break</span> filename.c:function <span class="comment">// 在程序代码档 filename.c 中的函数 function 处设定断点。</span></span><br><span class="line">(gdb) <span class="keyword">break</span> <span class="comment">// 在下一个将被执行的命令设定断点。</span></span><br><span class="line">(gdb) <span class="keyword">break</span> ... <span class="keyword">if</span> cond <span class="comment">// 只有当 cond 成立的时候才中断。cond 须以 C 语言的语法写成。</span></span><br></pre></td></tr></table></figure><h4><span id="显示各个断点的信息">显示各个断点的信息。</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) info break</span><br></pre></td></tr></table></figure><h4><span id="清除断点命令为-clear格式同-break-例如">清除断点(命令为 <code>clear</code>)，格式同 <code>break</code> 。例如 :</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) clear filename.c:30</span><br></pre></td></tr></table></figure><h4><span id="清除断点num-是在-info-break-显示出来的断点编号">清除断点，<code>NUM</code> 是在 <code>info break</code> 显示出来的断点编号</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) delete NUM</span><br></pre></td></tr></table></figure><h3><span id="全速及逐步执行程序">全速及逐步执行程序</span></h3><h5><span id="从程序开头全速执行程序直到遇到断点或是程序执行完毕为止">从程序开头全速执行程序，直到遇到断点或是程序执行完毕为止</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) run</span><br></pre></td></tr></table></figure><h5><span id="在程序被中断后全速执行程序到下一个断点或是程序结束为止-continue-指令可简写为-c">在程序被中断后，全速执行程序到下一个断点或是程序结束为止 (<code>continue</code> 指令可简写为 <code>c</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) continue</span><br></pre></td></tr></table></figure><h5><span id="执行一行程序-若呼叫函数-则将该包含该函数程序代码视为一行程序-next-指令可简写为-n">执行一行程序. 若呼叫函数, 则将该包含该函数程序代码视为一行程序 (<code>next</code> 指令可简写为 <code>n</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) next</span><br></pre></td></tr></table></figure><h5><span id="执行一行程序-若呼叫函数-则进入函数逐行执行-step-指令可简写为-s">执行一行程序. 若呼叫函数, 则进入函数逐行执行 (<code>step</code> 指令可简写为 <code>s</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) step</span><br></pre></td></tr></table></figure><h5><span id="执行一行程序若此时程序是在-forwhiledo-loop-循环的最后一行则一直执行到循环结束后的第一行程序后停止-until-指令可简写为-u">执行一行程序，若此时程序是在 <code>for/while/do loop</code> 循环的最后一行，则一直执行到循环结束后的第一行程序后停止 (<code>until</code> 指令可简写为 <code>u</code>)</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) until</span><br></pre></td></tr></table></figure><h4><span id="执行现行程序到回到上一层程序为止">执行现行程序到回到上一层程序为止。</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) finish</span><br></pre></td></tr></table></figure><h3><span id="检视及更改变量值">检视及更改变量值</span></h3><h5><span id="print-叙述显示该叙述执行的结果-print-指令可简写为-p如"><code>print</code> 叙述，显示该叙述执行的结果 (<code>print</code> 指令可简写为 <code>p</code>).如</span></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gdb) print a <span class="comment">// 显示 a 变量的内容.</span></span><br><span class="line">(gdb) <span class="function">print <span class="title">sizeof</span><span class="params">(a)</span> <span class="comment">// 显示 a 变量的长度.</span></span></span><br></pre></td></tr></table></figure><h5><span id="display-叙述在每个断点或是每执行一步时显示该叙述值-如"><code>display</code> 叙述，在每个断点或是每执行一步时显示该叙述值。如</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) display a</span><br></pre></td></tr></table></figure><h5><span id="更改变量值">更改变量值：</span></h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) print (a=<span class="number">10</span>) <span class="comment">// 将变量 a 的值设定为 10.</span></span><br></pre></td></tr></table></figure><h3><span id="检视程序执行状态">检视程序执行状态</span></h3><h4><span id="查看程序执行到此时是经过哪些函数呼叫的程序-backtrace-指令可简写为-bt也就是查看函数呼叫堆栈">查看程序执行到此时，是经过哪些函数呼叫的程序 (<code>backtrace</code> 指令可简写为 <code>bt</code>)，也就是查看函数呼叫堆栈。</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(gdb) backtrace</span><br></pre></td></tr></table></figure><h3><span id="读取-core-文件信息">读取 Core 文件信息</span></h3><h5><span id="读入-program-及-programcore-档可检视-core-dump-时程序变量值及程序流程状态">读入 <code>PROGRAM</code> 及 <code>PROGRAM.CORE</code> 档，可检视 Core Dump 时程序变量值及程序流程状态 。</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb PROGRAM core</span><br></pre></td></tr></table></figure><blockquote><p>说明：<code>core</code> 档案是由 <code>PROGRAM</code> 档执行后，遇到 Core Dump 时产生的 Core 檔檔名。如果你还需要该 Core 档，我们建议你将该档案档名更改为 <code>PROGRAM.core</code>。在输入上述命令后，你可以用 GDB 提供的检视变量值以及检视程序执行状态来读取程序 Core Dump 时的状态。</p></blockquote><h3><span id="查看汇编代码-寄存器-内存等">查看汇编代码、寄存器、内存等</span></h3><p><strong>查看汇编代码</strong></p><p>查看从当前位置往后10行的代码 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x /10i $pc</span><br></pre></td></tr></table></figure></p><p><strong>查看寄存器的值</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">info register</span><br><span class="line">info all-registers</span><br><span class="line">info registers &lt;regname ...&gt;</span><br></pre></td></tr></table></figure><p><strong>查看内存的值</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x /10x *&lt;addr&gt;</span><br><span class="line">x /10x $esp</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GDB </tag>
            
            <tag> Debug </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>在PHP语言中使用JSON</title>
      <link href="/2015/12/17/%E5%9C%A8PHP%E8%AF%AD%E8%A8%80%E4%B8%AD%E4%BD%BF%E7%94%A8JSON/"/>
      <url>/2015/12/17/%E5%9C%A8PHP%E8%AF%AD%E8%A8%80%E4%B8%AD%E4%BD%BF%E7%94%A8JSON/</url>
      
        <content type="html"><![CDATA[<blockquote><p>从5.2版本开始，PHP原生提供<code>json_encode()</code>和<code>json_decode()</code>函数，前者用于编码，后者用于解码。</p></blockquote><a id="more"></a><h2><span id="json_encode">json_encode()</span></h2><p>该函数主要用来将数组和对象，转换为json格式。先看一个数组转换的例子： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$arr = array(&apos;a&apos;=&gt;1,&apos;b&apos;=&gt;2,&apos;c&apos;=&gt;3,&apos;d&apos;=&gt;4,&apos;e&apos;=&gt;5);</span><br><span class="line">echo json_encode($arr);</span><br></pre></td></tr></table></figure></p><p>结果为 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">　　&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;</span><br></pre></td></tr></table></figure></p><p>　　 再看一个对象转换的例子： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$obj-&gt;body = &apos;another post&apos;;　　</span><br><span class="line">$obj-&gt;id = 21;　　</span><br><span class="line">$obj-&gt;approved = true;　　</span><br><span class="line">$obj-&gt;favorite_count = 1;　</span><br><span class="line">$obj-&gt;status= NULL;</span><br><span class="line">　　</span><br><span class="line">echo json_encode($obj);</span><br></pre></td></tr></table></figure></p><p>结果为 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">　　&#123;</span><br><span class="line">　　　　&quot;body&quot;:&quot;another post&quot;,</span><br><span class="line">　　</span><br><span class="line">　　　　&quot;id&quot;:21,</span><br><span class="line">　　</span><br><span class="line">　　　　&quot;approved&quot;:true,</span><br><span class="line">　　</span><br><span class="line">　　　　&quot;favorite_count&quot;:1,</span><br><span class="line">　　</span><br><span class="line">　　　　&quot;status&quot;:null</span><br><span class="line">　　&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>由于json只接受utf-8编码的字符，所以json_encode()的参数必须是utf-8编码，否则会得到空字符或者null。当中文使用GB2312编码，或者外文使用ISO-8859-1编码的时候，这一点要特别注意。</p></blockquote><h3><span id="索引数组和关联数组">索引数组和关联数组</span></h3><blockquote><p>PHP支持两种数组，一种是只保存&quot;值&quot;（value）的索引数组（indexed array），另一种是保存&quot;名值对&quot;（name/value）的关联数组（associative array）。 由于javascript不支持关联数组，所以json_encode()只将索引数组（indexed array）转为数组格式，而将关联数组（associative array）转为对象格式。</p></blockquote><p>比如，现在有一个索引数组 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$arr = Array(&apos;one&apos;, &apos;two&apos;, &apos;three&apos;);</span><br><span class="line">echo json_encode($arr);</span><br></pre></td></tr></table></figure></p><p>结果为： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">　　[&quot;one&quot;,&quot;two&quot;,&quot;three&quot;]</span><br></pre></td></tr></table></figure></p><p>如果将它改为关联数组： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$arr = Array(&apos;1&apos;=&gt;&apos;one&apos;, &apos;2&apos;=&gt;&apos;two&apos;, &apos;3&apos;=&gt;&apos;three&apos;);</span><br><span class="line">echo json_encode($arr);</span><br></pre></td></tr></table></figure></p><p>结果就变了： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;1&quot;:&quot;one&quot;,&quot;2&quot;:&quot;two&quot;,&quot;3&quot;:&quot;three&quot;&#125;</span><br></pre></td></tr></table></figure></p><p><strong>注意，数据格式从[]（数组）变成了{}（对象）。</strong></p><p>如果你需要将&quot;索引数组&quot;强制转化成&quot;对象&quot;，可以这样写 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">　　json_encode( (object)$arr );</span><br></pre></td></tr></table></figure></p><p>或者 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">　　json_encode ( $arr, JSON_FORCE_OBJECT );</span><br></pre></td></tr></table></figure></p><h3><span id="类class的转换">类（class）的转换</span></h3><p>下面是一个PHP的类： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">class Foo &#123;</span><br><span class="line">  const     ERROR_CODE = &apos;404&apos;;</span><br><span class="line">  public    $public_ex = &apos;this is public&apos;;</span><br><span class="line">  private   $private_ex = &apos;this is private!&apos;;　</span><br><span class="line">  protected $protected_ex = &apos;this should be protected&apos;; </span><br><span class="line"> 　　</span><br><span class="line">  public function getErrorCode() &#123;</span><br><span class="line">    return self::ERROR_CODE;</span><br><span class="line">  &#125;　　</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>现在，对这个类的实例进行json转换： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">　　$foo = new Foo;</span><br><span class="line">　　</span><br><span class="line">　　$foo_json = json_encode($foo);</span><br><span class="line">　　</span><br><span class="line">　　echo $foo_json;</span><br></pre></td></tr></table></figure></p><p>输出结果是 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">　　&#123;&quot;public_ex&quot;:&quot;this is public&quot;&#125;</span><br></pre></td></tr></table></figure></p><p>可以看到，除了公开变量（public），其他东西（常量、私有变量、方法等等）都遗失了。</p><h2><span id="json_decode">json_decode()</span></h2><blockquote><p>该函数用于将json文本转换为相应的PHP数据结构。</p></blockquote><p>下面是一个例子： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">　　$json = &apos;&#123;&quot;foo&quot;: 12345&#125;&apos;;</span><br><span class="line">　　$obj = json_decode($json);</span><br><span class="line">　　print $obj-&gt;&#123;&apos;foo&apos;&#125;; // 12345</span><br></pre></td></tr></table></figure></p><p>通常情况下，<code>json_decode()</code>总是<strong>返回一个PHP对象，而不是数组</strong>。 比如： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$json = &apos;&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;&apos;;</span><br><span class="line">var_dump(json_decode($json));</span><br></pre></td></tr></table></figure></p><p>结果就是生成一个PHP对象： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">　　object(stdClass)#1 (5) &#123;</span><br><span class="line">　　　　[&quot;a&quot;] =&gt; int(1)</span><br><span class="line">　　　　[&quot;b&quot;] =&gt; int(2)</span><br><span class="line">　　　　[&quot;c&quot;] =&gt; int(3)</span><br><span class="line">　　　　[&quot;d&quot;] =&gt; int(4)</span><br><span class="line">　　　　[&quot;e&quot;] =&gt; int(5)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>如果想要强制生成PHP关联数组，json_decode()需要加一个参数true</strong>： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$json = &apos;&#123;&quot;a&quot;:1,&quot;b&quot;:2,&quot;c&quot;:3,&quot;d&quot;:4,&quot;e&quot;:5&#125;&apos;;</span><br><span class="line">var_dump(json_decode($json,true));</span><br></pre></td></tr></table></figure></p><p>结果就生成了一个关联数组： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">　　array(5) &#123;</span><br><span class="line">　　 　　[&quot;a&quot;] =&gt; int(1)</span><br><span class="line">　　 　　[&quot;b&quot;] =&gt; int(2)</span><br><span class="line">　　 　　[&quot;c&quot;] =&gt; int(3)</span><br><span class="line">　　 　　[&quot;d&quot;] =&gt; int(4)</span><br><span class="line">　　 　　[&quot;e&quot;] =&gt; int(5)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3><span id="json_decode的常见错误">json_decode()的常见错误</span></h3><p>下面三种json写法都是错的，你能看出错在哪里吗？ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">　　$bad_json = &quot;&#123; &apos;bar&apos;: &apos;baz&apos; &#125;&quot;;</span><br><span class="line">　　</span><br><span class="line">　　$bad_json = &apos;&#123; bar: &quot;baz&quot; &#125;&apos;;</span><br><span class="line">　　</span><br><span class="line">　　$bad_json = &apos;&#123; &quot;bar&quot;: &quot;baz&quot;, &#125;&apos;;</span><br></pre></td></tr></table></figure></p><p><strong>对这三个字符串执行json_decode()都将返回null，并且报错</strong>。 &gt; 第一个的错误是，<strong>json的分隔符（delimiter）只允许使用双引号，不能使用单引号</strong>。 &gt; 第二个的错误是，<strong>json名值对的&quot;名&quot;（冒号左边的部分），任何情况下都必须使用双引号</strong>。 &gt; 第三个的错误是，<strong>最后一个值之后不能添加逗号（trailing comma）</strong>。</p><blockquote><p>另外，json只能用来表示对象<code>(object)</code>和数组<code>(array)</code>，如果对一个字符串或数值使用<code>json_decode()</code>，将会返回<code>null</code>。 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var_dump(json_decode(&quot;Hello World&quot;)); //null</span><br></pre></td></tr></table></figure></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PHP </tag>
            
            <tag> JSON </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL 笔记</title>
      <link href="/2015/12/17/MySQL%20%E7%AC%94%E8%AE%B0/"/>
      <url>/2015/12/17/MySQL%20%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h3><span id="登陆">登陆</span></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mysql [-h hostname] -u username -p</span></span><br><span class="line">Enter Password:</span><br></pre></td></tr></table></figure><a id="more"></a><h3><span id="新建数据库">新建数据库</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database dbname;</span><br></pre></td></tr></table></figure><h3><span id="创建用户和分配权限">创建用户和分配权限</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">privileges</span> [columes] </span><br><span class="line"><span class="keyword">ON</span> item</span><br><span class="line"><span class="keyword">TO</span> user_name [<span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'password'</span>]</span><br><span class="line">[REQUIRE ssl_options]</span><br><span class="line">[<span class="keyword">WITH</span> [<span class="keyword">GRANT</span> <span class="keyword">OPTION</span> | limit_options] ]</span><br></pre></td></tr></table></figure><h5><span id="创建用户">创建用户</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER &apos;username&apos;@&apos;host&apos; IDENTIFIED BY &apos;password&apos;;</span><br></pre></td></tr></table></figure><h5><span id="授权">授权</span></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GRANT privileges ON databasename.tablename TO &apos;username&apos;@&apos;host&apos;</span><br></pre></td></tr></table></figure><p>说明: privileges – 用户的操作权限,如<code>SELECT</code> , <code>INSERT</code> , <code>UPDATE</code> 等.如果要授予所 的权限则使用<code>ALL</code>.;<code>databasename</code> – 数据库名,<code>tablename</code>-表名,如果要授予该用户对所有数据库和表的相应操作权限则可用<code>*</code> 表示, 如: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GRANT SELECT, INSERT ON test.user TO &apos;pig&apos;@&apos;%&apos;;</span><br></pre></td></tr></table></figure></p><h3><span id="使用数据库">使用数据库</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; use dbname;</span><br></pre></td></tr></table></figure><h3><span id="创建数据库表">创建数据库表</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE DATABASE dbname;</span><br><span class="line">mysql&gt; CREATE TABLE tablename (columns);</span><br><span class="line">// 丛文件中载入</span><br><span class="line">mysql&gt; -h host -u username -D dbname -p &lt; bookorama.sql;</span><br></pre></td></tr></table></figure><p>举例： <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE books(</span><br><span class="line">isbn char(13) NOT NULL PRIMARY KEY,</span><br><span class="line">author char(50),</span><br><span class="line">title char(100),</span><br><span class="line">price float(4, 2)</span><br><span class="line">);</span><br></pre></td></tr></table></figure></p><h3><span id="查看数据库">查看数据库</span></h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show tables;</span><br><span class="line">mysql&gt; show database;</span><br><span class="line">mysql&gt; describe tables;// 查看某个表的详细信息</span><br></pre></td></tr></table></figure><h3><span id="索引">索引</span></h3><blockquote><p>索引的创建可以在<code>CREATE TABLE</code>语句中进行，也可以单独用<code>CREATE INDEX</code>或<code>ALTER TABLE</code>来给表增加索引。删除索引可以利用<code>ALTER TABLE</code>或<code>DROP INDEX</code>语句来实现。</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">UNIQUE</span> | FULLTEXT] <span class="keyword">INDEX</span> index_name <span class="keyword">ON</span> table_name (index_column_name [(<span class="keyword">length</span>)] [<span class="keyword">ASC</span>|<span class="keyword">DESC</span>], ...)</span><br></pre></td></tr></table></figure><h4><span id="使用alter-table语句创建索引">使用<code>ALTER TABLE</code>语句创建索引</span></h4><p>语法如下 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter table table_name add index index_name (column_list) ;</span><br><span class="line">alter table table_name add unique (column_list) ;</span><br><span class="line">alter table table_name add primary key (column_list) ;</span><br></pre></td></tr></table></figure></p><p>其中包括 * 普通索引、<code>UNIQUE</code>索引和<code>PRIMARY KEY</code>索引3种创建索引的格式 * <code>table_name</code>是要增加索引的表名 * <code>column_list</code>指出对哪些列进行索引，<strong>多列时各列之间用逗号分隔</strong>。 * 索引名<code>index_name</code>可选，缺省时，MySQL将根据第一个索引列赋一个名称。 * <code>ALTER TABLE</code>允许在单个语句中更改多个表，因此可以同时创建多个索引。</p><p>创建索引的示例如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; alter table table_test add index index_test1(name) ;</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br></pre></td></tr></table></figure></p><h4><span id="使用create-index语句对表增加索引">使用<code>CREATE INDEX</code>语句对表增加索引</span></h4><p>能够增加普通索引和<code>UNIQUE</code>索引两种。其格式如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create index index_name on table_name (column_list) ;</span><br><span class="line">create unique index index_name on table_name (column_list) ;</span><br></pre></td></tr></table></figure></p><p>创建索引的示例如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create index index_test2 on table_test(age);</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br></pre></td></tr></table></figure></p><p>说明：<code>table_name</code>、<code>index_name</code>和<code>column_list</code>具有与<code>ALTER TABLE</code>语句中相同的含义，索引名不可选。另外，不能用<code>CREATE INDEX</code>语句创建<code>PRIMARY KEY</code>索引。</p><h4><span id="删除索引">删除索引</span></h4><blockquote><p>删除索引可以使用<code>ALTER TABLE</code>或<code>DROP INDEX</code>语句来实现。</p></blockquote><p><code>DROP INDEX</code>可以在<code>ALTER TABLE</code>内部作为一条语句处理，其格式如下： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">drop index index_name on table_name ;</span><br><span class="line">alter table table_name drop index index_name ;</span><br><span class="line">alter table table_name drop primary key ;</span><br></pre></td></tr></table></figure></p><p>其中，在前面的两条语句中，都删除了<code>table_name</code>中的索引<code>index_name</code>。而在最后一条语句中，只在删除<code>PRIMARY KEY</code>索引中使用，因为一个表只可能有一个<code>PRIMARY KEY</code>索引，因此不需要指定索引名。如果没有创建<code>PRIMARY KEY</code>索引，但表具有一个或多个<code>UNIQUE</code>索引，则MySQL将删除第一个<code>UNIQUE</code>索引。</p><blockquote><p>如果从表中删除某列，则索引会受影响。对于多列组合的索引，如果删除其中的某列，则该列也会从索引中删除。如果删除组成索引的所有列，则整个索引将被删除。</p></blockquote><p>删除索引的操作，如下面的代码： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; drop index name on table_test ;</span><br><span class="line">Query OK, 2 rows affected (0.08 sec)</span><br></pre></td></tr></table></figure></p><h3><span id="数据类型">数据类型</span></h3><h4><span id="整数类型">整数类型</span></h4><table><thead><tr class="header"><th style="text-align: left;">类型</th><th style="text-align: left;">取值范围</th><th style="text-align: center;">存储空间</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">TINYINT[(M)]</td><td style="text-align: left;">-127<sub>128或0</sub>255</td><td style="text-align: center;">1</td><td style="text-align: left;">非常小的整数</td></tr><tr class="even"><td style="text-align: left;">BIT</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">TINYINT的同义词</td></tr><tr class="odd"><td style="text-align: left;">BOOL</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">TINYINT的同义词</td></tr><tr class="even"><td style="text-align: left;">SMALLINT[(M)]</td><td style="text-align: left;">-32768<sub>32767或0</sub>65535</td><td style="text-align: center;">2</td><td style="text-align: left;">小型整数</td></tr><tr class="odd"><td style="text-align: left;">MEDIUMINT[(M)]</td><td style="text-align: left;">-8388608<sub>8883607或0</sub>16777215</td><td style="text-align: center;">3</td><td style="text-align: left;">中型整数</td></tr><tr class="even"><td style="text-align: left;">INT[(M)]</td><td style="text-align: left;"><span class="math inline">\(-2^{31}\)</span><sub><span class="math inline">\(2^{31}-1\)</span>或0</sub><span class="math inline">\(2^{32}-1\)</span></td><td style="text-align: center;">4</td><td style="text-align: left;">一般整数</td></tr><tr class="odd"><td style="text-align: left;">INTEGER[(M)]</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">INT的同义词</td></tr><tr class="even"><td style="text-align: left;">BIGINT[(M)]</td><td style="text-align: left;"><span class="math inline">\(-2^{63}\)</span><sub><span class="math inline">\(2^{63}-1\)</span>或0</sub><span class="math inline">\(2^{64}-1\)</span></td><td style="text-align: center;">8</td><td style="text-align: left;">大型整数</td></tr></tbody></table><h4><span id="浮点类型">浮点类型</span></h4><table><thead><tr class="header"><th style="text-align: left;">类型</th><th style="text-align: left;">取值范围</th><th style="text-align: center;">存储空间</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">FLOAT(精度)</td><td style="text-align: left;">取决于精度</td><td style="text-align: center;">可变</td><td style="text-align: left;">可用于指定单精度和双精度浮点数</td></tr><tr class="even"><td style="text-align: left;">FLOAT[(M, D)]</td><td style="text-align: left;">+- 1.17549E-38</td><td style="text-align: center;">4</td><td style="text-align: left;">单精度浮点数，等同于FLOAT(4)</td></tr><tr class="odd"><td style="text-align: left;">DOUBLE[(M), D]</td><td style="text-align: left;">+- 3.40282E+308</td><td style="text-align: center;">8</td><td style="text-align: left;">双精度浮点数，等同于FLOAT(8)</td></tr><tr class="even"><td style="text-align: left;">DOUBLE</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">DOUBLE[(M, D)]的同义词</td></tr><tr class="odd"><td style="text-align: left;">PRECISION[(M, D)]</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">同上</td></tr><tr class="even"><td style="text-align: left;">REAL[(M, D)]</td><td style="text-align: left;"></td><td style="text-align: center;"></td><td style="text-align: left;">同上</td></tr><tr class="odd"><td style="text-align: left;">DECIMAL[(M [,D])]</td><td style="text-align: left;">可变</td><td style="text-align: center;">M + 2</td><td style="text-align: left;">浮点数，以char存储。范围取决于M</td></tr><tr class="even"><td style="text-align: left;">NUMERIC[(M, D)]</td><td style="text-align: left;">同上</td><td style="text-align: center;"></td><td style="text-align: left;">DECIMAL的同义词</td></tr><tr class="odd"><td style="text-align: left;">DEC[(M, D)]</td><td style="text-align: left;">同上</td><td style="text-align: center;"></td><td style="text-align: left;">DECIMAL的同义词</td></tr><tr class="even"><td style="text-align: left;">FIXED[(M, D)]</td><td style="text-align: left;">同上</td><td style="text-align: center;"></td><td style="text-align: left;">DECIMAL的同义词</td></tr></tbody></table><h4><span id="日期和时间类型">日期和时间类型</span></h4><table><thead><tr class="header"><th style="text-align: left;">类型</th><th style="text-align: left;">取值范围</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">DATE</td><td style="text-align: left;">1000-01-01 ~ 9999-12-31</td><td style="text-align: left;">一个日期，以YYYY-MM-DD格式显示</td></tr><tr class="even"><td style="text-align: left;">TIME</td><td style="text-align: left;">-838:59:59 ~ 838:59:59</td><td style="text-align: left;">一个时间，以HH:MM:SS形式显示</td></tr><tr class="odd"><td style="text-align: left;">DATETIME</td><td style="text-align: left;">1000-01-01 00:00:00 ~ 9999-12-31 23:59:59</td><td style="text-align: left;">日期和时间</td></tr><tr class="even"><td style="text-align: left;">TIMESTAMP[(M)]</td><td style="text-align: left;">1970-01-01 00:00:00 ~ 2037年的某个时间</td><td style="text-align: left;">时间标签，在处理报告中有意义。</td></tr><tr class="odd"><td style="text-align: left;">YEAR[(2/4)]</td><td style="text-align: left;">70<sub>69(1970</sub>2069)</td><td style="text-align: left;">年份。可以指定2位数字或4位数字的格式。</td></tr></tbody></table><h4><span id="字符串类型">字符串类型</span></h4><h5><span id="常规字符串类型">常规字符串类型</span></h5><table><thead><tr class="header"><th style="text-align: left;">类型</th><th style="text-align: left;">取值范围</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">CHAR(M)</td><td style="text-align: left;">0~255个字符</td><td style="text-align: left;">固定长度为M的字符串，M的取值为0~255</td></tr><tr class="even"><td style="text-align: left;">CHAR</td><td style="text-align: left;"></td><td style="text-align: left;">CHAR(1)的同义词</td></tr><tr class="odd"><td style="text-align: left;">VARCHAR(M)</td><td style="text-align: left;">1~255个字符</td><td style="text-align: left;">可变长度</td></tr></tbody></table><h5><span id="text和blob类型">TEXT和BLOB类型</span></h5><table><thead><tr class="header"><th style="text-align: left;">类型</th><th style="text-align: center;">最大长度(字符数)</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">TINYBLOB</td><td style="text-align: center;">255</td><td style="text-align: left;">小二进制大对象(BLOB)字段</td></tr><tr class="even"><td style="text-align: left;">TINYTEXT</td><td style="text-align: center;">255</td><td style="text-align: left;">小TEXT字段</td></tr><tr class="odd"><td style="text-align: left;">BLOB</td><td style="text-align: center;">65535</td><td style="text-align: left;">常规BLOB字段</td></tr><tr class="even"><td style="text-align: left;">TEXT</td><td style="text-align: center;">65535</td><td style="text-align: left;">常规TEXT字段</td></tr><tr class="odd"><td style="text-align: left;">MEDIUMBLOB</td><td style="text-align: center;"><span class="math inline">\(2^{24}-1\)</span></td><td style="text-align: left;">中型BLOB字段</td></tr><tr class="even"><td style="text-align: left;">MEDIUMTEXT</td><td style="text-align: center;"><span class="math inline">\(2^{24}-1\)</span></td><td style="text-align: left;">中型TEXT字段</td></tr><tr class="odd"><td style="text-align: left;">LONGBLOB</td><td style="text-align: center;"><span class="math inline">\(2^{32}-1\)</span></td><td style="text-align: left;">长BLOB字段</td></tr><tr class="even"><td style="text-align: left;">LONGTEXT</td><td style="text-align: center;"><span class="math inline">\(2^{32}-1\)</span></td><td style="text-align: left;">长TEXT字段</td></tr></tbody></table><h5><span id="set和enum类型">SET和ENUM类型</span></h5><table><thead><tr class="header"><th style="text-align: left;">类型</th><th style="text-align: center;">集合中的最大值</th><th style="text-align: left;">描述</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">ENUM('value1', 'value2', ...)</td><td style="text-align: center;">65535</td><td style="text-align: left;">该类型的列只可以容纳所列值之一或者为NULL</td></tr><tr class="even"><td style="text-align: left;">SET('value1', 'value2', ...)</td><td style="text-align: center;">64</td><td style="text-align: left;">该类型的列可以容纳一组值或者为NULL</td></tr></tbody></table><h3><span id="插入数据">插入数据</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> [<span class="keyword">INTO</span>] table_name [(column1, column2, ...)] </span><br><span class="line"><span class="keyword">VALUES</span>(value1, value2, ...);</span><br></pre></td></tr></table></figure><h3><span id="查询数据">查询数据</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [options] items</span><br><span class="line">[<span class="keyword">INTO</span> file_details]</span><br><span class="line"><span class="keyword">FROM</span> <span class="string">`tables_name`</span></span><br><span class="line">[ <span class="keyword">WHERE</span> conditions ]</span><br><span class="line">[ <span class="keyword">GROUP</span> <span class="keyword">BY</span> group_type ]</span><br><span class="line">[ <span class="keyword">HAVING</span> where_definition ]</span><br><span class="line">[ <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_type ]</span><br><span class="line">[ <span class="keyword">LIMIT</span> limit_criteria ]</span><br><span class="line">[ <span class="keyword">PROCEDURE</span> proc_name(arguments)]</span><br><span class="line">[ lock_options ];</span><br></pre></td></tr></table></figure><p><del>此处略过1000字</del></p><h3><span id="更新数据">更新数据</span></h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> [<span class="keyword">LOW_PRIORITY</span>] [<span class="keyword">IGNORE</span>] tablename</span><br><span class="line"><span class="keyword">SET</span> column1 = expression1, ...</span><br><span class="line">[ <span class="keyword">WHERE</span> condition ]</span><br><span class="line">[ <span class="keyword">ORDER</span> <span class="keyword">BY</span> order_criteria ]</span><br><span class="line">[ <span class="keyword">LIMIT</span> <span class="built_in">number</span> ]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后台开发 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用命令总结(三)：网络与进程</title>
      <link href="/2015/12/17/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%89)_%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%9B%E7%A8%8B/"/>
      <url>/2015/12/17/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%89)_%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%9B%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Linux常用命令总结</p></blockquote><a id="more"></a><h2><span id="查看哪个进程在占用端口lsof">查看哪个进程在占用端口：lsof</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo lsof -i:（端口号）</span><br></pre></td></tr></table></figure><h2><span id="结束进程kill">结束进程：kill</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo kill 进程PID</span><br></pre></td></tr></table></figure><h2><span id="ip">ip</span></h2><p><strong>show / manipulate routing, devices, policy routing and tunnels</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ip link</span><br></pre></td></tr></table></figure></p><h2><span id="iwconfig">iwconfig</span></h2><p>iwconfig - configure a <strong>wireless network interface</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ iwconfig</span><br></pre></td></tr></table></figure></p><h2><span id="netstat-跟踪网络">netstat - 跟踪网络</span></h2><p><em>用法：</em> <code>netstat  -[atunlp]</code> <em>参数：</em> * -a : 将目前系统上所有的连接、监听、Socket数据都列出来 * -t : 列出tcp网络数据包的数据 * -u : 列出udp网络数据包的数据 * -n : 不列出进程的服务名称，以端口号(port number)来显示 * -l : 列出目前正在网络监听的服务 * -p : 列出该网络服务的进程PID</p><h2><span id="ps-将某个时间点的进程运行情况选取下来">ps -将某个时间点的进程运行情况选取下来</span></h2><p><em>用法：</em> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps   aux      # 查看系统所有的进程数据 </span><br><span class="line">ps   -lA      # 同上</span><br><span class="line">ps   axjf     # 连同部分进程树的状态</span><br></pre></td></tr></table></figure></p><p><em>参数：</em> * -A : 所有进程均显示出来，与-e具有同样的作用 * -a : 不列出与terminal有关的所有进程 * -u : 有效用户(effective user)相关的进程 * x : 通常与a这个参数一起使用，可以列出较完整信息 * 输出格式规划： * l ： 较长、较详细地将该PID的信息列出 * j : 工作的格式(job format) * -f : 做一个更为完整的输出 &gt;常用： * ps -l : 只查看自己bash程序的所有进程 * ps aux : 查看所有系统运行的程序</p><h2><span id="top-动态查看进程变化">top -动态查看进程变化</span></h2><p><em>用法：</em></p><p><code>top  [-d  数字]  |  top  [-bnp]</code> <em>参数：</em> * -d : 后面可以接秒数，就是整个进程界面更新的秒数。默认是5秒 * -b : 以批次的方式执行top，通常会搭配数据流重定向来将批处理的结果输出成文件 * -n : 与-b搭配，意义是，需要进行几次top的输出结果 * -p : 指定某些个PID来进行查看检测 &gt;在top执行过程中可以使用以下按键： * ? : 显示在top中可以输入的按键命令 * P : 以CPU的使用资源排序显示 * M: 以内存的使用资源排序显示 * N : 以PID来排序 * T : 由该进程使用的CPU时间积累排序 * k : 给予某个PID一个信号 * r : 给予某个PID重新制定一个nice值 * q : 离开top</p><h2><span id="scp-安全复制用于不同的linux之间">scp - 安全复制，用于不同的linux之间</span></h2><p><em>用法：</em></p><p><code>scp  [-vCP46]  文件名1   远程用户名@IP地址：文件名2</code> <em>参数：</em> * -v : 显示进度、查看连接，认证或是匹配错误 * -C : 使能压缩 * -P : 选择端口 * -4 : 强制使用ipv4地址 * -6 : 强制使用ipv6地址</p><h2><span id="wget-下载文件工具">wget - 下载文件工具</span></h2><p><em>用法：</em> <code>wget [options]  url</code> <em>部分参数：</em> * -V : 显示wget的版本并退出 * -d : 显示Debug信息 * -x : 强制建立与服务器上一样的目录 * -r : 递归地下载服务器上所有的文件和目录（包括网站内指向的地址） * -l n: n为数字，为递归下载的层数 * -c : 断点续传 * -i : 批量下载，后面接txt文件，把每个url写成一行 * --http-user=USER, --http-passwd=PASS ： 访问限制网站所需的账号密码 * -t : 尝试下载重复次数 * -O : 指定下载目录和文件名 * -nc : 不要覆盖已存在文件 * -N : 只下载比本地文件新的文件 * -T : 设置超时时间 * -b : 启动转入后台执行</p><h2><span id="curl-url下载工具">curl - url下载工具</span></h2><p><em>用法：</em> <code>curl  [options1]   url1   [options2]  url2  ….</code> <em>参数：</em> * -o : 后接文件名，将文件保存为指定文件名的文件中 * -O : 使用url中默认文件名保存到本地 * -L : 进行重定向 * -C : 断点续传 * --limit-rate : 后面接数字，限制最大下载速度 * -u username[ : passwd ]: 需要授权时提供账号【密码】 * -T : 将本地文件上传至ftp服务器上</p><h2><span id="ifconfig-获取修改网络接口配置信息">ifconfig - 获取/修改网络接口配置信息</span></h2><p><em>用法：</em> <code>ifconfig  [网络设备]   [参数]</code> <em>参数：</em> * up : 启动指定网络设备/网卡 * down : 关闭指定设备/网卡 * arp : 设置网卡是否支持arp协议 * -a : 显示全部接口信息 * -s : 显示摘要信息 * add : 给指定网卡配置ipv6地址 * del : 删除指定网卡的ipv6地址 * address : 为网卡配置ipv4地址</p><h2><span id="ssh-ssh客户端">ssh - SSH客户端</span></h2><blockquote><p><strong>常用方法：</strong> * ssh host : 不加任何选项参数，直接加服务器地址 * ssh -l : 指定用户 host 用指定用户名登陆 * ssh host -p 端口号 : 指定端口 * ssh -C host : 请求压缩发送/接收的数据 * ssh -v host : 打开调试模式 * ssh -b source destination: 绑定源地址 * ssh -F 配置文件 : host 使用指定配置文件 * ssh -X user@host : 启用X11 Forwarding</p></blockquote><h2><span id="apt-get"><strong>apt-get</strong></span></h2><ul><li><p><code>apt-get update</code> : 在修改<code>/etc/apt/sources.list</code>或<code>/etc/apt/preferences</code>之后运行该命令。此外您需要定期运行这一命令以确保您的软件包列表是最新的</p></li><li><p><code>apt-get install packagename</code> : 安装一个新软件包</p></li><li><p><code>apt-get remove packagename</code> : 卸载一个已安装的软件包（保留配置文档）</p></li><li><p><code>apt-get remove --purge packagename</code> : 卸载一个已安装的软件包（删除配置文档）</p></li><li><p><code>apt-get autoremove packagename</code> : 删除包及其依赖的软件包</p></li><li><p><code>apt-get autoremove --purge packagname</code> : 删除包及其依赖的软件包+配置文件，比上面的要删除的彻底一点</p></li><li><p><code>dpkg --force-all --purge packagename</code> : 有些软件很难卸载，而且还阻止了别的软件的应用，就能够用这个，但是有点冒险。</p></li><li><p><code>apt-get autoclean</code> : apt会把已装或已卸的软件都备份在硬盘上，所以假如需要空间的话，能够让这个命令来删除您已卸载掉的软件的备份</p></li><li><p><code>apt-get clean</code> : 这个命令会把安装的软件的备份也删除，但是这样不会影响软件的使用。</p></li><li><p><code>apt-get upgrade</code> : 可以使用这条命令更新软件包，<code>apt-get upgrade</code>不仅可以从相同版本号的发布版中更新软件包，也可以从新版本号的发布版中更新软件包，尽管实现后一种更新的推荐命令为<code>apt-get dist-upgrade</code>。</p></li><li><p><code>apt-get -u upgrade</code> : 这个选项让APT显示完整的可更新软件包列表。APT会下载每个软件包的最新更新版本，然后以合理的次序安装它们。注意在运行该命令前应先运行<code>apt-get update</code>更新数据库，更新任何已安装的软件包。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用命令总结(二)：数据处理</title>
      <link href="/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%BA%8C)_%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
      <url>/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%BA%8C)_%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Linux常用命令总结</p></blockquote><a id="more"></a><h2><span id="数据流重定向">数据流重定向</span></h2><ul><li><strong>标准输入(stdin)</strong> : 代码为0，使用<code>&lt;</code>或<code>&lt;&lt;</code></li><li><strong>标准输出(stdout)</strong> : 代码为1，使用<code>&gt;</code>或<code>&gt;&gt;</code></li><li><strong>标准错误输出(stderr)</strong> : 代码为2，使用<code>2&gt;</code>或<code>2&gt;&gt;</code></li></ul><p>范例： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls /home &gt; ~/homefile <span class="comment"># 将屏幕信息输出到homefile里</span></span><br></pre></td></tr></table></figure></p><h3><span id="devnull垃圾黑洞设备"><code>/dev/null</code>垃圾黑洞设备</span></h3><p><code>/dev/null</code>可以吃掉任何导向这个设备的信息</p><p>范例： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ find /home -name .bashrc 2&gt; /dev/null</span><br><span class="line"><span class="comment"># 只有stdout会显示到屏幕上，stderr被丢弃了</span></span><br></pre></td></tr></table></figure></p><h3><span id="将正确与错误数据写入同一文件">将正确与错误数据写入同一文件</span></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ find /home -name .bashrc &gt; list 2&gt;&amp;1</span><br><span class="line">$ find /home -name .bashrc &amp;&gt; list</span><br></pre></td></tr></table></figure><h3><span id="lt与ltlt"><code>&lt;</code>与<code>&lt;&lt;</code></span></h3><p>用<code>stdin</code>替代键盘输入以创建新文件的简单流程 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; catdile &lt; ~/.bashrc</span><br></pre></td></tr></table></figure></p><p><code>&lt;&lt;</code>代表输入结束： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cat &gt; catfile &lt;&lt; &quot;eof&quot;</span><br><span class="line">&gt; This is a test.</span><br><span class="line">&gt; eof  # 输入这个关键字，立刻结束而不需要[ctrl]+d</span><br></pre></td></tr></table></figure></p><h2><span id="tee-双向重定向">tee -双向重定向</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ tee [-a] file</span><br><span class="line">参数：-a : 以累加的方式输出到文件</span><br></pre></td></tr></table></figure><p><strong><code>tee</code>可以让<code>standard output</code>转存一份到文件内并将同样的数据继续送到屏幕上。</strong></p><p>选取命令 ： cut、grepsad</p><h2><span id="cut-在一行信息中取出想要的">cut -在一行信息中取出想要的</span></h2><p><em>用法：</em> <code>cut  -d  '分割字符'   -f  fields</code> <code>cut  -c   字符范围</code> <em>参数：</em> * -d : 后面接分割字符，与 -f 一起使用 * -f : 依据-d的分割字符将一段信息切割成数段，用-f取出第几段的意思 * -c : 以字符的单位取出固定字符区间 <em>例：</em> <code>echo $PATH | cut -d ':' -f 4</code> <code>export | cut -c 12-</code></p><h2><span id="sed-工具">sed 工具</span></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ sed [-nefr] [动作]</span><br><span class="line">参数：</span><br><span class="line">-n : 使用安静模式。只有经过sed特殊处理的那一行才会被列出来</span><br><span class="line">-e : 直接在命令行模式上进行sed动作编辑</span><br><span class="line">-f : -f filename 可以执行filename里的sed动作</span><br><span class="line">-r : sed的动作支持的是扩展型正则表达式的语法</span><br><span class="line">-i : 直接修改读取的文件内容，而不是屏幕输出</span><br><span class="line"></span><br><span class="line">动作说明： [n1[, n2]]funciton</span><br><span class="line">n1, n2 : 不见得会存在，一般代表选择进行动作的行数</span><br><span class="line"></span><br><span class="line">function有以下：</span><br><span class="line">a : 新增, a的后面可以接字符串，这些字符串会出现在目前行的下一行</span><br><span class="line">c : 替换, c的后面可以接字符串，这些字符串可以替换n1-n2之间的行</span><br><span class="line">d : 删除</span><br><span class="line">i : 插入, i的后面可以接字符串，这些字符串会出现在目前行的上一行</span><br><span class="line">p : 打印, 将某个选择的数据打印出来，通常与-n连用</span><br><span class="line">s : 替换, 可以直接进行替换工作，可以搭配正则表达式</span><br></pre></td></tr></table></figure><h3><span id="以行为单位的新增删除功能">以行为单位的新增/删除功能</span></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将/etc/passwd 的内容列出并且打印行号，同时将第2-5行删除</span></span><br><span class="line">$ nl /etc/passwd | sed <span class="string">'2,5d'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在第二行后加上"drink tea?"字样</span></span><br><span class="line">$ nl /etc/passwd | sed <span class="string">'2a drink tea'</span></span><br></pre></td></tr></table></figure><p><strong>用s命令替换</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat pets.txt</span><br><span class="line">This is my cat</span><br><span class="line">  my cat<span class="string">'s name is betty</span></span><br><span class="line"><span class="string">This is my dog</span></span><br><span class="line"><span class="string">  my dog'</span>s name is frank</span><br><span class="line">This is my fish</span><br><span class="line">  my fish<span class="string">'s name is george</span></span><br><span class="line"><span class="string">This is my goat</span></span><br><span class="line"><span class="string">  my goat'</span>s name is adam</span><br></pre></td></tr></table></figure><p>把其中的 <code>my</code> 字符串替换成 <code>Hao Chen’s</code>，下面的语句应该很好理解（s表示替换命令，/my/表示匹配my，/Hao Chen’s/表示把匹配替换成Hao Chen’s，/g 表示一行上的替换所有的匹配）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sed <span class="string">"s/my/Hao Chen's/g"</span> pets.txt</span><br><span class="line">This is Hao Chen<span class="string">'s cat</span></span><br><span class="line"><span class="string">  Hao Chen'</span>s cat<span class="string">'s name is betty</span></span><br><span class="line"><span class="string">This is Hao Chen'</span>s dog</span><br><span class="line">  Hao Chen<span class="string">'s dog'</span>s name is frank</span><br><span class="line">This is Hao Chen<span class="string">'s fish</span></span><br><span class="line"><span class="string">  Hao Chen'</span>s fish<span class="string">'s name is george</span></span><br><span class="line"><span class="string">This is Hao Chen'</span>s goat</span><br><span class="line">  Hao Chen<span class="string">'s goat'</span>s name is adam</span><br></pre></td></tr></table></figure><p>注意：如果你要使用单引号，那么你没办法通过’这样来转义，就有双引号就可以了，在双引号内可以用”来转义。</p><h2><span id="grep-分析一行信息若有想要的就拿出整行">grep -分析一行信息，若有想要的就拿出整行</span></h2><p><em>用法：</em> <code>grep [-acinv] [-A] [-B] [--color=auto]   '查找字符串'   filename</code> <em>参数：</em> * -a : 将binary文件以text文件的方式查找数据 * -c : 计算找到'查找字符串'的次数 * -i : 忽略大小写 * -n : 输出行号 * -v : 反向选择 * -A : 后面接数字，为after的意思，后续的n行也列出来 * -B : 后面接数字，为before的意思，前面的n行也列出来 * --color=auto : 可以将找到的关键字部分加上颜色显示</p><p>例： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ last | grep -v &apos;neymar&apos; | cut -d &apos; &apos; -f 1</span><br><span class="line">$ dmesg | grep -n -A3 -B2 --color=auto &apos;eth&apos;</span><br><span class="line"># dmesg可列出内核产生的信息。通过grep来选取网卡相关信息</span><br></pre></td></tr></table></figure></p><h2><span id="排序命令sort-wc-uniq">排序命令：sort, wc, uniq</span></h2><h3><span id="sort">sort</span></h3><p><em>用法：</em> <code>sort   [-fbMnrtuk]   [file or stdin]</code> <em>参数：</em> * -f : 忽略大小写 * -b : 忽略最前面空格 * -M: 以月份的名字来排序 * -n : 使用纯数字进行排序（默认以文字类型来排序） * -r : 反向排序 * -u : 就是uniq，相同的数据中，仅出现一行代表 * -t : 分隔符，默认用[Tab]来分割，配合-k使用 * -k : 后面加数字，以-t分割出来的哪个区间进行排序 <em>例：</em> <code>last | cut -d '.' f 1 | sort</code></p><h3><span id="uniq-重复数据仅列出一个">uniq -重复数据仅列出一个</span></h3><p><em>用法：</em> <code>uniq  [-ic]</code> <em>参数：</em> * -i : 忽略大小写字符的不同 * -c : 进行计数 <em>例：</em> <code>last | cut -d ' ' -f1 | sort | uniq -c</code></p><h3><span id="wc-计算输出信息的整体数据">wc - 计算输出信息的整体数据</span></h3><p><em>用法：</em> <code>wc   [-lwm]</code> <em>参数：</em> * -l : 仅列出行 * -w: 仅列出多少字 * -m : 仅列出多少字符 <em>例：</em> <code>cat /etc/passwd | wc</code></p><h3><span id="awk-数据处理工具">awk - 数据处理工具</span></h3><blockquote><p>awk主要是处理每一行的字段内数据，而默认的字段的分隔符为空格键或[tab]键</p></blockquote><p><em>用法:</em> <code>awk   '条件类型1{动作1}  条件类型2{动作2} …  '  filename</code></p><blockquote><p>awk的内置变量与含义： * $0 一整行数据 * $1, $2 … $n 第1列，第2列 …. 第n列 * NF 每一行拥有的字段总数 * NR 目前处理的行数 * FS 目前的分隔符，默认时空格键</p></blockquote><blockquote><p>awk的逻辑运算符： * &gt; &lt; &gt;= &lt;= == !=</p></blockquote><blockquote><p>说明： * 所有awk动作，即在{}内的动作，如果有需要多个命令辅助时，可用”;“间隔，或者直接以[Enter]键来隔开每个命令 * 与bash、shell的变量不同，在awk中，变量可以直接使用，不需要加”$“</p></blockquote><p>举例： * 取出账号与登录者IP，且账号与IP之间以[tab]隔开： <code>last -n 5 | awk '{print $1 “\t” $3}'</code> * 列出每一行的账号，列出正在处理的行数，并说明该行有多少字段： <code>last -n 5 | awk '{print $1 “\t  lines: “ NR “\t  columes:  “ NF}'</code> * 在/etc/passwd中以”：“来分隔字段，列出第三列小于10的数据，并且仅列出账号与第三列 <code>cat /etc/passwd | awk 'BEGIN {FS=&quot;:&quot;} $3 &lt; 10 {print $1 &quot;\t&quot; $3}'</code></p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用命令总结(一)：常规</title>
      <link href="/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%80)_%E5%B8%B8%E8%A7%84/"/>
      <url>/2015/12/15/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93(%E4%B8%80)_%E5%B8%B8%E8%A7%84/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Linux常用命令总结</p></blockquote><a id="more"></a><h2><span id="man-在线参考手册的接口">man - 在线参考手册的接口</span></h2><blockquote><p>man是系统的手册分页程序。指定给man的页选项通常是程序、工具或函数名。程序将显示找到的相关手册页。如果指定了章节，man将只在手册的指定章节搜索。默认将按预定的顺序查找。</p></blockquote><p><em>常用的手册章节及类型：</em> * 1 可执行程序或shell命令 * 5 文件格式和规范，如/etc/passwd * 8 系统管理命令（通常只针对root用户）</p><blockquote><p>一个手册页面包含若干个小节。 小节通常包括：NAME, 概述(SYNOPSIS), 配置(CONFIGURATION), 描述(DESCRIPTION), 选项(OPTIONS), 退出状态(EXIT STATUS), 返回值(RETURN VALUE), 错误(ERRORS), 环境(ENVIRONMENT), 文件(FILES), 版本(VERSIONS), 符合标准(CONFORMING TO), 注(NOTES), 缺陷(BUGS), 示例(EXAMPLE), 作者(AUTHORS), 和 亦见(SEE ALSO).</p></blockquote><p><em>概述小节规范：</em> * 加粗文本 原样显示的样式。 * 倾斜文本 替换为相应的参数。 * [-abc] [ ] 内的任意/全部参数都是可选的。 * -a|-b 以 | 分隔的选项可以一起使用。 * 参数 ... 参数 可以重复。 * [表达式] ... [ ] 内的整个 表达式 可以重复。</p><p><em>查询数据方法：</em> 1. 先查看NAME的项目，约略看一下这个数据的意思。 2. 再仔细看一下DESCROPTION，这个部分会提到很多相关的资料与用法，从这个地方可以学到很多细节。 3. 而如果对这个命令其实很熟悉了，那么主要就是查询关于OPTIONS的部分了。可以知道每个选项的意义，这样就可以执行比较细部的内容。 4. 最后会看一下跟这个资料相关的还有哪些东西可以使用的。</p><p><strong>man的参数</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">man -k printf #在系统说明文件中，只要有printf这个关键字就将该说明列出来。</span><br><span class="line">man -f smail  #查找smail 引用的手册页并输出找到的任何概述</span><br></pre></td></tr></table></figure></p><p><strong>man page 中常用按键</strong> | 空格键, [Page Down] | 向下翻一页 | | :-------- | :--------| | [Page Up] | 向上翻一页 | | [Home] | 去第一页 | | [End] | 去最后一页 | |<strong>/string</strong> |<strong>向下查询string字符串</strong> | | ?string | 向上查询string字符串 | |<strong>n, N</strong>| <strong>查询时, 利用n来继续下一个查询,N来进行反向查询</strong> | | q | 退出man page|</p><h2><span id="nano-简单的文本编辑器">nano - 简单的文本编辑器</span></h2><p><em>用法</em> <code>nano  文件名      打开一个文本文件</code></p><p><em>nano的几个重要的组合键</em> |[Ctrl] + G | 取得在线帮助| | :-------- | :--------| |[Ctrl] + X | 离开nano，若有修改会提示是否需要保存| |[Ctrl] + O | 保存文件| |[Ctrl] + R | 从其他文件读入数据| |[Ctrl] + W | 查询字符串| |[Ctrl] + C | 说明目前光标所在行列等信息| |[Ctrl] + 行号 | 可以让光标移动到该行| |[Alt] + M | 可以支持鼠标来移动光标功能|</p><h2><span id="ls-列出目录内容">ls - 列出目录内容</span></h2><p><em>描述：</em> <strong>列出当前目录（默认）文件信息，如果没指定排序规则的话就按照字母顺序排序。</strong></p><p><em>用法：</em> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls   [-aAdfFhilnrRSt]   目录名称</span><br><span class="line">ls   [--color=&#123;never, auto, always&#125; ]  目录名称</span><br><span class="line">ls   [--full-time]   目录名称</span><br></pre></td></tr></table></figure></p><p><em>参数： </em><br>|-a, -all | 列出包括隐藏文件(即 “.”开头的文件名)| | :-------- | :--------| |-A | 列出全部文件连同隐藏文件但不包括 . 与 ..| |<strong>-d </strong>| <strong>仅列出目录，而不是列出目录里文件数据</strong>| | -f | 直接列出结果，不排序| | -F | 根据文件、目录等信息给予附加数据结构, 例如 * 代表可执行文件； / 代表目录| | -h | 将文件容量以人类较易读的方式列出来(GB, KB等)| | -i | 列出inode号码| |<strong>-l</strong> | <strong>列出长数据串， 包含文件的属性与权限等数据</strong>| | -r | 将排序结果反序输出| | -t | 按时间排序| | -s | 显示文件大小| | -S | 按文件大小排序| | --sort=WORD|按WORD方式排序,WORD取值：none (-U), extension (-X), size (-S), time (-t), version (-v)| | --full-time |以完整的时间模式（包含年月日时分）输出|</p><p>注：<code>ll = ls -l</code></p><p><strong>ls -al 文件信息详解</strong></p><p><strong>表示列出所有的文件详细的权限与属性（包含隐藏文件）</strong> 例如： <code>-rw-------  1 neymar neymar     2532 10月 13 23:42 .bash_history</code> * 第一列代表这个文件的类型与权限 * 第一个字符若是[d]则是目录，若是[-]则是文件接下来的字符，三个为一组，且均为”rwx”的组合。其中<strong>[r]</strong>代表可读(read)，<strong>[w]</strong>代表可写(write), <strong>[x]</strong>代表可执行(execute),如果没有权限就会出现<strong>[-]</strong>。 * 第一组为 <em>文件所有者</em> 的权限 * 第二组为 <em>同用户组</em> 的权限 * 第三组为 <em>其他非本用户组</em> 的权限 * 第二列表示有多少文件名连接到此节点 * 第三列表示这个文件（目录）的”所有者账号“ * 第四列表示这个文件的所属用户组 * 第五列表示这个文件的容量大小，默认单位为B * 第六列为这个文件的最近修改日期 * 第七列为文件名</p><h2><span id="chgrp-改变文件所属用户组-change-group">chgrp - 改变文件所属用户组 change group</span></h2><p><em>用法：</em> <code>chgrp [-R] 用户组名 目录/文件名</code> <em>参数：</em> * -R : 进行递归的持续更改，也即连同子目录下所有文件、目录都更新成这个用户组</p><p><em>注意：</em>要改变的组名必须再/etc/group文件内存在才行，否则就会显示错误</p><h2><span id="chown-改变文件所有者和用户组-change-owner">chown - 改变文件所有者和用户组 change owner</span></h2><p><em>用法：</em> <code>chown [-R] 账号名称:组名 文件或目录</code> <em>注意：</em>用户必须是已经存在于系统中的账号，也就是在/etc/passwd这个文件中有记录的用户名才能改变</p><h2><span id="chmod-改变权限">chmod - 改变权限</span></h2><p><strong>数字类型改变文件权限：</strong> * r : 4<br>* w : 2<br>* x : 1 <code>chmod [-R] xyz 文件或目录</code> <em>xyz : 数字类型权限属性，为rwx属性值相加</em></p><p>例：<code>chmod 777 .bashrc</code></p><p><strong>符号类型改变文件权限：</strong> | | | u | | | | | :-------- | :--------| :------- | :--------| | | chmod | g | +(加入) | r | 文件或目录 | | |o | -(减去) | w | | |a | =(等于) | x |</p><p><strong>user → u, group → g, others → o, all → a</strong></p><p><em>例：</em> <code>chmod u=rwx,go=rx .bashrc</code></p><h2><span id="cd-切换目录-change-directory">cd - 切换目录 Change Directory</span></h2><p><em>用法：</em> <code>cd [相对路径或绝对路径]</code></p><p><strong>特殊目录：</strong> * . 代表此层目录 * .. 代表上一层目录 * - 代表前一个工作目录 * ~ 代表目前用户身份所在的主文件夹 * ~account 代表account这个用户的主文件夹</p><h2><span id="pwd-显示目前所在的目录-print-working-directory">pwd - 显示目前所在的目录 print working directory</span></h2><p><em>用法：</em> <code>pwd   [-P]</code> <em>参数：</em> * -P : 显示出当前的路径，而非使用连接(link)路径</p><h2><span id="mkdir-新建目录-make-directory">mkdir - 新建目录 make directory</span></h2><p><em>用法：</em> <code>mkdir [-mp]  目录名称</code> <em>参数：</em> * -m : 配置文件夹的权限(数字方式) * -p : 帮助你直接将所需要的目录递归创建起来(不建议经常使用)</p><h2><span id="rmdir-删除空目录-remove-directory">rmdir - 删除空目录 remove directory</span></h2><p><em>用法：</em> <code>rmdir  [-p]   目录名称</code> <em>参数：</em> * -p : 连同上层空目录一起删除</p><h2><span id="echo-显示打印出">echo - 显示,打印出</span></h2><p><em>用法：</em> <code>echo   [-eE]  字符串</code> <code>echo   $variable</code> <em>参数：</em> * -e : 把 ”  “ 当做转义字符 * -E : 不把反斜扛当做转义字符（默认）</p><h2><span id="cp-复制-copy">cp - 复制 copy</span></h2><p><em>用法：</em> <code>cp  [-adfilprsu]   源文件  目标文件</code> <code>cp  [options]    source1  source2  source3.... directory</code> <em>参数：</em> * <strong>-a : 相当于 -pdr 的意思，数据特性完全复制（效果与身份有关）</strong> * -d : 若源文件为连接文件的属性(link file),则复制连接文件属性而非文件身 * -f : force，若目标文件已存在且无法开启，则删除后再试一次 * <strong>-i : 若目标文件已存在则会询问是否覆盖</strong> * -l : 进行硬连接(hard link)的连接文件创建，而非复制文件本身 * -p : 连同文件属性一起复制过去，而非使用默认属性（备份常用） * <strong>-r : 递归持续复制，用于目录的复制行为</strong> * -s : 复制成为符号链接文件(symbolic link)，即“快捷方式”文件 * -u : 若目标文件比源文件旧时才更新 <strong>注意：如果源文件有两个以上，则最后一个目的文件一定要是目录才行</strong></p><h2><span id="rm-移除文件或目录">rm - 移除文件或目录</span></h2><p><em>用法：</em> <code>rm  [-fir]  文件或目录</code> <em>参数：</em> * -f : force, 忽略不存在的文件，不会出现警告信息 * -i : 互动模式，在删除前会询问用户是否操作 * -r : 递归删除。最常用在目录的删除了。<strong>这是非常危险的参数。</strong></p><h2><span id="mv-移动文件与目录或更名">mv - 移动文件与目录或更名</span></h2><p><em>用法：</em> <code>mv  [-fiu]  source  destination</code> <code>mv  [option]  source1  source2  source3 …  directory</code> <em>参数：</em> * -f : force，如果目标文件已经存在，不会询问而直接覆盖 * -i : 若目标文件已经存在时，询问是否覆盖 * -u : 若目标文件存在且source比较新才会更新</p><h2><span id="cat-查看文件内容-concatenate">cat - 查看文件内容 concatenate</span></h2><p><em>用法：</em> <code>cat  [-AbEnTv]</code> <em>参数：</em> * -A : 相当于-vET的结合，可以列出一些特殊字符，而不是空白 * -b : 列出行号，仅针对非空白行 * -E : 将结尾的断行字符 $ 显示出来 * <strong>-n : 显示行号，连同空白符，与-b不同</strong> * -T : 将[Tab]按键以 ^I 显示出来 * -v : 列出一些看不见的特殊字符</p><h2><span id="nl-添加行号打印">nl - 添加行号打印</span></h2><p><em>用法：</em> <code>nl  [-bnw]  文件</code> <em>参数：</em> * -b : 指定行号的显示方式，主要有两种： * -b a : 表示无论是否为空行，也同样列出行号（类似与 cat -n） * -b t : 空行不列出行号（默认） * -n : 列出行号的表示方法，主要有三种： * -n ln : 行号在屏幕最左方显示 * -n rn : 行号在字段最右方显示，且不加0 * -n rz : 行号在字段最右方显示，加0 * -w : 行号字段占用位数</p><h2><span id="more-可翻页查看">more - 可翻页查看</span></h2><p><em>用法：</em> <code>more  文件名</code> <em>操作：</em> | 空格键 | 代表向下翻一页| | :-------- | :--------| | Enter | 代表向下滚动一行| | /字符串 | 向下查询”字符串“关键字| | :f | 立刻显示出文件名以及目前显示的行数| | q | 代表立刻立刻more，不再显示该文件内容| | b或[ctrl]-b | 代表往回翻页，不过这只对文件有用，对管道无用|</p><h2><span id="less-一页一页翻动">less - 一页一页翻动</span></h2><p><em>用法：</em> <code>less    文件名</code> <em>操作：</em> | 空格 | 向下翻动一页| | :-------- | :-------- | | [PageDown] | 向下翻动一页| | [PageUp] | 向上翻动一页| | /字符串 | 向下查询”字符串“| | ? 字符串 | 向上查询”字符串“| | n | 重复前一个查询| | N | 反向重复前一个查询| | q | 离开less|</p><h2><span id="head-取出前面几行">head - 取出前面几行</span></h2><p><em>用法：</em> <code>head    [-n  number]   文件</code> <em>参数：</em> * -n : 后面接数字，代表显示几行的意思（默认10行）</p><h2><span id="tail-取出后面几行">tail - 取出后面几行</span></h2><p><em>用法：</em> <code>tail   [-n  number]   文件</code> <em>参数：</em> * -n : 后面接数字，代表显示几行（默认10行） * -f : 表示持续检测后面所接的文件名，要等到按下[ctrl]-c才会结束tail的检测</p><h2><span id="od-读取非纯文本文件">od - 读取非纯文本文件</span></h2><p><em>用法：</em> <code>od  [-t  TYPE]   文件</code> <em>参数：</em> * -t : 后面接类型： * a : 利用默认的字符来输出 * c : 使用ASCII字符来输出 * d[size] : 利用十进制来输出数据，每个整数占用size bytes * f[size] : 利用浮点数来输出数据，每个数占size bytes * x[size] : 利用十六进制来输出数据，每个整数占size bytes</p><h2><span id="touch-修改文件时间或创建新文件">touch - 修改文件时间或创建新文件</span></h2><p><em>用法：</em> <code>touch  [-acdmt]   文件</code> <em>参数：</em> * -a : 仅修改访问时间 * -c : 仅修改文件时间，若该文件不存在则不创建新文件 * -d : 后面可以接欲修改的日期而不用目前的日期，也可以使用 –date=”日期或时间” * -m : 仅修改mtime * -t : 后面可以接欲修改时间而不是当前时间，格式为[YYMMDDhhmm]</p><h2><span id="whereis-寻找特定文件">whereis -寻找特定文件</span></h2><p><em>用法：</em> <code>whereis  [-bmsu]  文件或目录名</code> <em>参数：</em> * -b : 只查找二进制文件 * -m : 只查找在manual路径下的文件 * -s : 只找source源文件 * -u : 查找不在上述三个选项中的其他特殊文件 <strong>注：whereis是利用数据库查找文件而不是直接在硬盘里找</strong></p><h2><span id="locate-查找文件">locate - 查找文件</span></h2><p><em>用法：</em> <code>locate  [-ir]   keyword</code> <em>参数：</em> * -i : 忽略大小写差异 * -r : 后面可接正则表达式的显示方式 <strong>注：locate也是经由数据库查找，速度较快，更新数据库命令：<code>updatedb</code></strong></p><h2><span id="find-在硬盘里寻找文件">find - 在硬盘里寻找文件</span></h2><p><em>用法：</em> <code>find   [PATH]    [option]    [action]</code> <em>参数：</em> 1. 与时间有关的: 共有 -atime, -ctime 与 -mtime，下面以-mtime说明 * -mtime n : n为数字，意为查找在n天之前的那一天之内被更改过的文件 * -mtime +n : 列出在n天之前（不含n天本身）被更改过的文件名 * -mtine -n : 列出n天之内（包含第n天）被更改过的文件名 * -newer file : file为一个已存在文件，列出比file要新的文件名</p><ol start="2" type="1"><li>与用户或用户组名有关的参数：<ul><li><pre><code>   -uid   n   :  n为数字，这个数字是用户的账号ID，即UID，记录在/etc/passwd里面与账号名                                                 称对应的数字</code></pre></li><li><pre><code>   -gid   n   :  n为数字，这个数字是用户组名的ID，即GID，这个GID记录在/etc/group中</code></pre></li><li><pre><code>     -user  name  :  查找用户名为name的文件</code></pre></li><li><pre><code>     -group  name :  查找用户组名为name的文件</code></pre></li><li><pre><code>     -nouser          :    寻找文件所有者不在/etc/passwd的人</code></pre></li><li><pre><code>     -nogroup       :    寻找用户组名不存在与/etc/group的人</code></pre></li></ul></li><li>与文件权限及名称有关的参数：<ul><li><pre><code>     -name  filenname :  查找文件名为filename的文件</code></pre></li><li><pre><code>      -size     [+-]SIZE   :   查找比SIZE还要大(+)或小(-)的文件，SIZE规格：c代表byte,k代 表kb</code></pre></li><li><pre><code>      -type   TYPE  :  查找文件类型为TYPE的文件。类型主要有：一般正规文件(f),设备文件(b,c)目录(d)，连接文件(l)，socket(s)及FIFO(p)等</code></pre></li><li><pre><code>       -perm  mode :  查找文件权限“刚好等于”mode的文件，这个mode类似于chmod的属性值</code></pre></li><li><pre><code>       -perm  -mode : 查找文件权限：必须要全部包括mode的权限“的文件</code></pre></li><li><pre><code>      -perm +mode : 查找文件权限”包含任一mode权限“的文件</code></pre></li></ul></li><li>其他可进行的操作：<ul><li><pre><code>     -exec command  :  command为其他命令  -exec后面可再接其他命令来处理查找到的结果{}代表由find找到的内容，命令借书标志” \; ”例：`find / -perm +7000 -exec ls -l {} \;`</code></pre></li><li><pre><code>      -print  :  将结果打印到屏幕上（默认）</code></pre></li></ul></li></ol><h2><span id="vi-文本编辑器">vi -文本编辑器</span></h2><p><strong>vi分为三种模式：一般模式，编辑模式与命令行模式。</strong></p><blockquote><p>一般模式：可以用上下左右键移动光标，删除字符或整行，也可以复制、粘贴文件数据 编辑模式：一般模式无法编辑内容，在一般模式中按下i,I,o,O等可以进入编辑模式 命令行模式：在一般模式中输入“ :, /, ? “三个中的任一字符就可以将光标移动到最下面一行，在此模式中可以提供查询数据操作，大量替换字符、离开vi、显示行号等操作</p></blockquote><p><strong>常用按键说明</strong> |移动光标方法| | | :-------- | :-------- | | h或左键头键 |光标向左移动一个字符| | j或向下箭头 |光标向下移动一个字符| | k或向上箭头| 光标向上移动一个字符| | l或向右箭头 |光标向右移动一个字符| | 数字+上下箭头 |向上下移动“数字”行| | [Crtl]+[f]、[PageDown] |向下翻一页| | [Ctrl]+[b]、[PageUp] |向上翻一页| | G |移动到这个文件的最后一行| | nG |n为数字，移动到这个文件的第n行| | gg | 移动到这个文件的第一行，相当于1G| | N[Enter] | n为数字。光标向下移动n行|</p><table><thead><tr class="header"><th style="text-align: left;">删除、复制与粘贴</th><th style="text-align: left;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">x</td><td style="text-align: left;">在一行字当中，向后删除一个字符([Del])</td></tr><tr class="even"><td style="text-align: left;">X</td><td style="text-align: left;">向前删除一个字符([Backspace])</td></tr><tr class="odd"><td style="text-align: left;">dd</td><td style="text-align: left;">删除光标所在的那一整行</td></tr><tr class="even"><td style="text-align: left;">ndd</td><td style="text-align: left;">n为数字，删除光标所在的下n行</td></tr><tr class="odd"><td style="text-align: left;">yy</td><td style="text-align: left;">复制光标所在那一行</td></tr><tr class="even"><td style="text-align: left;">nyy</td><td style="text-align: left;">n为数字，复制光标向下的n行</td></tr><tr class="odd"><td style="text-align: left;">p, P</td><td style="text-align: left;">p为将已复制的数据在光标下一行粘贴， P为粘贴在光标上一行</td></tr><tr class="even"><td style="text-align: left;">u</td><td style="text-align: left;">撤销</td></tr><tr class="odd"><td style="text-align: left;">[Ctrl]+r 、.</td><td style="text-align: left;">重做</td></tr></tbody></table><table><thead><tr class="header"><th style="text-align: left;">进入插入或替换的编辑模式</th><th style="text-align: left;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">i, I</td><td style="text-align: left;">i为从目前光标所在的下一个字符开始插入为所在目前所在行第一个非空格处插入</td></tr><tr class="even"><td style="text-align: left;">a, A</td><td style="text-align: left;">a为从目前光标所在的下一个字符开始插入A为从目前光标所在行的最后一个字符开始插入</td></tr><tr class="odd"><td style="text-align: left;">o, O</td><td style="text-align: left;">o为在目前光标的下一行插入新的一行O为在目前光标的上一行插入新的一行</td></tr><tr class="even"><td style="text-align: left;">r, R</td><td style="text-align: left;">r只会替换光标所在的那一个字符一次；R会一直替换光标所在的那个文字,直到按下[ESC]</td></tr></tbody></table><p><strong>命令行的保存、离开等命令</strong> * :w 保存 * :w! 强制保存，与文件权限有关 * :q 离开vi * :wq 保存并离开，wq!为强制保存后离开 * :! command 暂时离开vi到命令行下执行command命令 * :set nu 显示行号 * :set nonu 取消显示行号</p><h2><span id="paste-将多个文件的同一行贴在一起中间用tab隔开">paste -将多个文件的同一行贴在一起，中间用[tab]隔开</span></h2><p><em>用法：</em> <code>paste  [-d]  file1  file2</code> <em>参数：</em> * -d : 后面可以接分隔字符，默认是以[tab]来分隔的 * - : 如果file部分写成 - ，表示来自stdin的数据</p><h2><span id="passwd-设置修改密码">passwd -设置/修改密码</span></h2><p><em>用法：</em> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">passwd   [--stdin]  # 所有人均可使用来改自己密码</span><br><span class="line">passwd   [-l] [-u] [--stdin] [-S] [-n 日数] [-x 日数] [-w 日数] [-i 日期]   账号  # root功能</span><br></pre></td></tr></table></figure></p><p><em>参数：</em> * --stdin : 可以来自前一个管道的数据，作为密码输入，对shell script有帮助 * -l : Lock，会将/etc/shadow第二列最前面加上！使密码失效 * -u : 与-l相对，Unlock * -S : 列出密码相关参数，即shadow文件内的大部分信息 * -n : 后面接天数，shadow的第4字段，多久不可修改密码的天数 * -x : 后面接天数，shadow的第5字段，多久内必须要改动密码 * -w : 后面接天数，shadow的第6字段，密码过期前的警告天数 * -i : 后面接日期，密码失效日期 &gt;注：<strong>给一般账号新建密码需要使用”passwd 账号“的格式，使用”passwd“表示修改自己的密码</strong></p><h2><span id="sudo-以其他用户身份执行命令">sudo - 以其他用户身份执行命令</span></h2><p><em>用法：</em> <code>sudo  [-b]  [-u  用户账号]</code> <em>参数：</em> * -b : 将后续的命令让系统自行执行，而不与目前的shell产生影响 * -u : 后面接欲切换的用户，若无此项则代表切换身份root &gt;注： * sudo的执行仅需要自己的密码即可 * 仅有/etc/sudoers内的用户才能够执行sudo这个命令</p>]]></content>
      
      
      <categories>
          
          <category> 学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
