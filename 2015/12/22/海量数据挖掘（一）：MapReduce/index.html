<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>
    海量数据挖掘（一）：MapReduce | NIUHE | Be Myself Enjoy My Life
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE&#39;s Blog">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:title" content="海量数据挖掘（一）：MapReduce">
  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">Be Myself Enjoy My Life</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">目录</a></li>
      
        <li><a href="/categories">分类</a></li>
      
        <li><a href="/tags">标签</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        <article>

  
  
  <h3 class="article-title"><span>
      海量数据挖掘（一）：MapReduce</span></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2015/12/22/海量数据挖掘（一）：MapReduce/" rel="bookmark">
        <time class="entry-date published" datetime="2015-12-22T07:09:40.000Z">
          2015-12-22
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <blockquote>
<p>此系列为Cousera上Standford的<a href="https://class.coursera.org/mmds-002" target="_blank" rel="noopener">Mining Massive Datasets</a>课程学习笔记。 这是该系列的第一篇笔记：<strong>MapReduce</strong></p>
</blockquote>
<a id="more"></a>
<h2><span id="分布式文件系统-distributed-file-systems">分布式文件系统 Distributed File Systems</span></h2>
<h3><span id="cluster-architecture">Cluster Architecture</span></h3>
<p>传统的数据挖掘都在一台主机上搞定，而如今数据量之大早已不是一台主机可以处理的了，拿Google举例：</p>
<ul>
<li><strong>100亿</strong>个网页</li>
<li>每个网页平均大小 = <strong>20KB</strong></li>
<li>总共 10 billion * 20 KB = <strong>200TB</strong></li>
<li>磁盘读取速度 = <strong>50 MB/sec </strong></li>
<li>总共读取时间 = 四百万秒 = <strong>46天</strong></li>
<li>读取数据时间甚至比处理数据时间还要长</li>
</ul>
<p>所以现在的集群架构(Cluster Architecture)是这样的： <img src="/images/1450707371717.png" alt="Alt text"></p>
<p>构成树形结构，上面的节点都是交换机，底层叶子节点是Linux主机集群，每个集群包含14-64个主机节点。</p>
<p>这种集群架构虽然可以通过并发处理解决IO问题，但是它也面临新的问题： * Linux节点会挂掉 * 如何做到即使某个主机挂了也能永久保存其中的数据？ * 如何处理在计算中节点挂掉的情况？</p>
<ul>
<li>网络瓶颈
<ul>
<li>目前网络带宽 = 1 Gbps</li>
<li>移动10TB的数据大约需要一天</li>
</ul></li>
<li>编写分布式的程序比较困难！
<ul>
<li>需要一个简单的模型来消除大部分困难</li>
</ul></li>
</ul>
<h3><span id="mapreduce">MapReduce</span></h3>
<blockquote>
<p>Map-Reduce 解决了集群计算的一些困难与挑战。 * <strong>以冗余的方式把数据存储在多个节点</strong>上来保持数据的永久性和可用性。 * <strong>让计算靠近数据</strong>来最小化数据的移动。 * <strong>简单的编程模型</strong></p>
</blockquote>
<h3><span id="冗余存储基础设施-redundant-storage-infrastructure">冗余存储基础设施 Redundant Storage Infrastructure</span></h3>
<ul>
<li>分布式文件系统
<ul>
<li>Google GFS</li>
<li>Hadoop HDFS</li>
</ul></li>
<li>典型使用场景
<ul>
<li>数据量大</li>
<li>少更新</li>
<li>读取频繁</li>
</ul></li>
</ul>
<p>文件分布系统就像以下： <img src="/images/1450709258137.png" alt="Alt text"> <strong>每一“块”的服务器也有计算功能，不光是存储数据！</strong> <img src="/images/1450709278438.png" alt="Alt text"></p>
<h2><span id="计算模型-conputational-model">计算模型 Conputational model</span></h2>
<h3><span id="word-count">Word Count</span></h3>
<blockquote>
<p>一个例子 Word Count： * 有一个非常大的文本文件 * 需要统计每个单词出现的次数</p>
</blockquote>
<ul>
<li>Case 1 : 整个文件无法读取进内存，但是所有的<code>&lt;word, count&gt;</code>键值对可以存储在内存里。</li>
</ul>
<p>这种情况我们可以简单写一个Hash Table，以word作为key，count作为value来实现。</p>
<ul>
<li>Case 2 : 连<code>&lt;word, count&gt;</code>都无法完全保存在内存里。</li>
</ul>
<p>这种情况可以用一条Linux命令来解决： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">words(doc.txt) | sort | uniq -c</span><br></pre></td></tr></table></figure></p>
<p><code>words</code>是一个程序，用来把文件输出成单词，一行一个。</p>
<p>这种方法正是MapReduce模型的计算方法，而且还天然地可以并行计算。</p>
<h3><span id="整体概揽">整体概揽</span></h3>
<figure>
<img src="/images/1450710473291.png" alt="Alt text"><figcaption>Alt text</figcaption>
</figure>
<h3><span id="具体分析">具体分析</span></h3>
<h4><span id="map">Map</span></h4>
<p>输入一些原始的键值对，输出中间状态的键值对，一对一或一对多，在上述例子里就是<code>words</code>这个程序，输入文件名，输出<code>&lt;word, 1&gt;</code>的键值对。 <img src="/images/1450710723670.png" alt="Alt text"></p>
<h4><span id="reduce">Reduce</span></h4>
<p>把中间状态的键值对按照<code>key</code>分组整理，输出的键值对都已经分好组，在上述例子中就是<code>sort</code>这个命令。</p>
<p>最后是把每组键值对的<code>value</code>合并成一个。 <img src="/images/1450711030365.png" alt="Alt text"></p>
<p>整个处理过程中，程序员只需要写两个函数：<code>Map(k, v)</code>和<code>Reduce(K, &lt;V&gt;*)</code>，对于解决不同的问题两个函数的实现各有不同，但是框架都是这一个。 <img src="/images/1450711170607.png" alt="Alt text"></p>
<h3><span id="并行计算">并行计算</span></h3>
<ol type="1">
<li>大文件拆分成多个部分</li>
<li>每部分文件分别在一个主机上进行Map计算。</li>
<li>通过Hash把所有主机Map之后的导入到一个或多个主机里，使具有同一个<code>key</code>的键值对都出现在一个主机里，并在每个主机里分别进行排序。</li>
<li>在各个主机里分别Reduce</li>
</ol>
<figure>
<img src="/images/1450711387926.png" alt="Alt text"><figcaption>Alt text</figcaption>
</figure>
<p>伪码示例： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">map(key, value):</span><br><span class="line">    <span class="comment"># key: document name; value: text of the document</span></span><br><span class="line">    <span class="keyword">for</span> each word w <span class="keyword">in</span> value:</span><br><span class="line">        emit(w, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">reduce(key, values):</span><br><span class="line">    <span class="comment"># key: a word; value: an iterator over counts</span></span><br><span class="line">    result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> each count v <span class="keyword">in</span> values:</span><br><span class="line">        result += v</span><br><span class="line">    emit(key, result)</span><br></pre></td></tr></table></figure></p>
<h3><span id="examples">Examples</span></h3>
<p><img src="/images/1450712456661.png" alt="Alt text"> <img src="/images/1450712474358.png" alt="Alt text"></p>
<h2><span id="调度和数据流动-scheduling-and-data-flow">调度和数据流动 Scheduling and Data Flow</span></h2>
<p>描述Map-Reduce的工作图： <img src="/images/1450747181061.png" alt="Alt text"></p>
<p>并行处理模型，上一节已经描述过了： <img src="/images/1450747276231.png" alt="Alt text"></p>
<h3><span id="environment">Environment</span></h3>
<p>Map-Reduce过程需要考虑的问题： * 对输入数据<strong>划分</strong> * 程序的执行在一大堆机器里进行<strong>调度</strong> * 执行<strong>按<code>key</code>分组</strong>这一步骤 * 处理节点(机器)<strong>崩溃</strong> * 管理必要地机器之间的<strong>通信</strong></p>
<h3><span id="data-flow">Data Flow</span></h3>
<blockquote>
<p>输入和最终输出是储存在分布式文件系统上的(DFS)，调度者应尽量调度Map任务&quot;靠近&quot;输入数据实际所存储的地方，让计算靠近数据。</p>
</blockquote>
<blockquote>
<p>中间结果存储在Map工作者和Reduce工作者<strong>本地</strong>的文件系统里。</p>
</blockquote>
<blockquote>
<p>一个Map-Reduce任务的输出通常是另一个Map-Reduce任务的的输入。</p>
</blockquote>
<h3><span id="coordination">Coordination</span></h3>
<blockquote>
<p>每个Map-Reduce任务都有一个Master节点，Master节点需要负责总体任务的协调与调度。</p>
</blockquote>
<p>Master节点需要考虑的问题： * 每个节点的<strong>任务状态</strong>：空闲的(idle), 正在工作的(in-progress), 已完成的(completed) * 有空闲任务的话就找可用的节点去处理 * 当一个Map任务完成时，工作者向Master节点发送<em>R</em>个中间文件的位置和大小，<em>R</em>是Reduce工作者的个数，每个Reduce工作者获得一个中间文件。 * Master节点把数据推送到Reducers节点。 * Master节点还要时不时地ping一下工作者看机器是否还活着。</p>
<h3><span id="失败处理办法">失败处理办法</span></h3>
<ul>
<li>处理Map任务的节点挂了</li>
</ul>
<p>由于Map任务输出的中间结果是存储在本地的，所以机器挂了输出的数据也就没了，只能重新做了。 <strong>把挂了节点的Map任务重设成空闲</strong>，不管挂之前是处理中还是已完成，反正数据都没了，然后等着有其他可用节点来完成这个节点的工作。</p>
<ul>
<li>处理Reduce任务的节点挂了</li>
</ul>
<p>由于Reduce任务输出的最终结果是保存在分布式文件系统上的，我们前面已经讨论过了，一个节点坏了没关系，还有其他节点保存着备份，所以如果该节点是完成Reduce任务之后挂的那就不用管了，数据还在; 如果是没完成就挂了，那就需要重做了。 <strong>只把没做完就挂了的任务重设为空闲</strong>，等着其他节点有空来作。</p>
<ul>
<li>Master节点挂了怎么办</li>
</ul>
<p>失去了领导者这个<strong>任务只能终止</strong>，然后等待从头重新开始咯。 不过机器的平均使用寿命在1000天左右，单台机器挂掉的概率是很小的，在Map任务和Reduce任务节点的集群里，很可能会出现有一两台挂掉的情况，<strong>对于Master这个单一节点来讲，挂掉的几率非常小</strong>，可以不考虑。</p>
<h3><span id="map和reduce的工作数量">Map和Reduce的工作数量</span></h3>
<p>设有<em>M</em>个Map任务，<em>R</em>个Reduce任务，我们的目的就是确定M和R。</p>
<p>拇指规则（经验）： * 让M远大于集群里节点个数 * 每个DFS区块处理一个map任务，可以减少单个节点的任务量 * 提高动态负载均衡和从挂掉节点恢复的速度 * 通常R比M小</p>
<h2><span id="优化-refinements">优化 Refinements</span></h2>
<h3><span id="combiners">Combiners</span></h3>
<p>通常一个Map任务会处理出许多个具有相同<code>key</code>的键值对，直接把这样的数据传给Reducer会很巨大，网络带宽占用多，有时候可以在传输前<strong>预合并</strong>一下，极大的减少了数据量，发送速度也显著提高。</p>
<p>合并(combine)函数通常与Reduce函数是一样的。</p>
<p>回到之前Word Count的例子 Map任务输出结果中可能会有大量的<code>&lt;word, 1&gt;</code>具有相同的<code>key</code>,比如<code>the</code>可能出现了1000次，那么里面就有1000个<code>('the', 1)</code>，这时候可以通过预合并把具有相同<code>key</code>的键值对合并，就变为了<code>('the', 1000)</code>，然后再推送到Reduce任务中，极大减少了传输数据量。 如图所示： <img src="/images/1450752050711.png" alt="Alt text"></p>
<p>但预合并并不是什么时候都管用的，它要求<strong>Reduce函数满足交换律和结合律</strong>。</p>
<p>举个例子，比如求和(sum)满足交换律和结合律，即<code>a + b = b + a</code>和<code>(a + b) + c = a + (b + c)</code>，所以它可以在本地预处理。</p>
<p>如果Reduce函数是求平均值(Average)呢？ 我们都过把大数据分成了很多小块，在每个小块里进行map，然后把输出结果具有相同<code>key</code>的键值对加起来再取平均，然后发送给Reduce任务，Reduce把每个小块的平均值加起来再取平均，得到最终结果。</p>
<p>得到的是正确结果吗？ <strong>显然不是！</strong></p>
<p><strong>求平均值这个运算不满足结合律</strong>，分成小块取平均然后加起来再取平均与直接把所有数据加起来取平均是不相等的！</p>
<p>所以<strong>这个例子不能用与Reduce一样的合并函数</strong>，但也不是没有办法，可以只求出它们的和，不取平均，然后发送到Reduce里，Reduce函数把所有的区块的和加起来再取平均，得到的就是正确结果了。</p>
<p>再换一个，如果要求中位数(Median)呢？ 那就没辙了，只能直接传原始map输出数据了。</p>
<h3><span id="分块函数">分块函数</span></h3>
<figure>
<img src="/images/1450753330650.png" alt="Alt text"><figcaption>Alt text</figcaption>
</figure>
<h2><span id="实现-implementations">实现 Implementations</span></h2>
<ul>
<li>Hadoop
<ul>
<li>开源、用java实现</li>
<li>使用HDFS作为稳定的存储</li>
<li>下载： http://lucene.apache.org/hadoop/</li>
</ul></li>
<li>Hive, Pig
<ul>
<li>在hadoop MapReduce层上面的抽象</li>
</ul></li>
<li>Google MapReduce
<ul>
<li>使用Google File System作为存储</li>
<li>只有google内部可以使用</li>
</ul></li>
</ul>
<figure>
<img src="/images/1450753341548.png" alt="Alt text"><figcaption>Alt text</figcaption>
</figure>
<h2><span id="资源和延伸阅读">资源和延伸阅读</span></h2>
<p>课件pdf下载</p>
<p>延伸阅读： <a href="http://research.google.com/archive/mapreduce.html" target="_blank" rel="noopener">MapReduce: Simplified Data Processing on Large Clusters</a></p>
<p><a href="http://research.google.com/archive/gfs.html" target="_blank" rel="noopener">The Google File System</a></p>
<p>资源：</p>
<ul>
<li>Hadoop Wiki
<ul>
<li><a href="http://wiki.apache.org/hadoop/" target="_blank" rel="noopener">介绍</a></li>
<li><a href="http://wiki.apache.org/hadoop/GettingStartedWithHadoop" target="_blank" rel="noopener">Getting Start</a></li>
<li><a href="http://wiki.apache.org/hadoop/HadoopMapReduce" target="_blank" rel="noopener">MapReduce 概揽</a></li>
<li>http://wiki.apache.org/lucene-hadoop/HadoopMapRedClasses</li>
<li><a href="http://wiki.apache.org/hadoop/EclipseEnvironment" target="_blank" rel="noopener">Eclipse环境</a></li>
</ul></li>
<li><p><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">Hadoop 官网</a></p></li>
<li><p><a href="http://www.apache.org/dyn/closer.cgi/lucene/" target="_blank" rel="noopener">镜像</a></p></li>
</ul>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/学习笔记/">学习笔记</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/数据挖掘/">数据挖掘</a>
      </span>
      

    </div>

    
  </div>
</article>

<div class="social-share"></div>


	<section id="comment" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'Niuhe';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>



      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2018
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      

<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>