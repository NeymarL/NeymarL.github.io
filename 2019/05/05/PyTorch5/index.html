<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

  <meta charset="utf-8">
  
  <!-- if (config.subtitle) {
    title.push(config.subtitle);
  } -->
  <title>
    PyTorch源码浅析(5)：Python扩展 | NIUHE
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE的博客">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:title" content="PyTorch源码浅析(5)：Python扩展">
  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script>
  <script type="text/javascript" src="/js/search.js"></script>
  <script type="text/javascript" src="/js/jquery.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれんな</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">博客</a></li>
      
        <li><a href="/notes">笔记</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/search">搜索</a></li>
      
        <li><a href="/about">关于</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        <article>

  
  
  <h3 class="article-title"><span>
      PyTorch源码浅析(5)：Python扩展</span></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch5/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:58:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>这篇是本系列最后一篇博客了，介绍一下前面的C++代码怎么与Python交互，或者说Python里怎么调用C++代码进行高效的计算。首先简单介绍一下预备知识，既Python的C扩展通常怎么写；然后以比较核心的数据结构 Tensor 和 Storage 为例看一下它们怎么转换为Python类型的；最后稍带点儿Python自微分函数的实现。</p>
<a id="more"></a>
<p><strong>目录</strong></p>
<!-- toc -->
<ul>
<li><a href="#python的cc扩展">Python的C/C++扩展</a>
<ul>
<li><a href="#扩展模块">扩展模块</a></li>
<li><a href="#自定义python类型">自定义Python类型</a></li>
</ul></li>
<li><a href="#torch_c">torch._C</a>
<ul>
<li><a href="#storage">Storage</a></li>
<li><a href="#tensor">Tensor</a></li>
<li><a href="#nn">NN</a></li>
</ul></li>
</ul>
<!-- tocstop -->
<h2><span id="python的cc扩展">Python的C/C++扩展</span></h2>
<h3><span id="扩展模块">扩展模块</span></h3>
<p>对于简单的C代码，构建一个自定义扩展模块是很容易的。<code>C/C++</code>部分基本上只需要做以下几件事：</p>
<ul>
<li><p>包含头文件<code>Python.h</code></p></li>
<li><p>正确的声明函数，即</p>
<ul>
<li><p>函数必须是<code>static</code></p></li>
<li><p>返回类型必须是<code>PyObject *</code></p></li>
<li><p>参数列表必须是<code>PyObject *self, PyObject *args</code></p></li>
</ul></li>
<li><p>定义一个Method Table，把模块需要包括的函数都放进去</p></li>
<li><p>定义模块和初始化函数</p></li>
</ul>
<p>举个🌰，下面的代码构建了一个只有一个函数的Python模块，该函数的功能是求最大公约数（<code>py_gcd</code>）:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"Python.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"sample.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 把普通C语言实现的gcd()封装成Python可以调用的函数 */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> PyObject *<span class="title">py_gcd</span><span class="params">(PyObject *self, PyObject *args)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> x, y, result;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 从 args 里解析实际参数 */</span></span><br><span class="line">  <span class="keyword">if</span> (!PyArg_ParseTuple(args,<span class="string">"ii"</span>, &amp;x, &amp;y)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/* 调用普通C语言实现的gcd() */</span></span><br><span class="line">  result = gcd(x,y);</span><br><span class="line">  <span class="comment">/* 把 int 转化为 PyObject* */</span></span><br><span class="line">  <span class="keyword">return</span> Py_BuildValue(<span class="string">"i"</span>, result);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 定义模块的 method table */</span></span><br><span class="line"><span class="keyword">static</span> PyMethodDef SampleMethods[] = &#123;</span><br><span class="line">  &#123;<span class="string">"gcd"</span>,  py_gcd, METH_VARARGS, <span class="string">"Greatest common divisor"</span>&#125;,</span><br><span class="line">  &#123; <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 定义模块结构 */</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyModuleDef</span> <span class="title">samplemodule</span> = &#123;</span></span><br><span class="line">  PyModuleDef_HEAD_INIT,</span><br><span class="line">  <span class="string">"sample"</span>,           <span class="comment">/* name of module */</span></span><br><span class="line">  <span class="string">"A sample module"</span>,  <span class="comment">/* Doc string (may be NULL) */</span></span><br><span class="line">  <span class="number">-1</span>,                 <span class="comment">/* Size of per-interpreter state or -1 */</span></span><br><span class="line">  SampleMethods       <span class="comment">/* Method table */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 模块初始化函数 */</span></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">PyInit_sample</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> PyModule_Create(&amp;samplemodule);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>具体细节就不展开了，有兴趣的童鞋可以参考下面的链接。</p>
<p>要绑定这个扩展模块，像下面这样创建一个 <code>setup.py</code> 文件：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># setup.py</span></span><br><span class="line"><span class="keyword">from</span> distutils.core <span class="keyword">import</span> setup, Extension</span><br><span class="line"></span><br><span class="line">setup(name=<span class="string">'sample'</span>,</span><br><span class="line">      ext_modules=[</span><br><span class="line">        Extension(<span class="string">'sample'</span>,</span><br><span class="line">                  [<span class="string">'pysample.c'</span>],</span><br><span class="line">                  include_dirs = [<span class="string">'/some/dir'</span>],</span><br><span class="line">                  define_macros = [(<span class="string">'FOO'</span>,<span class="string">'1'</span>)],</span><br><span class="line">                  undef_macros = [<span class="string">'BAR'</span>],</span><br><span class="line">                  library_dirs = [<span class="string">'/usr/local/lib'</span>],</span><br><span class="line">                  libraries = [<span class="string">'sample'</span>]</span><br><span class="line">                  )</span><br><span class="line">        ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>为了构建最终的函数库，只需简单的使用 <code>python3 buildlib.py build_ext --inplace</code> 命令即可。它会创建一个名字叫 <code>sample.so</code> 的共享库，当被编译后，你就能将它作为一个模块导入进来了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> sample</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sample.gcd(<span class="number">35</span>, <span class="number">42</span>)</span><br><span class="line"><span class="number">7</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：这部分主要参考<a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/c15/p02_write_simple_c_extension_module.html" target="_blank" rel="noopener">Python3-Cookbook</a>.</p>
</blockquote>
<h3><span id="自定义python类型">自定义Python类型</span></h3>
<p>在Python代码中如果要创建一个自定义类使用<code>class</code>关键字即可，但是在C代码中就没那么方便了。首先简单介绍下Python中的类型。在Python中一切皆对象，Python中有两种对象：</p>
<ul>
<li><p>一种是类型对象（class对象）：表示Python定义的类型，例如<code>int, str, object</code>等；</p></li>
<li><p>另一种是实例对象（instance对象）：表示由class对象创建的实例。</p></li>
</ul>
<p>Python中的所有对象都是直接或者间接继承<code>object</code>，然后<code>object</code>又是<code>type</code>类型。Python对象的C语言实现也是分为两部分，一部分表示实例对象，存储对象实际的数据；另一部分是类型对象，存储对象的元数据。也就是说，自定义类型也要实现这两部分，举个例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 实例对象 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    PyObject_HEAD</span><br><span class="line">    <span class="comment">/* 类型实际的数据在这里定义 */</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">&#125; noddy_NoddyObject;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 类型对象 */</span></span><br><span class="line"><span class="keyword">static</span> PyTypeObject noddy_NoddyType = &#123;</span><br><span class="line">    PyVarObject_HEAD_INIT(<span class="literal">NULL</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="string">"noddy.Noddy"</span>,             <span class="comment">/*tp_name*/</span></span><br><span class="line">    <span class="keyword">sizeof</span>(noddy_NoddyObject), <span class="comment">/*tp_basicsize*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_itemsize*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_dealloc*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_print*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_getattr*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_setattr*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_compare*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_repr*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_number*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_sequence*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_mapping*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_hash */</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_call*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_str*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_getattro*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_setattro*/</span></span><br><span class="line">    <span class="number">0</span>,                         <span class="comment">/*tp_as_buffer*/</span></span><br><span class="line">    Py_TPFLAGS_DEFAULT,        <span class="comment">/*tp_flags*/</span></span><br><span class="line">    <span class="string">"Noddy objects"</span>,           <span class="comment">/*tp_doc*/</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>然后创建一个新扩展模块，并完成初始化：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 定义模块的 method table */</span></span><br><span class="line"><span class="keyword">static</span> PyMethodDef noddy_methods[] = &#123;</span><br><span class="line">    &#123;<span class="literal">NULL</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 模块初始化函数 */</span></span><br><span class="line"><span class="function">PyMODINIT_FUNC <span class="title">initnoddy</span><span class="params">(<span class="keyword">void</span>)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    PyObject* m;</span><br><span class="line">    <span class="comment">/* tp_new 相当于Python里的 __new__ */</span></span><br><span class="line">    noddy_NoddyType.tp_new = PyType_GenericNew;</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (PyType_Ready(&amp;noddy_NoddyType) &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    m = Py_InitModule3(<span class="string">"noddy"</span>, noddy_methods,</span><br><span class="line">                       <span class="string">"Example module"</span>);</span><br><span class="line"></span><br><span class="line">    Py_INCREF(&amp;noddy_NoddyType);</span><br><span class="line">    <span class="comment">/* 向模块添加类型 */</span></span><br><span class="line">    PyModule_AddObject(m, <span class="string">"Noddy"</span>, (PyObject*)&amp;noddy_NoddyType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：这部分介绍的比较简略，详细请参考 <a href="http://www.xefan.com/archives/84091.html" class="uri" target="_blank" rel="noopener">http://www.xefan.com/archives/84091.html</a>.</p>
</blockquote>
<h2><span id="torch_c">torch._C</span></h2>
<p>有了上面的预备知识之后，我们就能看ATen还有autograd等模块的代码是怎么导入Python了。构建Python扩展模块的代码在 <code>torch/csrc/Module.cpp</code> 里，主要部分如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">/* method table */</span></span><br><span class="line"><span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;PyMethodDef&gt; methods;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 初始化模块 */</span></span><br><span class="line"><span class="function">PyObject* <span class="title">initModule</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  HANDLE_TH_ERRORS</span><br><span class="line">  THInferNumThreads();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 向 method table 添加函数 */</span></span><br><span class="line">  THPUtils_addPyMethodDefs(methods, TorchMethods);</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, DataLoaderMethods);</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, </span><br><span class="line">                           torch::autograd::python_functions());</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, </span><br><span class="line">                       torch::multiprocessing::python_functions());</span><br><span class="line">	...</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 构建 torch._C 模块 */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> PY_MAJOR_VERSION == 2</span></span><br><span class="line">  ASSERT_TRUE(<span class="keyword">module</span> = Py_InitModule(<span class="string">"torch._C"</span>, methods.data()));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  <span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyModuleDef</span> <span class="title">torchmodule</span> = &#123;</span></span><br><span class="line">      PyModuleDef_HEAD_INIT, <span class="string">"torch._C"</span>, <span class="literal">nullptr</span>, <span class="number">-1</span>, </span><br><span class="line">      methods.data()</span><br><span class="line">  &#125;;</span><br><span class="line">  ASSERT_TRUE(<span class="keyword">module</span> = PyModule_Create(&amp;torchmodule));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 各种初始化 */</span></span><br><span class="line">  ASSERT_TRUE(THPWrapper_init(<span class="keyword">module</span>));</span><br><span class="line">  ...</span><br><span class="line">  torch::autograd::initNNFunctions(<span class="keyword">module</span>);     <span class="comment">// 初始化自微分相关API</span></span><br><span class="line">  torch::autograd::init_legacy_variable(<span class="keyword">module</span>);<span class="comment">// 初始化Tensor类型</span></span><br><span class="line">  torch::python::init_bindings(<span class="keyword">module</span>);         <span class="comment">// 初始化NN相关函数</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> USE_CUDA</span></span><br><span class="line">  torch::cuda::initModule(<span class="keyword">module</span>);              <span class="comment">// 初始化CUDA模块</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="comment">/* 初始化各种Storage类型 */</span></span><br><span class="line">  ASSERT_TRUE(THPDoubleStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPFloatStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPHalfStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPLongStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPIntStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPShortStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPCharStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPByteStorage_init(<span class="keyword">module</span>));</span><br><span class="line">  ASSERT_TRUE(THPBoolStorage_init(<span class="keyword">module</span>));</span><br><span class="line"> </span><br><span class="line">  ...</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">module</span>;</span><br><span class="line">  END_HANDLE_TH_ERRORS</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>基本上所有C/C++实现的API都被绑定在 <code>torch._C</code> 扩展模块中，下面以Storage和Tensor为例，看一下 <code>torch.Storage</code>和<code>torch.Tensor</code> 类型的绑定方法，比较有意思的是它们两个的绑定方式区别还挺大的。</p>
<h3><span id="storage">Storage</span></h3>
<p>从上面的 <code>initModule()</code> 函数中可以看到，里面有许多初始化各种Storage类型的代码，它们的目的就是创建各种Storage类型，如 <code>torch._C._FloatStorageBase</code>, <code>torch._C._LongStorageBase</code>等，而 <code>torch.FloatStorage</code> 等类型是从Python端创建的，继承自 <code>torch._C._FloatStorageBase</code> 等类型，这部分代码可以在<code>torch/__init__.py</code>中找到。</p>
<p>回到绑定过程，<code>THPDoubleStorage_init()</code> 等函数其实是用C范式生成的，和<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/">第一篇</a>里的TH库中用的方法一样。它实际调用的函数是 <code>bool THPStorage_(init)(PyObject *module)</code>，实现 <code>torch/csrc/generic/Storage.cpp</code>里，这个函数会根据不同类型展开：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">THPStorage_</span><span class="params">(init)</span><span class="params">(PyObject *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;PyMethodDef&gt; methods;</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, THPStorage_(methods));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> THD_GENERIC_FILE</span></span><br><span class="line">  THPUtils_addPyMethodDefs(methods, THPStorage_(sharingMethods));</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 绑定类方法 */</span></span><br><span class="line">  THPStorageType.tp_methods = methods.data();</span><br><span class="line">  <span class="comment">/* 绑定类成员 */</span></span><br><span class="line">  THPStorageType.tp_members = THPStorage_(members);</span><br><span class="line">  <span class="keyword">if</span> (PyType_Ready(&amp;THPStorageType) &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  Py_INCREF(&amp;THPStorageType);</span><br><span class="line">  <span class="comment">/* 向模块添加 THPStorage 类型 */</span></span><br><span class="line">  PyModule_AddObject(<span class="keyword">module</span>, THPStorageBaseStr, </span><br><span class="line">                     (PyObject*)&amp;THPStorageType);</span><br><span class="line">  THPStorage_(initCopyMethods)();</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个函数初始化了 <code>THPStorageType</code> 类型并添加到<code>torch._C</code>模块中，该类型的定义如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 实例对象 */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THPStorage</span> &#123;</span></span><br><span class="line">  PyObject_HEAD</span><br><span class="line">  <span class="comment">/* THWStorage 为宏定义，会转换为 THxxxStorage */</span></span><br><span class="line">  THWStorage *cdata;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 类型对象 */</span></span><br><span class="line">PyTypeObject THPStorageType = &#123;</span><br><span class="line">  PyVarObject_HEAD_INIT(<span class="literal">nullptr</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="string">"torch._C."</span> THPStorageBaseStr,         <span class="comment">/* tp_name */</span></span><br><span class="line">  <span class="keyword">sizeof</span>(THPStorage),                    <span class="comment">/* tp_basicsize */</span></span><br><span class="line">  <span class="number">0</span>,                                     <span class="comment">/* tp_itemsize */</span></span><br><span class="line">  (destructor)THPStorage_(dealloc),      <span class="comment">/* tp_dealloc */</span></span><br><span class="line">  ...</span><br><span class="line">  THPStorage_(pynew),                    <span class="comment">/* tp_new */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>Python里类型的名字由 <code>tp_name</code> 域确定，也就是 <code>&quot;torch._C.&quot; THPStorageBaseStr</code>，后者一看就是宏定义，它展开后会变成 <code>_xxxStorageBase</code>，其中<code>xxx</code>为各种类型，所以最后就变成了 <code>torch._C._FloatStorageBase</code> 等类型。</p>
<h3><span id="tensor">Tensor</span></h3>
<p><code>torch.Tensor</code>的实现就与<code>torch.Storage</code> 不一样了，因为ATen的存在，绑定的话也是绑定ATen里的Tensor，不会绑定THTensor。还有一点，就是Python里的Tensor和Variable合并了，所以<code>torch.Tensor</code>直接和 <code>autograd::Variable</code> 绑定在一起了。不过准确来说是 <code>torch._C._TensorBase</code> 和 <code>autograd::Variable</code> 绑定在一起了，而 <code>torch.Tensor</code> 继承自 <code>torch._C._TensorBase</code>。</p>
<p>绑定的代码在 <code>torch/csrc/autograd/python_variable.cpp</code>中：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// python_variable.h</span></span><br><span class="line"><span class="comment">/* 实例对象 */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THPVariable</span> &#123;</span></span><br><span class="line">    PyObject_HEAD</span><br><span class="line">    <span class="comment">// Payload</span></span><br><span class="line">    torch::autograd::Variable cdata;</span><br><span class="line">    PyObject* backward_hooks = <span class="literal">nullptr</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// python_variable.cpp</span></span><br><span class="line">...</span><br><span class="line"><span class="comment">/* 类型对象 */</span></span><br><span class="line">PyTypeObject THPVariableType = &#123;</span><br><span class="line">  PyVarObject_HEAD_INIT(<span class="literal">nullptr</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="string">"torch._C._TensorBase"</span>,                <span class="comment">/* tp_name */</span></span><br><span class="line">  <span class="keyword">sizeof</span>(THPVariable),                   <span class="comment">/* tp_basicsize */</span></span><br><span class="line">  <span class="number">0</span>,                                     <span class="comment">/* tp_itemsize */</span></span><br><span class="line">  (destructor)THPVariable_dealloc,       <span class="comment">/* tp_dealloc */</span></span><br><span class="line">  ...</span><br><span class="line">  THPVariable_pynew                      <span class="comment">/* tp_new */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 初始化类型 */</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">THPVariable_initModule</span><span class="params">(PyObject *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="comment">/* 获取 method table */</span></span><br><span class="line">  <span class="keyword">static</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;PyMethodDef&gt; methods;</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, </span><br><span class="line">                           torch::autograd::variable_methods);</span><br><span class="line">  THPUtils_addPyMethodDefs(methods, extra_methods);</span><br><span class="line">  <span class="comment">/* 绑定类方法 */</span></span><br><span class="line">  THPVariableType.tp_methods = methods.data();</span><br><span class="line">  <span class="keyword">if</span> (PyType_Ready(&amp;THPVariableType) &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  Py_INCREF(&amp;THPVariableType);</span><br><span class="line">  <span class="comment">/* 向模块中添加类型 */</span></span><br><span class="line">  PyModule_AddObject(<span class="keyword">module</span>, <span class="string">"_TensorBase"</span>, </span><br><span class="line">                     (PyObject *)&amp;THPVariableType);</span><br><span class="line">  torch::autograd::initTorchFunctions(<span class="keyword">module</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意到，这里只绑定了 <code>_TensorBase</code> 一种类型，而不像Storage那样利用宏把各种类型的StorageBase都定义了。</p>
<p>其他类型的Tensor，如 <code>torch.FloatTensor</code> 等在 <code>torch/tensor/python_tensor.cpp</code> 中的 <code>initialize_python_bindings()</code> 函数里动态绑定：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initialize_python_bindings</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* 把ATen里的Tensor类型转化为Python里的PyTypeObject */</span></span><br><span class="line">  initialize_aten_types(tensor_types);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 初始化上面转化来的PyTypeObject */</span></span><br><span class="line">  py_initialize_metaclass(metaclass);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 获取 torch.Tensor 的所有方法 */</span></span><br><span class="line">  <span class="keyword">auto</span> tensor_dict = get_tensor_dict();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 把torch.Tensor的方法复制给每个类型，如torch.FloatTensor等 */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; tensor_type : tensor_types) &#123;</span><br><span class="line">    py_initialize_tensor_type(tensor_type.py_type, </span><br><span class="line">                              tensor_type.name, tensor_dict.get());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 向torch模块绑定这些各种类型的Tensor */</span></span><br><span class="line">  py_bind_tensor_types(tensor_types);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 设置 torch.Tensor 的默认类型为 torch.FloatTensor */</span></span><br><span class="line">  set_default_tensor_type(at::globalContext().getVariableType(</span><br><span class="line">    at::Backend::CPU, at::kFloat));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个函数由Python调用，调用的代码在 <code>torch/__init__.py</code> 中（<code>_C._initExtension()</code>）。调用时 <code>torch.Tensor</code> 已经定义，这个函数要做的就是定义其他Tensor类型，然后把Tensor类型的方法直接拷贝给它们，最后在设置一下默认类型的Tensor。为什么数据类型不同却可以直接拷贝？因为 <code>at::Tensor</code> 可以针对不同数据类型调用不同的方法，类型多态已经在ATen内部实现了。</p>
<p>在上面的代码中，Tensor 绑定的方法来自 <code>torch::autograd::variable_methods</code>，这个列表在 <code>csrc/autograd/generated/python_variable_methods.cpp</code> 中：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PyMethodDef variable_methods[] = &#123;</span><br><span class="line">  &#123;<span class="string">"__add__"</span>, (PyCFunction)THPVariable_add, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__radd__"</span>, (PyCFunction)THPVariable_add, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__iadd__"</span>, (PyCFunction)THPVariable_add_, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__rmul__"</span>, (PyCFunction)THPVariable_mul, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__mul__"</span>, (PyCFunction)THPVariable_mul, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__imul__"</span>, (PyCFunction)THPVariable_mul_, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"__sub__"</span>, (PyCFunction)THPVariable_sub, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"addcmul"</span>, (PyCFunction)THPVariable_addcmul, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从文件路径可以看出这也是根据 <code>derivatives.yaml</code> 自动生成的代码，拿 <code>addcmul</code> 举个例子看看这些函数的实现方法：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> PyObject * <span class="title">THPVariable_addcmul</span><span class="params">(PyObject* self_, PyObject* args, PyObject* kwargs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  HANDLE_TH_ERRORS</span><br><span class="line">  <span class="function"><span class="keyword">static</span> PythonArgParser <span class="title">parser</span><span class="params">(&#123;</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="string">"addcmul(Scalar value, Tensor tensor1, Tensor tensor2)|deprecated"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="string">"addcmul(Tensor tensor1, Tensor tensor2, *, Scalar value=1)"</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">  &#125;, <span class="comment">/*traceable=*/</span><span class="literal">true</span>)</span></span>;</span><br><span class="line">  <span class="comment">/* 获取autograd::Variable实例 */</span></span><br><span class="line">  <span class="keyword">auto</span>&amp; self = <span class="keyword">reinterpret_cast</span>&lt;THPVariable*&gt;(self_)-&gt;cdata;</span><br><span class="line">  <span class="comment">/* 解析函数参数 */</span></span><br><span class="line">  ParsedArgs&lt;<span class="number">4</span>&gt; parsed_args;</span><br><span class="line">  <span class="keyword">auto</span> r = parser.parse(args, kwargs, parsed_args);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 调用 dispatch */</span></span><br><span class="line">  <span class="keyword">if</span> (r.idx == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> wrap(dispatch_addcmul(self, r.scalar(<span class="number">0</span>), r.tensor(<span class="number">1</span>), r.tensor(<span class="number">2</span>)));</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (r.idx == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> wrap(dispatch_addcmul(self, r.tensor(<span class="number">0</span>), r.tensor(<span class="number">1</span>), r.scalar(<span class="number">2</span>)));</span><br><span class="line">  &#125;</span><br><span class="line">  Py_RETURN_NONE;</span><br><span class="line">  END_HANDLE_TH_ERRORS</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终函数调用了 <code>dispatch_addcmul()</code> 进行下一步计算，该函数在同文件夹的 <code>python_variable_methods_dispatch.h</code> ，可见这个文件也是自动生成的，函数声明如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> Tensor <span class="title">dispatch_addcmul</span><span class="params">(Tensor &amp; self, Scalar value, <span class="keyword">const</span> Tensor &amp; tensor1, <span class="keyword">const</span> Tensor &amp; tensor2)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* 释放GIL锁 */</span></span><br><span class="line">  AutoNoGIL no_gil;</span><br><span class="line">  <span class="comment">/* 调用 autograd::Variable.addcmul */</span></span><br><span class="line">  <span class="keyword">return</span> self.addcmul(tensor1, tensor2, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个函数首先获取了GIL锁，然后调用C++前端 <code>Variable.addcmul()</code> 进行计算，由于后者实现了自动微分，所以Python调用也具有自动微分功能。为什么要释放GIL锁？因为这样才能使其与Python解释器中的其他进程一起正确的执行。</p>
<p>也就是说，Python Tensor的方法的封装思路是：</p>
<ul>
<li>生成dispatch系列函数，该函数用于释放GIL锁，然后调用Variable的对应实现</li>
<li>生成可被Python调用的API，该函数解析Python参数，并调用dispatch系列函数进行实际计算</li>
</ul>
<h3><span id="nn">NN</span></h3>
<p>神经网络的部分函数也有部分函数是直接从 ATen 绑定而来，绑定到 <code>torch._C._nn</code> 模块中，代码在 <code>csrc/autograd/generate/python_nn_functions.cpp</code> 中：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> PyMethodDef nn_functions[] = &#123;</span><br><span class="line">  &#123;<span class="string">"_parse_to"</span>, (PyCFunction)THPVariable__parse_to, METH_VARARGS | METH_KEYWORDS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_avg_pool2d"</span>, (PyCFunction)THPVariable_adaptive_avg_pool2d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_avg_pool3d"</span>, (PyCFunction)THPVariable_adaptive_avg_pool3d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_max_pool2d"</span>, (PyCFunction)THPVariable_adaptive_max_pool2d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"adaptive_max_pool3d"</span>, (PyCFunction)THPVariable_adaptive_max_pool3d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"avg_pool2d"</span>, (PyCFunction)THPVariable_avg_pool2d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"avg_pool3d"</span>, (PyCFunction)THPVariable_avg_pool3d, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"binary_cross_entropy"</span>, (PyCFunction)THPVariable_binary_cross_entropy, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"elu"</span>, (PyCFunction)THPVariable_elu, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"elu_"</span>, (PyCFunction)THPVariable_elu_, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> initNNFunctions(PyObject* <span class="keyword">module</span>) &#123;</span><br><span class="line">#<span class="keyword">if</span> PY_MAJOR_VERSION == <span class="number">2</span></span><br><span class="line">  PyObject* nn = Py_InitModule(<span class="string">"torch._C._nn"</span>, nn_functions);</span><br><span class="line">  Py_XINCREF(nn);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  <span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyModuleDef</span> <span class="title">def</span> = &#123;</span></span><br><span class="line">     PyModuleDef_HEAD_INIT,</span><br><span class="line">     <span class="string">"torch._C._nn"</span>,</span><br><span class="line">     <span class="literal">NULL</span>,</span><br><span class="line">     <span class="number">-1</span>,</span><br><span class="line">     nn_functions</span><br><span class="line">  &#125;;</span><br><span class="line">  PyObject* nn = PyModule_Create(&amp;def);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="keyword">if</span> (!nn) &#123;</span><br><span class="line">    <span class="keyword">throw</span> python_error();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (PyModule_AddObject(<span class="keyword">module</span>, <span class="string">"_nn"</span>, nn) != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> python_error();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里面有pooling, loss, conv等相关函数，供Python里的<code>nn.functional</code>调用。</p>
<p>此外，为了方便在Python中自定义的自微分的函数，Python里也实现了上一篇对应的Function：<code>torch.autograd.Function</code>。继承它，重载 <code>forward()</code> 和 <code>backward()</code> 方法就可以用Python实现自定义的自微分函数，详见<a href="https://pytorch.org/docs/stable/notes/extending.html" target="_blank" rel="noopener">文档</a>。</p>
<p><code>torch.autograd.Function</code> 的定义在 <code>torch/autograd/function.py</code> 中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Function</span><span class="params">(with_metaclass<span class="params">(FunctionMeta, _C._FunctionBase, _ContextMethodMixin, _HookMixin)</span>)</span>:</span></span><br><span class="line">    <span class="comment"># only for backward compatibility</span></span><br><span class="line">    __call__ = _C._FunctionBase._do_forward</span><br><span class="line"></span><br><span class="line">    <span class="comment"># for the tracer</span></span><br><span class="line">    is_traceable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(ctx, *args, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(ctx, *grad_outputs)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<p>它继承自 <code>torch._C.FunctionBase</code>，该类型在 <code>csrc/autograd/python_function.cpp</code>中绑定，实现的逻辑和 <code>autograd::Function</code> 一样，也是在前向计算时建立反向计算图，这里就不读赘述了。绑定部分的代码如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">THPFunction</span> &#123;</span></span><br><span class="line">    PyObject_HEAD</span><br><span class="line"></span><br><span class="line">    PyObject *needs_input_grad;</span><br><span class="line">    PyObject *to_save;</span><br><span class="line">    PyObject *non_differentiable;</span><br><span class="line">    PyObject *dirty_tensors;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;torch::autograd::VariableInfo&gt; output_info;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;torch::autograd::VariableInfo&gt; input_info;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;torch::autograd::SavedVariable&gt; saved_variables;</span><br><span class="line">    <span class="comment">// For each input, true if the input is a THPVariable</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt; is_variable_input;</span><br><span class="line">    <span class="keyword">char</span> has_freed_buffers;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* PyFunction继承自Function，实际调用最终转发到Function中 */</span></span><br><span class="line">    torch::autograd::PyFunction cdata;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyGetSetDef</span> <span class="title">THPFunction_properties</span>[] = &#123;</span></span><br><span class="line">  &#123;<span class="string">"saved_tensors"</span>, (getter)THPFunction_saved_tensors, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"saved_variables"</span>, (getter)THPFunction_saved_variables, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="string">"next_functions"</span>, (getter)THPFunction_next_functions, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  ...</span><br><span class="line">  &#123;<span class="literal">nullptr</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">PyMethodDef</span> <span class="title">THPFunction_methods</span>[] = &#123;</span></span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"apply"</span>, (PyCFunction)THPFunction_apply, METH_CLASS | METH_VARARGS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"_do_forward"</span>, (PyCFunction)THPFunction_do_forward, METH_VARARGS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"_do_backward"</span>, (PyCFunction)THPFunction_do_backward, METH_VARARGS, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"_register_hook_dict"</span>, (PyCFunction)THPFunction__register_hook_dict, METH_O, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;(<span class="keyword">char</span>*)<span class="string">"register_hook"</span>, (PyCFunction)THPFunction_register_hook, METH_O, <span class="literal">nullptr</span>&#125;,</span><br><span class="line">  &#123;<span class="literal">nullptr</span>&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">PyTypeObject THPFunctionType = &#123;</span><br><span class="line">  PyVarObject_HEAD_INIT(<span class="literal">nullptr</span>, <span class="number">0</span>)</span><br><span class="line">  <span class="string">"torch._C._FunctionBase"</span>,              <span class="comment">/* tp_name */</span></span><br><span class="line">  <span class="keyword">sizeof</span>(THPFunction),                   <span class="comment">/* tp_basicsize */</span></span><br><span class="line">  <span class="number">0</span>,                                     <span class="comment">/* tp_itemsize */</span></span><br><span class="line">  ...</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">THPFunction_initModule</span><span class="params">(PyObject *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (PyType_Ready(&amp;THPFunctionType) &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  Py_INCREF(&amp;THPFunctionType);</span><br><span class="line">  PyModule_AddObject(<span class="keyword">module</span>, <span class="string">"_FunctionBase"</span>, </span><br><span class="line">                     (PyObject *)&amp;THPFunctionType);</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>总结一下：</p>
<ul>
<li><p><code>THPFunction</code> = <code>_C._FunctionBase</code></p></li>
<li><p>Python的<code>autograd.Function</code>继承自上面实现自动微分</p></li>
</ul>
<p>完</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">上一篇：<a href="https://www.52coding.com.cn/2019/05/05/PyTorch4/">Autograd</a></th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
</tr>
</tbody>
</table>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/C/">C++</a><a href="/tags/PyTorch/">PyTorch</a><a href="/tags/Python扩展/">Python扩展</a>
      </span>
      

    </div>

    
  </div>
</article>

<div class="social-share"></div>
<script type="text/javascript">
  var $config = {
    image: "icon.png",
  };
  socialShare('.social-share-cs', $config);
</script>



<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC80MTI4MC8xNzgyOA==">
	<script type="text/javascript">
		(function (d, s) {
			var j, e = d.getElementsByTagName(s)[0];

			if (typeof LivereTower === 'function') {
				return;
			}

			j = d.createElement(s);
			j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
			j.async = true;

			e.parentNode.insertBefore(j, e);
		})(document, 'script');
	</script>
	<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->


      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2019
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>