<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

  <meta charset="utf-8">
  
  <!-- if (config.subtitle) {
    title.push(config.subtitle);
  } -->
  <title>
    PyTorch源码浅析(4)：Autograd | NIUHE
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE的博客">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:title" content="PyTorch源码浅析(4)：Autograd">
  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script>
  <script type="text/javascript" src="/js/search.js"></script>
  <script type="text/javascript" src="/js/jquery.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれんな</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">博客</a></li>
      
        <li><a href="/notes">笔记</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/search">搜索</a></li>
      
        <li><a href="/about">关于</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        <article>

  
  
  <h3 class="article-title"><span>
      PyTorch源码浅析(4)：Autograd</span></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch4/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:57:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>这篇博客介绍 PyTorch 中自动微分引擎的实现，主要分为三部分：首先简要介绍一下计算图的原理；然后介绍 PyTorch 中与 autograd 的相关数据结构和 <code>backward()</code>函数的实现，数据结构包括 <code>torch::autograd::Variable</code>, <code>torch::autograd::Function</code> 等；最后讲一下动态建立计算图的实现，这部分代码涉及到动态派发机制，而且都是用脚本生成的，不太容易理解。</p>
<a id="more"></a>
<p><strong>目录</strong></p>
<!-- toc -->
<ul>
<li><a href="#计算图简介">计算图简介</a></li>
<li><a href="#autograd-engine">Autograd Engine</a>
<ul>
<li><a href="#variable">Variable</a></li>
<li><a href="#autogradmeta">AutogradMeta</a></li>
<li><a href="#function-edge">Function &amp; Edge</a></li>
<li><a href="#engine">Engine</a></li>
</ul></li>
<li><a href="#动态建立计算图">动态建立计算图</a></li>
</ul>
<!-- tocstop -->
<h2><span id="计算图简介">计算图简介</span></h2>
<p>计算图是一个有向图，它的每个节点都表示一个函数（如加减乘除等）或者输入数据（叶子节点）。计算图的边代表数据流向：指向某个节点的边为该节点的输入，由该节点流出的边表示它的输出。计算图可以用来描述神经网络的计算，如下图描述了 <span class="math inline">\(y = \sin(xa+b)​\)</span> 的计算过程：</p>
<p><img src="/images/pytorch/comp_graph.png"></p>
<p>计算图的求值分为前向传播和反向传播，分别用于计算输出和梯度。前向传播的过程就是从叶子节点开始遍历计算图，直到整个图都被遍历过；而反向传播就是从输出节点开始遍历，节点表示的函数也变为原函数对输入的导数。举个栗子，下面是<code>addcmul()</code>函数的计算图的前向和反向计算过程：</p>
<p><img src="/images/pytorch/forward.gif"></p>
<h2><span id="autograd-engine">Autograd Engine</span></h2>
<p>介绍完了标准的计算图结构，那么PyTorch里面是怎么实现的呢？在回答这个问题之前首先要看几个相关的数据结构，分别是<code>Variable</code>, <code>AutogradMeta</code>, <code>Function</code>和<code>Edge</code>。</p>
<h3><span id="variable">Variable</span></h3>
<p>相信用过老版本的PyTorch的小伙伴对<code>Variable</code>一定不会陌生，它是用来实现自动微分的核心数据结构，代码在<code>torch/csrc/autograd/variable.h</code>。<code>Variable</code>可以表示计算图中的叶子节点，如权重，也可以表示图中的中间变量，虽然在新版本中<code>Tensor</code>与<code>Variable</code>合并了，在前端中可以直接用<code>Tensor</code>代替<code>Variable</code>，但是<code>Variable</code>并没有消失。</p>
<p>它的实现确实改变了，但功能依旧。<code>Variable</code>继承自<code>at::Tensor</code>，重载了<code>Tensor</code>里与梯度计算相关的方法，同时也提供了和<code>Tensor</code>隐式转换的构造函数。</p>
<p><code>Variable</code>的底层实现<code>Variable::Impl</code>也继承<code>at::TensorImpl</code>，这个类在<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/">此系列的第一篇</a>中介绍过，它里面有一个成员<code>bool is_variable</code>，用于识别这个 Tensor 到底是<code>at::Tensor</code>还是<code>Variable</code>。<code>TensorImpl</code>里还有一个重要的成员：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;c10::AutogradMetaInterface&gt; autograd_meta_=<span class="literal">nullptr</span>;</span><br></pre></td></tr></table></figure>
<p><code>autograd_meta_</code>记录了当前与<code>Variable</code>相关的计算图信息，在<code>Variable::Impl</code>里它被强制转换成<code>AutogradMeta*</code>类型：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Variable::<span class="function">AutogradMeta* <span class="title">get_autograd_meta</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;Variable::AutogradMeta*&gt;(autograd_meta());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中<code>AutogradMeta</code>类型实现了<code>c10::AutogradMetaInterface</code>接口。</p>
<h3><span id="autogradmeta">AutogradMeta</span></h3>
<p><code>AutogradMeta</code>的声明也在<code>variable.h</code>中，它的声明如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TORCH_API</span> <span class="title">Variable</span>:</span>:AutogradMeta : <span class="keyword">public</span> c10::AutogradMetaInterface &#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> name;</span><br><span class="line"></span><br><span class="line">  Variable grad_;		<span class="comment">// 存储梯度</span></span><br><span class="line">  <span class="comment">// 反向传播函数 for 中间节点</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Function&gt; grad_fn_;</span><br><span class="line">  <span class="comment">// 反向传播函数 for 叶节点（权重），只是把梯度累加起来用来更新</span></span><br><span class="line">  <span class="built_in">std</span>::weak_ptr&lt;Function&gt; grad_accumulator_;</span><br><span class="line"></span><br><span class="line">  VariableVersion version_counter_;</span><br><span class="line">  <span class="comment">// 预处理</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;FunctionPreHook&gt;&gt; hooks_;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">bool</span> requires_grad_;</span><br><span class="line">  <span class="keyword">bool</span> is_view_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 若该Variable是某个函数的输出，那么output_nr_记录它是第几个输出</span></span><br><span class="line">  <span class="keyword">uint32_t</span> output_nr_;</span><br><span class="line">  PyObject* pyobj_ = <span class="literal">nullptr</span>; <span class="comment">// weak reference</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::mutex mutex_;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_requires_grad</span><span class="params">(<span class="keyword">bool</span> requires_grad, at::TensorImpl* self_impl)</span> override </span>&#123;</span><br><span class="line">    <span class="comment">/* check */</span></span><br><span class="line">    requires_grad_ = requires_grad;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">requires_grad</span><span class="params">()</span> <span class="keyword">const</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> requires_grad_ || grad_fn_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">Variable&amp; <span class="title">grad</span><span class="params">()</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> grad_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">const</span> Variable&amp; <span class="title">grad</span><span class="params">()</span> <span class="keyword">const</span> override </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> grad_;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>从声明中可以看出<code>AutogradMeta</code>不但存储了梯度，还存储了该<code>Variable</code>对应的反向传播函数，也就是计算图的节点。</p>
<p>PyTorch只建立反向传播的计算图，因为其实前向传播是用户自己定义的，不用PyTorch干什么。但是在用户在定义前向连接的时候，PyTorch需要偷偷建立反向连接，具体怎么操作见下一节。PyTorch里计算图的节点全部都是<code>Function</code>，由于只计算图只用于反向传播，所以 <code>Function</code> 实现都是反向传播函数。对于计算图中的中间结果，对应的<code>grad_fn_</code>是相应的反向传播函数；而对于叶节点（权重），对应的<code>grad_fn_</code>为<code>nullptr</code>，而<code>grad_accumulator_</code>为其相应的处理函数，就是把梯度累加存储到<code>grad_</code>里。除此之外，不需要梯度的输入是不会进入计算图中的。</p>
<p>仔细观察我们会发现，<code>Variable</code>里拥有<code>AutogradMeta</code>，而后者里用有<code>Function</code>，所以实际上<code>Variable</code>和它的<code>grad_fn_</code>是绑定的，也就是说，一个<code>Variable</code>只能有一个<code>grad_fn_</code>，但反过来则不一定，一个<code>grad_fn_</code>也可能属于多个<code>Variable</code>（如果正向传播函数输出很多的话，那么这些输出共享一个反向传播函数）。</p>
<h3><span id="function-amp-edge">Function &amp; Edge</span></h3>
<p><code>Function</code>和<code>Edge</code>实现是紧密相连的，<code>Function</code>本质是一个函数对象，可以当作反向传播的函数来用。除此之外，<code>Function</code>里还有一个成 <code>edge_list next_edges_;</code>，是与该节点相连的边。PyTorch的计算图中的边其实就是<code>{function, input_nr}</code>pair：前者表示这条边指向哪个节点，后者表示本节点是目标节点的第几个输入（从0开始）。</p>
<p><code>Function</code>的实现在<code>csrc/autograd/function.h</code>，大致声明如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TORCH_API</span> <span class="title">Function</span> :</span> <span class="built_in">std</span>::enable_shared_from_this&lt;Function&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">/* 构造函数略 */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 不可拷贝或移动</span></span><br><span class="line">  Function(<span class="keyword">const</span> Function&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  Function(Function&amp;&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  Function&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Function&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  Function&amp; <span class="keyword">operator</span>=(Function&amp;&amp; other) = <span class="keyword">delete</span>;</span><br><span class="line">  <span class="keyword">virtual</span> ~Function() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 重载()运算符实现函数对象功能，需重载apply函数</span></span><br><span class="line">  <span class="comment">// 该函数接收一系列variable，返回一系列variable</span></span><br><span class="line">  <span class="function">variable_list <span class="title">operator</span><span class="params">()</span><span class="params">(variable_list&amp;&amp; inputs)</span> </span>&#123;</span><br><span class="line">    profiler::<span class="function">RecordFunction <span class="title">rec</span><span class="params">(<span class="keyword">this</span>)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> apply(<span class="built_in">std</span>::move(inputs));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 有关计算图的 API</span></span><br><span class="line">  <span class="comment">//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">const</span> Edge&amp; <span class="title">next_edge</span><span class="params">(<span class="keyword">size_t</span> index)</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_[index];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_next_edge</span><span class="params">(<span class="keyword">size_t</span> index, Edge edge)</span> </span>&#123;</span><br><span class="line">    next_edges_[index] = <span class="built_in">std</span>::move(edge);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">add_next_edge</span><span class="params">(Edge edge)</span> </span>&#123;</span><br><span class="line">    next_edges_.push_back(<span class="built_in">std</span>::move(edge));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_next_edges</span><span class="params">(edge_list&amp;&amp; next_edges)</span> </span>&#123;</span><br><span class="line">    next_edges_ = <span class="built_in">std</span>::move(next_edges);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">const</span> edge_list&amp; <span class="title">next_edges</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">edge_list&amp; <span class="title">next_edges</span><span class="params">()</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">uint32_t</span> num_outputs() <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> next_edges_.size();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="function"><span class="keyword">static</span> uint64_t&amp; <span class="title">get_next_sequence_nr</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 需要重载的apply函数，实现实际功能</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> variable_list <span class="title">apply</span><span class="params">(variable_list&amp;&amp; inputs)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">variable_list <span class="title">traced_apply</span><span class="params">(variable_list inputs)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 函数序列号</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">uint64_t</span> sequence_nr_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 保存邻边</span></span><br><span class="line">  edge_list next_edges_;</span><br><span class="line">  PyObject* pyobj_ = <span class="literal">nullptr</span>; <span class="comment">// weak reference</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;AnomalyMetadata&gt; anomaly_metadata_ = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;FunctionPreHook&gt;&gt; pre_hooks_;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;FunctionPostHook&gt;&gt; post_hooks_;</span><br><span class="line">  at::SmallVector&lt;InputMetadata, <span class="number">2</span>&gt; input_metadata_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><code>Edge</code>的声明在<code>csrc/autograd/edge.h</code>，它的声明就很简单了：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Edge</span> &#123;</span></span><br><span class="line">  Edge() <span class="keyword">noexcept</span> : function(<span class="literal">nullptr</span>), input_nr(<span class="number">0</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  Edge(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Function&gt; function_, <span class="keyword">uint32_t</span> input_nr_) <span class="keyword">noexcept</span></span><br><span class="line">      : function(<span class="built_in">std</span>::move(function_)), input_nr(input_nr_) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Convenience method to test if an edge is valid.</span></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">is_valid</span><span class="params">()</span> <span class="keyword">const</span> <span class="keyword">noexcept</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> function != <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Required for use in associative containers.</span></span><br><span class="line">  <span class="keyword">bool</span> <span class="keyword">operator</span>==(<span class="keyword">const</span> Edge&amp; other) <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>-&gt;function == other.function &amp;&amp; <span class="keyword">this</span>-&gt;input_nr == other.input_nr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">bool</span> <span class="keyword">operator</span>!=(<span class="keyword">const</span> Edge&amp; other) <span class="keyword">const</span> <span class="keyword">noexcept</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> !(*<span class="keyword">this</span> == other);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 目标函数</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Function&gt; function;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 第几个输入</span></span><br><span class="line">  <span class="keyword">uint32_t</span> input_nr;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>总结一下，<code>Variable</code>，<code>AutogradMeta</code>，<code>Function</code>和<code>Edge</code>的大致关系如下图所示：</p>
<p><img src="/images/pytorch/Variable.svg"></p>
<h3><span id="engine">Engine</span></h3>
<p>我们先不看怎么建立计算图，而是先假设图已经建立好，考虑具体怎么执行反向传播。你可能觉得答案已经很明显了，不就是对图进行遍历么，没错，是对图进行遍历，但考虑到效率以及要在不同设备上计算，实际操作起来还是有点麻烦的，这部分代码主要由<code>autograd::Engine</code>实现，声明和实现分别在<code>csrc/autograd/engine.h</code>和<code>csrc/autograd/engine.cpp</code>中。</p>
<p>用 PyTorch 建立神经网络的时候，相信你一定用过<code>loss.backward()</code>来进行反向传播，那就从<code>Variable::backward()</code>函数开始一步一步看反向传播是怎么执行的：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> Variable::backward(</span><br><span class="line">    c10::optional&lt;Tensor&gt; gradient,</span><br><span class="line">    <span class="keyword">bool</span> keep_graph,</span><br><span class="line">    <span class="keyword">bool</span> create_graph) <span class="keyword">const</span> &#123;</span><br><span class="line">  <span class="comment">// 获取 AutogradMeta</span></span><br><span class="line">  <span class="keyword">auto</span> autograd_meta = get_autograd_meta();</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 构造起始边，做为遍历的起点（图的root）</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Edge&gt; edges;</span><br><span class="line">  edges.emplace_back(autograd_meta-&gt;grad_fn_, autograd_meta-&gt;output_nr_);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造输入：variable list</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Variable&gt; inputs;</span><br><span class="line">  inputs.push_back(<span class="built_in">std</span>::move(as_variable_ref(*gradient)));</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 调用 execute 进行反向传播</span></span><br><span class="line">  Engine::get_default_engine().execute(edges, inputs, keep_graph, create_graph);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>函数首先构造遍历的起点和输入，然后调用<code>Engine::execute()</code>进行计算，其中<code>Engine::get_default_engine()</code>返回的是<code>Engine</code>的实例。</p>
<p>接着研究<code>Engine::execute()</code>：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::execute(<span class="keyword">const</span> edge_list&amp; roots,</span><br><span class="line">                     <span class="keyword">const</span> variable_list&amp; inputs,</span><br><span class="line">                     <span class="keyword">bool</span> keep_graph,</span><br><span class="line">                     <span class="keyword">bool</span> create_graph,</span><br><span class="line">                     <span class="keyword">const</span> edge_list&amp; outputs) -&gt; variable_list &#123;</span><br><span class="line">  <span class="comment">// 启动多线程（每个设备一个线程）</span></span><br><span class="line">  <span class="built_in">std</span>::call_once(start_threads_flag, &amp;Engine::start_threads, <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 验证outputs */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 记录计算图的任务</span></span><br><span class="line">  <span class="function">GraphTask <span class="title">graph_task</span><span class="params">(keep_graph, create_graph)</span></span>;</span><br><span class="line">  <span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; lock(graph_task.mutex);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遍历一遍计算图，计算每个函数的依赖</span></span><br><span class="line">  <span class="comment">// 所谓某函数的依赖就是有几条边指向该函数，用图的术语说就是节点的入度</span></span><br><span class="line">  <span class="comment">// 依赖大于零（入度&gt;0）的节点不能够执行</span></span><br><span class="line">  <span class="keyword">auto</span> graph_root = <span class="built_in">std</span>::make_shared&lt;GraphRoot&gt;(roots, inputs);</span><br><span class="line">  compute_dependencies(graph_root.get(), graph_task);</span><br><span class="line">  <span class="keyword">if</span> (!outputs.empty()) &#123;</span><br><span class="line">    graph_task.init_to_execute(*graph_root, outputs);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 把root加入准备队列，每个设备有一个准备队列，-1代表CPU</span></span><br><span class="line">  ready_queue(<span class="number">-1</span>).push(FunctionTask(&amp;graph_task, <span class="built_in">std</span>::move(graph_root), InputBuffer(<span class="number">0</span>)));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (worker_device == NO_DEVICE) &#123;</span><br><span class="line">    <span class="comment">// 非工作线程：老老实实等待图计算完毕</span></span><br><span class="line">    graph_task.not_done.wait(lock, [&amp;graph_task]&#123;</span><br><span class="line">      <span class="keyword">return</span> graph_task.outstanding_tasks.load() == <span class="number">0</span>;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 工作线程：996!</span></span><br><span class="line">    graph_task.owner = worker_device;</span><br><span class="line">    lock.unlock();</span><br><span class="line">    <span class="comment">// 线程主循环</span></span><br><span class="line">    thread_main(&amp;graph_task);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* check exceptions */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> graph_task.captured_vars;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>Engine::execute()</code>里做了这几件事（可以把它想象成一个公司）：</p>
<ul>
<li>招聘员工（启动多线程）</li>
<li>明确整体任务（计算依赖）</li>
<li>准备第一份工作（把<code>root</code>加入准备队列）</li>
<li>开始工作！</li>
</ul>
<p>首先看启动多线程的代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::start_threads() -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">// 获取GPU数目</span></span><br><span class="line">  <span class="keyword">int</span> num_devices = at::getNumGPUs();</span><br><span class="line">  <span class="comment">// 线程数 = GPU数 + 1 (for CPU)</span></span><br><span class="line">  <span class="keyword">int</span> num_threads = num_devices + <span class="number">1</span>;</span><br><span class="line">  ready_queues = <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;ReadyQueue&gt;&gt;(num_threads);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; <span class="built_in">queue</span> : ready_queues)</span><br><span class="line">    <span class="comment">// 初始化每个设备的准备队列</span></span><br><span class="line">    <span class="built_in">queue</span>.reset(<span class="keyword">new</span> ReadyQueue());</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_threads; ++i) &#123;</span><br><span class="line">    <span class="comment">// 赋予每个线程对应的 device，然后进入 thread_main()</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="function">thread <span class="title">t</span><span class="params">(&amp;Engine::thread_init, <span class="keyword">this</span>, i - <span class="number">1</span>)</span></span>;</span><br><span class="line">    t.detach();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来看如何计算依赖：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::compute_dependencies(Function* root, GraphTask&amp; task) -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">// 记录已访问过节点</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_set</span>&lt;Function*&gt; seen;</span><br><span class="line">  <span class="comment">// 节点队列，用于BFS</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Function*&gt; <span class="built_in">queue</span> &#123; root &#125;;</span><br><span class="line">	<span class="comment">// 记录依赖的数据结构，类型为 unordered_map&lt;Function*, int&gt;</span></span><br><span class="line">  <span class="keyword">auto</span>&amp; dependencies = task.dependencies;</span><br><span class="line">  <span class="comment">// BFS</span></span><br><span class="line">  <span class="keyword">while</span> (!<span class="built_in">queue</span>.empty()) &#123;</span><br><span class="line">    <span class="keyword">auto</span> fn = <span class="built_in">queue</span>.back(); <span class="built_in">queue</span>.pop_back();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; edge : fn-&gt;next_edges()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">auto</span> next_ptr = edge.function.get()) &#123;</span><br><span class="line">        <span class="comment">// 目标节点的依赖+1</span></span><br><span class="line">        dependencies[next_ptr] += <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">bool</span> was_inserted = seen.insert(next_ptr).second;</span><br><span class="line">        <span class="keyword">if</span> (was_inserted) <span class="built_in">queue</span>.push_back(next_ptr);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后来看最主要的<code>thread_main()</code>：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::thread_main(GraphTask *graph_task) -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">// 获取当前进程的准备队列</span></span><br><span class="line">  <span class="keyword">auto</span> <span class="built_in">queue</span> = ready_queues[worker_device + <span class="number">1</span>];</span><br><span class="line">  <span class="comment">// 工作没完成之前不能下班：</span></span><br><span class="line">  <span class="keyword">while</span> (!graph_task || graph_task-&gt;outstanding_tasks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 获取最新工作，pop()是阻塞的，只有来工作了才会继续执行</span></span><br><span class="line">    <span class="comment">// 生产者消费者模型</span></span><br><span class="line">    FunctionTask task = <span class="built_in">queue</span>-&gt;pop();</span><br><span class="line">    <span class="keyword">if</span> (task.fn &amp;&amp; !task.base-&gt;has_error.load()) &#123;</span><br><span class="line">      GradMode::set_enabled(task.base-&gt;grad_mode);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 执行该任务</span></span><br><span class="line">        evaluate_function(task);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (<span class="built_in">std</span>::exception&amp; e) &#123;</span><br><span class="line">        thread_on_exception(task, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 找到发布任务的人</span></span><br><span class="line">    <span class="keyword">auto</span> base_owner = task.base-&gt;owner;</span><br><span class="line">    <span class="comment">// 若该任务来自非工作线程（i.e.s 领导线程，发号施令）：</span></span><br><span class="line">    <span class="keyword">if</span> (base_owner == NO_DEVICE) &#123;</span><br><span class="line">      <span class="comment">// 自减剩余任务数</span></span><br><span class="line">      <span class="keyword">if</span> (--task.base-&gt;outstanding_tasks == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 所有任务完毕，通知大伙下班</span></span><br><span class="line">        <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(task.base-&gt;mutex);</span><br><span class="line">        task.base-&gt;not_done.notify_all();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 如果任务发布者是自己：</span></span><br><span class="line">      <span class="keyword">if</span> (base_owner == worker_device) &#123;</span><br><span class="line">        <span class="comment">// 自减剩余任务数</span></span><br><span class="line">        --task.base-&gt;outstanding_tasks;</span><br><span class="line">      <span class="comment">// 如果任务发布自其他工人：</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (base_owner != worker_device) &#123;</span><br><span class="line">        <span class="comment">// 自减剩余任务数</span></span><br><span class="line">        <span class="keyword">if</span> (--task.base-&gt;outstanding_tasks == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="comment">// 提醒他们那个任务做完了</span></span><br><span class="line">          <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_release);</span><br><span class="line">          ready_queue(base_owner).push(FunctionTask(task.base, <span class="literal">nullptr</span>, InputBuffer(<span class="number">0</span>)));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>thread_main()</code>里没有具体执行任务的代码，而是把它单独抽出变成一个方法，下面看该方法都干了什么：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> Engine::evaluate_function(FunctionTask&amp; task) -&gt; <span class="keyword">void</span> &#123;</span><br><span class="line">  <span class="comment">/* exec info blabla... */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 调用 task 里的函数获取输出，基本相当于 (*task.fn)()</span></span><br><span class="line">  <span class="keyword">auto</span> outputs = call_function(task);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span>&amp; fn = *task.fn;</span><br><span class="line">  <span class="comment">// 如果不保留图的话就把当前节点释放了</span></span><br><span class="line">  <span class="keyword">if</span> (!task.base-&gt;keep_graph) &#123;</span><br><span class="line">    fn.release_variables();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取输出个数</span></span><br><span class="line">  <span class="keyword">int</span> num_outputs = outputs.size();</span><br><span class="line">  <span class="comment">// 如果没有输出这个任务就完成了，直接返回</span></span><br><span class="line">  <span class="keyword">if</span> (num_outputs == <span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; lock(task.base-&gt;mutex);</span><br><span class="line">  <span class="comment">// 遍历每个输出（遍历与之相邻的节点）：</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_outputs; ++i) &#123;</span><br><span class="line">    <span class="keyword">auto</span>&amp; output = outputs[i];</span><br><span class="line">    <span class="comment">// 获取第i条边（指向第i个输出所对应的函数）</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span>&amp; next = fn.next_edge(i);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!next.is_valid()) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查这条边是否准备好（依赖是否为0）</span></span><br><span class="line">    <span class="keyword">bool</span> is_ready = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">auto</span>&amp; dependencies = task.base-&gt;dependencies;</span><br><span class="line">    <span class="comment">// 获取这条边的依赖数</span></span><br><span class="line">    <span class="keyword">auto</span> it = dependencies.find(next.function.get());</span><br><span class="line">    <span class="keyword">if</span> (it == dependencies.end()) &#123;</span><br><span class="line">      <span class="comment">/* 没找到，抛出异常 */</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (--it-&gt;second == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 依赖自减后等于零，说明该任务已准备好</span></span><br><span class="line">      dependencies.erase(it);</span><br><span class="line">      is_ready = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取/创建该节点的 input_buffer</span></span><br><span class="line">    <span class="keyword">auto</span>&amp; not_ready = task.base-&gt;not_ready;</span><br><span class="line">    <span class="keyword">auto</span> not_ready_it = not_ready.find(next.function.get());</span><br><span class="line">    <span class="comment">// 还没有为该节点分配 input_buffer:</span></span><br><span class="line">    <span class="keyword">if</span> (not_ready_it == not_ready.end()) &#123;</span><br><span class="line">      <span class="comment">/* 跳过那些不该被执行的函数 */</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment">// 用 output 构造该节点的 input_buffer</span></span><br><span class="line">      <span class="function">InputBuffer <span class="title">input_buffer</span><span class="params">(next.function-&gt;num_inputs())</span></span>;</span><br><span class="line">      input_buffer.add(next.input_nr, <span class="built_in">std</span>::move(output));</span><br><span class="line">      <span class="keyword">if</span> (is_ready) &#123;</span><br><span class="line">        <span class="comment">// 准备好就加入准备队列</span></span><br><span class="line">        <span class="keyword">auto</span>&amp; <span class="built_in">queue</span> = ready_queue(input_buffer.device());</span><br><span class="line">        <span class="built_in">queue</span>.push(FunctionTask(task.base, next.function, <span class="built_in">std</span>::move(input_buffer)));</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 没准备好就缓存 input_buffer</span></span><br><span class="line">        not_ready.emplace(next.function.get(), <span class="built_in">std</span>::move(input_buffer));</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">// 该节点已有 input_buffer:</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 向已有 input_buffer 里添加新的输入</span></span><br><span class="line">      <span class="keyword">auto</span> &amp;input_buffer = not_ready_it-&gt;second;</span><br><span class="line">      input_buffer.add(next.input_nr, <span class="built_in">std</span>::move(output));</span><br><span class="line">      <span class="keyword">if</span> (is_ready) &#123;</span><br><span class="line">        <span class="comment">// 准备好就加入准备队列</span></span><br><span class="line">        <span class="keyword">auto</span>&amp; <span class="built_in">queue</span> = ready_queue(input_buffer.device());</span><br><span class="line">        <span class="built_in">queue</span>.push(FunctionTask(task.base, next.function, <span class="built_in">std</span>::move(input_buffer)));</span><br><span class="line">        <span class="comment">// 从输入缓存里删除该节点</span></span><br><span class="line">        not_ready.erase(not_ready_it);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>好，至此执行计算图的代码就梳理完了，简单总结一下：</p>
<ul>
<li>把调用<code>backward()</code>的节点设为根节点，从该节点开始遍历</li>
<li>首先BFS一遍计算图，计算每个节点的依赖</li>
<li>为每个设备建立一个工作线程，每个线程里有一个准备队列
<ul>
<li>每个线程等待任务到来直到任务全部完成</li>
<li>完成一个任务后遍历与之相邻的节点，更新他们的依赖(-1)，若依赖为0则加入准备队列</li>
</ul></li>
</ul>
<h2><span id="动态建立计算图">动态建立计算图</span></h2>
<p>这一小节介绍 PyTorch 是怎么建立用于反向传播的计算图的。根据前面的分析，计算图一定是在定义前向传播是建立的，那么机密一定是藏在前向传播API里了，这个猜想是没错，但是由于 ATen 复杂的动态派发机制以及使用脚本生成代码，我也是费了九牛二虎之力才找到具体实现以及理解其中的逻辑。</p>
<p>神经网络的具体计算：每一层的前向和反向传播，其实都是在 ATen 里实现的，但回去看 ATen 的API实现，并没有发现其中有任何建立计算图的代码。这其中的机密实际在<code>tools/autograd</code>目录里。这个目录里有<code>derivatives.yaml</code>和用于生成代码的脚本，前者记录了所有需要自动微分的ATen API，后者为它们生成一层wrapper代码，这些代码主要干两件事：</p>
<ul>
<li>把ATen的反向传播API转换成<code>Function</code></li>
<li>在ATen的正向传播API中加入建图过程</li>
</ul>
<p>举个例子，<code>derivatives.yaml</code>第119行的<code>addcmul()</code>API：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">addcmul(Tensor</span> <span class="string">self,</span> <span class="string">Tensor</span> <span class="string">tensor1,</span> <span class="string">Tensor</span> <span class="string">tensor2,</span> <span class="string">*,</span> <span class="string">Scalar</span> <span class="string">value)</span></span><br><span class="line"><span class="attr">  self:</span> <span class="string">grad</span></span><br><span class="line"><span class="attr">  tensor1:</span> <span class="string">grad</span> <span class="string">*</span> <span class="string">tensor2</span> <span class="string">*</span> <span class="string">value</span></span><br><span class="line"><span class="attr">  tensor2:</span> <span class="string">grad</span> <span class="string">*</span> <span class="string">tensor1</span> <span class="string">*</span> <span class="string">value</span></span><br></pre></td></tr></table></figure>
<p>这里指明了函数名、参数、反向计算方法。执行<code>gen_autograd.py</code>可以自动为其生成代码，生成的代码在<code>torch/csrc/autograd/generated</code>中，有 <code>addcmul()</code>的前向传播的代码在<code>VariableType0.cpp</code>中， 反向传播的代码在<code>Functions.h</code>和<code>Functionss.cpp</code>中。</p>
<p><strong>前向传播</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Tensor VariableType::addcmul(<span class="keyword">const</span> Tensor &amp; self, <span class="keyword">const</span> Tensor &amp; tensor1, <span class="keyword">const</span> Tensor &amp; tensor2, Scalar value) <span class="keyword">const</span> </span><br><span class="line">&#123;</span><br><span class="line">  profiler::<span class="function">RecordFunction <span class="title">profiler</span><span class="params">(<span class="string">"addcmul"</span>, Function::peek_at_next_sequence_nr())</span></span>;</span><br><span class="line">  <span class="comment">// 获取输入</span></span><br><span class="line">  <span class="keyword">auto</span>&amp; self_ = unpack(self, <span class="string">"self"</span>, <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">auto</span>&amp; tensor1_ = unpack(tensor1, <span class="string">"tensor1"</span>, <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span>&amp; tensor2_ = unpack(tensor2, <span class="string">"tensor2"</span>, <span class="number">2</span>);</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;AddcmulBackward&gt; grad_fn;</span><br><span class="line">  <span class="keyword">if</span> (compute_requires_grad( self, tensor1, tensor2 )) &#123;</span><br><span class="line">    <span class="comment">// 建立反向传播节点 AddcmulBackward</span></span><br><span class="line">    grad_fn = <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;AddcmulBackward&gt;(<span class="keyword">new</span> AddcmulBackward(), deleteFunction);</span><br><span class="line">    <span class="comment">// 新建边指向与 self, tensor1, tensor2 绑定的节点</span></span><br><span class="line">    grad_fn-&gt;set_next_edges(collect_next_edges(self, tensor1, </span><br><span class="line">                                               tensor2));</span><br><span class="line">    <span class="keyword">if</span> (grad_fn-&gt;should_compute_output(<span class="number">1</span>)) &#123;</span><br><span class="line">      grad_fn-&gt;tensor2_ = SavedVariable(tensor2, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    grad_fn-&gt;value = value;</span><br><span class="line">    <span class="keyword">if</span> (grad_fn-&gt;should_compute_output(<span class="number">2</span>)) &#123;</span><br><span class="line">      grad_fn-&gt;tensor1_ = SavedVariable(tensor1, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 调用 ATen API 进行实际计算</span></span><br><span class="line">  <span class="keyword">auto</span> tmp = ([&amp;]() &#123;</span><br><span class="line">    at::AutoNonVariableTypeMode non_var_type_mode(<span class="literal">true</span>);</span><br><span class="line">    <span class="keyword">return</span> baseType-&gt;addcmul(self_, tensor1_, tensor2_, value);</span><br><span class="line">  &#125;)();</span><br><span class="line">  <span class="keyword">auto</span> result = as_variable(tmp);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 把 grad_fn 与输出绑定</span></span><br><span class="line">  set_history(flatten_tensor_args(result), grad_fn);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个函数是前向计算的API，在具体计算之前先建立反向传播函数（节点），并且把该节点与<strong>输入</strong>的节点相连；然后调用下层API计算结果；最后把结果和新建立的节点绑定，这样用于反向传播的计算图就建立完成了。由于这是反向传播计算图，所以前向传播中的输入节点变成反向的输出，前向的输出节点变成反向的输入，如下图所示。</p>
<p><img src="/images/pytorch/addcmul.png"></p>
<p><strong>反向传播</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 声明在 Functions.h</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">AddcmulBackward</span> :</span> <span class="keyword">public</span> TraceableFunction &#123;</span><br><span class="line">  <span class="keyword">using</span> TraceableFunction::TraceableFunction;</span><br><span class="line">  <span class="function">variable_list <span class="title">apply</span><span class="params">(variable_list&amp;&amp; grads)</span> override</span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">name</span><span class="params">()</span> <span class="keyword">const</span> override </span>&#123; <span class="keyword">return</span> <span class="string">"AddcmulBackward"</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">release_variables</span><span class="params">()</span> override </span>&#123;</span><br><span class="line">    tensor2_.reset_data();</span><br><span class="line">    tensor2_.reset_grad_function();</span><br><span class="line">    tensor1_.reset_data();</span><br><span class="line">    tensor1_.reset_grad_function();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  SavedVariable tensor2_;</span><br><span class="line">  Scalar value;</span><br><span class="line">  SavedVariable tensor1_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现在 Functions.cpp</span></span><br><span class="line"><span class="comment">// 重载 Function::apply 实现梯度计算</span></span><br><span class="line">variable_list AddcmulBackward::apply(variable_list&amp;&amp; grads) &#123;</span><br><span class="line">  IndexRangeGenerator gen;</span><br><span class="line">  <span class="keyword">auto</span> self_ix = gen.range(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span> tensor1_ix = gen.range(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span> tensor2_ix = gen.range(<span class="number">1</span>);</span><br><span class="line">  <span class="function">variable_list <span class="title">grad_inputs</span><span class="params">(gen.size())</span></span>;</span><br><span class="line">  <span class="keyword">auto</span>&amp; grad = grads[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">auto</span> tensor2 = tensor2_.unpack();</span><br><span class="line">  <span class="keyword">auto</span> tensor1 = tensor1_.unpack();</span><br><span class="line">  <span class="comment">// 计算梯度，与 derivatives.yaml 中的定义相同</span></span><br><span class="line">  <span class="keyword">if</span> (should_compute_output(&#123; self_ix &#125;)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> grad_result = grad;</span><br><span class="line">    copy_range(grad_inputs, self_ix, grad_result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (should_compute_output(&#123; tensor1_ix &#125;)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> grad_result = grad * tensor2 * value;</span><br><span class="line">    copy_range(grad_inputs, tensor1_ix, grad_result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (should_compute_output(&#123; tensor2_ix &#125;)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> grad_result = grad * tensor1 * value;</span><br><span class="line">    copy_range(grad_inputs, tensor2_ix, grad_result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> grad_inputs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到这些代码确确实实把 ATen API 转换成了计算图节点<code>Function</code>。</p>
<p><strong>动态派发</strong></p>
<p>最后还有一个问题就是代码中调用的API是<code>torch.addcmul()</code>或<code>variable.addcmul()</code>怎么就会执行到上面的<code>VariableType::addcmul()</code>呢？这就要归功于 ATen 的动态派发了，以第二种调用举例分析一下，也就是通过一个<code>Variable</code>类型变量调用<code>addcmul()</code>。</p>
<p>首先，上一篇说过，ATen 的API都记录在<code>ATen/native/native_functions.yaml</code>里，这些API如果有生成 method 的需求的话，会把声明通过脚本自动添加 <code>at::Tensor</code>类里，这样就可以通过<code>tensor.addcmul()</code>调用该API，而<code>Variable</code>继承自<code>at::Tensor</code>，自然也就拥有了该方法。</p>
<p>但这还没完，如果查看这个方法的实现会发现：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> Tensor Tensor::addcmul(<span class="keyword">const</span> Tensor &amp; tensor1, <span class="keyword">const</span> Tensor &amp; tensor2, Scalar value) <span class="keyword">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> type().addcmul(*<span class="keyword">this</span>, tensor1, tensor2, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它调用了<code>type()</code>的相应方法，这个<code>type()</code>返回的是<code>Type</code>类型的实例。<code>Type</code>类型同样声明了所有 ATen API，并且有<code>TensorType</code> <code>VariableType</code>继承自它。根据ATen的动态派发机制，如果调用者是<code>Tensor</code>的话，并且<code>is_variable == False</code>，就会返回<code>TensorType</code>实例；如果调用者是<code>Variable</code>的话，或者<code>is_variable == True</code>，就会返回上述的<code>VariableType</code>实例。所以一个<code>Variable</code>类型的变量调用<code>addcmul()</code>的话实际会执行<code>VariableType::addcmul()</code>。</p>
<p>つづく</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">上一篇：<a href="https://www.52coding.com.cn/2019/05/05/PyTorch3/">NN</a></th>
<th style="text-align: right;">下一篇：<a href="https://www.52coding.com.cn/2019/05/05/PyTorch5/">Python扩展</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
</tr>
</tbody>
</table>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/PyTorch/">PyTorch</a><a href="/tags/Autograd/">Autograd</a><a href="/tags/自动微分引擎/">自动微分引擎</a><a href="/tags/Variable/">Variable</a>
      </span>
      

    </div>

    
  </div>
</article>

<div class="social-share"></div>
<script type="text/javascript">
  var $config = {
    image: "icon.png",
  };
  socialShare('.social-share-cs', $config);
</script>



<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC80MTI4MC8xNzgyOA==">
	<script type="text/javascript">
		(function (d, s) {
			var j, e = d.getElementsByTagName(s)[0];

			if (typeof LivereTower === 'function') {
				return;
			}

			j = d.createElement(s);
			j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
			j.async = true;

			e.parentNode.insertBefore(j, e);
		})(document, 'script');
	</script>
	<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->


      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2019
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>