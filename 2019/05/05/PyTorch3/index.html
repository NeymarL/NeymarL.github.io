<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

  <meta charset="utf-8">
  
  <!-- if (config.subtitle) {
    title.push(config.subtitle);
  } -->
  <title>
    PyTorch源码浅析(3)：NN | NIUHE
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE的博客">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:title" content="PyTorch源码浅析(3)：NN">
  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script>
  <script type="text/javascript" src="/js/search.js"></script>
  <script type="text/javascript" src="/js/jquery.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれんな</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">博客</a></li>
      
        <li><a href="/notes">笔记</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/search">搜索</a></li>
      
        <li><a href="/about">关于</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        <article>

  
  
  <h3 class="article-title"><span>
      PyTorch源码浅析(3)：NN</span></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2019/05/05/PyTorch3/" rel="bookmark">
        <time class="entry-date published" datetime="2019-05-05T07:55:01.000Z">
          2019-05-05
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>THNN是一个用C语言实现的神经网络模块的库，提供的功能非常底层。它实现了许多基础的神经网络模块，包括线性层，卷积层，Sigmoid等各种激活层，一些基本的loss函数，这些API都声明在<code>THNN/generic/THNN.h</code>中。每个模块都实现了前向传导（forward）和后向传导（backward）的功能。THCUNN则是对应模块的CUDA实现。</p>
<a id="more"></a>
<p><strong>目录</strong></p>
<!-- toc -->
<ul>
<li><a href="#thnn-thcunn">THNN &amp; THCUNN</a>
<ul>
<li><a href="#tanh">Tanh</a></li>
<li><a href="#2d-convolution">2D Convolution</a>
<ul>
<li><a href="#前向传播">前向传播</a></li>
<li><a href="#反向传播">反向传播</a></li>
</ul></li>
</ul></li>
<li><a href="#aten">ATen</a></li>
</ul>
<!-- tocstop -->
<h2><span id="thnn-amp-thcunn">THNN &amp; THCUNN</span></h2>
<p>我们通过几个例子具体看一下几种模块是怎么实现的。</p>
<h3><span id="tanh">Tanh</span></h3>
<p>首先从最简单的激活层开始看，以 <span class="math inline">\(\tanh​\)</span> 为代表，代码在<code>THNN/generic/Tanh.c</code>。这个模块只有两个函数，分别是<code>THNN_(Tanh_updateOutput)()</code>和<code>THNN_(Tanh_updateGradInput)()</code>，其中前者实现了前向传播，后者实现了反向传播。注意到函数的命名方式，依旧是使用宏实现范式，<code>THNN_</code>是宏定义，<code>Tanh_</code>是具体模块名，<code>updateOutput</code>表示前向传播，<code>updateGradInput</code>表示反向传播，与之前不同的是，这里只需生成浮点类型（<code>float</code>和<code>double</code>）的实现即可。</p>
<p>前向传播的实现很简单，直接调用之前实现的tanh函数就行了：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(Tanh_updateOutput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">          THNNState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *output)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THTensor_(<span class="built_in">tanh</span>)(output, input);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它有三个参数，分别是THNN状态（暂不知有何用），本层的输入（<code>input</code>）和本层的输出（<code>output</code>），输出存储在<code>output</code>参数中。</p>
<p>反向传播的实现为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(Tanh_updateGradInput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">          THNNState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *gradOutput,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *gradInput,</span></span></span><br><span class="line"><span class="function"><span class="params">          THTensor *output)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  THNN_CHECK_SHAPE(output, gradOutput);</span><br><span class="line">  THTensor_(resizeAs)(gradInput, output);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="comment">/* output, gradInput, 和 gradOutput 的内存是连续的 */</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    TH_TENSOR_APPLY3(<span class="keyword">scalar_t</span>, gradInput, <span class="keyword">scalar_t</span>, gradOutput,</span><br><span class="line">                     <span class="keyword">scalar_t</span>, output,</span><br><span class="line">      <span class="keyword">scalar_t</span> z = *output_data;            \</span><br><span class="line">      *gradInput_data = *gradOutput_data * (<span class="number">1.</span> - z*z);</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">scalar_t</span>* ptr_gradOutput = gradOutput-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;();</span><br><span class="line">    <span class="keyword">scalar_t</span>* ptr_gradInput  = gradInput-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;();</span><br><span class="line">    <span class="keyword">scalar_t</span>* ptr_output     = output-&gt;data&lt;<span class="keyword">scalar_t</span>&gt;();</span><br><span class="line">    <span class="keyword">int64_t</span> i;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for private(i)</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; THTensor_(nElement)(gradInput); i++)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">scalar_t</span> z = ptr_output[i];</span><br><span class="line">      ptr_gradInput[i] = ptr_gradOutput[i] * (<span class="number">1.</span> - z*z);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>反向传播接收5个参数，分别是THNN状态，从后面传回来的梯度（<code>gradOutput</code>），本层往回传的梯度（<code>gradInput</code>），本层前向传播的输出（<code>output</code>），这个函数计算的是本层的梯度，然后存储在<code>gradInput</code>中。</p>
<p><span class="math inline">\(\tanh\)</span> 的导数为： <span class="math display">\[
f(z) = \tanh(z)\\
f&#39;(z) = 1 - (f(z))^2
\]</span> 其中，<span class="math inline">\(f(z)​\)</span> 就是前向传播时本层的输出，也就是<code>output</code>参数（循环里的<code>z</code>），根据链式法则，再乘以后面层传回来的梯度（<code>gradOutput</code>）就是本层应该往回传的梯度了（相对于本层输入的梯度），所以循环里的代码为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*gradInput_data = *gradOutput_data * (<span class="number">1.</span> - z*z);</span><br></pre></td></tr></table></figure>
<p>注：<code>_data</code>后缀表示数据指针，具体可以看<a href="https://www.52coding.com.cn/2019/05/05/PyTorch1/#tensor-apply-dynamic-dispatch">Apply宏</a>的实现。</p>
<h3><span id="2d-convolution">2D Convolution</span></h3>
<p>最普通的2D卷积，CPU实现在<code>THNN/generic/SpatialConvolutionMM.c</code>，CUDA实现在<code>THCUNN/generic/SpatialConvolutionMM.cu</code>，大体的算法是把输入展开成一个特殊的矩阵，然后把卷积转化为矩阵相乘（MM = Matrix Multiplication）。模块里主要包含三个函数，前向传播（<code>THNN_(SpatialConvolutionMM_updateOutput)()</code>），反向传播（<code>THNN_(SpatialConvolutionMM_updateGradInput)()</code>），和更新层内参数（<code>THNN_(SpatialConvolutionMM_accGradParameters)()</code>）。</p>
<h4><span id="前向传播">前向传播</span></h4>
<p>PyTorch实现卷积的做法是用im2col算法把输入展开成一个大矩阵，然后用kernel乘以这个大矩阵，就得了卷积的结果。这里不具体介绍im2col算法是怎么做的，但会解释为什么可以这么做。</p>
<p>首先定义符号，为了和代码中的符号一致，首先来看一下updateOutput的声明：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_updateOutput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">           THCState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *output,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *weight,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *bias,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *columns,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *ones,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> kW, <span class="keyword">int</span> kH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dW, <span class="keyword">int</span> dH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> padW, <span class="keyword">int</span> padH)</span></span>;</span><br></pre></td></tr></table></figure>
<p>其中，</p>
<ul>
<li><code>input</code>是输入的4D Tensor，大小为 <span class="math inline">\(\text{batch}\times\text{nInputPlane}\times\text{inputHeight}\times\text{inputWidth}\)</span>，batch维也可以没有，就变为3D Tensor；</li>
<li><code>output</code>是输出的4D或3D Tensor，大小为 <span class="math inline">\(\text{batch}\times\text{nOutputPlane}\times\text{outputHeight}\times\text{outputWidth}\)</span>，其中，</li>
</ul>
<p><span class="math display">\[
\text{outputHeight}=\frac{\text{inputHeight}+2\ast\text{padH}-\text{kH}}{\text{dH}}+1\\
\text{outputWidth}=\frac{\text{inputWidth}+2\ast\text{padW}-\text{kW}}{\text{dW}}+1
\]</span></p>
<ul>
<li><code>weight</code>是权重，也就是卷积核，大小为 <span class="math inline">\(\text{nOutputPlane}\times\text{nInputPlane}\times\text{kH}\times\text{kW}\)</span>；</li>
<li><code>bias</code>是偏置，大小为 <span class="math inline">\(\text{nOutputPlane}\times1\times1\times1\)</span>；</li>
<li><code>columns</code>用于存储im2col的结果；</li>
<li><code>ones</code>是一个值全为1的矩阵，大小为 <span class="math inline">\(\text{outputHeight}\times\text{outputWidth}\)</span>，用于计算偏置；</li>
<li><code>kW</code>和<code>kH</code>是卷积核（kernel）的宽和高；</li>
<li><code>dW</code>和<code>dH</code>是步长（stride）；</li>
<li><code>padW</code>和<code>padH</code>是补零的宽和高。</li>
</ul>
<p>定义好了符号之后来看一下卷积是怎么转化为一个矩阵乘法的。首先来看卷积是怎么做的，下图是一个简单的例子，其中输入和输出深度 <span class="math inline">\(\text{nInputPlane}=\text{nOutputPlane}=1​\)</span>，卷积核大小 <span class="math inline">\(\text{kH}=\text{kW}=3​\)</span>，输入大小 <span class="math inline">\(\text{inputHeight}=\text{inputWidth}=7​\)</span>，步长 <span class="math inline">\(\text{dW}=\text{dH}=2​\)</span>，补零 <span class="math inline">\(\text{padW}=\text{padH}=1​\)</span>，可以算出 <span class="math inline">\(\text{outputHeight}=\text{outputWidth}=3​\)</span>。</p>
<p><img src="/images/pytorch/conv.png"></p>
<p>要想把卷积变成一次矩阵乘法运算，就需要<strong>把输入中每个卷积窗口变为单独一列</strong>，这也就是im2col做的事情，见下图：</p>
<p><img src="/images/pytorch/im2col.png"></p>
<p>上图中右边矩阵的每一列都是原输入矩阵的一个卷积窗口，转换后的矩阵大小为 <span class="math display">\[
(\text{nInputPlane}\times\text{kH}\times\text{kW})\times(\text{outputHeight}\times\text{outputWidth})
\]</span> 得到上述矩阵之后，只需把kernel的大小也resize成 <span class="math display">\[
(\text{nOutputPlane})\times(\text{nInputPlane}\times\text{kH}\times\text{kW})
\]</span> 就可以直接用kernel乘以该矩阵得到卷积结果了，见下图。</p>
<p><img src="/images/pytorch/convmm.png"></p>
<p><strong>代码</strong>（CUDA版）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_updateOutput)</span><span class="params">(<span class="comment">/* 参数列表前面有 */</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* 省略了一些常规check */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* resize 卷积核 */</span></span><br><span class="line">  weight = THNN_(newViewWeightMM2d)(state, weight);</span><br><span class="line">  <span class="comment">/* 对输入的维度进行check */</span></span><br><span class="line">  THNN_(SpatialConvolutionMM_shapeCheck)</span><br><span class="line">       (state, input, <span class="literal">NULL</span>, weight, bias, kH, kW, dH, dW, padH, </span><br><span class="line">        padW, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> ndim = input-&gt;dim();</span><br><span class="line">  <span class="keyword">int</span> dimf = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> dimh = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">int</span> dimw = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (ndim == <span class="number">4</span>) &#123;	<span class="comment">/* 如果输入是4D的话，第0维是batch size */</span></span><br><span class="line">    dimf++;</span><br><span class="line">    dimh++;</span><br><span class="line">    dimw++;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 计算输入输出大小 */</span></span><br><span class="line">  <span class="keyword">int64_t</span> nInputPlane = input-&gt;size(dimf);</span><br><span class="line">  <span class="keyword">int64_t</span> inputHeight  = input-&gt;size(dimh);</span><br><span class="line">  <span class="keyword">int64_t</span> inputWidth   = input-&gt;size(dimw);</span><br><span class="line">  <span class="keyword">int64_t</span> nOutputPlane = weight-&gt;size(<span class="number">0</span>);</span><br><span class="line">  <span class="keyword">int64_t</span> outputHeight = (inputHeight + <span class="number">2</span>*padH - kH) / dH + <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">int64_t</span> outputWidth  = (inputWidth + <span class="number">2</span>*padW - kW) / dW + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">  input = THCTensor_(newContiguous)(state, input);</span><br><span class="line">  <span class="keyword">int</span> is_batch = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> (input-&gt;dim() == <span class="number">3</span>) &#123;</span><br><span class="line">    <span class="comment">/* 强行加入 batch 维度，把输入变为4D Tensor（batch size = 1）*/</span></span><br><span class="line">    is_batch = <span class="number">0</span>;</span><br><span class="line">    THCTensor_(resize4d)(state, input, <span class="number">1</span>, input-&gt;size(<span class="number">0</span>), </span><br><span class="line">                         input-&gt;size(<span class="number">1</span>), input-&gt;size(<span class="number">2</span>));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 获取 batch size */</span></span><br><span class="line">  <span class="keyword">int64_t</span> batchSize = input-&gt;size(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Resize output</span></span><br><span class="line">  THCTensor_(resize4d)(state, output, batchSize, nOutputPlane,</span><br><span class="line">                       outputHeight, outputWidth);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Resize columns 矩阵 */</span></span><br><span class="line">  THCTensor_(resize2d)(state, columns, nInputPlane*kW*kH,</span><br><span class="line">                       outputHeight*outputWidth);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 定义 buffer `ones`，代码略 */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Helpers</span></span><br><span class="line">  THCTensor *input_n = THCTensor_(<span class="keyword">new</span>)(state);</span><br><span class="line">  THCTensor *output_n = THCTensor_(<span class="keyword">new</span>)(state);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 对每个batch单独计算： */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> elt = <span class="number">0</span>; elt &lt; batchSize; elt ++) &#123;</span><br><span class="line">    <span class="comment">/* 取出对应batch的输入和输出buffer */</span></span><br><span class="line">    <span class="comment">/* input_n = input[elt] */</span></span><br><span class="line">    THCTensor_(select)(state, input_n, input, <span class="number">0</span>, elt);</span><br><span class="line">    THCTensor_(select)(state, output_n, output, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 首先计算偏置 bias，即把 bias 存到 output_n 中 */</span></span><br><span class="line">    <span class="comment">// M,N,K are dims of matrix A and B</span></span><br><span class="line">    <span class="keyword">int64_t</span> m_ = nOutputPlane;</span><br><span class="line">    <span class="keyword">int64_t</span> n_ = outputHeight * outputWidth;</span><br><span class="line">    <span class="keyword">int64_t</span> k_ = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 调用 GEMM 计算 output_n = 1 * ones * bias + 0 * output_n */</span></span><br><span class="line">    <span class="keyword">if</span> (bias) &#123;</span><br><span class="line">      <span class="meta">#<span class="meta-keyword">ifdef</span> THC_REAL_IS_FLOAT</span></span><br><span class="line">      THCudaBlas_Sgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">      THCudaBlas_Hgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      THCudaBlas_Dgemm(</span><br><span class="line">      #endif</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>, <span class="string">'n'</span>,</span><br><span class="line">          n_, m_, k_,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, ones), k_,</span><br><span class="line">          THCTensor_(data)(state, bias), k_,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">0</span>),</span><br><span class="line">          THCTensor_(data)(state, output_n), n_</span><br><span class="line">      );</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">/* 如果没有 bias 就把 output_n 填零 */</span></span><br><span class="line">      THCTensor_(zero)(state, output_n);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 用 im2col 把输入 input_n 转化为列矩阵存储在 columns */</span></span><br><span class="line">    im2col(</span><br><span class="line">      THCState_getCurrentStream(state),</span><br><span class="line">      THCTensor_(data)(state, input_n),</span><br><span class="line">      nInputPlane, inputHeight, inputWidth,</span><br><span class="line">      outputHeight, outputWidth,</span><br><span class="line">      kH, kW, padH, padW, dH, dW,</span><br><span class="line">      <span class="number">1</span>, <span class="number">1</span>, THCTensor_(data)(state, columns)</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 接下来计算 kernel * columns: */</span></span><br><span class="line">    <span class="keyword">int64_t</span> m = nOutputPlane;</span><br><span class="line">    <span class="keyword">int64_t</span> n = columns-&gt;size(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int64_t</span> k = nInputPlane*kH*kW;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 计算 output_n = 1 * weight * columns + 1 * bias */</span></span><br><span class="line">    <span class="comment">/* 代码中 columns 在 weight 前面是因为 GEMM 假设矩阵是列主序 */</span></span><br><span class="line">    #ifdef THC_REAL_IS_FLOAT</span><br><span class="line">    THCudaBlas_Sgemm(</span><br><span class="line">    #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">    THCudaBlas_Hgemm(</span><br><span class="line">    #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">    THCudaBlas_Dgemm(</span><br><span class="line">    #endif</span><br><span class="line">        state,</span><br><span class="line">        <span class="string">'n'</span>, <span class="string">'n'</span>,</span><br><span class="line">        n, m, k,</span><br><span class="line">        ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">        THCTensor_(data)(state, columns), n,</span><br><span class="line">        THCTensor_(data)(state, weight), k,</span><br><span class="line">        ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">        THCTensor_(data)(state, output_n), n</span><br><span class="line">    );</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* free 临时变量 input_n, output_n 等 */</span></span><br><span class="line">  <span class="comment">/* resize 输出矩阵，代码略 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4><span id="反向传播">反向传播</span></h4>
<p>首先来看一下卷积层反向传播的公式，设第 <span class="math inline">\(l\)</span> 层的输入为 <span class="math inline">\(a^{l-1}\)</span>，卷积核为 <span class="math inline">\(W\)</span>，偏置为 <span class="math inline">\(b\)</span>，输出为 <span class="math inline">\(z^l = a^{l-1}*W+b\)</span>，相对于输出的误差梯度为 <span class="math inline">\(\delta^l = \frac{\partial \text{Loss}}{\partial z^l}\)</span>，则相对于输入的梯度为： <span class="math display">\[
\delta^{l-1}=\delta^l*\text{rot180}(W^l)
\]</span> 相对于权重和偏置的梯度为： <span class="math display">\[
\frac{\partial\text{Loss}}{\partial W^l}=\frac{\partial\text{Loss}}{\partial z^l}\frac{\partial z^l}{\partial W^l}=a^{l-1}*\delta^l\\
\frac{\partial\text{Loss}}{\partial b^l}=\sum_{u,v}(\delta^l)_{u,v}
\]</span> <strong>注</strong>：<span class="math inline">\(*\)</span> 为卷积的意思，<span class="math inline">\(\text{rot180}(x)\)</span> 为把矩阵 <span class="math inline">\(x\)</span> 旋转180度的意思。公式推导可以看<a href="https://www.cnblogs.com/pinard/p/6494810.html" target="_blank" rel="noopener">这篇博客</a>。</p>
<p>从公式可以看出反向传播分为两个部分：计算对输入的梯度和计算对参数的梯度，这两部分也分别对应了模块里的两个函数，我们一个一个分析。</p>
<p><strong>THNN_(SpatialConvolutionMM_updateGradInput)</strong></p>
<p>这部分是计算对输入的梯度，虽然公式摆在了那里，但Torch的代码实现并不是直接翻译公式，我也一直没能把这部分的实现和公式对上，不过倒是可以通过图示的方式来理解，有点像前向传播的逆过程，把卷积后的梯度分配回卷积前。</p>
<p>在画图之前还是先定义一些符号：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_updateGradInput)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">           THCState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradOutput,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradInput,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *weight,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradColumns,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *ones,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> kW, <span class="keyword">int</span> kH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dW, <span class="keyword">int</span> dH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> padW, <span class="keyword">int</span> padH)</span></span>;</span><br></pre></td></tr></table></figure>
<p>其中（与前向传播相同的参数就不重复介绍了），</p>
<ul>
<li><code>gradOutput</code> 是相对于输出的梯度，即 <span class="math inline">\(\delta^l\)</span>，大小与前向传播的输出 <code>output</code> 相同；</li>
<li><code>gradInput</code> 是相对于输入的梯度，即 <span class="math inline">\(\delta^{l-1}\)</span>，是这个函数需要计算的对象，大小与输入 <code>input</code> 相同；</li>
<li><code>gradColumns</code> 是个列矩阵，用于存储临时的梯度，大小为 <span class="math inline">\((\text{nInputPlane}\times\text{kH}\times\text{kW})\times(\text{outputHeight}\times\text{outputWidth})\)</span>；</li>
</ul>
<p>代码的实现逻辑是用权重的转置乘以输出梯度，得到<code>gradColumns</code>，然后通过col2im还原到输入的大小，即得到了相对输入的梯度 <code>gradInput</code>。这个操作看起来就是前向传播的逆操作，但是搞不懂为什么这样就实现了 <span class="math inline">\(\delta^l*\text{rot180}(W^l)\)</span>，<strong>如果有大佬知道希望评论区指点一下</strong>。使用前面例子的设定，这波操作的示意图如下所示：</p>
<p><img src="/images/pytorch/convmm2.png"></p>
<p><img src="/images/pytorch/col2im.png"></p>
<p><strong>核心部分代码</strong>（其余部分与前向传播类似）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 循环取每个批次： */</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> elt = <span class="number">0</span>; elt &lt; batchSize; elt ++) &#123;</span><br><span class="line">  <span class="comment">/* gradInput_n = gradInput[elt]; gradInput_n 同理 */</span></span><br><span class="line">  THCTensor_(select)(state, gradInput_n, gradInput, <span class="number">0</span>, elt);</span><br><span class="line">  THCTensor_(select)(state, gradOutput_n, gradOutput, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// M,N,K are dims of matrix A and B</span></span><br><span class="line">  <span class="keyword">int64_t</span> m = nInputPlane*kW*kH;</span><br><span class="line">  <span class="keyword">int64_t</span> n = gradColumns-&gt;size(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">int64_t</span> k = nOutputPlane;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 调用GEMM计算 gradColumns = weight' * gradOutput_n */</span></span><br><span class="line">  <span class="meta">#<span class="meta-keyword">ifdef</span> THC_REAL_IS_FLOAT</span></span><br><span class="line">  THCudaBlas_Sgemm(</span><br><span class="line">  #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">  THCudaBlas_Hgemm(</span><br><span class="line">  #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">  THCudaBlas_Dgemm(</span><br><span class="line">  #endif</span><br><span class="line">      state,</span><br><span class="line">      <span class="string">'n'</span>, <span class="string">'t'</span>,</span><br><span class="line">      n, m, k,</span><br><span class="line">      ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">      THCTensor_(data)(state, gradOutput_n), n,</span><br><span class="line">      THCTensor_(data)(state, weight), m,</span><br><span class="line">      ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">0</span>),</span><br><span class="line">      THCTensor_(data)(state, gradColumns), n</span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* 调用 col2im 把 gradColumns 还原为 gradInput_n */</span></span><br><span class="line">  col2im&lt;<span class="keyword">scalar_t</span>, accreal&gt;(</span><br><span class="line">    THCState_getCurrentStream(state),</span><br><span class="line">    THCTensor_(data)(state, gradColumns),</span><br><span class="line">    nInputPlane, inputHeight, inputWidth, outputHeight,</span><br><span class="line">    outputWidth, kH, kW, padH, padW, dH, dW,</span><br><span class="line">    <span class="number">1</span>, <span class="number">1</span>, THCTensor_(data)(state, gradInput_n)</span><br><span class="line">  );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>THNN_(SpatialConvolutionMM_accGradParameters)</strong></p>
<p>接下来看计算参数梯度的部分，这部分相对好理解，因为代码和公式一样，还是先看函数声明：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_accGradParameters)</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">           THCState *state,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *input,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradOutput,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradWeight,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *gradBias,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *columns,</span></span></span><br><span class="line"><span class="function"><span class="params">           THCTensor *ones,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> kW, <span class="keyword">int</span> kH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> dW, <span class="keyword">int</span> dH,</span></span></span><br><span class="line"><span class="function"><span class="params">           <span class="keyword">int</span> padW, <span class="keyword">int</span> padH,</span></span></span><br><span class="line"><span class="function"><span class="params">           accreal scale_)</span></span>;</span><br></pre></td></tr></table></figure>
<p>其中，</p>
<ul>
<li><code>gradWeight</code> 是权重的梯度，是这个函数需要计算的对象，大小和权重相同；</li>
<li><code>gradBias</code> 是偏置的梯度，也是函数需要计算的对象，大小与偏置相同（就是一个Vector）</li>
<li><code>columns</code> 是用来存储 im2col 的结果，因为要计算卷积，所以要把输入展开</li>
<li><code>scale_</code> 是学习速率（learning rate）</li>
</ul>
<p>已知<strong>权重梯度</strong>的计算公式为 <span class="math inline">\(\frac{\partial\text{Loss}}{\partial W^l}=a^{l-1}*\delta^l\)</span>，这个卷积的计算方式和前向传播相同：首先把输入（<span class="math inline">\(a^{l-1}\)</span>）通过im2col展开为列矩阵，存储到<code>columns</code>里，然后用 <code>gradOutput</code> 乘以 <code>columns</code> 计算卷积。而<strong>偏置梯度</strong>的计算就是把 <code>gradOutput</code> 累加成一个长度为 <span class="math inline">\(\text{nOutputPlane}​\)</span> 的 Tensor 即可。</p>
<p><strong>核心代码</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">THNN_</span><span class="params">(SpatialConvolutionMM_accGradParameters)</span><span class="params">(<span class="comment">/* 略 */</span>)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 循环取每个batch： */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> elt = <span class="number">0</span>; elt &lt; batchSize; elt ++) &#123;</span><br><span class="line">    <span class="comment">/* gradOutput_n = gradOutput[elt] */</span></span><br><span class="line">    THCTensor_(select)(state, gradOutput_n, gradOutput, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 计算权重梯度 */</span></span><br><span class="line">    <span class="keyword">if</span> (gradWeight) &#123;</span><br><span class="line">      <span class="comment">/* input_n = input[elt] */</span></span><br><span class="line">      THCTensor_(select)(state, input_n, input, <span class="number">0</span>, elt);</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* 把 input_n 展开为 columns */</span></span><br><span class="line">      im2col(</span><br><span class="line">        THCState_getCurrentStream(state),</span><br><span class="line">        THCTensor_(data)(state, input_n),</span><br><span class="line">        nInputPlane, inputHeight, inputWidth,</span><br><span class="line">        outputHeight, outputWidth,</span><br><span class="line">        kH, kW, padH, padW, dH, dW,</span><br><span class="line">        <span class="number">1</span>, <span class="number">1</span>, THCTensor_(data)(state, columns)</span><br><span class="line">      );</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">      <span class="keyword">int64_t</span> m = nOutputPlane;</span><br><span class="line">      <span class="keyword">int64_t</span> n = nInputPlane*kW*kH;</span><br><span class="line">      <span class="keyword">int64_t</span> k = columns-&gt;size(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* 调用GEMM计算gradWeight += scale * gradOutput_n * columns'*/</span></span><br><span class="line">      <span class="meta">#<span class="meta-keyword">ifdef</span> THC_REAL_IS_FLOAT</span></span><br><span class="line">      THCudaBlas_Sgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_HALF)</span><br><span class="line">      THCudaBlas_Hgemm(</span><br><span class="line">      #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      THCudaBlas_Dgemm(</span><br><span class="line">      #endif</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>, <span class="string">'n'</span>,</span><br><span class="line">          n, m, k,</span><br><span class="line">          scale,</span><br><span class="line">          THCTensor_(data)(state, columns), k,</span><br><span class="line">          THCTensor_(data)(state, gradOutput_n), k,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, gradWeight), n</span><br><span class="line">      );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 计算偏置梯度 */</span></span><br><span class="line">    <span class="keyword">if</span> (gradBias) &#123;</span><br><span class="line">     	</span><br><span class="line">      <span class="keyword">int64_t</span> m_ = nOutputPlane;</span><br><span class="line">      <span class="keyword">int64_t</span> k_ = outputHeight * outputWidth;</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* 调用GEMV计算 gradBias += scale * gradOutput_n * ones */</span></span><br><span class="line">      #<span class="keyword">if</span> defined(THC_REAL_IS_FLOAT) || defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      #ifdef THC_REAL_IS_FLOAT</span><br><span class="line">      THCudaBlas_Sgemv(</span><br><span class="line">      #elif defined(THC_REAL_IS_DOUBLE)</span><br><span class="line">      THCudaBlas_Dgemv(</span><br><span class="line">      #endif</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>,</span><br><span class="line">          k_, m_,</span><br><span class="line">          scale,</span><br><span class="line">          THCTensor_(data)(state, gradOutput_n), k_,</span><br><span class="line">          THCTensor_(data)(state, ones), <span class="number">1</span>,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, gradBias), <span class="number">1</span></span><br><span class="line">      );</span><br><span class="line">      #endif</span><br><span class="line">      #ifdef THC_REAL_IS_HALF</span><br><span class="line">      THCudaBlas_Hgemm(</span><br><span class="line">          state,</span><br><span class="line">          <span class="string">'t'</span>, <span class="string">'n'</span>,</span><br><span class="line">          m_, <span class="number">1</span>, k_,</span><br><span class="line">          scale,</span><br><span class="line">          THCTensor_(data)(state, gradOutput_n), k_,</span><br><span class="line">          THCTensor_(data)(state, ones), k_,</span><br><span class="line">          ScalarConvert&lt;<span class="keyword">int</span>, <span class="keyword">scalar_t</span>&gt;::to(<span class="number">1</span>),</span><br><span class="line">          THCTensor_(data)(state, gradBias), m_</span><br><span class="line">      );</span><br><span class="line">      #endif</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* ... */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2><span id="aten">ATen</span></h2>
<p>看了<code>THNN.h</code>的读者可能会发现，THNN和THCUNN只定义了少量的神经网络相关的函数，其实大部分都定义在ATen中，这个ATen是指<code>pytorch/aten/src/ATen</code>文件夹（下同）。说到底，TH系列库都是torch lua时代留下的产物，是用C语言实现的，后来PyTorch开发者觉得cpp大法好，就用C++写了ATen，把TH里的接口都封装了，同时新的API直接在ATen里实现。</p>
<p>这个ATen有点意思，它大概干了这么几件事情：</p>
<ul>
<li>在<code>ATen/core/Tensor.h</code>定义了<code>at::Tensor</code>类型，这个是C++前端以及更上层的API都在用的Tensor类型，它的成员内有一个<code>TensorImpl impl_</code>，提供底层实现；</li>
<li>实现和封装了有关Tensor的所有操作，并根据数据类型和设备进行自动派发；</li>
<li>使用Python脚本生成ATen API。</li>
</ul>
<p>其中从TH（包括THC、THNN等）里封装的函数叫做 legacy函数，而在ATen直接实现的函数叫 native函数。native函数的实现全在<code>ATen/native</code>文件夹中，实现了THNN里没有的神经网络和Tensor操作，比如RNN什么的，API列表在<code>ATen/native/native_functions.yaml</code>里，感兴趣的童鞋可以自己阅读。</p>
<p>了解了神经网络每一层的前向传播和反向传播的实现之后，下一步就是控制执行顺序了，也就是自动微分（Autograd），下一章将介绍PyTorch自动微分的实现。</p>
<p>つづく</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">上一篇：<a href="https://www.52coding.com.cn/2019/05/05/PyTorch2/">THC</a></th>
<th style="text-align: right;">下一篇：<a href="https://www.52coding.com.cn/2019/05/05/PyTorch4/">Autograd</a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
</tr>
</tbody>
</table>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/博客/">博客</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/Neural-Network/">Neural Network</a><a href="/tags/PyTorch/">PyTorch</a><a href="/tags/THNN/">THNN</a><a href="/tags/CONV/">CONV</a>
      </span>
      

    </div>

    
  </div>
</article>

<div class="social-share"></div>
<script type="text/javascript">
  var $config = {
    image: "icon.png",
  };
  socialShare('.social-share-cs', $config);
</script>



<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC80MTI4MC8xNzgyOA==">
	<script type="text/javascript">
		(function (d, s) {
			var j, e = d.getElementsByTagName(s)[0];

			if (typeof LivereTower === 'function') {
				return;
			}

			j = d.createElement(s);
			j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
			j.async = true;

			e.parentNode.insertBefore(j, e);
		})(document, 'script');
	</script>
	<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->


      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2019
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>