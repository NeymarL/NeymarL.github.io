<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

  <meta charset="utf-8">
  
  <title>
    RL - DQN &amp; A3C | NIUHE | 日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれん
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE&#39;s Blog">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:title" content="RL - DQN &amp; A3C">
  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれん</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">目录</a></li>
      
        <li><a href="/categories">分类</a></li>
      
        <li><a href="/tags">标签</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        <article>

  
  
  <h3 class="article-title"><span>
      RL - DQN &amp; A3C</span></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/11/16/RL - DQN and A3C/" rel="bookmark">
        <time class="entry-date published" datetime="2018-11-16T06:24:32.000Z">
          2018-11-16
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <h2><span id="deep-q-network">Deep Q-Network</span></h2>
<p>使用非线性函数拟合 Q-value 的RL算法不稳定主要因为：</p>
<ol type="1">
<li>同一个观测序列中的数据相关性较大</li>
<li>当 Q-value 发生了很小的改变，可能导致整个策略（policy）发生较大变化，从而导致 Q-value 和目标 <span class="math inline">\(r + \gamma * \max_{a&#39;}Q(s&#39; ,a&#39;)\)</span> 的差距不稳定</li>
</ol>
<a id="more"></a>
<p>DQN使用了两个trick来解决上述问题：</p>
<ul>
<li>Experience replay
<ul>
<li>使用经验池缓存数据，每次训练时从经验池里sample数据，从而降低训练数据之间的相关性</li>
</ul></li>
<li>Two Q networks
<ul>
<li>一个网络用来生成 Q-target，另一个网络进行探索；每隔一定时间两个网络进行同步</li>
<li>这样使得 Q-target 相对稳定</li>
</ul></li>
</ul>
<p><strong>整体算法</strong></p>
<p><img src="/images/dqn.jpg"></p>
<hr>
<h2><span id="asynchronous-actor-critic">Asynchronous Actor Critic</span></h2>
<p>使用上述经验池有以下问题：</p>
<ol type="1">
<li>使用更多的内存和计算资源</li>
<li>只能使用 <strong>off-policy</strong> 的RL算法（学习 old policy 产生的数据）</li>
</ol>
<p>为了使用 on-policy 算法，Deep Mind提出了使用异步学习代替经验池的方法，同时也能保持算法的稳定性，其中使用最广泛的是A3C算法，它具有以下特点：</p>
<ul>
<li>并行地使用多个 agent 在各自的环境里探索，每个 agent 在同一时刻探索的内容各不相同，从而降低了数据相关性</li>
<li>在CPU上训练更加高效</li>
</ul>
<p><strong>整体算法</strong></p>
<ol type="1">
<li>同步线程专属网络（<span class="math inline">\(\theta&#39;, \theta_v&#39;\)</span>）和全局网络（<span class="math inline">\(\theta, theta_v\)</span>）</li>
<li>每个 agent 使用线程专属网络各自进行探索</li>
<li>根据线程专属网络计算梯度：<span class="math inline">\(d\theta, d\theta_v\)</span></li>
<li>使用 <span class="math inline">\(d\theta, d\theta_v\)</span> 更新全局网络（<span class="math inline">\(\theta, theta_v\)</span>）</li>
<li>回到第一步</li>
</ol>
<p><img src="/images/IMG_25EB14880DD1-1.jpeg"></p>
<p><strong>其他细节</strong></p>
<ul>
<li><strong>主线程向子线程传参数，子线程向主线程传梯度</strong></li>
<li>agent 和 critic 共用一个网络，输出分为两头</li>
<li>增加了熵正则化（鼓励探索）
<ul>
<li><span class="math inline">\(\triangledown_{\theta&#39;}\log\pi(a_t|s_t;\theta&#39;)(R_t-V(s_t;\theta_v))+\beta\triangledown_{\theta&#39;}H(\pi(s_t; \theta&#39;))\)</span></li>
<li><span class="math inline">\(H(X) = E[-\log P(X)]\)</span></li>
</ul></li>
<li>代码参考：https://github.com/NeymarL/Pacman-RL/blob/master/src/a3c.py
<ul>
<li><strong>注</strong>：计算 policy loss 中的 advantage 的时候不能保留其梯度，否则 policy 的梯度会流入 value network 中，产生bug</li>
</ul></li>
</ul>
<hr>
<h2><span id="与题无关">与题无关</span></h2>
<h3><span id="batch-normalization">Batch-Normalization</span></h3>
<p>解决网络层数变多梯度<strong>消失</strong>/爆炸问题</p>
<ul>
<li>梯度截断</li>
<li>初始化</li>
<li>RELU</li>
</ul>
<p>对每层神经元处理结果进行归一化，但又不能破坏上一层提取的特征（变换重构，引入了可学习参数<span class="math inline">\(\gamma, \beta\)</span>）</p>
<figure>
<img src="/images/bn.png" alt="bn"><figcaption>bn</figcaption>
</figure>
<p>Inference时 <span class="math inline">\(\mu_B\)</span> 和 <span class="math inline">\(\sigma^2_B\)</span> 固定。</p>
<p>为什么不用白化？</p>
<ul>
<li>在模型训练过程中进行白化操作会带来过高的计算代价和运算时间</li>
</ul>
<p>在BN中，是通过将activation规范为均值和方差一致的手段使得原本会减小的activation的scale变大。 <span class="math display">\[
\frac{\partial h_l}{\partial h_{l-1}} = \frac{\partial BN(w_l h_{l-1})}{\partial h_{l-1}} = \frac{\partial \alpha w_l h_{l-1}}{\partial h_{l-1}}
\]</span> 其中 <span class="math inline">\(\alpha\)</span> 指缩放。可以看到此时反向传播乘以的数不再和 <span class="math inline">\(w\)</span> 的尺度相关，也就是说尽管我们在更新过程中改变 <span class="math inline">\(w\)</span> 的值，但是反向传播的梯度却不受影响。</p>
<h3><span id="variance-reduction-techniques">Variance reduction Techniques</span></h3>
<p><strong>Advantage Estimation</strong></p>
<p>Use advantage function to reduce variance. <span class="math display">\[
A(s, a) = Q(s, a) - V(s)
\]</span> How much better is selecting action <span class="math inline">\(a\)</span> than usual(mean)</p>
<p><strong>Reward Estimator</strong></p>
<p>Train a reward estimator <span class="math inline">\(\hat{R}(s_t)\)</span>, use <span class="math inline">\(\hat{R}\)</span> instead of <span class="math inline">\(R\)</span> when training RL model, this estimation will reduce the variance propagated to the value function.</p>
<p>Optimize <span class="math inline">\(\hat{R}\)</span>: <span class="math inline">\((r_t - \hat{R}(s_t))^2\)</span>.</p>
<h3><span id="activation-layers">Activation Layers</span></h3>
<h4><span id="relu">ReLU</span></h4>
<figure>
<img src="/images/relu.png" alt="relu"><figcaption>relu</figcaption>
</figure>
<p>整流线性单元易于优化，因为它们和线性单元非常类似。线性单元和整流线性单元的唯一区别在于整流线性单元在其一半的定义域上输出为零。这使得只要整流线性单元处于激活状态，它的导数都能保持较大。它的梯度不仅大而且一致。整流操作的二阶导数几乎处处为 0，并且在整流线性单元处于激活状态时，它的一阶导数处处为 1。这意味着相比于引入二阶效应的激活函数来说，它的梯度方向对于学习来说更加有用。</p>
<p>ReLU 的过程更接近生物神经元的作用过程</p>
<p><strong>Leaky ReLU</strong></p>
<p>ReLU 及其扩展都是基于一个原则，那就是如果它们的行为更接近线性，那么模型更容易优化。 <span class="math display">\[
g(z; \alpha) = \max(0, z) + \alpha \min(0, z)
\]</span> <span class="math inline">\(\alpha\)</span> 为固定值或可学习参数。</p>
<h4><span id="sigmoid-amp-tanh">Sigmoid &amp; Tanh</span></h4>
<p><img src="/images/sigmoid.png" alt="sigmoid"> <span class="math display">\[
g(z) = \frac{1}{1 + e^{-z}}
\]</span></p>
<ul>
<li>sigmoid 常作为输出单元用来预测二值型变量取值为 1 的概率</li>
<li>sigmoid 函数在输入取绝对值非常大的正值或负值时会出现<strong>饱和</strong>（saturate）现象，在图像上表现为开始变得很平，此时函数会对输入的微小改变会变得不敏感。仅当输入接近 0 时才会变得敏感。从而使得学习变困难。</li>
<li>如果要使用 sigmoid 作为激活函数时（浅层网络），tanh 通常要比 sigmoid 函数表现更好。</li>
</ul>
<h3><span id="bagging">Bagging</span></h3>
<p>思想：多个模型平均效果好于单个模型</p>
<p><strong>Bagging（bootstrap aggregating）</strong>是通过结合几个模型降低泛化误差的技术 (Breiman, 1994)。</p>
<p>具体来说，Bagging 涉及构造 k 个<strong>不同的数据集</strong>。每个数据集从原始数据集中<strong>重复采样</strong>构成，和原始数据集具有<strong>相同数量</strong>的样例。这意味着，每个数据集以高概率缺少一些来自原始数据集的例子，还包含若干重复的例子（更具体的，如果采样所得的训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 <strong>2/3</strong> 的实例）</p>
<figure>
<img src="/images/bagging.png" alt="bagging"><figcaption>bagging</figcaption>
</figure>
<p>第一个分类器学到上面的圆圈就会认为数字是8，第二个分类器检测到下面的圈就会认为数字是8，把两个结合起来就知道只有当上下都有圈（置信概率最大）的时候数字才是8。</p>
<h3><span id="dropout">Dropout</span></h3>
<p>简单来说，Dropout (Srivastava et al., 2014) 通过<strong>参数共享</strong>提供了一种廉价的 <strong>Bagging</strong> 集成近似，能够训练和评估<strong>指数级数量</strong>的神经网络。</p>
<figure>
<img src="/images/dropout.png" alt="dropout"><figcaption>dropout</figcaption>
</figure>
<p><strong>Dropout与Bagging的不同点</strong>：</p>
<ul>
<li>Bagging 为串行策略；Dropout 为并行策略</li>
<li>在 Bagging 的情况下，所有模型都是独立的；而在 Dropout 的情况下，所有模型<strong>共享参数</strong>，其中每个模型继承父神经网络参数的不同子集。</li>
<li>在 Bagging 的情况下，每一个模型都会在其相应训练集上训练到收敛。而在 Dropout 的情况下，通常大部分模型都没有显式地被训练；取而代之的是，在单个步骤中我们训练一小部分的子网络，参数共享会使得剩余的子网络也能有好的参数设定。</li>
</ul>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/学习笔记/">学习笔记</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/Reinforcement-Learning/">Reinforcement Learning</a><a href="/tags/Q-learning/">Q-learning</a><a href="/tags/DQN/">DQN</a><a href="/tags/A3C/">A3C</a>
      </span>
      

    </div>

    
  </div>
</article>

<div class="social-share"></div>


	<section id="comment" class="comment">
	  <div id="disqus_thread">
	  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	  </div>
	</section>

	<script type="text/javascript">
	var disqus_shortname = 'Niuhe';
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	(function(){
	  var dsq = document.createElement('script');
	  dsq.type = 'text/javascript';
	  dsq.async = true;
	  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
	  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	}());
	</script>



      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2018
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>