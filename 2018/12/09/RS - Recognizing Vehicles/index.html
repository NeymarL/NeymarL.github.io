<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

  <meta charset="utf-8">
  
  <!-- if (config.subtitle) {
    title.push(config.subtitle);
  } -->
  <title>
    Recognizing Vehicles | NIUHE
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE的博客">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  
  <meta property="og:title" content="Recognizing Vehicles">
  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script>
  <script type="text/javascript" src="/js/search.js"></script>
  <script type="text/javascript" src="/js/jquery.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれんな</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">目录</a></li>
      
        <li><a href="/categories">分类</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/search">搜索</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        <article>

  
  
  <h3 class="article-title"><span>
      Recognizing Vehicles</span></h3>
  
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/12/09/RS - Recognizing Vehicles/" rel="bookmark">
        <time class="entry-date published" datetime="2018-12-09T11:54:07.000Z">
          2018-12-09
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
      <p>HKUST CSIT5401 Recognition System lecture notes 6. 识别系统复习笔记。</p>
<p>Vehicle recognition, including detection, tracking and identification, has been a research topic among automotive manufacturers, suppliers and universities for enhancing road safety.</p>
<p>For example, the <a href="http://www.argo.ce.unipr.it/ARGO/english/index.html" target="_blank" rel="noopener">ARGO</a> project, started in 1996 at the University of Parma and the University of Pavia, Italy, is aimed at developing a system for improving road safety by controlling and supervising the driver activity.</p>
<a id="more"></a>
<!-- toc -->
<ul>
<li><a href="#lane-detection">Lane Detection</a>
<ul>
<li><a href="#canny-edge-detector">Canny edge detector</a></li>
</ul></li>
<li><a href="#vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</a></li>
<li><a href="#visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</a></li>
<li><a href="#application-examples">Application Examples</a></li>
</ul>
<!-- tocstop -->
<h2><span id="lane-detection">Lane Detection</span></h2>
<p>For vehicle detection and tracking and intelligent transportation systems, lane marking detection is one of the key steps. Lane markings can be detected based on the camera inverse perspective mapping (IPM) and the assumption that the lane markings are represented by almost vertical bright lines of constant width, surrounded by a darker background.</p>
<p>The lanes can then be detected by using the camera <strong>inverse perspective mapping (IPM)</strong> and the <strong>Canny edge detector</strong>.</p>
<p><strong>Inverse perspective mapping</strong></p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/impres.png"></p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/ipmreason.png"></p>
<h3><span id="canny-edge-detector">Canny edge detector</span></h3>
<p><a href="http://en.wikipedia.org/wiki/Canny_edge_detector" target="_blank" rel="noopener">Canny edge detector</a> is one of the most popular detectors of edge pixels. The edge detection process serves to simplify the analysis of images by drastically <strong>reducing the amount of data to be processed</strong>, while at the same time <strong>preserving useful structural information</strong> about object boundaries.</p>
<p>There are three common criteria relevant to edge detector performance.</p>
<ul>
<li>It is important that edges that occur in the image should not be missed and that there be <em>no spurious responses</em>.</li>
<li>The edge points should be well localized. That is, the distance between the points marked by the detector and the true edge center should be minimized.</li>
<li>The last requirement is to circumvent the possibility of multiple responses to a single edge.</li>
</ul>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/cedbalala.jpg"></p>
<p>In the figure above, (a) is a noisy step edge; (b) is a difference of boxes operator; (c) is the output of filtering by box operator; (d) is the first derivative of Gaussian operator; and (e) is the first derivative of Gaussian applied to the edge.</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/cannysd.png"></p>
<p>The <strong>edge center</strong> is marked as <strong>red circle</strong> at a local maximum in the output of the filter responses. Within the region of the edge, the boxes operator exhibits more local maxima than the Gaussian operator. Therefore, <strong>the Gaussian operator is better</strong> than the boxes operator in this example.</p>
<p><strong>The three performance criteria</strong></p>
<ol type="1">
<li><p>Good detection → Detection Criterion</p>
<p>There should be a low probability of failing to mark real edge points, and low probability of falsely marking non-edge points. This is controlled by signal-to-noise ratio: <span class="math display">\[
\text{SNR}=\frac{|\int_{-w}^{+w}G(-x)f(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f(x)^2dx}}
\]</span></p></li>
<li><p>Good localization → Localization Criterion</p>
<p>The points marked as edge points by the operator should be as close as possible to the true edge center. The localization is defined as the reciprocal of <span class="math inline">\(\delta x_0\)</span>: <span class="math display">\[
\text{Localization}=\frac{|\int_{-w}^{+w}G(-x)f&#39;(x)dx |}{n_0\sqrt{\int_{-w}^{+w}f&#39;(x)^2dx}}
\]</span></p></li>
<li><p>Only one response to a single edge → Multiple Response Constraint <span class="math display">\[
x_{zc}(f)=\pi\left(\frac{\int_{-\infty}^{+\infty}f&#39;(x)^2dx}{\int_{-\infty}^{+\infty}f&#39;&#39;(x)^2dx}\right)^{1/2}
\]</span></p></li>
</ol>
<p>It is very difficult to find the function <span class="math inline">\(f\)</span> (filter) which maximizes the detection and localization criteria subject to the multiple response constraint. Numerical optimization is therefore used.</p>
<p>The solution is of the form <span class="math display">\[
f(x)=a_1e^{\alpha x}\sin\omega x+a_2e^{\alpha x}\cos\omega x+a_3e^{-\alpha x}\sin\omega x\\
+a_4e^{-\alpha x}\cos\omega x+c
\]</span> The variables are determined by the non-linear optimization with boundary conditions.</p>
<p>The numerically estimated optimal edge detector can be approximated by the <strong>first derivative of a Gaussian</strong> G, where <span class="math display">\[
G(x)=\exp(-\frac{x^2}{2\sigma^2})\\
f(x)=G&#39;(x)=-\frac{x}{\sigma^2}\exp(-\frac{x^2}{2\sigma^2})
\]</span> For 2D, the solution proposed by Canny amounts to convolving the initial image with a Gaussian function followed by computation of the derivatives in <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> of the result.</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/firstderofgaus.png"></p>
<p>There are three main steps in the Canny edge detection</p>
<ol type="1">
<li><p>Gradient calculation</p>
<p>compute <span class="math inline">\(M\)</span>: <span class="math display">\[
I_x=\frac{\partial}{\partial x}(I\ast G(x,y))\\
I_y=\frac{\partial}{\partial y}(I\ast G(x,y))\\
M=\sqrt{I_x^2+I_y^2}\approx |I_x|+|I_y|
\]</span></p></li>
<li><p>Non-maximum suppression</p>
<p>keep local maximum, set others to zero.</p></li>
<li><p>Hysteresis thresholding</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/hyposisthres.png"></p></li>
</ol>
<h2><span id="vehicle-detection-based-on-symmetry">Vehicle Detection based on Symmetry</span></h2>
<p>Vehicle detection is based on the assumption that the rear or frontal views of the vehicles are generally symmetric; can be characterized by a rectangular bounding box which satisfies specific aspect ratio constraints and is placed in a specific region of the image, e.g., within lanes.</p>
<p>These features are used to identify vehicles in the image.</p>
<ol type="1">
<li>Area of interest is identified on the basis of road position and perspective constraints.</li>
<li>This area of interest is searched for possible vertical symmetries. Not only are the gray level symmetries considered, but also vertical and horizontal edge symmetries are considered.</li>
<li>Step 3: Once the symmetry axis has been detected, the lower part (the two bottom corners) of a rectangular bounding box is detected.</li>
<li>The top horizontal limit of the vehicle is then searched according to the pre-defined aspect ratio.</li>
</ol>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/vdbasedonsys.png"></p>
<p>Vertical and horizontal binary edges can help solve the problems of strong reflection areas in the vehicle images. The analysis of symmetry produces symmetry maps for gray-level intensity, edge (total), horizontal edge, vertical edge and total (combined) symmetry. The symmetry axis can be found from the total symmetry map.</p>
<p><strong>Bounding box detection</strong></p>
<p>After detecting the symmetry axis, the width of the symmetrical region is checked for the presence of two corners representing the bottom of the bounding box around the vehicle.</p>
<p>Once the two corners are detected, the top side of the rectangle box can be detected by searching.</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/boundingboxde.png"></p>
<h2><span id="visual-saliency-for-detection-and-tracking">Visual Saliency For Detection and Tracking</span></h2>
<p><strong>Visual saliency</strong> refers to the idea that certain parts of a scene are pre-attentively distinctive (pop-out) and create some form of immediate significant visual arousal within the early stages of the <strong>Human Visual System (HVS)</strong>. The figure below is an example.</p>
<p>In image analysis, an <strong>edge</strong> is a pop-out region (<strong>region of saliency</strong>) since the edge is more visually significant than the other parts of the image.</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/vsexamples.png"></p>
<p>The salient points are literally the points on the object which are almost unique. These points maximize the discrimination between objects. The visual saliency is defined in terms of <strong>local signal complexity</strong>.</p>
<p><strong>Shannon entropy</strong> of local attributes (called <strong>local entropy</strong>) is <span class="math display">\[
H_{D,Rx}(x)=-\sum_{i\in D}P_{D,Rx}(x,d_i)\log_2P_{D,Rx}(x,d_i)
\]</span> where <span class="math inline">\(x\)</span> is point location, <span class="math inline">\(Rx\)</span> is local neighborhood at <span class="math inline">\(x\)</span>, <span class="math inline">\(D\)</span> is descriptor (e.g. intensity), and <span class="math inline">\(P_{D,Rx}(x,d_i)\)</span> is histogram value at <span class="math inline">\(x\)</span>.</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/entropylsakdjad.jpg"></p>
<p>Below are sample frames from the processed sequences using a <strong>fixed scale</strong> based on local entropy. Red square boxes represent the most salient icons or parts of the image. The size of the local window or scale and threshold used were selected manually to give the most satisfactory results.</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/saliegsdas.png"></p>
<ul>
<li>Problem: the scale is fixed and global. For example, the scale is inappropriate for the pedestrians and the road markings in DT sequence.</li>
<li>Problem: Small salient regions are not picked up. Highly textured regions, e.g., large intensity variation regions, are picked up. For example, trees and bushes in Vicky sequence.</li>
</ul>
<p>Therefore, scale is an important and implicit part of the saliency detection problem.</p>
<p><strong>Scale selection for salient region detection</strong></p>
<p>Scale is selected based on the scale-space behavior of the saliency of a given feature.</p>
<p>For each pixel position <span class="math inline">\(x\)</span></p>
<ul>
<li><p>For each scale <span class="math inline">\(s\)</span> inside a range between <span class="math inline">\(s_\min\)</span> and <span class="math inline">\(s_\max\)</span> :</p>
<ul>
<li><p>Measure the local descriptor values (e.g.,intensity values) within a window of scale <span class="math inline">\(s\)</span>.</p></li>
<li><p>Estimate the local probability density function (PDF) from this (e.g. using histogram).</p></li>
<li><p>Calculate the local entropy <span class="math inline">\(H_D\)</span> <span class="math display">\[
H_{D}(s,x)=-\sum_{i\in D}P_{D}(s,x,d_i)\log_2P_{D}(s,x,d_i)
\]</span></p></li>
</ul></li>
<li><p>Select scales for which the entropy is peaked <span class="math display">\[
s:\frac{\partial^2H_D(s,x)}{\partial s^2}&lt;0
\]</span></p></li>
<li><p>Detection performance can be further improved if change of histogram is considered.</p></li>
</ul>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/salenscaleg.png"></p>
<p><strong>Vehicle Detection by using AdaBoost</strong></p>
<p>Vehicles can be detected by using <a href="https://www.52coding.com.cn/2018/12/06/RS%20-%20Recognizing%20Faces/#adaboost">AdaBoost</a>.</p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/vehildabboo.png"></p>
<p>By using the AdaBoost, vehicles in their lateral view can be detected in real time.</p>
<p><strong>Vehicle Recognition</strong></p>
<p>After vehicle detection, the vehicle can be recognition by using PCA and classification methods, e.g., k-NN or Bayesian methods.</p>
<h2><span id="application-examples">Application Examples</span></h2>
<p><strong>Vehicle counting in traffic surveillance</strong></p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/survelleg.png"></p>
<p><strong>Traffic jam detection and alarming</strong></p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/trafficjamsdeg.png"></p>
<p><strong>Abnormal vehicle behavior detection</strong></p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/abnormaldetec.png"></p>
<p><strong>Target tracking in night</strong></p>
<p><img src="/Users/liuhe/Documents/Recognition%20System/review/images/targetrackinni.png"></p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

      
      

      <span class="post-categories">
        <i class="icon-categories"></i>
        <a href="/categories/学习笔记/">学习笔记</a>
      </span>
      

      
      

      <span class="post-tags">
        <i class="icon-tags"></i>
        <a href="/tags/Recognition-System/">Recognition System</a><a href="/tags/Canny/">Canny</a><a href="/tags/visual-saliency/">visual saliency</a><a href="/tags/lane-detection/">lane detection</a><a href="/tags/vehicle-detection/">vehicle detection</a>
      </span>
      

    </div>

    
  </div>
</article>

<div class="social-share"></div>
<script type="text/javascript">
  var $config = {
    image: "icon.png",
  };
  socialShare('.social-share-cs', $config);
</script>



<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC80MTI4MC8xNzgyOA==">
	<script type="text/javascript">
		(function (d, s) {
			var j, e = d.getElementsByTagName(s)[0];

			if (typeof LivereTower === 'function') {
				return;
			}

			j = d.createElement(s);
			j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
			j.async = true;

			e.parentNode.insertBefore(j, e);
		})(document, 'script');
	</script>
	<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->


      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2018
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>