<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  

<!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-71540601-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-71540601-1');
</script>

  <meta charset="utf-8">
  
  <!-- if (config.subtitle) {
    title.push(config.subtitle);
  } -->
  <title>
    Page 4 | NIUHE
  </title>

  
  <meta name="author" content="NIUHE">
  

  
  <meta name="description" content="NIUHE的博客">
  

  
  <meta name="keywords" content="编程,读书,学习笔记">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  

  <meta property="og:site_name" content="NIUHE">

  
  <meta property="og:image" content="/favicon.ico">
  

  <link href="/icon.png" type="image/png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="NIUHE" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script type="text/javascript" src="/js/social-share.min.js"></script>
  <script type="text/javascript" src="/js/search.js"></script>
  <script type="text/javascript" src="/js/jquery.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="blog">
    <div class="content">

      <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">NIUHE</a>
    </h1>
    <p class="site-description">日々私たちが过ごしている日常というのは、実は奇迹の连続なのかもしれんな</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">博客</a></li>
      
        <li><a href="/categories">笔记</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/search">搜索</a></li>
      
    </ul>
  </nav>
</header>

      <main class="site-main posts-loop">
        

<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/15/SAN for Image QA/"><span>
                Paper Reading - Stacked Attention Networks for Image QA</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/15/SAN for Image QA/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-15T01:30:19.000Z">
                    2017-08-15
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <blockquote>
<p>Zichao Yang, Xiaodong He, Jianfeng Gao , Li Deng , Alex Smola <a href="https://arxiv.org/abs/1511.02274" target="_blank" rel="noopener">Stacked Attention Networks for Image Question Answering</a></p>
</blockquote>
<p>这篇文章发表在CVPR2016，作者把 attention 机制应用在 Visual QA，不但能理解神经网络生成答案的 multiple resoning，而且获得了当时最好的效果。</p>
<p>SAN总共由三部分组成：</p>
<ul>
<li>Image Model：用来编码图片信息</li>
<li>Question Moel：用来编码问题信息</li>
<li>Stacked Attention Networks：通过多层 attention layer 不断优化对问题的编码</li>
</ul>
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/博客/">博客</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/Attention/">Attention</a><a href="/tags/CV/">CV</a><a href="/tags/CNN/">CNN</a><a href="/tags/VQA/">VQA</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/14/Neural Machine Translation In Linear Time (ByteNet)/"><span>
                Paper Reading - Neural Machine Translation In Linear Time (ByteNet)</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/14/Neural Machine Translation In Linear Time (ByteNet)/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-14T01:30:19.000Z">
                    2017-08-14
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <p>ByteNet 可用于<strong>字符级</strong>的机器翻译模型并且有着很好的表现，它的特点在于可以在线性时间 (linear time) 完成翻译而且能够处理长距离依赖。它也采用编码器-解码器架构，并且编码器和解码器都由CNN组成。</p>
<p>ByteNet 之所以有上述的这些特性，是因为使用了如下一些技术：</p>
<ul>
<li>Dynamic Unfolding
<ul>
<li>解决了生成不同长度翻译的问题</li>
</ul></li>
<li>Dilated Convolution
<ul>
<li>缩短了依赖传播的距离</li>
</ul></li>
<li>Masked 1D Convolution
<ul>
<li>保证训练时只用过去的信息生成当前字符</li>
</ul></li>
<li>Residual Blocks
<ul>
<li>解决梯度消失问题</li>
</ul></li>
</ul>
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/博客/">博客</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/NMT/">NMT</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/CNN/">CNN</a><a href="/tags/ByteBet/">ByteBet</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/13/Attention Is All You Need/"><span>
                Paper Reading - Attention Is All You Need</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/13/Attention Is All You Need/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-13T01:30:19.000Z">
                    2017-08-13
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <p>Google的<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">这篇论文</a>提出了一个只使用Attention机制的神经翻译模型，该模型依旧采用编码器-解码器（Encoder-Decoder）架构，但未使用RNN和CNN。文章的主要目的是在减少计算量和提高并行效率的同时不损害最终的实验结果，创新之处在于提出了两个新的Attention机制，分别叫做 Scaled Dot-Product Attention 和 Multi-Head Attention.</p>
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/博客/">博客</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/NMT/">NMT</a><a href="/tags/Attention/">Attention</a><a href="/tags/Deep-NLP/">Deep NLP</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/12/Deep NLP - Question Answering/"><span>
                Deep NLP - Question Answering</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/12/Deep NLP - Question Answering/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-12T13:30:19.000Z">
                    2017-08-12
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <p>Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.</p>
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/笔记/">笔记</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/Attention/">Attention</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/QA/">QA</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/10/Deep NLP - Speech Recognition/"><span>
                Deep NLP - Speech Recognition</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/10/Deep NLP - Speech Recognition/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-10T13:30:19.000Z">
                    2017-08-10
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <p>Speech recognition (SR) is the inter-disciplinary sub-field of computational linguistics that develops methodologies and technologies that enables the recognition and translation of spoken language into text by computers.
            
        </p></div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/笔记/">笔记</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/Speech-Recognition/">Speech Recognition</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/09/Deep NLP - Conditional Language Model with Attention/"><span>
                Deep NLP - Conditional Language Model with Attention</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/09/Deep NLP - Conditional Language Model with Attention/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-09T14:30:19.000Z">
                    2017-08-09
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <!-- toc -->
<ul>
<li><a href="#machine-translation-with-attention">Machine translation with attention</a>
<ul>
<li><a href="#with-concatenation">With Concatenation</a></li>
<li><a href="#with-convolutional-nets">With Convolutional Nets</a></li>
<li><a href="#with-bidirectional-rnns">With Bidirectional RNNS</a></li>
<li><a href="#attention">Attention</a></li>
</ul></li>
<li><a href="#image-caption-generation-with-attention">Image caption generation with attention</a></li>
</ul>
<!-- tocstop -->
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/笔记/">笔记</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/NMT/">NMT</a><a href="/tags/Attention/">Attention</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/Machine-Translation/">Machine Translation</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/08/Deep NLP - Conditional Language Modeling/"><span>
                Deep NLP - Conditional Language Model</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/08/Deep NLP - Conditional Language Modeling/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-08T13:30:19.000Z">
                    2017-08-08
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <!-- toc -->
<ul>
<li><a href="#kalchbrenner-and-blunsom-2013">Kalchbrenner and Blunsom 2013</a></li>
<li><a href="#sutskever-et-al-2014">Sutskever et al. (2014)</a></li>
<li><a href="#kiros-et-al2013">Kiros et al.(2013)</a></li>
</ul>
<!-- tocstop -->
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/笔记/">笔记</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/NMT/">NMT</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/Machine-Translation/">Machine Translation</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/07/Deep NLP - Text Classification/"><span>
                Deep NLP - Text Classification</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/07/Deep NLP - Text Classification/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-07T13:30:19.000Z">
                    2017-08-07
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <!-- toc -->
<ul>
<li><a href="#generative-and-discriminative-models">Generative and discriminative models</a></li>
<li><a href="#naive-bayes-classifier">Naive Bayes classifier</a></li>
<li><a href="#feature-representations">Feature Representations</a></li>
<li><a href="#logistic-regression">Logistic Regression</a></li>
<li><a href="#representing-text-with-a-rnn">Representing Text with a RNN</a></li>
<li><a href="#convolutional-neural-network">Convolutional Neural Network</a></li>
</ul>
<!-- tocstop -->
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/笔记/">笔记</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/LSTM/">LSTM</a><a href="/tags/Naive-Bayes/">Naive Bayes</a><a href="/tags/Text-Classification/">Text Classification</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/06/Deep NLP - RNNs and Language Modelling/"><span>
                Deep NLP - Recurrent Neural Networks and Language Modelling</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/06/Deep NLP - RNNs and Language Modelling/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-06T12:30:19.000Z">
                    2017-08-06
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <!-- toc -->
<ul>
<li><a href="#count-based-n-gram-language-models">Count based N-Gram Language Models</a></li>
<li><a href="#neural-n-gram-language-models">Neural N-Gram Language Models</a></li>
<li><a href="#recurrent-neural-network-language-models">Recurrent Neural Network Language Models</a>
<ul>
<li><a href="#long-short-term-memory-lstm">Long Short Term Memory (LSTM)</a></li>
<li><a href="#deep-rnn-lms">Deep RNN LMs</a></li>
</ul></li>
</ul>
<!-- tocstop -->
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/笔记/">笔记</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/RNN/">RNN</a><a href="/tags/LSTM/">LSTM</a><a href="/tags/Language-Model/">Language Model</a><a href="/tags/N-Gram/">N-Gram</a>
            </span>
            

        </div>

        
    </div>
</article>




<h1></h1>
<article>

    
    
    <h3 class="article-title"><a href="/2017/08/05/DeepNLP-Word Level Semantics/"><span>
                Deep NLP - Word Level Semantics</span></a></h3>
    
    

    <div class="article-top-meta">
        <span class="posted-on">
            <a href="/2017/08/05/DeepNLP-Word Level Semantics/" rel="bookmark">
                <time class="entry-date published" datetime="2017-08-05T10:30:19.000Z">
                    2017-08-05
                </time>
            </a>
        </span>
    </div>


    

    <div class="article-content">
        <div class="entry">
            
            <!-- toc -->
<ul>
<li><a href="#word-level-semantics">Word Level Semantics</a>
<ul>
<li><a href="#count-based-methods">Count-based methods</a></li>
<li><a href="#neural-embedding-models">Neural Embedding Models</a>
<ul>
<li><a href="#cw">C&amp;W</a></li>
<li><a href="#cbow">CBoW</a></li>
<li><a href="#skip-gram">Skip-gram</a></li>
</ul></li>
<li><a href="#task-based-embedding-learning">Task-based Embedding Learning</a></li>
</ul></li>
</ul>
<!-- tocstop -->
            
        </div>

    </div>

    <div class="article-footer">
        <div class="article-meta pull-left">

            
            

            <span class="post-categories">
                <i class="icon-categories"></i>
                <a href="/categories/笔记/">笔记</a>
            </span>
            

            
            

            <span class="post-tags">
                <i class="icon-tags"></i>
                <a href="/tags/Deep-Learning/">Deep Learning</a><a href="/tags/NLP/">NLP</a><a href="/tags/Deep-NLP/">Deep NLP</a><a href="/tags/Word2Vec/">Word2Vec</a><a href="/tags/CBoW/">CBoW</a><a href="/tags/Skip-gram/">Skip-gram</a>
            </span>
            

        </div>

        
    </div>
</article>




<nav class="pagination">
  
  <a href="/page/3/" class="pagination-prev">Prev</a>
  
  
  <a href="/page/5/" class="pagination-next">Next</a>
  
</nav>
      </main>

      <footer class="site-footer">
  <p class="site-info">
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank">Hacker</a>
    <br>
    
    &copy;
    2019
    NIUHE <a href="https://github.com/NeymarL" target="_blank"><i class="fab fa-github"></i></a>
    
  </p>
</footer>
      
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
        tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
  </script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
          var all = MathJax.Hub.getAllJax(), i;
          for(i=0; i < all.length; i += 1) {
              all[i].SourceElement().parentNode.className += ' has-jax';
          }
      });
  </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

      <script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
    </div>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>